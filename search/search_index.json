{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"INTRODUCCI\u00d3N","text":"<p>El proyecto general de Comfenalco tiene como objetivo principal optimizar y estructurar la gesti\u00f3n de datos de la organizaci\u00f3n para facilitar la toma de decisiones informadas y estrat\u00e9gicas. A trav\u00e9s de un enfoque integral, el proyecto abarca diferentes \u00e1reas clave como educaci\u00f3n, protecci\u00f3n social, programas transversales y servicios administrativos, consolidando la informaci\u00f3n en una plataforma robusta y escalable.</p> <p>Este esfuerzo tiene como base la implementaci\u00f3n de un Data Warehouse (DWH) centralizado, el cual adopta un modelo dimensional para garantizar la eficiencia en el acceso y an\u00e1lisis de datos. Adem\u00e1s, se dise\u00f1an e implementan procesos de Extracci\u00f3n, Transformaci\u00f3n y Carga (ETL) que permiten integrar y normalizar la informaci\u00f3n proveniente de diversas fuentes operativas, asegurando su calidad y relevancia para las \u00e1reas funcionales.</p>"},{"location":"#objetivos-del-proyecto","title":"Objetivos del Proyecto","text":"<p>Objetivo General:</p> <ul> <li>Desarrollar una soluci\u00f3n tecnol\u00f3gica que permite la consolidaci\u00f3n, an\u00e1lisis y explotaci\u00f3n eficiente de los datos organizacionales para apoyar la planeaci\u00f3n estrat\u00e9gica y operativa de Comfenalco.</li> </ul> <p>Objetivos Espec\u00edficos:</p> <ol> <li>Centralizar la informaci\u00f3n de m\u00faltiples \u00e1reas en un sistema \u00fanico, garantizando la consistencia y accesibilidad de los datos.</li> <li>Dise\u00f1ar modelos de datos modulares que permiten an\u00e1lisis por dimensiones espec\u00edficas como tiempo, poblaci\u00f3n, servicios, y programas acad\u00e9micos.</li> <li>Implementar mecanismos que aseguran la integridad, seguridad y calidad de los datos procesados.</li> <li>Proveer herramientas y reportes anal\u00edticos que facilitan la supervisi\u00f3n del desempe\u00f1o y la identificaci\u00f3n de oportunidades de mejora.</li> <li>Asegurar la escalabilidad del sistema para adaptarse a futuras necesidades de informaci\u00f3n y m\u00f3dulos adicionales.</li> </ol>"},{"location":"#alcance","title":"Alcance","text":"<p>El proyecto abarca la optimizaci\u00f3n y mejora de los procesos de gesti\u00f3n de datos en \u00e1reas como:</p> <ul> <li>Educaci\u00f3n Formal y Continua: Incluyendo informaci\u00f3n sobre estudiantes, docentes, matr\u00edculas, y desempe\u00f1o acad\u00e9mico.</li> <li>Protecci\u00f3n Social: Gesti\u00f3n de poblaciones vulnerables, programas de cobertura y caracterizaci\u00f3n.</li> <li>Programas Transversales: Datos sobre servicios administrativos, financieros y operativos.</li> <li>Gesti\u00f3n de Recursos: Informaci\u00f3n de bibliotecas, transporte, y servicios auxiliares.</li> </ul> <p>La implementaci\u00f3n del DWH est\u00e1 respaldada por \u00edndices optimizados y esquemas de modelado que permiten consultas eficientes, integraciones directas con plataformas de an\u00e1lisis y reportes avanzados.</p>"},{"location":"#impacto-esperado","title":"Impacto Esperado","text":"<p>Con este proyecto, Comfenalco cuenta con una herramienta centralizada para la gesti\u00f3n y an\u00e1lisis de datos que proporciona:</p> <ul> <li>Mayor eficiencia operativa al reducir redundancias y tiempos de procesamiento.</li> <li>Toma de decisiones basada en datos con acceso r\u00e1pido a informaci\u00f3n consolidada.</li> <li>Cumplimiento normativo y de calidad gracias a procesos de auditor\u00eda y normalizaci\u00f3n.</li> <li>Escalabilidad tecnol\u00f3gica para abordar retos futuros.</li> </ul> <p>Se generan tres diagramas que integran todo el proyecto con el fin de proporcionar una visi\u00f3n clara y estructurada:</p> <ol> <li>Diagrama de flujo de datos: Representa c\u00f3mo se organizan e integran los datos desde sus fuentes hasta el Data Warehouse (DWH).</li> <li>Diagrama entidad-relaci\u00f3n: Muestra las relaciones entre las tablas principales del modelo de datos, incluyendo dimensiones y hechos.</li> <li>Diagrama de secuencia: Describe el proceso de ETL desde la extracci\u00f3n de datos hasta su carga en el DWH.</li> </ol>"},{"location":"#diagramas","title":"Diagramas","text":""},{"location":"#diagrama-1-flujo-de-datos","title":"Diagrama 1: Flujo de Datos","text":"<pre><code>graph TD\n    A(Fuentes de Datos) --&gt; B(Extracci\u00f3n)\n    B --&gt; C(Transformaci\u00f3n)\n    C --&gt; D(Carga en el Data Warehouse)\n    D --&gt; E(M\u00f3dulos Espec\u00edficos)\n    E --&gt; F(An\u00e1lisis y Reportes)\n    E --&gt; G(Integraci\u00f3n con Plataformas)\n    F --&gt; H(Toma de Decisiones Estrat\u00e9gicas)</code></pre>"},{"location":"#diagrama-2-entidad-relacion","title":"Diagrama 2: Entidad-Relaci\u00f3n","text":"<pre><code>erDiagram\n    DIM_TIEMPO {\n        int ID_FECHA PK\n        datetime FECHA\n        varchar DIA_SEMANA\n        varchar MES\n        int ANIO\n    }\n\n    DIM_ESTUDIANTES {\n        int ID_ESTUDIANTE PK\n        varchar NOMBRE\n        varchar DOCUMENTO\n        int ID_PROGRAMA FK\n    }\n\n    DIM_PROGRAMA {\n        int ID_PROGRAMA PK\n        varchar NOMBRE_PROGRAMA\n    }\n\n    FACT_MATRICULAS {\n        int ID_MATRICULA PK\n        int ID_ESTUDIANTE FK\n        int ID_FECHA FK\n        int ID_PROGRAMA FK\n        decimal COSTO\n    }\n\n    DIM_TIEMPO ||--o{ FACT_MATRICULAS : \"ID_FECHA\"\n    DIM_ESTUDIANTES ||--o{ FACT_MATRICULAS : \"ID_ESTUDIANTE\"\n    DIM_PROGRAMA ||--o{ FACT_MATRICULAS : \"ID_PROGRAMA\"</code></pre>"},{"location":"#diagrama-3-secuencia-del-proceso-etl","title":"Diagrama 3: Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    participant Fuente as Fuentes de Datos\n    participant ETL as Proceso ETL\n    participant DWH as Data Warehouse\n    participant Usuario as Usuario Final\n\n    Fuente -&gt;&gt; ETL: Proveer datos crudos\n    ETL -&gt;&gt; ETL: Limpiar y transformar datos\n    ETL -&gt;&gt; DWH: Cargar datos transformados\n    DWH -&gt;&gt; Usuario: Proveer reportes y an\u00e1lisis\n    Usuario -&gt;&gt; DWH: Consultar datos espec\u00edficos</code></pre>"},{"location":"Conexiones_BD/","title":"CONEXI\u00d3N A BASE DE DATOS","text":""},{"location":"Conexiones_BD/#documentacion-para-conexion-a-bases-de-datos-comfenalco","title":"Documentaci\u00f3n para Conexi\u00f3n a Bases de Datos Comfenalco","text":"<p>Este apartado detalla los pasos y configuraciones necesarias para acceder a las distintas fuentes de datos utilizadas en el proyecto de Comfenalco, incluyendo DWH, Q10 y C4C. </p>"},{"location":"Conexiones_BD/#requisitos-previos","title":"Requisitos Previos","text":""},{"location":"Conexiones_BD/#instalacion-y-configuracion-de-vpn","title":"Instalaci\u00f3n y Configuraci\u00f3n de VPN","text":"<ol> <li>Descargue e instale FortiClient VPN.</li> <li>Configure la conexi\u00f3n VPN de acuerdo con las instrucciones de la imagen.  </li> <li>Use las siguientes credenciales:<ul> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxxxxx</code></li> </ul> </li> </ol>"},{"location":"Conexiones_BD/#acceso-a-las-fuentes-de-datos","title":"Acceso a las Fuentes de Datos","text":""},{"location":"Conexiones_BD/#1-data-warehouse-dwh","title":"1. Data Warehouse (DWH)","text":"<ul> <li>Requisitos: Es necesario estar conectado a la VPN.</li> <li>Acceso:<ul> <li>Use SQL Server Management Studio 20 (versi\u00f3n 20.1.10.0 o posterior).</li> <li>Configure la conexi\u00f3n utilizando las instrucciones del archivo <code>\"02.ConfiguracionDWH\"</code>.</li> </ul> </li> <li>Credenciales:<ul> <li>Use las mismas credenciales configuradas para la VPN.</li> </ul> </li> </ul>"},{"location":"Conexiones_BD/#2-q10","title":"2. Q10","text":"<p>El acceso a Q10 no requiere conexi\u00f3n VPN. Siga las instrucciones seg\u00fan el portal espec\u00edfico:</p> <ul> <li> <p>Q10 Cedesarrollo:</p> <ul> <li>URL: https://site.q10.com/login?ReturnUrl=%2F&amp;aplentId=8fa60f3a-1a89-4048-a798-afd5cda72549</li> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxxxxxxx</code></li> </ul> </li> <li> <p>Q10 Desarrollo Empresarial:</p> <ul> <li>URL: https://site.q10.com/login?ReturnUrl=%2F&amp;aplentId=da5db6b7-bead-4cee-b8d0-6503733312d6</li> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxx</code></li> </ul> </li> </ul>"},{"location":"Conexiones_BD/#3-c4c","title":"3. C4C","text":"<ul> <li>Requisitos: Se requiere conexi\u00f3n previa a la VPN para acceder.</li> <li> <p>Acceso:</p> <ul> <li>Ingrese con las siguientes credenciales:</li> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxxx</code></li> <li>URL: https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime</li> </ul> </li> </ul>"},{"location":"Conexiones_BD/#notas-importantes","title":"Notas Importantes","text":"<ul> <li> <p>Licencias</p> <ul> <li><code>Q10</code> requiere licencia para el m\u00f3dulo de <code>cedesarrollo</code> y otra licencia para el m\u00f3dulo <code>desarrollo empresarial</code></li> <li><code>C4C</code> requiere licencia vinculada a <code>SAP</code> </li> </ul> </li> <li> <p>VPN:</p> <ul> <li>La conexi\u00f3n VPN es esencial para el acceso a DWH y C4C, pero no se requiere para Q10.</li> <li>Aseg\u00farese de mantener la VPN activa durante toda la sesi\u00f3n de trabajo.</li> </ul> </li> <li> <p>Seguridad:</p> <ul> <li>Evite compartir las credenciales de acceso.</li> <li>Cierre la sesi\u00f3n despu\u00e9s de utilizar las plataformas.</li> </ul> </li> <li> <p>Soporte:</p> <ul> <li>Para problemas de conexi\u00f3n o configuraci\u00f3n, comun\u00edquese con el equipo de TI o consulte los videos de referencia en los documentos de configuraci\u00f3n.</li> </ul> </li> </ul> <p>Esta gu\u00eda asegura un acceso seguro y estructurado a las fuentes de datos clave del proyecto.</p>"},{"location":"about/","title":"Acerca de este proyecto","text":"<p>Este proyecto tiene como objetivo proporcionar una soluci\u00f3n eficiente y f\u00e1cil de usar para [describir el prop\u00f3sito del proyecto]. </p>"},{"location":"about/#proposito","title":"Prop\u00f3sito","text":"<p>El prop\u00f3sito de este proyecto es [especificar el prop\u00f3sito del proyecto, por ejemplo, facilitar la edici\u00f3n de documentos, mejorar la colaboraci\u00f3n, etc.].</p>"},{"location":"about/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>Caracter\u00edstica 1: [Descripci\u00f3n de la caracter\u00edstica 1]</li> <li>Caracter\u00edstica 2: [Descripci\u00f3n de la caracter\u00edstica 2]</li> <li>Caracter\u00edstica 3: [Descripci\u00f3n de la caracter\u00edstica 3]</li> </ul>"},{"location":"about/#detalles-relevantes","title":"Detalles relevantes","text":"<p>Para m\u00e1s informaci\u00f3n sobre c\u00f3mo contribuir o utilizar este proyecto, consulte la documentaci\u00f3n en [enlace a la documentaci\u00f3n o repositorio].</p>"},{"location":"buenaspracticas/","title":"Buenas Pr\u00e1cticas Implementadas en el Proyecto Comfenalco","text":""},{"location":"buenaspracticas/#buenas-practicas-implementadas-en-el-proyecto-comfenalco","title":"Buenas Pr\u00e1cticas Implementadas en el Proyecto Comfenalco","text":"<p>El proyecto Comfenalco adopta una serie de buenas pr\u00e1cticas para garantizar la eficiencia, escalabilidad, calidad y mantenibilidad de los procesos y el Data Warehouse (DWH). A continuaci\u00f3n, se destacan las principales buenas pr\u00e1cticas identificadas y aplicadas en el proyecto, con el an\u00e1lisis adicional del archivo <code>Funciones.py</code>.</p>"},{"location":"buenaspracticas/#1-modelado-dimensional","title":"1. Modelado Dimensional","text":"<p>Descripci\u00f3n: El uso de un modelo dimensional permite organizar los datos en tablas de dimensiones y hechos, optimizando las consultas y an\u00e1lisis. Esto asegura un dise\u00f1o eficiente y escalable.</p> <p>Ejemplos: - Tablas <code>DIM_TIEMPO</code>, <code>DIM_ESTUDIANTES</code> y <code>FACT_NOTAS</code> para an\u00e1lisis temporal y acad\u00e9mico. - Separaci\u00f3n clara entre datos descriptivos (dimensiones) y m\u00e9tricas (hechos), como en los m\u00f3dulos <code>Cedesarrollo</code>, <code>Protecci\u00f3n</code> y <code>Colegio</code>.</p> <p>Beneficios: - Eficiencia en las consultas. - Flexibilidad para agregar nuevas dimensiones y hechos.</p>"},{"location":"buenaspracticas/#2-integridad-referencial","title":"2. Integridad Referencial","text":"<p>Descripci\u00f3n: El uso de claves primarias y for\u00e1neas en todas las relaciones asegura la consistencia de los datos entre tablas.</p> <p>Ejemplos: - Relaciones entre <code>DIM_ESTUDIANTES</code>, <code>DIM_PROGRAMA</code> y <code>FACT_MATRICULAS</code>. - Implementaci\u00f3n de restricciones <code>FOREIGN KEY</code> en m\u00f3dulos como <code>Transversal</code> y <code>Cedesarrollo</code>.</p> <p>Beneficios: - Evita inconsistencias y errores en los datos. - Garantiza la coherencia de las relaciones.</p>"},{"location":"buenaspracticas/#3-automatizacion-y-modularidad-en-el-etl","title":"3. Automatizaci\u00f3n y Modularidad en el ETL","text":"<p>Descripci\u00f3n: El proyecto utiliza un flujo ETL modular y automatizado para facilitar la extracci\u00f3n, transformaci\u00f3n y carga de datos.</p> <p>Ejemplos: - Uso de decoradores para registrar eventos y tiempos en funciones clave como <code>process_files_from_folder</code>. - Dise\u00f1o modular mediante funciones espec\u00edficas como <code>guardar_en_dwh</code>, <code>obtener_conexion</code> y <code>limpiar_html</code>.</p> <p>Beneficios: - Reutilizaci\u00f3n de c\u00f3digo. - Facilidad para realizar ajustes y escalabilidad.</p>"},{"location":"buenaspracticas/#4-gestion-de-credenciales-segura","title":"4. Gesti\u00f3n de Credenciales Segura","text":"<p>Descripci\u00f3n: Las credenciales se gestionan de forma centralizada y segura mediante archivos de configuraci\u00f3n externos y bibliotecas como <code>configparser</code>.</p> <p>Ejemplos: - Funci\u00f3n <code>credenciales</code> para obtener credenciales de plataformas espec\u00edficas. - Uso de archivos <code>.env</code> para almacenar credenciales sensibles.</p> <p>Beneficios: - Mejora la seguridad al evitar exposici\u00f3n directa de credenciales en el c\u00f3digo. - Facilita la configuraci\u00f3n de m\u00faltiples entornos.</p>"},{"location":"buenaspracticas/#5-registro-detallado-con-logging","title":"5. Registro Detallado con Logging","text":"<p>Descripci\u00f3n: El uso del m\u00f3dulo <code>logging</code> asegura el registro detallado de eventos, errores y tiempos de procesamiento.</p> <p>Ejemplos: - Decorador <code>log_step_decorator</code> para registrar el inicio, finalizaci\u00f3n y duraci\u00f3n de procesos. - Configuraci\u00f3n de logs personalizados para registrar eventos a nivel de consola y archivo.</p> <p>Beneficios: - Facilita la depuraci\u00f3n y el monitoreo de procesos. - Proporciona trazabilidad completa de las operaciones realizadas.</p>"},{"location":"buenaspracticas/#6-gestion-de-archivos-automatizada","title":"6. Gesti\u00f3n de Archivos Automatizada","text":"<p>Descripci\u00f3n: El proyecto incluye funciones avanzadas para procesar, descargar, renombrar y cargar archivos de forma automatizada.</p> <p>Ejemplos: - Funci\u00f3n <code>process_files_from_folder</code> para procesar archivos en una carpeta espec\u00edfica. - <code>upload_file_to_sharepoint</code> para subir archivos autom\u00e1ticamente a SharePoint.</p> <p>Beneficios: - Ahorro de tiempo y reducci\u00f3n de errores manuales. - Consistencia en la gesti\u00f3n de archivos.</p>"},{"location":"buenaspracticas/#7-limpieza-y-normalizacion-de-datos","title":"7. Limpieza y Normalizaci\u00f3n de Datos","text":"<p>Descripci\u00f3n: Se asegura la calidad de los datos mediante funciones dedicadas a la limpieza y estandarizaci\u00f3n.</p> <p>Ejemplos: - <code>limpiar_columnas</code> para eliminar columnas innecesarias y renombrar columnas clave. - <code>replace_values_df</code> para reemplazar valores basados en un diccionario.</p> <p>Beneficios: - Datos m\u00e1s precisos y consistentes. - Menor riesgo de errores en an\u00e1lisis y reportes.</p>"},{"location":"buenaspracticas/#8-escalabilidad-y-modularidad","title":"8. Escalabilidad y Modularidad","text":"<p>Descripci\u00f3n: El dise\u00f1o modular permite incorporar nuevas funciones sin afectar el flujo existente.</p> <p>Ejemplos: - Funciones espec\u00edficas para operaciones como <code>procesar_excel_con_hojas</code>, <code>Combine_and_store</code>, y <code>setup_driver</code>. - Uso de decoradores para extender la funcionalidad sin alterar el c\u00f3digo base.</p> <p>Beneficios: - Reducci\u00f3n de tiempos de implementaci\u00f3n para nuevos requerimientos. - Facilita el mantenimiento y la expansi\u00f3n del sistema.</p>"},{"location":"buenaspracticas/#9-buenas-practicas-de-programacion-en-python","title":"9. Buenas Pr\u00e1cticas de Programaci\u00f3n en Python","text":"<p>Descripci\u00f3n: El c\u00f3digo sigue las buenas pr\u00e1cticas de Python, como modularidad, uso de decoradores, y manejo seguro de excepciones.</p> <p>Ejemplos: - Decoradores como <code>log_step_decorator</code> para mejorar la legibilidad y reutilizaci\u00f3n del c\u00f3digo. - Manejo robusto de excepciones en funciones cr\u00edticas como <code>procesar</code>, <code>descargar_archivos</code> y <code>setup_logger</code>.</p> <p>Beneficios: - Mejora la mantenibilidad del c\u00f3digo. - Reduce errores inesperados durante la ejecuci\u00f3n.</p>"},{"location":"buenaspracticas/#10-uso-de-selenium-para-automatizacion-de-navegacion-web","title":"10. Uso de Selenium para Automatizaci\u00f3n de Navegaci\u00f3n Web","text":"<p>Descripci\u00f3n: Se utiliza Selenium para realizar automatizaci\u00f3n avanzada de navegaci\u00f3n web y manipulaci\u00f3n de interfaces web.</p> <p>Ejemplos: - Funci\u00f3n <code>setup_driver</code> para configurar un entorno de Selenium optimizado. - Operaciones complejas en men\u00fas desplegables y modales mediante funciones como <code>seleccionar_opcion_custom_dropdown</code>.</p> <p>Beneficios: - Automatizaci\u00f3n de tareas repetitivas. - Mayor precisi\u00f3n en la interacci\u00f3n con plataformas web.</p>"},{"location":"buenaspracticas/#11-control-de-versiones-en-descargas","title":"11. Control de Versiones en Descargas","text":"<p>Descripci\u00f3n: Las descargas y sus versiones se manejan de manera efectiva para evitar conflictos de nombres y redundancias.</p> <p>Ejemplos: - Uso de <code>corregir_nombre_archivo</code> para generar nombres \u00fanicos y manejables. - Verificaci\u00f3n de archivos existentes antes de sobrescribir.</p> <p>Beneficios: - Evita p\u00e9rdida de datos por sobrescritura accidental. - Proporciona una estructura clara para las versiones de archivos.</p>"},{"location":"buenaspracticas/#12-facilidad-para-actualizar-credenciales-de-sharepoint","title":"12. Facilidad para Actualizar Credenciales de SharePoint","text":"<p>Descripci\u00f3n: El proyecto Comfenalco incluye una implementaci\u00f3n que permite cambiar las credenciales de SharePoint de manera centralizada y sencilla sin necesidad de modificar el c\u00f3digo fuente del proyecto. Esto se logra utilizando un archivo de configuraci\u00f3n (<code>credenciales.env</code>) para almacenar las credenciales de manera externa.</p> <p>Ejemplo de Implementaci\u00f3n:</p> <ol> <li> <p>Gesti\u00f3n Centralizada de Credenciales:     Las credenciales de SharePoint se almacenan en un archivo llamado <code>credenciales.env</code> ubicado en el directorio del proyecto:</p> <pre><code>client_id = \"nuevo_client_id\"\ncert_thumbprint = \"nueva_cert_thumbprint\"\ntenant_id = \"nuevo_tenant_id\"\nscopes_sharepoint_online = \"https://new.scope.url/.default\"\nsharepoint_base_url = \"https://new.sharepoint.url\"\n</code></pre> </li> <li> <p>Carga Din\u00e1mica de Credenciales:     En el c\u00f3digo, la funci\u00f3n <code>credenciales</code> se encarga de leer este archivo y devolver las credenciales necesarias para conectarse a SharePoint:</p> <pre><code>def credenciales():\n    original_dir = os.getcwd()\n    try:\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        os.chdir(script_dir)\n\n        # Leer las credenciales desde el archivo credenciales.env\n        with open('credenciales.env', 'r') as key_file:\n            lines = key_file.readlines()\n\n        keys = {}\n        for line in lines:\n            key, value = line.strip().split(\" = \")\n            keys[key] = value.strip('\"')\n\n        return keys\n    finally:\n        os.chdir(original_dir)\n</code></pre> </li> <li> <p>Uso en el Proyecto:     Las credenciales cargadas din\u00e1micamente se utilizan para configurar la conexi\u00f3n a SharePoint sin necesidad de modificaciones adicionales en el proyecto:</p> <pre><code>keys = credenciales()\n\nmsal_app = ConfidentialClientApplication(\n    client_id=keys.get(\"client_id\"),\n    authority=f\"https://login.microsoftonline.com/{keys.get('tenant_id')}\",\n    client_credential={\n        \"private_key\": open('key.pem').read(),\n        \"thumbprint\": keys.get(\"cert_thumbprint\")\n    },\n)\n\nheaders = {\n    \"Authorization\": f\"Bearer {msal_app.acquire_token_for_client([keys.get('scopes_sharepoint_online')])['access_token']}\",\n    \"Accept\": \"application/json;odata=verbose\",\n    \"Content-Type\": \"application/json\",\n}\n</code></pre> </li> <li> <p>Cambio de Credenciales en Tiempo de Ejecuci\u00f3n:     Para actualizar las credenciales, solo se necesita modificar el archivo <code>credenciales.env</code> con los nuevos valores. No es necesario cambiar el c\u00f3digo ni reiniciar el proyecto.</p> </li> </ol> <p>Ventajas:</p> <ul> <li>Centralizaci\u00f3n: Permite un \u00fanico punto de administraci\u00f3n de credenciales.</li> <li>Seguridad: Mantiene las credenciales fuera del c\u00f3digo fuente, reduciendo riesgos de exposici\u00f3n.</li> <li>Flexibilidad: Facilita actualizaciones r\u00e1pidas en entornos de desarrollo, pruebas y producci\u00f3n.</li> <li>Escalabilidad: Compatible con m\u00faltiples entornos sin necesidad de cambios en el c\u00f3digo.</li> </ul>"},{"location":"buenaspracticas/#conclusion","title":"Conclusi\u00f3n","text":"<p>Las pr\u00e1cticas implementadas en el proyecto Comfenalco no solo garantizan la eficiencia y la escalabilidad t\u00e9cnica, sino que tambi\u00e9n aseguran la calidad y la seguridad de los procesos. Este enfoque integral establece una base s\u00f3lida para la sostenibilidad y expansi\u00f3n del sistema.</p>"},{"location":"instalacion/","title":"INSTALACI\u00d3N Y CONFIGURACI\u00d3N","text":""},{"location":"instalacion/#instalacion-y-configuracion-del-entorno-para-el-proyecto-comfenalco","title":"Instalaci\u00f3n y Configuraci\u00f3n del Entorno para el Proyecto Comfenalco","text":"<p>Este apartado detalla los pasos necesarios para configurar un entorno funcional que permita la implementaci\u00f3n y ejecuci\u00f3n de los procesos de carga, transformaci\u00f3n y an\u00e1lisis de datos utilizados en el proyecto de Comfenalco. El objetivo principal es garantizar una instalaci\u00f3n uniforme de herramientas y dependencias, configurar correctamente las conexiones a las bases de datos y estructurar el entorno para el \u00f3ptimo funcionamiento del Data Warehouse (DWH).</p>"},{"location":"instalacion/#pasos-para-la-configuracion-del-entorno","title":"Pasos para la Configuraci\u00f3n del Entorno","text":""},{"location":"instalacion/#1-instalacion-de-herramientas-necesarias","title":"1. Instalaci\u00f3n de Herramientas Necesarias","text":""},{"location":"instalacion/#versionamiento-de-herramientas","title":"Versionamiento de Herramientas","text":"<p>Los paquetes ETL del proyecto Comfenalco se desarrollaron originalmente utilizando Visual Studio Community 2022, seg\u00fan las definiciones establecidas en la fase 1 del proyecto. Posteriormente, en la entrega del proyecto, Comfenalco degrada a la versi\u00f3n Visual Studio Professional 2019 para garantizar compatibilidad con los est\u00e1ndares de la organizaci\u00f3n.</p> <p>Entre el 14 y el 17 de enero de 2025, se llevaron a cabo mesas de trabajo conjuntas con el equipo de Comfenalco. Durante estas sesiones, se validaron los paquetes y se realiz\u00f3 la migraci\u00f3n al servidor de pruebas, asegurando el correcto funcionamiento en el entorno de la organizaci\u00f3n. </p>"},{"location":"instalacion/#11-sql-server-management-studio-ssms","title":"1.1 SQL Server Management Studio (SSMS)","text":"<p>Requisitos:</p> <ul> <li>Versi\u00f3n 20.1.10.0 o posterior.</li> <li>Disponible en el siguiente enlace: Descargar SSMS.</li> </ul>"},{"location":"instalacion/#12-visual-studio","title":"1.2 Visual Studio","text":"<p>Versi\u00f3n:</p> <ul> <li>Comfenalco utiliza Visual Studio Profesional 2019 (paga).</li> <li>Para desarrollo, se utiliza Visual Studio Community 2022 (gratuita), versi\u00f3n 17.11.5.</li> <li>Disponible en el siguiente enlace: Descargar Visual Studio Community.</li> </ul>"},{"location":"instalacion/#13-integration-services-ssis","title":"1.3 Integration Services (SSIS)","text":"<p>Pasos de Instalaci\u00f3n:</p> <ol> <li>Crear un proyecto en blanco en Visual Studio.</li> <li>Ir a la pesta\u00f1a Extensiones \u2192 Administrar Extensiones.</li> <li>Buscar Integration Services e instalar la versi\u00f3n 1.3.2 (compatibilidad con Visual Studio 17.11.5).</li> </ol>"},{"location":"instalacion/#14-analysis-services-ssas","title":"1.4 Analysis Services (SSAS)","text":"<p>Pasos de Instalaci\u00f3n:</p> <ol> <li>Crear un proyecto en blanco en Visual Studio.</li> <li>Ir a la pesta\u00f1a Extensiones \u2192 Administrar Extensiones.</li> <li>Buscar Analysis Services e instalar la versi\u00f3n m\u00e1s reciente.</li> <li>Validar que no presente problemas de compatibilidad.</li> </ol>"},{"location":"instalacion/#recomendaciones","title":"Recomendaciones:","text":"<p>Se recomienda dejar las mismas estructuras. La actualizaci\u00f3n de datos de consultas y web scraping es autom\u00e1tica. Y la de archivos corresponde a los propietarios de la informaci\u00f3n.</p>"},{"location":"instalacion/#2-creacion-del-entorno-virtual","title":"2. Creaci\u00f3n del Entorno Virtual","text":"<p>Un entorno virtual permite organizar y aislar las dependencias necesarias para este proyecto. Siga estos pasos:</p> <p>1. Cree un entorno virtual ejecutando el siguiente comando:</p> <pre><code>python -m venv comfenalco_env\n</code></pre> <p>2. Active el entorno virtual:</p> <p>En Windows:</p> <pre><code>comfenalco_env\\Scripts\\activate\n</code></pre> <p>En Linux/macOS:</p> <pre><code>source comfenalco_env/bin/activate\n</code></pre>"},{"location":"instalacion/#3-instalacion-de-dependencias","title":"3. Instalaci\u00f3n de Dependencias","text":"<p>Una vez activado el entorno virtual, instale las librer\u00edas necesarias:</p> <pre><code>pip install sqlalchemy pandas beautifulsoup4 numpy logging python-dateutil concurrent.futures\n</code></pre>"},{"location":"instalacion/#configuracion-inicial-del-proyecto","title":"Configuraci\u00f3n Inicial del Proyecto","text":""},{"location":"instalacion/#1-creacion-de-conexiones","title":"1. Creaci\u00f3n de Conexiones","text":"<p>1. Configuraci\u00f3n en SSIS:</p> <ul> <li>Use el administrador de conexiones ADO.NET.</li> <li>Cree las siguientes conexiones:<ul> <li><code>DWH_COMFENALCO</code></li> <li><code>STAGE_AREA</code></li> <li><code>SAP_ERP</code></li> </ul> </li> <li>Es importante tener activa la VPN al configurar las conexiones.</li> </ul> <p>2. Configuraci\u00f3n Local:</p> <ul> <li>Cree una base de datos local en SQL Server Management Studio llamada <code>DWH_COMFENALCO_local</code> para realizar pruebas.</li> <li>Cree una conexi\u00f3n a esta base local.</li> </ul> <p>3. Parametrizaci\u00f3n de Conexiones:</p> <ul> <li>Configure las variables <code>ConnectionString</code> y <code>Password</code> en el proyecto de SSIS para cada conexi\u00f3n.</li> <li>Consulte el siguiente video (minuto 11 en adelante).</li> </ul> <p>4. Referencia de Proyecto:</p> <ul> <li>Abra el proyecto de referencia disponible en: Proyecto SSIS.</li> </ul>"},{"location":"instalacion/#funciones-principales-del-proyecto","title":"Funciones Principales del Proyecto","text":""},{"location":"instalacion/#1-configuracion-del-logger","title":"1. Configuraci\u00f3n del Logger","text":"<p>Para garantizar un registro de eventos y errores, utilice la funci\u00f3n <code>setup_logger</code>:</p> <pre><code>from Funciones import setup_logger\nimport logging\n\nlogger = setup_logger(log_filename='etl.log', log_level=logging.INFO)\nlogger.info(\"Proceso de configuraci\u00f3n iniciado.\")\n</code></pre>"},{"location":"instalacion/#2-conexion-a-la-base-de-datos","title":"2. Conexi\u00f3n a la Base de Datos","text":"<p>Configure la conexi\u00f3n a las bases de datos con la funci\u00f3n <code>obtener_conexion</code> y el uso de SQLAlchemy:</p> <pre><code>from Funciones import obtener_conexion\nfrom sqlalchemy import create_engine\n\ncadena_conexion = obtener_conexion('nombre_base_datos')\nmotor = create_engine(cadena_conexion)\n</code></pre>"},{"location":"instalacion/#3-funciones-de-procesamiento","title":"3. Funciones de Procesamiento","text":""},{"location":"instalacion/#31-guardar_en_dwh","title":"3.1 <code>guardar_en_dwh</code>","text":"<ul> <li>Prop\u00f3sito: Guarda un <code>DataFrame</code> en una tabla espec\u00edfica del DWH.</li> <li>Uso:</li> </ul> <pre><code>from Funciones import guardar_en_dwh\n\nguardar_en_dwh(df, 'nombre_tabla', logger, multiple=False, if_exists='replace')\n</code></pre>"},{"location":"instalacion/#32-limpiar_html","title":"3.2 <code>limpiar_html</code>","text":"<ul> <li>Prop\u00f3sito: Limpia el contenido de texto con etiquetas HTML.</li> <li>Uso:</li> </ul> <pre><code>from Funciones import limpiar_html\n\ntexto_limpio = limpiar_html(\"&lt;p&gt;Ejemplo&lt;/p&gt;\")\nprint(texto_limpio)  # Salida: Ejemplo\n</code></pre>"},{"location":"instalacion/#33-storeduplicated","title":"3.3 <code>StoreDuplicated</code>","text":"<ul> <li>Prop\u00f3sito: Guarda registros duplicados para an\u00e1lisis posterior.</li> <li>Uso:</li> </ul> <pre><code>from Funciones import StoreDuplicated\n\nStoreDuplicated(\"duplicados.xlsx\", ['columna1', 'columna2'], df, './output')\n</code></pre>"},{"location":"instalacion/#creacion-del-cubo","title":"Creaci\u00f3n del Cubo","text":"<p>1. Configuraci\u00f3n del Cubo:</p> <ul> <li>Use Analysis Services para crear un cubo que contenga las medidas y KPIs necesarios.</li> <li>Incluya esquemas de datos de <code>Transversal</code>, <code>Colegio</code>, <code>Cedesarrollo</code> y <code>Protecci\u00f3n</code>.</li> </ul> <p>2. Poblaci\u00f3n de Tablas:</p> <ul> <li>Llene primero las tablas Dim y posteriormente las tablas Fact.</li> <li>Aseg\u00farese de que las tablas de DWH est\u00e9n vac\u00edas antes de iniciar el proceso de carga.</li> </ul> <p>3. Consumo en Power BI:</p> <ul> <li>Todas las medidas deben estar definidas en el cubo, ya que Power BI no permite la creaci\u00f3n de medidas en tiempo de consulta.</li> </ul> <p>4. Referencias:</p> <ul> <li>Creaci\u00f3n del Cubo 1.</li> <li>Creaci\u00f3n del Cubo 2.</li> </ul>"},{"location":"instalacion/#ejemplo-de-flujo-etl","title":"Ejemplo de Flujo ETL","text":"<pre><code>from Funciones import obtener_conexion, guardar_en_dwh, setup_logger\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\n# Configurar logger\nlogger = setup_logger(log_filename='etl_proceso.log', log_level=logging.INFO)\n\n# Conectar a la base de datos\ncadena_conexion = obtener_conexion('dwh_comfenalco')\nmotor = create_engine(cadena_conexion)\n\n# Leer datos de origen\ndf_origen = pd.read_sql_query(\"SELECT * FROM tabla_origen\", motor)\n\n# Transformaciones necesarias\ndf_origen['nueva_columna'] = df_origen['columna_existente'] * 2\n\n# Cargar datos transformados al DWH\nguardar_en_dwh(df_origen, 'tabla_destino', logger, multiple=False, if_exists='append')\n</code></pre>"},{"location":"instalacion/#conclusion","title":"Conclusi\u00f3n","text":"<p>Con estos pasos, el entorno estar\u00e1 listo para manejar los procesos ETL del proyecto Comfenalco. Al seguir este flujo, se asegura una configuraci\u00f3n consistente, se minimizan errores y se facilita la integraci\u00f3n de nuevos m\u00f3dulos o expansiones del DWH.</p>"},{"location":"00.etl/00.etl_00.Introduccion/","title":"Introducci\u00f3n","text":""},{"location":"00.etl/00.etl_00.Introduccion/#introduccion-a-los-procesos-etl-basados-en-webscraping-para-educacion-tecnica-y-continua","title":"Introducci\u00f3n a los Procesos ETL Basados en Webscraping para Educaci\u00f3n T\u00e9cnica y Continua","text":"<p>La Educaci\u00f3n T\u00e9cnica y Continua exige sistemas robustos y automatizados para gestionar la creciente cantidad de datos acad\u00e9micos y administrativos. Los procesos ETL (Extract, Transform, Load), fundamentados en t\u00e9cnicas avanzadas de webscraping, aseguran la extracci\u00f3n eficiente, la transformaci\u00f3n precisa y la carga estructurada de datos desde diversas fuentes en l\u00ednea. Este enfoque permite consolidar la informaci\u00f3n en tiempo real, optimizando la toma de decisiones y fomentando la colaboraci\u00f3n a trav\u00e9s de plataformas como SharePoint y C4C.</p>"},{"location":"00.etl/00.etl_00.Introduccion/#01-q10","title":"01. Q10","text":"<p>Los flujos ETL asociados a Q10 se dividen en Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua, cada uno dise\u00f1ado para garantizar la calidad, organizaci\u00f3n y accesibilidad de la informaci\u00f3n. La metodolog\u00eda de webscraping permite extraer datos en tiempo real de sistemas acad\u00e9micos, procesarlos autom\u00e1ticamente y presentarlos de manera estructurada.</p> <ul> <li> <p>Educaci\u00f3n T\u00e9cnica:</p> <ul> <li>Docentes Cedesarrollo: Automatiza la recopilaci\u00f3n de informaci\u00f3n docente para su integraci\u00f3n en sistemas acad\u00e9micos. Ver detalle</li> <li>Dise\u00f1o Curricular: Extrae datos de planes de estudio publicados en plataformas digitales. Ver detalle</li> <li>Listado Matr\u00edculas: Captura y procesa datos de matr\u00edculas de estudiantes desde fuentes en l\u00ednea. Ver detalle</li> <li>Ingresos: Estandariza y organiza datos financieros relacionados con estudiantes. Ver detalle</li> <li>Hist\u00f3rico Notas: Recupera y ordena registros de calificaciones hist\u00f3ricos. Ver detalle</li> <li>Egresados: Automatiza el registro y consolidaci\u00f3n de datos de graduados. Ver detalle</li> <li>Desertores: Identifica y categoriza patrones de deserci\u00f3n estudiantil mediante la extracci\u00f3n de datos en l\u00ednea. Ver detalle</li> </ul> </li> <li> <p>Educaci\u00f3n Continua:</p> <ul> <li>Docentes Desarrollo Empresarial: Consolida informaci\u00f3n de instructores provenientes de plataformas empresariales. Ver detalle</li> <li>Preinscritos: Automatiza la captura y organizaci\u00f3n de registros de preinscripci\u00f3n. Ver detalle</li> <li>Listado Matr\u00edculas Empresarial: Procesa matr\u00edculas de estudiantes en el contexto empresarial. Ver detalle</li> <li>Consolidado Inasistencias: Identifica y resume patrones de inasistencias. Ver detalle</li> <li>Estudiantes Inasistencias: Procesa informaci\u00f3n de estudiantes con ausencias frecuentes. Ver detalle</li> <li>Egresados Graduados Empresarial: Establece registros detallados de egresados empresariales desde fuentes remotas. Ver detalle</li> </ul> </li> </ul>"},{"location":"00.etl/00.etl_00.Introduccion/#02-sharepoint-q10","title":"02. SharePoint Q10","text":"<p>La integraci\u00f3n de SharePoint con Q10 potencia la colaboraci\u00f3n y el acceso en tiempo real a los datos extra\u00eddos mediante webscraping. Esta integraci\u00f3n permite una gesti\u00f3n optimizada y compartida de informaci\u00f3n clave.</p> <ul> <li> <p>Cedesarrollo:</p> <ul> <li>Automatiza la extracci\u00f3n y consolidaci\u00f3n de datos sobre docentes, dise\u00f1o curricular, matr\u00edculas, ingresos y registros hist\u00f3ricos, asegurando su disponibilidad en SharePoint.</li> </ul> </li> <li> <p>Desarrollo Empresarial:</p> <ul> <li>Implementa procesos adaptados al \u00e1mbito empresarial, facilitando la gesti\u00f3n de docentes, matr\u00edculas y otros aspectos relevantes.</li> </ul> </li> </ul>"},{"location":"00.etl/00.etl_00.Introduccion/#03-c4c","title":"03. C4C","text":"<p>Los procesos ETL de C4C integran t\u00e9cnicas avanzadas de webscraping para capturar informaci\u00f3n directamente desde sitios web, proporcionando datos din\u00e1micos y de referencia hist\u00f3rica.</p> <ul> <li>Webscraping Actualizable: Captura datos din\u00e1micos que requieren actualizaciones frecuentes.</li> <li>Webscraping Hist\u00f3rico: Archiva y organiza informaci\u00f3n hist\u00f3rica para an\u00e1lisis comparativos y toma de decisiones estrat\u00e9gicas.</li> </ul>"},{"location":"00.etl/00.etl_00.Introduccion/#beneficios-del-enfoque-basado-en-webscraping","title":"Beneficios del Enfoque Basado en Webscraping","text":"<p>Este marco de procesos ETL garantiza:</p> <ul> <li>Eficiencia: Automatizaci\u00f3n de tareas repetitivas y consumo de datos en tiempo real.</li> <li>Calidad de los Datos: Transformaciones y validaciones en cada etapa del flujo.</li> <li>Accesibilidad: Integraci\u00f3n con plataformas como SharePoint y sistemas externos para compartir informaci\u00f3n.</li> <li>Toma de Decisiones Informada: Disponibilidad de datos actualizados y estructurados para an\u00e1lisis estrat\u00e9gicos.</li> </ul>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/00.Procesar_manual/","title":"00.Procesar manual","text":"<pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    procesar\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\n# Si el logger ya tiene manejadores, limpiarlos\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Crear un formateador para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Crear un manejador de archivo para guardar los logs en un archivo\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)  # Asignar el formateador al manejador de archivo\nlogger.addHandler(file_handler)  # Agregar el manejador de archivo al logger\n\n# Crear un manejador de consola para mostrar los logs en la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)  # Asignar el formateador al manejador de consola\nlogger.addHandler(console_handler)  # Agregar el manejador de consola al logger\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\nlogging.info(\"Inicio del proceso principal\")\ntry:\n    # Definir la subcarpeta de descarga\n    subcarpeta_descarga = \"Graduados\"\n    base_dir = os.path.dirname(os.path.dirname(os.getcwd()))  # Subir un nivel desde el directorio actual\n    # Llamar a setup_driver una vez con la subcarpeta deseada para definir el entorno del navegador\n    DOWNLOAD_DIR = os.path.join(base_dir, \"01.Q10\", \"Procesados\", subcarpeta_descarga) \n    # Procesar todos los informes descargados\n    procesar(\"emp_Egresados_Graduados\",DOWNLOAD_DIR)\n    logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\nfinally:\n    logging.info(\"Fin del proceso principal\")\n</code></pre> <pre><code>2024-12-27 20:36:22,094 - INFO - Inicio del proceso principal\n\n\nProcesando archivo: Graduados_Diciembre 2021.xlsx\nArchivo procesado y guardado como: Graduados_Diciembre 2021_27_12_2024.xlsx\nProcesando archivo: Graduados_Noviembre 2024.xlsx\nArchivo procesado y guardado como: Graduados_Noviembre 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2024.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2024.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2024.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Julio 2024.xlsx\nArchivo procesado y guardado como: Graduados_Julio 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Junio 2024.xlsx\nArchivo procesado y guardado como: Graduados_Junio 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Mayo 2024.xlsx\nArchivo procesado y guardado como: Graduados_Mayo 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Abril 2024.xlsx\nArchivo procesado y guardado como: Graduados_Abril 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Marzo 2024.xlsx\nArchivo procesado y guardado como: Graduados_Marzo 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Febrero 2024.xlsx\nArchivo procesado y guardado como: Graduados_Febrero 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Enero 2024.xlsx\nArchivo procesado y guardado como: Graduados_Enero 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Diciembre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Diciembre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Noviembre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Noviembre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2023.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Julio 2023.xlsx\nArchivo procesado y guardado como: Graduados_Julio 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Junio 2023.xlsx\nArchivo procesado y guardado como: Graduados_Junio 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Mayo 2023.xlsx\nArchivo procesado y guardado como: Graduados_Mayo 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Abril 2023.xlsx\nArchivo procesado y guardado como: Graduados_Abril 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Marzo 2023.xlsx\nArchivo procesado y guardado como: Graduados_Marzo 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Febrero 2023.xlsx\nArchivo procesado y guardado como: Graduados_Febrero 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Enero 2023.xlsx\nArchivo procesado y guardado como: Graduados_Enero 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Diciembre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Diciembre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Noviembre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Noviembre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2022.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Julio 2022.xlsx\nArchivo procesado y guardado como: Graduados_Julio 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Junio 2022.xlsx\nArchivo procesado y guardado como: Graduados_Junio 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Mayo 2022.xlsx\nArchivo procesado y guardado como: Graduados_Mayo 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Abril 2022.xlsx\nArchivo procesado y guardado como: Graduados_Abril 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Marzo 2022.xlsx\nArchivo procesado y guardado como: Graduados_Marzo 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Febrero 2022.xlsx\nArchivo procesado y guardado como: Graduados_Febrero 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Enero 2022.xlsx\nArchivo procesado y guardado como: Graduados_Enero 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2021.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2021_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2021.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2021_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2021.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2021_27_12_2024.xlsx\n\n\n2024-12-27 20:39:24,133 - ERROR - Error al subir el archivo Graduados_Diciembre 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2021_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2021.xlsx\n\n\n2024-12-27 20:39:27,544 - ERROR - Error al subir el archivo Graduados_Noviembre 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2024.xlsx\n\n\n2024-12-27 20:39:31,126 - ERROR - Error al subir el archivo Graduados_Octubre 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2024.xlsx\n\n\n2024-12-27 20:39:34,588 - ERROR - Error al subir el archivo Graduados_Septiembre 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2024.xlsx\n\n\n2024-12-27 20:39:38,070 - ERROR - Error al subir el archivo Graduados_Agosto 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2024.xlsx\n\n\n2024-12-27 20:39:41,622 - ERROR - Error al subir el archivo Graduados_Julio 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2024.xlsx\n\n\n2024-12-27 20:39:45,165 - ERROR - Error al subir el archivo Graduados_Junio 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2024.xlsx\n\n\n2024-12-27 20:39:48,702 - ERROR - Error al subir el archivo Graduados_Mayo 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2024.xlsx\n\n\n2024-12-27 20:39:52,235 - ERROR - Error al subir el archivo Graduados_Abril 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2024.xlsx\n\n\n2024-12-27 20:39:55,767 - ERROR - Error al subir el archivo Graduados_Marzo 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2024.xlsx\n\n\n2024-12-27 20:39:59,245 - ERROR - Error al subir el archivo Graduados_Febrero 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2024.xlsx\n\n\n2024-12-27 20:40:02,708 - ERROR - Error al subir el archivo Graduados_Enero 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2024.xlsx\n\n\n2024-12-27 20:40:06,252 - ERROR - Error al subir el archivo Graduados_Diciembre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2023.xlsx\n\n\n2024-12-27 20:40:09,955 - ERROR - Error al subir el archivo Graduados_Noviembre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2023.xlsx\n\n\n2024-12-27 20:40:13,505 - ERROR - Error al subir el archivo Graduados_Octubre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2023.xlsx\n\n\n2024-12-27 20:40:17,034 - ERROR - Error al subir el archivo Graduados_Septiembre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2023.xlsx\n\n\n2024-12-27 20:40:20,564 - ERROR - Error al subir el archivo Graduados_Agosto 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2023.xlsx\n\n\n2024-12-27 20:40:24,026 - ERROR - Error al subir el archivo Graduados_Julio 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2023.xlsx\n\n\n2024-12-27 20:40:27,668 - ERROR - Error al subir el archivo Graduados_Junio 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2023.xlsx\n\n\n2024-12-27 20:40:31,261 - ERROR - Error al subir el archivo Graduados_Mayo 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2023.xlsx\n\n\n2024-12-27 20:40:34,829 - ERROR - Error al subir el archivo Graduados_Abril 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2023.xlsx\n\n\n2024-12-27 20:40:38,378 - ERROR - Error al subir el archivo Graduados_Marzo 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2023.xlsx\n\n\n2024-12-27 20:40:41,798 - ERROR - Error al subir el archivo Graduados_Febrero 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2023.xlsx\n\n\n2024-12-27 20:40:45,253 - ERROR - Error al subir el archivo Graduados_Enero 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2023.xlsx\n\n\n2024-12-27 20:40:48,678 - ERROR - Error al subir el archivo Graduados_Diciembre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2022.xlsx\n\n\n2024-12-27 20:40:52,215 - ERROR - Error al subir el archivo Graduados_Noviembre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2022.xlsx\n\n\n2024-12-27 20:40:55,747 - ERROR - Error al subir el archivo Graduados_Octubre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2022.xlsx\n\n\n2024-12-27 20:40:59,443 - ERROR - Error al subir el archivo Graduados_Septiembre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2022.xlsx\n\n\n2024-12-27 20:41:02,934 - ERROR - Error al subir el archivo Graduados_Agosto 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2022.xlsx\n\n\n2024-12-27 20:41:06,541 - ERROR - Error al subir el archivo Graduados_Julio 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2022.xlsx\n\n\n2024-12-27 20:41:09,995 - ERROR - Error al subir el archivo Graduados_Junio 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2022.xlsx\n\n\n2024-12-27 20:41:13,458 - ERROR - Error al subir el archivo Graduados_Mayo 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2022.xlsx\n\n\n2024-12-27 20:41:16,902 - ERROR - Error al subir el archivo Graduados_Abril 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2022.xlsx\n\n\n2024-12-27 20:41:20,401 - ERROR - Error al subir el archivo Graduados_Marzo 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2022.xlsx\n\n\n2024-12-27 20:41:23,881 - ERROR - Error al subir el archivo Graduados_Febrero 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2022.xlsx\n\n\n2024-12-27 20:41:27,299 - ERROR - Error al subir el archivo Graduados_Enero 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2022.xlsx\n\n\n2024-12-27 20:41:30,710 - ERROR - Error al subir el archivo Graduados_Agosto 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2021_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2021.xlsx\n\n\n2024-12-27 20:41:34,138 - ERROR - Error al subir el archivo Graduados_Octubre 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2021_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2021.xlsx\n\n\n2024-12-27 20:41:37,540 - ERROR - Error al subir el archivo Graduados_Septiembre 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2021_27_12_2024.xlsx\n\n\n2024-12-27 20:41:40,550 - INFO - Procesamiento de periodos, jornadas y programas completado.\n2024-12-27 20:41:40,551 - INFO - Fin del proceso principal\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2021.xlsx\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/","title":"0.1. Docentes Cedesarrollo.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code> y <code>warnings</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <pre><code>import logging\nimport time\nimport os\nimport sys\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n# Importar funciones personalizadas desde Utils.Funciones\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, _descargar, close_driver, hacer_clic, procesar,\n    configurar_pasos_autenticacion_cedesarrollo, eliminar_archivos_anteriores\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\nlogging.basicConfig(level=logging.INFO)\n\n# Limpiar manejadores existentes si los hay\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Formateador para los logs\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Manejador para archivo de log\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n\n# Manejador para la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/#automatizacion-de-descarga-y-procesamiento-del-reporte-docentes","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Docentes\"","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Docentes\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>DOWNLOAD_DIR</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_cedesarrollo</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Ingresos detallados por producto\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Este enfoque modular y estructurado facilita la depuraci\u00f3n, escalabilidad y mantenimiento del flujo automatizado.</p> <pre><code>@log_step_decorator(\"Docentes Cedesarrollo\")\ndef main():\n    # Inicia el proceso principal con un mensaje en el log\n    logging.info(\"Inicio del proceso principal\")\n    driver = None  # Inicializa el objeto driver como None para asegurar que est\u00e9 definido\n\n    try:\n        # Define la subcarpeta donde se almacenar\u00e1n las descargas\n        subcarpeta_descarga = \"Docentes\"\n\n        # Configura el driver para la automatizaci\u00f3n del navegador, incluyendo la carpeta de descargas\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configura los pasos de autenticaci\u00f3n requeridos\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n        # Elimina archivos previos que podr\u00edan interferir con las descargas actuales\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        eliminar_archivos_anteriores(nombre_archivo=\"Cedesarrollo_DocenteS\", download_dir=DOWNLOAD_DIR)\n\n        # Define los pasos para la automatizaci\u00f3n del proceso\n        step_1 = pasos_autenticacion + [\n            # Paso: enviar formulario\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n\n            # Paso: acceder a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), \n            {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n\n            # Paso: seleccionar el informe de ingresos detallados por producto\n            (\"clic_Ingresos_detallados_por_producto\", log_step_decorator(\"clic_Ingresos_detallados_por_producto\")(hacer_clic), \n            {'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[5]/div[2]/div[1]/div[2]/a', 'wait_time': 5}),\n\n            # Paso: abrir el selector de fechas\n            (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), \n            {'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n\n            # Paso: descargar el archivo con el informe\n            (\"descargar_archivo\", log_step_decorator(\"descargar_archivo\")(_descargar), \n            {'driver': driver, 'xpath': '//*[@id=\"generar-reporte-btn\"]', \n            'download_dir': DOWNLOAD_DIR, \n            'archivo': f\"Cedesarrollo_Docentes_{time.strftime('%Y_%m_%d')}\", 'wait_time': 10}),\n\n            # Paso: hacer clic en el usuario\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), \n            {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', 'wait_time': 5}),\n\n            # Paso: cerrar sesi\u00f3n\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), \n            {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', 'wait_time': 5}),\n        ]\n\n        # Ejecuta todos los pasos definidos, registrando el progreso en el log\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        # Procesa los datos descargados\n        procesar('cede_Docentes', DOWNLOAD_DIR)\n\n    finally:\n        # Asegura que el driver se cierre correctamente al finalizar el proceso\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\nif __name__ == \"__main__\":\n    # Inicia el script si se ejecuta directamente\n    main()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/","title":"0.2. Dise\u00f1o Curricular.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el flujo de trabajo. Finalmente, se ajustan los niveles de registro de otros loggers configurados en el entorno para mantener la coherencia en el nivel de detalle de los logs.</p> <pre><code>import logging  # Importa el m\u00f3dulo de logging para registrar eventos\nimport os       # Permite interactuar con el sistema operativo (rutas, archivos)\nimport sys      # Proporciona acceso a variables y funciones del sistema\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\n# Esto permite importar m\u00f3dulos definidos en directorios superiores\nsys.path.append(os.path.abspath(\"../../\"))\n\n\n# Importaci\u00f3n de funciones y herramientas necesarias desde el m\u00f3dulo `Utils.Funciones`\nfrom Utils.Funciones import (\n    log_step_decorator,       # Decorador para registrar pasos en el log\n    setup_driver,             # Configura el navegador para la automatizaci\u00f3n\n    procesar,                 # Procesa archivos descargados\n    close_driver,             # Cierra el navegador de forma segura\n    hacer_clic,               # Realiza clics en elementos de la interfaz web\n    configurar_pasos_autenticacion_cedesarrollo,  # Configura pasos de autenticaci\u00f3n\n    procesar_reporte_modal,     # Maneja y valida reportes descargados\n    log_tiempo,                 # Calcula y registra el tiempo de ejecuci\u00f3n    \n)\n\n# Configuraci\u00f3n del sistema de logging\nlogger = logging.getLogger(__name__)  # Crea un logger con el nombre del m\u00f3dulo actual\nlogger.setLevel(logging.INFO)         # Define el nivel de registro como INFO\n\n# Evita duplicar manejadores si ya se han configurado previamente\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Configura el formato est\u00e1ndar para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Manejador para registrar los mensajes en un archivo de log\nfile_handler = logging.FileHandler(\"scraper.log\")  # Define el archivo de salida\nfile_handler.setFormatter(formatter)              # Aplica el formato al manejador\nlogger.addHandler(file_handler)                   # Agrega el manejador al logger\n\n# Manejador para registrar los mensajes en la consola\nconsole_handler = logging.StreamHandler()         # Define la salida por consola\nconsole_handler.setFormatter(formatter)           # Aplica el formato al manejador\nlogger.addHandler(console_handler)                # Agrega el manejador al logger\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/#automatizacion-de-descarga-y-procesamiento-del-reporte-diseno-curricular","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Dise\u00f1o Curricular\"","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Dise\u00f1o Curricular\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>download_dir</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_cedesarrollo</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Dise\u00f1o Curricular\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar_reporte_modal</code> y <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Este enfoque modular y estructurado facilita la depuraci\u00f3n, escalabilidad y mantenimiento del flujo automatizado.</p> <pre><code>@log_step_decorator(\"Dise\u00f1o Curricular\")\ndef main():\n    # Registra el inicio del proceso en el log\n    driver = None  # Inicializa el driver como None\n\n    try:\n        # Define la subcarpeta para descargas y configura el driver\n        subcarpeta_descarga = \"Dise\u00f1o_curricular\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configura los elementos clave del proceso\n        xpath_boton = '//*[@id=\"formReportes\"]/div[1]/div[3]/div/button'  # XPath del bot\u00f3n de opciones\n        xpath_contenedor_opciones = '//*[@id=\"formReportes\"]/div[1]/div[3]/div/div/ul'  # XPath del contenedor de opciones\n        excluir_opciones = {}  # Diccionario para excluir opciones, si corresponde\n\n        id_descargar = 'generar-reporte-btn'  # ID del bot\u00f3n para generar el reporte\n        nombre_archivo = 'Dise\u00f1o_curricular'  # Nombre base del archivo\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'  # Nombre completo con extensi\u00f3n\n\n        # Configura los pasos de autenticaci\u00f3n necesarios para acceder al sistema\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n        # Define los pasos del flujo de trabajo, incluyendo autenticaci\u00f3n, navegaci\u00f3n y generaci\u00f3n del reporte\n        step_1 = pasos_autenticacion + [\n            # Paso: Enviar formulario de autenticaci\u00f3n\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n            }),\n            # Paso: Entrar a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5\n            }),\n            # Paso: Seleccionar el reporte \"Dise\u00f1o Curricular\"\n            (\"dise\u00f1o_curricular\", log_step_decorator(\"dise\u00f1o_curricular\")(hacer_clic), {\n                'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[4]/div[2]/a', 'wait_time': 5\n            }),\n            # Paso: Generar el reporte\n            (\"clic_generar_reporte\", log_step_decorator(\"clic_generar_reporte\")(hacer_clic), {\n                'driver': driver, 'id': id_descargar, 'wait_time': 30\n            }),\n            # Paso: Procesar el reporte generado\n            (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {\n                'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo\n            })\n        ]\n\n        # Ejecuta los pasos del flujo, registrando el progreso en el log\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        # Procesa los datos descargados del reporte\n        procesar('cede_Dise\u00f1o_Curricular', download_dir)\n\n    finally:\n        # Cierra el driver al finalizar, garantizando que los recursos se liberen\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    # Inicia la ejecuci\u00f3n del script si es ejecutado directamente\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/","title":"0.3. Listado Matr\u00edculas.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code> y <code>argparse</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Finalmente, se ajustan los niveles de registro de otros loggers configurados en el entorno para mantener la coherencia en el nivel de detalle de los logs.</p> <pre><code>import logging, os, sys, time, argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\n# Importar funciones espec\u00edficas del m\u00f3dulo Utils.Funciones\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, generar_fechas,\n    close_driver, hacer_clic, configurar_pasos_autenticacion_cedesarrollo, procesar_reporte_modal\n)\n\n# Configuraci\u00f3n del logger\nlogger = logging.getLogger(__name__)  # Crear un logger con el nombre del m\u00f3dulo actual\nlogger.setLevel(logging.INFO)  # Establecer el nivel de registro en INFO\n\n# Limpiar los manejadores existentes si los hay\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Crear un formateador para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Crear un manejador de archivo para registrar los logs en un archivo\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)  # Asignar el formateador al manejador de archivo\nlogger.addHandler(file_handler)  # Agregar el manejador de archivo al logger\n\n# Crear un manejador de consola para mostrar los logs en la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)  # Asignar el formateador al manejador de consola\nlogger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/#automatizacion-de-descarga-de-listados-de-matriculas-por-ano","title":"Automatizaci\u00f3n de Descarga de Listados de Matr\u00edculas por A\u00f1o","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Listado_matriculas\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los rangos de fechas por a\u00f1o. Cada iteraci\u00f3n del bucle configura un rango de fechas personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar fechas y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos obligatorios: <code>--start-year</code> y <code>--end-year</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los listados de matr\u00edculas desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Listado de matr\u00edculas\")\ndef main(fechas):\n    # Registra el inicio del proceso en el log\n    driver = None  # Inicializa el driver como None para su manejo seguro\n\n    try:\n        # Define la subcarpeta para las descargas y configura el navegador\n        subcarpeta_descarga = \"Listado_matriculas\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        nombre_archivo = 'Listado_matriculas2024'  # Nombre base del archivo\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'  # Nombre completo con extensi\u00f3n\n\n        # Configura los pasos de autenticaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n        # Pasos iniciales: autenticarse y navegar al listado de matr\u00edculas\n        step_1 = pasos_autenticacion + [\n            # Enviar formulario de autenticaci\u00f3n\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n            }),\n            # Entrar a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5\n            }),\n            # Seleccionar el listado de matr\u00edculas\n            (\"listado\", log_step_decorator(\"listado\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[1]/div[2]/div[3]/div[2]/div[9]/div[1]/a', 'wait_time': 5\n            })\n        ]\n\n        # Ejecuta los pasos iniciales\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)        \n\n        # Itera por cada rango de fechas para configurar y descargar el reporte\n        for fecha in fechas:\n            logging.info(f\"Fecha: {fecha}\")\n            logging.info(f\"Desde {fechas[fecha]['desde']} hasta {fechas[fecha]['hasta']}\")\n\n            # Pasos para configurar el rango de fechas y descargar el reporte\n            step_2 = [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), {\n                    'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3\n                }),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[9]/div[3]/ul/li[7]', 'wait_time': 3\n                }),\n                (\"entrar_en_fecha1\", log_step_decorator(\"entrar_en_fecha1\")(hacer_clic), {\n                    'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', \n                    'value': fechas[fecha]['desde'], \n                    'driver': driver, 'wait_time': 3\n                }),\n                (\"entrar_en_fecha2\", log_step_decorator(\"entrar_en_fecha2\")(hacer_clic), {\n                    'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', \n                    'value': fechas[fecha]['hasta'], \n                    'driver': driver, 'wait_time': 3\n                }),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 3\n                }),\n                (\"descargar\", log_step_decorator(\"descargar\")(hacer_clic), {\n                    'driver': driver, 'xpath': '//*[@id=\"generar-reporte-btn\"]', 'wait_time': 3\n                }),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {\n                    'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo\n                })\n            ]\n            # Ejecuta los pasos del flujo para el rango de fechas actual\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                time.sleep(5)  # Pausa breve para evitar problemas de sincronizaci\u00f3n\n\n    finally:\n        # Asegura que el navegador se cierre correctamente\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n        # Procesa los datos descargados tras la finalizaci\u00f3n del flujo\n        time.sleep(5)\n        procesar(\"cede_Listado_Matriculas\", download_dir)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/04.Ingresos/","title":"0.4. Ingresos.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/04.Ingresos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, y <code>argparse</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Todos los loggers configurados en el entorno tambi\u00e9n se ajustan al nivel <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <pre><code>import logging, os, sys, time,argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, generar_fechas, _descargar,procesar,\n    close_driver, hacer_clic, configurar_pasos_autenticacion_cedesarrollo, procesar_reporte_modal,seleccionar_opcion_custom_dropdown\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/04.Ingresos/#automatizacion-de-descarga-de-ingresos","title":"Automatizaci\u00f3n de Descarga de Ingresos","text":"<p>Este script automatiza la descarga y procesamiento de listados de ingresos correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Ingresos\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los periodos por a\u00f1o generados din\u00e1micamente seg\u00fan los argumentos proporcionados. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del ultimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el ultimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Ingresos\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    # Genera el diccionario de fechas para el semestre cuando se deja semestre = True, de lo contrario hace el diccionario de acuerdo a los a\u00f1os inicio y fin\n    nombre_archivo = 'Ingresos'\n    subcarpeta_descarga = \"Ingresos\"\n    nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n\n    for fecha in fechas:\n        logging.info(f\"Fecha: {fecha}\")\n        logging.info(f\"Desde {fechas[fecha]['desde']} hasta {fechas[fecha]['hasta']}\")\n        driver = None\n        try:\n            driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n            pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n            step_1 = [\n                (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                    'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n                }),\n                (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5\n                }),\n                (\"Ingresos\", log_step_decorator(\"Ingresos\")(hacer_clic), {\n                    'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[5]/div[2]/a', 'wait_time': 3\n                }),\n                (\"descartar\", log_step_decorator(\"descartar0\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[3]/button', 'wait_time': 3\n                }),            \n                (\"descartar\", log_step_decorator(\"descartar1\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[1]/div[2]/div/button/span', 'wait_time': 3\n                }),            \n                (\"descartar1\", log_step_decorator(\"descartar2\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[3]/button', 'wait_time': 3\n                })                             \n            ]\n\n\n\n            step_2 =pasos_autenticacion + step_1 + [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[10]/div[3]/ul/li[7]', 'wait_time': 3}),\n                # (\"entrar_en_personalizado_2\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[12]/div[3]/ul/li[7]', 'wait_time': 5}),   \n                (\"entrar_en_fecha1\",log_step_decorator(\"entrar_en_fecha1\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', 'value': fechas[fecha]['desde'], 'driver': driver,'wait_time': 5}),\n                (\"entrar_en_fecha2\",log_step_decorator(\"entrar_en_fecha2\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[2]/input','value': fechas[fecha]['hasta'],'driver': driver,'wait_time': 5}),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 5}),\n                (\"programar-reporte-btn\", log_step_decorator(\"descargar\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"programar-reporte-btn\"]', 'wait_time': 80}), \n                (\"abrir-reporte\", log_step_decorator(\"descargar1\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"abrir-reporte\"]', 'wait_time': 5}),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo}),\n                (\"descartar\", log_step_decorator(\"descartar\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[3]/button', 'wait_time': 10})\n                ]\n\n            ultimo=0\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                if step_name==\"programar-reporte-btn\":\n                    time.sleep(80)\n                time.sleep(5)\n            procesar(\"cede_Ingresos\", download_dir)\n\n\n        finally:\n            if driver:\n                close_driver(driver)\n            logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular ultimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/05.Historico_notas_Cedesarrollo/","title":"0.5. Hist\u00f3rico notas.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/05.Historico_notas_Cedesarrollo/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>argparse</code> y <code>warnings</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>eliminar_archivos_anteriores</code> para gestionar los archivos descargados previamente.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Finalmente, se ajustan los niveles de otros loggers configurados para mantener la coherencia en el registro de eventos.</p> <pre><code>import logging, time, os, sys, argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar_reporte_modal, obtener_elementos_dropdown, \n    hacer_clic, procesar, seleccionar_opcion_con_js, guardar_diccionario,\n    configurar_pasos_autenticacion_cedesarrollo, eliminar_archivos_anteriores, ejecutar_pasos\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\n# Si el logger ya tiene manejadores, limpiarlos\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Crear un formateador para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Crear un manejador de archivo para guardar los logs en un archivo\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)  # Asignar el formateador al manejador de archivo\nlogger.addHandler(file_handler)  # Agregar el manejador de archivo al logger\n\n# Crear un manejador de consola para mostrar los logs en la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)  # Asignar el formateador al manejador de consola\nlogger.addHandler(console_handler)  # Agregar el manejador de consola al logger\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/05.Historico_notas_Cedesarrollo/#automatizacion-de-descarga-de-historico-notas","title":"Automatizaci\u00f3n de Descarga de H\u00edstorico Notas","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Historico_notas\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un conjunto llamado <code>consulta</code>, que contiene los periodos por a\u00f1o desde el a\u00f1o inicial hasta el a\u00f1o final. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, selecciona jornadas, programas, m\u00f3dulos y cursos, y finalmente descarga los reportes correspondientes. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_1</code>. Adem\u00e1s, el script incluye un fragmento comentado para generar autom\u00e1ticamente este conjunto de periodos mediante una funci\u00f3n.</p> <p>El c\u00f3digo asegura que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. El procesamiento incluye la selecci\u00f3n de elementos en men\u00fas desplegables (como periodos, jornadas, programas, m\u00f3dulos y cursos) y la descarga de los reportes correspondientes. Cada paso del proceso est\u00e1 registrado en el log para facilitar la depuraci\u00f3n y el monitoreo.</p> <p>Por \u00faltimo, todos los recursos son liberados de manera segura con <code>driver.quit()</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos.</p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos, tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Historico de Notas\")\ndef main(consulta):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Historico_notas\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada para definir el entorno del navegador\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones en la aplicaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n        step_1 = pasos_autenticacion + [\n            # Enviar formulario de autenticaci\u00f3n\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            # Navegar a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n            # Hacer clic en el enlace de Hist\u00f3rico de Notas\n            (\"clic_historico_notas\",log_step_decorator(\"clic_historico_notas\")(hacer_clic), {'driver': driver, 'xpath': \n                '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[7]/div[2]/a',\n                'wait_time': 5}),\n        ]\n        # Ejecutar los pasos de autenticaci\u00f3n configurados\n        ejecutar_pasos(step_1)\n\n        # Definir los elementos de selecci\u00f3n del per\u00edodo (bot\u00f3n y lista desplegable)\n        _xpath_periodo  = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[1]/div[3]'\n        periodo_boton = f'{_xpath_periodo}/div/button'\n        periodo_list = f'{_xpath_periodo}/div/div/ul'        \n        nivel=1\n\n        # Obtener los periodos disponibles en el dropdown\n        _periodos = obtener_elementos_dropdown(driver, periodo_boton, periodo_list, nivel)\n\n        periodos_generados = [f\"{year}\" for year in consulta]\n\n        # Filtrar solo los per\u00edodos que contienen con los valores generados\n        periodos = [\n            periodo for periodo in _periodos \n            if any(generado in periodo for generado in periodos_generados)\n        ]\n\n        # Guardar los per\u00edodos seleccionados en un archivo para referencia\n        # guardar_diccionario(periodos, 'periodos')\n\n        # Eliminar archivos anteriores en la carpeta de descargas antes de procesar nuevos\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        # Procesar cada periodo seleccionado\n        if periodos:\n            for periodo in periodos:\n                # Seleccionar el per\u00edodo en el dropdown\n                hacer_clic(driver= driver, xpath=periodo_boton, wait_time= 1)\n                seleccionar_opcion_con_js(driver, periodo_boton, periodo)\n                logging.info(f\"Procesando periodo: {periodo}\")\n\n                # Obtener jornadas para el per\u00edodo seleccionado\n                xpath_jornada = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[2]/div[3]'\n                jornada_boton = f'{xpath_jornada}/div/button'\n                jornada_list = f'{xpath_jornada}/div/div/ul'\n                jornadas = obtener_elementos_dropdown(driver, jornada_boton, jornada_list, nivel=2)\n                excluir_jornadas = {'Seleccione'}\n                jornadas = [jornada for jornada in jornadas if jornada not in excluir_jornadas]                \n\n                # Procesar cada jornada seleccionada\n                if jornadas:\n                    for jornada in jornadas:\n                        # Seleccionar la jornada en el dropdown\n                        hacer_clic(driver= driver, xpath=jornada_boton, wait_time= 1)\n                        seleccionar_opcion_con_js(driver, jornada_boton, jornada)\n                        logging.info(f\"Procesando jornada: {jornada}\")\n\n                        # Obtener programas para la jornada seleccionada\n                        xpath_programa = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[3]/div[3]'\n                        programa_boton = f'{xpath_programa}/div/button'\n                        programa_list = f'{xpath_programa}/div/div/ul'\n                        programas = obtener_elementos_dropdown(driver, programa_boton, programa_list, nivel=3)\n                        excluir_opciones = {'Seleccione','Control de Calidad'}\n                        programas = [programa for programa in programas if programa not in excluir_opciones]\n\n                        # Procesar cada programa seleccionado\n                        if programas:\n                            for programa in programas:\n                                # Seleccionar el programa en el dropdown\n                                hacer_clic(driver= driver, xpath=programa_boton, wait_time= 1)\n                                seleccionar_opcion_con_js(driver, programa_boton, programa)\n                                logging.info(f\"Procesando programa: {programa}\")\n\n                                # Obtener m\u00f3dulos para el programa seleccionado\n                                xpath_modulo = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[4]/div[3]'\n                                modulo_boton = f'{xpath_modulo}/div/button'\n                                modulo_list = f'{xpath_modulo}/div/div/ul'\n                                modulos = obtener_elementos_dropdown(driver, modulo_boton, modulo_list, nivel=4)\n                                excluir_modulos = {'Seleccione'}\n                                modulos = [modulo for modulo in modulos if modulo not in excluir_modulos]\n\n                                # Procesar cada m\u00f3dulo seleccionado\n                                if modulos:\n                                    for modulo in modulos:\n                                        # Seleccionar el m\u00f3dulo en el dropdown\n                                        hacer_clic(driver= driver, xpath=modulo_boton, wait_time= 1)\n                                        seleccionar_opcion_con_js(driver, modulo_boton, modulo)\n                                        logging.info(f\"Procesando modulo: {modulo}\")\n\n                                        # Obtener cursos para el m\u00f3dulo seleccionado\n                                        xpath_curso = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[5]/div[3]'\n                                        cursos_boton = f'{xpath_curso}/div/button'\n                                        cursos_list = f'{xpath_curso}/div/div/ul'\n                                        cursos = obtener_elementos_dropdown(driver, cursos_boton, cursos_list, nivel=5)\n                                        excluir_cursos = {'Seleccione'}\n                                        cursos = [curso for curso in cursos if curso not in excluir_cursos]\n\n                                        # Procesar cada curso seleccionado\n                                        if cursos:\n                                            for curso in cursos:\n                                                try:\n                                                    # Seleccionar el curso en el dropdown\n                                                    # seleccionar_opcion_con_js(driver, cursos_boton, curso)\n                                                    # Hacer clic en el bot\u00f3n para descargar el informe\n                                                    hacer_clic(driver=driver, xpath='/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[7]/button', wait_time=5)\n                                                    # Guardar el archivo descargado con un nombre significativo\n                                                    archivo = f'Cede_{periodo}_{jornada}_{programa}_{modulo}_{curso}.xlsx'\n                                                    try:\n                                                        procesar_reporte_modal(driver, DOWNLOAD_DIR, archivo)\n                                                    except Exception as e:\n                                                        logging.error(f\"Error procesando el archivo {archivo}: {e}. Continuando con el siguiente curso.\")\n                                                        continue\n                                                    # Esperar un poco entre descargas\n                                                    time.sleep(5)\n                                                except Exception as e:\n                                                    logging.error(f\"Error procesando el curso {curso}: {e}. Continuando con el siguiente curso.\")\n                                                    continue    \n                                else: continue\n                        else: continue\n                else: continue\n\n        # Procesar todos los informes descargados\n        procesar(\"cede_Historico_Notas\",DOWNLOAD_DIR)\n        logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\n    finally:\n        # Cerrar el driver para liberar recursos\n        if driver:\n            driver.quit()\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    consulta = {_inicio, _fin}\n    main(consulta=consulta)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/06.Egresados_graduados_Cedesarrollo/","title":"0.6. Egresados.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/06.Egresados_graduados_Cedesarrollo/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>argparse</code> y <code>time</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <pre><code>import logging\nimport time\nimport os\nimport sys,argparse\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic, generar_fechas, generar_periodos,\n    configurar_pasos_autenticacion_cedesarrollo, eliminar_archivos_anteriores, pre_procesamiento_periodo\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/06.Egresados_graduados_Cedesarrollo/#automatizacion-de-descarga","title":"Automatizaci\u00f3n de Descarga","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Graduados\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>periodos</code>, que contiene los periodos por a\u00f1o desde el a\u00f1o inicial hasta el a\u00f1o final especificados por el usuario. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_1</code>. Adem\u00e1s, el script incluye un fragmento comentado para generar autom\u00e1ticamente este diccionario de periodos mediante una funci\u00f3n.</p> <p>El diccionario <code>step_1</code> contiene una serie de pasos que se ejecutan secuencialmente para automatizar el proceso de scraping. Cada entrada en el diccionario es una tupla que incluye:</p> <ol> <li>Nombre del paso: Una cadena que describe la acci\u00f3n a realizar.</li> <li>Funci\u00f3n del paso: Una funci\u00f3n decorada con <code>log_step_decorator</code> que realiza la acci\u00f3n.</li> <li>Par\u00e1metros del paso: Un diccionario de par\u00e1metros que se pasan a la funci\u00f3n del paso.</li> </ol> <p>Por ejemplo, el paso <code>(\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10})</code> indica que se debe hacer clic en el bot\u00f3n de env\u00edo del formulario, utilizando el driver de Selenium y esperando hasta 10 segundos para que el elemento est\u00e9 disponible.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Graduados\")\ndef main(periodos):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Graduados\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Graduados'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n            (\"clic_egresados\", log_step_decorator(\"clic_egresados\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[5]/div[2]/div[1]/div[3]/a', \n                'wait_time': 5\n            }),\n            (\"seleccionar_tipo_graduado\", log_step_decorator(\"seleccionar_tipo_graduado\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[1]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"seleccionperiodos\", log_step_decorator(\"seleccionperiodos\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[2]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"pre_procesamiento_periodo\", log_step_decorator(\"pre_procesamiento\")(pre_procesamiento_periodo), {\n                'driver': driver,\n                'download_dir': DOWNLOAD_DIR,\n                'id_descargar': 'generar-reporte-btn',\n                'nombre_archivo': nombre_archivo,\n                'nombre_archivo_completo': nombre_archivo_completo,\n                'xpath_boton': '//*[@id=\"form0\"]/div[4]/div[3]/div/button',\n                'tipo':'normal',\n                'xpath_contenedor_opciones':  '//*[@id=\"form0\"]/div[4]/div[3]/div/div/ul',\n                'items_opciones':periodos\n            }),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', \n                'wait_time': 5\n            }),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', \n                'wait_time': 5\n            })\n        ]\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        procesar('cede_Egresados_Graduados', DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    periodos = generar_periodos(_inicio, _fin)\n    main(periodos)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/07.Desertores/","title":"0.7. Desertores.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/07.Desertores/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, y <code>time</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos, <code>configurar_pasos_autenticacion_cedesarrollo</code> para configurar los pasos de autenticaci\u00f3n, y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <pre><code>import logging\nimport os, time\nimport sys,argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\n# Importar funciones espec\u00edficas del m\u00f3dulo Utils.Funciones\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, generar_fechas, procesar,guardar_diccionario,\n    close_driver, hacer_clic, configurar_pasos_autenticacion_cedesarrollo, procesar_reporte_modal\n)\n\n# Obtener el logger con el nombre del m\u00f3dulo actual\nlogger = logging.getLogger(__name__)  \n\n# Establecer el nivel de registro a INFO\nlogger.setLevel(logging.INFO)\n\n# Limpiar los manejadores existentes si los hay\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Formato de los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Configuraci\u00f3n del manejador de archivos para el log\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n\n# Configuraci\u00f3n del manejador de consola para el log\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/07.Desertores/#automatizacion-de-descarga","title":"Automatizaci\u00f3n de Descarga","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Desertores\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los periodos definidos por el usuario. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El diccionario <code>step_1</code> contiene una serie de pasos que se ejecutan secuencialmente para automatizar el proceso de scraping. Cada entrada en el diccionario es una tupla que incluye:</p> <ol> <li>Nombre del paso: Una cadena que describe la acci\u00f3n a realizar.</li> <li>Funci\u00f3n del paso: Una funci\u00f3n decorada con <code>log_step_decorator</code> que realiza la acci\u00f3n.</li> <li>Par\u00e1metros del paso: Un diccionario de par\u00e1metros que se pasan a la funci\u00f3n del paso.</li> </ol> <p>Por ejemplo, el paso <code>(\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10})</code> indica que se debe hacer clic en el bot\u00f3n de env\u00edo del formulario, utilizando el driver de Selenium y esperando hasta 10 segundos para que el elemento est\u00e9 disponible.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Desertores\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        subcarpeta_descarga = \"Desertores\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Dise\u00f1o_curricular'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n        # Pasar driver al configurar pasos de autenticaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n        # Definir los pasos de autenticaci\u00f3n y navegaci\u00f3n inicial\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n            (\"desertores\", log_step_decorator(\"desertores\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[3]/div[1]/a', 'wait_time': 5}),\n        ]\n\n        # Ejecutar los pasos de autenticaci\u00f3n y navegaci\u00f3n inicial\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n        guardar_diccionario(fechas, 'fechas')\n        for fecha in fechas:\n            logging.info(f\"Fecha: {fecha}\")\n\n            step_2 = [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/div[9]/div[3]/ul/li[7]', 'wait_time': 3}),\n                (\"entrar_en_fecha1\", log_step_decorator(\"entrar_en_fecha1\")(hacer_clic), {'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', 'value': fechas[fecha]['desde'], 'driver': driver, 'wait_time': 3}),\n                (\"entrar_en_fecha2\", log_step_decorator(\"entrar_en_fecha2\")(hacer_clic), {'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', 'value': fechas[fecha]['hasta'], 'driver': driver, 'wait_time': 3}),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 3}),\n                (\"descargar\", log_step_decorator(\"descargar\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"generar-reporte-btn\"]', 'wait_time': 5}),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo})\n            ]\n\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                time.sleep(5)\n\n        procesar('cede_Cancelados_Desertores',download_dir)\n\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/","title":"cede_01 procesar_docentes","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport re\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, extract_date, obtener_sharepoint,replace_values_df,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/#procesar_docentes","title":"procesar_docentes","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de docentes almacenados en SharePoint. Primero, se define una funci\u00f3n <code>obtener_sharepoint_docentes</code> que descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica el archivo m\u00e1s reciente basado en la fecha en su nombre, y elimina los archivos m\u00e1s antiguos. Luego, carga el archivo m\u00e1s reciente en un DataFrame de pandas y registra informaci\u00f3n sobre el archivo y su contenido.</p> <p>La funci\u00f3n <code>procesar_cede_Docentes</code> toma el DataFrame cargado y realiza varias transformaciones. Estas incluyen la limpieza de espacios en blanco en los nombres y apellidos, la concatenaci\u00f3n de estos en una nueva columna 'NOMBRE', y la eliminaci\u00f3n y renombrado de columnas seg\u00fan un diccionario de mapeo. Finalmente, selecciona y reordena las columnas del DataFrame para que coincidan con un formato espec\u00edfico.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se registran mensajes informativos, se obtienen y procesan los datos de SharePoint, se muestran las primeras filas del DataFrame procesado y se actualizan los datos procesados de vuelta en SharePoint.</p> <pre><code>@log_step_decorator('obtener_sharepoint_docentes')\ndef obtener_sharepoint_docentes():\n    # Obtiene la URL de la carpeta de SharePoint desde un diccionario `etl_to_folder_url`.\n    folder_url = etl_to_folder_url.get('cede_Docentes', \"URL por defecto si no se encuentra el valor de etl\")\n    # Llama a la funci\u00f3n `obtener_sharepoint` para descargar los archivos en la carpeta local `_folder`.\n    obtener_sharepoint(folder_url,_folder)\n\n    # Busca todos los archivos que coincidan con el patr\u00f3n \"Docentes_*.xlsx\" en la carpeta local.\n    files = glob.glob(os.path.join(_folder, \"Docentes_*.xlsx\"))\n\n    # Utiliza una expresi\u00f3n regular para extraer la fecha de los nombres de los archivos.\n    date_pattern = re.compile(r'Docentes_(\\d{2})_(\\d{2})_(\\d{4})\\.xlsx')\n\n    # Encuentra el archivo m\u00e1s reciente basado en la fecha extra\u00edda.\n    latest_file = max(files, key=lambda f: extract_date(f,date_pattern))\n\n    # Elimina todos los archivos excepto el m\u00e1s reciente.\n    for file in files:\n        if file != latest_file:\n            os.remove(file)\n\n    # Registra informaci\u00f3n sobre el archivo m\u00e1s reciente y su contenido.\n    logger.info(f\"El archivo m\u00e1s reciente es: {latest_file}\")\n\n    # Carga el archivo m\u00e1s reciente en un DataFrame de pandas.\n    df = pd.read_excel(latest_file)\n\n    # Registra informaci\u00f3n sobre el contenido del archivo m\u00e1s reciente.\n    logger.info(f\"Contenido del archivo {latest_file}:\")\n    return df\n\n\n@log_step_decorator('procesar_cede_Docentes')\ndef procesar_cede_Docentes(df):\n    # Reemplaza valores en el DataFrame seg\u00fan sea necesario.\n    df = replace_values_df(df)\n\n    # Elimina espacios en blanco de los nombres y apellidos.\n    df['Primer nombre'] = df['Primer nombre'].str.strip()\n    df['Segundo nombre'] = df['Segundo nombre'].str.strip()\n    df['Primer apellido'] = df['Primer apellido'].str.strip()\n    df['Segundo apellido'] = df['Segundo apellido'].str.strip()\n\n    # Concatena los nombres y apellidos en una sola columna 'NOMBRE', omitiendo los vac\u00edos.\n    df['NOMBRE'] = df[['Primer nombre', 'Segundo nombre', 'Primer apellido', 'Segundo apellido']].apply(lambda x: ' '.join(x.dropna().astype(str)).upper(), axis=1)\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = []\n    renombres = {\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'E-mail':'CORREO',\n        'Direcci\u00f3n':'DIRECCION',\n        'C\u00e9dula':'CEDULA',\n        'Municipio direcci\u00f3n':'CIUDAD',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n': 'DOCUMENTO',\n        'Fecha de nacimiento':'FECHA_NACIMIENTO',\n        'Sexo':'GENERO'\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n\n    # Selecciona y reordena las columnas del DataFrame.\n    df = df[[\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'NOMBRE',\n        'PRIMER NOMBRE',\n        'SEGUNDO NOMBRE',\n        'PRIMER APELLIDO',\n        'SEGUNDO APELLIDO',\n        'TELEFONO',\n        'CELULAR',\n        'CORREO',\n        'DIRECCION',\n        'CIUDAD',\n        'FECHA_NACIMIENTO',\n        'MUNICIPIO EXPEDICI\u00d3N',\n        'FECHA DE EXPEDICI\u00d3N',\n        'GENERO',\n        'MUNICIPIO NACIMIENTO',\n        'TIPO DE SANGRE',\n        'ESCALAF\u00d3N',\n        'ESTADO CIVIL',\n        'CALIDAD DE DESEMPE\u00d1O',\n        'ESTADO',\n        'FECHA DE INGRESO',\n        'TIEMPO LABORAL',\n        'TIPO DE VINCULACI\u00d3N',\n        'ORIGEN VINCULACI\u00d3N',\n        'NIVEL ACAD\u00c9MICO',\n        'ESPECIALIDAD',\n        'FUENTE DE RECURSOS',\n        'SALARIO',\n        'USUARIO',\n        ]]\n\n    # Retorna el DataFrame procesado.\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():\n    # Obtener los datos de SharePoint para los docentes\n    df_cede_Docentes = obtener_sharepoint_docentes()\n    # Procesar los datos obtenidos de SharePoint\n    df_cede_Docentes = procesar_cede_Docentes(df_cede_Docentes)\n    # Mostrar las primeras filas del DataFrame procesado\n    df_cede_Docentes.head()\n    # Actualizar los datos procesados de vuelta en SharePoint\n\n    # Decorar la funci\u00f3n `actualizar_sharepoint_procesado` con `log_step_decorator` para registrar el paso\n    actualizar_sharepoint_func = log_step_decorator('actualizar_sharepoint_procesado')(actualizar_sharepoint_procesado)\n\n    # Llamar a la funci\u00f3n decorada para actualizar los datos procesados en SharePoint\n    actualizar_sharepoint_func(df_cede_Docentes, 'cede_Docentes')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/","title":"cede_02 procesar_Dise\u00f1o_Curricular","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport re\nimport pandas as pd\nimport openpyxl\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, extract_date, obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/#procesar_diseno_curricular","title":"procesar_diseno_curricular","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de dise\u00f1o curricular almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. </p> <p>La funci\u00f3n <code>procesar_diseno_curricular</code> abre un archivo de Excel, procesa cada hoja del libro, identifica las tablas de datos basadas en un encabezado espec\u00edfico, y extrae las filas relevantes. Los datos extra\u00eddos se almacenan en un <code>DataFrame</code> de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_dise\u00f1o_curricular</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica el archivo m\u00e1s reciente basado en la fecha en su nombre, y elimina los archivos m\u00e1s antiguos. Luego, carga el archivo m\u00e1s reciente y lo procesa utilizando la funci\u00f3n  <code>procesar_diseno_curricular</code>. Se asegura de que no haya valores nulos en la columna <code>Nombre Modulo</code> antes de filtrar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Adem\u00e1s, se realiza una comprobaci\u00f3n temporal de la subida de archivos a una carpeta espec\u00edfica en SharePoint.</p> <pre><code>@log_step_decorator('procesar_cede_Dise\u00f1o_Curricular')\ndef procesar_diseno_curricular(file_path):\n    # Abrir el archivo de Excel con openpyxl\n    wb = openpyxl.load_workbook(file_path, data_only=True)\n    all_data = []\n\n    for sheet_name in wb.sheetnames:\n        sheet = wb[sheet_name]\n        sheet_data = []\n        header_row = None\n        registro_num = 0  # Contador para el n\u00famero de registro\n\n        for row_idx, row in enumerate(sheet.iter_rows(values_only=True), start=1):  # row_idx comienza en 1\n            if row[0] == \"C\u00f3digo \":  # Identificar el inicio de la tabla\n                header_row = row\n                header_info = sheet.cell(row=row_idx - 3, column=1).value  # Fila [C\u00f3digo - 2]\n                registro_num = 0  # Reiniciar el n\u00famero de registro\n                continue\n\n            empty_row_count = 0  # Contador de filas vac\u00edas consecutivas\n\n            if header_row and row[0] is None:\n                empty_row_count += 1\n                if empty_row_count &gt;= 10:  # Si hay 10 filas vac\u00edas consecutivas, hacer break\n                    break\n                continue\n            else:\n                empty_row_count = 0  # Reiniciar el contador si se encuentra una fila no vac\u00eda\n\n            if row[0] == \"C\u00f3digo \":  # Identificar el inicio de una nueva tabla\n                header_row = row\n                header_info = sheet.cell(row=row_idx - 3, column=1).value  # Fila [C\u00f3digo - 2]\n                registro_num = 0  # Reiniciar el n\u00famero de registro\n                continue\n\n            if header_row:\n                # Incrementar el n\u00famero de registro\n                registro_num += 1\n                # Seleccionar solo las columnas relevantes\n                data_row = {\n                    \"Registro\": registro_num,  # Agregar n\u00famero de registro\n                    \"Programa (Pensum)\": header_info, \n                    \"C\u00f3digo\": row[0],\n                    \"Nombre Modulo\": row[1],\n                    \"Abreviaci\u00f3n\": row[5],\n                    \"Nivel\": row[7],\n                    \"Intensidad Horaria\": row[9],\n                    \"Intensidad Horaria Semanal\": row[10],\n                    \"No Cr\u00e9ditos\": row[12],\n                }\n                sheet_data.append(data_row)\n\n        # Combinar los datos de cada hoja\n        if sheet_data:\n            all_data.extend(sheet_data)\n\n    # Crear un DataFrame final con todos los datos procesados\n    df = pd.DataFrame(all_data)\n    return df\n\n@log_step_decorator('obtener_sharepoint_dise\u00f1o_curricular')\ndef obtener_sharepoint_dise\u00f1o_curricular():\n    folder_url = etl_to_folder_url.get('cede_Dise\u00f1o_Curricular', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Dise\u00f1o_Curricular_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Dise\u00f1o_Curricular_*.xlsx' en la carpeta.\")\n        return None\n\n    # Expresi\u00f3n regular para extraer la fecha del nombre del archivo\n    date_pattern = re.compile(r'Dise\u00f1o_Curricular_(\\d{2})_(\\d{2})_(\\d{4})\\.xlsx')\n\n    # Encontrar el archivo con la fecha m\u00e1s reciente\n    try:\n        latest_file = max(files, key=lambda f: extract_date(f,date_pattern))\n    except ValueError:\n        logger.error(\"No se pudo encontrar un archivo con fecha v\u00e1lida.\")\n        return None\n\n    # Eliminar todos los archivos excepto el m\u00e1s reciente\n    for file in files:\n        if file != latest_file:\n            os.remove(file)\n\n    logger.info(f\"El archivo m\u00e1s reciente es: {latest_file}\")\n    # Ruta del archivo m\u00e1s reciente descargado\n    df = procesar_diseno_curricular(latest_file)\n\n    # Asegurar que no hay valores nulos en \"Nombre Modulo\" antes de filtrar\n    if \"Nombre Modulo\" in df.columns:\n        df = df.dropna(subset=[\"Nombre Modulo\"])\n    else:\n        logger.warning(\"La columna 'Nombre Modulo' no existe en el DataFrame procesado.\")\n\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = []\n    renombres = {\n            'Programa (Pensum)':'PROGRAMA',\n            'C\u00f3digo':'COD_MODULO',\n            'Nombre Modulo':'MODULO',\n            'Nivel':'SEMESTRE',\n            'Intensidad Horaria':'INTENSIDAD_HORARIA',\n            'Intensidad Horaria Semanal':'INTENSIDAD_HORARIA_SEMANAL',\n            'No Cr\u00e9ditos':'NO_CREDITOS'\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():\n    df_cede_Dise\u00f1o_Curricular = obtener_sharepoint_dise\u00f1o_curricular()\n    actualizar_sharepoint_procesado(df_cede_Dise\u00f1o_Curricular, 'cede_Dise\u00f1o_Curricular')\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/","title":"cede_03 procesar_listado_matriculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) automatizado, utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno y el manejo de datos. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>limpiar_columnas</code>, <code>obtener_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>, que son fundamentales para el flujo de trabajo.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se define un diccionario llamado <code>etl_to_folder_url</code>, que mapea nombres de procesos ETL a rutas espec\u00edficas en SharePoint. Este diccionario es clave para identificar las ubicaciones de los datos en la plataforma y permite una configuraci\u00f3n flexible para diferentes flujos de trabajo.</p> <p>El c\u00f3digo tambi\u00e9n incluye configuraciones para ignorar advertencias espec\u00edficas y ajustar los niveles de otros loggers, asegurando que no interfieran con el proceso principal. Finalmente, se define una carpeta temporal (<code>_folder</code>) para almacenar archivos procesados, lo que facilita la gesti\u00f3n de datos intermedios durante la ejecuci\u00f3n del proceso ETL.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code>import logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\nimport openpyxl\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/#procesar_listado_matriculas","title":"procesar_listado_matriculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de matr\u00edculas almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. </p> <p>La funci\u00f3n <code>procesar_listado_matriculas</code> abre un archivo de Excel y procesa cada hoja del libro. Identifica las tablas de datos basadas en un encabezado espec\u00edfico (como \"Estudiante\") y extrae las filas relevantes. Durante este proceso, se manejan encabezados din\u00e1micos, se detectan filas vac\u00edas consecutivas para detener el procesamiento, y se dividen los valores de la columna \"Identificaci\u00f3n\" en tipo y n\u00famero. Los datos extra\u00eddos se almacenan en un <code>DataFrame</code> de pandas, eliminando filas con valores nulos en la columna \"Identificaci\u00f3n\".</p> <p>La funci\u00f3n <code>obtener_sharepoint_listado_matriculas</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos m\u00e1s recientes basados en un patr\u00f3n de nombre, y elimina los archivos m\u00e1s antiguos. Luego, procesa los archivos descargados utilizando la funci\u00f3n <code>procesar_listado_matriculas</code>. Los datos procesados se consolidan en un \u00fanico <code>DataFrame</code>, donde se eliminan columnas innecesarias, se renombran columnas clave (como \"Estudiante\" a \"NOMBRE_ESTUDIANTE\"), y se dividen valores compuestos en columnas separadas (como \"SEDE - JORNADA - PROGRAMA\" en \"SEDE\", \"JORNADA\" y \"PROGRAMA\"). Adem\u00e1s, se eliminan duplicados basados en las columnas \"FECHA_MATRICULA\" y \"DOCUMENTO_ESTUDIANTE\".</p> <p>El bloque principal del c\u00f3digo, definido en la funci\u00f3n <code>main</code>, controla la ejecuci\u00f3n del proceso de ETL. Primero, llama a <code>obtener_sharepoint_listado_matriculas</code> para obtener y procesar los datos. Luego, utiliza la funci\u00f3n <code>actualizar_sharepoint_procesado</code> para cargar los datos procesados de vuelta a SharePoint. En caso de errores durante la ejecuci\u00f3n, se registran en el log para facilitar la depuraci\u00f3n.</p> <p>Este flujo asegura que los datos de matr\u00edculas sean procesados de manera eficiente y estructurada, proporcionando trazabilidad y flexibilidad para manejar diferentes escenarios de datos.</p> <pre><code>@log_step_decorator('procesar_listado_matriculas')\ndef procesar_listado_matriculas(file_path):\n    wb = openpyxl.load_workbook(file_path, data_only=True)\n    all_data = []\n\n    # Iterar sobre las hojas del archivo con \u00edndice\n    for sheet_idx, sheet_name in enumerate(wb.sheetnames):\n        sheet = wb[sheet_name]\n        sheet_data = []\n        header_row = None\n        registro_num = 0  # Contador para el n\u00famero de registro\n        empty_row_count = 0  # Contador de filas vac\u00edas consecutivas\n\n        for row_idx, row in enumerate(sheet.iter_rows(values_only=True), start=1):\n            if row[0] and row[0].strip() == \"Estudiante\":  # Detectar encabezado\n                header_row = row\n                _info = sheet.cell(row=row_idx - 3, column=1).value\n                if _info:\n                    header_info = _info\n                    registro_num = 0\n\n                # Analizar header_row y obtener los nombres de las columnas\n                if header_row:\n                    col_indices = {\n                        col_name.replace(\"\\n\", \" \"): idx\n                        for idx, col_name in enumerate(header_row)\n                        if col_name and col_name.replace(\"\\n\", \" \") in [\n                            \"Estudiante\", \"Identificaci\u00f3n\", \"Fecha Matr\u00edcula\",\n                            \"Tel\u00e9fono\", \"Celular\", \"Correo\", \"Nivel\", \"Estado\"\n                        ]\n                    }\n                continue\n\n            if header_row:\n                registro_num += 1                \n                # Validar si la fila tiene suficientes columnas\n                if row[0] is None:\n                    empty_row_count += 1\n                    if empty_row_count &gt;= 5:  \n                        break\n                    continue\n                elif row[0] == 'www.q10.com':\n                    break\n                else:\n                    empty_row_count = 0  # Reiniciar contador si se encuentra una fila v\u00e1lida\n\n                # Procesar datos\n\n                # Dividir la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n                identificacion = row[col_indices.get(\"Identificaci\u00f3n\", 1)]\n                tipo, numero = (None, None)  # Valores predeterminados en caso de error\n                if identificacion and \" \" in identificacion:\n                    tipo, numero = identificacion.split(\" \", 1)\n\n                data_row = {\n                    \"Hoja\": sheet_name,\n                    \"Registro\": registro_num,\n                    \"Sede - jornada - Programa\": header_info,\n                    \"Estudiante\": row[col_indices.get(\"Estudiante\", 0)],\n                    \"Tipo Identificaci\u00f3n\": tipo,\n                    \"Identificaci\u00f3n\": numero,\n                    \"Fecha Matr\u00edcula\": row[col_indices.get(\"Fecha Matr\u00edcula\", 2)],\n                    \"Tel\u00e9fono\": row[col_indices.get(\"Tel\u00e9fono\", 3)],\n                    \"Celular\": row[col_indices.get(\"Celular\", 4)],\n                    \"Correo\": row[col_indices.get(\"Correo\", 5)],\n                    \"Nivel\": row[col_indices.get(\"Nivel\", 6)],\n                    \"Estado\": row[col_indices.get(\"Estado\", 7)],\n                }\n                sheet_data.append(data_row)\n\n        # Combinar los datos de cada hoja\n        if sheet_data:\n            all_data.extend(sheet_data)\n\n    # Crear un DataFrame final con todos los datos procesados\n    df = pd.DataFrame(all_data)\n    df = df.dropna(subset=[\"Identificaci\u00f3n\"])  # Eliminar filas con identificaci\u00f3n nula\n    return df\n\n@log_step_decorator('obtener_sharepoint_listado_matriculas')\ndef obtener_sharepoint_listado_matriculas():\n    folder_url = etl_to_folder_url.get('cede_Listado_Matriculas', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Listado_Matriculas_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Listado_Matriculas_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        df_temp = procesar_listado_matriculas(file)\n        all_dfs.append(df_temp)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = ['Hoja','Registro']\n    #    'Sede - jornada - Programa',\n    renombres = {\n        'Estudiante': 'NOMBRE_ESTUDIANTE',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO',\n        'Identificaci\u00f3n':'DOCUMENTO_ESTUDIANTE',\n        'Fecha Matr\u00edcula':'FECHA_MATRICULA',\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'Correo':'CORREO',\n        'Nivel':'SEMESTRE',\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    # Remove dots from TIPO_DOCUMENTO\n    df['TIPO_DOCUMENTO'] = df['TIPO_DOCUMENTO'].str.replace('.', '', regex=False)\n\n    # Split column into SEDE, JORNADA, and PROGRAMA\n    df[['SEDE', 'JORNADA', 'PROGRAMA']] = df['SEDE - JORNADA - PROGRAMA'].str.extract(r'(\\w+ \\w+) (\\w+) - (.+)')\n\n    # Eliminar columna: 'SEDE - JORNADA - PROGRAMA'\n    df = df.drop(columns=['SEDE - JORNADA - PROGRAMA'])\n\n    #elimina de df los duplicados por las columnas 'Fecha Matr\u00edcula' y 'Identificaci\u00f3n'\n    df = df.drop_duplicates(subset=['FECHA_MATRICULA', 'DOCUMENTO_ESTUDIANTE'])\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():\n    try:\n        df_cede_Listado_Matriculas = obtener_sharepoint_listado_matriculas()\n        actualizar_sharepoint_procesado(df_cede_Listado_Matriculas, 'cede_Listado_Matriculas')\n    except Exception as e:\n        logging.info(f\"Estructura invalida: {e}. Proceso finalizado.\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/","title":"cede_04 procesar_Ingresos","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado,get_data_range\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/#procesar_cede_ingresos","title":"procesar_cede_Ingresos","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de ingresos almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>procesar_cede_Ingresos</code>abre un archivo de Excel, procesa los datos eliminando filas y columnas innecesarias, y transforma los datos en un formato adecuado para su an\u00e1lisis. Los datos procesados se almacenan en un DataFrame de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_cede_Ingresos</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Ingresos_*.xlsx', y procesa cada archivo utilizando la funci\u00f3n <code>procesar_cede_Ingresos</code>. Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan y renombran columnas espec\u00edficas para limpiar y estandarizar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Este proceso asegura que los datos de ingresos est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>@log_step_decorator('procesar_cede_Ingresos')\ndef procesar_cede_Ingresos(file_path):\n\n    # Obtener rango de datos\n    try:\n        data = get_data_range(file_path, 0)\n    except Exception as e:\n        print(f\"Error: {e}\")\n\n    df_range = pd.DataFrame(data)\n    # Variable cargada \"df_range\" del estado del Kernel\n\n    # Remove rows from 0 to 8\n    df_range = df_range.drop(index=range(0, 9))\n\n    # Drop columns with all missing values\n    df_range = df_range.dropna(axis=1, how='all')\n    # Mostrar las primeras filas del DataFrame para verificar el contenido\n\n\n    df_range.reset_index(drop=True, inplace=True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    # Fill NaN in row 0 with values from row 2\n    df_range.iloc[0] = df_range.iloc[0].fillna(df_range.iloc[2])\n\n    #elimina las columnas 17,22,23\n    df_range = df_range.drop(columns=[17, 22, 23])\n\n\n    # Set first row as column names, enumerate duplicates\n    df_range.columns = df_range.iloc[0]\n    df_range = df_range[1:]\n\n    # Rename the second 'Valor' column to 'Valor_1'\n    df_range.columns = ['Valor_1' if (col == 'Valor' and idx == 1) else col for idx, col in enumerate(df_range.columns)]\n\n    # Filter column 'N\u00b0 Recibo' to keep non-null values\n    df_range = df_range[df_range['N\u00b0 Recibo'].notna()]\n\n    # Crear un diccionario para rastrear las columnas duplicadas y renombrarlas\n    columns = pd.Series(df_range.columns)\n    duplicates = columns[columns.duplicated()].unique()\n\n    # Crea un diccionario para rastrear las columnas duplicadas y renombrarlas adecuadamente\n    for dup in duplicates:\n        dup_indices = columns[columns == dup].index\n        for i, idx in enumerate(dup_indices):\n            if i != 0:\n                columns[idx] = f\"{dup}_{i}\"\n\n    # Asignar las nuevas columnas al DataFrame\n    df_range.columns = columns\n\n    # Reinicia el \u00edndice nuevamente\n    df_range.reset_index(drop=True, inplace=True)        \n\n    # Separar la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n    df_range[['Tipo Identificaci\u00f3n', 'Identificaci\u00f3n']] = df_range['Identificaci\u00f3n'].str.split(' ', expand=True)\n\n    # Separar la columna \"Concepto\" por \" - \"\n    df_range[['C\u00f3digo Concepto', 'Concepto']] = df_range['Concepto'].str.split(' - ', n=1, expand=True)    \n\n    df_range = df_range[['N\u00b0 Recibo', 'Fecha', 'Pagado por', 'Tipo Identificaci\u00f3n', 'Identificaci\u00f3n', 'Cajero', 'C\u00f3digo Concepto', 'Concepto', 'Valor', 'Nombre', 'Valor_1', 'Total Pagado']]\n\n    # Remove rows with None in 'Fecha' column\n    df_range = df_range[df_range['Fecha'].notna()]\n\n    return df_range\n\n\n@log_step_decorator('obtener_sharepoint_cede_Ingresos')\ndef obtener_sharepoint_cede_Ingresos():\n    folder_url = etl_to_folder_url.get('cede_Ingresos', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Ingresos_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Ingresos_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        df_temp = procesar_cede_Ingresos(file)\n        all_dfs.append(df_temp)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n\n    columnas_a_eliminar = ['Hoja','Registro']\n\n    renombres = {\n        'N\u00b0 Recibo':'NO_RECIBO',\n        'Fecha':'FECHA_CONTABLE',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO_PAGO',\n        'Identificaci\u00f3n':'DOCUMENTO_PAGO',\n        'C\u00f3digo Concepto':'ID_CONCEPTO',\n        'Valor':'VALOR_FACTURADO',\n        'Pagado por':'PAGADO_POR',\n        'Total Pagado':'VALOR_PAGADO'}\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n    # Variable cargada \"df\" del estado del Kernel\n    df['TIPO_DOCUMENTO_PAGO'] = df['TIPO_DOCUMENTO_PAGO'].str.replace('.', '', regex=False)\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_cede_Ingresos = obtener_sharepoint_cede_Ingresos()\n    actualizar_sharepoint_procesado(df_cede_cede_Ingresos, 'cede_Ingresos')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/","title":"cede_05 cede_Historico_Notas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado,procesar_excel_con_hojas\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/#cede_historico_notas","title":"cede_Historico_Notas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de notas hist\u00f3ricas almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>procesar_periodos</code> abre un archivo de Excel, procesa los datos eliminando filas y columnas innecesarias, y transforma los datos en un formato adecuado para su an\u00e1lisis. Los datos procesados se almacenan en un DataFrame de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_cede_Historico_Notas</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Historico_Notas_*.xlsx', y procesa cada archivo utilizando la funci\u00f3n <code>procesar_periodos</code>. Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan y renombran columnas espec\u00edficas para limpiar y estandarizar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Este proceso asegura que los datos de notas hist\u00f3ricas est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>@log_step_decorator('procesar_cede_Historico_Notas')\ndef procesar_corte(df, corte_nombre, columnas_a_eliminar, renombres):\n    df_corte = df[df['corte'] == corte_nombre].copy()\n    df_corte.reset_index(drop=True, inplace=True)\n    if not df_corte.empty:\n        df_corte = df_corte.drop(0).reset_index(drop=True)\n        df_corte.columns = [value if str(value).startswith('C') else col for col, value in zip(df_corte.columns, df_corte.iloc[0])]\n        df_corte = df_corte.drop(0).reset_index(drop=True)\n    df_corte = limpiar_columnas(df_corte, columnas_a_eliminar, renombres)\n    return df_corte\n\n@log_step_decorator('procesar_periodos')\ndef procesar_periodos(file_path):\n    resultado_df = procesar_excel_con_hojas(file_path)\n    df = resultado_df.copy()\n\n    # Crear diccionarios desde filas espec\u00edficas\n    _encabezados = resultado_df.iloc[3:7, [0, 2]].set_index(resultado_df.columns[0]).to_dict()[resultado_df.columns[2]]\n    dic_tempB = resultado_df.iloc[3:7, [7, 9]].set_index(resultado_df.columns[7]).to_dict()[resultado_df.columns[9]]\n    _encabezados.update(dic_tempB)\n\n    # Limpieza inicial del DataFrame\n    columnas_a_eliminar = ['Unnamed: 0', 'Cedesarrollo - Comfenalco']\n    renombres_iniciales = {'Unnamed: 1': 'Estudiante', 'Unnamed: 3': 'referencia'}\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres_iniciales)\n\n    # Crear columna 'corte' con valores que contienen 'Corte'\n    df['corte'] = df['referencia'].apply(lambda x: x if 'Corte' in str(x) else None).ffill()\n\n    # Procesar Primer y Tercer Corte\n    columnas_a_eliminar_corte = ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12']\n    df_tercer_corte = procesar_corte(df, 'Tercer Corte', columnas_a_eliminar_corte, {'Unnamed: 7': 'Nota Acum.', 'Unnamed: 8': 'Inasis Acum.'})\n    df_primer_corte = procesar_corte(df, 'Primer Corte', columnas_a_eliminar_corte, {})\n\n    # Unir Primer y Tercer Corte por 'Estudiante'\n    df_merged = pd.merge(df_primer_corte, df_tercer_corte, on='Estudiante', how='inner')\n\n    # Agregar columnas con el diccionario _encabezados\n    for key, value in _encabezados.items():\n        df_merged[key] = value\n\n    return df_merged\n\n\n@log_step_decorator('obtener_sharepoint_cede_Historico_Notas')\ndef obtener_sharepoint_cede_Historico_Notas():\n    folder_url = etl_to_folder_url.get('cede_Historico_Notas', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Historico_Notas_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Historico_Notas_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [procesar_periodos(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # Variable cargada \"df_cede_Historico_Notas\" del estado del Kernel\n\n    # Filtrar filas seg\u00fan la columna: 'Estudiante'\n    df = df[df['Estudiante'].notna()]\n\n    # Reset index of DataFrame\n    df = df.reset_index(drop=True)\n\n    # Eliminate columns with all NaN values\n    df = df.dropna(axis=1, how='all')\n\n    # Split \"Sede - jornada:\" into \"SEDE\" and \"JORNADA\"\n    df[['SEDE', 'JORNADA']] = df['Sede - jornada: '].str.split(' - ', expand=True)\n    campos = df.columns.tolist()\n    # guardar_diccionario(campos,'campos')\n    renombrar = {\n        'Estudiante':'NOMBRE_ESTUDIANTE',\n        'referencia':'PRIMER_CORTE',\n        'CP C1-E1':'PRIMER_CORTE_CP1',\n        'CP C1-E2':'PRIMER_CORTE_CP2',\n        'CT C1-E1':'PRIMER_CORTE_CT1',\n        'CT C1-E2':'PRIMER_CORTE_CT2',\n        'Unnamed: 8':'SEGUNDO_CORTE',\n        'CP C2-E1':'SEGUNDO_CORTE_CP1',\n        'CP C2-E2':'SEGUNDO_CORTE_CP2',\n        'CT C2-E1':'SEGUNDO_CORTE_CT1',\n        'CT C2-E2':'SEGUNDO_CORTE_CT2',\n        'Unnamed: 13_x':'TERCER_CORTE',\n        'CP C3-E1':'TERCER_CORTE_CP1',\n        'CP C3-E2':'TERCER_CORTE_CP2',\n        'CT C3-E1':'TERCER_CORTE_CT1',\n        'CT C3-E2':'TERCER_CORTE_CT2',\n        'Nota Acum.':'NOTA_FINAL',\n        'M\u00f3dulo: ':'MODULO',\n        'Curso: ':'CURSO',\n        'Fecha inicio: ':'FECHA_INICIO',\n        'Per\u00edodo: ':'PERIODO_ACADEMICO',\n        'Programa: ':'PROGRAMA_ACADEMICO',\n        'Docente: ':'NOMBRE_DOCENTE',\n        'Inasis Acum.':'INASISTENCIAS_ACUMULADAS',\n        'Fecha fin: ':'FECHA_FIN',\n    }\n    eliminar = ['Sede - jornada: ','corte_x','corte_y']\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Historico_Notas = obtener_sharepoint_cede_Historico_Notas()\n    actualizar_sharepoint_procesado(df_cede_Historico_Notas, 'cede_Historico_Notas')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/","title":"cede_06 cede_Egresados_Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,replace_values_df,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/#cede_egresados_graduados","title":"cede_Egresados_Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de egresados y graduados almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n </p> <p>obtener_sharepoint_cede_Egresados_Graduados</p> <p>descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Graduados_*.xlsx', y procesa cada archivo utilizando pandas para leer los datos.</p> <p>Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan columnas espec\u00edficas y se reemplazan valores en el DataFrame. Finalmente, se renombran las columnas para limpiar y estandarizar los datos.</p> <p>Este proceso asegura que los datos de egresados y graduados est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_cede_Egresados_Graduados():\n    folder_url = etl_to_folder_url.get('cede_Egresados_Graduados', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Graduados_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Graduados_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # Eliminar columna: 'Grupo'\n    df = df.drop(columns=['Grupo'])\n    df = replace_values_df(df)\n    renombrar = {\n        'C\u00f3digo de matr\u00edcula':'ID_MATRICULA',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n':'DOCUMENTO',\n        'Grupo Sisben':'GRUPO',\n        'Nivel de formaci\u00f3n':'NIVEL_FORMACION',\n        'Ocupaci\u00f3n':'OCUPACION',\n        'Sede':'SEDE',\n        'Jornada':'JORNADA',\n        'Programa':'PROGRAMA',\n        'Per\u00edodo':'PERIODO_ACADEMICO',\n        'Nivel':'SEMESTRE',\n        'Fecha graduado':'FECHA_GRADUADO',\n        'Acta graduado':'ACTA_GRADUADO',\n        'Folio graduado':'FOLIO_GRADUADO',\n        'Diploma graduado':'DIPLOMA_GRADUADO'    \n    }\n    eliminar = []\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    df = df[['ID_MATRICULA',\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'GRUPO',\n        'NIVEL_FORMACION',\n        'OCUPACION',\n        'SEDE',\n        'JORNADA',\n        'PROGRAMA',\n        'PERIODO_ACADEMICO',\n        'SEMESTRE',\n        'FECHA_GRADUADO',\n        'ACTA_GRADUADO',\n        'FOLIO_GRADUADO',\n        'DIPLOMA_GRADUADO',\n        'ZONA',\n        '\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N']]\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Egresados_Graduados = log_step_decorator(\"Obtener y procesar Egresados Graduados\")(obtener_sharepoint_cede_Egresados_Graduados)()    \n    actualizar_sharepoint_procesado(df_cede_Egresados_Graduados, 'cede_Egresados_Graduados')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/","title":"cede_07 Cancelados Desertores","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado,procesar_excel_con_hojas,actualizar_columna_programa\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/#obtener_sharepoint_cede_cancelados_desertores","title":"obtener_sharepoint_cede_Cancelados_Desertores","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de cancelados y desertores almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_cede_Cancelados_Desertores</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Cancelados_*.xlsx', y procesa cada archivo utilizando pandas para leer los datos.</p> <p>Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan columnas espec\u00edficas y se reemplazan valores en el DataFrame. Finalmente, se renombran las columnas para limpiar y estandarizar los datos.</p> <p>Este proceso asegura que los datos de cancelados y desertores est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_cede_Cancelados_Desertores():\n    folder_url = etl_to_folder_url.get('cede_Cancelados_Desertores', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Cancelados_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Cancelados_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        _df = procesar_excel_con_hojas(file)\n        all_dfs.append(_df)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n    return df\n\n@log_step_decorator(\"Procesar Cancelados Desertores\")\ndef procesar_Cancelados_Desertores(df_cede_Cancelados_Desertores):\n    # Variable cargada \"df_cede_Cancelados_Desertores\" del estado del Kernel\n\n    df_cede_Cancelados_Desertores.columns = [f'Columna_{i}' for i in range(len(df_cede_Cancelados_Desertores.columns))]\n\n\n    # Iterate over Columna_11 from row 8\n    for index, row in df_cede_Cancelados_Desertores.iloc[8:].iterrows():\n        if pd.isna(row['Columna_11']):\n            if not pd.isna(row['Columna_12']):\n                df_cede_Cancelados_Desertores.at[index, 'Columna_11'] = row['Columna_12']\n                df_cede_Cancelados_Desertores.at[index, 'Columna_12'] = row['Columna_14']\n\n    df_cede_Cancelados_Desertores['Columna_5'] = df_cede_Cancelados_Desertores['Columna_5'].combine_first(df_cede_Cancelados_Desertores['Columna_6'])\n    df_cede_Cancelados_Desertores['Columna_7'] = df_cede_Cancelados_Desertores['Columna_7'].combine_first(df_cede_Cancelados_Desertores['Columna_8'])\n    df_cede_Cancelados_Desertores['Columna_9'] = df_cede_Cancelados_Desertores['Columna_9'].combine_first(df_cede_Cancelados_Desertores['Columna_10'])\n\n\n    df_cede_Cancelados_Desertores = actualizar_columna_programa(\n        df_cede_Cancelados_Desertores, \n        columna_condicional='Columna_0', \n        columna_origen='Columna_0', \n        columna_destino='Sede',\n        texto_filtro='Sede'\n    )\n\n    # Variable cargada \"df_cede_Cancelados_Desertores\" del estado del Kernel\n\n    # Filtrar filas seg\u00fan la columna: 'Columna_0'\n    df_cede_Cancelados_Desertores = df_cede_Cancelados_Desertores[df_cede_Cancelados_Desertores['Columna_0'].notna()]\n\n    # Filtrar filas seg\u00fan la columna: 'Columna_3'\n    df_cede_Cancelados_Desertores = df_cede_Cancelados_Desertores[df_cede_Cancelados_Desertores['Columna_3'].notna()]\n\n    # Fill empty Columna_12 with Columna_13 values\n    df_cede_Cancelados_Desertores['Columna_12'] = df_cede_Cancelados_Desertores['Columna_12'].fillna(df_cede_Cancelados_Desertores['Columna_13'])\n\n    # Separar la columna \"Sede\" en SEDE y JORNADA\n    df_cede_Cancelados_Desertores[['SEDE', 'JORNADA']] = df_cede_Cancelados_Desertores['Sede'].str.split(' - ', expand=True)\n\n    # Filtrar filas seg\u00fan la columna: 'PROGRAMA'\n    df_cede_Cancelados_Desertores = df_cede_Cancelados_Desertores[df_cede_Cancelados_Desertores['Columna_0'] != \"Programa\"]\n\n\n    eliminar = [\n        'Columna_2',\n        'Columna_4',\n        'Columna_6',\n        'Columna_8',\n        'Columna_10',\n        'Columna_13',\n        'Columna_14',\n        'Columna_15',\n        'Sede',\n        'Columna_1',\n        'Columna_5'\n    ]\n    renombrar = {\n        'Columna_0':'PROGRAMA',\n        'Columna_3':'NOMBRE_ESTUDIANTE',\n        'Columna_7':'FECHA',\n        'Columna_9':'TIPO',\n        'Columna_11':'CAUSA',\n        'Columna_12':'OBSERVACIONES',\n        'Columna_5':'SEDE',\n    }\n    df_cede_Cancelados_Desertores = limpiar_columnas(df_cede_Cancelados_Desertores, eliminar, renombrar,True)\n\n\n    return df_cede_Cancelados_Desertores\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Cancelados_Desertores = log_step_decorator(\"Obtener Cancelados Desertores\")(obtener_sharepoint_cede_Cancelados_Desertores)()    \n    df_cede_Cancelados_Desertores = procesar_Cancelados_Desertores(df_cede_Cancelados_Desertores)    \n    actualizar_sharepoint_procesado(df_cede_Cancelados_Desertores, 'cede_Cancelados_Desertores')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/","title":"emp_01 Docentes Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\n\nimport logging\nimport os\nimport sys\nimport glob\nimport re\nimport datetime\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,replace_values_df,limpiar_carpeta, obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/#obtener_sharepoint_docentes","title":"obtener_sharepoint_docentes","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de docentes almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_docentes</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Docentes_*.xlsx', y selecciona el archivo m\u00e1s reciente basado en la fecha incluida en el nombre del archivo.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia. Luego, descarga los archivos desde SharePoint y filtra el archivo m\u00e1s reciente utilizando una expresi\u00f3n regular para extraer la fecha del nombre del archivo. Los archivos m\u00e1s antiguos se eliminan para mantener la carpeta organizada.</p> <p>El archivo m\u00e1s reciente se lee en un <code>DataFrame</code> de pandas, y se registra el contenido del archivo para su seguimiento. La funci\u00f3n <code>procesar_cede_Docentes</code> se encarga de reemplazar valores en el DataFrame y eliminar espacios en blanco de los nombres y apellidos, asegurando que los datos est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_docentes():\n    folder_url = etl_to_folder_url.get('emp_Docentes', \"URL por defecto si no se encuentra el valor de etl\")\n    if not os.path.exists(_folder):\n        os.makedirs(_folder)\n    else:\n        limpiar_carpeta(_folder)\n\n    obtener_sharepoint(folder_url,_folder)\n    files = glob.glob(os.path.join(_folder, \"Docentes_*.xlsx\"))\n\n    date_pattern = re.compile(r'Docentes_(\\d{2})_(\\d{2})_(\\d{4})\\.xlsx')\n\n    def extract_date(file_name):\n        match = date_pattern.search(file_name)\n        if match:\n            day, month, year = map(int, match.groups())\n            return datetime.date(year, month, day)\n        return None\n    latest_file = max(files, key=lambda f: extract_date(f))\n\n    for file in files:\n        if file != latest_file:\n            os.remove(file)\n\n    logger.info(f\"El archivo m\u00e1s reciente es: {latest_file}\")\n\n\n    df = pd.read_excel(latest_file)\n\n    logger.info(f\"Contenido del archivo {latest_file}:\")\n    return df\n\n\n@log_step_decorator('procesar_cede_Docentes')\ndef procesar_cede_Docentes(df):\n    # Reemplaza valores en el DataFrame seg\u00fan sea necesario.\n    df = replace_values_df(df)\n\n    # Elimina espacios en blanco de los nombres y apellidos.\n    df['Primer nombre'] = df['Primer nombre'].str.strip()\n    df['Segundo nombre'] = df['Segundo nombre'].str.strip()\n    df['Primer apellido'] = df['Primer apellido'].str.strip()\n    df['Segundo apellido'] = df['Segundo apellido'].str.strip()\n\n    # Concatena los nombres y apellidos en una sola columna 'NOMBRE', omitiendo los vac\u00edos.\n    df['NOMBRE'] = df[['Primer nombre', 'Segundo nombre', 'Primer apellido', 'Segundo apellido']].apply(lambda x: ' '.join(x.dropna().astype(str)).upper(), axis=1)\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = []\n    renombres = {\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'E-mail':'CORREO',\n        'Direcci\u00f3n':'DIRECCION',\n        'C\u00e9dula':'CEDULA',\n        'Municipio direcci\u00f3n':'CIUDAD',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n': 'DOCUMENTO',\n        'Fecha de nacimiento':'FECHA_NACIMIENTO',\n        'Sexo':'GENERO'\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n\n    # Selecciona y reordena las columnas del DataFrame.\n    df = df[[\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'NOMBRE',\n        'PRIMER NOMBRE',\n        'SEGUNDO NOMBRE',\n        'PRIMER APELLIDO',\n        'SEGUNDO APELLIDO',\n        'TELEFONO',\n        'CELULAR',\n        'CORREO',\n        'DIRECCION',\n        'CIUDAD',\n        'FECHA_NACIMIENTO',\n        'MUNICIPIO EXPEDICI\u00d3N',\n        'FECHA DE EXPEDICI\u00d3N',\n        'GENERO',\n        'MUNICIPIO NACIMIENTO',\n        'TIPO DE SANGRE',\n        'ESCALAF\u00d3N',\n        'ESTADO CIVIL',\n        'CALIDAD DE DESEMPE\u00d1O',\n        'ESTADO',\n        'FECHA DE INGRESO',\n        'TIEMPO LABORAL',\n        'TIPO DE VINCULACI\u00d3N',\n        'ORIGEN VINCULACI\u00d3N',\n        'NIVEL ACAD\u00c9MICO',\n        'ESPECIALIDAD',\n        'FUENTE DE RECURSOS',\n        'SALARIO',\n        'USUARIO',\n        ]]\n\n    # Retorna el DataFrame procesado.\n    # Remove empty columns\n    df = df.dropna(axis=1, how='all')\n    return df\n\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Docentes = obtener_sharepoint_docentes()\n    df_emp_Docentes = procesar_cede_Docentes(df_emp_Docentes)\n    actualizar_sharepoint_procesado(df_emp_Docentes, 'emp_Docentes')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/","title":"emp_02 Listado Matr\u00edculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\nimport openpyxl\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/#obtener_sharepoint_listado_matriculas","title":"obtener_sharepoint_listado_matriculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de matr\u00edculas almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_listado_matriculas</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Listado_Matriculas_*.xlsx', y selecciona el archivo m\u00e1s reciente basado en la fecha incluida en el nombre del archivo.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia. Luego, descarga los archivos desde SharePoint y filtra el archivo m\u00e1s reciente utilizando una expresi\u00f3n regular para extraer la fecha del nombre del archivo. Los archivos m\u00e1s antiguos se eliminan para mantener la carpeta organizada.</p> <p>El archivo m\u00e1s reciente se lee en un <code>DataFrame</code> de pandas, y se registran las columnas del archivo para su seguimiento. La funci\u00f3n <code>limpiar_columnas</code> se encarga de eliminar y renombrar columnas espec\u00edficas para limpiar y estandarizar los datos. Adem\u00e1s, se eliminan los puntos de la columna <code>TIPO_DOCUMENTO</code>, se dividen los valores de la columna <code>SEDE - JORNADA - PROGRAMA</code> en tres columnas separadas (<code>SEDE</code>, <code>JORNADA</code> y <code>PROGRAMA</code>), y se eliminan duplicados basados en las columnas <code>FECHA_MATRICULA</code> y <code>DOCUMENTO_ESTUDIANTE</code>.</p> <p>Finalmente, si la variable de control <code>ejecutar</code> est\u00e1 activada, se llama a la funci\u00f3n <code>actualizar_sharepoint_procesado</code> para actualizar los datos procesados de vuelta en SharePoint, asegurando que los datos de matr\u00edculas est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def procesar_listado_matriculas(file_path):\n    wb = openpyxl.load_workbook(file_path, data_only=True)\n    all_data = []\n\n    # Iterar sobre las hojas del archivo con \u00edndice\n    for sheet_idx, sheet_name in enumerate(wb.sheetnames):\n        sheet = wb[sheet_name]\n        sheet_data = []\n        header_row = None\n        registro_num = 0  # Contador para el n\u00famero de registro\n        empty_row_count = 0  # Contador de filas vac\u00edas consecutivas\n\n        for row_idx, row in enumerate(sheet.iter_rows(values_only=True), start=1):\n            if row[0] and row[0].strip() == \"Estudiante\":  # Detectar encabezado\n                header_row = row\n                _info = sheet.cell(row=row_idx - 3, column=1).value\n                if _info:\n                    header_info = _info\n                    registro_num = 0\n\n                # Analizar header_row y obtener los nombres de las columnas\n                if header_row:\n                    col_indices = {\n                        col_name.replace(\"\\n\", \" \"): idx\n                        for idx, col_name in enumerate(header_row)\n                        if col_name and col_name.replace(\"\\n\", \" \") in [\n                            \"Estudiante\", \"Identificaci\u00f3n\", \"Fecha Matr\u00edcula\",\n                            \"Tel\u00e9fono\", \"Celular\", \"Correo\", \"Nivel\", \"Estado\"\n                        ]\n                    }\n                continue\n\n            if header_row:\n                registro_num += 1                \n                # Validar si la fila tiene suficientes columnas\n                if row[0] is None:\n                    empty_row_count += 1\n                    if empty_row_count &gt;= 5:  \n                        break\n                    continue\n                elif row[0] == 'www.q10.com':\n                    break\n                else:\n                    empty_row_count = 0  # Reiniciar contador si se encuentra una fila v\u00e1lida\n\n                # Procesar datos\n\n                # Dividir la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n                identificacion = row[col_indices.get(\"Identificaci\u00f3n\", 1)]\n                tipo, numero = (None, None)  # Valores predeterminados en caso de error\n                if identificacion and \" \" in identificacion:\n                    tipo, numero = identificacion.split(\" \", 1)\n\n                data_row = {\n                    \"Hoja\": sheet_name,\n                    \"Registro\": registro_num,\n                    \"Sede - jornada - Programa\": header_info,\n                    \"Estudiante\": row[col_indices.get(\"Estudiante\", 0)],\n                    \"Tipo Identificaci\u00f3n\": tipo,\n                    \"Identificaci\u00f3n\": numero,\n                    \"Fecha Matr\u00edcula\": row[col_indices.get(\"Fecha Matr\u00edcula\", 2)],\n                    \"Tel\u00e9fono\": row[col_indices.get(\"Tel\u00e9fono\", 3)],\n                    \"Celular\": row[col_indices.get(\"Celular\", 4)],\n                    \"Correo\": row[col_indices.get(\"Correo\", 5)],\n                    \"Nivel\": row[col_indices.get(\"Nivel\", 6)],\n                    \"Estado\": row[col_indices.get(\"Estado\", 7)],\n                }\n                sheet_data.append(data_row)\n\n        # Combinar los datos de cada hoja\n        if sheet_data:\n            all_data.extend(sheet_data)\n\n    # Crear un DataFrame final con todos los datos procesados\n    df = pd.DataFrame(all_data)\n    df = df.dropna(subset=[\"Identificaci\u00f3n\"])  # Eliminar filas con identificaci\u00f3n nula\n    return df\n\n@log_step_decorator(\"obtener_sharepoint_listado_matriculas\")\ndef obtener_sharepoint_listado_matriculas():\n    folder_url = etl_to_folder_url.get('emp_Listado_Matriculas', \"URL por defecto si no se encuentra el valor de etl\")\n    # obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Listado_Matriculas_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Listado_Matriculas_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        df_temp = log_step_decorator(f\"Procesando {file}\")(procesar_listado_matriculas)(file)\n        all_dfs.append(df_temp)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = ['Hoja','Registro']\n    #    'Sede - jornada - Programa',\n    renombres = {\n        'Estudiante': 'NOMBRE_ESTUDIANTE',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO',\n        'Identificaci\u00f3n':'DOCUMENTO_ESTUDIANTE',\n        'Fecha Matr\u00edcula':'FECHA_MATRICULA',\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'Correo':'CORREO',\n        'Nivel':'SEMESTRE',\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres, True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    # Remove dots from TIPO_DOCUMENTO\n    df['TIPO_DOCUMENTO'] = df['TIPO_DOCUMENTO'].str.replace('.', '', regex=False)\n\n    # Split column into SEDE, JORNADA, and PROGRAMA\n    df[['SEDE', 'JORNADA', 'PROGRAMA']] = df['SEDE - JORNADA - PROGRAMA'].str.extract(r'(\\w+ \\w+) (\\w+) - (.+)')\n\n    # Eliminar columna: 'SEDE - JORNADA - PROGRAMA'\n    df = df.drop(columns=['SEDE - JORNADA - PROGRAMA'])\n\n    #elimina de df los duplicados por las columnas 'Fecha Matr\u00edcula' y 'Identificaci\u00f3n'\n    df = df.drop_duplicates(subset=['FECHA_MATRICULA', 'DOCUMENTO_ESTUDIANTE'])\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_listado_matriculas = obtener_sharepoint_listado_matriculas()\n    if df_listado_matriculas is not None:\n        # elimina de df los duplicados por las columnas 'Fecha Matr\u00edcula' y 'Identificaci\u00f3n'\n        actualizar_sharepoint_procesado(df_listado_matriculas, 'emp_Listado_Matriculas')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/","title":"emp_03 Preinscritos Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\n\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/#procesar_preinscritos","title":"procesar_preinscritos","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de preinscritos almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Preinscritos</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Preinscritos_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan las filas duplicadas basadas en las columnas <code>N\u00famero de identificaci\u00f3n</code> y <code>Fecha</code>, asegurando que los datos est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <p>La funci\u00f3n <code>procesar_preinscritos</code> se encarga de limpiar y transformar los datos. Primero, elimina los espacios en blanco de los nombres y apellidos. Luego, concatena los nombres y apellidos en una sola columna <code>NOMBRE</code>, omitiendo los valores vac\u00edos y convirtiendo todo a may\u00fasculas. Adem\u00e1s, divide la columna <code>Sede - jornada</code> en dos columnas separadas (<code>SEDE</code> y <code>JORNADA</code>). Finalmente, define las columnas a eliminar para limpiar y estandarizar los datos.</p> <pre><code>def obtener_sharepoint_emp_Preinscritos():\n    folder_url = etl_to_folder_url.get('emp_Preinscritos', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Preinscritos_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Preinscritos_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # elimina las filas duplicadas por 'N\u00famero de identificaci\u00f3n' y Fecha\n    df = df.drop_duplicates(subset=['N\u00famero de identificaci\u00f3n', 'Fecha'])\n    return df\n\ndef procesar_preinscritos(df):\n    # Elimina espacios en blanco de los nombres y apellidos.\n    df['Primer nombre'] = df['Primer nombre'].str.strip()\n    df['Segundo nombre'] = df['Segundo nombre'].str.strip()\n    df['Primer apellido'] = df['Primer apellido'].str.strip()\n    df['Segundo apellido'] = df['Segundo apellido'].str.strip()\n\n    # Concatena los nombres y apellidos en una sola columna 'NOMBRE', omitiendo los vac\u00edos.\n    df['NOMBRE'] = df[['Primer nombre', 'Segundo nombre', 'Primer apellido', 'Segundo apellido']].apply(lambda x: ' '.join(x.dropna().astype(str)).upper(), axis=1)\n    # Split column into SEDE and JORNADA\n    df[['SEDE', 'JORNADA']] = df['Sede - jornada'].str.extract(r'(.+) - (.+)')\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = [\n        'Primer nombre',\n        'Segundo nombre',\n        'Primer apellido',\n        'Segundo apellido',\n        'Sexo',\n        'Tel\u00e9fono',\n        'Celular',\n        'Correo electr\u00f3nico',\n        'Fecha de nacimiento',\n        'Direcci\u00f3n',\n        'Lugar de residencia',\n        'Sede - jornada',\n        'Barrio',    ]\n    renombres = {\n        'N\u00famero de identificaci\u00f3n':'DOCUMENTO_ESTUDIANTE',\n        'C\u00f3digo de referencia':'REFERENCIA',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)    \n    # Remove dots from TIPO_DOCUMENTO\n    df['TIPO_DOCUMENTO'] = df['TIPO_DOCUMENTO'].str.replace('.', '', regex=False)\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Preinscritos = obtener_sharepoint_emp_Preinscritos()\n    df_emp_Preinscritos = procesar_preinscritos(df_emp_Preinscritos)\n    actualizar_sharepoint_procesado(df_emp_Preinscritos, 'emp_Preinscritos')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/","title":"emp_04 Egresados Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,replace_values_df,obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/#obtener_sharepoint_emp_egresados_graduados","title":"obtener_sharepoint_emp_Egresados_Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de egresados y graduados almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Egresados_Graduados</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Graduados_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se elimina la columna <code>Grupo</code> y se reemplazan valores en el <code>DataFrame</code> utilizando la funci\u00f3n <code>replace_values_df</code>. Finalmente, se renombran las columnas para limpiar y estandarizar los datos utilizando la funci\u00f3n <code>limpiar_columnas</code>, asegurando que los datos est\u00e9n estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_emp_Egresados_Graduados():\n    folder_url = etl_to_folder_url.get('emp_Egresados_Graduados', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Graduados_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Graduados_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # Eliminar columna: 'Grupo'\n    df = df.drop(columns=['Grupo'])\n    df = replace_values_df(df)\n    renombrar = {\n        'C\u00f3digo de matr\u00edcula':'ID_MATRICULA',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n':'DOCUMENTO',\n        'Grupo Sisben':'GRUPO',\n        'Nivel de formaci\u00f3n':'NIVEL_FORMACION',\n        'Ocupaci\u00f3n':'OCUPACION',\n        'Sede':'SEDE',\n        'Jornada':'JORNADA',\n        'Programa':'PROGRAMA',\n        'Per\u00edodo':'PERIODO_ACADEMICO',\n        'Nivel':'SEMESTRE',\n        'Fecha graduado':'FECHA_GRADUADO',\n        'Acta graduado':'ACTA_GRADUADO',\n        'Folio graduado':'FOLIO_GRADUADO',\n        'Diploma graduado':'DIPLOMA_GRADUADO'    \n    }\n    eliminar = []\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    df = df[['ID_MATRICULA',\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'GRUPO',\n        'NIVEL_FORMACION',\n        'OCUPACION',\n        'SEDE',\n        'JORNADA',\n        'PROGRAMA',\n        'PERIODO_ACADEMICO',\n        'SEMESTRE',\n        'FECHA_GRADUADO',\n        'ACTA_GRADUADO',\n        'FOLIO_GRADUADO',\n        'DIPLOMA_GRADUADO',\n        'ZONA',\n        '\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N']]\n\n    # Remove empty columns\n    df = df.dropna(axis=1, how='all')\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Egresados_Graduados = obtener_sharepoint_emp_Egresados_Graduados()\n    actualizar_sharepoint_procesado(df_emp_Egresados_Graduados, 'emp_Egresados_Graduados')\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>2024-12-08 21:02:57,281 - INFO - \u001b[92mIniciando: ETL\u001b[0m\n2024-12-08 21:02:57,287 - INFO - \u001b[92mIniciando: Limpiar carpeta de descargas\u001b[0m\n2024-12-08 21:02:57,299 - INFO - Archivo eliminado: Graduados_Junio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,307 - INFO - Archivo eliminado: Graduados_Julio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,316 - INFO - Archivo eliminado: Graduados_Septiembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,325 - INFO - Archivo eliminado: Graduados_Abril 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,332 - INFO - Archivo eliminado: Graduados_Octubre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,337 - INFO - Archivo eliminado: Graduados_Marzo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,357 - INFO - Archivo eliminado: Graduados_Diciembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,366 - INFO - Archivo eliminado: Graduados_Junio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,371 - INFO - Archivo eliminado: Graduados_Noviembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,380 - INFO - Archivo eliminado: Graduados_Octubre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,386 - INFO - Archivo eliminado: Graduados_Julio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,394 - INFO - Archivo eliminado: Graduados_Octubre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,403 - INFO - Archivo eliminado: Graduados_Septiembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,411 - INFO - Archivo eliminado: Graduados_Septiembre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,418 - INFO - Archivo eliminado: Graduados_Enero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,425 - INFO - Archivo eliminado: Graduados_Agosto 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,432 - INFO - Archivo eliminado: Graduados_Agosto 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,440 - INFO - Archivo eliminado: Graduados_Noviembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,448 - INFO - Archivo eliminado: Graduados_Mayo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,455 - INFO - Archivo eliminado: Graduados_Enero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,464 - INFO - Archivo eliminado: Graduados_Abril 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,470 - INFO - Archivo eliminado: Graduados_Abril 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,478 - INFO - Archivo eliminado: Graduados_Mayo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,485 - INFO - Archivo eliminado: Graduados_Septiembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,492 - INFO - Archivo eliminado: Graduados_Enero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,500 - INFO - Archivo eliminado: Graduados_Marzo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,506 - INFO - Archivo eliminado: Graduados_Diciembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,515 - INFO - Archivo eliminado: Graduados_Diciembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,524 - INFO - Archivo eliminado: Graduados_Febrero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,532 - INFO - Archivo eliminado: Graduados_Agosto 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,538 - INFO - Archivo eliminado: Graduados_Julio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,546 - INFO - Archivo eliminado: Graduados_Febrero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,553 - INFO - Archivo eliminado: Graduados_Octubre 2019_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,561 - INFO - Archivo eliminado: Graduados_Marzo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,568 - INFO - Archivo eliminado: Graduados_Agosto 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,575 - INFO - Archivo eliminado: Graduados_Febrero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,583 - INFO - Archivo eliminado: Graduados_Octubre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,589 - INFO - Archivo eliminado: Graduados_Mayo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,596 - INFO - Archivo eliminado: Graduados_Junio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,598 - INFO - \u001b[92mProceso 'Limpiar carpeta de descargas' completado exitosamente en 0.31 segundos.\u001b[0m\n2024-12-08 21:02:57,599 - INFO - \u001b[92mIniciando: Descargar archivos de SharePoint\u001b[0m\n2024-12-08 21:02:58,772 - INFO - Archivo descargado: Graduados_Junio 2023_21_11_2024.xlsx\n2024-12-08 21:03:00,128 - INFO - Archivo descargado: Graduados_Julio 2024_21_11_2024.xlsx\n2024-12-08 21:03:01,439 - INFO - Archivo descargado: Graduados_Septiembre 2022_21_11_2024.xlsx\n2024-12-08 21:03:02,793 - INFO - Archivo descargado: Graduados_Abril 2023_21_11_2024.xlsx\n2024-12-08 21:03:04,293 - INFO - Archivo descargado: Graduados_Octubre 2023_21_11_2024.xlsx\n2024-12-08 21:03:05,531 - INFO - Archivo descargado: Graduados_Marzo 2022_21_11_2024.xlsx\n2024-12-08 21:03:06,757 - INFO - Archivo descargado: Graduados_Diciembre 2022_21_11_2024.xlsx\n2024-12-08 21:03:08,140 - INFO - Archivo descargado: Graduados_Junio 2024_21_11_2024.xlsx\n2024-12-08 21:03:09,507 - INFO - Archivo descargado: Graduados_Noviembre 2022_21_11_2024.xlsx\n2024-12-08 21:03:10,785 - INFO - Archivo descargado: Graduados_Octubre 2024_21_11_2024.xlsx\n2024-12-08 21:03:12,150 - INFO - Archivo descargado: Graduados_Julio 2023_21_11_2024.xlsx\n2024-12-08 21:03:13,729 - INFO - Archivo descargado: Graduados_Octubre 2022_21_11_2024.xlsx\n2024-12-08 21:03:14,966 - INFO - Archivo descargado: Graduados_Septiembre 2021_21_11_2024.xlsx\n2024-12-08 21:03:16,188 - INFO - Archivo descargado: Graduados_Septiembre 2024_21_11_2024.xlsx\n2024-12-08 21:03:17,471 - INFO - Archivo descargado: Graduados_Enero 2023_21_11_2024.xlsx\n2024-12-08 21:03:18,876 - INFO - Archivo descargado: Graduados_Agosto 2024_21_11_2024.xlsx\n2024-12-08 21:03:20,304 - INFO - Archivo descargado: Graduados_Agosto 2022_21_11_2024.xlsx\n2024-12-08 21:03:22,227 - INFO - Archivo descargado: Graduados_Noviembre 2023_21_11_2024.xlsx\n2024-12-08 21:03:23,650 - INFO - Archivo descargado: Graduados_Mayo 2022_21_11_2024.xlsx\n2024-12-08 21:03:25,017 - INFO - Archivo descargado: Graduados_Enero 2024_21_11_2024.xlsx\n2024-12-08 21:03:26,300 - INFO - Archivo descargado: Graduados_Abril 2022_21_11_2024.xlsx\n2024-12-08 21:03:27,795 - INFO - Archivo descargado: Graduados_Abril 2024_21_11_2024.xlsx\n2024-12-08 21:03:29,145 - INFO - Archivo descargado: Graduados_Mayo 2023_21_11_2024.xlsx\n2024-12-08 21:03:30,567 - INFO - Archivo descargado: Graduados_Septiembre 2023_21_11_2024.xlsx\n2024-12-08 21:03:31,793 - INFO - Archivo descargado: Graduados_Enero 2022_21_11_2024.xlsx\n2024-12-08 21:03:33,260 - INFO - Archivo descargado: Graduados_Marzo 2024_21_11_2024.xlsx\n2024-12-08 21:03:34,704 - INFO - Archivo descargado: Graduados_Diciembre 2023_21_11_2024.xlsx\n2024-12-08 21:03:35,986 - INFO - Archivo descargado: Graduados_Diciembre 2021_21_11_2024.xlsx\n2024-12-08 21:03:37,264 - INFO - Archivo descargado: Graduados_Febrero 2023_21_11_2024.xlsx\n2024-12-08 21:03:38,677 - INFO - Archivo descargado: Graduados_Agosto 2023_21_11_2024.xlsx\n2024-12-08 21:03:40,022 - INFO - Archivo descargado: Graduados_Julio 2022_21_11_2024.xlsx\n2024-12-08 21:03:41,313 - INFO - Archivo descargado: Graduados_Febrero 2022_21_11_2024.xlsx\n2024-12-08 21:03:42,530 - INFO - Archivo descargado: Graduados_Octubre 2019_21_11_2024.xlsx\n2024-12-08 21:03:44,019 - INFO - Archivo descargado: Graduados_Marzo 2023_21_11_2024.xlsx\n2024-12-08 21:03:45,303 - INFO - Archivo descargado: Graduados_Agosto 2021_21_11_2024.xlsx\n2024-12-08 21:03:46,667 - INFO - Archivo descargado: Graduados_Febrero 2024_21_11_2024.xlsx\n2024-12-08 21:03:47,884 - INFO - Archivo descargado: Graduados_Octubre 2021_21_11_2024.xlsx\n2024-12-08 21:03:49,438 - INFO - Archivo descargado: Graduados_Mayo 2024_21_11_2024.xlsx\n2024-12-08 21:03:50,790 - INFO - Archivo descargado: Graduados_Junio 2022_21_11_2024.xlsx\n2024-12-08 21:03:51,792 - INFO - \u001b[92mProceso 'Descargar archivos de SharePoint' completado exitosamente en 54.19 segundos.\u001b[0m\n2024-12-08 21:04:05,897 - INFO - Archivo procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx subido exitosamente a SharePoint.\n\n\nArchivo subido a SharePoint: procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx, folder_url: Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/06.Egresados_Graduados\n\n\n2024-12-08 21:04:06,408 - INFO - \u001b[92mProceso 'ETL' completado exitosamente en 1.15 minutos.\u001b[0m\n\n\nArchivo original eliminado: procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/","title":"emp_05 Estudiantes Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>concatenar_dataframes</code>, <code>obtener_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>, que son fundamentales para el flujo de trabajo.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se define un diccionario llamado <code>etl_to_folder_url</code>, que mapea nombres de procesos ETL a rutas espec\u00edficas en SharePoint. Este diccionario es clave para identificar las ubicaciones de los datos en la plataforma y permite una configuraci\u00f3n flexible para diferentes flujos de trabajo. Tambi\u00e9n se configura una carpeta temporal (<code>_folder</code>) para almacenar archivos procesados, lo que facilita la gesti\u00f3n de datos intermedios durante la ejecuci\u00f3n del proceso.</p> <p>El c\u00f3digo incluye configuraciones para ignorar advertencias espec\u00edficas y ajustar los niveles de otros loggers, asegurando que no interfieran con el proceso principal. Estas configuraciones garantizan que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code>import logging\nimport os\nimport sys\nimport glob\nfrom datetime import datetime\nimport calendar\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,procesar_excel_con_hojas,limpiar_columnas,concatenar_dataframes,\n    obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/#emp_estudiantes_inasistencias","title":"emp_Estudiantes_inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de estudiantes con inasistencias almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. </p> <p>La funci\u00f3n <code>obtener_sharepoint_emp_Estudiantes_inasistencias</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identificando los archivos que cumplen con el patr\u00f3n <code>'emp_Estudiantes_inasistencias_*.xlsx'</code>. Si no se encuentran archivos, se registra un error en el log. Los archivos encontrados se procesan utilizando la funci\u00f3n <code>procesar_inasistencias</code>, que transforma los datos en un formato estructurado.</p> <p>La funci\u00f3n <code>procesar_inasistencias</code> realiza varias operaciones sobre los datos, como:</p> <ul> <li>Leer los datos de cada archivo Excel y procesar las hojas utilizando <code>pandas</code>.</li> <li>Extraer y dividir valores de columnas espec\u00edficas, como separar <code>SEDE</code> y <code>JORNADA</code> desde una columna combinada.</li> <li>Limpiar y estandarizar los datos eliminando columnas innecesarias y renombrando columnas clave, como <code>ESTUDIANTE</code> a <code>NOMBRE_ESTUDIANTE</code> y <code>IDENTIFICACION</code> a <code>DOCUMENTO_ESTUDIANTE</code>.</li> <li>Separar la columna <code>Identificaci\u00f3n</code> en tipo y n\u00famero de documento.</li> <li>Filtrar filas seg\u00fan criterios espec\u00edficos, como excluir filas con valores nulos en columnas clave o aquellas que contienen encabezados repetidos.</li> <li>Agregar una columna de fecha basada en el nombre del archivo procesado, utilizando la funci\u00f3n <code>construir_fecha</code>.</li> </ul> <p>La funci\u00f3n <code>construir_fecha</code> se utiliza para extraer y construir una fecha basada en el nombre del archivo procesado. Espec\u00edficamente, busca informaci\u00f3n sobre el mes y el a\u00f1o en el nombre del archivo y genera una fecha correspondiente al primer d\u00eda de ese mes. Si no se puede extraer una fecha v\u00e1lida, se asigna una fecha predeterminada. Devuelve un objeto <code>datetime</code> que representa la fecha construida.</p> <p>Finalmente, los datos procesados de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code> utilizando la funci\u00f3n <code>concatenar_dataframes</code>. Este <code>DataFrame</code> consolidado se pasa a la funci\u00f3n <code>actualizar_sharepoint_procesado</code>, que carga los datos procesados de vuelta a SharePoint.</p> <p>El flujo principal del c\u00f3digo est\u00e1 controlado por la funci\u00f3n <code>main</code>, que coordina la descarga, el procesamiento y la carga de los datos. Este enfoque asegura que los datos de estudiantes con inasistencias sean transformados y estructurados de manera eficiente, proporcionando trazabilidad y flexibilidad para su an\u00e1lisis o integraci\u00f3n en otros sistemas.</p> <pre><code>def construir_fecha(ruta_completa):\n    # Buscar el comienzo del nombre del archivo\n    inicio_nombre = \"emp_Estudiantes_inasistencias_Per\u00edodo\"\n    indice_inicio = ruta_completa.find(inicio_nombre)\n\n    # Extraer el nombre del archivo desde el texto\n    nombre_archivo = ruta_completa[indice_inicio:].strip()\n\n    try:\n        # Dividir el nombre del archivo en partes\n        partes = nombre_archivo.split(\" \")\n\n        # Obtener el mes y el a\u00f1o\n        mes = partes[-2]  # Pen\u00faltima palabra (mes)\n        anio = anio = partes[-1][:4]  # \u00daltima palabra (a\u00f1o)\n\n        # Convertir el mes a n\u00famero\n        mes = mes.upper()\n        # Diccionario que mapea los meses a sus n\u00fameros\n        mes_numero = {\n            \"ENERO\": 1,\n            \"FEBRERO\": 2,\n            \"MARZO\": 3,\n            \"ABRIL\": 4,\n            \"MAYO\": 5,\n            \"JUNIO\": 6,\n            \"JULIO\": 7,\n            \"AGOSTO\": 8,\n            \"SEPTIEMBRE\": 9,\n            \"OCTUBRE\": 10,\n            \"NOVIEMBRE\": 11,\n            \"DICIEMBRE\": 12\n        }\n\n        # Verificar si el a\u00f1o es v\u00e1lido\n        if not anio.isdigit():\n            raise ValueError(f\"A\u00f1o no v\u00e1lido: {anio}\")\n        logging.info(\"La fecha es valida\")\n        # Crear la fecha en el primer d\u00eda del mes\n        fecha = datetime(int(anio), mes_numero.get(mes, 1), 1)\n    except (ValueError, IndexError):  # Captura errores de formato, mes o a\u00f1o inv\u00e1lido\n        # Usar la fecha predeterminada\n        logging.info(f\"Ruta completa no se puede procesar {ruta_completa}\")\n        fecha = datetime(2009, 1, 1)\n\n    return fecha\n\ndef procesar_inasistencias(file_path):\n    df=procesar_excel_con_hojas(file_path)\n    df.columns = [f'Columna_{i}' for i in range(len(df.columns))]\n\n\n    # Split column into SEDE and JORNADA\n    df[['SEDE', 'JORNADA']] = df['Columna_0'].str.extract(r'(.+) - (.+)')\n    df = df.drop(df.index[:8])\n    df_emp_Estudiantes_inasistencias =  df\n    elimina = {'Columna_1'}\n\n    # Fill empty values in Columna_12 with values from Columna_13\n    df_emp_Estudiantes_inasistencias['Columna_12'] = df_emp_Estudiantes_inasistencias['Columna_12'].fillna(df_emp_Estudiantes_inasistencias['Columna_13'])\n\n    # Asumiendo que df_emp_Estudiantes_inasistencias ya existe\n    df = df_emp_Estudiantes_inasistencias\n    # Variables para controlar el estado\n    found_porcentaje = False\n    found_creditos = False\n    # Funci\u00f3n para procesar cada fila\n    def process_row(row):\n        global found_porcentaje, found_creditos\n        if isinstance(row['Columna_15'], str) and 'Porcentaje' in row['Columna_15']:\n            found_porcentaje = True\n            found_creditos = False\n        elif row['Columna_15'] == 'Creditos':\n            found_creditos = True\n            found_porcentaje = False\n        if found_porcentaje:\n            row['Columna_16'] = row['Columna_15']\n        elif found_creditos:\n            row['Columna_14'] = row['Columna_15']\n        return row\n    # Aplicar la funci\u00f3n a cada fila del DataFrame\n    df = df.apply(process_row, axis=1)\n    # Asignar el resultado de vuelta a df_emp_Estudiantes_inasistencias\n    df_emp_Estudiantes_inasistencias = df\n\n    df = df_emp_Estudiantes_inasistencias\n    # Extraer los valores en las columnas 'Tipo Identificacion' e 'Identificacion'\n\n    # Eliminar los puntos de la columna 'Columna_7'\n    df['Columna_7'] = df['Columna_7'].str.replace('.', '', regex=False)\n\n    df[['Tipo_documento', 'Identificacion']] = df['Columna_7'].str.extract(r'(.+?)\\s+(.+)')\n\n\n    df = df.dropna(axis=1, how='all')\n\n    renombrar = {\n    }\n    eliminar = ['Columna_11',\n                'Columna_7',\n                'Columna_0',\n                'Columna_13',\n                'Columna_15',\n                ]\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n\n    # Restablecer el \u00edndice antes de renombrar las columnas\n    df = df.reset_index(drop=True)\n\n    # Rename columns starting with 'Columna_' using row 0 values in uppercase\n    df.columns = [\n        str(df.iloc[0][col]).upper() if col.startswith('COLUMNA_') else col\n        for col in df.columns\n    ]\n    df = df.drop(0).reset_index(drop=True)\n\n    # Filtrar filas seg\u00fan la columna: 'ESTUDIANTE'\n    df = df[df['ESTUDIANTE'].notna()]\n\n    # Filtrar filas seg\u00fan la columna: 'PROGRAMA'\n    df = df[df['PROGRAMA'] != \"Programa\"]\n\n    renombrar={\n        'ESTUDIANTE': 'NOMBRE_ESTUDIANTE',\n        'IDENTIFICACION': 'DOCUMENTO_ESTUDIANTE',\n        'NIVEL': 'SEMESTRE',\n        'M\u00d3DULO': 'MODULO'        \n    }\n    eliminar = []\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    df['FECHA'] = construir_fecha(file_path)\n    return df\n\ndef obtener_sharepoint_emp_Estudiantes_inasistencias():\n    folder_url = etl_to_folder_url.get('emp_Estudiantes_inasistencias', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"emp_Estudiantes_inasistencias_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'emp_Estudiantes_inasistencias_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [procesar_inasistencias(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    # df = pd.concat(all_dfs, ignore_index=True)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = concatenar_dataframes(all_dfs)\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Estudiantes_inasistencias = obtener_sharepoint_emp_Estudiantes_inasistencias()\n    actualizar_sharepoint_procesado(df_emp_Estudiantes_inasistencias, 'emp_Estudiantes_inasistencias')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/","title":"emp_06 Consolidado Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,actualizar_columna_programa,obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/#consolidado_inasistencias","title":"consolidado_Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de estudiantes con inasistencias almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Consolidado_inasistenciass</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Consolidado_inasistencias_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan las columnas innecesarias y se renombran las columnas para limpiar y estandarizar los datos utilizando la funci\u00f3n <code>limpiar_columnas</code>. Adem\u00e1s, se actualizan las columnas de programa, sede y per\u00edodo utilizando la funci\u00f3n <code>actualizar_columna_programa</code>. Finalmente, se separa la columna <code>Identificaci\u00f3n</code> en tipo y n\u00famero, y se filtran las filas seg\u00fan la columna <code>Sede - jornada</code>, asegurando que los datos est\u00e9n estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_emp_Consolidado_inasistenciass():\n    folder_url = etl_to_folder_url.get('emp_Consolidado_inasistencias', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Consolidado_inasistencias_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Consolidado_inasistencias_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n\n    return df\n\n\ndef procesar_inasistencias(df):\n\n    df.columns = [f'Columna_{i}' for i in range(len(df.columns))]\n\n    df = actualizar_columna_programa(\n        df, \n        columna_condicional='Columna_4', \n        columna_origen='Columna_5', \n        columna_destino='Programa',\n        texto_filtro='Programa'\n    )\n\n    df = actualizar_columna_programa(\n        df, \n        columna_condicional='Columna_1', \n        columna_origen='Columna_3', \n        columna_destino='Sede',\n        texto_filtro='Sede'\n    )\n\n    df = actualizar_columna_programa(\n        df, \n        columna_condicional='Columna_11', \n        columna_origen='Columna_12', \n        columna_destino='Per\u00edodo',\n        texto_filtro='Per\u00edodo'\n    )\n\n\n    columnas_a_eliminar = ['Columna_4','Columna_11','Columna_0','Columna_1','Columna_8','Columna_9','Columna_10','Columna_12']\n    renombres = {'Columna_2': 'Identificaci\u00f3n', 'Columna_3': 'Apellidos y Nombres', 'Columna_5': 'Nivel', 'Columna_6': 'Area', 'Columna_7': 'Total'}\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres)\n\n    # Filtrar filas seg\u00fan la columna: 'Identificaci\u00f3n'\n    df = df[df['Identificaci\u00f3n'].notna()]\n\n    # Eliminar espacios adicionales en la columna 'Identificaci\u00f3n'\n    df['Identificaci\u00f3n'] = df['Identificaci\u00f3n'].str.strip()\n\n\n    # Separar la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n    df[['Tipo Identificaci\u00f3n', 'Identificaci\u00f3n']] = df['Identificaci\u00f3n'].str.split(' ', expand=True)\n    df['Tipo Identificaci\u00f3n'] = df['Tipo Identificaci\u00f3n'].apply(lambda x: str(x).replace('.', ''))\n\n\n    #filtra Identificaci\u00f3n y elimina todas las filas que contentan Identificaci\u00f3n\n    df = df[df['Identificaci\u00f3n'].str.contains('Identificaci\u00f3n')==False]\n\n    df = df[[\n        'Identificaci\u00f3n',\n        'Tipo Identificaci\u00f3n',\n        'Apellidos y Nombres',\n        'Nivel',\n        'Area',\n        'Total',\n        'Programa',\n        'Sede',\n        'Per\u00edodo'\n        ]]\n    df.to_excel(\"emp_Consolidado_inasistencias.xlsx\", index=False)\n\n    df[['SEDE', 'JORNADA']] = df['Sede'].str.extract(r'(.+) - (.+)')\n    #ELIMINA COLUMNA Sede\n    df.drop(columns=['Sede'], inplace=True)\n\n    renombres = {\n        'Identificaci\u00f3n':'DOCUMENTO',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO',\n        'Apellidos y Nombres':'ESTUDIANTE',\n        'Nivel':'SEMESTRE',\n        'Total':'TOTAL_INASISTENCIA',\n        'Programa':'CURSO',\n        'Per\u00edodo':'PERIODO_ACADEMICO'\n    }\n\n    eliminar = [\n                ]\n\n    df = limpiar_columnas(df, eliminar, renombres,True)\n\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Consolidado_inasistencias = obtener_sharepoint_emp_Consolidado_inasistenciass()\n    df_emp_Consolidado_inasistencias = procesar_inasistencias(df_emp_Consolidado_inasistencias)\n    actualizar_sharepoint_procesado(df_emp_Consolidado_inasistencias, 'emp_Consolidado_inasistencias')\n\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/","title":"0.1. Docentes Desarrollo Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se ignoran advertencias espec\u00edficas para evitar distracciones innecesarias durante la ejecuci\u00f3n del script. Si hay otros loggers configurados, tambi\u00e9n se ajusta su nivel de detalle a <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport logging\nimport time\nimport os\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, _descargar, close_driver, hacer_clic, procesar,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/#automatizacion-de-descarga-y-procesamiento-del-reporte-docentes","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Docentes\"","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Docentes\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>DOWNLOAD_DIR</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_des_empresarial</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Docentes\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Este enfoque modular y estructurado facilita la depuraci\u00f3n, escalabilidad y mantenimiento del flujo automatizado.</p> <pre><code>@log_step_decorator(\"Docentes desarrollo empresarial\")\ndef main():\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Docentes\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"clic_docentes\",log_step_decorator(\"clic_docentes\")(hacer_clic), {'driver': driver, 'xpath': \n                '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[1]/div[1]/a',\n                'wait_time': 5}),\n            (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n            (\"descargar_archivo\", log_step_decorator(\"descargar_archivo\")(_descargar), {'driver': driver, 'xpath': \n                '//*[@id=\"generar-reporte-btn\"]','download_dir': DOWNLOAD_DIR,\n                'archivo':  f\"Desarrollo_Docentes_{time.strftime('%Y_%m_%d')}\", 'wait_time': 10}),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', 'wait_time': 5}),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', 'wait_time': 5}),\n        ]\n\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        procesar('emp_Docentes', DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/","title":"0.2. Preinscritos","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>time</code>, <code>sys</code>, <code>json</code>, <code>warnings</code> y <code>datetime</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos, <code>close_driver</code> para cerrar el navegador de forma segura, <code>generar_fechas</code> para generar rangos de fechas, <code>configurar_pasos_autenticacion_des_empresarial</code> para configurar los pasos de autenticaci\u00f3n y <code>eliminar_archivos_anteriores</code> para limpiar archivos previos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con la ejecuci\u00f3n del script. Tambi\u00e9n se ajustan los niveles de detalle de otros loggers configurados en el entorno para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging, os, time, sys\nfrom datetime import datetime\nimport json\nfrom dateutil.relativedelta import relativedelta\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic,generar_fechas,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/#automatizacion-de-descarga-y-procesamiento-del-reporte-preinscritos","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Preinscritos\"","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Preinscritos\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>DOWNLOAD_DIR</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_des_empresarial</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Preinscritos\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>def guardar_json(diccionario, nombre_archivo):\n    with open(nombre_archivo, 'w') as archivo:\n        json.dump(diccionario, archivo)\n\n@log_step_decorator(\"Preinscritos\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Preinscritos\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        _eleccion = 1\n        _desde = fechas[_eleccion][\"desde\"]\n        _hasta = fechas[_eleccion][\"hasta\"]\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"clic_preinscritos\", log_step_decorator(\"clic_preinscritos\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[2]/div/a', \n                'wait_time': 5\n            }),\n            (\"abrir_fecha\", log_step_decorator(\"abrir_fecha\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '//*[@id=\"rangoFechas\"]/a/div[1]', \n                'wait_time': 3\n            }),\n            (\"seleccionar_rango_personalizado\", log_step_decorator(\"seleccionar_rango_personalizado\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/ul/li[7]', \n                'wait_time': 3\n            }),\n            (\"ingresar_fecha_inicial\", log_step_decorator(\"ingresar_fecha_inicial\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', \n                'value': _desde, \n                'wait_time': 3\n            }),\n            (\"ingresar_fecha_final\", log_step_decorator(\"ingresar_fecha_final\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', \n                'value': _hasta,  \n                'wait_time': 3\n            }),\n            (\"aceptar_fechas\", log_step_decorator(\"aceptar_fechas\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/div/button[1]', \n                'wait_time': 3\n            }),\n            (\"generar_reporte\", log_step_decorator(\"generar_reporte\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '//*[@id=\"generar-reporte-btn\"]', \n                'wait_time': 10\n            }),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', \n                'wait_time': 5\n            }),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', \n                'wait_time': 5\n            })\n        ]\n\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)  # Aqu\u00ed no se pasa `driver` directamente, solo los par\u00e1metros en `params`\n        procesar(\"emp_Preinscritos\",DOWNLOAD_DIR)\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/","title":"0.3. Listado Matr\u00edculas Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>random</code>, <code>logging</code>, <code>os</code>, <code>sys</code> y <code>time</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se importan y configuran advertencias para ignorar aquellas espec\u00edficas que no son relevantes para el proceso actual. Esto asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport argparse, random\nimport logging, os, sys, time\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n#importaa json\nimport json\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic, configurar_pasos_autenticacion_des_empresarial, \n    procesar_reporte_modal, generar_periodos,generar_fechas, generar_periodos_cortes\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/#automatizacion-de-descarga-de-listados-de-matriculas-empresarial","title":"Automatizaci\u00f3n de Descarga de Listados de Matr\u00edculas Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas empresariales desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Listado_matriculas_emp\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los rangos de fechas personalizados. Cada iteraci\u00f3n del bucle configura un rango de fechas en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar fechas y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Listado de matr\u00edculas empresarial\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        subcarpeta_descarga = \"Listado_matriculas_emp\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Listado_matriculas_emp'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n        # Pasar driver al configurar pasos de autenticaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n            }),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5\n            }),\n            (\"listado\", log_step_decorator(\"listado\")(hacer_clic), {\n                'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[4]/div[2]/a', 'wait_time': 5\n            }),\n        ]\n\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n\n\n        for fecha in fechas:\n            logging.info(f\"Fecha: {fecha}\")\n            _hash = f\"{random.randint(1000, 9999)}\"\n            nombre_archivo_completo = f'{nombre_archivo}_{_hash}.xlsx'\n\n            step_2 = [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[9]/div[3]/ul/li[7]', 'wait_time': 3}),\n                (\"entrar_en_fecha1\",log_step_decorator(\"entrar_en_fecha1\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[1]/input','value': fechas[fecha]['desde'],'driver': driver,'wait_time': 3}),\n                (\"entrar_en_fecha2\",log_step_decorator(\"entrar_en_fecha2\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', 'value': fechas[fecha]['hasta'],'driver': driver,'wait_time': 3}),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 3}),\n                (\"descargar\", log_step_decorator(\"descargar\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"generar-reporte-btn\"]', 'wait_time': 60}),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo})]\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                time.sleep(5)\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n        procesar(\"emp_Listado_Matriculas\",download_dir)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_periodos_cortes(anio_inicio=_inicio, anio_fin=_fin, tipo=4)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/","title":"0.4. Consolidado Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>warnings</code>, <code>pandas</code> y <code>selenium.webdriver.common.by.By</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>ejecutar_pasos</code> para ejecutar una serie de acciones de forma secuencial.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging\nimport time\nimport os\nimport sys\nimport pandas as pd\nfrom selenium.webdriver.common.by import By\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar_reporte_modal, obtener_elementos_dropdown, \n    hacer_clic, elemento_disponible, seleccionar_opcion_con_js, procesar, guardar_diccionario,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores,ejecutar_pasos\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/#automatizacion-de-descarga-de-consolidado-de-inasistencias","title":"Automatizaci\u00f3n de Descarga de Consolidado de Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de consolidado de inasistencias desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar periodos, jornadas, programas, m\u00f3dulos y cursos, y descargar los reportes correspondientes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Consolidado_inasistencias\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el consolidado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja la selecci\u00f3n de periodos, jornadas, programas, m\u00f3dulos y cursos. Cada iteraci\u00f3n del bucle configura estos par\u00e1metros en la interfaz de la web, genera el reporte y procesa los datos descargados. Adem\u00e1s, el script incluye la eliminaci\u00f3n de archivos anteriores en la carpeta de descargas antes de procesar nuevos.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>driver.quit()</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Consolidado_inasistencias\")\ndef main(consulta):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Consolidado_inasistencias\"\n        generar = False\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"consolidado\",log_step_decorator(\"consolidado\")(hacer_clic), {'driver': driver, 'xpath': \n                '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[1]/div[2]/a',\n                'wait_time': 5}),\n        ]\n\n        ejecutar_pasos(step_1)\n        # time.sleep(100)   \n\n\n        _xpath_periodo  = '//*[@id=\"form0\"]/div[1]/div[3]'\n        periodo_boton = f'{_xpath_periodo}/div/button'\n        periodo_list = f'{_xpath_periodo}/div/div/ul'\n        nivel = 1\n\n        # Obtener los periodos disponibles en el dropdown\n        _periodos = obtener_elementos_dropdown(driver, periodo_boton, periodo_list, nivel)\n\n        periodos_generados = [f\"{year}\" for year in consulta]\n        #elimina repetidos de periodos_generados        \n        periodos_generados = list(set(periodos_generados))\n        # Filtrar solo los per\u00edodos que comiencen con los valores generados\n        periodos = [\n            periodo for periodo in _periodos \n            if any(generado in periodo for generado in periodos_generados)\n        ]\n        # Guardar los per\u00edodos seleccionados en un archivo para referencia\n        guardar_diccionario(periodos, 'periodos')\n\n        # Eliminar archivos anteriores en la carpeta de descargas antes de procesar nuevos\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        # Procesar cada periodo seleccionado\n\n        if periodos:\n\n            for periodo in periodos:\n                # Seleccionar el periodo\n                hacer_clic(driver= driver, xpath=periodo_boton, wait_time= 1)\n                # seleccionar_opcion_custom_dropdown(driver=driver, xpath=periodo_boton, option=periodo, wait_time=1)\n                seleccionar_opcion_con_js(driver, periodo_boton, periodo)\n                logging.info(f\"Procesando periodo: {periodo}\")\n\n                # Obtener jornadas para el periodo seleccionado\n                xpath_jornada = '//*[@id=\"form0\"]/div[2]/div[3]'\n                jornada_boton = f'{xpath_jornada}/div/button'\n                jornada_list = f'{xpath_jornada}/div/div/ul'\n                jornadas = obtener_elementos_dropdown(driver, jornada_boton, jornada_list, nivel=2)\n                excluir_jornadas = {'Seleccione'}\n                jornadas = [jornada for jornada in jornadas if jornada not in excluir_jornadas]\n                jornadas = {'Programa'}\n                if jornadas:                    \n\n                    for jornada in jornadas:\n                        hacer_clic(driver= driver, xpath=jornada_boton, wait_time= 1)\n                        # Seleccionar la jornada\n                        seleccionar_opcion_con_js(driver, jornada_boton, jornada)\n                        time.sleep(4)\n                        logging.info(f\"Procesando jornada: {jornada}\")\n\n                        # Obtener programas para la jornada seleccionada\n                        if jornada == 'Curso':\n                            xpath_programa = '//*[@id=\"form0\"]/div[6]/div[3]'\n                        else:\n                            xpath_programa = '//*[@id=\"form0\"]/div[3]/div[3]' \n                        programa_boton = f'{xpath_programa}/div/button'\n                        programa_list = f'{xpath_programa}/div/div/ul'\n                        programas = obtener_elementos_dropdown(driver, programa_boton, programa_list, nivel=3)\n                        excluir_opciones = {'Seleccione'}\n                        programas = [programa for programa in programas if programa not in excluir_opciones]\n                        if programas:\n\n                            for programa in programas:\n                                hacer_clic(driver= driver, xpath=programa_boton, wait_time= 1)\n                                # Seleccionar el programa\n                                seleccionar_opcion_con_js(driver, programa_boton, programa)\n                                logging.info(f\"Procesando programa: {programa}\")\n                                # Obtener modulo para el programa seleccionado\n                                if jornada == 'Curso':\n                                    xpath_modulo = '//*[@id=\"form0\"]/div[7]/div[3]' \n                                else:\n                                    xpath_modulo = '//*[@id=\"form0\"]/div[4]/div[3]'\n                                modulo_boton = f'{xpath_modulo}/div/button'\n                                modulo_list = f'{xpath_modulo}/div/div/ul'\n                                modulos = obtener_elementos_dropdown(driver, modulo_boton, modulo_list, nivel=4)\n                                excluir_modulos = {'Seleccione'}\n                                modulo = [modulo for modulo in modulos if modulo not in excluir_modulos]\n                                if modulos:\n                                    for modulo in modulos:\n                                        hacer_clic(driver= driver, xpath=modulo_boton, wait_time= 1)\n                                        seleccionar_opcion_con_js(driver, modulo_boton, modulo)\n                                        logging.info(f\"Procesando modulo: {modulo}\")\n                                        # obtener modulo\n                                        if jornada == 'Curso':\n                                            xpath_modulo = '//*[@id=\"form0\"]/div[8]/div[3]'\n                                        else:\n                                            xpath_curso = '//*[@id=\"form0\"]/div[5]/div[3]'\n                                        cursos_boton = f'{xpath_curso}/div/button'\n                                        cursos_list = f'{xpath_curso}/div/div/ul'\n                                        cursos = obtener_elementos_dropdown(driver, cursos_boton, cursos_list, nivel=5)\n                                        excluir_cursos = {'Seleccione'}\n                                        curso = [curso for curso in cursos if curso not in excluir_cursos]\n                                        if cursos:\n                                            for curso in cursos:\n\n                                                seleccionar_opcion_con_js(driver, cursos_boton, curso)\n                                                hacer_clic(driver= driver, xpath=\n                                                    '//*[@id=\"generar-reporte-btn\"]'\n                                                    , wait_time=5)\n                                                #define la variable archivo uniendo periodo, jornada, programa y modulo\n                                                archivo = f'Cede_{periodo}_{jornada}_{programa}_{modulo}_{curso}.xlsx'\n                                                modal = elemento_disponible(driver, By.ID, \"master-modal\", timeout=10)\n                                                if modal:\n                                                    procesar_reporte_modal(driver, DOWNLOAD_DIR, archivo)\n                                                    time.sleep(5)\n                                else: continue\n                        else: continue\n                else: continue\n\n\n            procesar('emp_Consolidado_inasistencias',DOWNLOAD_DIR)\n            logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\n        #Eliminar esta linea en produccion \n        # procesar('emp_Consolidado_inasistencias',DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            # Cerrar el navegador\n            driver.quit()\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    # Generar lista de periodos de consulta (2019, 2020)\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    consulta = {_inicio, _fin}\n    main(consulta)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/","title":"0.5. Estudiantes Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>warnings</code> y <code>pandas</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, <code>procesar_reporte_modal</code>, <code>hacer_clic</code>, <code>obtener_elementos_dropdown</code>, <code>seleccionar_opcion_con_js</code>, <code>guardar_diccionario</code>, <code>configurar_pasos_autenticacion_des_empresarial</code>, <code>eliminar_archivos_anteriores</code> y <code>ejecutar_pasos</code>. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging\nimport time\nimport os\nimport sys\nimport pandas as pd\n\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar_reporte_modal, obtener_elementos_dropdown, \n    hacer_clic, procesar, seleccionar_opcion_con_js, guardar_diccionario,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores,ejecutar_pasos\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/#automatizacion-de-descarga-de-consolidado-de-inasistencias","title":"Automatizaci\u00f3n de Descarga de Consolidado de Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de consolidado de inasistencias desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar periodos y descargar los reportes correspondientes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Estudiantes_inasistencias\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el consolidado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja la selecci\u00f3n de periodos. Cada iteraci\u00f3n del bucle configura estos par\u00e1metros en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar opciones en dropdowns y descargar el archivo, est\u00e1n definidos en el c\u00f3digo. Adem\u00e1s, el script incluye la eliminaci\u00f3n de archivos anteriores en la carpeta de descargas antes de procesar nuevos.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>driver.quit()</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos periodos con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <p>El script utiliza un sistema de logging bien estructurado para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code>@log_step_decorator(\"Estudiantes inasistencias\")\ndef main(consulta):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Estudiantes_inasistencias\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 20}),\n            (\"Estudiantes_inasistencias\",log_step_decorator(\"Estudiantes_inasistencias\")(hacer_clic), {'driver': driver, 'xpath':\n                '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[2]/div[2]/a',\n                'wait_time': 5}),\n            # (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', 'wait_time': 5}),\n            # (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', 'wait_time': 5}),\n        ]\n\n        ejecutar_pasos(step_1)\n\n\n        _xpath_periodo  = '//*[@id=\"formReportes\"]/div/div[3]'\n        periodo_boton = f'{_xpath_periodo}/div/button'\n        periodo_list = f'{_xpath_periodo}/div/div/ul'        \n        nivel=1\n        # Obtener los periodos disponibles en el dropdown\n        _periodos = obtener_elementos_dropdown(driver, periodo_boton, periodo_list, nivel)        \n        periodos_generados = [f\"{year}\" for year in consulta]\n        #elimina repetidos de periodos_generados        \n        periodos_generados = list(set(periodos_generados))\n        # Filtrar solo los per\u00edodos que comiencen con los valores generados\n        periodos = [\n            periodo for periodo in _periodos \n            if any(generado in periodo for generado in periodos_generados)\n        ]\n        # Guardar los per\u00edodos seleccionados en un archivo para referencia\n        guardar_diccionario(periodos, 'periodos')\n\n        # Eliminar archivos anteriores en la carpeta de descargas antes de procesar nuevos\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        if periodos:\n            for periodo in periodos:\n                # Seleccionar el periodo\n                hacer_clic(driver= driver, xpath=periodo_boton, wait_time= 1)\n                seleccionar_opcion_con_js(driver, periodo_boton, periodo)\n                logging.info(f\"Procesando periodo: {periodo}\")\n                hacer_clic(driver= driver, xpath= '//*[@id=\"generar-reporte-btn\"]', wait_time=5)\n                #define la variable archivo uniendo periodo, jornada, programa y modulo\n                archivo = f'Cede_{periodo}.xlsx'\n                procesar_reporte_modal(driver, DOWNLOAD_DIR, archivo)\n                time.sleep(5)\n            logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\n\n\n    finally:\n        if driver:\n            driver.quit\n        logging.info(\"Fin del proceso principal\")\n        procesar('emp_Estudiantes_inasistencias', DOWNLOAD_DIR)\n\n\nif __name__ == \"__main__\":\n    # Generar lista de periodos de consulta (2019, 2020)\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    consulta = {_inicio, _fin}\n    main(consulta)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/","title":"0.6. Egresados Graduados Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code> y <code>warnings</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, <code>hacer_clic</code>, <code>configurar_pasos_autenticacion_des_empresarial</code>, <code>eliminar_archivos_anteriores</code>, <code>pre_procesamiento</code> y <code>obtener_elementos_dropdown</code>. Tambi\u00e9n se incluye <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging\nimport time\nimport os\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic,generar_periodos,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores,pre_procesamiento,obtener_elementos_dropdown\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/#automatizacion-de-descarga-de-consolidado-de-graduados","title":"Automatizaci\u00f3n de Descarga de Consolidado de Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de consolidado de graduados desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un conjunto de pasos para configurar opciones y descargar los reportes correspondientes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Graduados\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el consolidado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>El script maneja la selecci\u00f3n de opciones espec\u00edficas para el tipo de graduado y el periodo. Cada paso configura estos par\u00e1metros en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar opciones en dropdowns y descargar el archivo, est\u00e1n definidos en el c\u00f3digo. Adem\u00e1s, el script incluye la eliminaci\u00f3n de archivos anteriores en la carpeta de descargas antes de procesar nuevos.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>pre_procesamiento</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Graduados\")\ndef main(periodo):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Graduados\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Graduados'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"clic_egresados\", log_step_decorator(\"clic_egresados\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[1]/div[2]/a', \n                'wait_time': 5\n            }),\n            (\"seleccionar_tipo_graduado\", log_step_decorator(\"seleccionar_tipo_graduado\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[1]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"seleccionperiodos\", log_step_decorator(\"seleccionperiodos\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[2]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"pre_procesamiento\", log_step_decorator(\"pre_procesamiento\")(pre_procesamiento), {\n                'driver': driver,\n                'download_dir': DOWNLOAD_DIR,\n                'id_descargar': 'generar-reporte-btn',\n                'nombre_archivo': nombre_archivo,\n                'nombre_archivo_completo': nombre_archivo_completo,\n                'xpath_boton': '//*[@id=\"form0\"]/div[4]/div[3]/div/button',\n                'tipo':'normal',\n                'xpath_contenedor_opciones':  '//*[@id=\"form0\"]/div[4]/div[3]/div/div/ul',\n                'excluir_opciones': periodos\n            }),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', \n                'wait_time': 5\n            }),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', \n                'wait_time': 5\n            })\n        ]\n\n        # Ejecutar cada uno de los pasos definidos en el diccionario \n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        procesar('emp_Egresados_Graduados', DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    periodos = generar_periodos(_inicio, _fin)\n    main(periodos)\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/","title":"3.1. Webscraping Actualizable","text":""},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code> y <code>dateutil.relativedelta</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_logger</code>, para configurar el sistema de logging, <code>log_tiempo</code>, para registrar el tiempo de ejecuci\u00f3n, y <code>download_file_between_dates</code>, para manejar la descarga de archivos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se ignoran advertencias espec\u00edficas para evitar distracciones innecesarias durante la ejecuci\u00f3n del script. Si hay otros loggers configurados, tambi\u00e9n se ajusta su nivel de detalle a <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <ol> <li>Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping: Configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</li> <li>Importaci\u00f3n de Librer\u00edas: Importa las librer\u00edas necesarias como <code>selenium</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code>, y <code>dateutil.relativedelta</code>. Tambi\u00e9n se agrega la ruta de la carpeta <code>Funciones</code> al <code>sys.path</code> y se importan funciones espec\u00edficas.</li> <li>Definici\u00f3n de Selectores XPath: Define un diccionario <code>_dict</code> que contiene los selectores XPath necesarios para interactuar con los elementos de la p\u00e1gina web.</li> <li>Inicio del Proceso ETL: Registra el tiempo de inicio y configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n y Formateo de Fechas: Calcula el primer y \u00faltimo d\u00eda del mes anterior y los formatea en el formato 'dd/MM/yyyy'.</li> <li>Automatizaci\u00f3n de la Descarga de Archivos: Utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. Se inicializa el WebDriver, se abre la URL, y se llama a la funci\u00f3n <code>download_file_between_dates()</code> para realizar la descarga.</li> <li>Registro de Informaci\u00f3n y C\u00e1lculo del Tiempo: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga y calcula el tiempo total del proceso ETL.</li> </ol> <pre><code>## Import libraries\nfrom selenium import webdriver                                          ### selenium version 4.25.0\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n#from time import datetime\nimport time\nimport datetime\nimport os\nimport logging\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../\")) \n\nfrom Utils.Funciones import (\n    setup_logger,log_tiempo,download_file_between_dates\n)\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/#diccionario-de-pasos","title":"Diccionario de pasos","text":"<pre><code>_dict = {\n    \"Ticket_button\" : '//*[@id=\"__button12-img\"]',\n    \"Filter_button\" : '//*[@id=\"findformpaneLkIKPWD61a2ejhlWKfn3Bm_151-img\"]',\n    \"Dates\" : '//*[@id=\"__button51-inner\"]',\n    \"Menu\" :'//*[@id=\"__box4-arrow\"]',\n    \"Entre\" : '//*[@id=\"__item154-content\"]/div/div',\n    \"initial_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_532-datePicker-inner',\n    \"final_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_534-datePicker-inner',\n    \"Aceptar\" : '//*[@id=\"__button77-BDI-content\"]',\n    \"Categoria\" : '//*[@id=\"objectvalueselectorPbJLA_soJqak9j9Ey7mLqvW_346-inputField-vhi\"]',\n    \"Educacion\" : '//*[@id=\"statictextm9D_2UNbhq6mK7P6aHrdQ0_559-listdefintion_O68bB2vS4gwMYerXwebjm_556-9\"]',\n    \"Go_button\" : '//*[@id=\"findformpaneGLsDRJxMiqEpkW0gKJRoAW_152-goButton-BDI-content\"]',\n    \"Plus_botton\" : '//*[@id=\"actionbuttonmenuCTxPLT0i_qoT0xcR7Kdqnm_131-button-BDI-content\"]',\n    \"Export_button\" : '//*[@id=\"navigationitemQQFWfu3deac0r5R10TiQ10_144-BDI-content\"]',\n    \"Download_button\" : '//*[@id=\"__button97-content\"]' \n}\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/#etl","title":"ETL","text":"<ol> <li>Inicio del Proceso ETL: Registra el tiempo de inicio.</li> <li>Configuraci\u00f3n del Logger: Configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n de Fechas: Calcula el primer y \u00faltimo d\u00eda del mes anterior.</li> <li>Formateo de Fechas: Formatea las fechas calculadas en el formato 'dd/MM/yyyy'.</li> <li>Registro de Fechas: (Comentado) Registra las fechas calculadas.</li> </ol> <p>El c\u00f3digo configura un proceso ETL, calcula fechas relevantes y utiliza un logger para monitorear el proceso.</p> <pre><code>inicio_etl = time.time()\n#---------------------------------------------\nlogger = setup_logger(log_filename='scraper.log', log_level=logging.INFO)  # Cambiado a logging.INFO\nlogger.info('COMIENZO ETL')\n\n\n# Obtener la fecha actual\ncurrent_date = datetime.now()\n\n# Calcular el primer d\u00eda del mes anterior\nfirst_day_previous_month = (current_date.replace(day=1) - relativedelta(months=1)).replace(day=1)\n\n# Calcular el \u00faltimo d\u00eda del mes anterior\nlast_day_previous_month = current_date.replace(day=1) - relativedelta(days=1)\n\n# Formatear las fechas como texto en formato 'dd/MM/yyyy'\nstart_date = first_day_previous_month.strftime('%m/%d/%Y')\nend_date = last_day_previous_month.strftime('%m/%d/%Y')\n\n# Imprimir las fechas\n#logger.info(\"Primer d\u00eda del mes anterior:\", start_date)\n#logger.info(\"\u00daltimo d\u00eda del mes anterior:\", end_date)\n</code></pre> <pre><code>#Fecha_inicial\n#initial_date = '07/01/2017'\n#Fecha_final\n#final_date = '10/01/2017'\n</code></pre> <pre><code>#time.sleep(4)\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. A continuaci\u00f3n, se explica cada parte del c\u00f3digo en detalle:</p> <p>Primero, se define la ruta al ejecutable de ChromeDriver y se establece en la variable de entorno <code>webdriver.chrome.driver</code>. Esto es necesario para que Selenium pueda controlar el navegador Chrome. Luego, se inicializan las variables <code>initial_date</code> y <code>final_date</code> con los valores de <code>start_date</code> y <code>end_date</code>, respectivamente.</p> <p>Se crea una instancia de <code>webdriver.Chrome()</code> para iniciar una sesi\u00f3n de navegador Chrome. No es necesario proporcionar el argumento <code>executable_path</code> ya que la ruta se ha configurado previamente en las variables de entorno. A continuaci\u00f3n, se maximiza la ventana del navegador utilizando el m\u00e9todo <code>maximize_window()</code>.</p> <p>El navegador se dirige a la URL especificada mediante el m\u00e9todo <code>get()</code>. Esta URL parece ser una p\u00e1gina de inicio de sesi\u00f3n de un sistema CRM basado en SAP. Se registra un mensaje informativo indicando el rango de fechas para la descarga utilizando el m\u00e9todo <code>info()</code> del logger.</p> <p>La funci\u00f3n <code>download_file_between_dates()</code> se llama con las fechas inicial y final, as\u00ed como el controlador del navegador. Esta funci\u00f3n se encarga de conectar al sistema C4C, iterar sobre las opciones en un diccionario <code>_dict</code>, y realizar las acciones necesarias para configurar las fechas y descargar el archivo. Se incluye un tiempo de espera para asegurar que la descarga se complete antes de cerrar el navegador.</p> <p>Finalmente, se registra un mensaje informativo indicando que la descarga se ha completado y se cierra la sesi\u00f3n del navegador con <code>driver.quit()</code>. Este script automatiza el proceso de descarga de archivos, lo que puede ser \u00fatil para tareas repetitivas y ahorrar tiempo en la gesti\u00f3n de datos.</p> <pre><code># Replace with the actual path to your ChromeDriver executable\nCHROME_DRIVER_PATH = \"C:\\\\Program Files (x86)\\\\chromedriver.exe\"\nos.environ[\"webdriver.chrome.driver\"] = CHROME_DRIVER_PATH\n\n##Descargar Educacion\ninitial_date = start_date\nfinal_date = end_date\ndriver = webdriver.Chrome()  # No need for executable_path argument\n# Maximizar la ventana del navegador \ndriver.maximize_window()\ndriver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\nlogger.info(f\"Descargando archivo entre {initial_date} y {final_date}\")\ndownload_file_between_dates(initial_date, final_date, driver, _dict)\nlogger.info(f\"Descarga completa entre {initial_date} y {final_date}\")\n\nlogger.info(\"Descargas completadas.\")\n</code></pre> <pre><code>#Descargar Proteccion\n_dict = {\n    \"Ticket_button\" : '//*[@id=\"__button12-img\"]',\n    \"Filter_button\" : '//*[@id=\"findformpaneLkIKPWD61a2ejhlWKfn3Bm_151-img\"]',\n    \"Dates\" : '//*[@id=\"__button51-inner\"]',\n    \"Menu\" :'//*[@id=\"__box4-arrow\"]',\n    \"Entre\" : '//*[@id=\"__item154-content\"]/div/div',\n    \"initial_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_532-datePicker-inner',\n    \"final_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_534-datePicker-inner',\n    \"Aceptar\" : '//*[@id=\"__button77-BDI-content\"]',\n    \"Categoria\" : '//*[@id=\"objectvalueselectorPbJLA_soJqak9j9Ey7mLqvW_346-inputField-vhi\"]',\n    \"Proteccion\" : '//*[@id=\"statictextm9D_2UNbhq6mK7P6aHrdQ0_559-listdefintion_O68bB2vS4gwMYerXwebjm_556-11\"]',\n    \"Go_button\" : '//*[@id=\"findformpaneGLsDRJxMiqEpkW0gKJRoAW_152-goButton-BDI-content\"]',\n    \"Plus_botton\" : '//*[@id=\"actionbuttonmenuCTxPLT0i_qoT0xcR7Kdqnm_131-button-BDI-content\"]',\n    \"Export_button\" : '//*[@id=\"navigationitemQQFWfu3deac0r5R10TiQ10_144-BDI-content\"]',\n    \"Download_button\" : '//*[@id=\"__button97-content\"]' \n}\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde una p\u00e1gina web. Aqu\u00ed est\u00e1 el resumen:</p> <ol> <li>Inicializaci\u00f3n de Fechas: Asigna las fechas de inicio y fin para la descarga.</li> <li>Inicializaci\u00f3n del WebDriver: Inicia el WebDriver de Chrome y maximiza la ventana del navegador.</li> <li>Carga de la URL: Abre la p\u00e1gina web desde la cual se descargar\u00e1 el archivo.</li> <li>Registro de Informaci\u00f3n: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga.</li> <li>Descarga del Archivo: Llama a una funci\u00f3n para descargar el archivo entre las fechas especificadas.</li> <li>C\u00e1lculo del Tiempo: Calcula y registra el tiempo total del proceso ETL.</li> </ol> <pre><code>initial_date = start_date\nfinal_date = end_date\n#driver = webdriver.Chrome()  # Inicializar el WebDriver\ndriver = webdriver.Chrome()  # No need for executable_path argument\n# Maximizar la ventana del navegador \ndriver.maximize_window()\ndriver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\nlogger.info(f\"Descargando archivo entre {initial_date} y {final_date}\")\ndownload_file_between_dates(initial_date, final_date, driver, _dict)\nlogger.info(f\"Descarga completa entre {initial_date} y {final_date}\")\n\n\n\ntiempo_total = time.time() - inicio_etl\nlog_tiempo(logger, f'FINAL ETL --- ', tiempo_total)\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/02.C4C_webscraping_v4_Historico/","title":"3.2. Webscraping Hist\u00f3rico","text":""},{"location":"00.etl/00.etl_02.C4C/02.C4C_webscraping_v4_Historico/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code> y <code>dateutil.relativedelta</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_logger</code>, para configurar el sistema de logging, <code>log_tiempo</code>, para registrar el tiempo de ejecuci\u00f3n, y <code>download_file_between_dates</code>, para manejar la descarga de archivos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se ignoran advertencias espec\u00edficas para evitar distracciones innecesarias durante la ejecuci\u00f3n del script. Si hay otros loggers configurados, tambi\u00e9n se ajusta su nivel de detalle a <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <ol> <li>Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping: Configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</li> <li>Importaci\u00f3n de Librer\u00edas: Importa las librer\u00edas necesarias como <code>selenium</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code>, y <code>dateutil.relativedelta</code>. Tambi\u00e9n se agrega la ruta de la carpeta <code>Funciones</code> al <code>sys.path</code> y se importan funciones espec\u00edficas.</li> <li>Definici\u00f3n de Selectores XPath: Define un diccionario <code>_dict</code> que contiene los selectores XPath necesarios para interactuar con los elementos de la p\u00e1gina web.</li> <li>Inicio del Proceso ETL: Registra el tiempo de inicio y configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n y Formateo de Fechas: Calcula la lista de fechas cada tres meses desde el 06/01/2017 hasta el 06/01/2024 y las formatea en el formato 'mm/dd/yyyy'.</li> <li>Automatizaci\u00f3n de la Descarga de Archivos: Utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. Se inicializa el WebDriver, se abre la URL, y se llama a la funci\u00f3n <code>download_file_between_dates()</code> para realizar la descarga.</li> <li>Registro de Informaci\u00f3n y C\u00e1lculo del Tiempo: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga y calcula el tiempo total del proceso ETL.</li> </ol> <pre><code>## Import libraries\nfrom selenium import webdriver                                          ### selenium version 4.25.0\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\n#from time import datetime\nimport time\nimport datetime\nimport os\nimport logging\nfrom datetime import datetime, timedelta\nfrom dateutil.relativedelta import relativedelta\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../\")) \n\nfrom Utils.Funciones import (\n    setup_logger,log_tiempo,download_file_between_dates\n)\n</code></pre> <pre><code>_dict = {\n    \"Ticket_button\" : '//*[@id=\"__button12-img\"]',\n    \"Filter_button\" : '//*[@id=\"findformpaneLkIKPWD61a2ejhlWKfn3Bm_151-img\"]',\n    \"Dates\" : '//*[@id=\"__button51-inner\"]',\n    \"Menu\" :'//*[@id=\"__box4-arrow\"]',\n    \"Entre\" : '//*[@id=\"__item154-content\"]/div/div',\n    \"initial_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_532-datePicker-inner',\n    \"final_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_534-datePicker-inner',\n    \"Aceptar\" : '//*[@id=\"__button77-BDI-content\"]',\n    \"Categoria\" : '//*[@id=\"objectvalueselectorPbJLA_soJqak9j9Ey7mLqvW_346-inputField-vhi\"]',\n    \"Educacion\" : '//*[@id=\"statictextm9D_2UNbhq6mK7P6aHrdQ0_559-listdefintion_O68bB2vS4gwMYerXwebjm_556-9\"]',\n    \"Go_button\" : '//*[@id=\"findformpaneGLsDRJxMiqEpkW0gKJRoAW_152-goButton-BDI-content\"]',\n    \"Plus_botton\" : '//*[@id=\"actionbuttonmenuCTxPLT0i_qoT0xcR7Kdqnm_131-button-BDI-content\"]',\n    \"Export_button\" : '//*[@id=\"navigationitemQQFWfu3deac0r5R10TiQ10_144-BDI-content\"]',\n    \"Download_button\" : '//*[@id=\"__button97-content\"]' \n}\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/02.C4C_webscraping_v4_Historico/#etl","title":"ETL","text":"<ol> <li>Inicio del Proceso ETL: Registra el tiempo de inicio.</li> <li>Configuraci\u00f3n del Logger: Configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n de Fechas: Calcula la lista de fechas cada tres meses desde el 06/01/2017 hasta el 06/01/2024.</li> <li>Formateo de Fechas: Formatea las fechas calculadas en el formato 'mm/dd/yyyy'.</li> <li>Registro de Fechas: (Comentado) Registra las fechas calculadas.</li> </ol> <p>El c\u00f3digo configura un proceso ETL, calcula fechas relevantes y utiliza un logger para monitorear el proceso.</p> <pre><code>inicio_etl = time.time()\n#---------------------------------------------\nlogger = setup_logger(log_filename='scraper.log', log_level=logging.INFO)  # Cambiado a logging.INFO\nlogger.info('COMIENZO ETL')\n\n\n# Fecha de inicio y fecha de fin\nstart_date = datetime.strptime('06/01/2017', '%m/%d/%Y')\nend_date = datetime.strptime('06/01/2024', '%m/%d/%Y')\n\n# Generar la lista de fechas cada tres meses\ndate_list = []\ncurrent_date = start_date\nwhile current_date &lt;= end_date:\n    date_list.append(current_date.strftime('%m/%d/%Y'))\n    current_date += relativedelta(months=3)\n\n# Imprimir la lista de fechas\n#for date in date_list:\n    #print(date)\n#date_list\n</code></pre> <pre><code>#Fecha_inicial\n#initial_date = '07/01/2017'\n#Fecha_final\n#final_date = '10/01/2017'\n</code></pre> <pre><code>#time.sleep(4)\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. A continuaci\u00f3n, se explica cada parte del c\u00f3digo en detalle:</p> <p>Primero, se define la ruta al ejecutable de ChromeDriver y se establece en la variable de entorno <code>webdriver.chrome.driver</code>. Esto es necesario para que Selenium pueda controlar el navegador Chrome. Luego, se itera sobre los pares de fechas consecutivas generadas previamente en <code>date_list</code>.</p> <p>Se crea una instancia de <code>webdriver.Chrome()</code> para iniciar una sesi\u00f3n de navegador Chrome. No es necesario proporcionar el argumento <code>executable_path</code> ya que la ruta se ha configurado previamente en las variables de entorno. A continuaci\u00f3n, se maximiza la ventana del navegador utilizando el m\u00e9todo <code>maximize_window()</code>.</p> <p>El navegador se dirige a la URL especificada mediante el m\u00e9todo <code>get()</code>. Esta URL parece ser una p\u00e1gina de inicio de sesi\u00f3n de un sistema CRM basado en SAP. Se imprime un mensaje indicando el rango de fechas para la descarga.</p> <p>La funci\u00f3n <code>download_file_between_dates()</code> se llama con las fechas inicial y final, as\u00ed como el controlador del navegador. Esta funci\u00f3n se encarga de conectar al sistema C4C, iterar sobre las opciones en un diccionario <code>_dict</code>, y realizar las acciones necesarias para configurar las fechas y descargar el archivo.</p> <p>Finalmente, se imprime un mensaje indicando que la descarga se ha completado. Este script automatiza el proceso de descarga de archivos, lo que puede ser \u00fatil para tareas repetitivas y ahorrar tiempo en la gesti\u00f3n de datos.</p> <pre><code># Replace with the actual path to your ChromeDriver executable\nCHROME_DRIVER_PATH = \"C:\\\\Program Files (x86)\\\\chromedriver.exe\"\nos.environ[\"webdriver.chrome.driver\"] = CHROME_DRIVER_PATH\n\n# Iterar sobre los pares de fechas consecutivas y ejecutar la funci\u00f3n\n#for i in range(len(date_list[0:3]) - 1): #---Pruebas\nfor i in range(len(date_list) - 1): #--- Historico Total\n    initial_date = date_list[i]\n    final_date = (datetime.strptime(date_list[i + 1], '%m/%d/%Y') - timedelta(days=1)).strftime('%m/%d/%Y')\n    #driver = webdriver.Chrome()  # Inicializar el WebDriver\n    driver = webdriver.Chrome()  # No need for executable_path argument\n    # Maximizar la ventana del navegador \n    driver.maximize_window()\n    driver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\n    print(f\"Descargando archivo entre {initial_date} y {final_date}\")\n    download_file_between_dates(initial_date, final_date, driver, _dict)\n    print(f\"Descarga completa entre {initial_date} y {final_date}\")\n\nprint(\"Descargas completadas.\")\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde una p\u00e1gina web. Aqu\u00ed est\u00e1 el resumen:</p> <ol> <li>Inicializaci\u00f3n de Fechas: Asigna las fechas de inicio y fin para la descarga.</li> <li>Inicializaci\u00f3n del WebDriver: Inicia el WebDriver de Chrome y maximiza la ventana del navegador.</li> <li>Carga de la URL: Abre la p\u00e1gina web desde la cual se descargar\u00e1 el archivo.</li> <li>Registro de Informaci\u00f3n: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga.</li> <li>Descarga del Archivo: Llama a una funci\u00f3n para descargar el archivo entre las fechas especificadas.</li> <li>C\u00e1lculo del Tiempo: Calcula y registra el tiempo total del proceso ETL.</li> <li>Protecci\u00f3n de Datos: Utiliza un diccionario actualizado para seleccionar la categor\u00eda de protecci\u00f3n de datos.</li> </ol> <pre><code>initial_date = start_date.strftime('%m/%d/%Y')\nfinal_date = (end_date - timedelta(days=1)).strftime('%m/%d/%Y')\n#driver = webdriver.Chrome()  # Inicializar el WebDriver\ndriver = webdriver.Chrome()  # No need for executable_path argument\n# Maximizar la ventana del navegador \ndriver.maximize_window()\ndriver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\nprint(f\"Descargando archivo entre {initial_date} y {final_date}\")\ndownload_file_between_dates(initial_date, final_date, driver,_dict)\nprint(f\"Descarga completa entre {initial_date} y {final_date}\")\n\ntiempo_total = time.time() - inicio_etl\nlog_tiempo(logger, f'FINAL ETL --- ', tiempo_total)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/","title":"Funciones.py","text":"<p>Este archivo contiene una serie de funciones automatizadas desarrolladas para gestionar tareas comunes en la manipulaci\u00f3n de datos y la interacci\u00f3n con sistemas externos. Las funciones descritas est\u00e1n dise\u00f1adas principalmente para automatizar procesos en plataformas como SharePoint y sistemas como C4C, as\u00ed como para facilitar el procesamiento de datos utilizando herramientas como Selenium, pandas y xlwings.</p> <p>Las funciones cubren una variedad de tareas, incluyendo:</p> <ol> <li> <p>Autenticaci\u00f3n y acceso a plataformas externas:</p> <ul> <li>Funciones que automatizan el proceso de inicio de sesi\u00f3n y la autenticaci\u00f3n en plataformas como C4C y SharePoint.</li> </ul> </li> <li> <p>Interacci\u00f3n con men\u00fas desplegables y formularios web:</p> <ul> <li>Herramientas para manejar men\u00fas desplegables personalizados y formularios en p\u00e1ginas web, facilitando la automatizaci\u00f3n de interacciones con elementos HTML mediante Selenium.</li> </ul> </li> <li> <p>Descarga y procesamiento de datos:</p> <ul> <li>Funciones que permiten la descarga de archivos desde plataformas externas basadas en fechas, as\u00ed como la transformaci\u00f3n y organizaci\u00f3n de los datos descargados en un formato adecuado para an\u00e1lisis.</li> </ul> </li> <li> <p>Manejo de archivos y directorios:</p> <ul> <li>Funciones que facilitan la gesti\u00f3n de archivos en el sistema de archivos local y en plataformas como SharePoint, incluyendo el renombrado, carga y descarga de archivos.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n de datos:</p> <ul> <li>Funciones espec\u00edficas para preprocesar, normalizar y limpiar los datos antes de ser utilizados o almacenados, asegurando que la informaci\u00f3n est\u00e9 en el formato adecuado para su posterior an\u00e1lisis.</li> </ul> </li> </ol> <p>Este conjunto de herramientas es esencial para mejorar la eficiencia en tareas repetitivas, reduciendo la necesidad de intervenci\u00f3n manual y permitiendo una integraci\u00f3n m\u00e1s fluida entre los sistemas externos y el entorno de trabajo. La automatizaci\u00f3n de estos procesos optimiza el flujo de trabajo y facilita la administraci\u00f3n y procesamiento de grandes vol\u00famenes de datos.</p>"},{"location":"00.etl/Utils/Funciones/#configuracion-e-import-de-librerias","title":"Configuracion e import de Librerias","text":"<p>Este bloque de c\u00f3digo configura el entorno de trabajo importando todas las librer\u00edas necesarias para manipulaci\u00f3n de datos, automatizaci\u00f3n de Excel, autenticaci\u00f3n y automatizaci\u00f3n de navegadores web. <code>Funciones.py</code> importa varias librer\u00edas est\u00e1ndar y externas necesarias para el funcionamiento del script. </p>"},{"location":"00.etl/Utils/Funciones/#librerias-estandar","title":"Librer\u00edas est\u00e1ndar","text":"<ul> <li><code>calendar</code>: Funciones de calendario.</li> <li><code>configparser</code>: Manejo de archivos de configuraci\u00f3n.</li> <li><code>hashlib</code>: Funciones hash seguras.</li> <li><code>json</code>: Trabajo con datos JSON.</li> <li><code>logging</code>: Registro de mensajes.</li> <li><code>os</code>: Interacci\u00f3n con el sistema operativo.</li> <li><code>re</code>: Expresiones regulares.</li> <li><code>time</code>: Funciones relacionadas con el tiempo.</li> <li><code>unicodedata</code>: Manipulaci\u00f3n de datos Unicode.</li> <li><code>datetime</code>: Manejo de fechas y horas.</li> <li><code>timedelta</code>: Diferencia entre fechas o tiempos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#librerias-externas","title":"Librer\u00edas externas","text":"<ul> <li><code>numpy (np)</code>: Computaci\u00f3n num\u00e9rica.</li> <li><code>pandas (pd)</code>: Manipulaci\u00f3n y an\u00e1lisis de datos.</li> <li><code>requests</code>: Solicitudes HTTP.</li> <li><code>xlwings (xw)</code>: Automatizaci\u00f3n de Excel.</li> <li><code>msal</code>: Autenticaci\u00f3n de Microsoft.</li> <li><code>openpyxl</code>: Lectura y escritura de archivos de Excel.</li> <li><code>selenium</code>: Automatizaci\u00f3n de navegadores web.</li> </ul> <p>Dentro de <code>selenium</code>, se importan excepciones y m\u00f3dulos espec\u00edficos para manejar errores y realizar acciones complejas en el navegador.</p> <pre><code># pylint: disable=all\n# Librer\u00edas est\u00e1ndar\nimport calendar\nimport configparser\nimport hashlib\nimport json\nimport logging\nimport os\nimport re\nimport time\nimport unicodedata\nfrom datetime import datetime, timedelta\n\n# Librer\u00edas externas\nimport numpy as np\nimport pandas as pd\nimport requests\nimport xlwings as xw\nfrom msal import ConfidentialClientApplication\nfrom openpyxl import load_workbook\nfrom selenium import webdriver\nfrom selenium.common.exceptions import (\n    ElementNotInteractableException, NoSuchElementException, StaleElementReferenceException, \n    TimeoutException, WebDriverException\n)\nfrom selenium.webdriver.common.action_chains import ActionChains\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.support.ui import Select, WebDriverWait\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#autenticacion-y-configuracion-sharepoint","title":"Autenticacion y Configuracion Sharepoint","text":"<p>Este c\u00f3digo realiza varias tareas relacionadas con la autenticaci\u00f3n y configuraci\u00f3n para procesar archivos en SharePoint. A continuaci\u00f3n, se detalla cada parte del c\u00f3digo:</p> <ol> <li> <p>Inicializaci\u00f3n de Variables:</p> <ul> <li><code>csv_files</code>: Lista de archivos CSV a procesar.</li> <li><code>original_dir</code>: Guarda el directorio de trabajo actual.</li> </ul> </li> <li> <p>Cambio de Directorio:</p> <ul> <li>Guarda el directorio de trabajo actual y cambia al directorio del script.</li> </ul> </li> <li> <p>Lectura de Credenciales:</p> <ul> <li>Lee las credenciales desde un archivo <code>credenciales.env</code>.</li> <li>Procesa las claves y las almacena en un diccionario <code>keys</code>.</li> </ul> </li> <li> <p>Configuraci\u00f3n de MSAL:</p> <ul> <li>Configura la autenticaci\u00f3n usando <code>msal</code> con las credenciales le\u00eddas.</li> <li>Lee la clave privada desde un archivo <code>key.pem</code>.</li> <li>Configura la aplicaci\u00f3n <code>msal</code> con el <code>client_id</code>, <code>authority</code> y <code>client_credential</code>.</li> <li>Adquiere un token de acceso para SharePoint Online.</li> <li>Configura los encabezados de autorizaci\u00f3n para las solicitudes HTTP.</li> </ul> </li> <li> <p>Lectura de Configuraci\u00f3n Adicional:</p> <ul> <li>Lee m\u00e1s credenciales desde un archivo <code>scraping.env</code>.</li> <li>Almacena las credenciales en variables para diferentes servicios.</li> </ul> </li> <li> <p>Restauraci\u00f3n del Directorio Original:</p> <ul> <li>Restaura el directorio de trabajo original.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#resumen","title":"Resumen","text":"<p>Este c\u00f3digo realiza las siguientes tareas:</p> <ol> <li>Guarda y cambia el directorio de trabajo.</li> <li>Lee credenciales desde archivos de configuraci\u00f3n.</li> <li>Configura la autenticaci\u00f3n con MSAL para acceder a SharePoint.</li> <li>Lee configuraciones adicionales para otros servicios.</li> <li>Restaura el directorio de trabajo original.</li> </ol> <p>Este proceso es esencial para asegurar que las credenciales y configuraciones necesarias est\u00e9n disponibles y seguras para el procesamiento de archivos en SharePoint y otros servicios relacionados.</p> <pre><code>#Determina si un archivo es un archivo de Excel o csv para los procesados en Sharepoint\n#csv_files = [\"cede_Listado_Matriculas\",\"emp_Listado_Matriculas\"]\ncsv_files = []\n\n# Guardar el directorio de trabajo actual\noriginal_dir = os.getcwd()\ntry:\n    # Cambiar el directorio de trabajo al directorio del script\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    os.chdir(script_dir)\n\n    # Leer la clave privada desde el archivo key.pem\n    with open('credenciales.env', 'r') as key_file:\n        lines = key_file.readlines()\n\n    # Procesar las claves\n    keys = {}\n    for line in lines:\n        key, value = line.strip().split(\" = \")\n        keys[key] = value.strip('\"')\n\n    client_id = keys.get(\"client_id\")\n    cert_thumbprint = keys.get(\"cert_thumbprint\")\n    tenant_id = keys.get(\"tenant_id\")\n\n    authority = f\"https://login.microsoftonline.com/{tenant_id}\"\n\n    # Leer la clave privada desde el archivo key.pem\n    with open('key.pem', 'r') as key_file:\n        private_key = key_file.read()\n\n    cert = {\n        \"private_key\": private_key,\n        \"thumbprint\": cert_thumbprint,\n    }\n\n    msal_app = ConfidentialClientApplication(\n        client_id=client_id,\n        authority=authority,\n        client_credential=cert,\n    )\n\n    scopes_sharepoint_online = [keys.get(\"scopes_sharepoint_online\")]\n\n    results = msal_app.acquire_token_for_client(scopes_sharepoint_online)\n\n    if \"access_token\" in results:\n        access_token = results.get(\"access_token\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {access_token}\",\n        \"Accept\": \"application/json;odata=verbose\",\n        \"Content-Type\": \"application/json\",\n    }\n\n    sharepoint_base_url = keys.get(\"sharepoint_base_url\")\n\n\n\n    # Leer las credenciales desde el archivo credenciales.env\n    config = configparser.ConfigParser(interpolation=None)\n    config.read('scraping.env')\n\n    # Almacenar las credenciales en variables\n    desarrollo_empresarial_url = config['desarrollo_empresarial']['url'].strip('\"')\n    desarrollo_empresarial_username = config['desarrollo_empresarial']['username'].strip('\"')\n    desarrollo_empresarial_password = config['desarrollo_empresarial']['password'].strip('\"')\n\n    cedesarrollo_url = config['cedesarrollo']['url'].strip('\"')\n    cedesarrollo_username = config['cedesarrollo']['username'].strip('\"')\n    cedesarrollo_password = config['cedesarrollo']['password'].strip('\"')\n\n    C4C_username = config['C4C']['username'].strip('\"')\n    C4C_password = config['C4C']['password'].strip('\"')\nfinally:\n    # Restaurar el directorio de trabajo original\n    os.chdir(original_dir)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-credenciales","title":"Funci\u00f3n <code>credenciales</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito","title":"Prop\u00f3sito","text":"<p>La funci\u00f3n <code>credenciales</code> se utiliza para recuperar las credenciales almacenadas en un archivo de configuraci\u00f3n (<code>scraping.env</code>) seg\u00fan la plataforma especificada. Las credenciales se procesan eliminando cualquier comilla circundante en los valores.</p>"},{"location":"00.etl/Utils/Funciones/#entradas","title":"Entradas","text":"<ul> <li><code>plataforma</code> (str): El nombre de la plataforma para la cual se necesitan las credenciales. Las opciones v\u00e1lidas son:</li> <li><code>\"desarrollo_empresarial\"</code></li> <li><code>\"cedesarrollo\"</code></li> <li><code>\"C4C\"</code></li> </ul>"},{"location":"00.etl/Utils/Funciones/#salidas","title":"Salidas","text":"<p>Dependiendo de la plataforma solicitada:</p> <ul> <li><code>desarrollo_empresarial</code>:<ul> <li>URL</li> <li>Nombre de usuario</li> <li>Contrase\u00f1a</li> </ul> </li> <li><code>cedesarrollo</code>:<ul> <li>URL</li> <li>Nombre de usuario</li> <li>Contrase\u00f1a</li> </ul> </li> <li><code>C4C</code>:<ul> <li>Nombre de usuario</li> <li>Contrase\u00f1a</li> </ul> </li> </ul>"},{"location":"00.etl/Utils/Funciones/#detalles-de-implementacion","title":"Detalles de implementaci\u00f3n","text":"<ol> <li> <p>Cambio temporal del directorio:</p> <ul> <li>Guarda el directorio actual (<code>os.getcwd</code>) y cambia al directorio donde se encuentra el archivo de script (<code>__file__</code>). Esto asegura que <code>scraping.env</code> sea accesible incluso si el script se ejecuta desde un directorio diferente.</li> </ul> </li> <li> <p>Lectura del archivo de configuraci\u00f3n:</p> <ul> <li>Utiliza <code>configparser.ConfigParser</code> con <code>interpolation=None</code> para cargar los valores directamente sin interpolaci\u00f3n.</li> </ul> </li> <li> <p>Eliminaci\u00f3n de comillas:</p> <ul> <li>Se usa la funci\u00f3n <code>remove_quotes</code> para eliminar comillas simples y dobles de los valores cargados.</li> </ul> </li> <li> <p>Restauraci\u00f3n del directorio original:</p> <ul> <li>Una vez procesadas las credenciales, se restaura el directorio original, garantizando que no haya efectos secundarios en otros procesos que utilicen el directorio de trabajo actual.</li> </ul> </li> </ol> <pre><code># Funci\u00f3n para eliminar las comillas del valor\ndef remove_quotes(value):\n    return value.strip('\"').strip(\"'\")\n\ndef credenciales(plataforma):\n    # Guardar el directorio de trabajo actual\n    original_dir = os.getcwd()\n    try:\n        # Cambiar el directorio de trabajo al directorio del script\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        os.chdir(script_dir)\n        # Leer las credenciales desde el archivo scraping.env\n        config = configparser.ConfigParser(interpolation=None)\n        config.read('scraping.env')\n        # Almacenar las credenciales en variables\n        if plataforma == \"desarrollo_empresarial\":\n            desarrollo_empresarial_url = remove_quotes(config['desarrollo_empresarial']['url'])\n            desarrollo_empresarial_username = remove_quotes(config['desarrollo_empresarial']['username'])\n            desarrollo_empresarial_password = remove_quotes(config['desarrollo_empresarial']['password'])\n            return desarrollo_empresarial_url, desarrollo_empresarial_username, desarrollo_empresarial_password\n        elif plataforma == \"cedesarrollo\":\n            cedesarrollo_url = remove_quotes(config['cedesarrollo']['url'])\n            cedesarrollo_username = remove_quotes(config['cedesarrollo']['username'])\n            cedesarrollo_password = remove_quotes(config['cedesarrollo']['password'])\n            return cedesarrollo_url, cedesarrollo_username, cedesarrollo_password\n        elif plataforma == \"C4C\":\n            C4C_username = remove_quotes(config['C4C']['username'])\n            C4C_password = remove_quotes(config['C4C']['password'])\n            return C4C_username, C4C_password\n\n    finally:\n        # Restaurar el directorio de trabajo original\n        os.chdir(original_dir)\n</code></pre> <p><code>generar_periodos</code> crea un conjunto de a\u00f1os desde el a\u00f1o inicial (<code>inicio</code>) hasta el a\u00f1o final (<code>fin</code>), incluyendo ambos extremos. Devuelve un conjunto de enteros \u00fanicos representando los a\u00f1os en el rango especificado.</p> <pre><code>def generar_periodos(inicio, fin):\n    return {year for year in range(inicio, fin + 1)}\n</code></pre> <p><code>dias_del_mes</code> devuelve el n\u00famero de d\u00edas de un mes espec\u00edfico en un a\u00f1o determinado, teniendo en cuenta si el a\u00f1o es bisiesto.</p> <pre><code>def dias_del_mes(mes, anio):\n    \"\"\"Devuelve el n\u00famero de d\u00edas en un mes dado, considerando a\u00f1os bisiestos.\"\"\"\n    return calendar.monthrange(anio, mes)[1]\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-setup_logger","title":"Funci\u00f3n <code>setup_logger</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_1","title":"Prop\u00f3sito","text":"<p>Configura un logger para manejar y formatear mensajes de registro, permitiendo guardar los logs en un archivo y mostrarlos en la consola.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_1","title":"Entradas","text":"<ul> <li><code>log_filename</code> (str): Nombre del archivo donde se almacenar\u00e1n los logs (por defecto, <code>scraper.log</code>).</li> <li><code>log_level</code> (nivel de log): Nivel de severidad de los mensajes registrados (por defecto, <code>logging.DEBUG</code>).</li> <li><code>log_format</code> (str): Formato de los mensajes de log (por defecto, <code>'%(asctime)s - %(levelname)s - %(message)s'</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#salida","title":"Salida","text":"<ul> <li><code>logger</code> (logging.Logger): Objeto configurado para registrar mensajes con los manejadores y formato especificados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#detalles","title":"Detalles","text":"<ol> <li>Configura un logger con el nivel deseado.</li> <li>Define manejadores para archivo y consola.</li> <li>Establece un formato uniforme para los logs.</li> <li>Elimina manejadores existentes en caso de configuraci\u00f3n previa, evitando duplicados.</li> <li>Retorna el logger configurado.</li> </ol> <pre><code>def setup_logger(log_filename='scraper.log', log_level=logging.DEBUG, log_format='%(asctime)s - %(levelname)s - %(message)s'):\n    # Crea un logger con el nivel especificado\n    logger = logging.getLogger()\n    logger.setLevel(log_level)\n\n    # Crea un manejador para el archivo de log\n    file_handler = logging.FileHandler(log_filename)\n    file_handler.setLevel(log_level)\n\n    # Crea un manejador para la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(log_level)\n\n    # Crea un formato para los logs\n    formatter = logging.Formatter(log_format)\n    file_handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n\n    # Si el logger ya tiene manejadores, eliminar todos para evitar duplicados\n    if logger.hasHandlers():\n        logger.handlers.clear()\n\n    # A\u00f1adir los manejadores al logger\n    logger.addHandler(file_handler)\n    logger.addHandler(console_handler)\n\n    return logger\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-log_step_decorator","title":"Funci\u00f3n <code>log_step_decorator</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_2","title":"Prop\u00f3sito","text":"<p>Decora una funci\u00f3n para registrar informaci\u00f3n sobre su ejecuci\u00f3n, incluyendo inicio, finalizaci\u00f3n exitosa o errores, as\u00ed como la duraci\u00f3n del proceso.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_2","title":"Entradas","text":"<ul> <li><code>step_name</code> (str): Nombre descriptivo del paso que se est\u00e1 decorando, utilizado para identificar los registros.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento","title":"Funcionamiento","text":"<ul> <li>Inicio: Registra un mensaje indicando el inicio del paso.</li> <li>Finalizaci\u00f3n exitosa:<ul> <li>Calcula y registra la duraci\u00f3n del paso en segundos o minutos.</li> </ul> </li> <li>Error:<ul> <li>Registra un mensaje de error con la duraci\u00f3n transcurrida y el detalle de la excepci\u00f3n.</li> </ul> </li> <li>Formato: Los mensajes se registran con colores en consola (<code>\\033[92m</code> para \u00e9xito y <code>\\033[91m</code> para errores).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#salida_1","title":"Salida","text":"<ul> <li>Devuelve un decorador que envuelve la funci\u00f3n original, a\u00f1adiendo la funcionalidad de registro.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#detalles-adicionales","title":"Detalles adicionales","text":"<ul> <li>Utiliza un logger configurado previamente para registrar los eventos.</li> <li>Maneja tanto procesos exitosos como excepciones, asegurando que los logs sean informativos.</li> </ul> <pre><code>logger = setup_logger(\"scraper.log\")\ndef log_step_decorator(step_name):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            start_time = time.time()\n            logger.info(f\"\\033[92mIniciando: {step_name}\\033[0m\")\n            try:\n                result = func(*args, **kwargs)\n                duration = time.time() - start_time\n                if duration &gt;= 60:\n                    duration_minutes = duration / 60\n                    logger.info(f\"\"\"\\033[92mProceso '{step_name}' \n                                completado exitosamente en {duration_minutes:.2f} minutos.\\033[0m\"\"\")\n                else:\n                    logger.info(f\"\"\"\\033[92mProceso '{step_name}' \n                                completado exitosamente en {duration:.2f} segundos.\\033[0m\"\"\")\n                return result\n            except Exception as e:\n                duration = time.time() - start_time\n                if duration &gt;= 60:\n                    duration_minutes = duration / 60\n                    logger.error(f\"\\033[91mError en el paso '{step_name}' despu\u00e9s de {duration_minutes:.2f} minutos: {e}\\033[0m\")\n                else:\n                    logger.error(f\"\\033[91mError en el paso '{step_name}' despu\u00e9s de {duration:.2f} segundos: {e}\\033[0m\")\n                raise\n        return wrapper\n    return decorator\n</code></pre> <p><code>log_tiempo</code> registra un mensaje en el logger indicando el tiempo transcurrido, mostrando minutos si supera los 60 segundos. Toma tres par\u00e1metros: <code>logger</code> para manejar el registro, <code>message</code> como texto base y <code>tiempo_transcurrido</code> como duraci\u00f3n en segundos.</p> <pre><code>def log_tiempo(logger, message, tiempo_transcurrido):\n    \"\"\"\n    Funci\u00f3n para registrar tiempo en el logger, mostrando en minutos si es mayor a 60 segundos.\n    Par\u00e1metros:\n     - logger: instancia del logger\n     - message: mensaje base a mostrar\n     - tiempo_transcurrido: tiempo transcurrido en segundos\n    \"\"\"\n    if tiempo_transcurrido &gt;= 60:\n        tiempo_minutos = tiempo_transcurrido / 60\n        logger.info(f'{message} --- {tiempo_minutos:.2f} minutes ---')\n    else:\n        logger.info(f'{message} --- {tiempo_transcurrido:.2f} seconds ---')\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-process_files_from_folder","title":"Funci\u00f3n <code>process_files_from_folder</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_3","title":"Prop\u00f3sito","text":"<p>Procesa archivos de una carpeta de SharePoint que han sido modificados en los \u00faltimos seis meses, almacenando los datos en una lista de DataFrames.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_3","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL de la carpeta en SharePoint desde donde se obtendr\u00e1n los archivos.</li> <li><code>dfs</code> (list): Lista utilizada para almacenar los DataFrames procesados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_1","title":"Funcionamiento","text":"<ol> <li>Listar archivos: Obtiene la lista de archivos en la carpeta de SharePoint.</li> <li>Filtrar por fecha: Identifica archivos modificados en los \u00faltimos seis meses.</li> <li>Procesar archivos:<ul> <li>Recupera el contenido de los archivos seleccionados desde SharePoint.</li> <li>Lee el contenido de los archivos como DataFrames utilizando <code>pandas</code>.</li> <li>Registra informaci\u00f3n sobre el contenido y lo almacena en la lista <code>dfs</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_2","title":"Salida","text":"<ul> <li>No retorna ning\u00fan valor. Modifica la lista <code>dfs</code> proporcionada al agregar los DataFrames procesados.</li> </ul> <pre><code>@log_step_decorator(\"Procesar archivos de una carpeta de SharePoint\")\ndef process_files_from_folder(folder_url, dfs):\n    \"\"\"\n    Procesa los archivos en una carpeta de SharePoint que han sido modificados en los \u00faltimos seis meses.\n\n    Args:\n        folder_url (str): La URL de la carpeta en SharePoint.\n        dfs (list): Una lista para almacenar los DataFrames procesados.\n\n    Returns:\n        None\n    \"\"\"\n    files = list_files_from_sharepoint(folder_url)\n    six_months_ago = datetime.now() - timedelta(days=180)\n\n    for file in files:\n        file_name = file['Name']\n        file_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n        modified_date_str = file['TimeLastModified']\n        modified_date = datetime.strptime(modified_date_str, '%Y-%m-%dT%H:%M:%SZ')\n\n        if modified_date &gt;= six_months_ago:\n            # Obtener el archivo de SharePoint\n            file_content = get_file_from_sharepoint(file_url)\n\n            if file_content:\n                # Leer el archivo Excel sin descargar\n                df = pd.read_excel(file_content)\n                logger.info(\"Contenido de {}:\\n{}\".format(file_name, df.head()))\n                dfs.append(df)\n</code></pre> <p><code>list_files_from_sharepoint</code> obtiene una lista de archivos presentes en una carpeta de SharePoint indicada por la URL proporcionada. Recibe como entrada <code>folder_url</code> (str), que especifica la ubicaci\u00f3n de la carpeta, y devuelve una lista de archivos si la solicitud es exitosa o una lista vac\u00eda en caso de fallo. Tambi\u00e9n registra advertencias en caso de errores durante la solicitud.</p> <pre><code>@log_step_decorator(\"Listar archivos de SharePoint\")\ndef list_files_from_sharepoint(folder_url):\n    \"\"\"\n    Lista los archivos en una carpeta de SharePoint.\n\n    Args:\n        folder_url (str): La URL de la carpeta en SharePoint.\n\n    Returns:\n        list: Una lista de archivos en la carpeta si la solicitud es exitosa.\n        list: Una lista vac\u00eda si la solicitud falla.\n    \"\"\"\n    list_files_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n    response = requests.get(list_files_url, headers=headers)\n\n    if response.status_code == 200:\n        files = response.json()['d']['results']\n        return files\n    else:\n        logger.warning(f\"Error al listar los archivos. C\u00f3digo de estado: {response.status_code}\")\n        return []\n</code></pre> <p><code>get_file_from_sharepoint</code> descarga un archivo desde SharePoint utilizando su URL. Recibe como entrada <code>file_url</code> (str), que especifica la ubicaci\u00f3n del archivo, y devuelve el contenido del archivo como bytes si la solicitud es exitosa. En caso de error, retorna <code>None</code> y registra una advertencia con el c\u00f3digo de estado de la respuesta.</p> <pre><code>@log_step_decorator(\"Obtener archivo de SharePoint\")\ndef get_file_from_sharepoint(file_url):\n    \"\"\"\n    Descarga un archivo desde SharePoint dado su URL.\n\n    Args:\n        file_url (str): La URL del archivo en SharePoint.\n\n    Returns:\n        bytes: El contenido del archivo si la solicitud es exitosa.\n        None: Si la solicitud falla.\n    \"\"\"\n    response = requests.get(file_url, headers=headers)\n    logger.info(f\"Response Status Code: {response.status_code}\")\n\n    if response.status_code == 200:\n        return response.content\n    else:\n        logger.warning(f\"Error al acceder al archivo. C\u00f3digo de estado: {response.status_code}\")\n        return None\n</code></pre> <p><code>_extract_date</code> convierte una fecha extra\u00edda de un nombre de archivo en un objeto <code>datetime.date</code>. Recibe como entrada <code>file_name</code> (str), que contiene la fecha incrustada, y <code>date_pattern</code>, un patr\u00f3n de expresi\u00f3n regular para buscar la fecha. Si encuentra coincidencias, devuelve un objeto <code>datetime.date</code>; de lo contrario, retorna <code>None</code>.</p> <pre><code># Funci\u00f3n para convertir la fecha extra\u00edda en un objeto datetime\ndef _extract_date(file_name,date_pattern):\n    match = date_pattern.search(file_name)\n    if match:\n        day, month, year = map(int, match.groups())\n        return datetime.date(year, month, day)\n    return None\n</code></pre> <p><code>obtener_sharepoint</code> limpia una carpeta local especificada y descarga todos los archivos desde una carpeta de SharePoint hacia esa ubicaci\u00f3n. Recibe como entradas <code>folder_url</code> (str), que indica la URL de la carpeta de SharePoint, y <code>_folder</code> (str), la ruta de la carpeta local donde se guardar\u00e1n los archivos.</p> <pre><code>def obtener_sharepoint(folder_url,_folder):\n    limpiar_carpeta(_folder)\n    download_all_files_from_sharepoint(folder_url, _folder)\n</code></pre> <p>Funci\u00f3n <code>extract_date</code> para convertir la fecha extra\u00edda en un objeto datetime</p> <pre><code>def extract_date(file_name, date_pattern):\n    match = date_pattern.search(file_name)\n    if match:\n        day, month, year = map(int, match.groups())\n        return datetime(year, month, day)  # Usar datetime en lugar de date\n    return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-upload_file_to_sharepoint","title":"Funci\u00f3n <code>upload_file_to_sharepoint</code>","text":"<p>Sube un archivo local a una carpeta de SharePoint especificada. Recibe como entradas:</p> <ul> <li><code>file_path</code> (str): Ruta local del archivo que se desea subir.</li> <li><code>folder_url</code> (str): URL de la carpeta de destino en SharePoint.</li> </ul> <p>Funcionamiento: 1. Validaci\u00f3n de existencia: Verifica que el archivo local exista. 2. Lectura del archivo: Abre el archivo en modo binario y lee su contenido. 3. Preparaci\u00f3n de la URL: Construye la URL para la subida en SharePoint. 4. Encabezados: Configura el encabezado <code>Content-Length</code> con el tama\u00f1o del archivo. 5. Subida: Realiza una solicitud POST para subir el archivo a SharePoint. 6. Logs:     - Registra un mensaje de \u00e9xito si el archivo se sube correctamente (excepto si es un archivo codificado con nombre MD5).     - Registra un error si la subida falla, indicando el c\u00f3digo de estado.</p> <p>Salidas: - No retorna ning\u00fan valor; realiza acciones y registra logs seg\u00fan el resultado.</p> <pre><code>def upload_file_to_sharepoint(file_path, folder_url):\n    if not os.path.exists(file_path):\n        # logging.error(f\"Archivo no encontrado: {file_path}. No se puede subir a SharePoint.\")\n        return\n\n    with open(file_path, \"rb\") as file:\n        file_content = file.read()\n\n    file_name = os.path.basename(file_path)\n    upload_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files/add(url='{file_name}',overwrite=true)\"\n\n    headers['Content-Length'] = str(len(file_content))  # A\u00f1adir encabezado para la longitud del contenido\n\n    response = requests.post(url=upload_url, headers=headers, data=file_content)\n\n    if response.status_code == 200:\n        if re.match(r'^[a-f0-9]{32}\\.xlsx$', file_name):\n            # Archivo codificado, no hacer logging\n            pass\n        else:\n            logging.info(f\"Archivo {file_name} subido exitosamente a SharePoint.\")\n    else:\n        logging.error(f\"Error al subir el archivo {file_name}. C\u00f3digo de estado: {response.status_code}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-actualizar_sharepoint_procesado","title":"Funci\u00f3n <code>actualizar_sharepoint_procesado</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_4","title":"Prop\u00f3sito","text":"<p>Sube un archivo procesado (en formato Excel o CSV) a una carpeta espec\u00edfica en SharePoint, determinada por un identificador ETL. El archivo se genera a partir de un DataFrame proporcionado.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_4","title":"Entradas","text":"<ul> <li><code>df</code> (pandas.DataFrame): Datos procesados que se guardar\u00e1n y subir\u00e1n como archivo.</li> <li><code>etl</code> (str): Identificador del tipo de proceso ETL, utilizado para determinar la carpeta de destino en SharePoint.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_2","title":"Funcionamiento","text":"<ol> <li>Mapeo de ETL a carpeta: Determina la URL de destino en SharePoint seg\u00fan el identificador <code>etl</code> usando el diccionario <code>etl_to_folder_url</code>.</li> <li>Generaci\u00f3n de archivo temporal:<ul> <li>Crea un archivo Excel (<code>.xlsx</code>) o CSV (<code>.csv</code>) a partir del DataFrame.</li> <li>El formato depende de si <code>etl</code> est\u00e1 presente en <code>csv_files</code>.</li> <li>El archivo incluye un timestamp en el nombre para garantizar unicidad.</li> </ul> </li> <li>Subida a SharePoint: Llama a <code>upload_file_to_sharepoint</code> para subir el archivo temporal a la URL correspondiente.</li> <li>Manejo de errores: Si ocurre un error durante la subida, registra un mensaje de error.</li> <li>Limpieza: Elimina el archivo temporal despu\u00e9s de subirlo, asegurando que no queden residuos en el sistema local.</li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_3","title":"Salida","text":"<ul> <li>No retorna valores. Realiza acciones y muestra mensajes en consola para registrar el \u00e9xito o errores durante el proceso.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#excepciones","title":"Excepciones","text":"<ul> <li>Maneja excepciones relacionadas con la subida a SharePoint e informa del error en consola. Limpia siempre los archivos temporales, incluso si ocurre un error.</li> </ul> <pre><code>def actualizar_sharepoint_procesado(df,etl):   \n\n    etl_to_folder_url = {\n        \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/01.Docentes',\n        \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/02.Disenio_Curricular',\n        \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/03.Listado_Matriculas',\n        \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/04.Ingresos',\n        \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/05.Historico_Notas',\n        \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/06.Egresados_Graduados',\n        \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/07.Cancelados_Desertores',\n        \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/01.Docentes',\n        \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/02.Preinscritos',\n        \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/03.Listado_Matriculas',\n        \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/04.Consolidado_inasistencias',\n        \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/05.Estudiantes_cancelados_por_inasistencias',\n        \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/06.Egresados_Graduados'    \n        }\n    # \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'\n    folder_url = etl_to_folder_url.get(etl, \"URL por defecto si no se encuentra el valor de etl\")\n    # Guardar en un archivo Excel temporal del df recibido\n    hoy = datetime.now().strftime(\"%d_%m_%Y_%H_%M\")\n\n    #si etl no esta en csv_files\n    if etl not in csv_files:\n        archivo_temporal = f\"procesado_{etl}_{hoy}.xlsx\"\n        df.to_excel(archivo_temporal, index=False)\n    else:\n        archivo_temporal = f\"procesado_{etl}_{hoy}.csv\"\n        #utf-8-sig para evitar problemas con caracteres especiales\n        df.to_csv(archivo_temporal, index=False, encoding='utf-8-sig')\n    try:\n        upload_file_to_sharepoint(file_path=archivo_temporal, folder_url=folder_url)\n        print(f\"Archivo subido a SharePoint: {archivo_temporal}, folder_url: {folder_url}\")\n    except Exception as e:\n        print(f\"Error al subir el archivo {archivo_temporal} a SharePoint: {e}\")\n    finally:\n        # cerrar el archivo temporal\n        # Eliminar el archivo original despu\u00e9s de procesarlo\n        time.sleep(0.5)  # Pausa de 500ms\n        os.remove(archivo_temporal)\n        print(f\"Archivo original eliminado: {archivo_temporal}\")\n</code></pre> <p><code>actualizar_columna_programa</code> actualiza una columna de destino en un DataFrame bas\u00e1ndose en condiciones de otra columna. Si la columna condicional no es nula y contiene un texto espec\u00edfico (si se proporciona), el valor de una columna origen se copia a la columna destino. Posteriormente, los valores nulos en la columna destino se rellenan usando el m\u00e9todo forward fill. Devuelve el DataFrame actualizado.</p> <pre><code>def actualizar_columna_programa(df, columna_condicional, columna_origen, columna_destino, texto_filtro=None):\n    \"\"\"\n    Actualiza una columna destino en un DataFrame en base a una condici\u00f3n de otra columna.\n    Si el valor en columna_condicional no es nulo y contiene un texto espec\u00edfico (opcional),\n    se copia el valor de columna_origen a columna_destino.\n    Luego, los valores nulos en columna_destino se rellenan usando el m\u00e9todo forward fill.\n\n    :param df: DataFrame a procesar.\n    :param columna_condicional: Nombre de la columna para evaluar la condici\u00f3n.\n    :param columna_origen: Nombre de la columna de donde copiar el valor.\n    :param columna_destino: Nombre de la columna destino que ser\u00e1 actualizada.\n    :param texto_filtro: Texto que debe estar presente en la columna_condicional (opcional).\n    :return: DataFrame actualizado.\n    \"\"\"\n    df[columna_destino] = df.apply(\n        lambda row: row[columna_origen]\n        if pd.notnull(row[columna_condicional]) and \n            (texto_filtro in str(row[columna_condicional]) if texto_filtro else True)\n        else None, \n        axis=1\n    )\n    df[columna_destino] = df[columna_destino].ffill()\n    return df\n</code></pre> <p><code>concatenar_dataframes</code> combina m\u00faltiples DataFrames en uno solo, ignorando los \u00edndices originales. Filtra y excluye DataFrames vac\u00edos o aquellos cuyos valores sean completamente nulos antes de la concatenaci\u00f3n. Si no hay DataFrames v\u00e1lidos, retorna un DataFrame vac\u00edo.</p> <pre><code>def concatenar_dataframes(dataframes):\n    # Filtrar DataFrames vac\u00edos o con todos los valores como NA\n    dataframes = [df for df in dataframes if not df.empty and not df.isna().all().all()]\n    if dataframes:\n        return pd.concat(dataframes, ignore_index=True)\n    else:\n        return pd.DataFrame()\n</code></pre> <p><code>process_row</code> procesa una fila de un DataFrame modificando columnas espec\u00edficas en funci\u00f3n del contenido de la columna <code>'Columna_15'</code>. Tambi\u00e9n actualiza dos indicadores booleanos, <code>found_porcentaje</code> y <code>found_creditos</code>, que rastrean si se encontraron palabras clave espec\u00edficas:</p> <ul> <li> <p>Condiciones:</p> <ul> <li>Si <code>'Columna_15'</code> es una cadena que contiene \"Porcentaje\", activa <code>found_porcentaje</code> y desactiva <code>found_creditos</code>.</li> <li>Si <code>'Columna_15'</code> es \"Creditos\", activa <code>found_creditos</code> y desactiva <code>found_porcentaje</code>.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Si <code>found_porcentaje</code> es <code>True</code>, copia el valor de <code>'Columna_15'</code> en <code>'Columna_16'</code>.</li> <li>Si <code>found_creditos</code> es <code>True</code>, copia el valor de <code>'Columna_15'</code> en <code>'Columna_14'</code>.</li> </ul> </li> </ul> <p>Devuelve la fila actualizada junto con los valores actualizados de <code>found_porcentaje</code> y <code>found_creditos</code>.</p> <pre><code>def process_row(row, found_porcentaje, found_creditos):\n    if isinstance(row['Columna_15'], str) and 'Porcentaje' in row['Columna_15']:\n        found_porcentaje = True\n        found_creditos = False\n    elif row['Columna_15'] == 'Creditos':\n        found_creditos = True\n        found_porcentaje = False\n    if found_porcentaje:\n        row['Columna_16'] = row['Columna_15']\n    elif found_creditos:\n        row['Columna_14'] = row['Columna_15']\n    return row, found_porcentaje, found_creditos\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar_excel_con_hojas","title":"Funci\u00f3n <code>procesar_excel_con_hojas</code>","text":"<p>Procesa un archivo Excel con m\u00faltiples hojas, combinando los datos seg\u00fan reglas espec\u00edficas:</p> <ol> <li> <p>Lectura inicial:</p> <ul> <li>Carga todas las hojas del archivo Excel.</li> <li>Procesa la primera hoja directamente.</li> </ul> </li> <li> <p>Procesamiento de hojas restantes:</p> <ul> <li>Identifica el inicio de los datos en cada hoja mediante la primera fila no nula de la columna A.</li> <li>Si los datos de la hoja comienzan con \"1\" en la columna A, combina alineando por esta columna usando un merge.</li> <li>Si no comienzan con \"1\", concatena los datos al final, continuando el listado.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve un \u00fanico DataFrame que combina los datos procesados de todas las hojas seg\u00fan las reglas descritas.</li> </ul> </li> </ol> <pre><code>def procesar_excel_con_hojas(file_path):\n    # Leer todas las hojas\n    excel_data = pd.ExcelFile(file_path)\n    hojas = excel_data.sheet_names\n\n    # Procesar la primera hoja directamente\n    hoja1 = pd.read_excel(file_path, sheet_name=hojas[0])\n\n    # Procesar las dem\u00e1s hojas\n    for sheet_name in hojas[1:]:\n        hoja_actual = pd.read_excel(file_path, sheet_name=sheet_name)\n\n        # Identificar d\u00f3nde empiezan los datos en la columna A\n        inicio_datos = hoja_actual[hoja_actual.iloc[:, 0].notna()].index[0]\n        hoja_actual = hoja_actual.iloc[inicio_datos:].reset_index(drop=True)\n\n        # Verificar si la columna A comienza con 1\n        if hoja_actual.iloc[0, 0] == 1:\n            # Combinar alineando por la columna A\n            hoja1 = pd.merge(\n                hoja1,\n                hoja_actual,\n                left_on=hoja1.columns[0],\n                right_on=hoja_actual.columns[0],\n                how=\"left\",\n            )\n        else:\n            # Agregar datos debajo continuando el listado\n\n            if not hoja_actual.empty:\n                hoja1 = pd.concat([hoja1, hoja_actual], ignore_index=True)\n\n    return hoja1\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-limpiar_columnas","title":"Funci\u00f3n <code>limpiar_columnas</code>","text":"<p>Realiza tareas de limpieza y transformaci\u00f3n en un DataFrame:</p> <ol> <li> <p>Eliminaci\u00f3n de columnas:</p> <ul> <li>Elimina las columnas especificadas en <code>columnas_a_eliminar</code> si existen en el DataFrame.</li> </ul> </li> <li> <p>Renombrado de columnas:</p> <ul> <li>Renombra columnas seg\u00fan el mapeo proporcionado en el diccionario <code>renombres</code>.</li> </ul> </li> <li> <p>Conversi\u00f3n a may\u00fasculas:</p> <ul> <li>Convierte todos los nombres de columnas a may\u00fasculas si se proporciona <code>columnas_a_mayusculas</code>.</li> </ul> </li> </ol> <p>Par\u00e1metros: - <code>df</code>: DataFrame a procesar. - <code>columnas_a_eliminar</code> (list): Lista de nombres de columnas a eliminar. - <code>renombres</code> (dict): Diccionario de renombramiento <code>{nombre_actual: nuevo_nombre}</code>. - <code>columnas_a_mayusculas</code> (bool, opcional): Si se proporciona, convierte los nombres de todas las columnas a may\u00fasculas.</p> <p>Salida: Devuelve el DataFrame transformado.</p> <pre><code>def limpiar_columnas(df, columnas_a_eliminar, renombres, columnas_a_mayusculas=None):\n    df = df.drop(columns=[col for col in columnas_a_eliminar if col in df.columns], errors='ignore')\n    df = df.rename(columns=renombres)\n    # COLOCAR TODAS LAS COLUMNAS EN MAY\u00daSCULAS\n    if columnas_a_mayusculas:\n        df.columns = df.columns.str.upper()\n    return df\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-replace_values_df","title":"Funci\u00f3n <code>replace_values_df</code>","text":"<p>Reemplaza valores en un DataFrame bas\u00e1ndose en un diccionario de sustituciones. Si no se especifica un diccionario <code>replacements</code>, utiliza uno predeterminado donde la columna <code>'Tipo de documento'</code> mapea valores largos como <code>'C\u00e9dula de Ciudadan\u00eda'</code> a formas abreviadas como <code>'CC'</code>. Itera por las columnas del diccionario y aplica los cambios definidos, devolviendo el DataFrame actualizado.</p> <p><code>_dict</code> contiene las claves y valores para reemplazar los tipos de documentos en espa\u00f1ol con sus correspondientes abreviaturas:</p> <ul> <li>C\u00e9dula de Ciudadan\u00eda: 'CC'</li> <li>Tarjeta de Identidad: 'TI'</li> <li>Registro Civil de Nacimiento: 'RC'</li> <li>C\u00e9dula \u00f3 Identificaci\u00f3n de Extranjer\u00eda: 'CE'</li> <li>Permiso de Protecci\u00f3n Temporal: 'PPT'</li> <li>Permiso Especial de Permanencia: 'PEP'</li> <li>N\u00famero de Identificaci\u00f3n Tributaria: 'NIT'</li> <li>C\u00f3digo NES: 'NES'</li> <li>Pasaporte: 'PA'</li> <li>Otros: 'OTRO' <pre><code>```python\n# Define the dictionary with the replacements\n_dict = {\n            'C\u00e9dula de Ciudadan\u00eda': 'CC',\n            'Tarjeta de Identidad': 'TI',\n            'Registro Civil de Nacimiento': 'RC',\n            'C\u00e9dula \u00f3 Identificaci\u00f3n de Extranjer\u00eda': 'CE',\n            'Permiso de Protecci\u00f3n Temporal': 'PPT',\n            'Permiso Especial de Permanencia': 'PEP',\n            'N\u00famero de Identificaci\u00f3n Tributaria': 'NIT',\n            'C\u00f3digo NES': 'NES',\n            'Pasaporte': 'PA',\n            'Otros': 'OTRO',\n            }\n\n# Define the function to replace values based on a dictionary\ndef replace_values_df(df, replacements=None):\n    if replacements is None:\n        replacements = {'Tipo de documento': _dict}\n\n    for column, changes in replacements.items():\n        df[column] = df[column].replace(changes)\n    return df\n</code></pre></li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcion-download_all_files_from_sharepoint","title":"Funci\u00f3n <code>download_all_files_from_sharepoint</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_5","title":"Prop\u00f3sito","text":"<p>Descarga todos los archivos de una carpeta de SharePoint a un directorio local especificado, asegurando que el directorio local sea creado o limpiado antes de la descarga.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_5","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL relativa de la carpeta en SharePoint.</li> <li><code>local_folder_path</code> (str): Ruta local donde se descargar\u00e1n los archivos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_3","title":"Funcionamiento","text":"<ol> <li> <p>Preparaci\u00f3n del directorio local:</p> <ul> <li>Verifica si el directorio existe:</li> <li>Si existe, elimina los archivos existentes.</li> <li>Si no existe, lo crea.</li> </ul> </li> <li> <p>Listado de archivos en SharePoint:</p> <ul> <li>Env\u00eda una solicitud HTTP para obtener la lista de archivos en la carpeta especificada.</li> <li>Procesa la respuesta JSON para obtener los detalles de los archivos.</li> </ul> </li> <li> <p>Descarga de archivos:</p> <ul> <li>Itera sobre la lista de archivos.</li> <li>Descarga cada archivo desde SharePoint y lo guarda en el directorio local.</li> <li>Registra informaci\u00f3n sobre cada archivo descargado o errores si ocurren durante la descarga.</li> </ul> </li> <li> <p>Manejo de sesiones HTTP:</p> <ul> <li>Utiliza una sesi\u00f3n HTTP para realizar las solicitudes.</li> <li>Configura un timeout para prevenir bloqueos.</li> <li>Cierra la sesi\u00f3n al finalizar.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_4","title":"Salida","text":"<ul> <li>No retorna valores. Registra los eventos relacionados con la limpieza del directorio, descarga de archivos y manejo de errores en el logger configurado.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#manejo-de-errores","title":"Manejo de errores","text":"<ul> <li>Registra errores en:</li> <li>Listado de archivos (problemas de red, tiempo de espera, etc.).</li> <li>Descarga de archivos individuales (problemas con la conexi\u00f3n o permisos).</li> <li>Asegura la limpieza del directorio local y el cierre de la sesi\u00f3n HTTP incluso en caso de errores.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones","title":"Consideraciones","text":"<ul> <li>La funci\u00f3n utiliza un decorador <code>log_step_decorator</code> para registrar el inicio, \u00e9xito o error del proceso completo.</li> </ul> <pre><code># Funci\u00f3n para descargar todos los archivos de una carpeta en SharePoint\n@log_step_decorator(\"Descargar archivos de SharePoint\")\ndef download_all_files_from_sharepoint(folder_url, local_folder_path):\n    # Asegurarnos de que el directorio local existe y limpiarlo\n    if os.path.exists(local_folder_path):\n        for file in os.listdir(local_folder_path):\n            file_path = os.path.join(local_folder_path, file)\n            try:\n                os.remove(file_path)\n                logger.info(f\"Archivo eliminado: {file}\")\n            except Exception as e:\n                logger.error(f\"No se pudo eliminar el archivo {file}. Error: {e}\")\n    else:\n        os.makedirs(local_folder_path)\n\n    # Crear una sesi\u00f3n para manejar las solicitudes HTTP\n    session = requests.Session()\n    session.headers.update(headers)  # Asegurar que los encabezados est\u00e1n configurados\n\n    # URL para listar los archivos de la carpeta en SharePoint\n    list_files_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n\n    try:\n        # Solicitud para obtener la lista de archivos\n        response = session.get(list_files_url, timeout=30)  # Configurar un timeout para evitar bloqueos\n        response.raise_for_status()  # Levantar un error si el c\u00f3digo de estado no es 200\n    except requests.exceptions.RequestException as e:\n        logger.error(f\"Error al listar los archivos de la carpeta. Detalles: {e}\")\n        session.close()\n        return\n\n    # Procesar la respuesta JSON\n    files = response.json().get('d', {}).get('results', [])\n    if not files:\n        logger.info(\"No hay archivos en la carpeta especificada.\")\n        session.close()\n        return\n\n    # Descargar cada archivo\n    for file in files:\n        file_name = file['Name']\n        file_url = file['ServerRelativeUrl']\n        download_url = f\"{sharepoint_base_url}/_api/web/GetFileByServerRelativeUrl('{file_url}')/$value\"\n        local_file_path = os.path.join(local_folder_path, file_name)\n\n        try:\n            file_response = session.get(download_url, timeout=30)  # Configurar timeout para cada descarga\n            file_response.raise_for_status()\n            with open(local_file_path, \"wb\") as local_file:\n                local_file.write(file_response.content)\n            logger.info(f\"Archivo descargado: {file_name}\")\n        except requests.exceptions.RequestException as e:\n            logger.error(f\"Error al descargar el archivo {file_name}. Detalles: {e}\")\n        time.sleep(1)  # A\u00f1adir un peque\u00f1o retraso entre descargas para evitar saturar el servidor\n\n    # Cerrar la sesi\u00f3n HTTP\n    session.close()\n</code></pre> <p><code>corregir_nombre_archivo</code> ajusta un nombre de archivo para cumplir con las restricciones del sistema de archivos. Reemplaza caracteres prohibidos (<code>\\ / : * ? \" &lt; &gt; |</code>) con guiones bajos, elimina guiones bajos consecutivos, y asegura que la longitud total no exceda los 255 caracteres. Retorna el nombre corregido.</p> <pre><code>def corregir_nombre_archivo(nuevo_nombre):\n    # Reemplazar caracteres prohibidos por un guion bajo\n    nuevo_nombre = re.sub(r'[\\\\/:*?\"&lt;&gt;|]', '_', nuevo_nombre)\n\n    # Reemplazar m\u00faltiples guiones bajos consecutivos por uno solo\n    nuevo_nombre = re.sub(r'_+', '_', nuevo_nombre)\n\n    # Limitar la longitud total a 255 caracteres\n    base_name, extension = os.path.splitext(nuevo_nombre)\n    if len(base_name) + len(extension) &gt; 255:\n        base_name = base_name[:127] + base_name[-(127 - len(extension)):]\n\n    # Retornar nombre corregido\n    return base_name + extension\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar","title":"Funci\u00f3n <code>procesar</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_6","title":"Prop\u00f3sito","text":"<p>Gestiona el procesamiento y renombrado de archivos en un directorio de descargas basado en un tipo de proceso ETL especificado. Los archivos se renombran seg\u00fan reglas espec\u00edficas y se cargan en una ubicaci\u00f3n correspondiente en SharePoint.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_6","title":"Entradas","text":"<ul> <li><code>etl</code> (str): Identificador del tipo de proceso ETL que determina las reglas de procesamiento y el destino en SharePoint.</li> <li><code>download_dir</code> (str): Ruta del directorio donde se encuentran los archivos a procesar.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_4","title":"Funcionamiento","text":"<ol> <li> <p>Iteraci\u00f3n sobre archivos:</p> <ul> <li>Procesa \u00fanicamente archivos con la extensi\u00f3n <code>.xlsx</code>.</li> <li>Intenta cargar y analizar cada archivo usando <code>openpyxl</code>.</li> </ul> </li> <li> <p>Reglas de procesamiento espec\u00edficas por ETL:</p> <ul> <li>Renombra los archivos bas\u00e1ndose en contenido de celdas espec\u00edficas o estructuras predefinidas.</li> <li>Aplica reglas personalizadas seg\u00fan el tipo de ETL, como extracci\u00f3n de fechas, nombres descriptivos o combinaci\u00f3n de valores en celdas.</li> </ul> </li> <li> <p>Renombrado de archivos:</p> <ul> <li>Genera nombres corregidos que cumplen con las restricciones del sistema de archivos.</li> <li>Verifica la existencia del archivo renombrado antes de continuar.</li> </ul> </li> <li> <p>Subida a SharePoint:</p> <ul> <li>Determina la carpeta de destino en SharePoint seg\u00fan el identificador ETL.</li> <li>Sube los archivos procesados a la carpeta correspondiente.</li> </ul> </li> <li> <p>Limpieza:</p> <ul> <li>Elimina archivos originales y temporales despu\u00e9s del procesamiento o subida.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_5","title":"Salida","text":"<ul> <li>No retorna valores. Registra mensajes en consola sobre el estado del procesamiento, subida o errores encontrados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#manejo-de-errores_1","title":"Manejo de errores","text":"<ul> <li>Captura y maneja excepciones en:</li> <li>Lectura y procesamiento de archivos.</li> <li>Renombrado de archivos.</li> <li>Subida a SharePoint.</li> <li>Registra detalles del error o marca archivos omitidos para su posterior revisi\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_1","title":"Consideraciones","text":"<ul> <li>Las reglas espec\u00edficas por ETL permiten flexibilidad para distintos tipos de procesamiento.</li> </ul> <pre><code>def procesar(etl, download_dir):\n    # Lista para almacenar las rutas completas de los archivos procesados y originales\n    archivos_a_subir = []\n\n    # Iterar sobre todos los archivos en el directorio de descargas\n    for archivo in os.listdir(download_dir):\n        if archivo.endswith('.xlsx'):  # Procesar solo archivos Excel\n            archivo_path = os.path.join(download_dir, archivo)\n            print(f\"Procesando archivo: {archivo}\")\n            # Intentar cargar el archivo Excel\n            try:\n                wb = load_workbook(archivo_path,data_only=True)\n                try:\n                    ws = wb.active\n                    fecha = datetime.now().strftime(\"%d_%m_%Y\")\n                    match etl:\n                        case \"C4C\":\n                            nuevo_nombre = f\"archivo_{fecha}.xlsx\"\n                            nuevo_path = os.path.join(download_dir, nuevo_nombre)\n                            os.makedirs(os.path.dirname(nuevo_path), exist_ok=True)  # Ensure directory exists\n\n                        case \"emp_Consolidado_inasistencias\":\n                            sede_jornada = ws['D6'].value.strip() if ws['D6'].value else \"SIN_SEDE\"\n                            curso = ws['F6'].value.strip() if ws['F6'].value else \"SIN_CURSO\"\n                            periodo = ws['M6'].value.strip() if ws['M6'].value else \"SIN_PERIODO\"\n\n                            nuevo_nombre = f\"Inasistencias_{sede_jornada}_{curso}_{periodo}_{fecha}.xlsx\"\n                            nuevo_path = os.path.join(download_dir, nuevo_nombre)\n                            os.makedirs(os.path.dirname(nuevo_path), exist_ok=True)  # Ensure directory exists\n\n                            if \"SIN\" in [sede_jornada, curso, periodo]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue\n\n                        case \"cede_Cancelados_Desertores\":\n                            # Filtrar y limpiar las fechas\n                            filtro_fechas = [cell.value for cell in ws['I'] if cell.value is not None and cell.value != 'Fecha']\n                            # Eliminar el primer valor si existe\n                            if filtro_fechas:\n                                filtro_fechas.pop(0)\n                            if not filtro_fechas:\n                                filtro_fechas = [cell.value for cell in ws['H'] if cell.value is not None and cell.value != 'Fecha']\n                            # Convertir todas las fechas a objetos datetime\n                            fechas = []\n                            for fecha in filtro_fechas:\n                                try:\n                                    if isinstance(fecha, str):\n                                        fechas.append(datetime.strptime(fecha, \"%d/%m/%Y\"))\n                                    elif isinstance(fecha, datetime):\n                                        fechas.append(fecha)\n                                except ValueError:\n                                    continue\n\n                            if fechas:\n                                fecha_inicio = min(fechas).strftime(\"%d_%m_%Y\")\n                                fecha_fin = max(fechas).strftime(\"%d_%m_%Y\")\n                                nuevo_nombre = f\"Cancelados_desertores_{fecha_inicio}_{fecha_fin}.xlsx\"\n                            else:\n                                fecha = datetime.now().strftime(\"%d_%m_%Y\")\n                                nuevo_nombre = f\"Cancelados_desertores_{fecha}.xlsx\"\n\n\n\n                        case \"cede_Dise\u00f1o_Curricular\":\n                            nuevo_nombre = f\"Dise\u00f1o_Curricular_{fecha}.xlsx\"\n\n\n                        case \"cede_Docentes\" | \"emp_Docentes\":\n                            nuevo_nombre = f\"Docentes_{fecha}.xlsx\"\n\n\n                        case \"cede_Egresados_Graduados\" | \"emp_Egresados_Graduados\":\n                            archivo_sin_ext = os.path.splitext(archivo)[0]\n                            nuevo_nombre = f\"{archivo_sin_ext}_{fecha}.xlsx\"\n\n                        case \"emp_Estudiantes_inasistencias\":\n                            periodo = ws['A7'].value.strip() if ws['A7'].value else \"SIN_DPTO\"\n                            periodo = periodo.replace(\":\", \"\").strip()\n                            nuevo_nombre = f\"emp_Estudiantes_inasistencias_{periodo}.xlsx\"\n\n\n                            if \"SIN_DPTO\" in [periodo]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue\n                        case \"cede_Historico_Notas\":\n                            periodo = ws['J5'].value.strip() if ws['J5'].value else \"SIN_CURSO\"\n                            nuevo_nombre = f\"Historico_Notas_{periodo}\"\n                            #elimina cualquier espacio en nuevo_nombre\n                            nuevo_nombre = nuevo_nombre.replace(\" \", \"\").replace(\"/\", \"_\").replace(\"-\", \"_\")\n                            #agrega un hash al final del nombre del archivo para que no se repitan\n                            nuevo_nombre = f\"{nuevo_nombre}_{os.urandom(4).hex()}_{fecha}.xlsx\"\n                            if \"SIN_CURSO\" in [periodo]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue\n                        case \"cede_Ingresos\":\n                            # nombre = \"Cajero: Todos  |  Desde: 01/01/2020  |  Hasta: 31/01/2020\"\n                            #estraer de nombre Todos_01_01_2020_31_01_2020\n                            nombre = ws['A7'].value.strip() if ws['A7'].value else \"SIN_CURSO\"\n                            nombre = nombre.replace(\"Cajero: \", \"\")\n                            nombre = nombre.replace(\"Todos\", \"Ingresos\")\n                            nombre = nombre.replace(\"  |  Desde: \", \"_\")\n                            nombre = nombre.replace(\"  |  Hasta: \", \"_\")\n                            nombre = nombre.replace(\"/\", \"_\")\n                            nombre = nombre.replace(\" \", \"\")\n\n                            nuevo_nombre = f\"{nombre}_{fecha}.xlsx\"\n\n\n                            if \"SIN_CURSO\" in [nombre]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue                            \n                            nuevo_nombre\n                        case \"cede_Listado_Matriculas\" | \"emp_Listado_Matriculas\":\n                            nombre = ws['A7'].value.strip() if ws['A7'].value else \"SIN_CURSO\"\n                            # texto de la celda Estado: Todos  |  Desde: 01/01/2016  |  Hasta: 31/12/2016\n                            #nombre final del archivo Listado_Matriculas_01_01_2016_31_12_2016\n                            nombre = nombre.replace(\"Estado: \", \"\")\n                            nombre = nombre.replace(\"Todos\", \"Listado_Matriculas\")                            \n                            nombre = nombre.replace(\"  |  Desde: \", \"_\")\n                            nombre = nombre.replace(\"  |  Hasta: \", \"_\")\n                            nombre = nombre.replace(\"/\", \"_\")\n                            nombre = nombre.replace(\" \", \"\")\n\n                            nuevo_nombre = f\"{nombre}_Act_{fecha}.xlsx\"\n\n\n                            if \"SIN_CURSO\" in [nombre]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue                            \n\n                        case \"emp_Preinscritos\":\n                            archivo_sin_ext = os.path.splitext(archivo)[0]\n                            nuevo_nombre = f\"{archivo_sin_ext}_{fecha}.xlsx\"                           \n                        case _:\n                            print(\"ETL no reconocido, se omite procesamiento.\")\n                            continue\n                except Exception as e:\n                    print(f\"Error al procesar el archivo {archivo}: {e}\")\n                    wb.close() \n                    continue\n                finally:\n                    wb.close()\n                nuevo_nombre = corregir_nombre_archivo(nuevo_nombre)\n                nuevo_path = os.path.join(download_dir, nuevo_nombre)\n                os.makedirs(os.path.dirname(nuevo_path), exist_ok=True)                \n                time.sleep(1)\n                if os.path.exists(nuevo_path):\n                    os.remove(nuevo_path)\n                time.sleep(1.5)  \n\n                # Intentar renombrar el archivo\n                try:\n                    os.rename(archivo_path, nuevo_path)\n                except Exception as e:\n                    print(f\"Error al renombrar el archivo: {e}\")\n                    # input(\"Presione Enter para continuar...\")\n\n                #Verificar que existe el nuevo archivo nuevo_nombre\n                if not os.path.exists(nuevo_path):\n                    print(f\"Error al procesar el archivo {nuevo_nombre}\")\n                    #pausa de teclado\n                    # input(\"Presione Enter para continuar...\")\n                else:\n                    print(f\"Archivo procesado y guardado como: {nuevo_nombre}\")\n                    archivos_a_subir.append(nuevo_path)\n                    # Eliminar el archivo original despu\u00e9s de procesarlo\n                    time.sleep(1)  # Pausa de 500ms\n                    os.remove(archivo_path)\n\n                print(f\"Archivo original eliminado: {archivo}\")\n\n            except Exception as e:\n                if not \"WinError 2\" in str(e):\n                    print(f\"Error al procesar el archivo {archivo}: {e}\")\n                # Agregar el archivo original a la lista de subida incluso si no se proces\u00f3\n                archivos_a_subir.append(archivo_path)\n            time.sleep(1)  # Pausa de 1 segundo entre archivos\n\n    etl_to_folder_url = {\n        \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n        \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n        \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n        \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n        \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n        \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n        \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n        \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n        \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n        \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n        \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n        \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n        \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados',\n        \"C4C\":'Documentos compartidos/02.C4C'   \n        }\n\n    folder_url = etl_to_folder_url.get(etl, \"URL por defecto si no se encuentra el valor de etl\")\n\n    for archivo in archivos_a_subir:\n        try:\n            upload_file_to_sharepoint(file_path=archivo, folder_url=folder_url)\n            time.sleep(1)  # Esperar 1 segundo \n            #pausa de teclado\n            # input(\"Presione Enter para continuar...\")\n            print(f\"Archivo subido a SharePoint: {archivo}\")\n            os.remove(archivo)\n            time.sleep(1)  # Esperar 1 segundo \n        except Exception as e:\n            if re.match(r'^[a-f0-9]{32}\\.xlsx$', archivo):\n                # Archivo codificado, no hacer logging\n                pass\n            else:        \n                print(f\"--Archivo {archivo}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-seleccionar_opcion_con_js","title":"Funci\u00f3n <code>seleccionar_opcion_con_js</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_7","title":"Prop\u00f3sito","text":"<p>Selecciona una opci\u00f3n en un men\u00fa desplegable (dropdown) utilizando JavaScript, lo que permite forzar la interacci\u00f3n en casos donde los m\u00e9todos est\u00e1ndar de Selenium pueden fallar.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_7","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador de Selenium para manejar el navegador.</li> <li><code>xpath_dropdown</code> (str): XPath del bot\u00f3n del dropdown que se desea abrir.</li> <li><code>opcion</code> (str): Texto exacto de la opci\u00f3n que se desea seleccionar en el men\u00fa desplegable.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_5","title":"Funcionamiento","text":"<ol> <li> <p>Abrir el dropdown:</p> <ul> <li>Localiza el elemento del dropdown mediante su XPath.</li> <li>Usa JavaScript para forzar la apertura del men\u00fa desplegable.</li> </ul> </li> <li> <p>Seleccionar la opci\u00f3n:</p> <ul> <li>Busca la opci\u00f3n deseada dentro del men\u00fa desplegable usando su texto.</li> <li>Utiliza JavaScript para hacer clic en la opci\u00f3n seleccionada.</li> </ul> </li> <li> <p>Manejo de tiempos:</p> <ul> <li>Incluye pausas breves entre las acciones para asegurar que los elementos se carguen correctamente.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li><code>TimeoutException</code>: Si el elemento tarda demasiado en cargarse.</li> <li><code>NoSuchElementException</code>: Si no se encuentra la opci\u00f3n especificada.</li> <li><code>Exception</code>: Captura cualquier otro error inesperado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_6","title":"Salida","text":"<ul> <li>No retorna valores. Registra en el log el estado del proceso, incluyendo \u00e9xito o errores. </li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_2","title":"Consideraciones","text":"<ul> <li>Es \u00fatil para casos donde los men\u00fas desplegables tienen comportamientos din\u00e1micos que dificultan su manejo con clics est\u00e1ndar de Selenium.</li> </ul> <pre><code>def seleccionar_opcion_con_js(driver, xpath_dropdown, opcion):\n    \"\"\"\n    Selecciona una opci\u00f3n en un dropdown utilizando JavaScript para forzar el cambio.\n\n    Args:\n        driver: Instancia del controlador de Selenium.\n        xpath_dropdown: XPath del bot\u00f3n del dropdown.\n        opcion: Texto de la opci\u00f3n a seleccionar.\n    \"\"\"\n    try:\n        # Encontrar el elemento dropdown\n        dropdown = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, xpath_dropdown)))\n\n        # Ejecutar JavaScript para abrir el dropdown\n        logging.info(f\"Abriendo dropdown ubicado en: {xpath_dropdown}\")\n        driver.execute_script(\"arguments[0].click();\", dropdown)\n        time.sleep(1)  # Breve pausa para permitir que el dropdown se abra\n\n        # Localizar la opci\u00f3n deseada en el men\u00fa desplegable\n        opcion_xpath = f\"//ul[contains(@class, 'dropdown-menu')]//span[text()='{opcion}']\"\n        opcion_elemento = WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.XPATH, opcion_xpath))\n        )\n\n        # Ejecutar JavaScript para hacer clic en la opci\u00f3n\n        logging.info(f\"Seleccionando opci\u00f3n: {opcion}\")\n        driver.execute_script(\"arguments[0].click();\", opcion_elemento)\n        time.sleep(5)  # Breve pausa para permitir que la opci\u00f3n se seleccione\n        logging.info(f\"Opci\u00f3n '{opcion}' seleccionada correctamente.\")\n    except TimeoutException as e:\n        logging.error(f\"Timeout al intentar seleccionar la opci\u00f3n '{opcion}' en el dropdown: {e}\")\n    except NoSuchElementException as e:\n        logging.error(f\"No se encontr\u00f3 la opci\u00f3n '{opcion}' en el dropdown: {e}\")\n    except Exception as e:\n        logging.error(f\"Error al seleccionar la opci\u00f3n '{opcion}': {e}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-configurar_pasos_autenticacion_des_empresarial","title":"Funci\u00f3n <code>configurar_pasos_autenticacion_des_empresarial</code>","text":"<p>Configura y devuelve una lista de pasos necesarios para autenticar al usuario en el sistema de Desarrollo Empresarial. </p> <p>Funcionamiento:</p> <ol> <li>Obtenci\u00f3n de credenciales: Recupera la URL, el nombre de usuario y la contrase\u00f1a mediante la funci\u00f3n <code>credenciales</code>.</li> <li>Definici\u00f3n de pasos:<ul> <li>Cada paso est\u00e1 representado como una tupla con:<ul> <li>Nombre del paso: Identificador descriptivo del paso.</li> <li>Funci\u00f3n decorada: Acci\u00f3n espec\u00edfica asociada al paso, como abrir la p\u00e1gina de inicio de sesi\u00f3n o ingresar credenciales.</li> <li>Par\u00e1metros: Diccionario con los argumentos requeridos por cada funci\u00f3n.</li> </ul> </li> </ul> </li> <li>Devoluci\u00f3n: Retorna una lista con los pasos configurados, lista para ejecutarse en un flujo de autenticaci\u00f3n.</li> </ol> <pre><code>def configurar_pasos_autenticacion_des_empresarial(driver):\n    \"\"\"\n    Configura y devuelve los pasos de autenticaci\u00f3n para acceder al sistema.\n    \"\"\"\n    # Configuraci\u00f3n de credenciales y URL de autenticaci\u00f3n\n    url, username, password = credenciales(\"desarrollo_empresarial\")\n    pasos_autenticacion = [\n        (\"abrir_pagina\", \n            log_step_decorator(\"abrir_pagina\")(open_login_page), \n            {\n                'driver': driver,\n                'url': url,\n                'wait_time': 10\n            }\n        ),\n        (\"ingresar_credenciales\", \n            log_step_decorator(\"ingresar_credenciales\")(enter_credentials), \n            {\n                'driver': driver,\n                'username': username,\n                'password': password,\n                'wait_time': 10\n            }\n        )\n    ]\n    return pasos_autenticacion\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-configurar_pasos_autenticacion_cedesarrollo","title":"Funci\u00f3n <code>configurar_pasos_autenticacion_cedesarrollo</code>","text":"<p>Configura y devuelve los pasos necesarios para autenticar al usuario en el sistema de Cedesarrollo.</p> <p>Funcionamiento:</p> <ol> <li>Obtenci\u00f3n de credenciales: Recupera la URL, el nombre de usuario y la contrase\u00f1a utilizando la funci\u00f3n <code>credenciales</code> con el identificador <code>\"cedesarrollo\"</code>.</li> <li>Definici\u00f3n de pasos: <ul> <li>Abrir p\u00e1gina: Usa <code>open_login_page</code> para cargar la URL del sistema.</li> <li>Ingresar credenciales: Utiliza <code>enter_credentials</code> para completar los campos de inicio de sesi\u00f3n con el nombre de usuario y la contrase\u00f1a.</li> <li>Cada paso incluye su nombre, la funci\u00f3n asociada decorada con <code>log_step_decorator</code>, y los par\u00e1metros requeridos.</li> </ul> </li> <li>Registro de informaci\u00f3n: Registra la URL utilizada en el log.</li> <li>Salida: Devuelve una lista de pasos configurados para ejecutar el flujo de autenticaci\u00f3n.</li> </ol> <pre><code>def configurar_pasos_autenticacion_cedesarrollo(driver):\n    \"\"\"\n    Configura y devuelve los pasos de autenticaci\u00f3n para acceder al sistema.\n    \"\"\"\n\n    # Configuraci\u00f3n de credenciales y URL de autenticaci\u00f3n\n    url, username, password = credenciales(\"cedesarrollo\")\n    # url = f\"https://site.q10.com/login?ReturnUrl=%2F&amp;aplentId=8fa60f3a-1a89-4048-a798-afd5cda72549\"\n    logging.info(f\"URL: {url}\")\n    pasos_autenticacion = [\n        (\"abrir_pagina\", \n            log_step_decorator(\"abrir_pagina\")(open_login_page), \n            {\n                'driver': driver,\n                'url': url,\n                'wait_time': 10\n            }\n        ),\n        (\"ingresar_credenciales\", \n            log_step_decorator(\"ingresar_credenciales\")(enter_credentials), \n            {\n                'driver': driver,\n                'username': username,\n                'password': password,\n                'wait_time': 10\n            }\n        )\n    ]\n    return pasos_autenticacion\n</code></pre> <p><code>esperar_y_renombrar_archivo</code> monitorea un directorio de descargas para detectar la aparici\u00f3n de un nuevo archivo, esperando hasta 10 segundos, y lo renombra con un nombre base especificado.</p> <p>Funcionamiento:</p> <ol> <li>Detecci\u00f3n de nuevos archivos:     -Obtiene la lista de archivos antes y despu\u00e9s de la espera.     -Identifica los archivos nuevos comparando ambas listas.</li> <li>Renombrar archivo:     -Si se encuentra un archivo nuevo, selecciona el m\u00e1s reciente seg\u00fan la fecha de creaci\u00f3n.     -Renombra el archivo con el nombre base y extensi\u00f3n proporcionados.</li> <li>Manejo de tiempos:     -Espera hasta 10 segundos, verificando cada segundo si hay un archivo nuevo.</li> <li>Resultados:     -Devuelve <code>True</code> si el archivo fue renombrado exitosamente.     -Devuelve <code>False</code> si no se encuentra un nuevo archivo dentro del tiempo l\u00edmite.</li> </ol> <p>Entradas: - <code>download_dir</code> (str): Ruta al directorio donde se espera el archivo. - <code>archivo</code> (str): Nombre base del archivo para renombrar.</p> <p>Salida: - <code>bool</code>: Indica si el renombrado fue exitoso (<code>True</code>) o no (<code>False</code>).</p> <pre><code>def esperar_y_renombrar_archivo(download_dir, archivo):\n    \"\"\"\n    Espera a que un archivo nuevo aparezca en el directorio de descargas y lo renombra.\n\n    Args:\n        download_dir (str): Directorio de descargas.\n        archivo (str): Nombre base del archivo.\n        opcion (str): Opci\u00f3n para renombrar el archivo.\n\n    Returns:\n        bool: True si el archivo fue renombrado exitosamente, False en caso contrario.\n    \"\"\"\n    archivos_antes = set(os.listdir(download_dir))\n\n    # Esperar a que un archivo nuevo aparezca en el directorio\n    for _ in range(10):\n        archivos_despues = set(os.listdir(download_dir))\n        archivos_nuevos = archivos_despues - archivos_antes  # Detectar nuevos archivos\n        if archivos_nuevos:\n            # Obtener el archivo nuevo m\u00e1s reciente\n            latest_file = max(archivos_nuevos, key=lambda f: os.path.getctime(os.path.join(download_dir, f)))\n            latest_file_path = os.path.join(download_dir, latest_file)\n\n            # Renombrar el archivo descargado\n            base_name, extension = os.path.splitext(archivo)\n            new_file_path = os.path.join(download_dir, f'{base_name}{extension}')\n            os.rename(latest_file_path, new_file_path)\n            logging.info(f\"Archivo renombrado a: {new_file_path}\")\n            return True\n        logging.info(\"Esperando que la descarga se complete...\")\n        time.sleep(1)\n\n    logging.error(\"No se encontr\u00f3 un archivo nuevo en el tiempo esperado.\")\n    return False\n</code></pre> <p><code>elemento_disponible</code> verifica si un elemento en el DOM es clickeable dentro de un tiempo de espera especificado. Recibe como argumentos el controlador de Selenium (<code>driver</code>), el tipo de localizador (<code>by</code>), el valor del localizador (<code>value</code>), y un tiempo m\u00e1ximo de espera (<code>timeout</code>). Retorna el elemento web si est\u00e1 disponible, o <code>None</code> en caso de que no sea clickeable en el tiempo especificado, registrando una advertencia en el log.</p> <pre><code>def elemento_disponible(driver, by, value, timeout=5):\n    \"\"\"\n    Verifica si un elemento est\u00e1 presente y es clickeable en el DOM dentro del tiempo especificado.\n\n    Args:\n        driver: Instancia del controlador de Selenium.\n        by: Tipo de localizaci\u00f3n (By.ID, By.XPATH, etc.).\n        value: Valor del localizador.\n        timeout: Tiempo m\u00e1ximo de espera (en segundos).\n\n    Returns:\n        WebElement si el elemento est\u00e1 disponible, None en caso contrario.\n    \"\"\"\n    try:\n        return WebDriverWait(driver, timeout).until(EC.element_to_be_clickable((by, value)))\n    except TimeoutException:\n        logging.warning(f\"Elemento no disponible: {value}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar_reporte_modal","title":"Funci\u00f3n <code>procesar_reporte_modal</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_8","title":"Prop\u00f3sito","text":"<p>Gestiona la exportaci\u00f3n de un reporte desde un modal con un <code>iframe</code>, descargando el archivo en formato <code>XLSX</code>, verificando su aparici\u00f3n en el directorio de descargas y renombr\u00e1ndolo con un nombre espec\u00edfico.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_8","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>download_dir</code> (str): Ruta del directorio de descargas donde se guardar\u00e1 el archivo.</li> <li><code>archivo</code> (str): Nombre con el que se renombrar\u00e1 el archivo descargado.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_6","title":"Funcionamiento","text":"<ol> <li> <p>Acceso al modal:</p> <ul> <li>Espera a que el modal sea visible y cambia al contexto del <code>iframe</code>.</li> </ul> </li> <li> <p>Interacci\u00f3n con el men\u00fa de exportaci\u00f3n:</p> <ul> <li>Hace clic en el elemento <code>exportSelect</code>.</li> <li>Intenta seleccionar la opci\u00f3n <code>XLSX</code>:</li> <li>Navega mediante teclas (flechas y Enter).</li> <li>Alternativamente, utiliza JavaScript para forzar la selecci\u00f3n.</li> </ul> </li> <li> <p>Gesti\u00f3n del archivo descargado:</p> <ul> <li>Verifica la aparici\u00f3n de nuevos archivos en el directorio de descargas.</li> <li>Renombra el archivo m\u00e1s reciente al nombre especificado (<code>archivo</code>).</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera o problemas al interactuar con elementos.</li> <li>Intenta cerrar el modal si ocurre un error.</li> </ul> </li> <li> <p>Finalizaci\u00f3n:</p> <ul> <li>Cierra el modal y regresa al contexto principal del navegador.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_7","title":"Salida","text":"<ul> <li>No retorna valores. Registra eventos y errores en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#manejo-de-errores_2","title":"Manejo de errores","text":"<ul> <li><code>TimeoutException</code>: Si un elemento no est\u00e1 disponible dentro del tiempo l\u00edmite.</li> <li><code>Exception</code>: Captura otros errores inesperados e intenta cerrar el modal.</li> </ul> <pre><code>def procesar_reporte_modal(driver, download_dir, archivo):\n    try:\n        # Esperar hasta que el modal est\u00e9 visible\n        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, \"master-modal\")))\n\n        # Cambiar al contexto del `iframe` dentro del modal\n        WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, \"report\")))\n\n        # Esperar hasta que el elemento 'exportSelect' est\u00e9 visible y hacer clic en \u00e9l\n        export_select = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"exportSelect\")))\n        export_select.click()\n        logging.info(\"Elemento exportSelect clickeado exitosamente.\")\n\n        # Espera adicional para que el men\u00fa de exportaci\u00f3n se despliegue\n        time.sleep(2)\n\n        # Intento 1: Navegar con teclas para seleccionar XLSX\n        export_select.send_keys(Keys.ARROW_DOWN)  # Baja una vez en el men\u00fa\n        export_select.send_keys(Keys.ARROW_DOWN)  # Baja dos veces (ajustar seg\u00fan sea necesario)\n        export_select.send_keys(Keys.ENTER)  # Seleccionar\n\n        logging.info(\"Intento de seleccionar XLSX usando teclas.\")\n\n        # Esperar unos segundos para que el efecto del clic se procese\n        time.sleep(2)\n\n        # Intento 2: Forzar clic en la opci\u00f3n 'XLSX' mediante JavaScript\n        try:\n            xlsx_option_js = driver.find_element(By.XPATH, \"//li[text()='XLSX']\")\n            driver.execute_script(\"arguments[0].click();\", xlsx_option_js)\n            logging.info(\"Opci\u00f3n XLSX seleccionada exitosamente mediante JavaScript.\")\n            time.sleep(2)\n\n\n            # Espera adicional para asegurar el procesamiento del cierre\n            time.sleep(2)\n\n            export_select.send_keys(Keys.ESCAPE)  # Baja una vez en el men\u00fa\n\n\n        except Exception as e:\n            logging.error(f\"No se pudo seleccionar la opci\u00f3n XLSX con JavaScript:\")\n\n        time.sleep(2)\n\n        # Verificar y renombrar el archivo\n        archivos_antes = set(os.listdir(download_dir))\n\n        #eliminar archivo anterior\n        # Eliminar solo el archivo espec\u00edfico si existe\n        file_path = os.path.join(download_dir, archivo)\n        if os.path.exists(file_path):\n            os.remove(file_path)\n            logging.info(f\"Archivo {archivo} eliminado correctamente\")\n\n        for _ in range(2):  # Reducir el tiempo de espera a m\u00e1ximo 5 segundos\n            time.sleep(1)  # Intervalos m\u00e1s cortos\n            archivos_despues = set(os.listdir(download_dir))\n            archivos_nuevos = archivos_despues - archivos_antes\n\n            if archivos_nuevos:\n                # Detectar el archivo m\u00e1s reciente\n                latest_file = max(\n                    archivos_nuevos,\n                    key=lambda f: os.path.getctime(os.path.join(download_dir, f))\n                )\n                latest_file_path = os.path.join(download_dir, latest_file)\n\n                # Renombrar el archivo descargado\n                base_name, extension = os.path.splitext(archivo)\n                new_file_path = os.path.join(download_dir, f'{base_name}{extension or \".xlsx\"}')\n\n                os.rename(latest_file_path, new_file_path)\n                logging.info(f\"Archivo renombrado a: {new_file_path}\")\n                break # Salir del bucle si se renombr\u00f3 correctamente\n        logging.warning(\"No se detect\u00f3 un nuevo archivo en el tiempo l\u00edmite.\")        \n        # Espera adicional para asegurar el procesamiento de la selecci\u00f3n\n        time.sleep(2)\n    except TimeoutException as te:\n        logging.error(f\"Tiempo de espera excedido al procesar el reporte: {te}\")\n    except Exception as e:\n        logging.error(f\"Error al procesar el reporte en el iframe: {e}\")\n        # Esperar hasta que el elemento 'exportSelect' est\u00e9 visible y hacer clic en \u00e9l\n        export_select = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"close\")))\n        export_select.click()\n    finally:\n        # Esperar hasta que el elemento 'exportSelect' est\u00e9 visible y hacer clic en \u00e9l\n        export_select = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"close\")))\n        export_select.click()\n        # Regresar al contexto principal si necesitas realizar m\u00e1s acciones fuera del iframe\n        driver.switch_to.default_content()\n</code></pre> <p><code>normalizar_texto</code> elimina tildes y caracteres especiales de un texto dado. Utiliza <code>unicodedata.normalize</code> para convertir caracteres Unicode a una representaci\u00f3n compatible con ASCII, eliminando acentos y caracteres no est\u00e1ndar. Retorna el texto normalizado.</p> <pre><code>def normalizar_texto(texto):\n    \"\"\"\n    Normaliza un texto eliminando tildes y caracteres especiales.\n    \"\"\"\n    return unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n</code></pre> <p><code>ejecutar_pasos</code> ejecuta de forma secuencial una lista de pasos definidos. Cada paso es una tupla que contiene el nombre del paso (<code>step_name</code>), la funci\u00f3n a ejecutar (<code>step_function</code>), y un diccionario de par\u00e1metros (<code>params</code>). Registra el nombre de cada paso antes de ejecutarlo y llama a la funci\u00f3n correspondiente con los par\u00e1metros proporcionados.</p> <pre><code>\"\"\"\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n\"\"\"\n        # Ejecutar cada uno de los pasos definidos en el diccionario\ndef ejecutar_pasos(pasos):\n    for step_name, step_function, params in pasos:\n        logging.info(f\"Ejecutando el paso: {step_name}\")\n        step_function(**params)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar_opciones_descarga","title":"Funci\u00f3n <code>procesar_opciones_descarga</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_9","title":"Prop\u00f3sito","text":"<p>Automatiza la selecci\u00f3n de opciones en un men\u00fa desplegable (dropdown), descarga los archivos correspondientes y los renombra con base en las opciones seleccionadas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_9","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Controlador de Selenium para manejar el navegador.</li> <li><code>opciones</code> (list): Lista de opciones del dropdown.</li> <li><code>xpath_boton</code> (str): XPath del bot\u00f3n para abrir el dropdown.</li> <li><code>id_descargar</code> (str): ID del bot\u00f3n de descarga.</li> <li><code>nombre_archivo</code> (str): Nombre base del archivo para el renombrado.</li> <li><code>nombre_archivo_completo</code> (str): Nombre completo del archivo descargado.</li> <li><code>download_dir</code> (str): Directorio donde se guardan las descargas.</li> <li><code>wait_time</code> (int): Tiempo de espera despu\u00e9s de cada acci\u00f3n (por defecto 2 segundos).</li> <li><code>xpath_omitir</code> (str, opcional): XPath para omitir popups opcionales.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_7","title":"Funcionamiento","text":"<ol> <li> <p>Preparaci\u00f3n inicial:</p> <ul> <li>Llama a <code>eliminar_archivos_anteriores</code> para limpiar descargas previas en el directorio.</li> </ul> </li> <li> <p>Interacci\u00f3n con el dropdown:</p> <ul> <li>Hace clic en el bot\u00f3n del dropdown para abrirlo.</li> <li>Itera sobre las opciones de la lista:</li> <li>Selecciona una opci\u00f3n usando <code>seleccionar_opcion_custom_dropdown</code>.</li> </ul> </li> <li> <p>Descarga de archivos:</p> <ul> <li>Para cada opci\u00f3n seleccionada:</li> <li>Si el tipo es <code>\"modal\"</code>, procesa la descarga mediante <code>procesar_reporte_modal</code>.</li> <li>En otros casos, utiliza <code>cola_descargar</code> para manejar la descarga y verificarla.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_8","title":"Salida","text":"<ul> <li>No retorna valores. Realiza acciones relacionadas con selecci\u00f3n, descarga y renombrado de archivos.</li> </ul> <pre><code>def procesar_opciones_descarga(driver, opciones, xpath_boton, id_descargar, nombre_archivo, tipo, nombre_archivo_completo, download_dir, wait_time=2, xpath_omitir=None):\n    \"\"\"\n    Itera sobre las opciones de un dropdown, selecciona cada opci\u00f3n, descarga el archivo\n    y renombra el archivo descargado con la opci\u00f3n seleccionada.\n\n    Args:\n        driver (WebDriver): El controlador de Selenium.\n        opciones (list): Lista de opciones del dropdown.\n        xpath_boton (str): XPath del bot\u00f3n para abrir el dropdown.\n        id_descargar (str): ID del bot\u00f3n de descarga.\n        nombre_archivo (str): Nombre base del archivo para renombrar.\n        nombre_archivo_completo (str): Nombre completo del archivo descargado.\n        download_dir (str): Directorio donde se guardan las descargas.\n        wait_time (int): Tiempo de espera despu\u00e9s de cada acci\u00f3n.\n        xpath_omitir (str): XPath opcional para omitir un popup.\n    \"\"\"\n    # Llamada a eliminar archivos anteriores usando el directorio especificado\n    eliminar_archivos_anteriores(nombre_archivo_completo, download_dir=download_dir)\n\n    # Clic en el bot\u00f3n de apertura del dropdown\n    hacer_clic(driver=driver, xpath=xpath_boton, wait_time=5)\n\n    # Itera sobre las opciones para seleccionar y descargar\n    for opcion in opciones:\n        seleccionar_opcion_custom_dropdown(driver=driver, xpath=xpath_boton, option=opcion, wait_time=wait_time)\n\n        # Descargar el archivo\n        if tipo == \"modal\":\n            procesar_reporte_modal(driver)\n        else:\n            se_descargo = cola_descargar(opcion=opcion,download_dir= download_dir,driver=driver, id=id_descargar, archivo=nombre_archivo_completo, wait_time=15, xpath_omitir=xpath_omitir)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-setup_driver","title":"Funci\u00f3n <code>setup_driver</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_10","title":"Prop\u00f3sito","text":"<p>Configura un controlador de Selenium con opciones personalizadas, estableciendo un directorio espec\u00edfico para las descargas de archivos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_10","title":"Entradas","text":"<ul> <li><code>subcarpeta</code> (str): Nombre de la subcarpeta dentro del directorio de descargas base donde se guardar\u00e1n los archivos (por defecto: <code>\"default\"</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_8","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n del directorio de descargas:</p> <ul> <li>Construye la ruta completa para las descargas en la subcarpeta especificada, ubicada dentro de <code>01.Q10/Procesados</code>.</li> <li>Crea el directorio si no existe y registra su creaci\u00f3n o existencia en el log.</li> </ul> </li> <li> <p>Configuraci\u00f3n de Chrome:</p> <ul> <li>Define preferencias espec\u00edficas para descargas:</li> <li>Descargas autom\u00e1ticas sin confirmaci\u00f3n.</li> <li>Actualizaci\u00f3n del directorio de descargas.</li> <li>Habilitaci\u00f3n de la navegaci\u00f3n segura.</li> <li>A\u00f1ade configuraciones para optimizar el navegador:</li> <li>Maximizaci\u00f3n de ventana.</li> <li>Deshabilitaci\u00f3n de caracter\u00edsticas innecesarias y controles autom\u00e1ticos.</li> </ul> </li> <li> <p>Inicia el controlador de Selenium:</p> <ul> <li>Configura un tiempo de espera para la carga de p\u00e1ginas (30 segundos).</li> <li>Registra la configuraci\u00f3n del controlador y la ruta de descargas en el log.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Retorna la instancia del controlador <code>driver</code> y la ruta completa del directorio de descargas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_9","title":"Salida","text":"<ul> <li><code>driver</code> (WebDriver): Instancia configurada del controlador de Selenium.</li> <li><code>download_dir</code> (str): Ruta absoluta del directorio de descargas configurado.</li> </ul> <pre><code>DOWNLOAD_DIR = os.path.join(os.path.abspath(os.getcwd()), \"Procesados\")\n\ndef setup_driver(subcarpeta=\"default\"):\n    \"\"\"\n    Configura el controlador de Selenium y crea la ruta de descargas en la subcarpeta especificada.\n    \"\"\"\n    # Define la ruta completa de descarga en la subcarpeta especificada\n    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # Subir un nivel desde `Codigos`\n    download_dir = os.path.join(base_dir, \"01.Q10\", \"Procesados\", subcarpeta)  # Ruta hacia `01.Q10\\Procesados`\n\n    # Crear el directorio si no existe\n    if not os.path.exists(download_dir):\n        os.makedirs(download_dir)\n        logging.info(f\"Directorio de descargas creado en: {download_dir}\")\n    else:\n        logging.info(f\"Directorio de descargas ya existe: {download_dir}\")\n\n    # Configura las preferencias de Chrome para las descargas\n    chrome_options = webdriver.ChromeOptions()\n    prefs = {\n        \"download.default_directory\": download_dir,\n        \"download.prompt_for_download\": False,\n        \"download.directory_upgrade\": True,\n        \"safebrowsing.enabled\": True\n    }\n    chrome_options.add_experimental_option(\"prefs\", prefs)\n    chrome_options.add_argument('--disable-gpu')\n    chrome_options.add_argument('--no-sandbox')\n    chrome_options.add_argument('--disable-dev-shm-usage')\n    chrome_options.add_argument('--window-size=1920x1080')\n    chrome_options.add_argument('--ignore-certificate-errors')\n    chrome_options.add_argument('--disable-extensions')\n    chrome_options.add_argument('--disable-infobars')\n    chrome_options.add_argument('--start-maximized')\n    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n\n    # Inicia el controlador\n    driver = webdriver.Chrome(options=chrome_options)\n    driver.set_page_load_timeout(30)\n    logging.info(f\"Controlador de Selenium configurado con el directorio de descargas en: {download_dir}\")\n\n    # Retorna el controlador y la ruta de descarga\n    return driver, download_dir\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-setup_driver_c4c","title":"Funci\u00f3n <code>setup_driver_C4C</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_11","title":"Prop\u00f3sito","text":"<p>Configura un controlador de Selenium para automatizaciones en el entorno C4C, estableciendo un directorio espec\u00edfico para descargas en una subcarpeta determinada.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_11","title":"Entradas","text":"<ul> <li><code>subcarpeta</code> (str): Nombre de la subcarpeta dentro del directorio base de descargas, donde se almacenar\u00e1n los archivos (por defecto: <code>\"default\"</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_9","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n del directorio de descargas:</p> <ul> <li>Construye la ruta completa del directorio de descargas en <code>02.C4C/Procesados</code>.</li> <li>Crea el directorio si no existe y registra el resultado en el log.</li> </ul> </li> <li> <p>Configuraci\u00f3n del navegador Chrome:</p> <ul> <li>Define preferencias para la gesti\u00f3n autom\u00e1tica de descargas:</li> <li>Descargas sin solicitud de confirmaci\u00f3n.</li> <li>Navegaci\u00f3n segura habilitada.</li> <li>Actualizaci\u00f3n autom\u00e1tica del directorio de descargas.</li> <li>Configura argumentos adicionales para optimizar el rendimiento y la experiencia del navegador:</li> <li>Maximiza la ventana y deshabilita extensiones y notificaciones innecesarias.</li> </ul> </li> <li> <p>Inicia el controlador de Selenium:</p> <ul> <li>Configura un tiempo de espera m\u00e1ximo para la carga de p\u00e1ginas (30 segundos).</li> <li>Registra en el log la ruta de descargas y la configuraci\u00f3n del controlador.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Retorna el controlador <code>driver</code> y la ruta absoluta del directorio de descargas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_10","title":"Salida","text":"<ul> <li><code>driver</code> (WebDriver): Instancia configurada del controlador de Selenium.</li> <li><code>download_dir</code> (str): Ruta completa del directorio de descargas configurado.</li> </ul> <pre><code># En Funciones.py\ndef setup_driver_C4C(subcarpeta=\"default\"):\n    \"\"\"\n    Configura el controlador de Selenium y crea la ruta de descargas en la subcarpeta especificada.\n    \"\"\"\n    # Define la ruta completa de descarga en la subcarpeta especificada\n    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # Subir un nivel desde `Codigos`\n    download_dir = os.path.join(base_dir, \"02.C4C\", \"Procesados\", subcarpeta)  # Ruta hacia `01.Q10\\Procesados`\n\n    # Crear el directorio si no existe\n    if not os.path.exists(download_dir):\n        os.makedirs(download_dir)\n        logging.info(f\"Directorio de descargas creado en: {download_dir}\")\n    else:\n        logging.info(f\"Directorio de descargas ya existe: {download_dir}\")\n\n    # Configura las preferencias de Chrome para las descargas\n    chrome_options = webdriver.ChromeOptions()\n    prefs = {\n        \"download.default_directory\": download_dir,\n        \"download.prompt_for_download\": False,\n        \"download.directory_upgrade\": True,\n        \"safebrowsing.enabled\": True\n    }\n    chrome_options.add_experimental_option(\"prefs\", prefs)\n    chrome_options.add_argument('--disable-gpu')\n    chrome_options.add_argument('--no-sandbox')\n    chrome_options.add_argument('--disable-dev-shm-usage')\n    chrome_options.add_argument('--window-size=1920x1080')\n    chrome_options.add_argument('--ignore-certificate-errors')\n    chrome_options.add_argument('--disable-extensions')\n    chrome_options.add_argument('--disable-infobars')\n    chrome_options.add_argument('--start-maximized')\n    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n\n    # Inicia el controlador\n    driver = webdriver.Chrome(options=chrome_options)\n    driver.set_page_load_timeout(30)\n    logging.info(f\"Controlador de Selenium configurado con el directorio de descargas en: {download_dir}\")\n\n    # Retorna el controlador y la ruta de descarga\n    return driver, download_dir\n</code></pre> <p><code>open_login_page</code> abre una p\u00e1gina de inicio de sesi\u00f3n en un navegador controlado por Selenium y espera a que el cuerpo de la p\u00e1gina se cargue completamente. Recibe el controlador (<code>driver</code>), la URL de la p\u00e1gina a abrir (<code>url</code>) y un tiempo de espera opcional (<code>wait_time</code>). Registra en el log tanto el inicio como la confirmaci\u00f3n de que la p\u00e1gina se ha abierto correctamente.</p> <pre><code>def open_login_page(driver, url, wait_time=2):\n    logger.info(f\"Abriendo la p\u00e1gina de inicio de sesi\u00f3n: {url}\")\n    driver.get(url)\n    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n    logger.info(f\"P\u00e1gina de inicio de sesi\u00f3n abierta: {url}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-enter_credentials","title":"Funci\u00f3n <code>enter_credentials</code>","text":"<p>Automatiza el ingreso de credenciales en una p\u00e1gina de inicio de sesi\u00f3n controlada por Selenium. </p> <p>Funcionamiento:</p> <ol> <li> <p>Ingreso del nombre de usuario:</p> <ul> <li>Espera hasta que el campo de entrada de usuario est\u00e9 presente (<code>NombreUsuario</code>).</li> <li>Ingresa el valor proporcionado en <code>username</code>.</li> </ul> </li> <li> <p>Ingreso de la contrase\u00f1a:</p> <ul> <li>Espera hasta que el campo de entrada de contrase\u00f1a est\u00e9 presente (<code>Contrasena</code>).</li> <li>Ingresa el valor proporcionado en <code>password</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas, y registra el error en el log antes de lanzarlo nuevamente.</li> </ul> </li> </ol> <p>Entradas:</p> <ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>username</code> (str): Nombre de usuario a ingresar.</li> <li><code>password</code> (str): Contrase\u00f1a asociada al usuario.</li> <li><code>wait_time</code> (int, opcional): Tiempo de espera entre interacciones (por defecto, 1 segundo).</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Realiza acciones y registra eventos o errores en el log.</li> </ul> <pre><code>def enter_credentials(driver, username, password, wait_time=1):\n    # Ingresa las credenciales de usuario en los campos correspondientes\n    try:\n        logging.info(\"Ingresando usuario\")\n        # Esperar hasta que el campo de nombre de usuario est\u00e9 presente y luego ingresar el nombre de usuario\n        username_field = WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.NAME, 'NombreUsuario'))\n        )\n        username_field.send_keys(username)\n        logging.info(\"Nombre de usuario ingresado correctamente\")\n\n        logging.info(\"Ingresando contrase\u00f1a\")\n        # Esperar hasta que el campo de contrase\u00f1a est\u00e9 presente y luego ingresar la contrase\u00f1a\n        password_field = WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.NAME, 'Contrasena'))\n        )\n        password_field.send_keys(password)\n        logging.info(\"Credenciales ingresadas correctamente\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error durante el ingreso de credenciales: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-submit_login","title":"Funci\u00f3n <code>submit_login</code>","text":"<p>Env\u00eda el formulario de inicio de sesi\u00f3n en una p\u00e1gina web controlada por Selenium y verifica que el inicio de sesi\u00f3n haya sido exitoso.</p> <p>Funcionamiento:</p> <ol> <li> <p>Interacci\u00f3n con el bot\u00f3n de inicio de sesi\u00f3n:</p> <ul> <li>Espera hasta que el bot\u00f3n del formulario est\u00e9 presente y sea clickeable (<code>//button[@type=\"submit\"]</code>).</li> <li>Hace clic en el bot\u00f3n para enviar el formulario.</li> </ul> </li> <li> <p>Verificaci\u00f3n del inicio de sesi\u00f3n:</p> <ul> <li>Espera a que un elemento indicativo del post-login (<code>elemento_post_login</code>) est\u00e9 presente para confirmar el \u00e9xito.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o no interactuables, registra el error en el log y lanza nuevamente la excepci\u00f3n.</li> </ul> </li> </ol> <p>Entradas:</p> <ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>wait_time</code> (int, opcional): Tiempo de espera entre interacciones (por defecto, 3 segundos).</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Realiza acciones en la p\u00e1gina y registra en el log el estado del proceso o errores.</li> </ul> <pre><code>def submit_login(driver, wait_time=3):\n    # Env\u00eda el formulario de inicio de sesi\u00f3n\n    try:\n        logging.info(\"Enviando formulario de inicio de sesi\u00f3n\")\n        # Esperar hasta que el bot\u00f3n de inicio de sesi\u00f3n est\u00e9 presente y luego hacer clic\n        login_button = WebDriverWait(driver, 10).until(\n            EC.element_to_be_clickable((By.XPATH, '//button[@type=\"submit\"]'))\n        )\n        login_button.click()\n        # Esperar hasta que un elemento post-login est\u00e9 presente para confirmar el \u00e9xito del inicio de sesi\u00f3n\n        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'elemento_post_login')))\n        logging.info(\"Formulario de inicio de sesi\u00f3n enviado\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException) as e:\n        logging.error(f\"Error al enviar el formulario de inicio de sesi\u00f3n: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-close_driver","title":"Funci\u00f3n <code>close_driver</code>","text":"<p>Cierra de manera segura el navegador controlado por Selenium.</p> <p>Funcionamiento:</p> <ol> <li> <p>Cierre del navegador:</p> <ul> <li>Intenta cerrar la instancia del controlador mediante <code>driver.quit()</code>.</li> <li>Registra en el log que el navegador se cerr\u00f3 correctamente.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura posibles excepciones (<code>WebDriverException</code>) durante el cierre y registra el error en el log.</li> </ul> </li> </ol> <p>Entradas:</p> <ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium que se desea cerrar.</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Realiza la acci\u00f3n de cierre y registra el estado del proceso en el log.</li> </ul> <pre><code>def close_driver(driver):\n    # Cierra el navegador de manera segura\n    logging.info(\"Cerrando el navegador\")\n    try:\n        driver.quit()\n        logging.info(\"Navegador cerrado correctamente\")\n    except WebDriverException as e:\n        logging.error(f\"Error al cerrar el navegador: {e}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-seleccionar_dropdown","title":"Funci\u00f3n <code>seleccionar_dropdown</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_12","title":"Prop\u00f3sito","text":"<p>Selecciona una opci\u00f3n de un men\u00fa desplegable (<code>dropdown</code>) en una p\u00e1gina web controlada por Selenium, utilizando diversos identificadores de localizaci\u00f3n.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_12","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para configurar la selecci\u00f3n:</li> <li><code>option</code> (str): Texto visible de la opci\u00f3n a seleccionar.</li> <li><code>n_option</code> (int): \u00cdndice de la opci\u00f3n a seleccionar.</li> <li><code>wait_time</code> (int, opcional): Tiempo en segundos para esperar despu\u00e9s de realizar la selecci\u00f3n (por defecto: <code>0</code>).</li> <li>Localizadores: Uno de los siguientes:<ul> <li><code>xpath</code> (str): Localizaci\u00f3n del dropdown usando XPath.</li> <li><code>id</code> (str): Identificaci\u00f3n del elemento.</li> <li><code>name</code> (str): Nombre del elemento.</li> <li><code>class_name</code> (str): Clase del elemento.</li> <li><code>css_selector</code> (str): Selector CSS.</li> </ul> </li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_10","title":"Funcionamiento","text":"<ol> <li> <p>Localizaci\u00f3n del dropdown:</p> <ul> <li>Determina el tipo de localizador (<code>id</code>, <code>xpath</code>, etc.) y su valor.</li> <li>Encuentra el elemento correspondiente en el DOM usando <code>WebDriverWait</code>.</li> </ul> </li> <li> <p>Selecci\u00f3n de la opci\u00f3n:</p> <ul> <li>Si se proporciona <code>option</code>, selecciona la opci\u00f3n por texto visible.</li> <li>Si se proporciona <code>n_option</code>, selecciona la opci\u00f3n por \u00edndice.</li> <li>Lanza un error si no se proporciona ninguna opci\u00f3n v\u00e1lida.</li> </ul> </li> <li> <p>Espera opcional:</p> <ul> <li>Realiza una pausa tras la selecci\u00f3n si se especifica <code>wait_time</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas.</li> <li>Registra el error en el log y lanza la excepci\u00f3n.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_11","title":"Salida","text":"<ul> <li>No retorna valores. Realiza la selecci\u00f3n en el dropdown y registra el estado del proceso en el log.</li> </ul> <pre><code>def seleccionar_dropdown(driver, **kwargs):\n    try:\n        logging.info(f\"Seleccionando opci\u00f3n del dropdown especificado\")\n\n        # Recoger 'wait_time' de kwargs o establecer un valor por defecto\n        wait_time = kwargs.get('wait_time', 0)\n\n        # Recorrer las posibles opciones de identificador y localizar el elemento\n        locator_type, locator_value, option_value, n_option = None, None, None, None\n        for key, value in kwargs.items():\n            if key == 'option':\n                option_value = value\n            elif key == 'n_option':\n                n_option = value\n            elif value is not None and key != 'wait_time':\n                locator_type = key\n                locator_value = value\n\n        # Verificar si se proporcion\u00f3 un localizador v\u00e1lido\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar una ubicaci\u00f3n v\u00e1lida para seleccionar un dropdown\")\n\n        # Convertir el identificador a By adecuado\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR\n        }\n        dropdown_element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((by_mapping[locator_type], locator_value)))\n        select = Select(dropdown_element)\n\n        # Seleccionar la opci\u00f3n por texto visible o por \u00edndice\n        if option_value is not None:\n            select.select_by_visible_text(option_value)\n            logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente en el dropdown\")\n        elif n_option is not None:\n            select.select_by_index(n_option)\n            logging.info(f\"Opci\u00f3n en el \u00edndice '{n_option}' seleccionada correctamente en el dropdown\")\n        else:\n            raise ValueError(\"Debe proporcionar un valor v\u00e1lido para seleccionar una opci\u00f3n en el dropdown\")\n\n        # Esperar el tiempo especificado si se proporcion\u00f3\n        if wait_time &gt; 0:\n            time.sleep(wait_time)\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al seleccionar la opci\u00f3n del dropdown: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-hacer_clic","title":"Funci\u00f3n <code>hacer_clic</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_13","title":"Prop\u00f3sito","text":"<p>Localiza un elemento en una p\u00e1gina web mediante un tipo de localizador, realiza clic en \u00e9l y, opcionalmente, interact\u00faa con un campo de entrada configurando un valor.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_13","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para la operaci\u00f3n:</li> <li>Localizadores (uno obligatorio):<ul> <li><code>xpath</code> (str): Localizaci\u00f3n del elemento mediante XPath.</li> <li><code>id</code> (str): Identificaci\u00f3n del elemento.</li> <li><code>name</code> (str): Nombre del elemento.</li> <li><code>class_name</code> (str): Clase CSS del elemento.</li> <li><code>css_selector</code> (str): Selector CSS del elemento.</li> <li><code>link_text</code> (str): Texto completo del enlace.</li> <li><code>partial_link_text</code> (str): Texto parcial del enlace.</li> <li><code>tag_name</code> (str): Nombre de la etiqueta del elemento.</li> </ul> </li> <li><code>value</code> (opcional): Valor para ingresar en un campo de entrada.</li> <li><code>wait_time</code> (int, opcional): Tiempo de espera despu\u00e9s de realizar la acci\u00f3n (por defecto: 2 segundos).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_11","title":"Funcionamiento","text":"<ol> <li> <p>Identificaci\u00f3n del elemento:</p> <ul> <li>Determina el tipo y valor del localizador (<code>locator_type</code> y <code>locator_value</code>) a partir de los argumentos proporcionados.</li> <li>Utiliza <code>WebDriverWait</code> para esperar hasta que el elemento sea clickeable.</li> <li>Si no se encuentra el elemento, registra una advertencia en el log y retorna <code>None</code>.</li> </ul> </li> <li> <p>Clic en el elemento:</p> <ul> <li>Realiza clic en el elemento localizado y espera el tiempo especificado (<code>wait_time</code>).</li> </ul> </li> <li> <p>Interacci\u00f3n con campos de entrada:</p> <ul> <li>Si el elemento es un campo de entrada (<code>&lt;input&gt;</code>) y se proporciona un valor (<code>value</code>):</li> <li>Si el valor es un objeto <code>datetime</code>, lo formatea como cadena (<code>'%d/%m/%Y'</code>).</li> <li>Limpia el campo, establece el valor, y registra la acci\u00f3n en el log.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas.</li> <li>Registra los errores en el log y retorna sin lanzar la excepci\u00f3n.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_12","title":"Salida","text":"<ul> <li><code>None</code>: Si el elemento no se encuentra o hay un error durante la operaci\u00f3n.</li> <li>Registra en el log el estado del proceso (clic o interacci\u00f3n con el campo de entrada).</li> </ul> <pre><code>def hacer_clic(driver, **kwargs):\n    try:\n        locator_type = None\n        locator_value = None\n        input_value = kwargs.get('value')\n        wait_time = kwargs.get('wait_time', 2)  # Manejar 'wait_time' con valor por defecto\n\n        for key, value in kwargs.items():\n            if key == 'value':\n                continue  # Ya se maneja 'value' arriba\n            elif key in ['xpath', 'id', 'name', 'class_name', 'css_selector', 'link_text', 'partial_link_text', 'tag_name']:\n                locator_type = key\n                locator_value = value\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos\")\n\n        # Convertir el identificador a By adecuado\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n        try:\n            elemento = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((by_mapping[locator_type], locator_value)))\n        except TimeoutException:\n            elemento = None\n            logging.warning(f\"Elemento no encontrado: {locator_type} = {locator_value}\")\n            #FINALIZAR retornando error\n            return None\n\n        logging.info(f\"Elemento localizado, realizando clic en {locator_type}: {locator_value}\")\n        elemento.click()\n        time.sleep(wait_time)\n        logging.info(f\"Clic realizado correctamente en {locator_type}: {locator_value}\")\n\n        # Si el elemento es un input y se proporcion\u00f3 un valor de fecha, formatear correctamente\n        if elemento.tag_name == 'input' and input_value is not None:\n            if isinstance(input_value, datetime):\n                input_value = input_value.strftime('%d/%m/%Y')  # Convertir datetime a cadena de texto\n\n            elemento.clear()\n            elemento.send_keys(input_value)\n            logging.info(f\"Valor '{input_value}' establecido en el elemento input correctamente\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        # logging.error(f\"Error al intentar hacer clic en el elemento con {locator_type}: {locator_value} - Detalles: {e}\")\n        logging.error(f\"Error al intentar hacer clic en el elemento con {locator_type}: {locator_value} \")\n        #raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-hacer_clic_modal","title":"Funci\u00f3n <code>hacer_clic_modal</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_14","title":"Prop\u00f3sito","text":"<p>Interact\u00faa con un modal en una p\u00e1gina web controlada por Selenium, localizando y haciendo clic en un elemento dentro del modal. Opcionalmente, permite realizar acciones adicionales dentro del modal y gestionar cambios de contexto hacia y desde un <code>iframe</code>.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_14","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Par\u00e1metros clave para la operaci\u00f3n:</li> <li><code>xpath_modal</code> (str, requerido): Localizador del modal usando XPath.</li> <li><code>iframe</code> (str, opcional): Nombre del iframe al que cambiar el contexto.</li> <li><code>elementos</code> (list, opcional): Lista de pasos adicionales a ejecutar dentro del modal. Cada paso debe estar definido como una tupla <code>(nombre_paso, funci\u00f3n, par\u00e1metros)</code>.</li> <li>Localizadores: <ul> <li><code>xpath</code> (str): XPath del elemento a interactuar.</li> <li><code>id</code>, <code>name</code>, <code>class_name</code>, <code>css_selector</code>, <code>link_text</code>, <code>partial_link_text</code>, <code>tag_name</code> (str): Alternativas de localizaci\u00f3n del elemento.</li> </ul> </li> <li><code>wait_time</code> (int, opcional): Tiempo de espera en segundos tras realizar la acci\u00f3n (por defecto: <code>2</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_12","title":"Funcionamiento","text":"<ol> <li> <p>Cambio al <code>iframe</code> (opcional):</p> <ul> <li>Si se proporciona un <code>iframe</code>, cambia al contexto del iframe indicado antes de realizar otras operaciones.</li> </ul> </li> <li> <p>Localizaci\u00f3n del modal:</p> <ul> <li>Espera hasta que el modal especificado por <code>xpath_modal</code> sea visible en el DOM.</li> </ul> </li> <li> <p>Interacci\u00f3n con el elemento:</p> <ul> <li>Localiza y verifica la clicabilidad del elemento especificado.</li> <li>Intenta realizar clic est\u00e1ndar. Si no es posible, utiliza JavaScript como alternativa.</li> </ul> </li> <li> <p>Ejecuci\u00f3n de pasos adicionales (opcional):</p> <ul> <li>Si se proporcionan pasos adicionales, los ejecuta dentro del contexto del modal.</li> </ul> </li> <li> <p>Cambio de regreso al contexto principal (si aplica):</p> <ul> <li>Regresa al contenido principal si se cambi\u00f3 previamente al <code>iframe</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura y registra excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_13","title":"Salida","text":"<ul> <li>No retorna valores. Realiza las acciones en el modal y registra el estado del proceso en el log.</li> </ul> <pre><code>def hacer_clic_modal(driver, **kwargs):\n    try:\n        modal_locator_type = None\n        modal_locator_value = kwargs.get('xpath_modal')\n        iframe_name = kwargs.get('iframe')\n        locator_type = None\n        locator_value = None\n        wait_time = kwargs.get('wait_time', 2)\n        elementos = kwargs.get('elementos', [])\n\n        if iframe_name:\n            try:\n                logging.info(f\"Cambiando al iframe con nombre: {iframe_name}\")\n                WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.NAME, iframe_name)))\n                logging.info(\"Cambio al iframe exitoso\")\n            except TimeoutException:\n                logging.error(f\"No se pudo cambiar al iframe '{iframe_name}' dentro del tiempo l\u00edmite.\")\n                raise\n\n        for key, value in kwargs.items():\n            if key in ['xpath_modal', 'iframe', 'elementos']:\n                continue\n            elif value is not None and key in ['xpath', 'id', 'name', 'class_name', 'css_selector', 'link_text', 'partial_link_text', 'tag_name']:\n                locator_type = key\n                locator_value = value\n\n        if not modal_locator_value:\n            raise ValueError(\"Debe proporcionar un localizador v\u00e1lido para el modal (por ejemplo, 'xpath_modal')\")\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos para el elemento de clic\")\n\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n\n        logging.info(f\"Esperando la visibilidad del modal con xpath: {modal_locator_value}\")\n        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, modal_locator_value)))\n        logging.info(f\"Modal localizado y visible: {modal_locator_value}\")\n\n        elemento = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((by_mapping[locator_type], locator_value)))\n        WebDriverWait(driver, 20).until(EC.element_to_be_clickable((by_mapping[locator_type], locator_value)))\n        logging.info(f\"Elemento localizado dentro del modal, realizando clic en {locator_type}: {locator_value}\")\n\n        try:\n            elemento.click()\n        except ElementNotInteractableException:\n            logging.warning(f\"No se pudo hacer clic en {locator_type}: {locator_value} con el m\u00e9todo est\u00e1ndar, intentando con JavaScript\")\n            driver.execute_script(\"arguments[0].click();\", elemento)\n\n        time.sleep(wait_time)\n        logging.info(f\"Clic realizado correctamente en {locator_type}: {locator_value}\")\n\n        if elementos:\n            for step_name, step_function, params in elementos:\n                logging.info(f\"Ejecutando el paso adicional dentro del modal: {step_name}\")\n                step_function(driver=driver, **params)\n\n        if iframe_name:\n            driver.switch_to.default_content()\n            logging.info(\"Cambio de regreso al contenido principal realizado\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al intentar hacer clic en el elemento dentro del modal con {locator_type}: {locator_value} - Detalles: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-hacer_clic_por_coordenadas","title":"Funci\u00f3n <code>hacer_clic_por_coordenadas</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_15","title":"Prop\u00f3sito","text":"<p>Realiza un clic en un elemento ubicado en una p\u00e1gina web controlada por Selenium utilizando sus coordenadas. Es \u00fatil cuando los clics tradicionales no son efectivos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_15","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para configurar la operaci\u00f3n:</li> <li>Localizadores (uno obligatorio):<ul> <li><code>xpath</code> (str): Localizador del elemento mediante XPath.</li> <li><code>id</code>, <code>name</code>, <code>class_name</code>, <code>css_selector</code>, <code>link_text</code>, <code>partial_link_text</code>, <code>tag_name</code> (str): Alternativas de localizaci\u00f3n del elemento.</li> </ul> </li> <li><code>iframe</code> (str, opcional): Nombre del iframe para cambiar el contexto antes de la operaci\u00f3n.</li> <li><code>wait_time</code> (int, opcional): Tiempo en segundos para esperar despu\u00e9s del clic (por defecto: <code>2</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_13","title":"Funcionamiento","text":"<ol> <li> <p>Cambio de contexto al iframe (opcional):</p> <ul> <li>Cambia al contexto del iframe especificado, si se proporciona.</li> </ul> </li> <li> <p>Localizaci\u00f3n del elemento:</p> <ul> <li>Encuentra el elemento utilizando el tipo y valor del localizador proporcionado.</li> <li>Asegura que el elemento est\u00e9 visible en la ventana mediante <code>scrollIntoView</code>.</li> </ul> </li> <li> <p>Obtenci\u00f3n de coordenadas:</p> <ul> <li>Calcula las coordenadas centrales del elemento (<code>x</code> y <code>y</code>) usando su posici\u00f3n y tama\u00f1o.</li> </ul> </li> <li> <p>Clic en las coordenadas:</p> <ul> <li>Usa <code>ActionChains</code> para mover el puntero a las coordenadas calculadas y realizar el clic.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o referencias obsoletas, registrando el error en el log.</li> </ul> </li> <li> <p>Restauraci\u00f3n del contexto principal:</p> <ul> <li>Si se cambi\u00f3 al iframe, regresa al contexto principal al finalizar.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_14","title":"Salida","text":"<ul> <li>No retorna valores. Realiza el clic en las coordenadas especificadas y registra en el log el estado del proceso.</li> </ul> <pre><code>def hacer_clic_por_coordenadas(driver, **kwargs):\n    try:\n        logging.info(\"Iniciando el proceso de clic por coordenadas\")\n\n        locator_type = None\n        locator_value = None\n        iframe = kwargs.get('iframe')  # Nombre del iframe si es necesario cambiar de contexto\n        wait_time = kwargs.get('wait_time', 2)  # Manejar 'wait_time' con valor por defecto\n\n        # Obtener el localizador del elemento de clic\n        for key, value in kwargs.items():\n            if key in ['iframe', 'wait_time']:\n                continue  # Omitir estos par\u00e1metros\n            elif value is not None and key in ['xpath', 'id', 'name', 'class_name', 'css_selector', 'link_text', 'partial_link_text', 'tag_name']:\n                locator_type = key\n                locator_value = value\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos\")\n\n        # Cambiar al contexto del iframe si se proporciona\n        if iframe:\n            logging.info(f\"Cambiando al contexto del iframe: {iframe}\")\n            WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.NAME, iframe)))\n            logging.info(\"Cambio al contexto del iframe completado\")\n\n        # Convertir el identificador a By adecuado\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n\n        logging.info(f\"Esperando la presencia del elemento {locator_type}: {locator_value}\")\n        elemento = WebDriverWait(driver, 10).until(EC.presence_of_element_located((by_mapping[locator_type], locator_value)))\n        logging.info(f\"Elemento encontrado: {locator_type} = {locator_value}\")\n\n        driver.execute_script(\"arguments[0].scrollIntoView(true);\", elemento)  # Asegurarse de que el elemento est\u00e9 visible en la ventana\n        logging.info(\"Elemento desplazado a la vista\")\n\n        # Obtener las coordenadas del elemento\n        location = elemento.location\n        size = elemento.size\n        x, y = location['x'] + (size['width'] / 2), location['y'] + (size['height'] / 2)\n\n        logging.info(f\"Coordenadas obtenidas - X: {x}, Y: {y}\")\n\n        # Hacer clic en las coordenadas usando ActionChains\n        action = ActionChains(driver)\n        action.move_by_offset(x, y).click().perform()\n\n        logging.info(\"Clic realizado en las coordenadas especificadas\")\n        time.sleep(wait_time)\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al intentar hacer clic en el elemento por coordenadas: {e}\")\n        raise\n    finally:\n        # Volver al contexto principal si se cambi\u00f3 al iframe\n        if iframe:\n            driver.switch_to.default_content()\n            logging.info(\"Cambio al contexto principal despu\u00e9s de la operaci\u00f3n en el iframe\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funciones-actualizar_nombre_archivo-y-verificar_descarga","title":"Funciones <code>actualizar_nombre_archivo</code> y <code>verificar_descarga</code>","text":""},{"location":"00.etl/Utils/Funciones/#funcion-actualizar_nombre_archivo","title":"Funci\u00f3n <code>actualizar_nombre_archivo</code>","text":"<p>Prop\u00f3sito:</p> <p>Actualiza el objeto global <code>proceso_info</code> con el nombre del archivo procesado.</p> <p>Entradas:</p> <ul> <li><code>nombre_archivo</code> (str): Nombre del archivo descargado.</li> </ul> <p>Funcionamiento:</p> <ul> <li>Establece el valor de <code>'nombre_archivo'</code> en el objeto global <code>proceso_info</code>.</li> <li>Registra en el log el nombre actualizado.</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Actualiza el objeto global y registra el cambio.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcion-verificar_descarga","title":"Funci\u00f3n <code>verificar_descarga</code>","text":"<p>Prop\u00f3sito:</p> <p>Verifica si un archivo espec\u00edfico se ha descargado correctamente dentro de un tiempo de espera m\u00e1ximo.</p> <p>Entradas:</p> <ul> <li><code>nombre_archivo</code> (str): Nombre del archivo a verificar.</li> <li><code>download_dir</code> (str, opcional): Directorio de descargas donde se busca el archivo (por defecto: <code>DOWNLOAD_DIR</code>).</li> <li><code>timeout</code> (int, opcional): Tiempo m\u00e1ximo de espera en segundos (por defecto: <code>10</code>).</li> </ul> <p>Funcionamiento:</p> <ol> <li>Construye la ruta completa del archivo a partir del nombre y el directorio de descargas.</li> <li>Monitorea la existencia del archivo en el sistema de archivos:<ul> <li>Si el archivo no se encuentra dentro del tiempo especificado, devuelve <code>False</code>.</li> <li>Si el archivo aparece, registra el \u00e9xito y devuelve <code>True</code>.</li> </ul> </li> </ol> <p>Salida:</p> <ul> <li><code>True</code>: Si el archivo se descarg\u00f3 correctamente.</li> <li><code>False</code>: Si el archivo no se descarg\u00f3 dentro del tiempo especificado.</li> </ul> <pre><code># Objeto global para almacenar detalles del proceso\nproceso_info = {\n    'nombre_archivo': None\n}\n\n# Funci\u00f3n que actualiza el objeto con el nombre del archivo descargado\ndef actualizar_nombre_archivo(nombre_archivo):\n    proceso_info['nombre_archivo'] = nombre_archivo\n    logging.info(f\"Nombre del archivo actualizado en el objeto: {nombre_archivo}\")\n\n\ndef verificar_descarga(nombre_archivo, download_dir=DOWNLOAD_DIR, timeout=10):\n    \"\"\"\n    Verifica que un archivo con el nombre especificado se descargue correctamente en el \n    directorio de descargas, con un tiempo de espera m\u00e1ximo.\n    \"\"\"\n    file_path = os.path.join(download_dir, nombre_archivo)\n    logging.info(f\"Verificando la presencia del archivo: {nombre_archivo}\")\n\n    start_time = time.time()\n    while not os.path.exists(file_path):\n        if time.time() - start_time &gt; timeout:\n            # logging.warning(f\"Tiempo de espera agotado para la descarga del archivo: {nombre_archivo}\")\n            return False  # Indica que el archivo no se descarg\u00f3 en el tiempo dado\n        logging.info(\"Esperando la descarga...\")\n        time.sleep(1)\n\n    logging.info(f\"Archivo {nombre_archivo} descargado correctamente.\")\n    return True  # Indica que el archivo se descarg\u00f3 con \u00e9xito\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-cargar_archivo_excel","title":"Funci\u00f3n <code>cargar_archivo_excel</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_16","title":"Prop\u00f3sito","text":"<p>Carga un archivo Excel desde el directorio de descargas y lo convierte en un DataFrame de pandas. Utiliza el nombre del archivo almacenado en el objeto global <code>proceso_info</code>.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_16","title":"Entradas","text":"<ul> <li>No recibe argumentos. Utiliza el nombre del archivo desde el objeto global <code>proceso_info</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_14","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n del nombre del archivo:</p> <ul> <li>Recupera el nombre del archivo desde <code>proceso_info['nombre_archivo']</code>.</li> <li>Si el nombre no est\u00e1 definido, registra una advertencia y retorna <code>None</code>.</li> </ul> </li> <li> <p>Cargado del archivo:</p> <ul> <li>Construye la ruta completa del archivo a partir del nombre y el directorio <code>DOWNLOAD_DIR</code>.</li> <li>Verifica si el archivo existe en la ruta:</li> <li>Si existe, lo carga en un DataFrame de pandas.</li> <li>Si no existe, registra una advertencia y retorna <code>None</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones durante la carga y registra el error en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_15","title":"Salida","text":"<ul> <li><code>pandas.DataFrame</code>: DataFrame cargado desde el archivo Excel si la operaci\u00f3n es exitosa.</li> <li><code>None</code>: Si el archivo no se encuentra o ocurre un error.</li> </ul> <pre><code>def cargar_archivo_excel():\n    \"\"\"\n    Carga un archivo de Excel desde el directorio de descargas en un DataFrame de pandas.\n    Utiliza el nombre del archivo almacenado en el objeto global.\n    \"\"\"\n    nombre_archivo = proceso_info.get('nombre_archivo')\n    if not nombre_archivo:\n        logging.warning(\"El nombre del archivo no se ha registrado en el objeto global.\")\n        return None\n\n    file_path = os.path.join(DOWNLOAD_DIR, nombre_archivo)\n    try:\n        if os.path.exists(file_path):\n            logging.info(f\"Cargando archivo {nombre_archivo} en DataFrame.\")\n            return pd.read_excel(file_path)\n        else:\n            logging.warning(f\"Archivo {nombre_archivo} no encontrado.\")\n            return None\n    except Exception as e:\n        logging.error(f\"Error al cargar el archivo {nombre_archivo} en DataFrame: {e}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-generar_fechas","title":"Funci\u00f3n <code>generar_fechas</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_17","title":"Prop\u00f3sito","text":"<p>Genera un diccionario con rangos de fechas por a\u00f1o o semestre, seg\u00fan los par\u00e1metros proporcionados.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_17","title":"Entradas","text":"<ul> <li><code>inicio</code> (int, opcional): A\u00f1o inicial del rango (requerido si <code>semestre</code> es <code>False</code>).</li> <li><code>fin</code> (int, opcional): A\u00f1o final del rango (requerido si <code>semestre</code> es <code>False</code>).</li> <li><code>semestre</code> (bool, opcional): Si es <code>True</code>, genera fechas del semestre anterior basado en la fecha actual (por defecto: <code>False</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_15","title":"Funcionamiento","text":"<ol> <li> <p>Generaci\u00f3n basada en semestres:</p> <ul> <li>Si <code>semestre</code> es <code>True</code>:</li> <li>Determina el semestre anterior con base en el mes actual:<ul> <li>Enero a junio: Devuelve el rango del segundo semestre del a\u00f1o anterior.</li> <li>Julio a diciembre: Devuelve el rango del primer semestre del a\u00f1o actual.</li> </ul> </li> <li>Retorna un diccionario con un \u00fanico rango de fechas.</li> </ul> </li> <li> <p>Generaci\u00f3n por a\u00f1os:</p> <ul> <li>Si <code>semestre</code> es <code>False</code>:</li> <li>Itera desde el a\u00f1o <code>inicio</code> hasta el a\u00f1o <code>fin</code> (inclusive).</li> <li>Genera un diccionario donde cada clave es el \u00edndice del a\u00f1o en el rango, y los valores son los rangos de fechas para todo el a\u00f1o.</li> </ul> </li> <li> <p>Registro de informaci\u00f3n:</p> <ul> <li>Registra en el log los rangos generados.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_16","title":"Salida","text":"<ul> <li><code>dict</code>: Diccionario con rangos de fechas. Formato:<ul> <li>Por semestre: <code>{1: {'desde': 'fecha_inicio', 'hasta': 'fecha_fin'}}</code></li> <li>Por a\u00f1os: <code>{\u00edndice: {'desde': '01-01-a\u00f1o', 'hasta': '12-31-a\u00f1o'}}</code></li> </ul> </li> </ul> <pre><code># Funci\u00f3n para generar el diccionario de fechas entre dos a\u00f1os dados\ndef generar_fechas(inicio=None, fin=None, semestre=False):\n\n    if semestre:\n        # Verificar si se solicita el semestre\n        #mes fecha actual\n        mes = datetime.now().month\n        #a\u00f1o fecha actual\n        a\u00f1o = datetime.now().year\n\n        if mes &lt;= 6:\n            # Primer semestre: el semestre anterior es el segundo semestre del a\u00f1o anterior\n            return {\n                1: {'desde': f'07-01-{a\u00f1o-1}', 'hasta': f'12-31-{a\u00f1o-1}'}\n            }\n        else:\n            # Segundo semestre: el semestre anterior es el primer semestre del mismo a\u00f1o\n            return {\n                1: {'desde': f'01-01-{a\u00f1o}', 'hasta': f'06-30-{a\u00f1o}'}\n            }\n\n\n    fechas = {}\n    for a\u00f1o in range(inicio, fin + 1):\n        fechas[a\u00f1o - inicio + 1] = {'desde': f'01-01-{a\u00f1o}', 'hasta': f'12-31-{a\u00f1o}'}\n    logging.info(f\"fechas: {json.dumps(fechas, indent=4)}\")\n    # input(\"Presione Enter para continuar...\")\n    return fechas\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-generar_periodos_cortes","title":"Funci\u00f3n <code>generar_periodos_cortes</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_18","title":"Prop\u00f3sito","text":"<p>Genera un diccionario que contiene periodos de tiempo divididos en cortes mensuales dentro de un rango de a\u00f1os.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_18","title":"Entradas","text":"<ul> <li><code>anio_inicio</code> (int): A\u00f1o inicial del rango.</li> <li><code>anio_fin</code> (int): A\u00f1o final del rango.</li> <li><code>tipo</code> (int, opcional): N\u00famero de cortes por a\u00f1o (por defecto: <code>2</code>). Debe estar entre <code>1</code> y <code>12</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_16","title":"Funcionamiento","text":"<ol> <li> <p>Validaci\u00f3n del par\u00e1metro <code>tipo</code>:</p> <ul> <li>Asegura que el valor de <code>tipo</code> sea un n\u00famero entre 1 y 12.</li> <li>Lanza un <code>ValueError</code> si el valor est\u00e1 fuera del rango.</li> </ul> </li> <li> <p>C\u00e1lculo de periodos:</p> <ul> <li>Divide los meses del a\u00f1o en cortes iguales seg\u00fan el valor de <code>tipo</code>:</li> <li>Calcula la cantidad de meses por periodo: <code>meses_por_periodo = 12 // tipo</code>.</li> <li>Itera sobre los a\u00f1os entre <code>anio_inicio</code> y <code>anio_fin</code> (inclusive).</li> <li>Dentro de cada a\u00f1o:</li> <li>Calcula el mes de inicio y el mes final de cada periodo.</li> <li>Genera los rangos de fechas, considerando el \u00faltimo d\u00eda del mes (<code>dias_del_mes</code>).</li> </ul> </li> <li> <p>Estructura del diccionario:</p> <ul> <li>Cada clave es un n\u00famero de periodo incremental.</li> <li>Cada valor es un rango de fechas con formato:</li> <li><code>desde</code> (str): Fecha de inicio del periodo (formato <code>MM-DD-AAAA</code>).</li> <li><code>hasta</code> (str): Fecha de fin del periodo (formato <code>MM-DD-AAAA</code>).</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Registra en el log los periodos generados.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_17","title":"Salida","text":"<ul> <li><code>dict</code>: Diccionario con los periodos generados. Ejemplo:   <pre><code>{\n    1: {'desde': '01-01-2023', 'hasta': '06-30-2023'},\n    2: {'desde': '07-01-2023', 'hasta': '12-31-2023'}\n}\n</code></pre></li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_3","title":"Consideraciones","text":"<ul> <li>La funci\u00f3n usa <code>dias_del_mes</code> para calcular correctamente el \u00faltimo d\u00eda de cada mes.</li> </ul> <pre><code>def generar_periodos_cortes(anio_inicio=None, anio_fin=None, tipo=2):\n    if tipo &lt; 1 or tipo &gt; 12:\n        raise ValueError(\"El par\u00e1metro 'tipo' debe ser un n\u00famero entre 1 y 12.\")\n\n    fechas = {}\n    periodo = 1\n    meses_por_periodo = 12 // tipo\n\n    for anio in range(anio_inicio, anio_fin + 1):\n        for i in range(tipo):\n            mes_inicio = i * meses_por_periodo + 1\n            mes_fin = (i + 1) * meses_por_periodo\n            fechas[periodo] = {\n                'desde': f\"{mes_inicio:02d}-01-{anio}\",\n                'hasta': f\"{mes_fin:02d}-{dias_del_mes(mes_fin, anio):02d}-{anio}\"\n            }\n            periodo += 1\n    logging.info(f\"fechas: {json.dumps(fechas, indent=4)}\")\n    return fechas\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-cola_descargar","title":"Funci\u00f3n <code>cola_descargar</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_19","title":"Prop\u00f3sito","text":"<p>Inicia la descarga de un archivo desde un bot\u00f3n en una p\u00e1gina web, espera la finalizaci\u00f3n de la descarga, y renombra el archivo m\u00e1s reciente en el directorio de descargas con un nombre basado en una opci\u00f3n especificada.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_19","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>archivo</code> (str): Nombre base para renombrar el archivo descargado.</li> <li><code>download_dir</code> (str): Ruta del directorio donde se descargan los archivos.</li> <li><code>opcion</code> (str): Valor adicional que se a\u00f1adir\u00e1 al nombre del archivo al renombrarlo.</li> <li><code>kwargs</code> (dict, opcional): Argumentos adicionales:</li> <li><code>wait_time</code> (int): Tiempo de espera en segundos para la descarga (por defecto: <code>10</code>).</li> <li><code>xpath_omitir</code> (str): XPath de un bot\u00f3n opcional para omitir antes de iniciar la descarga.</li> <li>Localizadores del bot\u00f3n de descarga (<code>xpath</code>, <code>id</code>, <code>name</code>, etc.).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_17","title":"Funcionamiento","text":"<ol> <li> <p>Omisi\u00f3n de popups:</p> <ul> <li>Si se proporciona <code>xpath_omitir</code>, busca el elemento correspondiente y hace clic en \u00e9l si est\u00e1 presente.</li> </ul> </li> <li> <p>Configuraci\u00f3n del bot\u00f3n de descarga:</p> <ul> <li>Determina el tipo y valor del localizador para identificar el bot\u00f3n de descarga.</li> <li>Espera hasta que el bot\u00f3n sea clickeable y realiza clic.</li> </ul> </li> <li> <p>Monitoreo del directorio de descargas:</p> <ul> <li>Compara el estado del directorio antes y despu\u00e9s de la descarga.</li> <li>Espera hasta 10 segundos para detectar un nuevo archivo.</li> </ul> </li> <li> <p>Renombrar archivo descargado:</p> <ul> <li>Identifica el archivo nuevo m\u00e1s reciente en el directorio.</li> <li>Renombra el archivo con el formato: <code>nombre_base_opcion.extension</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o no interactuables, y registra el error en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_18","title":"Salida","text":"<ul> <li><code>True</code>: Si el archivo se descarg\u00f3 y renombr\u00f3 correctamente.</li> <li><code>False</code>: Si no se detect\u00f3 el archivo dentro del tiempo especificado o hubo un error durante el proceso.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_4","title":"Consideraciones","text":"<ul> <li>Aseg\u00farese de proporcionar un localizador v\u00e1lido (<code>locator_type</code> y <code>locator_value</code>) para identificar el bot\u00f3n de descarga.</li> <li>La funci\u00f3n maneja escenarios donde puede ser necesario omitir popups antes de descargar.</li> <li>Dise\u00f1ada para flujos de automatizaci\u00f3n que requieren monitorear y renombrar archivos descargados din\u00e1micamente.</li> </ul> <pre><code>def cola_descargar(driver, archivo, download_dir, opcion, **kwargs):\n    \"\"\"\n    Inicia la descarga de un archivo, espera el tiempo especificado y renombra\n    el archivo m\u00e1s reciente en la carpeta de descargas con el nombre y la opci\u00f3n especificados.\n    \"\"\"\n    try:\n        # Verificar si se pasa un 'xpath_omitir' y, en caso afirmativo, si el elemento existe\n        xpath_omitir = kwargs.get('xpath_omitir')\n        if xpath_omitir:\n            try:\n                omitir_button = driver.find_element(By.XPATH, xpath_omitir)\n                omitir_button.click()\n                logging.info(f\"Omitido el clic en el bot\u00f3n de descarga: {xpath_omitir}\")\n                return True\n            except NoSuchElementException:\n                logging.info(f\"Elemento con xpath_omitir '{xpath_omitir}' no encontrado, continuando con la descarga\")\n\n        # Configuraci\u00f3n de los par\u00e1metros de localizaci\u00f3n del bot\u00f3n de descarga\n        locator_type = None\n        locator_value = None\n        wait_time = kwargs.get('wait_time', 10)\n\n        for key, value in kwargs.items():\n            if key not in {'wait_time', 'archivo', 'xpath_omitir'} and value:\n                locator_type = key\n                locator_value = value\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos\")\n\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n        # Obtener el n\u00famero de archivos antes de la descarga\n        archivos_antes = set(os.listdir(download_dir))\n\n        logging.info(f\"Esperando la presencia del elemento {locator_type}: {locator_value}\")\n        download_button = WebDriverWait(driver, 10).until(\n            EC.element_to_be_clickable((by_mapping[locator_type], locator_value))\n        )\n        download_button.click()\n        logging.info(f\"Bot\u00f3n de descarga clickeado, esperando {wait_time} segundos para la descarga\")\n        time.sleep(10)\n\n        # Esperar a que un archivo nuevo aparezca en el directorio\n        for _ in range(10):\n            archivos_despues = set(os.listdir(download_dir))\n            archivos_nuevos = archivos_despues - archivos_antes  # Detectar nuevos archivos\n            if archivos_nuevos:\n                # Obtener el archivo nuevo m\u00e1s reciente\n                latest_file = max(archivos_nuevos, key=lambda f: os.path.getctime(os.path.join(download_dir, f)))\n                latest_file_path = os.path.join(download_dir, latest_file)\n\n                # Renombrar el archivo descargado\n                base_name, extension = os.path.splitext(archivo)\n                new_file_path = os.path.join(download_dir, f'{base_name}_{opcion}{extension}')\n                os.rename(latest_file_path, new_file_path)\n                logging.info(f\"Archivo renombrado a: {new_file_path}\")\n                return True\n            logging.info(\"Esperando que la descarga se complete...\")\n            time.sleep(1)\n\n        logging.error(\"No se encontr\u00f3 el archivo descargado.\")\n        return False\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al intentar descargar el archivo con {locator_type}: {locator_value} - Detalles: {e}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-seleccionar_opcion_custom_dropdown","title":"Funci\u00f3n <code>seleccionar_opcion_custom_dropdown</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_20","title":"Prop\u00f3sito","text":"<p>Selecciona una opci\u00f3n espec\u00edfica en un men\u00fa desplegable personalizado (custom dropdown) en una p\u00e1gina web controlada por Selenium.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_20","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para configurar la operaci\u00f3n:</li> <li><code>xpath</code> (str): Localizaci\u00f3n del bot\u00f3n del men\u00fa desplegable.</li> <li><code>option</code> (str): Texto de la opci\u00f3n que se desea seleccionar.</li> <li><code>wait_time</code> (int, opcional): Tiempo en segundos para esperar despu\u00e9s de desplegar el men\u00fa (por defecto: <code>2</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_18","title":"Funcionamiento","text":"<ol> <li> <p>Verificaci\u00f3n de par\u00e1metros:</p> <ul> <li>Verifica que se hayan proporcionado un <code>xpath</code> v\u00e1lido para el bot\u00f3n del dropdown y un <code>option</code> para seleccionar.</li> </ul> </li> <li> <p>Desplegar el men\u00fa:</p> <ul> <li>Localiza el bot\u00f3n del men\u00fa usando <code>xpath</code>.</li> <li>Hace clic para desplegar el men\u00fa.</li> </ul> </li> <li> <p>Seleccionar la opci\u00f3n:</p> <ul> <li>Intenta localizar y seleccionar la opci\u00f3n utilizando texto exacto.</li> <li>Si no encuentra la opci\u00f3n, intenta con una b\u00fasqueda flexible que utiliza <code>contains</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o no interactuables, y registra el error en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_19","title":"Salida","text":"<ul> <li>No retorna valores. Realiza la acci\u00f3n en el men\u00fa desplegable y registra el estado del proceso en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_5","title":"Consideraciones","text":"<ul> <li>Dise\u00f1ada para trabajar con men\u00fas desplegables personalizados que contienen opciones identificadas por texto.</li> <li>Incluye una l\u00f3gica de respaldo para localizar opciones cuando no se encuentran con texto exacto.</li> </ul> <pre><code>def seleccionar_opcion_custom_dropdown(driver, **kwargs):\n    try:\n        logging.info(\"Seleccionando opci\u00f3n en un men\u00fa desplegable personalizado\")\n        xpath_boton = kwargs.get('xpath')\n        option_value = kwargs.get('option')\n        wait_time = kwargs.get('wait_time', 2)  # Manejar 'wait_time' con valor por defecto\n\n        if not xpath_boton or not option_value:\n            raise ValueError(\"Debe proporcionar 'xpath' y 'option' v\u00e1lidos\")\n\n        # Hacer clic en el bot\u00f3n para desplegar el men\u00fa\n        logging.info(f\"Haciendo clic en el men\u00fa desplegable con xpath: {xpath_boton}\")\n        dropdown = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath_boton)))\n        dropdown.click()\n        time.sleep(2)  # Pausa breve para que el men\u00fa se despliegue completamente\n\n        try:\n            # Seleccionar la opci\u00f3n del men\u00fa desplegable\n            logging.info(f\"Seleccionando la opci\u00f3n '{option_value}' en el men\u00fa desplegable\")\n\n            # Intentar buscar la opci\u00f3n con texto exacto\n            opcion = WebDriverWait(driver, 10).until(\n                EC.element_to_be_clickable((By.XPATH, f\"//ul[contains(@class, 'dropdown-menu')]//span[text()='{option_value}']\"))\n            )\n            opcion.click()\n            logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente.\")\n        except TimeoutException:\n            logging.warning(f\"No se encontr\u00f3 la opci\u00f3n '{option_value}' con texto exacto. Intentando con b\u00fasqueda flexible...\")\n            try:\n                # Intentar con b\u00fasqueda m\u00e1s flexible usando `contains`\n                opcion = WebDriverWait(driver, 10).until(\n                    EC.element_to_be_clickable((By.XPATH, f\"//ul[contains(@class, 'dropdown-menu')]//span[contains(normalize-space(text()), '{option_value}')]\"))\n                )\n                opcion.click()\n                logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente usando b\u00fasqueda flexible.\")\n            except Exception as e:\n                logging.error(f\"Error al seleccionar la opci\u00f3n '{option_value}': {e}\")\n        logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente en el men\u00fa desplegable\")\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al seleccionar la opci\u00f3n en el men\u00fa desplegable personalizado: {e}\")\n        #raise\n</code></pre> <p><code>listar_archivos_descargados</code> lista y registra los nombres de los archivos presentes en el directorio de descargas especificado.</p> <pre><code>def listar_archivos_descargados():\n    archivos = os.listdir(DOWNLOAD_DIR)\n    logging.info(f\"Archivos en la carpeta '{DOWNLOAD_DIR}': {archivos}\")\n    return archivos\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-obtener_elementos_dropdown","title":"Funci\u00f3n <code>obtener_elementos_dropdown</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_21","title":"Prop\u00f3sito","text":"<p>Extrae las opciones disponibles en un men\u00fa desplegable (<code>dropdown</code>) en una p\u00e1gina web controlada por Selenium.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_21","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>boton_xpath</code> (str): XPath del bot\u00f3n para abrir el men\u00fa desplegable.</li> <li><code>elementos_xpath</code> (str): XPath del contenedor que contiene las opciones del men\u00fa.</li> <li><code>nivel</code> (int): Nivel o jerarqu\u00eda del dropdown para fines de registro y depuraci\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_19","title":"Funcionamiento","text":"<ol> <li> <p>Interacci\u00f3n con el bot\u00f3n del dropdown:</p> <ul> <li>Espera hasta que el bot\u00f3n est\u00e9 visible y clickeable.</li> <li>Hace scroll para asegurar que el bot\u00f3n est\u00e9 en la vista.</li> <li>Usa JavaScript para forzar el clic en caso necesario.</li> </ul> </li> <li> <p>Extracci\u00f3n de opciones:</p> <ul> <li>Espera a que el contenedor de opciones est\u00e9 visible.</li> <li>Encuentra todos los elementos <code>&lt;li&gt;</code> dentro del contenedor <code>&lt;ul&gt;</code>.</li> <li>Para cada elemento:</li> <li>Obtiene el texto de la opci\u00f3n.</li> <li>Filtra opciones vac\u00edas o con texto no deseado como \"Seleccione\".</li> <li>Agrega el texto al resultado.</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Registra en el log el nivel del dropdown y las opciones extra\u00eddas.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones por tiempo de espera o errores generales, las registra y devuelve una lista vac\u00eda.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_20","title":"Salida","text":"<ul> <li><code>list</code>: Lista de textos de las opciones extra\u00eddas del men\u00fa desplegable.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_6","title":"Consideraciones","text":"<ul> <li>Excluye opciones con texto vac\u00edo o \"Seleccione\".</li> <li>Dise\u00f1ada para manejar men\u00fas desplegables con opciones representadas como elementos <code>&lt;li&gt;</code>.</li> <li>El par\u00e1metro <code>nivel</code> permite rastrear jerarqu\u00edas de dropdowns en procesos complejos.</li> </ul> <pre><code>@log_step_decorator(\"Obtener elementos dropdown\")\ndef obtener_elementos_dropdown(driver, boton_xpath, elementos_xpath, nivel):\n\n    opciones = []\n    try:\n        logging.info(f\"[Nivel {nivel}] Intentando abrir dropdown en: {boton_xpath}\")\n\n        # Esperar hasta que el bot\u00f3n est\u00e9 habilitado y visible en la pantalla\n        boton_dropdown = WebDriverWait(driver, 15).until(\n            EC.element_to_be_clickable((By.XPATH, boton_xpath))\n        )\n\n        # Intentar hacer scroll para que el bot\u00f3n sea visible\n        driver.execute_script(\"arguments[0].scrollIntoView();\", boton_dropdown)\n\n        # Usar JavaScript para forzar el clic si es necesario\n        driver.execute_script(\"arguments[0].click();\", boton_dropdown)\n        time.sleep(1)  # Pausa breve para permitir la expansi\u00f3n completa del dropdown\n\n        # Esperar a que el contenedor de opciones del dropdown est\u00e9 visible\n        elementos_ul = WebDriverWait(driver, 15).until(\n            EC.visibility_of_element_located((By.XPATH, elementos_xpath))\n        )\n\n        # Obtener todos los elementos &lt;li&gt; visibles dentro de `ul`\n        elementos_li = elementos_ul.find_elements(By.XPATH, \"./li\")\n\n        # Extraer y almacenar el texto y XPath de cada opci\u00f3n en el dropdown\n        for index, elemento in enumerate(elementos_li):\n            try:\n                # Obtener el texto de la opci\u00f3n\n                texto_opcion = elemento.find_element(By.XPATH, \".//span[@class='text']\").text.strip()\n\n                if texto_opcion and texto_opcion != \"Seleccione\":  # Excluir texto vac\u00edo y \"Seleccione\"\n                    # Construir un XPath \u00fanico para el elemento basado en su posici\u00f3n (index)\n                    xpath_opcion = f\"{elementos_xpath}/li[{index + 1}]/a\"  # Ejemplo de XPath con \u00edndice\n\n                    # Agregar el texto y el XPath al resultado\n                    opciones.append(texto_opcion)                    \n                    # _opciones.append({\"text\": texto_opcion,\"xpath\": xpath_opcion})\n            except Exception as inner_e:\n                logging.warning(f\"[Nivel {nivel}] No se pudo obtener el texto de una opci\u00f3n: {inner_e}\")\n\n        logging.info(f\"[Nivel {nivel}] Opciones obtenidas: {opciones}\")\n        return opciones\n\n    except TimeoutException:\n        logging.error(f\"[Nivel {nivel}] El dropdown no se pudo abrir debido a un Timeout.\")\n        return []\n    except Exception as e:\n        logging.error(f\"[Nivel {nivel}] Error al obtener elementos del dropdown: {e}\")\n        return []\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-eliminar_archivos_anteriores","title":"Funci\u00f3n <code>eliminar_archivos_anteriores</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_22","title":"Prop\u00f3sito","text":"<p>Elimina todos los archivos en un directorio de descargas que coincidan con un nombre base especificado, incluyendo variantes como <code>'Nombre'</code>, <code>'Nombre (1)'</code>, <code>'Nombre (2)'</code>, etc.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_22","title":"Entradas","text":"<ul> <li><code>nombre_archivo</code> (str): Nombre base del archivo cuyos duplicados o variantes deben ser eliminados.</li> <li><code>download_dir</code> (str): Ruta del directorio donde se buscar\u00e1n los archivos a eliminar.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_20","title":"Funcionamiento","text":"<ol> <li> <p>Construcci\u00f3n del patr\u00f3n de coincidencia:</p> <ul> <li>Extrae el nombre base del archivo sin extensi\u00f3n.</li> <li>Crea un patr\u00f3n de expresi\u00f3n regular que coincida con el nombre base seguido de cualquier texto adicional (como <code>' (1)'</code>) y cualquier extensi\u00f3n.</li> </ul> </li> <li> <p>B\u00fasqueda y eliminaci\u00f3n de archivos:</p> <ul> <li>Itera sobre los archivos en el directorio especificado.</li> <li>Si un archivo coincide con el patr\u00f3n, lo elimina y registra la acci\u00f3n en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_21","title":"Salida","text":"<ul> <li>No retorna valores. Realiza acciones directamente en el sistema de archivos y registra los archivos eliminados en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_7","title":"Consideraciones","text":"<ul> <li>Dise\u00f1ada para gestionar directorios de descargas en flujos automatizados, asegurando que no queden residuos de ejecuciones anteriores.</li> <li>Verifica patrones de archivos con extensiones gen\u00e9ricas (<code>.txt</code>, <code>.xlsx</code>, etc.). Si se espera un tipo espec\u00edfico, aseg\u00farese de que el nombre y patr\u00f3n sean precisos.</li> </ul> <pre><code>def eliminar_archivos_anteriores(nombre_archivo, download_dir):\n    \"\"\"\n    Elimina todos los archivos en el directorio de descargas que coincidan con el nombre\n    especificado o patrones como 'Nombre', 'Nombre (1)', 'Nombre (2)', etc.\n\n    Args:\n        nombre_archivo (str): El nombre base del archivo a eliminar.\n        download_dir (str): El directorio donde se buscar\u00e1n los archivos.\n    \"\"\"\n    nombre_base = os.path.splitext(nombre_archivo)[0]  # Remueve la extensi\u00f3n del archivo\n    patron = re.compile(rf\"^{re.escape(nombre_base)}.*\\.[a-zA-Z0-9]+$\")  # Coincidir con cualquier extensi\u00f3n de archivo\n\n    for archivo in os.listdir(download_dir):\n        if patron.match(archivo):\n            os.remove(os.path.join(download_dir, archivo))\n            logging.info(f\"Archivo eliminado: {archivo} en {download_dir}\")\n</code></pre> <p><code>limpiar_carpeta</code> elimina todos los archivos con extensiones <code>.csv</code>, <code>.xls</code> y <code>.xlsx</code> del directorio de descargas especificado (<code>download_dir</code>). Utiliza un decorador para registrar el inicio y finalizaci\u00f3n del proceso, adem\u00e1s de registrar cada archivo eliminado en el log.</p> <pre><code>@log_step_decorator(\"Limpiar carpeta de descargas\")\ndef limpiar_carpeta(download_dir):\n    #Eliminar todos los archivos (scv,xls,xlsx) de la carpeta \n    for archivo in os.listdir(download_dir):\n        if archivo.endswith(\".csv\") or archivo.endswith(\".xls\") or archivo.endswith(\".xlsx\"):\n            os.remove(os.path.join(download_dir, archivo))\n            logging.info(f\"Archivo eliminado: {archivo} en {download_dir}\")    \n</code></pre> <p><code>verificar_y_hacer_clic</code> localiza un elemento en la p\u00e1gina mediante un XPath proporcionado, realiza un clic en \u00e9l y env\u00eda un texto seguido de la tecla Enter. Si el elemento no se encuentra, captura la excepci\u00f3n y contin\u00faa sin interrupciones. Retorna <code>True</code> si la acci\u00f3n fue exitosa; de lo contrario, no retorna valor.</p> <pre><code>def verificar_y_hacer_clic(driver, xpath, wait_time=2):\n    \"\"\"\n    Verifica si un elemento con el XPath especificado existe.\n    Si existe, hace clic en \u00e9l.\n\n    :param driver: instancia del controlador de Selenium.\n    :param xpath: cadena XPath del elemento a verificar y hacer clic.\n    :param wait_time: tiempo opcional para esperar despu\u00e9s del clic.\n    \"\"\"\n    try:\n        elemento = driver.find_element(By.XPATH, xpath)\n        elemento.click()\n        elemento.send_keys(\"texto para enviar\" + Keys.ENTER)        \n        print(f\"Elemento encontrado y clic realizado en el XPath: {xpath}\")\n        time.sleep(wait_time)\n        return True\n    except NoSuchElementException:\n        print(f\"Elemento no encontrado en el XPath: {xpath}, continuando.\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-pre_procesamiento","title":"Funci\u00f3n <code>pre_procesamiento</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_23","title":"Prop\u00f3sito","text":"<p>Automatiza la selecci\u00f3n de opciones en un men\u00fa desplegable, filtra opciones no deseadas y gestiona las descargas asociadas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_23","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Controlador Selenium utilizado para interactuar con la p\u00e1gina.</li> <li><code>download_dir</code> (str): Ruta al directorio donde se guardan las descargas.</li> <li><code>id_descargar</code> (str): ID del bot\u00f3n que inicia la descarga.</li> <li><code>nombre_archivo</code> (str): Nombre base para los archivos descargados.</li> <li><code>nombre_archivo_completo</code> (str): Nombre completo esperado del archivo descargado.</li> <li><code>xpath_boton</code> (str): XPath del bot\u00f3n para desplegar el men\u00fa.</li> <li><code>xpath_contenedor_opciones</code> (str): XPath del contenedor que contiene las opciones del men\u00fa.</li> <li><code>tipo</code> (str): Tipo de descarga:</li> <li><code>modal</code>: Descargas que requieren interacci\u00f3n con un modal.</li> <li><code>directa</code>: Descargas iniciadas directamente desde el men\u00fa desplegable.</li> <li><code>excluir_opciones</code> (list): Lista de opciones que no deben ser procesadas.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_21","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n de opciones:</p> <ul> <li>Utiliza la funci\u00f3n <code>obtener_elementos_dropdown</code> para extraer todas las opciones visibles en el men\u00fa desplegable.</li> </ul> </li> <li> <p>Filtrado de opciones:</p> <ul> <li>Excluye las opciones especificadas en <code>excluir_opciones</code>.</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Registra las opciones finales que ser\u00e1n procesadas en el log para facilitar la depuraci\u00f3n.</li> </ul> </li> <li> <p>Procesamiento de cada opci\u00f3n:</p> <ul> <li>Itera sobre las opciones filtradas y llama a la funci\u00f3n <code>procesar_opciones_descarga</code>:</li> <li>Gestiona la interacci\u00f3n con el men\u00fa desplegable.</li> <li>Inicia las descargas seg\u00fan el tipo especificado (<code>modal</code> o <code>directa</code>).</li> <li>Asegura el manejo adecuado de archivos en el directorio de descargas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_22","title":"Salida","text":"<ul> <li>No retorna valores. Realiza las acciones de selecci\u00f3n, exclusi\u00f3n y descarga autom\u00e1ticamente.</li> </ul> <pre><code>def pre_procesamiento(driver, \n                download_dir,\n                id_descargar,\n                nombre_archivo,\n                nombre_archivo_completo,\n                xpath_boton,\n                xpath_contenedor_opciones,\n                tipo,\n                excluir_opciones):\n\n    opciones = obtener_elementos_dropdown(driver, xpath_boton, xpath_contenedor_opciones, nivel=1)\n    opciones = [opcion for opcion in opciones if opcion not in excluir_opciones]\n    logging.info(f\"Opciones a seleccionar: {opciones}\")\n\n    procesar_opciones_descarga(\n        driver=driver,\n        opciones=opciones,\n        xpath_boton=xpath_boton,\n        id_descargar=id_descargar,\n        nombre_archivo=nombre_archivo,\n        nombre_archivo_completo=nombre_archivo_completo,\n        download_dir=download_dir,\n        wait_time=2,\n        tipo=tipo,\n        xpath_omitir='/html/body/div[10]'\n    )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-pre_procesamiento_periodo","title":"Funci\u00f3n <code>pre_procesamiento_periodo</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_24","title":"Prop\u00f3sito","text":"<p>Automatiza la selecci\u00f3n de per\u00edodos espec\u00edficos desde un men\u00fa desplegable, filtra los per\u00edodos disponibles en funci\u00f3n de un conjunto de a\u00f1os, y gestiona las descargas asociadas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_24","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Controlador Selenium para manejar la interacci\u00f3n con la p\u00e1gina.</li> <li><code>download_dir</code> (str): Directorio donde se guardar\u00e1n las descargas.</li> <li><code>id_descargar</code> (str): ID del bot\u00f3n de descarga.</li> <li><code>nombre_archivo</code> (str): Nombre base del archivo descargado.</li> <li><code>nombre_archivo_completo</code> (str): Nombre completo esperado del archivo descargado.</li> <li><code>xpath_boton</code> (str): XPath del bot\u00f3n para desplegar el men\u00fa de per\u00edodos.</li> <li><code>xpath_contenedor_opciones</code> (str): XPath del contenedor de opciones del men\u00fa desplegable.</li> <li><code>tipo</code> (str): Tipo de descarga:</li> <li><code>modal</code>: Descargas que requieren interacci\u00f3n con un modal.</li> <li><code>directa</code>: Descargas iniciadas directamente desde el men\u00fa desplegable.</li> <li><code>items_opciones</code> (list): Lista de a\u00f1os a generar como per\u00edodos para consulta (e.g., <code>[2019, 2020]</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_22","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n de opciones del dropdown:</p> <ul> <li>Llama a <code>obtener_elementos_dropdown</code> para extraer todas las opciones disponibles en el men\u00fa desplegable.</li> </ul> </li> <li> <p>Generaci\u00f3n de per\u00edodos de consulta:</p> <ul> <li>Genera una lista de per\u00edodos en formato de cadena (<code>\"2019\"</code>, <code>\"2020\"</code>) a partir de los a\u00f1os en <code>items_opciones</code>.</li> <li>Guarda los per\u00edodos generados en un diccionario para registro y depuraci\u00f3n.</li> </ul> </li> <li> <p>Filtrado de per\u00edodos:</p> <ul> <li>Filtra las opciones del dropdown, reteniendo \u00fanicamente aquellas que comiencen con los per\u00edodos generados.</li> </ul> </li> <li> <p>Registro de opciones:</p> <ul> <li>Guarda las opciones filtradas en un diccionario y las registra en el log.</li> </ul> </li> <li> <p>Procesamiento de opciones:</p> <ul> <li>Llama a <code>procesar_opciones_descarga</code> para gestionar la interacci\u00f3n con el dropdown y realizar las descargas para cada per\u00edodo filtrado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_23","title":"Salida","text":"<ul> <li>No retorna valores. Realiza las acciones de selecci\u00f3n, filtrado y descarga autom\u00e1ticamente.</li> </ul> <pre><code>def pre_procesamiento_periodo(driver, \n                download_dir,\n                id_descargar,\n                nombre_archivo,\n                nombre_archivo_completo,\n                xpath_boton,\n                xpath_contenedor_opciones,\n                tipo,\n                items_opciones):\n\n    opciones = obtener_elementos_dropdown(driver, xpath_boton, xpath_contenedor_opciones, nivel=1)\n\n    # Obtener los periodos disponibles en el dropdown\n    _periodos = opciones\n\n    # Generar lista de periodos de consulta (2019, 2020)\n    consulta = items_opciones\n    periodos_generados = [f\"{year}\" for year in consulta]\n    guardar_diccionario(periodos_generados, 'periodos_generados')\n    # Filtrar solo los per\u00edodos que comiencen con los valores generados\n    opciones = [\n        periodo for periodo in _periodos \n        if any(periodo.startswith(generado) for generado in periodos_generados)\n    ]\n    guardar_diccionario(opciones, 'opciones')    \n    logging.info(f\"Opciones a seleccionar: {opciones}\")\n\n    procesar_opciones_descarga(\n        driver=driver,\n        opciones=opciones,\n        xpath_boton=xpath_boton,\n        id_descargar=id_descargar,\n        nombre_archivo=nombre_archivo,\n        nombre_archivo_completo=nombre_archivo_completo,\n        download_dir=download_dir,\n        wait_time=2,\n        tipo=tipo,\n        xpath_omitir='/html/body/div[10]'\n    )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-get_data_range","title":"Funci\u00f3n <code>get_data_range</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_25","title":"Prop\u00f3sito","text":"<p>Obtiene un rango de datos de una hoja de un archivo Excel y devuelve los valores contenidos en ese rango.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_25","title":"Entradas","text":"<ul> <li><code>file_path</code> (str): Ruta del archivo Excel a procesar.</li> <li><code>sheet_index</code> (int): \u00cdndice de la hoja en el archivo Excel de donde se extraer\u00e1n los datos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_23","title":"Funcionamiento","text":"<ol> <li> <p>Carga del archivo:</p> <ul> <li>Abre el archivo Excel en modo de solo lectura (<code>data_only=True</code>).</li> </ul> </li> <li> <p>Validaci\u00f3n del \u00edndice de la hoja:</p> <ul> <li>Verifica que el \u00edndice proporcionado est\u00e9 dentro del rango v\u00e1lido de hojas disponibles.</li> <li>Lanza un <code>IndexError</code> si el \u00edndice no es v\u00e1lido.</li> </ul> </li> <li> <p>Detecci\u00f3n del rango de datos:</p> <ul> <li>Itera sobre las celdas de la hoja para identificar los l\u00edmites m\u00ednimos y m\u00e1ximos (filas y columnas) donde existen valores no vac\u00edos.</li> </ul> </li> <li> <p>Extracci\u00f3n de datos:</p> <ul> <li>Con los l\u00edmites detectados (<code>min_row</code>, <code>min_col</code>, <code>max_row</code>, <code>max_col</code>), se genera un rango.</li> <li>Crea un iterador con los valores dentro del rango utilizando <code>sheet.iter_rows</code> con <code>values_only=True</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_24","title":"Salida","text":"<ul> <li><code>data</code> (iterable): Valores contenidos en el rango detectado de la hoja Excel.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-rango-detectado","title":"Ejemplo de rango detectado","text":"<p>Si el rango de datos encontrado es: - Desde la fila 2, columna 1 - Hasta la fila 10, columna 5</p> <p>El rango corresponde a las celdas <code>A2:E10</code> en el archivo Excel.</p> <pre><code>def get_data_range(file_path, sheet_index):\n    # Cargar el archivo de Excel\n    workbook = load_workbook(file_path, data_only=True)\n\n    # Verificar si el \u00edndice de la hoja es v\u00e1lido\n    if sheet_index &lt; 0 or sheet_index &gt;= len(workbook.sheetnames):\n        raise IndexError(f\"\u00cdndice de hoja inv\u00e1lido. Hay {len(workbook.sheetnames)} hojas disponibles.\")\n\n    # Obtener la hoja por \u00edndice\n    sheet_name = workbook.sheetnames[sheet_index]\n    sheet = workbook[sheet_name]\n\n    # Variables para rastrear los l\u00edmites del rango\n    min_row, min_col = None, None\n    max_row, max_col = None, None\n\n    # Recorrer las celdas para encontrar el rango de datos\n    for row in sheet.iter_rows():\n        for cell in row:\n            if cell.value is not None:\n                if min_row is None or cell.row &lt; min_row:\n                    min_row = cell.row\n                if max_row is None or cell.row &gt; max_row:\n                    max_row = cell.row\n                if min_col is None or cell.column &lt; min_col:\n                    min_col = cell.column\n                if max_col is None or cell.column &gt; max_col:\n                    max_col = cell.column\n\n    # return min_row, min_col, max_row, max_col\n    sheet_index = 0  # \u00cdndice de la hoja (empezando en 0)\n\n    print(f\"Rango de datos: Desde la fila {min_row}, columna {min_col} hasta la fila {max_row}, columna {max_col}\")\n    # Crear un DataFrame con el rango de datos obtenido\n    workbook = load_workbook(file_path, data_only=True)\n    sheet = workbook[workbook.sheetnames[sheet_index]]\n    data = sheet.iter_rows(min_row=min_row, max_row=max_row, min_col=min_col, max_col=max_col, values_only=True)\n    return data\n</code></pre> <p><code>guardar_diccionario</code> Guarda los valores de un diccionario o lista en un archivo CSV, creando una columna llamada Item para almacenar los datos.</p> <pre><code>def guardar_diccionario(diccionario, nombre_archivo):\n    # Almacenar periodos en un Archivo, en modo de pruebas\n    df = pd.DataFrame(diccionario, columns=['Item'])\n    df.to_csv(f'{nombre_archivo}.csv', index=False)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-crea_dataframes","title":"Funci\u00f3n <code>crea_dataframes</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_26","title":"Prop\u00f3sito","text":"<p>Procesa una lista de archivos Excel desde una carpeta, carg\u00e1ndolos en pandas DataFrames, y aplica renombramientos espec\u00edficos de columnas para cada archivo.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_26","title":"Entradas","text":"<ul> <li><code>files</code> (list): Lista de nombres de archivos Excel a procesar.</li> <li><code>upload_folder</code> (str): Ruta de la carpeta donde se encuentran los archivos Excel.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_24","title":"Funcionamiento","text":"<ol> <li> <p>Carga de archivos Excel:</p> <ul> <li>Itera sobre los nombres de los archivos en <code>files</code>.</li> <li>Carga cada archivo Excel desde la carpeta especificada (<code>upload_folder</code>) en un DataFrame y lo almacena en el diccionario <code>data_frames</code>, donde la clave es el nombre del archivo.</li> </ul> </li> <li> <p>Renombramiento de columnas:</p> <ul> <li>Aplica renombramientos espec\u00edficos para las columnas de cada archivo:</li> <li>Estandariza los nombres de columnas relevantes como <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>FECHA</code>, y otros campos seg\u00fan la estructura particular de cada archivo.</li> <li>Se realiza un mapeo detallado de las columnas para cada archivo en <code>files[0]</code>, <code>files[1]</code>, <code>files[2]</code> y <code>files[3]</code>.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve un diccionario <code>data_frames</code> donde:</li> <li>Las claves son los nombres de los archivos.</li> <li>Los valores son los DataFrames procesados.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_25","title":"Salida","text":"<ul> <li><code>data_frames</code> (dict): Diccionario con los DataFrames procesados y renombrados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-estructura-de-salida","title":"Ejemplo de estructura de salida","text":"<p>Si <code>files</code> contiene: <pre><code>['archivo1.xlsx', 'archivo2.xlsx']\n</code></pre> El diccionario <code>data_frames</code> tendr\u00e1: <pre><code>{\n    'archivo1.xlsx': DataFrame con columnas renombradas,\n    'archivo2.xlsx': DataFrame con columnas renombradas\n}\n</code></pre></p> <pre><code>################################################################################################################################\n@log_step_decorator(\"Procesar dataframes\")\ndef crea_dataframes(files, upload_folder):\n    data_frames = {}\n    for file in files:\n        data_frames[file] = pd.read_excel( upload_folder + \"\\\\\" + file )\n        #columnsTotal = columnsTotal + data_frames[file].columns.tolist()\n\n\n\n    data_frames[files[0]] = data_frames[files[0]].rename(columns={'TIPO DE IDENTIFICACION': 'TIPO_DOCUMENTO',\n                                                                'IDENTIFICACION': 'DOCUMENTO',\n                                                                'FECHA DEL PRODUCTO O SERVICIO PRESTADO': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO'})\n    data_frames[files[1]] = data_frames[files[1]].rename(columns={'TIPO DE IDENTIFICACION': 'TIPO_DOCUMENTO',\n                                                                'IDENTIFICACION': 'DOCUMENTO',\n                                                                'FECHA DEL PRODUCTO O SERVICIO PRESTADO': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO',\n                                                                'TELEFONO CELULAR':'TELEFONO'})\n    data_frames[files[2]] = data_frames[files[2]].rename(columns={'TIPO DE IDENTIFICACION DEL BENEFICIARIO': 'TIPO_DOCUMENTO',\n                                                                'IDENTIFICACION DEL BENEFICIARIO': 'DOCUMENTO',\n                                                                'FECHA DEL PRODUCTO O SERVICIO PRESTADO': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL NINIO O NINIA BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO',\n                                                                'PRIMER NOMBRE DEL BENEFICIARIO':'PRIMER NOMBRE',\n                                                                'PRIMER APELLIDO DEL BENEFICIARIO':'PRIMER APELLIDO',\n                                                                'SEGUNDO NOMBRE DEL BENEFICIARIO':'SEGUNDO NOMBRE',\n                                                                'SEGUNDO APELLIDO DEL BENEFICIARIO':'SEGUNDO APELLIDO',\n                                                                'PRIMER NOMBRE PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'PRIMER NOMBRE DEL ACUDIENTE', \n                                                                'SEGUNDO NOMBRE PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'SEGUNDO NOMBRE DEL ACUDIENTE',\n                                                                'PRIMER APELLIDO PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'PRIMER APELLIDO DEL ACUDIENTE',\n                                                                'SEGUNDO APELLIDO PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'SEGUNDO APELLIDO DEL ACUDIENTE',\n                                                                'EDAD DEL BENEFICIARIO':'EDAD',\n                                                                'TELEFONO\\xa0DEL ESTUDIANTE':'TELEFONO',\n                                                                'UBICACION DEL\\xa0 ESTABLECIMIENTO EDUCATIVO DEL ESTUDIANTE':'UBICACION DEL ESTABLECIMIENTO EDUCATIVO DEL ESTUDIANTE'})\n    data_frames[files[3]] = data_frames[files[3]].rename(columns={'TIPO DE IDENTIFICACION DEL BENEFICIARIO': 'TIPO_DOCUMENTO',\n                                                                'NUMERODEIDENTIFICACION': 'DOCUMENTO',\n                                                                'FECHA DE VINCULACION A PAIN': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL NINIO O NINIA BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO',\n                                                                'FECHA DE NACIMIENTO(DD/MM/AAAA)':'FECHA NACIMIENTO',\n                                                                'SEGUNDO\\xa0APELLIDO DEL ACUDIENTE':'SEGUNDO APELLIDO DEL ACUDIENTE',\n                                                                'SEGUNDO\\xa0NOMBRE DEL ACUDIENTE':'SEGUNDO NOMBRE DEL ACUDIENTE',\n                                                                'UBICACION DEL\\xa0 ESTABLECIMIENTO EDUCATIVO DEL BENEFICIARIO':'UBICACION DEL ESTABLECIMIENTO EDUCATIVO DEL BENEFICIARIO'})\n    return data_frames\n</code></pre> <p><code>normalize</code> elimina las tildes de un texto, reemplaz\u00e1ndolas por sus versiones sin acento, tanto en min\u00fasculas como en may\u00fasculas.</p> <pre><code>def normalize(s):\n    replacements = (\n        (\"\u00e1\", \"a\"),\n        (\"\u00e9\", \"e\"),\n        (\"\u00ed\", \"i\"),\n        (\"\u00f3\", \"o\"),\n        (\"\u00fa\", \"u\"),\n    )\n    for a, b in replacements:\n        s = s.replace(a, b).replace(a.upper(), b.upper())\n    return s\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-presave","title":"Funci\u00f3n <code>PreSave</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_27","title":"Prop\u00f3sito","text":"<p>Realiza un preprocesamiento de columnas en un DataFrame, limpiando y normalizando valores textuales, y opcionalmente eliminando signos de puntuaci\u00f3n espec\u00edficos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_27","title":"Entradas","text":"<ul> <li><code>df</code> (DataFrame): DataFrame original que se desea procesar.</li> <li><code>columnList</code> (list): Lista de columnas del DataFrame que ser\u00e1n procesadas.</li> <li><code>signs</code> (bool, opcional): Si es <code>True</code>, elimina signos de puntuaci\u00f3n como <code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code> de las columnas. Por defecto: <code>False</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_25","title":"Funcionamiento","text":"<ol> <li> <p>Copiar el DataFrame:</p> <ul> <li>Crea una copia del DataFrame original para evitar modificaciones en el objeto original.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n:</p> <ul> <li>Reemplazos espec\u00edficos:<ul> <li>Convierte <code>\\xf1</code> a <code>ni</code> (e.g., \"\u00f1\" a \"ni\").</li> <li>Convierte <code>\\xD1</code> a <code>NI</code> (e.g., \"\u00d1\" a \"NI\").</li> <li>Sustituye caracteres no rompibles (<code>\\u00A0</code>) por espacios.</li> </ul> </li> <li>Eliminaci\u00f3n de espacios:<ul> <li>Reemplaza espacios dobles por simples.</li> <li>Elimina espacios al inicio y final de las cadenas.</li> </ul> </li> <li>Normalizaci\u00f3n de texto:<ul> <li>Convierte los valores a cadenas en may\u00fasculas.</li> <li>Aplica la funci\u00f3n <code>normalize</code> para eliminar tildes.</li> <li>Reemplaza comas por espacios.</li> </ul> </li> <li>Gesti\u00f3n de valores nulos:<ul> <li>Sustituye valores <code>\"NAN\"</code> por <code>np.nan</code>.</li> </ul> </li> </ul> </li> <li> <p>Eliminaci\u00f3n de signos (opcional):</p> <ul> <li>Si <code>signs=True</code>, elimina signos de puntuaci\u00f3n (<code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code>) utilizando expresiones regulares.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_26","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame con las columnas especificadas procesadas y normalizadas.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-uso","title":"Ejemplo de uso","text":"<p>Si la entrada es: <pre><code>df = pd.DataFrame({'col1': ['\u00a1Hola, mundo!', '\u00bfQu\u00e9 tal?']})\nPreSave(df, ['col1'], signs=True)\n</code></pre></p> <p>La salida ser\u00e1: <pre><code>      col1\n0    HOLA MUNDO\n1    QUE TAL\n</code></pre></p> <pre><code>def PreSave(df , columnList, signs = False):\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xf1', 'ni'))\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xD1', 'NI'))\n\n    datfra = df.copy()\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xf1', 'ni'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xD1', 'NI'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('\\u00A0', ' '))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('  ', ' '))\n    datfra[columnList] = datfra[columnList].astype(str)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.strip())\n    datfra[columnList] = datfra[columnList].map(normalize)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.upper())\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(',', ' '))\n    datfra[columnList] = datfra[columnList].replace('NAN', np.nan)\n\n    if signs == True:\n        for col in columnList:\n            try:\n                datfra[col] = datfra[col].apply(lambda x: re.sub(r'[\u00a1!?\u00bf]', '', x) )\n            except:\n                print('Not Signs fixed for '+ col)\n\n    return datfra\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funciones-sorted_answer-y-fix_table_answers","title":"Funciones <code>Sorted_Answer</code> y <code>Fix_Table_Answers</code>","text":""},{"location":"00.etl/Utils/Funciones/#funcion-sorted_answer","title":"Funci\u00f3n <code>Sorted_Answer</code>","text":"<p>Prop\u00f3sito: Ordena alfab\u00e9ticamente las respuestas separadas por punto y coma (<code>;</code>) dentro de una cadena. Elimina valores vac\u00edos si existen.</p> <p>Entradas:</p> <ul> <li><code>x</code> (str o NaN): Cadena de texto con respuestas separadas por punto y coma o un valor nulo.</li> </ul> <p>Funcionamiento:</p> <ol> <li>Verifica si la entrada es nula (<code>NaN</code>). Si es as\u00ed, retorna la entrada sin cambios.</li> <li>Divide la cadena en una lista utilizando <code>split(';')</code>.</li> <li>Si hay m\u00e1s de una respuesta:<ul> <li>Ordena alfab\u00e9ticamente la lista.</li> <li>Elimina entradas vac\u00edas si est\u00e1n presentes.</li> <li>Reconstruye la cadena uniendo los valores con <code>;</code>.</li> </ul> </li> <li>Retorna la cadena ordenada o la entrada original si no se cumplen las condiciones.</li> </ol> <p>Salida:</p> <ul> <li><code>str</code> o <code>NaN</code>: Cadena con las respuestas ordenadas alfab\u00e9ticamente o valor original si no hay cambios.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcion-fix_table_answers","title":"Funci\u00f3n <code>Fix_Table_Answers</code>","text":"<p>Prop\u00f3sito:</p> <p>Aplica la funci\u00f3n <code>Sorted_Answer</code> a una columna espec\u00edfica de un DataFrame, actualizando la columna con las respuestas ordenadas.</p> <pre><code>def Sorted_Answer(x):\n    if pd.isnull(x):\n        return x\n    p =  x.split(';') \n    if len(p) &gt; 1:\n        p = sorted(p)\n        p.remove('')\n        p = ';'.join(p)\n        return p\n    return x\n\n\ndef Fix_Table_Answers( table , column_name ):\n    table['RESPUESTA_LIST'] = table[column_name].apply( lambda x: Sorted_Answer(x) )\n    table = table.drop([ column_name ], axis=1)\n    table = table.rename(columns={'RESPUESTA_LIST': column_name})\n\n    return table\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-fix_id_type_caract","title":"Funci\u00f3n <code>Fix_Id_Type_Caract</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_28","title":"Prop\u00f3sito","text":"<p>Estandariza y transforma diferentes representaciones de tipos de identificaci\u00f3n en c\u00f3digos abreviados predefinidos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_28","title":"Entradas","text":"<ul> <li><code>id_type</code> (str): Cadena de texto que representa un tipo de identificaci\u00f3n, como \"CEDULA DE CIUDADANIA\" o \"TARJETA DE IDENTIDAD\".</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_26","title":"Funcionamiento","text":"<ol> <li>Utiliza una estructura <code>match-case</code> para comparar el valor de <code>id_type</code> con diferentes representaciones conocidas.</li> <li>Devuelve el c\u00f3digo abreviado correspondiente:<ul> <li><code>CC</code>: C\u00e9dula de ciudadan\u00eda.</li> <li><code>TI</code>: Tarjeta de identidad.</li> <li><code>RC</code>: Registro civil.</li> <li><code>PE</code>: Permiso especial de permanencia.</li> <li><code>PPT</code>: Permiso especial de permanencia temporal.</li> <li><code>PA</code>: Pasaporte.</li> <li><code>CE</code>: Identificaci\u00f3n extranjera.</li> <li><code>NI</code>: NIT.</li> <li><code>NA</code>: No aplica o no reconocido.</li> </ul> </li> <li>Si no encuentra una coincidencia, devuelve el valor por defecto <code>NA</code>.</li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_27","title":"Salida","text":"<ul> <li><code>str</code>: C\u00f3digo abreviado del tipo de identificaci\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-uso_1","title":"Ejemplo de uso","text":"<p>Entrada: <pre><code>Fix_Id_Type_Caract('CEDULA DE CIUDADANIA')\n</code></pre></p> <p>Salida: <pre><code>'CC'\n</code></pre></p> <pre><code>def Fix_Id_Type_Caract(id_type):\n    match id_type:\n        case '1.CEDULA DE CIUDADANIA':\n             return 'CC'\n        case '2.TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3.REGISTRO CIVIL':\n             return 'RC'\n        case '1. CEDULA':\n             return 'CC'\n        case 'TARJETA DE IDENTIDAD':\n             return 'TI'\n        case 'CEDULA DE CIUDADANIA':\n             return 'CC'\n        case 'REGISTRO CIVIL':\n             return 'RC'\n        case '2. TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3. REGISTRO CIVIL':\n             return 'RC'\n        case '9. PERMISO ESPECIAL DE PERMANENCIA (P.E.P)':\n             return 'PE'\n        case '15. PERMISO ESPECIAL DE PERMANENCIA TEMPORAL':\n             return 'PPT'\n        case '11.\\xa0 IDENTIFICACION DADA POR LA SECRETARIA DE EDUCACION':\n             return 'NA'\n        case '14. ID EXTRANJEROS DIFERENTE A LA CEDULA DE EXTRANJERIA (SOLO PARA FONINIEZ)':\n             return 'C1X'\n        case '6. PASAPORTE':\n             return 'PA'\n        case '5. NUIP':\n             return 'NA'\n        case 'CERTIFICADO DE NACIMIENTO':\n             return 'RC'\n        case 'ID EXTRANJERO':\n             return 'CE'   \n        case 'NIT':\n             return 'NI' \n        case 'NONE':\n             return 'NA'         \n        case _:\n            return 'NA'\n\n    return 'NA'\n</code></pre> <p><code>Fix_Id_Type</code> aplica la transformaci\u00f3n de tipos de identificaci\u00f3n en una columna espec\u00edfica de una tabla si el nombre de la tabla es <code>\"CARACTERIZACION\"</code>.</p> <p><code>Truncate_Column</code> trunca el contenido de las columnas especificadas a un m\u00e1ximo de 255 caracteres. Por otro lado, <code>Fix_Datetime</code> convierte valores tipo <code>NaT</code> a un valor predeterminado (<code>2009-01-01 00:00:00</code>) y agrega la hora inicial a fechas v\u00e1lidas. </p> <p>Finalmente, <code>Fix_DatetimeFinal</code> normaliza una columna de fechas en un DataFrame, convirti\u00e9ndolas a formato <code>datetime</code>, estableciendo la hora como 00:00:00, y manejando errores de conversi\u00f3n de forma segura.</p> <pre><code>def Fix_Id_Type( table , typeIdColumn , tableName ):\n    if tableName == 'CARACTERIZACION':\n        table[typeIdColumn] = table[typeIdColumn].apply( Fix_Id_Type_Caract )\n\ndef Truncate_Column( table , columnsToTruncate ):\n    table[columnsToTruncate] = table[columnsToTruncate].astype(str).apply(lambda x: x.str[:255])\n\n\ndef Fix_Datetime(x):\n    if x == 'NaT':\n        return '2009-01-01 00:00:00'    \n    return x + ' 00:00:00'\n\ndef Fix_DatetimeFinal(table, columnName):\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = pd.to_datetime(table[columnName], format='%Y-%m-%d %H:%M:%S', errors='coerce',dayfirst=True)\n    table[columnName] = table[columnName].apply(lambda x: x.replace(hour=0, minute=0, second=0))\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = table[columnName].apply(lambda x: Fix_Datetime(x)   )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-fix_questions","title":"Funci\u00f3n <code>Fix_Questions</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_29","title":"Prop\u00f3sito","text":"<p>Transforma y organiza un DataFrame de respuestas de encuestas, estructur\u00e1ndolo para an\u00e1lisis, incluyendo la identificaci\u00f3n de preguntas relacionadas con NPS (Net Promoter Score).</p>"},{"location":"00.etl/Utils/Funciones/#entradas_29","title":"Entradas","text":"<ul> <li><code>data</code> (DataFrame): DataFrame original con datos de encuestas.</li> <li><code>servicio</code> (str): Nombre del servicio asociado a las encuestas.</li> <li><code>nps</code> (dict): Diccionario que mapea servicios a preguntas relacionadas con NPS.</li> <li><code>filename</code> (str): Nombre del archivo relacionado para fines de registro.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_27","title":"Funcionamiento","text":"<ol> <li> <p>Renombramiento de columnas:</p> <ul> <li>Cambia el nombre de las columnas <code>fecha</code> a <code>FECHA_ENCUESTA</code> y <code>identificacion</code> a <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas:</p> <ul> <li>Busca columnas cuyo nombre comience con <code>\"etapa3\"</code>, que representan preguntas con calificaci\u00f3n.</li> </ul> </li> <li> <p>Filtrado de columnas relevantes:</p> <ul> <li>Redefine el DataFrame para incluir solo las columnas: <code>FECHA_ENCUESTA</code>, <code>DOCUMENTO</code>, y las preguntas identificadas.</li> </ul> </li> <li> <p>Transformaci\u00f3n de datos:</p> <ul> <li>Transforma el DataFrame a un formato largo utilizando <code>melt</code>:<ul> <li><code>id_vars</code>: Columnas constantes (<code>FECHA_ENCUESTA</code> y <code>DOCUMENTO</code>).</li> <li><code>var_name</code>: Nombre de las columnas de preguntas (<code>PREGUNTA</code>).</li> <li><code>value_name</code>: Valores asociados a las preguntas (<code>CALIFICACION</code>).</li> </ul> </li> </ul> </li> <li> <p>Adici\u00f3n de columnas constantes:</p> <ul> <li>Agrega columnas adicionales:<ul> <li><code>SERVICIO</code>: Nombre del servicio.</li> <li><code>TIPO_DOCUMENTO</code>: Fijado como <code>'CC'</code>.</li> <li><code>NPS</code>: Inicializado como <code>'NO'</code>.</li> </ul> </li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas NPS:</p> <ul> <li>Actualiza la columna <code>NPS</code> a <code>'SI'</code> para las preguntas que coinciden con el servicio especificado en el diccionario <code>nps</code>.</li> </ul> </li> <li> <p>Salida del DataFrame:</p> <ul> <li>Registra el nombre del servicio y archivo procesado.</li> <li>Devuelve el DataFrame transformado.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>En caso de error, registra el servicio y archivo no procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_28","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame transformado en formato largo con las siguientes columnas:</li> <li><code>FECHA_ENCUESTA</code></li> <li><code>DOCUMENTO</code></li> <li><code>PREGUNTA</code></li> <li><code>CALIFICACION</code></li> <li><code>SERVICIO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NPS</code></li> </ul> <pre><code>def Fix_Questions( data , servicio , nps, filename):\n\n    try:\n        df = data  \n        #Modificaciones a columnas\n        df = df.rename(columns={'fecha': 'FECHA_ENCUESTA',\n                                'identificacion':'DOCUMENTO'\n                            })\n\n        #Buscar preguntas con nota\n        dfColumns = df.columns.tolist()\n        columnsWithObs = [val for val in dfColumns if val.startswith(\"etapa3\") ]\n\n        #Redefinir columna\n        df = df[['FECHA_ENCUESTA','DOCUMENTO']+columnsWithObs]\n\n        #Modificaciones y transpocision \n        df_unp = df.melt( id_vars = ['FECHA_ENCUESTA','DOCUMENTO'] , var_name=\"PREGUNTA\", value_name=\"CALIFICACION\")\n        df_unp['SERVICIO'] = servicio\n        df_unp['TIPO_DOCUMENTO'] = 'CC'\n        df_unp['NPS'] = 'NO'\n\n\n        df_unp.loc[df_unp[\"PREGUNTA\"] == nps[servicio], \"NPS\"] = 'SI'\n        print('Agregado: ' +  servicio + filename )\n        return df_unp\n    except:\n        print('Sin formato: ' +  servicio + filename )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-charge_excel_fixed","title":"Funci\u00f3n <code>Charge_Excel_Fixed</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_30","title":"Prop\u00f3sito","text":"<p>Carga un archivo Excel utilizando <code>xlwings</code>, procesa los datos de la primera hoja, y los guarda en un DataFrame despu\u00e9s de limpiar filas y columnas vac\u00edas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_30","title":"Entradas","text":"<ul> <li><code>ruta</code> (str): Ruta del archivo Excel a cargar.</li> <li><code>dfs</code> (dict): Diccionario donde se almacenar\u00e1 el DataFrame procesado, con el nombre del archivo como clave.</li> <li><code>file</code> (str): Nombre del archivo para usarlo como clave en el diccionario <code>dfs</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_28","title":"Funcionamiento","text":"<ol> <li> <p>Carga del archivo Excel:</p> <ul> <li>Utiliza <code>xlwings</code> para abrir el archivo Excel y seleccionar la primera hoja (<code>sheet[0]</code>).</li> </ul> </li> <li> <p>Lectura de datos:</p> <ul> <li>Lee todos los datos de la hoja utilizando <code>sheet.used_range.value</code>.</li> </ul> </li> <li> <p>Creaci\u00f3n del DataFrame:</p> <ul> <li>Convierte los datos le\u00eddos en un DataFrame de pandas.</li> </ul> </li> <li> <p>Limpieza de datos:</p> <ul> <li>Elimina filas y columnas que est\u00e9n completamente vac\u00edas utilizando <code>dropna()</code>.</li> <li>Resetea el \u00edndice del DataFrame con <code>reset_index(drop=True)</code>.</li> </ul> </li> <li> <p>Ajustes adicionales:</p> <ul> <li>Elimina las primeras dos filas (<code>df.drop([0, 1])</code>).</li> <li>Asigna la primera fila como los nombres de las columnas (<code>df.columns = df.iloc[0]</code>).</li> <li>Elimina la primera fila despu\u00e9s de asignarla como encabezado.</li> </ul> </li> <li> <p>Guardar el DataFrame:</p> <ul> <li>Guarda el DataFrame limpio en el diccionario <code>dfs</code> con el nombre del archivo como clave.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_29","title":"Salida","text":"<ul> <li>No retorna valores. El DataFrame limpio se almacena en el diccionario <code>dfs</code> bajo la clave <code>file</code>.</li> </ul> <pre><code>def Charge_Excel_Fixed( ruta , dfs , file ):\n    # Cargar el archivo Excel utilizando xlwings\n    wb = xw.Book(ruta)\n    sheet = wb.sheets[0]  # Seleccionar la primera hoja\n\n    # Leer todos los datos de la hoja\n    data = sheet.used_range.value\n\n    # Crear un DataFrame a partir de los datos le\u00eddos\n    df = pd.DataFrame(data)\n\n    # Eliminar filas completamente en blanco\n    df.dropna(how='all', inplace=True)\n\n    # Eliminar columnas completamente en blanco\n    df.dropna(axis=1, how='all', inplace=True)\n\n    wb.close()\n\n    df.reset_index(drop=True, inplace=True)\n    df = df.drop([0, 1])\n\n    df.columns = df.iloc[0]  \n    df = df[1:].reset_index(drop=True)  \n\n    dfs[file] = df\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funciones-combine_and_store_unparametro-y-combine_and_store","title":"Funciones <code>Combine_and_store_unparametro</code> y <code>Combine_and_store</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_31","title":"Prop\u00f3sito","text":"<p>Las funciones combinan m\u00faltiples archivos de una carpeta en un solo DataFrame, y opcionalmente, guardan el DataFrame combinado en un archivo Excel en una carpeta de destino especificada.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_31","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL de la carpeta que contiene los archivos a combinar.</li> <li><code>download_folder</code> (str, opcional): Ruta del directorio donde se guardar\u00e1 el archivo Excel combinado. Si es <code>None</code>, el DataFrame no se guarda.</li> <li><code>names_file</code> (str, opcional): Nombre del archivo donde se guardar\u00e1 el DataFrame combinado (solo si <code>download_folder</code> no es <code>None</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_29","title":"Funcionamiento","text":"<ol> <li> <p>Carga y procesamiento de archivos:</p> <ul> <li>Ambas funciones utilizan <code>process_files_from_folder</code> para procesar los archivos dentro de <code>folder_url</code>, almacenando los DataFrames en la lista <code>dfs</code>.</li> </ul> </li> <li> <p>Combinaci\u00f3n de DataFrames:</p> <ul> <li>Si se encontraron archivos, los DataFrames en <code>dfs</code> se combinan utilizando <code>pd.concat(dfs, ignore_index=True)</code>.</li> <li>El DataFrame combinado se registra en el log mostrando las primeras filas con <code>df_combined.head()</code>.</li> </ul> </li> <li> <p>Guardado del DataFrame combinado (si aplica):</p> <ul> <li>Si se proporciona <code>download_folder</code>, se verifica si la carpeta existe. Si no, se crea utilizando <code>os.makedirs()</code>.</li> <li>Luego, guarda el DataFrame combinado en un archivo Excel dentro de <code>download_folder</code> con el nombre especificado en <code>names_file</code>.</li> <li>Registra la ruta donde se guarda el archivo en el log.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Si <code>download_folder</code> es <code>None</code>, devuelve el DataFrame combinado.</li> <li>Si <code>download_folder</code> se especifica, guarda el archivo y no retorna nada.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_30","title":"Salida","text":"<ul> <li><code>DataFrame</code>: Si <code>download_folder</code> es <code>None</code>, retorna el DataFrame combinado.</li> <li><code>None</code>: Si se guarda el archivo Excel, no retorna ning\u00fan valor.</li> </ul> <pre><code># Funcion para almacenar los DataFrames &lt;-------------------------------------------\ndef Combine_and_store_unparametro(folder_url,download_folder =None, names_file=None):\n    dfs = []\n    process_files_from_folder(folder_url, dfs)\n    if dfs:\n        df_combined = pd.concat(dfs, ignore_index=True)\n        logger.info(\"Contenido combinado: \\n{}\".format(df_combined.head()))        \n        return df_combined\n\ndef Combine_and_store(folder_url,  download_folder =None , names_file =None):\n    dfs = []\n    process_files_from_folder(folder_url, dfs)\n    if dfs:\n        df_combined = pd.concat(dfs, ignore_index=True)\n        logger.info(\"Contenido combinado: \\n{}\".format(df_combined.head()))\n\n        # si download_folder no es None\n        if download_folder is not None:            \n            # Verificar si la carpeta de destino existe, si no, crearla\n            if not os.path.exists(download_folder):\n                os.makedirs(download_folder, exist_ok=True)\n\n            # Guardar el DataFrame combinado en un archivo Excel\n            output_path = os.path.join(download_folder, names_file)\n            df_combined.to_excel(output_path, index=False)\n            print(f\"Archivo guardado en {output_path}\")\n        else:\n            return df_combined\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-conection_to_c4c","title":"Funci\u00f3n <code>conection_to_C4C</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_32","title":"Prop\u00f3sito","text":"<p>Automatiza el proceso de inicio de sesi\u00f3n en la p\u00e1gina de C4C utilizando Selenium, ingresando las credenciales proporcionadas y haciendo clic en el bot\u00f3n de inicio de sesi\u00f3n.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_32","title":"Entradas","text":"<ul> <li><code>driver</code> (webdriver.Chrome): Instancia de Selenium WebDriver utilizada para interactuar con la p\u00e1gina web.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_30","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n de credenciales:</p> <ul> <li>Recupera el nombre de usuario y la contrase\u00f1a para el inicio de sesi\u00f3n en C4C mediante la funci\u00f3n <code>credenciales(\"C4C\")</code>.</li> </ul> </li> <li> <p>Localizaci\u00f3n de los elementos de inicio de sesi\u00f3n:</p> <ul> <li>Utiliza <code>WebDriverWait</code> para esperar hasta que los elementos necesarios para el inicio de sesi\u00f3n (campos de usuario y contrase\u00f1a, y el bot\u00f3n de login) sean visibles y clickeables.</li> <li>Los elementos son localizados por sus identificadores (<code>USERNAME_FIELD-inner</code>, <code>PASSWORD_FIELD-inner</code>) y el bot\u00f3n de inicio de sesi\u00f3n por su XPath.</li> </ul> </li> <li> <p>Ingreso de credenciales:</p> <ul> <li>Escribe el nombre de usuario y la contrase\u00f1a en los campos correspondientes.</li> </ul> </li> <li> <p>Env\u00edo del formulario de inicio de sesi\u00f3n:</p> <ul> <li>Hace clic en el bot\u00f3n de inicio de sesi\u00f3n para completar el proceso de login.</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Si el inicio de sesi\u00f3n es exitoso, registra un mensaje en el log indicando que el login fue exitoso.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_31","title":"Salida","text":"<ul> <li>No retorna valores. Realiza el inicio de sesi\u00f3n y registra el resultado en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#excepciones_1","title":"Excepciones","text":"<ul> <li><code>TimeoutException</code>: Si alguno de los elementos de la p\u00e1gina (campo de usuario, campo de contrase\u00f1a o bot\u00f3n de inicio de sesi\u00f3n) no se encuentra dentro del tiempo especificado.</li> </ul> <pre><code>def conection_to_C4C(driver):\n    username, password = credenciales(\"C4C\")\n\n    \"\"\"\n    Logs in to the C4C website using the provided credentials.\n\n    Args:\n        driver (webdriver.Chrome): The Selenium WebDriver instance.\n        username (str): The username for C4C login.\n        password (str): The password for C4C login.\n\n    Raises:\n        TimeoutException: If the login elements are not found within the timeout window.\n    \"\"\"\n\n    # Find login elements\n    username_field = WebDriverWait(driver, 10).until(\n        EC.presence_of_element_located((By.ID, \"USERNAME_FIELD-inner\"))\n    )\n    password_field = WebDriverWait(driver, 10).until(\n        EC.presence_of_element_located((By.ID, \"PASSWORD_FIELD-inner\"))\n    )\n    login_button = WebDriverWait(driver, 15).until(\n            EC.element_to_be_clickable((By.XPATH, \"//button[@type='submit']\"))\n    )\n\n    # Enter credentials and submit\n    username_field.send_keys(username)\n    password_field.send_keys(password)\n    login_button.click()\n\n    logging.info(\"Login Successful\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-download_file_between_dates","title":"Funci\u00f3n <code>download_file_between_dates</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_33","title":"Prop\u00f3sito","text":"<p>Automatiza el proceso de descargar un archivo de C4C entre dos fechas especificadas, interactuando con los campos de fecha y las opciones del formulario.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_33","title":"Entradas","text":"<ul> <li><code>initial_date</code> (str): Fecha de inicio en formato de texto (ej. <code>'01/01/2022'</code>).</li> <li><code>final_date</code> (str): Fecha de finalizaci\u00f3n en formato de texto (ej. <code>'12/31/2022'</code>).</li> <li><code>driver</code> (webdriver.Chrome): Instancia de Selenium WebDriver utilizada para interactuar con la p\u00e1gina de C4C.</li> <li><code>_dict</code> (dict): Diccionario que mapea nombres de campos de fecha y otras opciones a sus localizadores correspondientes (por ejemplo, <code>{'initial_date': 'field_id', 'final_date': 'field_id', 'option_1': 'option_xpath'}</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_31","title":"Funcionamiento","text":"<ol> <li> <p>Conexi\u00f3n a C4C:</p> <ul> <li>Llama a la funci\u00f3n <code>conection_to_C4C(driver)</code> para iniciar sesi\u00f3n en C4C utilizando las credenciales.</li> </ul> </li> <li> <p>Interacci\u00f3n con el formulario:</p> <ul> <li>Itera sobre las claves del diccionario <code>_dict</code>.</li> <li>Si la clave no es <code>'initial_date'</code> ni <code>'final_date'</code>, hace clic en el elemento correspondiente usando la funci\u00f3n <code>click_and_wait(driver, _dict[option])</code>.</li> <li>Si la clave es <code>'initial_date'</code>, ingresa la fecha de inicio en el campo correspondiente.</li> <li>Si la clave es <code>'final_date'</code>, ingresa la fecha de finalizaci\u00f3n en el campo correspondiente.</li> </ul> </li> <li> <p>Esperas:</p> <ul> <li>Se utiliza un <code>time.sleep(4)</code> despu\u00e9s de llenar las fechas para asegurarse de que los campos se actualicen correctamente.</li> <li>Se espera 40 segundos (<code>time.sleep(40)</code>) para dar tiempo a que la descarga se complete.</li> </ul> </li> <li> <p>Cierre del WebDriver:</p> <ul> <li>Despu\u00e9s de completar la acci\u00f3n, cierra el WebDriver con <code>driver.quit()</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_32","title":"Salida","text":"<ul> <li>No retorna valores. Realiza la descarga del archivo y cierra la sesi\u00f3n del WebDriver.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#excepciones_2","title":"Excepciones","text":"<ul> <li>Posibles excepciones de Selenium: Si los elementos no son encontrados, la funci\u00f3n podr\u00eda lanzar errores relacionados con la localizaci\u00f3n de elementos o interacci\u00f3n con los campos.</li> </ul> <pre><code>def download_file_between_dates(initial_date, final_date, driver,_dict):\n    # Conexi\u00f3n a C4C\n    conection_to_C4C(driver)\n    # Iterar sobre las opciones en el diccionario\n    for option in _dict:\n        if option not in (\"initial_date\", \"final_date\"):\n            click_and_wait(driver, _dict[option])\n        elif option == \"initial_date\":\n            date_input = driver.find_element(By.ID, _dict[option])\n            date_input.send_keys(initial_date)\n        elif option == \"final_date\":\n            date_input = driver.find_element(By.ID, _dict[option])\n            date_input.send_keys(final_date)\n        time.sleep(4)\n\n    # Tiempo de espera adicional para asegurarse de que la descarga se complete\n    time.sleep(40)  \n\n    # Cerrar el WebDriver\n    driver.quit()\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-click_and_wait","title":"Funci\u00f3n <code>click_and_wait</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_34","title":"Prop\u00f3sito","text":"<p>Hace clic en un elemento localizado mediante XPath y espera a que la p\u00e1gina se cargue o el elemento est\u00e9 listo para interactuar.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_34","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia de Selenium WebDriver utilizada para interactuar con la p\u00e1gina.</li> <li><code>xpath</code> (str): Expresi\u00f3n XPath que localiza el elemento en el DOM.</li> <li><code>timeout</code> (int, opcional): Tiempo m\u00e1ximo en segundos para esperar a que el elemento sea clickeable. El valor predeterminado es <code>30</code> segundos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_32","title":"Funcionamiento","text":"<ol> <li> <p>Esperar hasta que el elemento est\u00e9 clickeable:</p> <ul> <li>Utiliza <code>WebDriverWait</code> para esperar hasta que el elemento identificado por el XPath proporcionado est\u00e9 listo para ser clickeado.</li> </ul> </li> <li> <p>Clic en el elemento:</p> <ul> <li>Una vez que el elemento es clickeable, se realiza el clic en \u00e9l.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_33","title":"Salida","text":"<ul> <li>No retorna valores. Realiza el clic en el elemento especificado y espera a que se cargue.</li> </ul> <pre><code>def click_and_wait(driver, xpath, timeout=30):\n    \"\"\"\n    Clicks on an element identified by xpath and waits for the page to load.\n\n    Args:\n        driver: The WebDriver instance.\n        xpath: The xpath expression to locate the element.\n        timeout: The maximum wait time in seconds (default: 20).\n    \"\"\"\n    link_to_click = WebDriverWait(driver, timeout).until(\n        EC.element_to_be_clickable((By.XPATH, xpath))\n    )\n    link_to_click.click()\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/","title":"Funciones_DM.py","text":"<p>Este archivo contiene una serie de funciones automatizadas desarrolladas para gestionar tareas comunes en la manipulaci\u00f3n de datos y la interacci\u00f3n con sistemas externos. Las funciones descritas est\u00e1n dise\u00f1adas principalmente para automatizar procesos en plataformas como SharePoint y sistemas como C4C, as\u00ed como para facilitar el procesamiento de datos utilizando herramientas como pandas y xlwings.</p> <p>Las funciones cubren una variedad de tareas, incluyendo:</p> <ol> <li> <p>Autenticaci\u00f3n y acceso a plataformas externas:</p> <ul> <li><code>get_file_from_sharepoint</code>: Automatiza la descarga de archivos desde SharePoint.</li> <li><code>list_files_from_sharepoint</code>: Lista archivos en una carpeta de SharePoint.</li> <li><code>process_files_from_folder</code>: Procesa archivos en una carpeta de SharePoint.</li> </ul> </li> <li> <p>Interacci\u00f3n con men\u00fas desplegables y formularios web:</p> <ul> <li>No se incluyen funciones espec\u00edficas para esta tarea en el c\u00f3digo proporcionado.</li> </ul> </li> <li> <p>Descarga y procesamiento de datos:</p> <ul> <li><code>get_file_from_sharepoint</code>: Descarga archivos desde SharePoint.</li> <li><code>process_files_from_folder</code>: Procesa y lee archivos Excel sin descargarlos.</li> </ul> </li> <li> <p>Manejo de archivos y directorios:</p> <ul> <li><code>Charge_Excel_Fixed</code>: Carga y procesa archivos Excel, incluso si est\u00e1n comprimidos en un archivo ZIP.</li> <li><code>_Charge_Excel_Fixed</code>: Carga archivos Excel utilizando xlwings.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n de datos:</p> <ul> <li><code>normalize</code>: Normaliza cadenas de texto.</li> <li><code>PreSave</code>: Preprocesa y limpia datos en un DataFrame.</li> <li><code>Sorted_Answer</code>: Ordena respuestas en una cadena separada por punto y coma.</li> <li><code>Fix_Table_Answers</code>: Ajusta respuestas en una tabla.</li> <li><code>Fix_Id_Type_Caract</code> y <code>Fix_Id_Type</code>: Normalizan tipos de identificaci\u00f3n.</li> <li><code>Truncate_Column</code>: Trunca columnas a una longitud espec\u00edfica.</li> <li><code>Fix_Datetime</code> y <code>Fix_DatetimeFinal</code>: Ajustan formatos de fecha y hora.</li> <li><code>Fix_Questions</code>: Modifica y transpone columnas de preguntas en un DataFrame.</li> </ul> </li> </ol> <p>Este conjunto de herramientas es esencial para mejorar la eficiencia en tareas repetitivas, reduciendo la necesidad de intervenci\u00f3n manual y permitiendo una integraci\u00f3n m\u00e1s fluida entre los sistemas externos y el entorno de trabajo. La automatizaci\u00f3n de estos procesos optimiza el flujo de trabajo y facilita la administraci\u00f3n y procesamiento de grandes vol\u00famenes de datos.</p>"},{"location":"00.etl/Utils/Funciones_DM/#configuracion-e-importacion-de-librerias","title":"Configuraci\u00f3n e importaci\u00f3n de Librer\u00edas","text":"<p>Este bloque de c\u00f3digo configura el entorno de trabajo importando todas las librer\u00edas necesarias para manipulaci\u00f3n de datos, automatizaci\u00f3n de Excel, autenticaci\u00f3n y automatizaci\u00f3n de navegadores web. <code>Funciones.py</code> importa varias librer\u00edas est\u00e1ndar y externas necesarias para el funcionamiento del script.</p>"},{"location":"00.etl/Utils/Funciones_DM/#librerias-estandar","title":"Librer\u00edas est\u00e1ndar","text":"<ul> <li><code>datetime</code></li> <li><code>json</code></li> <li><code>re</code></li> <li><code>requests</code></li> <li><code>timedelta</code></li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#librerias-externas","title":"Librer\u00edas externas","text":"<ul> <li><code>numpy</code></li> <li><code>pandas</code></li> <li><code>xlwings</code></li> <li><code>zipfile</code></li> <li><code>log_step_decorator</code> (de <code>Utils.Funciones</code>)</li> </ul> <pre><code># pylint: disable=all\n# import pandas lib as pd\nimport numpy as np\nimport pandas as pd\nimport re\nimport xlwings as xw\nimport json\nimport requests\nfrom datetime import datetime, timedelta\nfrom Utils.Funciones import log_step_decorator\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#get_file_from_sharepoint","title":"<code>get_file_from_sharepoint</code>","text":"<p>Descarga un archivo desde SharePoint utilizando su URL. Recibe como entrada <code>file_url</code> (str), que especifica la ubicaci\u00f3n del archivo, y devuelve el contenido del archivo como bytes si la solicitud es exitosa. En caso de error, retorna <code>None</code> y registra una advertencia con el c\u00f3digo de estado de la respuesta.</p> <pre><code>@log_step_decorator(\"Obtener archivo de SharePoint\")\ndef get_file_from_sharepoint(file_url, headers):\n    response = requests.get(file_url, headers=headers)\n    print(f\"Response Status Code: {response.status_code}\")\n\n    if response.status_code == 200:\n        return response.content\n    else:\n        print(f\"Error al acceder al archivo. C\u00f3digo de estado: {response.status_code}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#list_files_from_sharepoint","title":"<code>list_files_from_sharepoint</code>","text":"<p>Obtiene una lista de archivos presentes en una carpeta de SharePoint indicada por la URL proporcionada. Recibe como entrada <code>folder_url</code> (str), que especifica la ubicaci\u00f3n de la carpeta, y devuelve una lista de archivos si la solicitud es exitosa o una lista vac\u00eda en caso de fallo. Tambi\u00e9n registra advertencias en caso de errores durante la solicitud.</p> <pre><code>@log_step_decorator(\"Listar archivos de SharePoint\")\ndef list_files_from_sharepoint(folder_url,headers,sharepoint_base_url):\n    list_files_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n    response = requests.get(list_files_url, headers=headers)\n\n\n    if response.status_code == 200:\n        files = response.json()['d']['results']\n        return files\n    else:\n        print(f\"Error al listar los archivos. C\u00f3digo de estado: {response.status_code}\")\n        return []\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-process_files_from_folder","title":"Funci\u00f3n <code>process_files_from_folder</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito","title":"Prop\u00f3sito","text":"<p>Procesa archivos de una carpeta de SharePoint que han sido modificados en los \u00faltimos seis meses, almacenando los datos en una lista de DataFrames.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL de la carpeta en SharePoint desde donde se obtendr\u00e1n los archivos.</li> <li><code>dfs</code> (list): Lista utilizada para almacenar los DataFrames procesados.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento","title":"Funcionamiento","text":"<ol> <li>Listar archivos: Obtiene la lista de archivos en la carpeta de SharePoint.</li> <li>Filtrar por fecha: Identifica archivos modificados en los \u00faltimos seis meses.</li> <li>Procesar archivos:<ul> <li>Recupera el contenido de los archivos seleccionados desde SharePoint.</li> <li>Lee el contenido de los archivos como DataFrames utilizando <code>pandas</code>.</li> <li>Registra informaci\u00f3n sobre el contenido y lo almacena en la lista <code>dfs</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida","title":"Salida","text":"<ul> <li>No retorna ning\u00fan valor. Modifica la lista <code>dfs</code> proporcionada al agregar los DataFrames procesados.</li> </ul> <pre><code>@log_step_decorator(\"Procesar archivos\")\ndef process_files_from_folder(folder_url, dfs,headers, sharepoint_base_url):\n\n    files = list_files_from_sharepoint(folder_url, headers, sharepoint_base_url)\n    six_months_ago = datetime.now() - timedelta(days=180)\n\n\n\n    for file in files:\n        file_name = file['Name']\n        file_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n        modified_date_str = file['TimeLastModified']\n        modified_date = datetime.strptime(modified_date_str, '%Y-%m-%dT%H:%M:%SZ')\n        print('MODIFY', modified_date)\n\n        if modified_date &gt;= six_months_ago:\n\n            # Obtener el archivo de SharePoint\n            file_content = get_file_from_sharepoint(file_url, headers)\n\n            if file_content:\n                # Leer el archivo Excel sin descargar\n                df = pd.read_excel(file_content)\n                print(f\"Contenido de {file_name}:\\n\", df.head())\n                dfs.append(df)\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#normalize","title":"<code>normalize</code>","text":"<p>Elimina las tildes de un texto, reemplaz\u00e1ndolas por sus versiones sin acento, tanto en min\u00fasculas como en may\u00fasculas.</p> <pre><code>def normalize(s):\n    replacements = (\n        (\"\u00e1\", \"a\"),\n        (\"\u00e9\", \"e\"),\n        (\"\u00ed\", \"i\"),\n        (\"\u00f3\", \"o\"),\n        (\"\u00fa\", \"u\"),\n    )\n    for a, b in replacements:\n        s = s.replace(a, b).replace(a.upper(), b.upper())\n    return s\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-presave","title":"Funci\u00f3n <code>PreSave</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_1","title":"Prop\u00f3sito","text":"<p>Realiza un preprocesamiento de columnas en un DataFrame, limpiando y normalizando valores textuales, y opcionalmente eliminando signos de puntuaci\u00f3n espec\u00edficos.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_1","title":"Entradas","text":"<ul> <li><code>df</code> (DataFrame): DataFrame original que se desea procesar.</li> <li><code>columnList</code> (list): Lista de columnas del DataFrame que ser\u00e1n procesadas.</li> <li><code>signs</code> (bool, opcional): Si es <code>True</code>, elimina signos de puntuaci\u00f3n como <code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code> de las columnas. Por defecto: <code>False</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_1","title":"Funcionamiento","text":"<ol> <li> <p>Copiar el DataFrame:</p> <ul> <li>Crea una copia del DataFrame original para evitar modificaciones en el objeto original.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n:</p> <ul> <li>Reemplazos espec\u00edficos:<ul> <li>Convierte <code>\\xf1</code> a <code>ni</code> (e.g., \"\u00f1\" a \"ni\").</li> <li>Convierte <code>\\xD1</code> a <code>NI</code> (e.g., \"\u00d1\" a \"NI\").</li> <li>Sustituye caracteres no rompibles (<code>\\u00A0</code>) por espacios.</li> </ul> </li> <li>Eliminaci\u00f3n de espacios:<ul> <li>Reemplaza espacios dobles por simples.</li> <li>Elimina espacios al inicio y final de las cadenas.</li> </ul> </li> <li>Normalizaci\u00f3n de texto:<ul> <li>Convierte los valores a cadenas en may\u00fasculas.</li> <li>Aplica la funci\u00f3n <code>normalize</code> para eliminar tildes.</li> <li>Reemplaza comas por espacios.</li> </ul> </li> <li>Gesti\u00f3n de valores nulos:<ul> <li>Sustituye valores <code>\"NAN\"</code> por <code>np.nan</code>.</li> </ul> </li> </ul> </li> <li> <p>Eliminaci\u00f3n de signos (opcional):</p> <ul> <li>Si <code>signs=True</code>, elimina signos de puntuaci\u00f3n (<code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code>) utilizando expresiones regulares.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_1","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame con las columnas especificadas procesadas y normalizadas.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#ejemplo-de-uso","title":"Ejemplo de uso","text":"<p>Si la entrada es: <pre><code>df = pd.DataFrame({'col1': ['\u00a1Hola, mundo!', '\u00bfQu\u00e9 tal?']})\nPreSave(df, ['col1'], signs=True)\n</code></pre></p> <p>La salida ser\u00e1: <pre><code>      col1\n0    HOLA MUNDO\n1    QUE TAL\n</code></pre></p> <pre><code>def PreSave(df , columnList, signs = False):\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xf1', 'ni'))\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xD1', 'NI'))\n\n    datfra = df.copy()\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xf1', 'ni'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xD1', 'NI'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('\\u00A0', ' '))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('  ', ' '))\n    datfra[columnList] = datfra[columnList].astype(str)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.strip())\n    datfra[columnList] = datfra[columnList].map(normalize)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.upper())\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(',', ' '))\n    datfra[columnList] = datfra[columnList].replace('NAN', np.nan)\n\n    if signs == True:\n        for col in columnList:\n            try:\n                datfra[col] = datfra[col].apply(lambda x: re.sub(r'[\u00a1!?\u00bf]', '', x) )\n            except:\n                print('Not Signs fixed for '+ col)\n\n    return datfra\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funciones-sorted_answer-y-fix_table_answers","title":"Funciones <code>Sorted_Answer</code> y <code>Fix_Table_Answers</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#funcion-sorted_answer","title":"Funci\u00f3n <code>Sorted_Answer</code>","text":"<p>Prop\u00f3sito: Ordena alfab\u00e9ticamente las respuestas separadas por punto y coma (<code>;</code>) dentro de una cadena. Elimina valores vac\u00edos si existen.</p> <p>Entradas:</p> <ul> <li><code>x</code> (str o NaN): Cadena de texto con respuestas separadas por punto y coma o un valor nulo.</li> </ul> <p>Funcionamiento:</p> <ol> <li>Verifica si la entrada es nula (<code>NaN</code>). Si es as\u00ed, retorna la entrada sin cambios.</li> <li>Divide la cadena en una lista utilizando <code>split(';')</code>.</li> <li>Si hay m\u00e1s de una respuesta:<ul> <li>Ordena alfab\u00e9ticamente la lista.</li> <li>Elimina entradas vac\u00edas si est\u00e1n presentes.</li> <li>Reconstruye la cadena uniendo los valores con <code>;</code>.</li> </ul> </li> <li>Retorna la cadena ordenada o la entrada original si no se cumplen las condiciones.</li> </ol> <p>Salida:</p> <ul> <li><code>str</code> o <code>NaN</code>: Cadena con las respuestas ordenadas alfab\u00e9ticamente o valor original si no hay cambios.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-fix_table_answers","title":"Funci\u00f3n <code>Fix_Table_Answers</code>","text":"<p>Prop\u00f3sito:</p> <p>Aplica la funci\u00f3n <code>Sorted_Answer</code> a una columna espec\u00edfica de un DataFrame, actualizando la columna con las respuestas ordenadas.</p> <pre><code>def Sorted_Answer(x):\n    if pd.isnull(x):\n        return x\n    p =  x.split(';') \n    if len(p) &gt; 1:\n        p = sorted(p)\n        p.remove('')\n        p = ';'.join(p)\n        return p\n    return x\n</code></pre> <pre><code>def Fix_Table_Answers( table , column_name ):\n    table['RESPUESTA_LIST'] = table[column_name].apply( lambda x: Sorted_Answer(x) )\n    table = table.drop([ column_name ], axis=1)\n    table = table.rename(columns={'RESPUESTA_LIST': column_name})\n\n    return table\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-fix_id_type_caract","title":"Funci\u00f3n <code>Fix_Id_Type_Caract</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_2","title":"Prop\u00f3sito","text":"<p>Estandariza y transforma diferentes representaciones de tipos de identificaci\u00f3n en c\u00f3digos abreviados predefinidos.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_2","title":"Entradas","text":"<ul> <li><code>id_type</code> (str): Cadena de texto que representa un tipo de identificaci\u00f3n, como \"CEDULA DE CIUDADANIA\" o \"TARJETA DE IDENTIDAD\".</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_2","title":"Funcionamiento","text":"<ol> <li>Utiliza una estructura <code>match-case</code> para comparar el valor de <code>id_type</code> con diferentes representaciones conocidas.</li> <li>Devuelve el c\u00f3digo abreviado correspondiente:<ul> <li><code>CC</code>: C\u00e9dula de ciudadan\u00eda.</li> <li><code>TI</code>: Tarjeta de identidad.</li> <li><code>RC</code>: Registro civil.</li> <li><code>PE</code>: Permiso especial de permanencia.</li> <li><code>PPT</code>: Permiso especial de permanencia temporal.</li> <li><code>PA</code>: Pasaporte.</li> <li><code>CE</code>: Identificaci\u00f3n extranjera.</li> <li><code>NI</code>: NIT.</li> <li><code>NA</code>: No aplica o no reconocido.</li> </ul> </li> <li>Si no encuentra una coincidencia, devuelve el valor por defecto <code>NA</code>.</li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_2","title":"Salida","text":"<ul> <li><code>str</code>: C\u00f3digo abreviado del tipo de identificaci\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#ejemplo-de-uso_1","title":"Ejemplo de uso","text":"<p>Entrada: <pre><code>Fix_Id_Type_Caract('CEDULA DE CIUDADANIA')\n</code></pre></p> <p>Salida: <pre><code>'CC'\n</code></pre></p> <p><pre><code>def Fix_Id_Type_Caract(id_type):\n    match id_type:\n        case '1.CEDULA DE CIUDADANIA':\n             return 'CC'\n        case '2.TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3.REGISTRO CIVIL':\n             return 'RC'\n        case '1. CEDULA':\n             return 'CC'\n        case 'TARJETA DE IDENTIDAD':\n             return 'TI'\n        case 'CEDULA DE CIUDADANIA':\n             return 'CC'\n        case 'REGISTRO CIVIL':\n             return 'RC'\n        case '2. TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3. REGISTRO CIVIL':\n             return 'RC'\n        case '9. PERMISO ESPECIAL DE PERMANENCIA (P.E.P)':\n             return 'PE'\n        case '15. PERMISO ESPECIAL DE PERMANENCIA TEMPORAL':\n             return 'PPT'\n        case '11.\\xa0 IDENTIFICACION DADA POR LA SECRETARIA DE EDUCACION':\n             return 'NA'\n        case '14. ID EXTRANJEROS DIFERENTE A LA CEDULA DE EXTRANJERIA (SOLO PARA FONINIEZ)':\n             return 'C1X'\n        case '6. PASAPORTE':\n             return 'PA'\n        case '5. NUIP':\n             return 'NA'\n        case 'CERTIFICADO DE NACIMIENTO':\n             return 'RC'\n        case 'ID EXTRANJERO':\n             return 'CE'   \n        case 'NIT':\n             return 'NI' \n        case 'NONE':\n             return 'NA'         \n        case _:\n            return 'NA'\n\n    return 'NA'\n</code></pre> <code>Fix_Id_Type</code> aplica la transformaci\u00f3n de tipos de identificaci\u00f3n en una columna espec\u00edfica de una tabla si el nombre de la tabla es <code>\"CARACTERIZACION\"</code>.</p> <p><code>Truncate_Column</code> trunca el contenido de las columnas especificadas a un m\u00e1ximo de 255 caracteres. Por otro lado, <code>Fix_Datetime</code> convierte valores tipo <code>NaT</code> a un valor predeterminado (<code>2009-01-01 00:00:00</code>) y agrega la hora inicial a fechas v\u00e1lidas. </p> <p>Finalmente, <code>Fix_DatetimeFinal</code> normaliza una columna de fechas en un DataFrame, convirti\u00e9ndolas a formato <code>datetime</code>, estableciendo la hora como 00:00:00, y manejando errores de conversi\u00f3n de forma segura.</p> <pre><code>def Fix_Id_Type( table , typeIdColumn , tableName ):\n    if tableName == 'CARACTERIZACION':\n        table[typeIdColumn] = table[typeIdColumn].apply( Fix_Id_Type_Caract )\n</code></pre> <pre><code>def Truncate_Column( table , columnsToTruncate ):\n    table[columnsToTruncate] = table[columnsToTruncate].astype(str).apply(lambda x: x.str[:255])\n</code></pre> <pre><code>def Fix_Datetime(x):\n    if x == 'NaT':\n        return '2009-01-01 00:00:00'    \n    return x + ' 00:00:00'\n</code></pre> <pre><code>def Fix_DatetimeFinal(table, columnName):\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = pd.to_datetime(table[columnName], format='%Y-%m-%d %H:%M:%S', errors='coerce',dayfirst=True)\n    table[columnName] = table[columnName].apply(lambda x: x.replace(hour=0, minute=0, second=0))\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = table[columnName].apply(lambda x: Fix_Datetime(x)   )\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-fix_questions","title":"Funci\u00f3n <code>Fix_Questions</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_3","title":"Prop\u00f3sito","text":"<p>Transforma y organiza un DataFrame de respuestas de encuestas, estructur\u00e1ndolo para an\u00e1lisis, incluyendo la identificaci\u00f3n de preguntas relacionadas con NPS (Net Promoter Score).</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_3","title":"Entradas","text":"<ul> <li><code>data</code> (DataFrame): DataFrame original con datos de encuestas.</li> <li><code>servicio</code> (str): Nombre del servicio asociado a las encuestas.</li> <li><code>nps</code> (dict): Diccionario que mapea servicios a preguntas relacionadas con NPS.</li> <li><code>filename</code> (str): Nombre del archivo relacionado para fines de registro.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_3","title":"Funcionamiento","text":"<ol> <li> <p>Renombramiento de columnas:</p> <ul> <li>Cambia el nombre de las columnas <code>fecha</code> a <code>FECHA_ENCUESTA</code> y <code>identificacion</code> a <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas:</p> <ul> <li>Busca columnas cuyo nombre comience con <code>\"etapa3\"</code>, que representan preguntas con calificaci\u00f3n.</li> </ul> </li> <li> <p>Filtrado de columnas relevantes:</p> <ul> <li>Redefine el DataFrame para incluir solo las columnas: <code>FECHA_ENCUESTA</code>, <code>DOCUMENTO</code>, y las preguntas identificadas.</li> </ul> </li> <li> <p>Transformaci\u00f3n de datos:</p> <ul> <li>Transforma el DataFrame a un formato largo utilizando <code>melt</code>:<ul> <li><code>id_vars</code>: Columnas constantes (<code>FECHA_ENCUESTA</code> y <code>DOCUMENTO</code>).</li> <li><code>var_name</code>: Nombre de las columnas de preguntas (<code>PREGUNTA</code>).</li> <li><code>value_name</code>: Valores asociados a las preguntas (<code>CALIFICACION</code>).</li> </ul> </li> </ul> </li> <li> <p>Adici\u00f3n de columnas constantes:</p> <ul> <li>Agrega columnas adicionales:<ul> <li><code>SERVICIO</code>: Nombre del servicio.</li> <li><code>TIPO_DOCUMENTO</code>: Fijado como <code>'CC'</code>.</li> <li><code>NPS</code>: Inicializado como <code>'NO'</code>.</li> </ul> </li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas NPS:</p> <ul> <li>Actualiza la columna <code>NPS</code> a <code>'SI'</code> para las preguntas que coinciden con el servicio especificado en el diccionario <code>nps</code>.</li> </ul> </li> <li> <p>Salida del DataFrame:</p> <ul> <li>Registra el nombre del servicio y archivo procesado.</li> <li>Devuelve el DataFrame transformado.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>En caso de error, registra el servicio y archivo no procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_3","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame transformado en formato largo con las siguientes columnas:</li> <li><code>FECHA_ENCUESTA</code></li> <li><code>DOCUMENTO</code></li> <li><code>PREGUNTA</code></li> <li><code>CALIFICACION</code></li> <li><code>SERVICIO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NPS</code></li> </ul> <pre><code>def Fix_Questions( data , servicio , nps, filename):\n\n    try:\n        df = data  \n        #Modificaciones a columnas\n        df = df.rename(columns={'fecha': 'FECHA_ENCUESTA',\n                                'identificacion':'DOCUMENTO'\n                            })\n\n        #Buscar preguntas con nota\n        dfColumns = df.columns.tolist()\n        columnsWithObs = [val for val in dfColumns if val.startswith(\"etapa3\") ]\n\n        #Redefinir columna\n        df = df[['FECHA_ENCUESTA','DOCUMENTO']+columnsWithObs]\n\n        #Modificaciones y transpocision \n        df_unp = df.melt( id_vars = ['FECHA_ENCUESTA','DOCUMENTO'] , var_name=\"PREGUNTA\", value_name=\"CALIFICACION\")\n        df_unp['SERVICIO'] = servicio\n        df_unp['TIPO_DOCUMENTO'] = 'CC'\n        df_unp['NPS'] = 'NO'\n\n\n        df_unp.loc[df_unp[\"PREGUNTA\"] == nps[servicio], \"NPS\"] = 'SI'\n        print('Agregado: ' +  servicio + filename )\n        return df_unp\n    except:\n        print('Sin formato: ' +  servicio + filename )\n</code></pre> <pre><code>import pandas as pd\nfrom zipfile import ZipFile\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-charge_excel_fixed","title":"Funci\u00f3n <code>Charge_Excel_Fixed</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_4","title":"Prop\u00f3sito","text":"<p>Carga un archivo Excel comprimido en formato ZIP, procesa los datos en un DataFrame de pandas, y lo limpia eliminando filas y columnas vac\u00edas antes de almacenarlo en un diccionario.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_4","title":"Entradas","text":"<ul> <li><code>ruta</code> (str): Ruta del archivo Excel, que puede estar comprimido en formato ZIP.</li> <li><code>dfs</code> (dict): Diccionario donde se almacenar\u00e1 el DataFrame procesado, con el nombre del archivo como clave.</li> <li><code>file</code> (str): Nombre del archivo para usarlo como clave en el diccionario <code>dfs</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_4","title":"Funcionamiento","text":"<ol> <li> <p>Verificaci\u00f3n del archivo ZIP:</p> <ul> <li>Intenta abrir el archivo como un archivo ZIP utilizando <code>ZipFile</code>. Si es un archivo ZIP v\u00e1lido, continua con el procesamiento.</li> </ul> </li> <li> <p>Carga del archivo Excel:</p> <ul> <li>Intenta cargar el archivo Excel utilizando pandas (<code>pd.read_excel</code>) con el motor <code>openpyxl</code>.</li> <li>Si se encuentra alg\u00fan error en la carga, se captura y se registra un mensaje.</li> </ul> </li> <li> <p>Procesamiento y limpieza del DataFrame:</p> <ul> <li>Se crea un DataFrame a partir de los datos cargados.</li> <li>Se eliminan filas y columnas vac\u00edas con <code>dropna(how='all')</code> y <code>dropna(axis=1, how='all')</code>.</li> <li>Se restablece el \u00edndice del DataFrame y se asigna la primera fila como nombres de columna.</li> <li>Se elimina la primera fila (que ahora se utiliza como encabezado).</li> <li>El DataFrame limpio se guarda en el diccionario <code>dfs</code> con la clave proporcionada por <code>file</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura y registra cualquier error que ocurra durante la carga o el procesamiento del archivo.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_4","title":"Salida","text":"<ul> <li>No retorna valores. El DataFrame procesado se almacena en el diccionario <code>dfs</code> bajo la clave <code>file</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#consideraciones","title":"Consideraciones","text":"<ul> <li>Se verifica si el archivo es un ZIP v\u00e1lido antes de intentar cargar el archivo Excel.</li> <li>El DataFrame es limpiado de cualquier fila o columna vac\u00eda antes de su procesamiento.</li> <li>Aseg\u00farese de que el archivo Excel est\u00e9 correctamente formateado para que las primeras filas contengan los encabezados.</li> </ul> <pre><code>def Charge_Excel_Fixed(ruta, dfs, file):\n    try:\n        # Verificar si es un archivo ZIP v\u00e1lido\n        with ZipFile(ruta, 'r'):\n            print(\"El archivo es un ZIP v\u00e1lido.\")\n\n        # Intentar cargar con pandas y openpyxl\n        data = pd.read_excel(ruta, engine='openpyxl')\n        print(\"Archivo cargado exitosamente con pandas y openpyxl.\")\n    except Exception as e:\n        print(f\"Error al cargar el archivo: {e}\")\n        return\n\n    # Procesar el DataFrame\n    try:\n        df = pd.DataFrame(data)\n        df.dropna(how='all', inplace=True)\n        df.dropna(axis=1, how='all', inplace=True)\n        df.reset_index(drop=True, inplace=True)\n        df.columns = df.iloc[0]\n        df = df[1:].reset_index(drop=True)\n        dfs[file] = df\n        print(\"Archivo procesado exitosamente.\")\n    except Exception as e:\n        print(f\"Error procesando el DataFrame: {e}\")\n</code></pre>"},{"location":"00.etl/Utils/c4c_from_sharepoint/","title":"c4c_from_sharepoint","text":"<p>Este script automatiza la descarga de archivos desde una carpeta de SharePoint utilizando el API de SharePoint y los m\u00f3dulos <code>requests</code> y <code>msal</code> para autenticar y obtener datos. El script tambi\u00e9n incluye funcionalidades de procesamiento de archivos, creaci\u00f3n de carpetas y manejo de archivos descargados. A continuaci\u00f3n, se describe el funcionamiento y prop\u00f3sito de cada componente y funci\u00f3n del script.</p>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#dependencias-y-configuracion","title":"Dependencias y configuraci\u00f3n","text":"<ol> <li> <p>Librer\u00edas:</p> <ul> <li>El script importa varias librer\u00edas como <code>argparse</code>, <code>io</code>, <code>logging</code>, <code>os</code>, <code>requests</code>, <code>pandas</code>, <code>msal</code>, entre otras, para realizar tareas de autenticaci\u00f3n, procesamiento de datos y manejo de archivos.</li> </ul> </li> <li> <p>Archivo <code>credenciales.env</code>:</p> <ul> <li>Se cargan las credenciales de acceso desde el archivo <code>credenciales.env</code>, que contiene las claves necesarias para autenticar la aplicaci\u00f3n en Microsoft Azure.</li> </ul> </li> <li> <p>Autenticaci\u00f3n en Microsoft Azure:</p> <ul> <li>Utiliza <code>msal</code> para obtener un token de acceso que se usar\u00e1 en las solicitudes de la API de SharePoint.</li> </ul> </li> <li> <p>Configuraci\u00f3n de logging:</p> <ul> <li>Se configura un logger para registrar los eventos en un archivo <code>scraper_SSIS.log</code> y en la consola. Esto permite el monitoreo del proceso de descarga y cualquier error que pueda ocurrir.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#funciones-principales","title":"Funciones principales","text":"<ol> <li> <p><code>download_file_from_sharepoint</code>:</p> <ul> <li>Esta funci\u00f3n se encarga de descargar un archivo desde SharePoint utilizando la URL del archivo y el token de autenticaci\u00f3n.</li> <li>La funci\u00f3n recibe el nombre del archivo, la URL de la carpeta de SharePoint y la ruta de destino para guardar el archivo descargado.</li> <li>Si la solicitud es exitosa (<code>status_code == 200</code>), guarda el archivo en el directorio indicado.</li> </ul> </li> <li> <p><code>download_all_files_from_sharepoint</code>:</p> <ul> <li>Descarga todos los archivos de una carpeta espec\u00edfica en SharePoint.</li> <li>Llama a la API de SharePoint para obtener la lista de archivos en la carpeta especificada.</li> <li>Filtra los archivos que coinciden con un modelo de archivo (por ejemplo, <code>Listadesolicitudesdeservicio__ES.xlsx</code>) y descarga cada uno de ellos utilizando la funci\u00f3n <code>download_file_from_sharepoint</code>.</li> </ul> </li> <li> <p><code>run_etl</code>:</p> <ul> <li>Esta funci\u00f3n envuelve el proceso de descarga de archivos de SharePoint, llamando a <code>download_all_files_from_sharepoint</code> con la URL de la carpeta y el directorio de destino.</li> </ul> </li> <li> <p>Autenticaci\u00f3n con <code>msal</code>:</p> <ul> <li>El script usa la librer\u00eda <code>msal</code> para obtener un token de acceso mediante las credenciales proporcionadas en el archivo <code>credenciales.env</code>. Este token se usa para autorizar las solicitudes a la API de SharePoint.</li> </ul> </li> <li> <p>Ejecuci\u00f3n del proceso de descarga:</p> <ul> <li>Dentro de la funci\u00f3n <code>run_etl</code>, se configuran los par\u00e1metros de carpeta y directorio de destino, y se inicia el proceso de descarga de los archivos de SharePoint.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#flujo-del-script","title":"Flujo del script","text":"<ol> <li> <p>Autenticaci\u00f3n:</p> <ul> <li>Se obtienen las credenciales y el token de acceso a la API de SharePoint utilizando <code>msal</code> con las credenciales proporcionadas en el archivo <code>credenciales.env</code>.</li> </ul> </li> <li> <p>Obtenci\u00f3n y descarga de archivos:</p> <ul> <li>El script obtiene los archivos de SharePoint desde la carpeta especificada (<code>folder_url</code>), filtra los archivos relevantes y los descarga al directorio de destino.</li> </ul> </li> <li> <p>Proceso ETL:</p> <ul> <li>El proceso ETL se lleva a cabo con el decorador <code>log_step_decorator</code>, lo que permite registrar el avance de cada paso en el proceso de descarga.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#consideraciones","title":"Consideraciones","text":"<ul> <li>Dependencias: Es necesario tener las librer\u00edas <code>msal</code>, <code>pandas</code>, <code>requests</code>, y <code>xlwings</code> instaladas para que el script funcione correctamente.</li> <li>Carpetas de destino: El script crea el directorio de descarga si no existe previamente, asegurando que los archivos descargados se almacenen en la ubicaci\u00f3n correcta.</li> <li>Manejo de errores: Se incluye un manejo b\u00e1sico de errores a trav\u00e9s del registro en logs para que cualquier error durante la descarga sea f\u00e1cilmente rastreable.</li> </ul> <p>Este script facilita la integraci\u00f3n y automatizaci\u00f3n del proceso de descarga de archivos C4C desde SharePoint, ideal para sistemas de gesti\u00f3n de archivos y procesamiento de datos.</p> <pre><code>import argparse\nimport io\nimport logging\nimport os\nimport re\nimport requests\nimport time\nfrom datetime import datetime\nimport pandas as pd\nfrom msal import ConfidentialClientApplication\n</code></pre> <pre><code>from Funciones import (\n    log_step_decorator, csv_files\n)\n</code></pre> <pre><code># Cambiar el directorio de trabajo al directorio del script\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nos.chdir(script_dir)\n</code></pre> <pre><code># Leer la clave privada desde el archivo key.pem\nwith open('credenciales.env', 'r') as key_file:\n    lines = key_file.readlines()\n</code></pre> <pre><code># Procesar las claves\nkeys = {}\nfor line in lines:\n    key, value = line.strip().split(\" = \")\n    keys[key] = value.strip('\"')\n</code></pre> <pre><code>client_id = keys.get(\"client_id\")\ncert_thumbprint = keys.get(\"cert_thumbprint\")\ntenant_id = keys.get(\"tenant_id\")\n</code></pre> <pre><code>authority = f\"https://login.microsoftonline.com/{tenant_id}\"\n</code></pre> <pre><code># Leer la clave privada desde el archivo key.pem\nwith open('key.pem', 'r') as key_file:\n    private_key = key_file.read()\n</code></pre> <pre><code>cert = {\n    \"private_key\": private_key,\n    \"thumbprint\": cert_thumbprint,\n}\n</code></pre> <pre><code>msal_app = ConfidentialClientApplication(\n    client_id=client_id,\n    authority=authority,\n    client_credential=cert,\n)\n</code></pre> <pre><code>scopes_sharepoint_online = [keys.get(\"scopes_sharepoint_online\")]\n</code></pre> <pre><code>results = msal_app.acquire_token_for_client(scopes_sharepoint_online)\n</code></pre> <pre><code>if \"access_token\" in results:\n    access_token = results.get(\"access_token\")\n</code></pre> <pre><code>headers = {\n    \"Authorization\": f\"Bearer {access_token}\",\n    \"Accept\": \"application/json;odata=verbose\",\n    \"Content-Type\": \"application/json\",\n}\n</code></pre> <pre><code>sharepoint_base_url = keys.get(\"sharepoint_base_url\")\n</code></pre> <pre><code># Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n</code></pre> <pre><code>if logger.hasHandlers():\n    logger.handlers.clear()\n</code></pre> <pre><code>formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper_SSIS.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n</code></pre> <pre><code>import warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n</code></pre> <pre><code># Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre> <pre><code>@log_step_decorator(\"Descargar archivo de SharePoint\")\ndef download_file_from_sharepoint(file_name, folder_url, download_path):\n    # Crear las carpetas si no existen\n    if not os.path.exists(os.path.dirname(download_path)):\n        os.makedirs(os.path.dirname(download_path))\n        logging.info(f\"Carpeta creada: {os.path.dirname(download_path)}\")\n\n    # Ruta completa del archivo en SharePoint\n    logging.info(f\"Ruta completa del archivo a descargar: {download_path}\")\n\n    download_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n    response = requests.get(download_url, headers=headers)\n\n    if response.status_code == 200:\n        # Eliminar la marca de fecha y hora del nombre del archivo\n        clean_file_name = file_name\n        clean_download_path = os.path.join(os.path.dirname(download_path), clean_file_name)\n\n        # Guardar el archivo descargado con el nuevo nombre\n        with open(clean_download_path, \"wb\") as file:\n            file.write(response.content)\n        logging.info(f\"Archivo descargado exitosamente como: {clean_file_name}\")\n    else:\n        logging.info(f\"Error al descargar el archivo. C\u00f3digo de estado: {response.status_code}\")\n        logging.info(f\"Error: {response.text}\")\n</code></pre> <pre><code># @log_step_decorator(\"ETL\")\ndef download_all_files_from_sharepoint(folder_url, download_directory):\n    # Construye la URL para acceder a los archivos de una carpeta espec\u00edfica en SharePoint\n    folder_api_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n\n    # Realiza una solicitud GET a la URL de la API de SharePoint para obtener los archivos de la carpeta\n    response = requests.get(folder_api_url, headers=headers)\n    # Imprime la URL a la que se est\u00e1 conectando\n    logging.info(f\"Conectando a {folder_api_url}\")\n    # Imprime el estado de la respuesta de la solicitud\n    logging.info(f\"Estado de la respuesta: {response.status_code}\")\n\n    if response.status_code == 200:\n        # Extrae la lista de archivos de la respuesta JSON de la solicitud GET\n        files = response.json().get('d', {}).get('results', [])\n        logging.info(f\"Se encontraron {len(files)} archivos en la carpeta especificada.\")        \n        if not files:\n            logging.info(\"No se encontraron archivos en la carpeta especificada.\")\n            return\n\n        if key in csv_files:\n            extension = \"csv\"\n        else:\n            extension = \"xlsx\"\n\n        # Obtiene el nombre del archivo sin la extensi\u00f3n\n        archivo = \"Listadesolicitudesdeservicio__ES.xlsx\"\n        if archivo:\n            archivo_modelo = os.path.splitext(archivo)[0]\n            # filtra todos los archivos que inicien con archivo_modelo sin extencion y los guarda en una lista \n            files = [file for file in files if file.get('Name').startswith(archivo_modelo)]    \n            logging.info(f\"Se encontraron {len(files)} archivos que coinciden con el modelo de archivo: {archivo_modelo}\")\n        else:\n            logging.info(f\"Se encontraron {len(files)} archivos\")\n            archivo = f\"procesado_{key}.{extension}\"\n\n\n        # Itera sobre la lista de archivos y descarga cada uno\n        for file in files:\n            file_name = file.get('Name')\n            download_path = os.path.join(download_directory, file_name)\n            download_file_from_sharepoint(file_name, folder_url, download_path)\n</code></pre> <pre><code>if __name__ == \"__main__\":\n    logging.info(f'Procesando Sharepoint C4C')\n    # Actualizar root_directory para que etl_destino lo asigne\n    root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n    destino = '02.Archivos/01.Transversal/PQRs'\n    root_directory = os.path.abspath(os.path.join(root_directory1, destino))\n    logging.info(root_directory + \" \\n \" + destino)\n    # Obtener la carpeta desde la clave proporcionada\n    folder_url = 'Documentos compartidos/02.C4C'\n\n    # Descargar archivos\n    @log_step_decorator(f\"ETL Sharepoint C4C\")\n    def run_etl():\n        download_all_files_from_sharepoint(folder_url, root_directory)\n\n    run_etl()\n</code></pre>"},{"location":"00.etl/Utils/dim_Estudiantes/","title":"dim_Estudiantes","text":"<p>Este script realiza las siguientes acciones:</p> <ol> <li> <p>Carga y concatena los archivos:</p> <ul> <li><code>procesado_cede_Listado_Matriculas.xlsx</code> ubicado en <code>02.Archivos/02.Cedesarrollo/01/03.Listado_Matriculas</code>.</li> <li><code>procesado_emp_Listado_Matriculas.xlsx</code> ubicado en <code>02.Archivos/02.Cedesarrollo/02/03.Listado_Matriculas</code>.</li> </ul> </li> <li> <p>Selecciona ciertas columnas espec\u00edficas de los archivos concatenados </p> <ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO_ESTUDIANTE</code></li> <li><code>NOMBRE_ESTUDIANTE</code></li> </ul> </li> <li> <p>Guarda el resultado como <code>dim_Estudiantes.xlsx</code> en el directorio <code>02.Archivos/02.Cedesarrollo</code>.</p> </li> </ol> <p>El directorio de destino se construye din\u00e1micamente utilizando <code>os.path.join</code> y <code>os.path.abspath</code> para asegurar que la ruta sea correcta y compatible con el sistema operativo. Si el directorio no existe, el script lo crea antes de guardar el archivo <code>dim_Estudiantes.xlsx</code>.</p>"},{"location":"00.etl/Utils/dim_Estudiantes/#resumen-del-script","title":"Resumen del Script","text":"<ol> <li> <p>Importaci\u00f3n de M\u00f3dulos:</p> <ul> <li><code>os</code>: Para manejar rutas y directorios.</li> <li><code>pandas</code>: Para manipulaci\u00f3n y procesamiento de datos.</li> </ul> </li> <li> <p>Funci\u00f3n <code>genera</code>:</p> <ul> <li>Verifica si un archivo existe en una ruta espec\u00edfica.</li> <li>Lee un archivo Excel utilizando <code>pandas.read_excel</code>.</li> </ul> </li> <li> <p>Construcci\u00f3n de Directorios:</p> <ul> <li>Usa <code>os.path.join</code> para crear rutas relativas para archivos y carpetas.</li> </ul> </li> <li> <p>Concatenaci\u00f3n de Archivos:</p> <ul> <li>Concatena dos DataFrames obtenidos de los archivos Excel especificados.</li> <li>Filtra las columnas <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO_ESTUDIANTE</code>, y <code>NOMBRE_ESTUDIANTE</code>.</li> </ul> </li> <li> <p>Exportaci\u00f3n del Resultado:</p> <ul> <li>Guarda el DataFrame resultante como un archivo Excel en el directorio especificado.</li> <li>Crea el directorio si no existe.</li> </ul> </li> </ol> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo, value):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede,2)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"02\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'procesado_emp_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp,3)\n</code></pre> <pre><code>#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n# Variable cargada \"df\" del estado del Kernel\n</code></pre> <pre><code># Keep only TIPO_DOCUMENTO and DOCUMENTO columns\ndf = df[['TIPO_DOCUMENTO', 'DOCUMENTO_ESTUDIANTE','NOMBRE_ESTUDIANTE']]\nroot_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'dim_Estudiantes.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/dim_periodo_academico/","title":"dim_periodo_academico","text":"<p>Este script procesa dos archivos de excel <code>procesado_cede_Listado_Matriculas</code> y <code>procesado_emp_Listado_Matriculas</code>, genera un DataFrame con informaci\u00f3n de periodos acad\u00e9micos y lo guarda en <code>dim_periodo_academico.xlsx</code>. A continuaci\u00f3n, se desgloza las secciones m\u00e1s importantes del c\u00f3digo:</p>"},{"location":"00.etl/Utils/dim_periodo_academico/#flujo-del-script","title":"Flujo del Script","text":"<ol> <li> <p>Importaci\u00f3n de M\u00f3dulos:</p> <ul> <li><code>os</code>: Para manejar rutas de directorios.</li> <li><code>pandas</code>: Para procesar datos.</li> </ul> </li> <li> <p>Funci\u00f3n <code>genera</code>:</p> <ul> <li>Lee un archivo Excel desde una ruta especificada.</li> <li>Extrae y procesa el a\u00f1o desde la columna <code>FECHA_MATRICULA</code>.</li> <li>Duplica las filas para generar los semestres acad\u00e9micos (<code>-1</code> y <code>-2</code>).</li> <li>A\u00f1ade una columna <code>ID_UNIDAD</code> con el valor recibido como par\u00e1metro.</li> </ul> <p>Comentarios:     - Utiliza pandas para transformar fechas y manejar valores \u00fanicos.     - Crea semestres autom\u00e1ticamente con l\u00f3gica de repetici\u00f3n y sufijos.</p> </li> <li> <p>Procesamiento de Archivos:</p> <ul> <li>Carga dos archivos de Excel (<code>procesado_cede_Listado_Matriculas.xlsx</code> y <code>procesado_emp_Listado_Matriculas.xlsx</code>).</li> <li>Concatena ambos DataFrames en uno solo.</li> </ul> </li> <li> <p>C\u00e1lculo de Fechas de Inicio y Fin:</p> <ul> <li>Divide la columna <code>PERIODO</code> en <code>YEAR</code> y <code>PERIOD</code>.</li> <li>Genera <code>FECHA_INICIO</code> y <code>FECHA_FIN</code> para cada semestre:<ul> <li><code>FECHA_INICIO</code>: Calcula el primer d\u00eda del semestre.</li> <li><code>FECHA_FIN</code>: Calcula el \u00faltimo d\u00eda del semestre.</li> </ul> </li> </ul> <p>L\u00f3gica:</p> <ul> <li><code>PERIOD</code> se usa para determinar el semestre: <code>-1</code> (Enero-Junio) y <code>-2</code> (Julio-Diciembre).</li> <li>Usa <code>DateOffset</code> para sumar meses y restar d\u00edas.</li> </ul> </li> <li> <p>Exportaci\u00f3n del Resultado:</p> <ul> <li>Crea un directorio de destino si no existe.</li> <li>Guarda el DataFrame resultante en un archivo Excel llamado <code>dim_periodo_academico.xlsx</code>.</li> </ul> </li> </ol> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo, value):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    # Imprimir los nombres de las columnas\n    df = df[['FECHA_MATRICULA']]\n    # Extraer el a\u00f1o de la columna FECHA_MATRICULA\n    df['PERIODO'] = df['FECHA_MATRICULA'].dt.year\n    # Eliminar columna: 'FECHA_MATRICULA'\n    df = df.drop(columns=['FECHA_MATRICULA'])\n\n    # Dejar solo los valores \u00fanicos en df\n    df = df.drop_duplicates()\n\n    # Crear dos valores por cada valor en PERIODO\n    df = df.loc[df.index.repeat(2)].reset_index(drop=True)\n\n\n    # Add \"-1\" and \"-2\" to each PERIODO value in the same column\n    df['PERIODO'] = df['PERIODO'].astype(str) + [\"-1\", \"-2\"] * (len(df) // 2)\n\n    # Add column ID_UNIDAD with value \n    df['ID_UNIDAD'] = value\n\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede,2)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"02\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'procesado_emp_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp,3)\n</code></pre> <pre><code>#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n</code></pre> <pre><code># Convert PERIODO to datetime range\ndf[['YEAR', 'PERIOD']] = df['PERIODO'].str.split('-', expand=True)\ndf['YEAR'] = df['YEAR'].astype(int)\ndf['PERIOD'] = df['PERIOD'].astype(int)\n# Define start and end dates\ndf['FECHA_INICIO'] = pd.to_datetime(df['YEAR'].astype(str) + '-' + ((df['PERIOD'] - 1) * 6 + 1).astype(str) + '-01')\ndf['FECHA_FIN'] = df['FECHA_INICIO'] + pd.DateOffset(months=6) - pd.DateOffset(days=1)\n# Drop temporary columns\ndf.drop(columns=['YEAR', 'PERIOD'], inplace=True)\n</code></pre> <pre><code>root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'dim_periodo_academico.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\nexit(0)\n</code></pre>"},{"location":"00.etl/Utils/download/","title":"Download.py","text":""},{"location":"00.etl/Utils/download/#manual-de-usuario-y-documentacion-del-script-etl","title":"Manual de Usuario y Documentaci\u00f3n del Script ETL","text":"<p>Esta documentaci\u00f3n explica el funcionamiento del script que descarga y procesa archivos desde SharePoint.</p>"},{"location":"00.etl/Utils/download/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El script realiza las siguientes acciones:</p> <ul> <li>Configura el entorno y cambia el directorio de trabajo.</li> <li>Lee las credenciales de autenticaci\u00f3n y configura MSAL para obtener un token.</li> <li>Define los headers para las solicitudes a SharePoint.</li> <li>Configura el logging para el registro de eventos.</li> <li>Define funciones para:<ul> <li>Eliminar marcas de fecha de los nombres de archivo.</li> <li>Descargar archivos desde SharePoint.</li> <li>Extraer la fecha de modificaci\u00f3n de los nombres de archivo.</li> <li>Filtrar archivos recientes (\u00faltimos 6 meses).</li> <li>Concatenar y procesar los datos descargados (CSV y Excel).</li> </ul> </li> <li>Define diccionarios que mapean claves a rutas y nombres de archivo.</li> <li>Orquesta el proceso ETL a trav\u00e9s del bloque principal, que configura argumentos y ejecuta la descarga y procesamiento.</li> </ul>"},{"location":"00.etl/Utils/download/#detalle-de-funciones-principales","title":"Detalle de funciones principales","text":"<ul> <li> <p>remove_datetime_from_filename(file_name):   Elimina la marca de fecha y hora del nombre del archivo mediante una expresi\u00f3n regular.</p> </li> <li> <p>download_file_from_sharepoint(file_name, folder_url, download_path):   Descarga el archivo indicado desde SharePoint, creando directorios y renombrando el archivo sin la marca de fecha.</p> </li> <li> <p>extract_datetime_from_filename(filename):   Extrae la fecha y hora del nombre del archivo para identificar la versi\u00f3n m\u00e1s reciente.</p> </li> <li> <p>find_most_recent_file(files, key):   Filtra la lista de archivos para retornar aquellos modificados en los \u00faltimos 6 meses.</p> </li> <li> <p>download_content_from_sharepoint(file_name, folder_url):   Descarga y retorna el contenido de un archivo desde SharePoint, validando la respuesta.</p> </li> <li> <p>download_all_files_from_sharepoint(folder_url, download_directory, key):   Coordinaci\u00f3n del proceso ETL:</p> <ul> <li>Consulta la API de SharePoint para obtener archivos.</li> <li>Filtra archivos relevantes usando el modelo de nombre.</li> <li>Descarga y procesa el contenido (CSV o Excel).</li> <li>Realiza la concatenaci\u00f3n y eliminaci\u00f3n de duplicados en el DataFrame.</li> <li>Guarda el DataFrame consolidado en el directorio destino.</li> </ul> </li> </ul>"},{"location":"00.etl/Utils/download/#instrucciones-de-uso","title":"Instrucciones de uso","text":"<p>Para ejecutar el script desde la l\u00ednea de comandos: <pre><code>python download.py --key &lt;clave&gt; --pausa &lt;True/False&gt;\n</code></pre> - Utiliza la opci\u00f3n --key para indicar la clave del diccionario correspondiente a la carpeta de SharePoint. - La opci\u00f3n --pausa indica si se debe pausar la ejecuci\u00f3n al finalizar.</p> <pre><code>import json&lt;br&gt;\nimport argparse\nimport io\nimport logging\nimport os\nimport re\nimport requests\nimport time\nfrom datetime import datetime\nimport pandas as pd\nfrom msal import ConfidentialClientApplication\n</code></pre> <pre><code>from Funciones import (\n    log_step_decorator, csv_files\n)\n</code></pre>"},{"location":"00.etl/Utils/download/#configuracion-del-directorio-de-trabajo","title":"Configuraci\u00f3n del Directorio de Trabajo","text":"<p>El siguiente c\u00f3digo establece el directorio de trabajo al directorio donde se encuentra el script actual. Esto es importante para asegurar que todas las rutas relativas utilizadas en el script funcionen correctamente, independientemente de desde d\u00f3nde se ejecute el script.</p> <p>La funci\u00f3n <code>os.path.abspath(__file__)</code> devuelve la ruta completa al archivo actual, y <code>os.path.dirname()</code> extrae el directorio que contiene ese archivo. Luego, <code>os.chdir()</code> cambia el directorio de trabajo actual a esa ubicaci\u00f3n.</p> <pre><code>script_dir = os.path.dirname(os.path.abspath(__file__))\nos.chdir(script_dir)\n</code></pre>"},{"location":"00.etl/Utils/download/#configuracion-del-directorio-de-trabajo_1","title":"Configuraci\u00f3n del Directorio de Trabajo","text":"<p>El siguiente c\u00f3digo establece el directorio de trabajo al directorio donde se encuentra el script actual. Esto es importante para asegurar que todas las rutas relativas utilizadas en el script funcionen correctamente, independientemente de desde d\u00f3nde se ejecute el script.</p> <p>La funci\u00f3n <code>os.path.abspath(__file__)</code> devuelve la ruta completa al archivo actual, y <code>os.path.dirname()</code> extrae el directorio que contiene ese archivo. Luego, <code>os.chdir()</code> cambia el directorio de trabajo actual a esa ubicaci\u00f3n.</p>"},{"location":"00.etl/Utils/download/#lectura-de-credenciales","title":"Lectura de Credenciales","text":"<p>El siguiente c\u00f3digo lee las credenciales necesarias para la autenticaci\u00f3n con Microsoft SharePoint. Estas credenciales se almacenan en un archivo de texto llamado 'credenciales.env' para mantener la seguridad y facilitar la gesti\u00f3n de configuraci\u00f3n.</p> <p>El archivo de credenciales contiene informaci\u00f3n importante como:</p> <ul> <li>Client ID: Identificador \u00fanico de la aplicaci\u00f3n registrada en Azure AD</li> <li>Certificate Thumbprint: Huella digital del certificado utilizado para autenticar</li> <li>Tenant ID: Identificador \u00fanico del directorio de Azure AD</li> <li>Otros par\u00e1metros de configuraci\u00f3n como URLs y scopes</li> </ul> <p>Este enfoque permite separar la configuraci\u00f3n sensible del c\u00f3digo, mejorando la seguridad y facilitando los despliegues en diferentes entornos sin necesidad de modificar el c\u00f3digo fuente.</p> <pre><code>with open('credenciales.env', 'r') as key_file:\n    lines = key_file.readlines()\nkeys = {}\nfor line in lines:\n    key, value = line.strip().split(\" = \")\n    keys[key] = value.strip('\"')\nclient_id = keys.get(\"client_id\")\ncert_thumbprint = keys.get(\"cert_thumbprint\")\ntenant_id = keys.get(\"tenant_id\")\nauthority = f\"https://login.microsoftonline.com/{tenant_id}\"\n</code></pre>"},{"location":"00.etl/Utils/download/#lectura-de-clave-privada","title":"Lectura de Clave Privada","text":"<p>El siguiente c\u00f3digo lee la clave privada almacenada en el archivo 'key.pem'. Esta clave es parte esencial del proceso de autenticaci\u00f3n basado en certificados con Microsoft SharePoint.</p> <p>La clave privada, junto con el thumbprint del certificado previamente cargado, se utiliza para crear las credenciales necesarias para que la aplicaci\u00f3n MSAL (Microsoft Authentication Library) obtenga un token de acceso. Este enfoque de autenticaci\u00f3n con certificado es m\u00e1s seguro que usar contrase\u00f1as y es recomendado para aplicaciones en entornos de producci\u00f3n.</p> <p>Una vez que se carga la clave privada, se configura la aplicaci\u00f3n MSAL y se solicita un token de acceso que ser\u00e1 utilizado en las cabeceras (headers) de todas las solicitudes HTTP posteriores a SharePoint.</p> <pre><code>with open('key.pem', 'r') as key_file:\n    private_key = key_file.read()\ncert = {\n    \"private_key\": private_key,\n    \"thumbprint\": cert_thumbprint,\n}\nmsal_app = ConfidentialClientApplication(\n    client_id=client_id,\n    authority=authority,\n    client_credential=cert,\n)\nscopes_sharepoint_online = [keys.get(\"scopes_sharepoint_online\")]\nresults = msal_app.acquire_token_for_client(scopes_sharepoint_online)\nif \"access_token\" in results:\n    access_token = results.get(\"access_token\")\nheaders = {\n    \"Authorization\": f\"Bearer {access_token}\",\n    \"Accept\": \"application/json;odata=verbose\",\n    \"Content-Type\": \"application/json\",\n}\nsharepoint_base_url = keys.get(\"sharepoint_base_url\")\n</code></pre>"},{"location":"00.etl/Utils/download/#configuracion-de-logging","title":"Configuraci\u00f3n de Logging","text":"<p>El siguiente c\u00f3digo configura el sistema de logging para registrar informaci\u00f3n durante la ejecuci\u00f3n del script. El logging es esencial para monitorear el proceso ETL, identificar problemas y depurar errores.</p> <pre><code># Configuraci\u00f3n del logger principal\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Configuraci\u00f3n del formato de los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Configuraci\u00f3n para guardar logs en archivo\nfile_handler = logging.FileHandler(\"scraper_SSIS.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n\n# Configuraci\u00f3n para mostrar logs en consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n# Suprimir advertencias que puedan distraer durante la ejecuci\u00f3n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n</code></pre> <p>El sistema de logging est\u00e1 configurado para:</p> <ul> <li>Guardar registros en archivo: Los registros se almacenan en \"scraper_SSIS.log\"</li> <li>Mostrar mensajes en consola: Proporciona retroalimentaci\u00f3n en tiempo real</li> <li>Formato de tiempo: Cada mensaje incluye fecha/hora, nivel de severidad y contenido</li> <li>Niveles de detalle: Configurado en INFO para capturar informaci\u00f3n operativa importante</li> </ul> <p>Adicionalmente, se ajustan los niveles de registro para otros loggers que pudieran estar activos:</p> <pre><code># Ajustar nivel de logging para otros loggers\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre> <p>Este enfoque de logging proporciona visibilidad completa del proceso ETL, facilitando la identificaci\u00f3n de posibles problemas o errores durante la ejecuci\u00f3n del script.</p>"},{"location":"00.etl/Utils/download/#remove_datetime_from_filename","title":"remove_datetime_from_filename","text":"<pre><code>def remove_datetime_from_filename(file_name):\n    \"\"\"\n    Elimina la marca de fecha y hora del nombre del archivo.\n    \"\"\"\n    # Usa una expresi\u00f3n regular para eliminar la fecha y hora en formato DD_MM_YYYY_HH_MM\n    return re.sub(r'_\\d{2}_\\d{2}_\\d{4}_\\d{2}_\\d{2}', '', file_name)\n</code></pre> <p>La funci\u00f3n <code>remove_datetime_from_filename()</code> elimina las marcas de fecha y hora de los nombres de archivo. Utiliza una expresi\u00f3n regular para identificar y remover patrones con formato <code>DD_MM_YYYY_HH_MM</code> (d\u00eda_mes_a\u00f1o_hora_minuto) que suelen a\u00f1adirse a los nombres de archivos para versionar documentos.</p> <p>Esta funci\u00f3n es especialmente \u00fatil durante el proceso ETL para normalizar los nombres de los archivos descargados, permitiendo una identificaci\u00f3n y procesamiento consistente independientemente de cu\u00e1ndo fueron generados los archivos.</p>"},{"location":"00.etl/Utils/download/#download_file_from_sharepoint","title":"download_file_from_sharepoint","text":"<p>La funci\u00f3n <code>download_file_from_sharepoint()</code> descarga archivos individuales desde SharePoint y los guarda en el sistema de archivos local. Esta funci\u00f3n:</p> <ol> <li>Crea directorios necesarios: Verifica si la ruta de destino existe y la crea si es necesaria</li> <li>Construye la URL de descarga: Genera la URL completa para acceder al archivo en SharePoint</li> <li>Realiza la petici\u00f3n: Obtiene el contenido del archivo mediante una solicitud HTTP</li> <li>Normaliza el nombre: Elimina las marcas de fecha/hora del nombre del archivo usando <code>remove_datetime_from_filename()</code></li> <li>Guarda el archivo: Escribe el contenido descargado en el sistema de archivos local</li> </ol> <p>Esta funci\u00f3n es esencial para el proceso ETL, permitiendo obtener datos actualizados desde SharePoint para su posterior procesamiento. Maneja tanto la autenticaci\u00f3n como la gesti\u00f3n de errores para garantizar descargas confiables.</p> <pre><code>@log_step_decorator(\"Descargar archivo de SharePoint\")\ndef download_file_from_sharepoint(file_name, folder_url, download_path):\n    \"\"\"\n    Descarga un archivo espec\u00edfico desde SharePoint y lo guarda localmente.\n\n    Args:\n        file_name: Nombre del archivo en SharePoint\n        folder_url: URL relativa de la carpeta en SharePoint\n        download_path: Ruta local donde se guardar\u00e1 el archivo\n    \"\"\"\n    # Crear las carpetas si no existen\n    if not os.path.exists(os.path.dirname(download_path)):\n        os.makedirs(os.path.dirname(download_path))\n        logging.info(f\"Carpeta creada: {os.path.dirname(download_path)}\")\n\n    # Ruta completa del archivo en SharePoint\n    logging.info(f\"Ruta completa del archivo a descargar: {download_path}\")\n    download_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n    response = requests.get(download_url, headers=headers)\n    if response.status_code == 200:\n        # Eliminar la marca de fecha y hora del nombre del archivo\n        clean_file_name = remove_datetime_from_filename(file_name)\n        clean_download_path = os.path.join(os.path.dirname(download_path), clean_file_name)\n\n        # Guardar el archivo descargado con el nuevo nombre\n        with open(clean_download_path, \"wb\") as file:\n            file.write(response.content)\n        logging.info(f\"Archivo descargado exitosamente como: {clean_file_name}\")\n    else:\n        logging.info(f\"Error al descargar el archivo. C\u00f3digo de estado: {response.status_code}\")\n        logging.info(f\"Error: {response.text}\")\n</code></pre>"},{"location":"00.etl/Utils/download/#funciones-de-manejo-de-archivo","title":"Funciones de Manejo de Archivo","text":""},{"location":"00.etl/Utils/download/#extract_datetime_from_filename","title":"extract_datetime_from_filename","text":"<pre><code>def extract_datetime_from_filename(filename):\n    \"\"\"\n    Extrae la fecha y hora del nombre del archivo en formato DD_MM_YYYY_HH_MM.\n    \"\"\"\n    match = re.search(r'(\\d{2}_\\d{2}_\\d{4}_\\d{2}_\\d{2})', filename)\n    if match:\n        return datetime.strptime(match.group(1), '%d_%m_%Y_%H_%M')\n    match = re.search(r'(\\d{2}_\\d{2}_\\d{4})', filename)\n    if match:\n        return datetime.strptime(match.group(1), '%d_%m_%Y')    \n    return None\n</code></pre> <p>La funci\u00f3n <code>extract_datetime_from_filename()</code> extrae informaci\u00f3n de fecha y hora de los nombres de archivo. Esta funci\u00f3n:</p> <ol> <li>Busca patrones de fecha/hora usando expresiones regulares</li> <li>Primero intenta encontrar el formato completo DD_MM_YYYY_HH_MM (d\u00eda_mes_a\u00f1o_hora_minuto)</li> <li>Si no encuentra ese formato, busca un formato m\u00e1s simple DD_MM_YYYY (d\u00eda_mes_a\u00f1o)</li> <li>Convierte la cadena encontrada en un objeto datetime para facilitar operaciones de comparaci\u00f3n</li> <li>Si no encuentra ning\u00fan formato de fecha v\u00e1lido, retorna None</li> </ol> <p>Esta funci\u00f3n es crucial para identificar la versi\u00f3n m\u00e1s reciente de archivos que incluyen marcas de tiempo en sus nombres, permitiendo al proceso ETL trabajar siempre con los datos m\u00e1s actualizados.</p>"},{"location":"00.etl/Utils/download/#find_most_recent_file","title":"find_most_recent_file","text":"<pre><code>@log_step_decorator(\"Filtrar archivos recientes\")\ndef find_most_recent_file(files, key):\n    \"\"\"\n    Encuentra el archivo m\u00e1s reciente en la lista de archivos bas\u00e1ndose en la fecha y hora en el nombre.\n    \"\"\"\n    most_recent_file = None\n    most_recent_datetime = None\n\n    # Itera sobre la lista de archivos\n    archivos_validos = []\n    for file in files:\n        # Obtiene el nombre del archivo\n        file_name = file.get('Name')\n\n        logging.info(f\"Archivo: {file_name}\")\n\n        # Extrae la fecha y hora del nombre del archivo\n        file_datetime = extract_datetime_from_filename(file_name)\n        # Si se pudo extraer la fecha y hora del nombre del archivo\n        if file_datetime:\n            # Si no hay una fecha y hora m\u00e1s reciente almacenada o si la fecha y hora actual es m\u00e1s reciente\n            if most_recent_datetime is None or file_datetime &gt; most_recent_datetime:\n                # Verifica si la fecha y hora est\u00e1 dentro de los \u00faltimos 6 meses\n                if (datetime.now() - file_datetime).days &lt;= 180:\n                    # Agrega el archivo a la lista de archivos v\u00e1lidos\n                    archivos_validos.append(file_name)\n        else:\n            archivos_validos.append(file_name)\n    # Registra los archivos v\u00e1lidos encontrados\n    logging.info(f\"Archivos v\u00e1lidos: {archivos_validos}\")\n    return archivos_validos\n</code></pre> <p>La funci\u00f3n <code>find_most_recent_file()</code> filtra una lista de archivos de SharePoint para identificar aquellos que son relevantes para el proceso ETL. Esta funci\u00f3n:</p> <ol> <li>Itera a trav\u00e9s de una lista de archivos obtenidos de SharePoint</li> <li>Para cada archivo, intenta extraer la informaci\u00f3n de fecha/hora del nombre utilizando <code>extract_datetime_from_filename()</code></li> <li>Si el archivo tiene una marca de tiempo v\u00e1lida:</li> <li>Verifica que la fecha est\u00e9 dentro de los \u00faltimos 6 meses</li> <li>Si cumple con este criterio, lo agrega a la lista de archivos v\u00e1lidos</li> <li>Si el archivo no tiene una marca de tiempo reconocible, lo incluye directamente en la lista de archivos v\u00e1lidos</li> <li>Retorna la lista completa de archivos v\u00e1lidos para su posterior procesamiento</li> </ol> <p>Esta funci\u00f3n implementa una pol\u00edtica de retenci\u00f3n de datos, asegurando que solo los archivos suficientemente recientes (menos de 6 meses de antig\u00fcedad) sean considerados para el proceso ETL, evitando as\u00ed el procesamiento de datos obsoletos.</p>"},{"location":"00.etl/Utils/download/#archivos-sharepoint","title":"Archivos Sharepoint","text":""},{"location":"00.etl/Utils/download/#download_content_from_sharepoint","title":"<code>download_content_from_sharepoint</code>","text":"<p>Esta funci\u00f3n  es responsable de recuperar archivos almacenados en SharePoint utilizando la API REST de Microsoft. La funci\u00f3n est\u00e1 decorada con <code>log_step_decorator</code>, lo que proporciona capacidades autom\u00e1ticas de registro para monitorear el proceso de descarga.</p> <p>El c\u00f3digo construye una URL espec\u00edfica de la API combinando una URL base de SharePoint con la ruta de la carpeta y el nombre del archivo solicitado. Esta construcci\u00f3n sigue el patr\u00f3n est\u00e1ndar de la API REST de SharePoint para obtener el contenido de un archivo (<code>/$value</code>). La funci\u00f3n realiza una solicitud HTTP GET a esta URL, incluyendo los encabezados de autenticaci\u00f3n necesarios.</p> <p>El manejo de respuestas implementa verificaciones b\u00e1sicas de errores: cuando la descarga es exitosa (c\u00f3digo de estado 200), la funci\u00f3n devuelve el contenido binario del archivo. En caso de error, registra tanto el c\u00f3digo de estado como el mensaje de error completo para facilitar la depuraci\u00f3n, y devuelve <code>None</code> para que el c\u00f3digo que la invoca pueda implementar l\u00f3gica de manejo de errores adecuada.</p> <p>Este enfoque es particularmente \u00fatil para integraciones automatizadas que necesitan acceder a documentos almacenados en SharePoint como parte de flujos de trabajo o procesos ETL.</p> <pre><code>@log_step_decorator(\"Descargar contenido de SharePoint\")\ndef download_content_from_sharepoint(file_name, folder_url):\n    download_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n    response = requests.get(download_url, headers=headers)\n    if response.status_code == 200:\n        logging.info(f\"Archivo {file_name} descargado exitosamente.\")\n        return response.content\n    else:\n        logging.info(f\"Error al descargar el archivo. C\u00c3\u00b3digo de estado: {response.status_code}\")\n        logging.info(f\"Error: {response.text}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/download/#download_all_files_from_sharepoint","title":"<code>download_all_files_from_sharepoint</code>","text":"<p>Este c\u00f3digo automatiza la descarga de archivos desde SharePoint, los procesa y los combina en un \u00fanico archivo de salida. </p> <p>La funci\u00f3n primero construye una URL para acceder a los archivos de una carpeta espec\u00edfica en SharePoint utilizando la API REST. Realiza una solicitud HTTP GET para obtener la lista de archivos disponibles, registrando el proceso mediante logging. Si la solicitud es exitosa (c\u00f3digo 200), extrae la informaci\u00f3n de los archivos del JSON de respuesta.</p> <p>Dependiendo del par\u00e1metro <code>key</code> proporcionado, la funci\u00f3n determina si debe trabajar con archivos CSV o Excel. Luego busca en un diccionario el nombre del archivo modelo correspondiente a esa clave, y filtra la lista de archivos para incluir solo aquellos que coincidan con ese modelo.</p> <p>La funci\u00f3n <code>find_most_recent_file</code> (que no se muestra en el c\u00f3digo proporcionado) se utiliza para identificar los archivos m\u00e1s recientes. Para cada archivo seleccionado, descarga su contenido, lo convierte en un DataFrame de pandas seg\u00fan su formato (Excel o CSV), y concatena todos los DataFrames en uno solo, eliminando duplicados.</p> <p>El c\u00f3digo incluye tambi\u00e9n un procesamiento espec\u00edfico para las columnas \"DOCUMENTO_ESTUDIANTE\" y \"DOCUMENTO\", convirti\u00e9ndolas a formato num\u00e9rico entero cuando est\u00e1n presentes.</p> <p>Finalmente, la funci\u00f3n crea el directorio de destino si no existe y guarda el DataFrame combinado como un archivo CSV o Excel en la ubicaci\u00f3n especificada. Si ocurre alg\u00fan error durante el proceso, registra los detalles para facilitar la depuraci\u00f3n.</p> <p>Esta utilidad es especialmente valiosa para automatizar la recopilaci\u00f3n y consolidaci\u00f3n de datos distribuidos en m\u00faltiples archivos en SharePoint, manteniendo un registro detallado de cada paso del proceso.</p> <pre><code>def download_all_files_from_sharepoint(folder_url, download_directory, key):\n    # Construye la URL para acceder a los archivos de una carpeta espec\u00edfica en SharePoint\n    folder_api_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n\n    # Realiza una solicitud GET a la URL de la API de SharePoint para obtener los archivos de la carpeta\n    response = requests.get(folder_api_url, headers=headers)\n    # Imprime la URL a la que se est\u00e1 conectando\n    logging.info(f\"Conectando a {folder_api_url}\")\n    # Imprime el estado de la respuesta de la solicitud\n    logging.info(f\"Estado de la respuesta: {response.status_code}\")\n\n    if response.status_code == 200:\n        # Extrae la lista de archivos de la respuesta JSON de la solicitud GET\n        files = response.json().get('d', {}).get('results', [])\n        logging.info(f\"Se encontraron {len(files)} archivos en la carpeta especificada.\")        \n        if not files:\n            logging.info(\"No se encontraron archivos en la carpeta especificada.\")\n            return\n\n        if key in csv_files:\n            extension = \"csv\"\n        else:\n            extension = \"xlsx\"\n\n        # Obtiene el nombre del archivo sin la extensi\u00f3n\n        archivo = diccionarios.get(key)\n        if archivo:\n            archivo_modelo = os.path.splitext(archivo)[0]\n            # filtra todos los archivos que inicien con archivo_modelo sin extencion y los guarda en una lista \n            files = [file for file in files if file.get('Name').startswith(archivo_modelo)]    \n            logging.info(f\"Se encontraron {len(files)} archivos que coinciden con el modelo de archivo: {archivo_modelo}\")\n        else:\n            logging.info(f\"Se encontraron {len(files)} archivos\")\n            archivo = f\"procesado_{key}.{extension}\"\n            if key == \"EP-PRS-04\":\n                archivo = f\"21.FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD.{extension}\"\n            else:\n                archivo = f\"procesado_{key}.{extension}\"\n\n\n        most_recent_files = find_most_recent_file(files, key)\n        if not most_recent_files:\n            logging.info(f\"No se encontr\u00f3 ning\u00fan archivo v\u00e1lido.\")\n            return\n        all_df = pd.DataFrame()\n        for most_recent_file in most_recent_files:\n            if isinstance(most_recent_file, str):\n                file_name = most_recent_file\n            else:\n                file_name = most_recent_file.get('Name')\n\n            file_content = download_content_from_sharepoint(file_name, folder_url)\n            logging.info(f\"Descargando archivo: {file_name}\")\n            if file_content:\n                if file_name.endswith('.xlsx'):\n                    df = pd.read_excel(io.BytesIO(file_content))\n                elif file_name.endswith('.csv'):\n                    df = pd.read_csv(io.StringIO(file_content.decode('utf-8')))\n                else:\n                    logging.info(f\"Formato de archivo no soportado: {file_name}\")\n                    continue\n                all_df = pd.concat([all_df, df], ignore_index=True)  # Concatena el DataFrame descargado al DataFrame existente\n                all_df = all_df.drop_duplicates() # Eliminar duplicados\n        logging.info(all_df)\n\n        #Si all_df contiene una columna DOCUMENTO_ESTUDIANTE hay que pasarla a entero\n        if \"DOCUMENTO_ESTUDIANTE\" in all_df.columns:\n            all_df['DOCUMENTO_ESTUDIANTE'] = pd.to_numeric(\n                all_df['DOCUMENTO_ESTUDIANTE'].astype(str).str.replace('[^0-9]', '', regex=True),\n                errors='coerce'\n            ).astype('Int64')\n\n        if \"DOCUMENTO\" in all_df.columns:\n            all_df['DOCUMENTO'] = pd.to_numeric(\n                all_df['DOCUMENTO'].astype(str).str.replace('[^0-9]', '', regex=True),\n                errors='coerce'\n            ).astype('Int64')\n\n\n\n        # Verifica si el directorio de descarga existe, si no, lo crea\n        if not os.path.exists(download_directory):\n            os.makedirs(download_directory)\n\n        #guarda all_df en un archivo excel\n        logging.info(f\"Guardando archivo en {download_directory}\")\n        if extension == \"csv\":\n            all_df.to_csv(os.path.join(download_directory, archivo), index=False, encoding='utf-8-sig')\n        else:\n            all_df.to_excel(os.path.join(download_directory, archivo), index=False)\n    else:\n        logging.info(f\"Error al obtener la lista de archivos. C\u00f3digo de estado: {response.status_code}\")\n        logging.info(f\"Contenido del error: {response.text}\")\n</code></pre>"},{"location":"00.etl/Utils/download/#diccionarios-y-main","title":"Diccionarios y Main()","text":"<p>Este c\u00f3digo implementa un sistema para la descarga automatizada de archivos desde SharePoint hacia ubicaciones locales espec\u00edficas. La estructura principal se basa en diccionarios que mapean identificadores a rutas y archivos.</p>"},{"location":"00.etl/Utils/download/#estructura-de-datos","title":"Estructura de datos","text":"<p>El c\u00f3digo define varios diccionarios clave: - <code>manuales</code> y <code>sin_fecha</code>: Mapean c\u00f3digos (como \"EPEPT06\") a nombres de archivos Excel espec\u00edficos - <code>etl_to_folder_url</code>: Contiene las rutas de origen en SharePoint para cada tipo de archivo - <code>etl_destino</code>: Especifica las rutas de destino local donde se guardar\u00e1n los archivos</p> <p>Los diccionarios auxiliares como <code>archivos_manuales_etl_destino</code> y <code>archivos_manuales_etl_to_folder_url</code> generan mapeos adicionales que luego se integran a los diccionarios principales.</p>"},{"location":"00.etl/Utils/download/#funcionamiento","title":"Funcionamiento","text":"<p>El script utiliza <code>argparse</code> para procesar dos par\u00e1metros principales desde la l\u00ednea de comandos: - <code>--key</code>: Especifica qu\u00e9 conjunto de archivos descargar (usando un identificador de los diccionarios) - <code>--pausa</code>: Determina si el script debe hacer una pausa al finalizar</p> <p>Cuando se ejecuta, el programa: 1. Determina la clave a utilizar (usa \"EPEPT04\" por defecto si no se proporciona) 2. Configura el directorio de destino bas\u00e1ndose en la clave 3. Obtiene la URL de SharePoint correspondiente 4. Ejecuta la descarga de archivos mediante la funci\u00f3n <code>download_all_files_from_sharepoint</code> 5. Registra el proceso utilizando un sistema de logging</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para facilitar la automatizaci\u00f3n de descargas desde diferentes secciones de SharePoint, como datos de educaci\u00f3n t\u00e9cnica, educaci\u00f3n continua y archivos de estructuras propuestas, organiz\u00e1ndolos autom\u00e1ticamente en carpetas locales predefinidas.</p> <pre><code>manuales  = {\n    \"EPEPT06\":\"EP-EPT-06.xlsx\", \n    \"EPEPT04\":\"EP-EPT-04.xlsx\",\n    \"EPEDF02\":\"EP-EDF-02.xlsx\",\n    \"EPEDF04\":\"EP-EDF-04.xlsx\",\n    \"AMDRE05\":\"AM-DRE-05.xlsx\",\n    \"EPEPT07\":\"EP-EPT-07.xlsx\",\n    \"EPEPT08\":\"EP-EPT-08.xlsx\",\n    \"EPEDF09\":\"EP-EDF-09.xlsx\",\n    \"EPEPT11\":\"EP-EPT-11.xlsx\",\n    \"EPEPT09\":\"EP-EPT-09.xlsx\",\n    \"EPEPT10\":\"EP-EPT-10.xlsx\",\n    \"EPEPT12\":\"EP-EPT-12.xlsx\",\n    \"EPEPT05\":\"EP-EPT-05.xlsx\",\n    \"EPPRS04\":\"EP-PRS-04.xlsx\",\n    }\n\n\nsin_fecha = {\n    \"EP-EDF-05\":\"EP-EDF-05.xlsx\",\n    \"EP-EDF-02\":'EP-EDF-02.xlsx',\n    \"EP-EDF-06\":'EP-EDF-06.xlsx',\n    \"EP-EDF-09\":'EP-EDF-09.xlsx',\n    \"EP-EDF-01\":'EP-EDF-01.xlsx',\n    \"EP-EDF-10\":'EP-EDF-10.xlsx',\n    \"EP-EDF-04\":'EP-EDF-04.xlsx',\n    \"EP-EDF-11\":'EP-EDF-11.xlsx',\n    \"EP-EDF-03\":'EP-EDF-03.xlsx',\n    \"EP-EDF-12\":'EP-EDF-12.xlsx',\n    \"EP-EDF-08\":'EP-EDF-08.xlsx',\n    \"EP-EDF-07\":'EP-EDF-07.xlsx',\n    }\n\n#une los diccionarios\ndiccionarios = {**manuales, **sin_fecha}\n\n# Generar el nuevo diccionario\narchivos_manuales_etl_destino = {clave: '02.Archivos/02.Cedesarrollo/' for clave in manuales.keys()}\narchivos_manuales_etl_to_folder_url = {clave: 'Documentos compartidos/03.Archivos_Manuales/03.Otros_Archivos' for clave in manuales.keys()}\n\n\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/06.Egresados_Graduados',\n    \"EP-EDF-01\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/06.FACT_ENFERMERIA',\n    \"EP-EDF-02\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/02.FACT_AUSENTISMO_DOCENTE',\n    \"EP-EDF-03\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/10.FACT_REEMPLAZO_DOCENTE',\n    \"EP-EDF-04\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/08.FACT_PERMISO_ESTUDIANTE',\n    \"EP-EDF-05\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/03.FACT_BIBLIOTECA',\n    \"EP-EDF-06\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/04.FACT_BIBLIOTECA_VIRTUAL',\n    \"EP-EDF-07\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/13.FACT_SABER11_INDIVIDUAL',\n    \"EP-EDF-08\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/12.FACT_SABER11_COLEGIOS',\n    \"EP-EDF-09\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/05.FACT_DESEMPENHO_DOCENTE',\n    \"EP-EDF-10\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/07.FACT_LEGALIZACION',\n    \"EP-EDF-11\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/09.FACT_PSIORIENTACION', \n    \"EP-EDF-12\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/11.FACT_RESERVA_ESPACIOS',\n    \"EP-EDF-13\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/14.FACT_SERVICIO_SOCIAL',\n    \"C4C\":'Documentos compartidos/02.C4C',\n    \"EP-PRS-04\": 'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PRS-04',\n    }\n\netl_destino = {\n    \"cede_Docentes\":'02.Archivos/02.Cedesarrollo/01/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'02.Archivos/02.Cedesarrollo/01/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'02.Archivos/02.Cedesarrollo/01/03.Listado_Matriculas',\n    \"cede_Ingresos\":'02.Archivos/02.Cedesarrollo/01/04.Ingresos',\n    \"cede_Historico_Notas\":'02.Archivos/02.Cedesarrollo/01/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'02.Archivos/02.Cedesarrollo/01/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'02.Archivos/02.Cedesarrollo/01/07.Cancelados_Desertores',\n    \"emp_Docentes\":'02.Archivos/02.Cedesarrollo/02/01.Docentes',\n    \"emp_Preinscritos\":'02.Archivos/02.Cedesarrollo/02/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'02.Archivos/02.Cedesarrollo/02/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'02.Archivos/02.Cedesarrollo/02/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'02.Archivos/02.Cedesarrollo/02/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'02.Archivos/02.Cedesarrollo/02/06.Egresados_Graduados',\n    \"EP-EDF-01\":'02.Archivos/04.Colegio',\n    \"EP-EDF-02\":'02.Archivos/04.Colegio',\n    \"EP-EDF-03\":'02.Archivos/04.Colegio',\n    \"EP-EDF-04\":'02.Archivos/04.Colegio',\n    \"EP-EDF-05\":'02.Archivos/04.Colegio',\n    \"EP-EDF-06\":'02.Archivos/04.Colegio',\n    \"EP-EDF-07\":'02.Archivos/04.Colegio',\n    \"EP-EDF-08\":'02.Archivos/04.Colegio',\n    \"EP-EDF-09\":'02.Archivos/04.Colegio',\n    \"EP-EDF-10\":'02.Archivos/04.Colegio',\n    \"EP-EDF-11\":'02.Archivos/04.Colegio',\n    \"EP-EDF-12\":'02.Archivos/04.Colegio',\n    \"EP-EDF-13\":'02.Archivos/04.Colegio',\n    \"C4C\"      :'02.Archivos/01.Transversal/PQRs',\n    \"EP-PRS-04\": '02.Archivos/03.Proteccion',\n    }\n\netl_to_folder_url.update(archivos_manuales_etl_to_folder_url)\netl_destino.update(archivos_manuales_etl_destino)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--key\", type=str, help=\"Clave del diccionario etl_to_folder_url para seleccionar la carpeta en SharePoint.\")\n    parser.add_argument(\"--pausa\", type=bool, default=False, help=\"Segunda clave con valores posibles True o False.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    __key = args.key if args.key else \"EPEPT04\"  # Valor predeterminado\n    _pausa = args.pausa if args.pausa else False\n    logging.info(f'Procesando download.py con la clave: {__key}')\n    # Actualizar root_directory para que etl_destino lo asigne\n    root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n    root_directory = os.path.abspath(os.path.join(root_directory1, etl_destino.get(__key, \"\").replace(\"/\", os.sep)))\n    logging.info(root_directory + \" \\n \" + etl_destino.get(__key, \"\"))\n\n    # Obtener la carpeta desde la clave proporcionada\n    folder_url = etl_to_folder_url.get(__key)\n    if not folder_url:\n        logging.info(f\"Error: La clave '{__key}' no existe en etl_to_folder_url.\")\n        exit(1)\n\n    # Descargar archivos\n    @log_step_decorator(f\"ETL {__key}\")\n    def run_etl():\n        download_all_files_from_sharepoint(folder_url, root_directory, __key)\n\n    run_etl()\n    if _pausa:\n        input(\"Presione Enter para continuar...\")\n</code></pre>"},{"location":"00.etl/Utils/fact_cotizacion/","title":"fact_cotizacion","text":""},{"location":"00.etl/Utils/fact_cotizacion/#fact-cotizacion","title":"FACT COTIZACI\u00d3N","text":""},{"location":"00.etl/Utils/fact_cotizacion/#explicacion-del-codigo-de-procesamiento-de-datos-de-cotizaciones","title":"Explicaci\u00f3n del C\u00f3digo de Procesamiento de Datos de Cotizaciones","text":"<p>Este script de Python realiza un proceso ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para datos relacionados con cotizaciones de servicios del Departamento de Desarrollo Empresarial. </p> <p>El c\u00f3digo comienza importando las bibliotecas necesarias y definiendo funciones auxiliares para normalizar texto y preparar los datos. La funci\u00f3n <code>normalize</code> elimina los acentos de las cadenas de texto, mientras que <code>PreSave</code> realiza m\u00faltiples transformaciones para limpiar y estandarizar los datos en columnas espec\u00edficas, como reemplazar caracteres especiales, convertir texto a may\u00fasculas y eliminar signos de puntuaci\u00f3n.</p> <p>En la parte central, el c\u00f3digo define rutas de directorio para localizar y almacenar archivos. La funci\u00f3n <code>genera</code> lee un archivo Excel espec\u00edfico ('AM-DRE-05.xlsx') y elimina columnas vac\u00edas. La funci\u00f3n <code>transformar_fecha</code> convierte las fechas al formato 'dd/mm/yy'.</p> <p>El flujo principal del programa: 1. Lee el archivo Excel con informaci\u00f3n de cotizaciones 2. Limpia los datos eliminando filas vac\u00edas y duplicados 3. Renombra columnas para estandarizar nombres 4. Elimina columnas innecesarias 5. Transforma los datos de formato amplio a formato largo usando <code>melt</code> 6. Limpia y estandariza el texto en las columnas relevantes 7. Formatea las fechas correctamente 8. Gestiona valores faltantes y trunca campos largos 9. Exporta el resultado final a un archivo Excel llamado 'fact_cotizaciones.xlsx'</p> <p>Este procesamiento permite convertir datos operativos de cotizaciones en un formato m\u00e1s adecuado para an\u00e1lisis o integraci\u00f3n con otros sistemas de informaci\u00f3n.</p> <pre><code>import os\nimport pandas as pd\nimport numpy as np\n# pylint: disable=all\nfrom Funciones import (\n    get_file_content_from_sharepoint\n)\ndef normalize(s):\n    replacements = (\n        (\"\u00e1\", \"a\"),\n        (\"\u00e9\", \"e\"),\n        (\"\u00ed\", \"i\"),\n        (\"\u00f3\", \"o\"),\n        (\"\u00fa\", \"u\"),\n    )\n    for a, b in replacements:\n        s = s.replace(a, b).replace(a.upper(), b.upper())\n    return s\ndef PreSave(df , columnList, signs = False):\n\n    datfra = df.copy()\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xf1', 'ni'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xD1', 'NI'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('\\u00A0', ' '))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('  ', ' '))\n    datfra[columnList] = datfra[columnList].astype(str)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.strip())\n    datfra[columnList] = datfra[columnList].map(normalize)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.upper())\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(',', ' '))\n    datfra[columnList] = datfra[columnList].replace('NAN', np.nan)\n\n    if signs == True:\n        for col in columnList:\n            try:\n                datfra[col] = datfra[col].apply(lambda x: re.sub(r'[\u00a1!?\u00bf]', '', x) )\n            except:\n                print('Not Signs fixed for '+ col)\n\n    return datfra\nfolder_url = \"Documentos compartidos/03.Archivos_Manuales/03.Otros_Archivos\"\n\n\n\ndef genera(root_directory, archivo):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    #elimina las columnas vacias\n    df = df.dropna(axis=1, how='all')\n    return df\n\ndef transformar_fecha(df, columna):\n    # Asegurarse de que la columna es de tipo datetime\n    df[columna] = pd.to_datetime(df[columna])\n\n    # Transformar la columna al formato \"dd/mm/yy\"\n    df[columna] = df[columna].dt.strftime('%d/%m/%y')\n\n    return \n\n\nroot_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n    \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n    )\n)\nprint('--------------------------------------')\nprint(os.getcwd())\n# Nombre del archivo\narchivo_emp = 'AM-DRE-05.xlsx'\n\ndf_emp = genera(root_directory, archivo_emp)\n\n#concatenar los df\ndf = pd.concat([df_emp], ignore_index=True)\ndf = df.dropna(how='all')\n# Eliminar filas que tienen NaN en la columna 'nombre_columna'\ndf = df.dropna(subset=['Fecha de registro'])\n\n#Modificaciones a columnas\ndf = df.rename(columns={'Fecha de registro': 'FECHA_REGISTRO',\n                          'Persona Contacto:': 'NOMBRE',\n                         'Identificaci\u00f3n': 'DOCUMENTO',\n                         'SOLICITUD DE SERVICIOS DEPARTAMENTO DE DESARROLLO EMPRESARIAL:':'SERVICIO',\n                       'Estado negocio':'ESTADO_COTIZACION'})\ndf['TIPO_DOCUMENTO'] = 'CC'\ndf = df.drop(columns=['Fecha tentativa de cierre', 'Fecha \u00faltima actividad','Fecha Final del evento', \n                      'Seguimiento Informe 1', 'Fecha Seguimiento Informe 1',\n                       'Seguimiento Informe 2', 'Fecha Seguimiento informe 2',\n                       'Seguimiento Informe Final', 'Fecha Seguimiento Informe Final','Mes de Inicio', \n                      'Facilitador - Consultor  asignado', 'Fecha inicio',\n                       'Acta de Inicio', 'Mes Reprogramaci\u00f3n', 'Fecha Reprogramaci\u00f3n','Tel\u00e9fono', 'Direcci\u00f3n', \n                      'Municipio', 'Barrio', 'Asesor','Correo electr\u00f3nico', 'Celular','Fecha Envi\u00f3 Propuesta'])\n\n#Eliminar duplicados\ndf = df.drop_duplicates()\nprint(type(df))\n\n\n\n#Limpiar y almacenar\nAMDRE05 = df.melt(id_vars=['FECHA_REGISTRO','NOMBRE','TIPO_DOCUMENTO','DOCUMENTO','SERVICIO','ESTADO_COTIZACION'] , var_name=\"PREGUNTA\", value_name=\"RESPUESTA\")\nAMDRE05['COD_SERVICIO'] = -1\nAMDRE05= PreSave( AMDRE05 , [ 'NOMBRE','TIPO_DOCUMENTO','DOCUMENTO','SERVICIO','ESTADO_COTIZACION',\"RESPUESTA\"] )\ndf_transformada = transformar_fecha(AMDRE05, 'FECHA_REGISTRO')\n\n\nAMDRE05['DOCUMENTO'] = AMDRE05['DOCUMENTO'].fillna('00000000')\nAMDRE05['DOCUMENTO'] = AMDRE05['DOCUMENTO'].astype(str).apply(lambda x: x[:20])\nAMDRE05['RESPUESTA'] = AMDRE05['RESPUESTA'].astype(str).apply(lambda x: x[:40])\nAMDRE05['PREGUNTA'] = AMDRE05['PREGUNTA'].str.replace(':', '')\nAMDRE05.to_excel(os.path.join(root_directory, 'fact_cotizaciones.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/fact_facturacion/","title":"fact_facturacion","text":"<p>El script procesa <code>procesado_cede_Ingresos.xlsx</code> y <code>EP-EPT-06.xlsx</code> provenientes de diferentes directorios, los limpia, los concatena, convierte una columna a formato de fecha y luego guarda el DataFrame combinado en un nuevo archivo Excel <code>fact_facturacion.xlsx</code>.</p>"},{"location":"00.etl/Utils/fact_facturacion/#funcionamiento","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n de la funci\u00f3n <code>genera</code>:</p> <ul> <li> <p>Entradas:</p> <ul> <li><code>root_directory</code> (str): Directorio base donde se encuentra el archivo.</li> <li><code>archivo</code> (str): Nombre del archivo Excel a procesar.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Verifica si el archivo existe en la ruta especificada.</li> <li>Lee el archivo Excel utilizando <code>pd.read_excel</code>.</li> <li>Elimina las columnas vac\u00edas utilizando <code>dropna(axis=1, how='all')</code>.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame del archivo procesado.</li> </ul> </li> </ul> </li> <li> <p>Lectura de archivos:</p> <ul> <li>Se leen dos archivos Excel: <code>procesado_cede_Ingresos.xlsx</code> y <code>EP-EPT-06.xlsx</code>, desde sus respectivas rutas base.</li> <li>La funci\u00f3n <code>genera</code> se aplica para procesar ambos archivos.</li> </ul> </li> <li> <p>Concatenaci\u00f3n de DataFrames:</p> <ul> <li>Los DataFrames obtenidos de ambos archivos se concatenan utilizando <code>pd.concat</code>, combinando las filas de ambos archivos.</li> </ul> </li> <li> <p>Conversi\u00f3n de tipo de datos:</p> <ul> <li>La columna <code>'FECHA_CONTABLE'</code> se convierte al tipo <code>datetime64[ns]</code> utilizando <code>df.astype({'FECHA_CONTABLE': 'datetime64[ns]'})</code>.</li> </ul> </li> <li> <p>Exportaci\u00f3n a Excel:</p> <ul> <li>El DataFrame combinado se guarda en un nuevo archivo Excel (<code>fact_facturacion.xlsx</code>) en el directorio de destino especificado, creando el directorio si no existe previamente.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/fact_facturacion/#entradas","title":"Entradas","text":"<ul> <li><code>root_directory</code>: Directorio base donde se encuentran los archivos a procesar.</li> <li><code>archivo</code>: Nombre del archivo Excel a procesar.</li> </ul>"},{"location":"00.etl/Utils/fact_facturacion/#salida","title":"Salida","text":"<ul> <li><code>df</code>: DataFrame combinado y procesado de los dos archivos.</li> <li>Archivo Excel exportado: El DataFrame procesado se guarda como <code>fact_facturacion.xlsx</code> en el directorio de destino.</li> </ul> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    #elimina las columnas vacias\n    df = df.dropna(axis=1, how='all')\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"04.Ingresos\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Ingresos.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'EP-EPT-06.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp)\n</code></pre> <pre><code>#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n</code></pre> <pre><code># Cambia el tipo de columna por datetime64[ns] para la columna: 'FECHA'\ndf = df.astype({'FECHA_CONTABLE': 'datetime64[ns]'})\n</code></pre> <pre><code>root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'fact_facturacion.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/fact_graduados/","title":"fact_graduados","text":""},{"location":"00.etl/Utils/fact_graduados/#fact-graduados","title":"FACT GRADUADOS","text":"<p>Este script en Python procesa informaci\u00f3n de graduados o egresados de dos fuentes distintas, las combina y guarda el resultado en un nuevo archivo Excel. A continuaci\u00f3n se detalla su funcionamiento:</p>"},{"location":"00.etl/Utils/fact_graduados/#funcion-principal","title":"Funci\u00f3n Principal","text":"<p>El c\u00f3digo define una funci\u00f3n <code>genera()</code> que: - Recibe la ruta base, nombre de archivo y un valor identificador - Verifica la existencia del archivo especificado - Lee datos desde un archivo Excel utilizando pandas - Asigna un identificador de unidad acad\u00e9mica (ID_UNIDAD) - Limpia columnas vac\u00edas - Devuelve un DataFrame procesado</p>"},{"location":"00.etl/Utils/fact_graduados/#procesamiento-de-archivos","title":"Procesamiento de Archivos","text":"<p>El script procesa dos archivos Excel diferentes: 1. Un archivo relacionado con \"CEDE\" (ID_UNIDAD=2) 2. Un archivo relacionado con \"EMP\" (ID_UNIDAD=3)</p> <p>Ambos archivos se encuentran en rutas espec\u00edficas dentro de una estructura de directorios predefinida.</p>"},{"location":"00.etl/Utils/fact_graduados/#combinacion-y-limpieza-de-datos","title":"Combinaci\u00f3n y Limpieza de Datos","text":"<p>Despu\u00e9s de leer los archivos: - A\u00f1ade una columna vac\u00eda llamada 'DIPLOMA_GRADUADO' al DataFrame de CEDE - Concatena ambos DataFrames en uno solo - Realiza un tratamiento especial sobre la columna 'DOCUMENTO', convirti\u00e9ndola a un formato num\u00e9rico entero si existe</p>"},{"location":"00.etl/Utils/fact_graduados/#exportacion-de-resultados","title":"Exportaci\u00f3n de Resultados","text":"<p>Finalmente, el c\u00f3digo: - Establece una ruta de destino para el archivo final - Crea el directorio destino si no existe - Guarda el DataFrame combinado como 'fact_egresados.xlsx' - Confirma la exportaci\u00f3n exitosa mediante un mensaje en consola</p> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n\n\n\ndef genera(root_directory, archivo, value):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    # Add column ID_UNIDAD with value \n    df['ID_UNIDAD'] = value    \n    #elimina las columnas vacias\n    df = df.dropna(axis=1, how='all')\n    return df\n\nroot_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"06.Egresados_Graduados\"\n    )\n)\n\n# Nombre del archivo\narchivo_cede = 'procesado_cede_Egresados_Graduados.xlsx'\n\ndf_cede = genera(root_directory, archivo_cede,2)\n\nroot_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"02\",\n        \"06.Egresados_Graduados\"\n    )\n)\n\n\n# Nombre del archivo\narchivo_emp = 'procesado_emp_Egresados_Graduados.xlsx'\n\ndf_emp = genera(root_directory, archivo_emp,3)\n\ndf_cede['DIPLOMA_GRADUADO'] = ''\n#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n\n\n#Si all_df contiene una columna DOCUMENTO_ESTUDIANTE hay que pasarla a entero\nif \"DOCUMENTO\" in df.columns:\n    df['DOCUMENTO'] = pd.to_numeric(\n        df['DOCUMENTO'].astype(str).str.replace('[^0-9]', '', regex=True),\n        errors='coerce'\n    ).astype('Int64')\n\n\nroot_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n\n# Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'fact_egresados.xlsx'), index=False)\n#abrir el excel\n#os.system('start excel.exe \"%s\"' % os.path.join(root_directory, 'fact_egresados.xlsx'))\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/fact_listado_matriculas/","title":"fact_listado_matriculas","text":"<p>Este script procesa dos archivos CSV relacionados con el listado de matr\u00edculas, les agrega una columna con un identificador de unidad, los concatena en un solo DataFrame y guarda el resultado en un nuevo archivo CSV <code>fact_listado_matriculas.csv</code>. </p>"},{"location":"00.etl/Utils/fact_listado_matriculas/#funcionamiento","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n de la funci\u00f3n <code>genera</code>:</p> <ul> <li> <p>Entradas:</p> <ul> <li><code>root_directory</code> (str): Directorio base donde se encuentra el archivo.</li> <li><code>archivo</code> (str): Nombre del archivo CSV a procesar.</li> <li><code>value</code> (int): Valor que se asignar\u00e1 a la nueva columna <code>ID_UNIDAD</code> en el DataFrame.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Verifica si el archivo existe en la ruta especificada.</li> <li>Lee el archivo CSV utilizando <code>pd.read_csv</code>, con codificaci\u00f3n UTF-8.</li> <li>Agrega una nueva columna <code>ID_UNIDAD</code> con el valor proporcionado.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame con la columna adicional <code>ID_UNIDAD</code>.</li> </ul> </li> </ul> </li> <li> <p>Lectura de archivos:</p> <ul> <li> <p>Se leen dos archivos CSV:</p> <ul> <li><code>procesado_cede_Listado_Matriculas.csv</code> desde el directorio <code>02.Archivos/02.Cedesarrollo/01/03.Listado_Matriculas</code>.</li> <li><code>procesado_emp_Listado_Matriculas.csv</code> desde el directorio <code>02.Archivos/02.Cedesarrollo/02/03.Listado_Matriculas</code>.</li> </ul> </li> <li> <p>Se aplica la funci\u00f3n <code>genera</code> a ambos archivos, agregando los valores de <code>ID_UNIDAD</code> como 2 y 3 respectivamente.</p> </li> </ul> </li> <li> <p>Concatenaci\u00f3n de DataFrames:</p> <ul> <li>Los DataFrames <code>df_cede</code> y <code>df_emp</code> se concatenan en un \u00fanico DataFrame (<code>df</code>).</li> </ul> </li> <li> <p>Exportaci\u00f3n a CSV:</p> <ul> <li>El DataFrame combinado se guarda en un nuevo archivo CSV llamado <code>fact_listado_matriculas.csv</code> en el directorio de destino <code>02.Archivos/02.Cedesarrollo</code>.</li> </ul> </li> <li> <p>Creaci\u00f3n del directorio de destino (si no existe):</p> <ul> <li>Si el directorio de destino no existe, se crea utilizando <code>os.makedirs()</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/fact_listado_matriculas/#entradas","title":"Entradas","text":"<ul> <li><code>root_directory</code>: Directorio base donde se encuentran los archivos a procesar.</li> <li><code>archivo</code>: Nombre del archivo CSV a procesar.</li> <li><code>value</code>: Valor para la columna <code>ID_UNIDAD</code>.</li> </ul>"},{"location":"00.etl/Utils/fact_listado_matriculas/#salida","title":"Salida","text":"<ul> <li><code>df</code>: DataFrame combinado y procesado de los dos archivos.</li> <li>Archivo CSV exportado: El DataFrame combinado se guarda como <code>fact_listado_matriculas.csv</code> en el directorio de destino.</li> </ul> <pre><code># pylint: disable=all\nimport os\nimport pandas as pd\nfrom Funciones import log_step_decorator\n</code></pre> <pre><code>@log_step_decorator(\"Generando el DataFrame a partir del archivo...\")\ndef genera(root_directory, archivo, value):\n    print(f\"Generando el DataFrame a partir del archivo '{archivo}'...\")\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    # df = pd.read_excel(ruta_archivo)\n\n    # Leer el archivo csv\n    df = pd.read_csv(ruta_archivo, sep=',', encoding='utf-8')\n\n    #agrega ID_UNIDAD al df con valor value\n    df['ID_UNIDAD'] = value\n\n    print(\"El DataFrame ha sido generado exitosamente. No de registros cargados: \", len(df))\n\n    return df\n</code></pre> <pre><code>@log_step_decorator(\"Procesando Listado Matriculas emp y cede\")\ndef main():\n    root_directory = os.path.abspath(\n        os.path.join(\n            os.getcwd(),\n            \"..\",\n            \"..\",\n            \"02.Archivos\",\n            \"02.Cedesarrollo\",\n            \"01\",\n            \"03.Listado_Matriculas\"\n        )\n    )\n\n    # Nombre del archivo\n    archivo_cede = 'procesado_cede_Listado_Matriculas.csv'\n\n    df_cede = genera(root_directory, archivo_cede,2)\n\n    root_directory = os.path.abspath(\n        os.path.join(\n            os.getcwd(),\n            \"..\",\n            \"..\",\n            \"02.Archivos\",\n            \"02.Cedesarrollo\",\n            \"02\",\n            \"03.Listado_Matriculas\"\n        )\n    )\n\n\n    # Nombre del archivo\n    archivo_emp = 'procesado_emp_Listado_Matriculas.csv'\n\n    df_emp = genera(root_directory, archivo_emp,3)\n\n    #concatenar los df\n    print(\"Concatenando los DataFrames...\")\n    df = pd.concat([df_cede, df_emp], ignore_index=True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    print(\"El DataFrame ha sido concatenado exitosamente. No de registros cargados: \", len(df))\n\n    root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n    # Actualizar root_directory para que etl_destino lo asigne\n    destino = '02.Archivos/02.Cedesarrollo'\n    root_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n\n    # Crear el directorio si no existe\n    if not os.path.exists(root_directory):\n        os.makedirs(root_directory)\n    #guarda en excel \n    df.to_csv(os.path.join(root_directory, 'fact_listado_matriculas.csv'), index=False, encoding='utf-8')\n</code></pre> <pre><code>if __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/","title":"00.DimTiempo","text":""},{"location":"01.scripts/00.DimTiempo/#documentacion-del-script-sql-para-el-esquema-dimensiones-tiempo","title":"Documentaci\u00f3n del Script SQL para el Esquema <code>Dimensiones Tiempo</code>","text":""},{"location":"01.scripts/00.DimTiempo/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL pertenece a un sistema de manejo de datos en un Data Warehouse, espec\u00edficamente en el esquema <code>Dwh</code>. Su prop\u00f3sito es eliminar restricciones de claves for\u00e1neas en las tablas del esquema, eliminar las tablas y el esquema, y luego crear el esquema y la tabla <code>DIM_TIEMPO</code>. A continuaci\u00f3n, se detallan las secciones del c\u00f3digo.</p>"},{"location":"01.scripts/00.DimTiempo/#descripcion-del-codigo","title":"Descripci\u00f3n del C\u00f3digo","text":""},{"location":"01.scripts/00.DimTiempo/#1-contexto-inicial","title":"1. Contexto Inicial","text":"<p>El script comienza seleccionando la base de datos <code>DWH_COMFENALCO</code> y establece configuraciones iniciales como <code>ANSI_NULLS</code> y <code>QUOTED_IDENTIFIER</code> para asegurar el comportamiento est\u00e1ndar de SQL Server.</p> <pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n</code></pre> <ul> <li><code>USE DWH_COMFENALCO</code>: Cambia el contexto de ejecuci\u00f3n a la base de datos <code>DWH_COMFENALCO</code>.</li> <li><code>SET ANSI_NULLS ON</code>: Habilita el tratamiento est\u00e1ndar de valores <code>NULL</code> en operaciones comparativas.</li> <li><code>SET QUOTED_IDENTIFIER ON</code>: Permite usar nombres de identificadores entre comillas dobles.</li> </ul>"},{"location":"01.scripts/00.DimTiempo/#2-eliminar-restricciones-de-claves-foraneas","title":"2. Eliminar Restricciones de Claves For\u00e1neas","text":"<p>Se utiliza un procedimiento din\u00e1mico para eliminar todas las restricciones de claves for\u00e1neas asociadas al esquema <code>Dwh</code>.</p> <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Dwh';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/#desglose","title":"Desglose:","text":"<ol> <li><code>sys.foreign_keys</code>: Obtiene informaci\u00f3n de todas las claves for\u00e1neas en las tablas.</li> <li><code>sys.tables</code> y <code>sys.schemas</code>: Se utiliza para vincular las tablas a sus esquemas.</li> <li>Construcci\u00f3n din\u00e1mica: El c\u00f3digo genera comandos <code>ALTER TABLE</code> para eliminar cada restricci\u00f3n.</li> <li><code>EXEC sp_executesql</code>: Ejecuta los comandos generados din\u00e1micamente.</li> </ol> <p>Motivaci\u00f3n: Esto es \u00fatil para realizar cambios en las estructuras de las tablas sin conflictos con dependencias existentes.</p>"},{"location":"01.scripts/00.DimTiempo/#3-eliminar-tablas-y-esquema","title":"3. Eliminar Tablas y Esquema","text":"<p>El script elimina todas las tablas del esquema <code>Dwh</code> y luego elimina el esquema.</p> <pre><code>-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Dwh';\nEXEC sp_executesql @sql;\n\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Dwh')\nBEGIN\n    DROP SCHEMA Dwh;\nEND\nGO\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/#desglose_1","title":"Desglose:","text":"<ol> <li>Eliminar tablas: Genera y ejecuta comandos <code>DROP TABLE</code> para eliminar todas las tablas del esquema <code>Dwh</code>.</li> <li>Eliminar esquema: Verifica si el esquema <code>Dwh</code> existe y lo elimina si es as\u00ed.</li> </ol> <p>Motivaci\u00f3n: Esto asegura que el esquema <code>Dwh</code> y sus tablas sean eliminados antes de recrearlos.</p>"},{"location":"01.scripts/00.DimTiempo/#4-crear-esquema-y-tabla-dim_tiempo","title":"4. Crear Esquema y Tabla <code>DIM_TIEMPO</code>","text":"<p>El script crea el esquema <code>Dwh</code> y la tabla <code>DIM_TIEMPO</code> con sus respectivas columnas.</p> <pre><code>-- Crear el esquema Dwh\nCREATE SCHEMA Dwh;\nGO\n\n-- Crear DIM_TIEMPO\nCREATE TABLE [Dwh].[DIM_TIEMPO](\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NULL,\n    [DESC_FECHA] [varchar](50) NULL,\n    [ID_SEMANA] [int] NULL,\n    [DESC_SEMANA] [varchar](50) NULL,\n    [ID_NO_MES] [int] NULL,\n    [DESC_NO_MES] [varchar](50) NULL,\n    [ID_MES] [int] NULL,\n    [DESC_MES] [varchar](50) NULL,\n    [DESC_MES_CORTA] [varchar](50) NULL,\n    [ID_BIMESTRE] [int] NULL,\n    [DESC_BIMESTRE] [varchar](50) NULL,\n    [ID_TRIMESTRE] [int] NULL,\n    [DESC_TRIMESTRE] [varchar](50) NULL,\n    [ID_CUATRIMESTRE] [int] NULL,\n    [DESC_CUATRIMESTRE] [varchar](50) NULL\n);\nGO\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/#desglose_2","title":"Desglose:","text":"<ol> <li>Crear esquema: Crea el esquema <code>Dwh</code>.</li> <li>Crear tabla <code>DIM_TIEMPO</code>: Define la tabla <code>DIM_TIEMPO</code> con sus columnas y tipos de datos.</li> </ol> <p>Motivaci\u00f3n: Esto establece la estructura necesaria para almacenar datos de tiempo en el esquema <code>Dwh</code>.</p>"},{"location":"01.scripts/00.DimTiempo/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li> <p>Uso de Restricciones de Integridad:</p> <ul> <li>La eliminaci\u00f3n y recreaci\u00f3n de restricciones asegura la integridad de los datos.</li> </ul> </li> <li> <p>Automatizaci\u00f3n en la Eliminaci\u00f3n de Restricciones:</p> <ul> <li>Permite realizar modificaciones estructurales masivas sin errores manuales.</li> </ul> </li> <li> <p>Configuraciones Iniciales:</p> <ul> <li>Se asegura un comportamiento est\u00e1ndar al trabajar con valores <code>NULL</code> y nombres de columnas.</li> </ul> </li> <li> <p>Modularidad y Dinamismo:</p> <ul> <li>El script est\u00e1 dise\u00f1ado para ser modular y din\u00e1mico, facilitando modificaciones estructurales complejas.</li> </ul> </li> <li> <p>Uso de Procedimientos Din\u00e1micos:</p> <ul> <li>La construcci\u00f3n din\u00e1mica de comandos SQL permite una mayor flexibilidad y adaptabilidad.</li> </ul> </li> <li> <p>Definici\u00f3n Clara de Esquemas:</p> <ul> <li>Las tablas y sus relaciones est\u00e1n claramente definidas, lo que mejora la comprensi\u00f3n y mantenimiento del c\u00f3digo.</li> </ul> </li> </ol>"},{"location":"01.scripts/00.DimTiempo/#diagrama-de-relacion-de-tablas","title":"Diagrama de Relaci\u00f3n de Tablas","text":"<pre><code>erDiagram\n    DIM_TIEMPO {\n        int ID_FECHA PK\n        datetime FECHA\n        varchar(50) DESC_FECHA\n        int ID_SEMANA\n        varchar(50) DESC_SEMANA\n        int ID_NO_MES\n        varchar(50) DESC_NO_MES\n        int ID_MES\n        varchar(50) DESC_MES\n        varchar(50) DESC_MES_CORTA\n        int ID_BIMESTRE\n        varchar(50) DESC_BIMESTRE\n        int ID_TRIMESTRE\n        varchar(50) DESC_TRIMESTRE\n        int ID_CUATRIMESTRE\n        varchar(50) DESC_CUATRIMESTRE\n    }</code></pre>"},{"location":"01.scripts/00.DimTiempo/#conclusion","title":"Conclusi\u00f3n","text":"<p>Este script SQL est\u00e1 dise\u00f1ado para gestionar de manera eficiente la eliminaci\u00f3n y creaci\u00f3n de estructuras de datos en el esquema <code>Dwh</code>. La automatizaci\u00f3n y modularidad implementadas aseguran que las operaciones se realicen de manera consistente y sin errores, facilitando el mantenimiento y la evoluci\u00f3n del Data Warehouse.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/","title":"00.DimensionesColegio a local","text":""},{"location":"01.scripts/00.DimensionesColegio_a_local/#documentacion-del-script-sql-para-el-esquema-dimensiones-colegio","title":"Documentaci\u00f3n del Script SQL para el Esquema <code>Dimensiones Colegio</code>","text":""},{"location":"01.scripts/00.DimensionesColegio_a_local/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL pertenece a un sistema de manejo de datos en un Data Warehouse, espec\u00edficamente en el esquema <code>Colegio</code>. Su prop\u00f3sito es eliminar restricciones de claves for\u00e1neas en las tablas del esquema, y luego realizar configuraciones de integridad referencial mediante la definici\u00f3n de claves primarias. A continuaci\u00f3n, se detallan las secciones del c\u00f3digo.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#descripcion-del-codigo","title":"Descripci\u00f3n del C\u00f3digo","text":""},{"location":"01.scripts/00.DimensionesColegio_a_local/#1-contexto-inicial","title":"1. Contexto Inicial","text":"<p>El script comienza seleccionando la base de datos <code>DWH_COMFENALCO</code> y establece configuraciones iniciales como <code>ANSI_NULLS</code> y <code>QUOTED_IDENTIFIER</code> para asegurar el comportamiento est\u00e1ndar de SQL Server.</p> <pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n</code></pre> <ul> <li><code>USE DWH_COMFENALCO</code>: Cambia el contexto de ejecuci\u00f3n a la base de datos <code>DWH_COMFENALCO</code>.</li> <li><code>SET ANSI_NULLS ON</code>: Habilita el tratamiento est\u00e1ndar de valores <code>NULL</code> en operaciones comparativas.</li> <li><code>SET QUOTED_IDENTIFIER ON</code>: Permite usar nombres de identificadores entre comillas dobles.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#2-eliminar-restricciones-de-claves-foraneas","title":"2. Eliminar Restricciones de Claves For\u00e1neas","text":"<p>Se utiliza un procedimiento din\u00e1mico para eliminar todas las restricciones de claves for\u00e1neas asociadas al esquema <code>Colegio</code>.</p> <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Colegio';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#desglose","title":"Desglose:","text":"<ol> <li><code>sys.foreign_keys</code>: Obtiene informaci\u00f3n de todas las claves for\u00e1neas en las tablas.</li> <li><code>sys.tables</code> y <code>sys.schemas</code>: Se utiliza para vincular las tablas a sus esquemas.</li> <li>Construcci\u00f3n din\u00e1mica: El c\u00f3digo genera comandos <code>ALTER TABLE</code> para eliminar cada restricci\u00f3n.</li> <li><code>EXEC sp_executesql</code>: Ejecuta los comandos generados din\u00e1micamente.</li> </ol> <p>Motivaci\u00f3n: Esto es \u00fatil para realizar cambios en las estructuras de las tablas sin conflictos con dependencias existentes.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#3-creacion-de-tablas-comentarios","title":"3. Creaci\u00f3n de Tablas (Comentarios)","text":"<p>Las tablas <code>DIM_CURSO</code>, <code>DIM_GRADO</code> y <code>DIM_POBLACION_MATRICULA</code> est\u00e1n definidas en comentarios como referencia.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#definicion-de-la-tablas","title":"Definici\u00f3n de la tablas","text":"<pre><code>CREATE TABLE [Colegio].[DIM_CURSO](\n    [ID_CURSO] [int] NOT NULL,\n    [DESC_CURSO] [nvarchar](100) NULL,\n    [FECHA_CREACION] [date] NULL,\n    [ESTADO_REGISTRO] [nvarchar](20) NULL\n) ON [PRIMARY]\n\nCREATE TABLE [Colegio].[DIM_GRADO](\n    [ID_GRADO] [int] IDENTITY(1,1) NOT NULL,\n    [DESC_GRADO] [nvarchar](100) NULL,\n    [FECHA_CREACION] [date] NULL,\n    [ESTADO_REGISTRO] [nvarchar](20) NULL\n) ON [PRIMARY]\n\nCREATE TABLE [Colegio].[DIM_POBLACION_MATRICULA](\n    [ID_POBLACION_MATRICULA] [int] IDENTITY(1,1) NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [NOMBRE_COMPLETO] [nvarchar](4000) NULL,\n    [GENERO] [varchar](20) NULL,\n    [DIRECCION] [nvarchar](300) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [CORREO] [nvarchar](250) NULL,\n    [FECHA_NACIMIENTO] [int] NULL\n) ON [PRIMARY]\n</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#campos-de-la-tabla-dim_curso","title":"Campos de la Tabla <code>DIM_CURSO</code>","text":"<ul> <li><code>ID_CURSO</code>: Identificador \u00fanico de la tabla <code>DIM_CURSO</code> (clave primaria).</li> <li><code>DESC_CURSO</code>: Descripci\u00f3n del curso en la tabla <code>DIM_CURSO</code>.</li> <li><code>FECHA_CREACION</code>: Fecha en que se cre\u00f3 el curso en la tabla <code>DIM_CURSO</code>.</li> <li><code>ESTADO_REGISTRO</code>: Indica si el registro est\u00e1 activo o inactivo en la tabla <code>DIM_CURSO</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#campos-de-la-tabla-dim_grado","title":"Campos de la Tabla <code>DIM_GRADO</code>","text":"<ul> <li><code>ID_GRADO</code>: Identificador \u00fanico de la tabla <code>DIM_GRADO</code> (clave primaria).</li> <li><code>DESC_GRADO</code>: Descripci\u00f3n del grado en la tabla <code>DIM_GRADO</code>.</li> <li><code>FECHA_CREACION</code>: Fecha en que se cre\u00f3 el grado en la tabla <code>DIM_GRADO</code>.</li> <li><code>ESTADO_REGISTRO</code>: Indica si el registro est\u00e1 activo o inactivo en la tabla <code>DIM_GRADO</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#campos-de-la-tabla-dim_poblacion_matricula","title":"Campos de la Tabla <code>DIM_POBLACION_MATRICULA</code>","text":"<ul> <li><code>ID_POBLACION_MATRICULA</code>: Identificador \u00fanico de la tabla <code>DIM_POBLACION_MATRICULA</code> (clave primaria).</li> <li><code>PARTNER</code>: Identificador del socio en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>TIPO_DOCUMENTO</code>: Tipo de documento en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>DOCUMENTO</code>: N\u00famero de documento en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>NOMBRE_COMPLETO</code>: Nombre completo del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>GENERO</code>: G\u00e9nero del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>DIRECCION</code>: Direcci\u00f3n del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>TELEFONO</code>: Tel\u00e9fono del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>CORREO</code>: Correo electr\u00f3nico del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>FECHA_NACIMIENTO</code>: Fecha de nacimiento del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#4-definicion-de-claves-primarias","title":"4. Definici\u00f3n de Claves Primarias","text":"<p>El script define claves primarias para las tablas <code>DIM_POBLACION_MATRICULA</code>, <code>DIM_CURSO</code> y <code>DIM_GRADO</code>.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#claves-primarias","title":"Claves primarias","text":"<pre><code>ALTER TABLE [Colegio].[DIM_POBLACION_MATRICULA]  WITH NOCHECK ADD  CONSTRAINT [PK_DIM_POBLACION_MATRICULA] PRIMARY KEY CLUSTERED ([ID_POBLACION_MATRICULA])\n\nALTER TABLE [Colegio].[DIM_CURSO]  WITH NOCHECK ADD  CONSTRAINT [PK_DIM_CURSO] PRIMARY KEY CLUSTERED ([ID_CURSO])\n\nALTER TABLE [Colegio].[DIM_GRADO]  WITH NOCHECK ADD  CONSTRAINT [PK_DIM_GRADO] PRIMARY KEY CLUSTERED ([ID_GRADO])\n</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#detalles","title":"Detalles:","text":"<ul> <li><code>WITH NOCHECK</code>: No verifica los datos existentes en la tabla antes de aplicar la restricci\u00f3n.</li> <li><code>PRIMARY KEY CLUSTERED</code>: Define una clave primaria con un \u00edndice cl\u00fasterado basado en <code>ID_POBLACION_MATRICULA</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#claves-primarias-definidas","title":"Claves Primarias Definidas:","text":"Tabla Clave Primaria <code>DIM_POBLACION_MATRICULA</code> <code>ID_POBLACION_MATRICULA</code> <code>DIM_CURSO</code> <code>ID_CURSO</code> <code>DIM_GRADO</code> <code>ID_GRADO</code>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#diagrama-de-relacion-de-tablas","title":"Diagrama de Relaci\u00f3n de Tablas","text":"<pre><code>erDiagram\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION_MATRICULA PK\n        nvarchar(10) PARTNER\n        nvarchar(4) TIPO_DOCUMENTO\n        nvarchar(20) DOCUMENTO\n        nvarchar(4000) NOMBRE_COMPLETO\n        varchar(20) GENERO\n        nvarchar(300) DIRECCION\n        nvarchar(30) TELEFONO\n        nvarchar(250) CORREO\n        int FECHA_NACIMIENTO\n    }\n\n    DIM_CURSO {\n        int ID_CURSO PK\n        nvarchar(100) DESC_CURSO\n        date FECHA_CREACION\n        nvarchar(20) ESTADO_REGISTRO\n    }\n\n    DIM_GRADO {\n        int ID_GRADO PK\n        nvarchar(100) DESC_GRADO\n        date FECHA_CREACION\n        nvarchar(20) ESTADO_REGISTRO\n    }</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li> <p>Uso de Restricciones de Integridad:</p> <ul> <li>Claves primarias garantizan la unicidad de registros y optimizan las consultas.</li> </ul> </li> <li> <p>Automatizaci\u00f3n en la Eliminaci\u00f3n de Restricciones:</p> <ul> <li>Permite realizar modificaciones estructurales masivas sin errores manuales.</li> </ul> </li> <li> <p>Comentarios:</p> <ul> <li>Las definiciones de tablas est\u00e1n comentadas como referencia.</li> </ul> </li> <li> <p>Configuraciones Iniciales:</p> <ul> <li>Se asegura un comportamiento est\u00e1ndar al trabajar con valores <code>NULL</code> y nombres de columnas.</li> </ul> </li> <li> <p>Modularidad y Dinamismo:</p> <ul> <li>El script est\u00e1 dise\u00f1ado para ser modular y din\u00e1mico, facilitando modificaciones estructurales complejas.</li> </ul> </li> <li> <p>Uso de Procedimientos Din\u00e1micos:</p> <ul> <li>La construcci\u00f3n din\u00e1mica de comandos SQL permite una mayor flexibilidad y adaptabilidad.</li> </ul> </li> <li> <p>Definici\u00f3n Clara de Esquemas:</p> <ul> <li>Las tablas y sus relaciones est\u00e1n claramente definidas, lo que mejora la comprensi\u00f3n y mantenimiento del c\u00f3digo.</li> </ul> </li> <li> <p>Garant\u00eda de Integridad Referencial:</p> <ul> <li>La definici\u00f3n de claves primarias y la eliminaci\u00f3n controlada de restricciones aseguran la integridad referencial del esquema.</li> </ul> </li> </ol>"},{"location":"01.scripts/00.Eliminar_todo/","title":"00. Eliminar Todo","text":""},{"location":"01.scripts/00.Eliminar_todo/#eliminar-todo","title":"Eliminar Todo","text":""},{"location":"01.scripts/00.Eliminar_todo/#descripcion-del-script","title":"Descripci\u00f3n del Script","text":"<p>El prop\u00f3sito del script SQL proporcionado es realizar una limpieza completa de los esquemas en una base de datos denominada <code>DWH_COMFENALCO</code>. Incluye la eliminaci\u00f3n de restricciones, tablas y esquemas espec\u00edficos para preparar la base de datos para un nuevo esquema o estructura de datos. A continuaci\u00f3n, se detalla el proceso ejecutado:</p>"},{"location":"01.scripts/00.Eliminar_todo/#componentes-y-pasos-del-script","title":"Componentes y Pasos del Script","text":""},{"location":"01.scripts/00.Eliminar_todo/#1-uso-del-contexto-de-la-base-de-datos","title":"1. Uso del Contexto de la Base de Datos","text":"<p><pre><code>USE DWH_COMFENALCO;\nGO\n</code></pre> Selecciona la base de datos <code>DWH_COMFENALCO</code> como contexto para las operaciones subsecuentes.</p>"},{"location":"01.scripts/00.Eliminar_todo/#2-configuraciones-iniciales","title":"2. Configuraciones Iniciales","text":"<p><pre><code>SET ANSI_NULLS ON;\nSET QUOTED_IDENTIFIER ON;\nGO\n</code></pre> Configura opciones para garantizar compatibilidad con valores nulos y el uso de identificadores entre comillas dobles en las consultas.</p>"},{"location":"01.scripts/00.Eliminar_todo/#3-eliminacion-de-restricciones-de-clave-foranea","title":"3. Eliminaci\u00f3n de Restricciones de Clave For\u00e1nea","text":"<p>Por cada esquema (<code>Colegio</code>, <code>Protecci\u00f3n</code>, <code>Cedesarrollo</code>, y <code>Transversal</code>), el script: 1. Busca las restricciones de clave for\u00e1nea. 2. Genera din\u00e1micamente comandos <code>ALTER TABLE ... DROP CONSTRAINT</code>. 3. Ejecuta estos comandos utilizando <code>sp_executesql</code>.</p> <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Colegio';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.Eliminar_todo/#4-eliminacion-de-tablas","title":"4. Eliminaci\u00f3n de Tablas","text":"<p>Una vez eliminadas las restricciones, el script elimina las tablas del esquema utilizando un proceso similar: 1. Genera comandos <code>DROP TABLE</code> din\u00e1micamente. 2. Ejecuta los comandos para cada tabla del esquema correspondiente.</p> <pre><code>SET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Proteccion';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.Eliminar_todo/#5-eliminacion-de-esquemas","title":"5. Eliminaci\u00f3n de Esquemas","text":"<p>Si un esquema existe despu\u00e9s de la eliminaci\u00f3n de tablas, se elimina con <code>DROP SCHEMA</code>.</p> <pre><code>IF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Transversal')\nBEGIN\n    DROP SCHEMA Transversal;\nEND\n</code></pre>"},{"location":"01.scripts/00.Eliminar_todo/#6-esquemas-y-tablas-afectados","title":"6. Esquemas y Tablas Afectados","text":"Esquema Tablas Incluidas Colegio <code>FACT_LEGALIZACION</code>, <code>FACT_ENFERMERIA</code>, <code>FACT_NOTAS</code>, etc. Proteccion <code>FACT_PLAN_COBERTURA</code>, <code>FACT_DESERCION</code>, etc. Cedesarrollo <code>FACT_NOTAS</code>, <code>FACT_INASISTENCIAS</code>, etc. Transversal Todas las tablas asociadas."},{"location":"01.scripts/00.Eliminar_todo/#consideraciones","title":"Consideraciones","text":"<ol> <li>Impacto del Script:</li> <li>Elimina de manera irreversible todas las tablas, restricciones y esquemas mencionados.</li> <li> <p>Se debe realizar una copia de seguridad previa si se requiere preservar datos.</p> </li> <li> <p>Ejecutar con Precauci\u00f3n:</p> </li> <li>Valide que los esquemas y tablas ya no son necesarios antes de ejecutar el script.</li> <li> <p>Considere ambientes de desarrollo para pruebas iniciales.</p> </li> <li> <p>Optimizaci\u00f3n del Proceso:</p> </li> <li>Los comandos din\u00e1micos utilizados son eficientes para manejar grandes cantidades de tablas y restricciones de forma automatizada.</li> </ol>"},{"location":"01.scripts/00.Eliminar_todo/#uso-sugerido","title":"Uso Sugerido","text":"<p>Este script es \u00fatil para: - Reiniciar un Data Warehouse antes de una nueva carga de datos. - Eliminar estructuras no necesarias en ambientes de desarrollo o pruebas.</p>"},{"location":"01.scripts/00.Inicio/","title":"Introducci\u00f3n","text":""},{"location":"01.scripts/00.Inicio/#documentacion-de-diseno-e-implementacion-del-data-warehouse-dwh_comfenalco","title":"Documentaci\u00f3n de Dise\u00f1o e Implementaci\u00f3n del Data Warehouse: <code>DWH_COMFENALCO</code>","text":""},{"location":"01.scripts/00.Inicio/#introduccion","title":"Introducci\u00f3n","text":"<p>El <code>DWH_COMFENALCO</code> es un Data Warehouse dise\u00f1ado para gestionar y analizar informaci\u00f3n relacionada con diversas \u00e1reas de la organizaci\u00f3n, como la educaci\u00f3n, bienestar social, protecci\u00f3n, y programas transversales. Este proyecto se estructura bajo un enfoque de modelado dimensional para optimizar la consulta y an\u00e1lisis de datos, y se apoya en una organizaci\u00f3n jer\u00e1rquica y relacional de tablas <code>dimensionales</code> y <code>hechos</code>.</p>"},{"location":"01.scripts/00.Inicio/#objetivos","title":"Objetivos","text":""},{"location":"01.scripts/00.Inicio/#objetivo-general","title":"Objetivo General","text":"<p>Crear una plataforma de datos robusta y optimizada que permita a las \u00e1reas interesadas acceder a informaci\u00f3n estrat\u00e9gica para la toma de decisiones basada en datos hist\u00f3ricos y actuales.</p>"},{"location":"01.scripts/00.Inicio/#objetivos-especificos","title":"Objetivos Espec\u00edficos","text":"<ol> <li>Estandarizar y centralizar la informaci\u00f3n proveniente de diferentes fuentes operativas.</li> <li>Dise\u00f1ar un esquema relacional que permita realizar an\u00e1lisis detallados por dimensiones clave (e.g., tiempo, poblaci\u00f3n, programas, etc.).</li> <li>Implementar \u00edndices y claves for\u00e1neas para optimizar el rendimiento de las consultas.</li> <li>Facilitar la integraci\u00f3n y an\u00e1lisis de informaci\u00f3n para \u00e1reas como colegios, protecci\u00f3n social y desarrollo acad\u00e9mico.</li> <li>Garantizar la escalabilidad para futuros m\u00f3dulos o esquemas.</li> </ol>"},{"location":"01.scripts/00.Inicio/#esquema-relacional","title":"Esquema Relacional","text":""},{"location":"01.scripts/00.Inicio/#arquitectura-general","title":"Arquitectura General","text":"<p>El Data Warehouse se organiza en m\u00f3dulos independientes que comparten dimensiones clave, cada uno enfocado en un \u00e1rea funcional:</p> <ol> <li>Dimensiones Comunes:</li> <li><code>DIM_TIEMPO</code>: Dimensi\u00f3n temporal que permite analizar datos por fechas espec\u00edficas.</li> <li> <p><code>DIM_PERSONAL</code>, <code>DIM_SERVICIOS</code>, y otras dimensiones transversales.</p> </li> <li> <p>M\u00f3dulos Espec\u00edficos:</p> </li> <li>Cedesarrollo: Datos relacionados con estudiantes, programas acad\u00e9micos y notas.</li> <li>Protecci\u00f3n: Informaci\u00f3n sobre caracterizaci\u00f3n, poblaci\u00f3n y planes de cobertura.</li> <li>Colegio: Gesti\u00f3n de notas, transporte, biblioteca y servicios sociales en colegios.</li> </ol>"},{"location":"01.scripts/00.Inicio/#esquema-relacional-simplificado","title":"Esquema Relacional Simplificado","text":"<pre><code>erDiagram\n    DIM_TIEMPO {\n        int ID_FECHA PK\n        date FECHA\n        varchar DIA_SEMANA\n        varchar MES\n        int ANIO\n    }\n\n    Transversal {\n        int ID_PERSONAL PK\n        int ID_SERVICIO PK\n        varchar NOMBRE_SERVICIO\n    }\n\n    Cedesarrollo {\n        int ID_ESTUDIANTE PK\n        int ID_PROGRAMA FK\n        int ID_PERIODO FK\n        decimal NOTA_FINAL\n    }\n\n    Proteccion {\n        int ID_POBLACION PK\n        int ID_PROGRAMA FK\n        int ID_FECHA FK\n    }\n\n    Colegio {\n        int ID_NOTA PK\n        int ID_POBLACION_MATRICULA FK\n        int ID_GRADO FK\n        int ID_CURSO FK\n        decimal NOTA_FINAL\n    }\n\n    DIM_TIEMPO ||--o{ Transversal: \"relaci\u00f3n temporal\"\n    DIM_TIEMPO ||--o{ Cedesarrollo: \"relaci\u00f3n temporal\"\n    DIM_TIEMPO ||--o{ Proteccion: \"relaci\u00f3n temporal\"\n    DIM_TIEMPO ||--o{ Colegio: \"relaci\u00f3n temporal\"\n    Transversal ||--o{ Cedesarrollo: \"uso compartido\"\n    Transversal ||--o{ Proteccion: \"uso compartido\"\n    Transversal ||--o{ Colegio: \"uso compartido\"</code></pre>"},{"location":"01.scripts/00.Inicio/#detalles-por-modulo","title":"Detalles por M\u00f3dulo","text":""},{"location":"01.scripts/00.Inicio/#1-dimensiones-comunes","title":"1. Dimensiones Comunes","text":"<p>Estas dimensiones son utilizadas transversalmente en todos los m\u00f3dulos:</p> <ul> <li><code>DIM_TIEMPO</code>: Estructura central para an\u00e1lisis temporal. Contiene informaci\u00f3n granular de fechas, d\u00edas de la semana, meses y a\u00f1os.</li> <li><code>DIM_SERVICIOS</code>: Identifica los servicios ofrecidos en diferentes programas.</li> <li><code>DIM_PERSONAL</code>: Informaci\u00f3n de personal administrativo y docente.</li> </ul>"},{"location":"01.scripts/00.Inicio/#2-cedesarrollo","title":"2. Cedesarrollo","text":"<p>Este m\u00f3dulo se enfoca en la informaci\u00f3n acad\u00e9mica de estudiantes:</p> <ul> <li>Tablas principales:</li> <li><code>DIM_ESTUDIANTES</code>: Informaci\u00f3n general de los estudiantes.</li> <li><code>DIM_PROGRAMA</code>: Datos de los programas acad\u00e9micos.</li> <li><code>FACT_NOTAS</code>: Notas por m\u00f3dulo, estudiante y periodo acad\u00e9mico.</li> </ul>"},{"location":"01.scripts/00.Inicio/#3-proteccion","title":"3. Protecci\u00f3n","text":"<p>M\u00f3dulo que gestiona informaci\u00f3n de poblaci\u00f3n vulnerable y programas sociales:</p> <ul> <li>Tablas principales:</li> <li><code>DIM_POBLACION</code>: Identificaci\u00f3n de beneficiarios de programas.</li> <li><code>FACT_CARACTERIZACION</code>: Caracterizaci\u00f3n de poblaciones seg\u00fan criterios.</li> <li><code>FACT_PLAN_COBERTURA</code>: Proyecciones y coberturas de programas sociales.</li> </ul>"},{"location":"01.scripts/00.Inicio/#4-colegio","title":"4. Colegio","text":"<p>Dise\u00f1ado para gestionar datos operativos y acad\u00e9micos en colegios:</p> <ul> <li>Tablas principales:</li> <li><code>DIM_PLAN_CURRICULAR</code>: Estructura acad\u00e9mica por asignaturas y cursos.</li> <li><code>FACT_NOTAS</code>: Notas obtenidas por estudiantes en diversas materias.</li> <li><code>FACT_BIBLIOTECA</code>: Registro de pr\u00e9stamos en bibliotecas f\u00edsicas y virtuales.</li> </ul>"},{"location":"01.scripts/00.Inicio/#nota","title":"Nota","text":"<ul> <li>La creaci\u00f3n de tablas se hace desde los scritps SQL. Incluidos en esta secci\u00f3n.</li> <li>Las funciones se encuentran en los scritps de Python y la explicaci\u00f3n de los paquetes.</li> <li>El unico procedimiento almacenado se ejecuta en el paquete 3 para calcular <code>FACT_RETIROS</code></li> <li>Parametros de SSIS. Se explican en la introducci\u00f3n de SSIS.</li> </ul>"},{"location":"01.scripts/00.Inicio/#conclusion","title":"Conclusi\u00f3n","text":"<p>El <code>DWH_COMFENALCO</code> es una herramienta poderosa y escalable que permite a los usuarios finales obtener insights r\u00e1pidos y precisos a trav\u00e9s de la integraci\u00f3n y an\u00e1lisis de datos en m\u00faltiples dominios. Con un dise\u00f1o modular y el uso eficiente de dimensiones compartidas, este Data Warehouse est\u00e1 preparado para soportar el crecimiento futuro y nuevos requisitos de an\u00e1lisis.</p>"},{"location":"01.scripts/00.Inicio/#pagina-principal","title":"P\u00e1gina Principal","text":"<p>Bienvenido a la documentaci\u00f3n.</p>"},{"location":"01.scripts/00.Inicio/#indice","title":"\u00cdndice","text":"<p>{{ pagetree }}</p>"},{"location":"01.scripts/01.Transversal%20copy/","title":"Documentaci\u00f3n SQL para el Esquema <code>Transversal</code>","text":""},{"location":"01.scripts/01.Transversal%20copy/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL est\u00e1 dise\u00f1ado para gestionar el esquema <code>Transversal</code> dentro de un Data Warehouse (DWH). Implementa una arquitectura dimensional compuesta por tablas de dimensiones y tablas de hechos, siguiendo las mejores pr\u00e1cticas de modelado dimensional.</p>"},{"location":"01.scripts/01.Transversal%20copy/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li>Eliminaci\u00f3n y Creaci\u00f3n del Esquema:</li> <li>Limpieza del esquema existente <code>Transversal</code> eliminando restricciones de claves for\u00e1neas, tablas y el esquema en s\u00ed.</li> <li> <p>Reinstalaci\u00f3n del esquema <code>Transversal</code> desde cero.</p> </li> <li> <p>Creaci\u00f3n de Tablas Dimensionales y de Hechos:</p> </li> <li>Tablas de Dimensiones (<code>DIM</code>): Contienen atributos descriptivos y categ\u00f3ricos relacionados con empresas, afiliados, beneficiarios, aportantes no afiliados, entre otros.</li> <li> <p>Tablas de Hechos (<code>FACT</code>): Contienen m\u00e9tricas y claves for\u00e1neas que conectan con las dimensiones, facilitando an\u00e1lisis transaccionales y operativos.</p> </li> <li> <p>Relaciones entre Tablas:</p> </li> <li>Configuraci\u00f3n de restricciones <code>FOREIGN KEY</code> para garantizar integridad referencial.</li> </ol>"},{"location":"01.scripts/01.Transversal%20copy/#detalle-de-las-tablas-y-relacion-dimensional","title":"Detalle de las Tablas y Relaci\u00f3n Dimensional","text":""},{"location":"01.scripts/01.Transversal%20copy/#tablas-dimensionales","title":"Tablas Dimensionales","text":""},{"location":"01.scripts/01.Transversal%20copy/#1-dim_empresas","title":"1. DIM_EMPRESAS","text":"<p>Contiene informaci\u00f3n b\u00e1sica sobre empresas, incluyendo tipo de documento, raz\u00f3n social, sector y estado.</p> Columna Tipo Descripci\u00f3n <code>ID_EMPRESA</code> <code>int</code> Identificador \u00fanico de la empresa. <code>RAZON_SOCIAL</code> <code>nvarchar</code> Nombre de la empresa. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento (NIT, CC). <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero del documento."},{"location":"01.scripts/01.Transversal%20copy/#2-dim_afiliados","title":"2. DIM_AFILIADOS","text":"<p>Contiene datos de los afiliados como nombre, g\u00e9nero, estado civil, y afiliaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_AFILIADO</code> <code>int</code> Identificador \u00fanico del afiliado. <code>NOMBRE_COMPLETO</code> <code>nvarchar</code> Nombre completo del afiliado. <code>GENERO</code> <code>nvarchar</code> G\u00e9nero del afiliado. <code>FECHA_AFILIACION</code> <code>nvarchar</code> Fecha de afiliaci\u00f3n."},{"location":"01.scripts/01.Transversal%20copy/#3-dim_beneficiarios","title":"3. DIM_BENEFICIARIOS","text":"<p>Contiene informaci\u00f3n de los beneficiarios relacionados con los afiliados.</p> Columna Tipo Descripci\u00f3n <code>ID_BENEFICIARIO</code> <code>int</code> Identificador \u00fanico del beneficiario. <code>NOMBRE_COMPLETO</code> <code>nvarchar</code> Nombre completo del beneficiario. <code>PARENTESCO</code> <code>nvarchar</code> Relaci\u00f3n del beneficiario con el titular."},{"location":"01.scripts/01.Transversal%20copy/#diagrama-de-las-tablas-dimensionales","title":"Diagrama de las Tablas Dimensionales","text":"<pre><code>erDiagram\n    DIM_EMPRESAS {\n        int ID_EMPRESA PK\n        nvarchar RAZON_SOCIAL\n        nvarchar TIPO_DOCUMENTO\n        nvarchar DOCUMENTO\n    }\n\n    DIM_AFILIADOS {\n        int ID_AFILIADO PK\n        nvarchar NOMBRE_COMPLETO\n        nvarchar GENERO\n        nvarchar FECHA_AFILIACION\n    }\n    DIM_BENEFICIARIOS {\n        int ID_BENEFICIARIO PK\n        nvarchar NOMBRE_COMPLETO\n        nvarchar PARENTESCO\n    }\n\n    DIM_EMPRESAS ||--o{ DIM_AFILIADOS : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ DIM_BENEFICIARIOS : \"ID_AFILIADO\"</code></pre>"},{"location":"01.scripts/01.Transversal%20copy/#tablas-de-hechos","title":"Tablas de Hechos","text":""},{"location":"01.scripts/01.Transversal%20copy/#1-fact_aportes_shr_det","title":"1. FACT_APORTES_SHR_DET","text":"<p>Registra detalles financieros de aportes realizados por empresas y afiliados.</p> Columna Tipo Descripci\u00f3n <code>ID_EMPRESA</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_EMPRESAS</code>. <code>ID_AFILIADO</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_AFILIADOS</code>. <code>PERIODO</code> <code>varchar</code> Per\u00edodo de los aportes. <code>APORTE_NUEVO</code> <code>numeric</code> Monto del aporte registrado."},{"location":"01.scripts/01.Transversal%20copy/#2-fact_detalle_contable","title":"2. FACT_DETALLE_CONTABLE","text":"<p>Registra operaciones contables como ingresos, gastos y resultados financieros.</p> Columna Tipo Descripci\u00f3n <code>ID_CEBE</code> <code>bigint</code> Relaci\u00f3n con la tabla <code>DIM_UNIDADES_ORGANIZATIVAS</code>. <code>ID_CUENTA</code> <code>bigint</code> Relaci\u00f3n con la tabla <code>DIM_CUENTA_CONTABLE</code>. <code>IMPORTE</code> <code>decimal</code> Importe de la operaci\u00f3n contable."},{"location":"01.scripts/01.Transversal%20copy/#3-fact_encuestas","title":"3. FACT_ENCUESTAS","text":"<p>Registra resultados de encuestas relacionadas con servicios y satisfacci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_UNIDAD</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_UNIDAD</code>. <code>SERVICIO</code> <code>nvarchar</code> Servicio evaluado en la encuesta. <code>CALIFICACION</code> <code>nvarchar</code> Puntuaci\u00f3n otorgada en la encuesta."},{"location":"01.scripts/01.Transversal%20copy/#diagrama-de-las-tablas-de-hechos","title":"Diagrama de las Tablas de Hechos","text":"<pre><code>erDiagram\n    FACT_APORTES_SHR_DET {\n        int ID_EMPRESA FK\n        int ID_AFILIADO FK\n        varchar PERIODO\n        numeric APORTE_NUEVO\n    }\n\n    FACT_DETALLE_CONTABLE {\n        bigint ID_CEBE FK\n        bigint ID_CUENTA FK\n        decimal IMPORTE\n    }\n\n    FACT_ENCUESTAS {\n        int ID_UNIDAD FK\n        nvarchar SERVICIO\n        nvarchar CALIFICACION\n    }\n\n    DIM_EMPRESAS ||--o{ FACT_APORTES_SHR_DET : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ FACT_APORTES_SHR_DET : \"ID_AFILIADO\"\n    DIM_UNIDADES_ORGANIZATIVAS ||--o{ FACT_DETALLE_CONTABLE : \"ID_CEBE\"\n    DIM_CUENTA_CONTABLE ||--o{ FACT_DETALLE_CONTABLE : \"ID_CUENTA\"\n    DIM_UNIDAD ||--o{ FACT_ENCUESTAS : \"ID_UNIDAD\"</code></pre>"},{"location":"01.scripts/01.Transversal%20copy/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li>Integridad Referencial:</li> <li> <p>Uso de claves for\u00e1neas para garantizar relaciones consistentes entre dimensiones y hechos.</p> </li> <li> <p>Arquitectura Modular:</p> </li> <li> <p>Separaci\u00f3n de tablas <code>DIM</code> y <code>FACT</code> para optimizar consultas y mantener un dise\u00f1o limpio.</p> </li> <li> <p>Documentaci\u00f3n:</p> </li> <li>Las descripciones de columnas y relaciones facilitan el entendimiento del modelo.</li> </ol>"},{"location":"01.scripts/01.Transversal%20copy/#conclusion","title":"Conclusi\u00f3n","text":"<p>El script implementa un esquema <code>Transversal</code> eficiente para an\u00e1lisis en un Data Warehouse. Las tablas de dimensiones proporcionan atributos descriptivos, mientras que las tablas de hechos registran transacciones y m\u00e9tricas clave. Este modelo es escalable y adaptable a m\u00faltiples casos de uso anal\u00edtico.</p>"},{"location":"01.scripts/01.Transversal/","title":"01. Transversal","text":""},{"location":"01.scripts/01.Transversal/#documentacion-del-esquema-transversal-en-sql","title":"Documentaci\u00f3n del Esquema <code>Transversal</code> en SQL","text":""},{"location":"01.scripts/01.Transversal/#1-introduccion","title":"1. Introducci\u00f3n","text":"<p>El esquema <code>Transversal</code> es un componente cr\u00edtico de un Data Warehouse (DWH) dise\u00f1ado para integrar datos de m\u00faltiples fuentes y facilitar an\u00e1lisis multidimensionales. Este manual detalla su estructura, tablas, relaciones y buenas pr\u00e1cticas.</p>"},{"location":"01.scripts/01.Transversal/#2-objetivos-del-esquema","title":"2. Objetivos del Esquema","text":"<ul> <li>Integraci\u00f3n: Consolidar datos de empresas, afiliados, transacciones financieras, encuestas y m\u00e1s.</li> <li>An\u00e1lisis: Habilitar consultas complejas para m\u00e9tricas como aportes, presupuestos, satisfacci\u00f3n de usuarios y PQRS.</li> <li>Escalabilidad: Dise\u00f1o modular para incorporar nuevas tablas sin afectar la estructura existente.</li> </ul>"},{"location":"01.scripts/01.Transversal/#3-arquitectura-del-esquema","title":"3. Arquitectura del Esquema","text":""},{"location":"01.scripts/01.Transversal/#31-componentes-principales","title":"3.1. Componentes Principales","text":"<ul> <li>Tablas de Dimensiones (<code>DIM_*</code>): Almacenan entidades descriptivas (empresas, afiliados, cuentas contables, g\u00e9nero, estado civil, etc.).</li> <li>Tablas de Hechos (<code>FACT_*</code>): Registran eventos transaccionales (aportes, movimientos contables, encuestas, PQRS, etc.).</li> <li>Relaciones: Claves for\u00e1neas para garantizar integridad referencial.</li> </ul>"},{"location":"01.scripts/01.Transversal/#32-diagrama-general","title":"3.2. Diagrama General","text":"<pre><code>erDiagram\n    DIM_EMPRESAS ||--o{ DIM_AFILIADOS : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ DIM_BENEFICIARIOS : \"ID_AFILIADO\"\n    DIM_EMPRESAS ||--o{ FACT_APORTES_SHR_DET : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ FACT_APORTES_SHR_DET : \"ID_AFILIADO\"\n    DIM_CUENTA_CONTABLE ||--o{ FACT_DETALLE_CONTABLE : \"ID_CUENTA\"\n    DIM_UNIDADES_ORGANIZATIVAS ||--o{ FACT_DETALLE_CONTABLE : \"ID_CEBE\"\n    DIM_UNIDAD ||--o{ FACT_ENCUESTAS : \"ID_UNIDAD\"\n    DIM_GENERO ||--o{ DIM_AFILIADOS : \"ID_GENERO\"\n    DIM_ESTADO_CIVIL ||--o{ DIM_AFILIADOS : \"ID_ESTADO_CIVIL\"\n    DIM_FACTOR_DE_VULNERABILIDAD ||--o{ DIM_AFILIADOS : \"ID_FACTOR_VULNERABILIDAD\"</code></pre>"},{"location":"01.scripts/01.Transversal/#4-tablas-clave-y-descripcion-detallada","title":"4. Tablas Clave y Descripci\u00f3n Detallada","text":""},{"location":"01.scripts/01.Transversal/#41-dimensiones-principales","title":"4.1. Dimensiones Principales","text":""},{"location":"01.scripts/01.Transversal/#dim_empresas","title":"DIM_EMPRESAS","text":"<ul> <li>Prop\u00f3sito: Datos maestros de empresas aportantes.</li> <li>Columnas Relevantes:<ul> <li><code>ID_EMPRESA</code> (PK): Identificador \u00fanico.</li> <li><code>RAZON_SOCIAL</code>: Nombre legal.</li> <li><code>TIPO_DOCUMENTO</code>: NIT, CC, etc.</li> <li><code>ESTADO</code>: Activa, inactiva, retirada.</li> </ul> </li> <li>Relaciones: Relacionada con <code>DIM_AFILIADOS</code> y <code>FACT_APORTES_SHR_DET</code>.</li> </ul>"},{"location":"01.scripts/01.Transversal/#dim_afiliados","title":"DIM_AFILIADOS","text":"<ul> <li>Prop\u00f3sito: Informaci\u00f3n demogr\u00e1fica y laboral de afiliados.</li> <li>Columnas Relevantes:<ul> <li><code>ID_AFILIADO</code> (PK): Identificador \u00fanico.</li> <li><code>NOMBRE_COMPLETO</code>: Nombre del afiliado.</li> <li><code>FECHA_AFILIACION</code>: Fecha de registro en el sistema.</li> <li><code>ID_EMPRESA</code> (FK): Empresa asociada.</li> <li><code>ID_GENERO</code> (FK): G\u00e9nero del afiliado.</li> <li><code>ID_ESTADO_CIVIL</code> (FK): Estado civil del afiliado.</li> <li><code>ID_FACTOR_VULNERABILIDAD</code> (FK): Factor de vulnerabilidad.</li> </ul> </li> <li>Relaciones: Vinculada a <code>DIM_BENEFICIARIOS</code>, <code>FACT_APORTES_SHR_DET</code> y otras dimensiones.</li> </ul>"},{"location":"01.scripts/01.Transversal/#dim_beneficiarios","title":"DIM_BENEFICIARIOS","text":"<ul> <li>Prop\u00f3sito: Beneficiarios vinculados a afiliados (familiares).</li> <li>Columnas Clave:<ul> <li><code>ID_BENEFICIARIO</code> (PK): Identificador \u00fanico.</li> <li><code>PARENTESCO</code>: Relaci\u00f3n con el afiliado (hijo, c\u00f3nyuge).</li> <li><code>ID_AFILIADO</code> (FK): Afiliado titular.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#dim_genero","title":"DIM_GENERO","text":"<ul> <li>Prop\u00f3sito: Clasificaci\u00f3n de g\u00e9nero.</li> <li>Columnas Clave:<ul> <li><code>ID_GENERO</code> (PK): Identificador \u00fanico.</li> <li><code>GENERO</code>: Descripci\u00f3n del g\u00e9nero.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#dim_estado_civil","title":"DIM_ESTADO_CIVIL","text":"<ul> <li>Prop\u00f3sito: Clasificaci\u00f3n del estado civil.</li> <li>Columnas Clave:<ul> <li><code>ID_ESTADO_CIVIL</code> (PK): Identificador \u00fanico.</li> <li><code>ESTADO_CIVIL</code>: Descripci\u00f3n del estado civil.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#dim_factor_de_vulnerabilidad","title":"DIM_FACTOR_DE_VULNERABILIDAD","text":"<ul> <li>Prop\u00f3sito: Clasificaci\u00f3n de factores de vulnerabilidad.</li> <li>Columnas Clave:<ul> <li><code>ID_FACTOR_VULNERABILIDAD</code> (PK): Identificador \u00fanico.</li> <li><code>FACTOR_VULNERABILIDAD</code>: Descripci\u00f3n del factor.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#42-tablas-de-hechos","title":"4.2. Tablas de Hechos","text":""},{"location":"01.scripts/01.Transversal/#fact_aportes_shr_det","title":"FACT_APORTES_SHR_DET","text":"<ul> <li>Prop\u00f3sito: Detalle de aportes financieros.</li> <li>M\u00e9tricas:<ul> <li><code>APORTE_NUEVO</code>: Monto del aporte.</li> <li><code>PERIODO</code>: Per\u00edodo contable (ej. <code>2023M01</code>).</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_EMPRESA</code> (FK): Empresa que realiza el aporte.</li> <li><code>ID_AFILIADO</code> (FK): Afiliado beneficiario.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#fact_detalle_contable","title":"FACT_DETALLE_CONTABLE","text":"<ul> <li>Prop\u00f3sito: Movimientos contables (ingresos, gastos).</li> <li>M\u00e9tricas:<ul> <li><code>IMPORTE</code>: Valor total de la transacci\u00f3n.</li> <li><code>INGRESOS_OPERACIONALES</code>: Ingresos core del negocio.</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_CUENTA</code> (FK): Cuenta contable (<code>DIM_CUENTA_CONTABLE</code>).</li> <li><code>ID_CEBE</code> (FK): Unidad organizativa (<code>DIM_UNIDADES_ORGANIZATIVAS</code>).</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#fact_encuestas","title":"FACT_ENCUESTAS","text":"<ul> <li>Prop\u00f3sito: Resultados de encuestas de satisfacci\u00f3n.</li> <li>M\u00e9tricas:<ul> <li><code>CALIFICACION</code>: Puntuaci\u00f3n del servicio (ej. 1-5).</li> <li><code>SERVICIO</code>: Tipo de servicio evaluado.</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_UNIDAD</code> (FK): Unidad responsable (<code>DIM_UNIDAD</code>).</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#fact_pqrs","title":"FACT_PQRS","text":"<ul> <li>Prop\u00f3sito: Registro de PQRS (Peticiones, Quejas, Reclamos y Sugerencias).</li> <li>M\u00e9tricas:<ul> <li><code>TIPO_PQRS</code>: Clasificaci\u00f3n del PQRS.</li> <li><code>FECHA_CREACION</code>: Fecha de creaci\u00f3n del PQRS.</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_EMPRESA</code> (FK): Empresa asociada.</li> <li><code>ID_AFILIADO</code> (FK): Afiliado asociado.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#5-relaciones-y-dependencias","title":"5. Relaciones y Dependencias","text":""},{"location":"01.scripts/01.Transversal/#51-reglas-de-integridad","title":"5.1. Reglas de Integridad","text":"<ul> <li>Claves For\u00e1neas: Todas las tablas de hechos incluyen FK a dimensiones.</li> <li>Valores por Defecto: <ul> <li><code>-1</code> para indicar \"No aplica\" o datos faltantes (ej. <code>ID_EMPRESA</code> en <code>FACT_ENCUESTAS</code>).</li> <li><code>20090101</code> para fechas m\u00ednimas (ej. <code>ID_FECHA</code> en <code>FACT_APORTES_SHR_DET</code>).</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#52-nuevas-tablas-agregadas","title":"5.2. Nuevas Tablas Agregadas","text":"<ul> <li>DIM_GENERO: Clasificaci\u00f3n de g\u00e9nero.</li> <li>DIM_ESTADO_CIVIL: Clasificaci\u00f3n del estado civil.</li> <li>DIM_FACTOR_DE_VULNERABILIDAD: Clasificaci\u00f3n de factores de vulnerabilidad.</li> </ul>"},{"location":"01.scripts/01.Transversal/#52-script","title":"5.2. Script","text":"<pre><code>USE DWH_COMFENALCO\nGO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- Eliminar restricciones de clave for\ufffdnea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Transversal')\nBEGIN\n    DROP SCHEMA Transversal;\nEND\nGO\n-- Crear el esquema Transversal\nCREATE SCHEMA Transversal;\nGO\n-- Crear DIM_EMPRESAS\nCREATE TABLE [Transversal].[DIM_EMPRESAS](\n    [ID_EMPRESA] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [RAZON_SOCIAL] [nvarchar](300) NULL,\n    [ID_ESTADO] [nvarchar](2) NULL,\n    [ESTADO] [nvarchar](40) NULL,\n    [ID_SECTOR] [nvarchar](2) NULL,\n    [SECTOR] [nvarchar](40) NULL,\n    [ID_CLASE] [nvarchar](2) NULL,\n    [CLASE] [nvarchar](40) NULL,\n    [ID_ACT_ECONOMICA] [nvarchar](4) NULL,\n    [ACT_ECONOMICA] [nvarchar](200) NULL,\n    [ES_NUEVO] [int] NULL,\n    [ID_TIPO_APORTANTE] [nvarchar](2) NULL,\n    [TIPO_APORTANTE] [nvarchar](40) NULL,\n    [FECHA_AFILIACION] [datetime] NULL,\n    [FECHA_FUNDACION] [nvarchar](50) NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_MOTIVO_RETIRO] [int] NULL,\n    [MOTIVO_RETIRO] [nvarchar](80) NULL,\n    [FECHA_DESDE] [datetime] NULL,\n    [FECHA_HASTA] [datetime] NULL,\n    [DIRECCION] [nvarchar](300) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [COD_CIUDAD] [nvarchar](5) NULL,\n    [NUMERO_PROCESO_SQL] [bigint] NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [ESTADOREGISTRO] [nvarchar](10) NULL,\n    [CORREO] [nvarchar](200) NULL,\n    [TIPO_PERSONA] [nvarchar](1) NULL,\n    [PRIMER_NOMBRE] [nvarchar](50) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](50) NULL,\n    [PRIMER_APELLIDO] [nvarchar](50) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](50) NULL,\n    [CONVENIO_LIB] [int] NULL,\n    [FECHA_PRIMER_APORTE] [int] NULL,\n    [DIGITO_VERIFICACON] [varchar](1) NULL,\n    [CAJA_COMPEN] [varchar](2) NULL,\n    [SITUACION_1429] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_1429] [nvarchar](10) NULL,\n    [SITUACION_590] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_590] [nvarchar](10) NULL,\n    [ORIGEN_EXTRACCION] [varchar](50) NULL,\n    CONSTRAINT [PK_DIM_EMPRESAS] PRIMARY KEY CLUSTERED ([ID_EMPRESA])\n) ON [PRIMARY]\nGO\n-- Crear DIM_AFILIADOS\nCREATE TABLE [Transversal].[DIM_AFILIADOS](\n    [ID_AFILIADO] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [NUMERO_DOCUMENTO] [nvarchar](20) NULL,\n    [NOMBRE_COMPLETO] [nvarchar](200) NULL,\n    [PRIMER_APELLIDO] [nvarchar](50) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](50) NULL,\n    [PRIMER_NOMBRE] [nvarchar](50) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](50) NULL,\n    [ID_TIPO_AFILIADO] [nvarchar](2) NULL,\n    [TIPO_AFILIADO] [varchar](80) NULL,\n    [ID_CATEGORIA] [nvarchar](2) NULL,\n    [CATEGORIA] [nvarchar](10) NULL,\n    [ID_ESTADO_AFILIACION] [nvarchar](4) NULL,\n    [ESTADO_AFILIACION] [nvarchar](40) NULL,\n    [FECHA_AFILIACION] [nvarchar](50) NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_MOTIVORETIRO] [nvarchar](2) NULL,\n    [MOTIVORETIRO] [nvarchar](50) NULL,\n    [ID_NIVEL_EDUCATIVO] [nvarchar](2) NULL,\n    [NIVEL_EDUCATIVO] [varchar](50) NULL,\n    [ID_GENERO] [nvarchar](2) NULL,\n    [GENERO] [varchar](20) NULL,\n    [ID_ORIENTACION_SEXUAL] [nvarchar](2) NULL,\n    [ORIENTACION_SEXUAL] [nvarchar](40) NULL,\n    [ID_ESTADO_CIVIL] [nvarchar](2) NULL,\n    [ESTADO_CIVIL] [nvarchar](40) NULL,\n    [COD_OCUPACION] [nvarchar](4) NULL,\n    [OCUPACION] [nvarchar](100) NULL,\n    [ID_PERTENENCIA_ETNICA] [nvarchar](2) NULL,\n    [PERTENENCIA_ETNICA] [nvarchar](100) NULL,\n    [ID_FACTOR_VULNERABILIDAD] [nvarchar](2) NULL,\n    [FACTOR_VULNERABILIDAD] [nvarchar](50) NULL,\n    [CONDICION_ESPECIAL] [nvarchar](2) NULL,\n    [FECHA_NACIMIENTO] [nvarchar](10) NULL,\n    [DIRECCION] [nvarchar](60) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [BARRIO] [nvarchar](40) NULL,\n    [ESTRATO] [nvarchar](2) NULL,\n    [ID_CIUDAD] [nvarchar](5) NULL,\n    [ID_AREA_GEOGRAFICA] [nvarchar](2) NULL,\n    [AREA_GEOGRAFICA] [nvarchar](10) NULL,\n    [CORREO] [nvarchar](250) NULL,\n    [SALARIO_BASICO] [nvarchar](50) NULL,\n    [ES_NUEVO] [nvarchar](50) NULL,\n    [TIPO_SALARIO] [nvarchar](50) NULL,\n    [HORAS_LAB_MENSUAL] [nvarchar](50) NULL,\n    [TIPO_APORTANTE] [nvarchar](50) NOT NULL,\n    [APORTANTE] [nvarchar](10) NULL,\n    [FEC_DESDE] [datetime] NULL,\n    [FEC_HASTA] [datetime] NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [ESTADOREGISTRO] [nvarchar](20) NULL,\n    [ID_RESGUARDO] [int] NULL,\n    [RESGUARDO] [varchar](100) NULL,\n    [COD_PAIS_RESIDENCIA] [int] NULL,\n    [PAIS_RESIDENCIA] [varchar](100) NULL,\n    [COD_MUN_LABOR_DANE] [varchar](5) NULL,\n    [AREA_GEOGRA_LABOR] [varchar](2) NULL,\n    [FECHA_INGRESO_EMPRESA] [varchar](50) NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [EMPRESA_PRINCIPAL] [varchar](1) NULL,\n    [VALOR_SALARIO_UVT] [numeric](18, 2) NULL,\n    [ID_CATEGORIA_UVT] [varchar](2) NULL,\n    [CATEGORIA_UVT] [varchar](10) NULL,\n CONSTRAINT [PK_DIM_AFILIADOS] PRIMARY KEY CLUSTERED \n(\n    [ID_AFILIADO] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, FILLFACTOR = 100, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY],\nCONSTRAINT [FK_DIM_AFILIADOS_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA])\n) ON [PRIMARY]\nGO\n-- Crear DIM_BENEFICIARIOS\nCREATE TABLE [Transversal].[DIM_BENEFICIARIOS](\n    [ID_BENEFICIARIO] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [TITULAR] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [NUMERO_DOCUMENTO] [nvarchar](20) NULL,\n    [NOMBRE_COMPLETO] [nvarchar](81) NULL,\n    [PRIMER_APELLIDO] [nvarchar](40) NOT NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](40) NULL,\n    [PRIMER_NOMBRE] [nvarchar](40) NOT NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](40) NULL,\n    [ID_PARENTESCO] [nvarchar](8) NULL,\n    [PARENTESCO] [varchar](50) NULL,\n    [FECHA_AFILIACION] [nvarchar](50) NOT NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_GENERO] [varchar](1) NOT NULL,\n    [GENERO] [varchar](9) NOT NULL,\n    [ID_NIVEL_EDUCATIVO] [nvarchar](2) NULL,\n    [NIVEL_EDUCATIVO] [nvarchar](50) NULL,\n    [ID_ESTADO_CIVIL] [nvarchar](2) NULL,\n    [ESTADO_CIVIL] [nvarchar](40) NULL,\n    [DISCAPACIDAD] [nvarchar](1) NULL,\n    [FECHA_NACIMIENTO] [datetime] NOT NULL,\n    [DIRECCION] [nvarchar](60) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [BARRIO] [nvarchar](40) NULL,\n    [ESTRATO] [nvarchar](2) NULL,\n    [ID_CIUDAD] [nvarchar](5) NULL,\n    [ID_AREA_GEOGRAFICA] [nvarchar](2) NULL,\n    [AREA_GEOGRAFICA] [nvarchar](10) NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](40) NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [ESTADOREGISTRO] [nvarchar](10) NULL,\n    [ID_PARENT_SAP] [nvarchar](10) NULL,\n    [PARENT_SAP] [nvarchar](30) NULL,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [APORTANTE] [nvarchar](10) NULL,\n    [TIPO_AFILIADO] [nvarchar](50) NOT NULL,\n    [TIPO_APORTANTE] [nvarchar](50) NOT NULL,\n    [FEC_DESDE] [datetime] NULL,\n    [FEC_HASTA] [datetime] NULL,\n    [ESTADO_BEN] [int] NULL,\n    [FECHA_INGRESO_EMPRESA] [varchar](50) NULL,\n CONSTRAINT [PK_DIM_BENENEFICIARIOS] PRIMARY KEY CLUSTERED \n(\n    [ID_BENEFICIARIO] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, FILLFACTOR = 100, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY],\nCONSTRAINT [FK_DIM_BENEFICIARIOS_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO])\n) ON [PRIMARY]\nGO\n-- Crear DIM_APORTANTE_NOAFILIADO\nCREATE TABLE [Transversal].[DIM_APORTANTE_NOAFILIADO](\n    [ID_APORTANTE] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [RAZON_SOCIAL] [nvarchar](300) NULL,\n    [ID_ESTADO] [nvarchar](2) NULL,\n    [ESTADO] [nvarchar](40) NULL,\n    [ID_SECTOR] [nvarchar](2) NULL,\n    [SECTOR] [nvarchar](40) NULL,\n    [ID_CLASE] [nvarchar](2) NULL,\n    [CLASE] [nvarchar](40) NULL,\n    [ID_ACT_ECONOMICA] [nvarchar](4) NULL,\n    [ACT_ECONOMICA] [nvarchar](200) NULL,\n    [ES_NUEVO] [int] NULL,\n    [ID_TIPO_APORTANTE] [nvarchar](2) NULL,\n    [TIPO_APORTANTE] [nvarchar](40) NULL,\n    [FECHA_AFILIACION] [datetime] NULL,\n    [FECHA_FUNDACION] [nvarchar](50) NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_MOTIVO_RETIRO] [int] NULL,\n    [MOTIVO_RETIRO] [nvarchar](80) NULL,\n    [FECHA_DESDE] [datetime] NULL,\n    [FECHA_HASTA] [datetime] NULL,\n    [DIRECCION] [nvarchar](300) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [COD_CIUDAD] [nvarchar](5) NULL,\n    [NUMERO_PROCESO_SQL] [bigint] NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [ESTADOREGISTRO] [nvarchar](10) NULL,\n    [CORREO] [nvarchar](200) NULL,\n    [TIPO_PERSONA] [nvarchar](1) NULL,\n    [PRIMER_NOMBRE] [nvarchar](50) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](50) NULL,\n    [PRIMER_APELLIDO] [nvarchar](50) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](50) NULL,\n    [CONVENIO_LIB] [int] NULL,\n    [FECHA_PRIMER_APORTE] [int] NULL,\n    [DIGITO_VERIFICACON] [varchar](1) NULL,\n    [CAJA_COMPEN] [varchar](2) NULL,\n    [SITUACION_1429] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_1429] [nvarchar](10) NULL,\n    [SITUACION_590] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_590] [nvarchar](10) NULL,\n    [FECHA_NACIMIENTO] [varchar](8) NULL,\n    [GENERO] [int] NULL,\n    CONSTRAINT [PK_DIM_APORTANTE_NOAFILIADO] PRIMARY KEY CLUSTERED ([ID_APORTANTE])\n) ON [PRIMARY]\nGO\n-- Crear FACT_APORTES_SHR_DET\nCREATE TABLE [Transversal].[FACT_APORTES_SHR_DET](\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [PERIODO] [varchar](10) NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [OPBEL] [varchar](50) NULL,\n    [BELNR] [varchar](50) NULL,\n    [MOVIMIENTO] [varchar](50) NULL,\n    [FECHA_CONTABLE] [int] NULL,\n    [NUM_CUENTA] [varchar](50) NULL,\n    [APORTE] [varchar](50) NULL,\n    [INTERES] [varchar](50) NULL,\n    [ESTADOREGISTRO] [varchar](50) NULL,\n    [FECHA_ACTUALIZACION] [datetime] NULL,\n    [DESDE] [datetime] NULL,\n    [HASTA] [datetime] NULL,\n    [PROCESO] [nvarchar](50) NULL,\n    [BP_EMPRESA] [varchar](10) NULL,\n    [BP_AFILIADO] [varchar](10) NULL,\n    [TIPO_APORTANTE] [int] NULL,\n    [SW_AJUSTE] [int] NULL,\n    [APORTE_NUEVO] [numeric](18, 0) NULL,\n    CONSTRAINT [FK_FACT_APORTES_SHR_DET_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_APORTES_SHR_DET_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_APORTES_SHR_DET_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n) ON [PRIMARY]\nGO\nALTER TABLE [Transversal].[FACT_APORTES_SHR_DET] ADD  DEFAULT ((0)) FOR [SW_AJUSTE]\nGO\nALTER TABLE [Transversal].[FACT_APORTES_SHR_DET] ADD  DEFAULT ((0)) FOR [APORTE_NUEVO]\nGO\nCREATE TABLE [Transversal].[DIM_CUENTA_CONTABLE](\n    [ID_CUENTA] [bigint] IDENTITY(1,1) NOT NULL,\n    [CUENTA_NUMERO] [bigint] NOT NULL,\n    [CUENTA] [nvarchar](10) NOT NULL,\n    [CUENTA_HOMOLOGA] [nvarchar](10) NOT NULL,\n    [DESCRIPCION] [nvarchar](50) NOT NULL,\n    [TIPO_CUENTA] [nvarchar](100) NOT NULL,\n    [TIPO_OPERACION] [nvarchar](100) NOT NULL,\n    [GRUPO_CUENTA] [nvarchar](100) NOT NULL,\n    [SUBGRUPO_CUENTA] [nvarchar](50) NOT NULL,\n    [GRUPO_OPERACION] [nvarchar](100) NOT NULL,\n    [FEC_PROCESO] [datetime] NOT NULL,\n    [UDATE] [datetime] NOT NULL,\n    [CUENTA_SSF] [int] NOT NULL,\n    [DESCRIPCION_SSF] [nvarchar](255) NOT NULL,\n    [CUENTA_DESCRIPCION]  AS (([CUENTA]+'-')+[DESCRIPCION]),\n    [CUENTA_DESCRIPCION_SSF]  AS ((rtrim(CONVERT([varchar],[CUENTA_SSF]))+'-')+[DESCRIPCION_SSF]),\n    [SIGNO_INGRESOS]  AS (case when [TIPO_CUENTA]='INGRESOS' then (1) else (0) end),\n    [NUMERO_PROCESO_SQL] [bigint] NOT NULL,\n    [CLASIFICACION] [int] NULL,\n    [USUARIO_PROCESO] [nvarchar](50) NOT NULL,\n    [ESTADO_REGISTRO] [nvarchar](10) NULL,\n    [NIVEL_1_TIPO_CUENTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(1))),\n    [DESC_NIVEL_1_TIPO_CUENTA]  AS ([TIPO_CUENTA]),\n    [NIVEL_2_TIPO_OPERAC]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(2))),\n    [DES_NIVEL_2_TIPO_OPERAC]  AS ([TIPO_OPERACION]),\n    [NIVEL_4_GRUPO_CTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(4))),\n    [DESC_NIVEL_4_GRUPO_CTA]  AS ([GRUPO_CUENTA]),\n    [NIVEL_6_SUBG_CTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(6))),\n    [DESC_NIVEL_6_SUBG_CTA]  AS ([SUBGRUPO_CUENTA]),\n    [NIVEL_8_GRUPO_OPERAC]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(8))),\n    [DESC_NIVEL_8_GRUPO_OPERAC]  AS ([GRUPO_OPERACION]),\n    [NIVEL_10_CUENTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(10))),\n    [DESC_NIVEL_10_CUENTA_NUMERO]  AS ([DESCRIPCION]),\n    [ID_CUENTA_AUXILIAR] AS ([ID_CUENTA]),\n CONSTRAINT [PK_DIM_CUENTA_CONTABLE] PRIMARY KEY CLUSTERED \n(\n    [ID_CUENTA] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY]\n) ON [PRIMARY]\nGO\n-- Crear DIM_UNIDAD\n CREATE TABLE [Transversal].[DIM_UNIDAD] (\n    [ID_UNIDAD] [int] IDENTITY(1,1) NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    CONSTRAINT [PK_DIM_UNIDAD] PRIMARY KEY CLUSTERED ([ID_UNIDAD])\n)\nGO\n-- Crear DIM_UNIDADES_ORGANIZATIVAS\nCREATE TABLE [Transversal].[DIM_UNIDADES_ORGANIZATIVAS](\n    [ID_CEBE] [bigint] NOT NULL,\n    [CEBE] [varchar](10) NOT NULL,\n    [DESCRIPCION_BREVE] [varchar](50) NOT NULL,\n    [DESCRIPCION_COMPLETA] [varchar](100) NOT NULL,\n    [CEBE_DESCRIPCION]  AS ((rtrim(CONVERT([char],[CEBE]))+'-')+[DESCRIPCION_COMPLETA]),\n    [DEPARTAMENTO] [varchar](100) NOT NULL,\n    [AREA] [varchar](100) NOT NULL,\n    [SUBAREA] [varchar](100) NOT NULL,\n    [SEGMENTO] [bigint] NOT NULL,\n    [DESCRIPCION_SEGMENTO] [varchar](50) NOT NULL,\n    [SEGMENTO_DESCRIPCION]  AS ((rtrim(CONVERT([char],[SEGMENTO]))+'-')+[DESCRIPCION_SEGMENTO]),\n    [CODIGO_SSF] [int] NOT NULL,\n    [NOMBRE_SSF] [varchar](100) NOT NULL,\n    [CODIGO_NOMBRE_SSF]  AS ((rtrim(CONVERT([char],[CODIGO_SSF]))+'-')+[NOMBRE_SSF]),\n    [UDATE] [smalldatetime] NOT NULL,\n    [NUMERO_PROCESO_SQL] [bigint] NOT NULL,\n    [FEC_PROCESO] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [GRUPO_CEBE] [varchar](50) NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n CONSTRAINT [PK__DIM_UNIDADES_ORGANIZATIVAS] PRIMARY KEY CLUSTERED \n(\n    [ID_CEBE] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY]\n) ON [PRIMARY]\nGO\nALTER TABLE [Transversal].[DIM_UNIDADES_ORGANIZATIVAS]  WITH NOCHECK ADD  CONSTRAINT [FK_DIM_UNIDADES_ORGANIZATIVAS_DIM_UNIDAD] FOREIGN KEY([ID_UNIDAD])\nREFERENCES [Transversal].[DIM_UNIDAD] ([ID_UNIDAD])\nGO\n-- FACT_DETALLE_CONTABLE\nCREATE TABLE [Transversal].[FACT_DETALLE_CONTABLE](\n    [ID_CEBE] [bigint] NOT NULL,\n    [ID_CUENTA] [bigint] NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [SEGMENT] [bigint] NOT NULL,\n    [IMPORTE] [decimal](28, 2),-- NOT NULL,\n    [INGRESOS] [decimal](28, 2) ,--NOT NULL,\n    [INGRESOS_OPERACIONALES] [decimal](28, 2),-- NOT NULL,\n    [GASTOS] [decimal](28, 2) ,--NOT NULL,\n    [GASTOS_OPERACIONALES] [decimal](28, 2),-- NOT NULL,\n    [GASTOS_OPERACIONALES_ADMIN] [decimal](28, 2),-- NOT NULL,\n    [RESULTADO_EJERCICIO] [decimal](28, 2),-- NOT NULL,\n    [COSTOS] [decimal](28, 2),-- NOT NULL,\n    [ACTIVO] [decimal](28, 2),-- NOT NULL,\n    [PASIVO] [decimal](28, 2),-- NOT NULL,\n    [PATRIMONIO] [decimal](28, 2),-- NOT NULL,\n    [GASTOS_CON_DISTRIBUCION] [decimal](28, 2),-- NOT NULL,\n    [GASTOS_SIN_DISTRIBUCION] [decimal](28, 2),-- NOT NULL,\n    [FECHA_REGISTRO_SAP] [datetime] NOT NULL,\n    [FECHA_PROCESO] [datetime] NOT NULL,\n    [USUARIO_PROCESO] [varchar](50) NOT NULL\n) ON [PRIMARY]\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_CUENTA_CONTABLE] FOREIGN KEY([ID_CUENTA])\nREFERENCES [Transversal].[DIM_CUENTA_CONTABLE] ([ID_CUENTA])\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE] CHECK CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_CUENTA_CONTABLE]\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_DETALLE_CONTABLE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA])\nREFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE] CHECK CONSTRAINT [FK_FACT_DETALLE_CONTABLE_Dim_TIEMPO]\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_UNIDADES_ORGANIZATIVAS] FOREIGN KEY([ID_CEBE])\nREFERENCES [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] ([ID_CEBE])\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE] CHECK CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_UNIDADES_ORGANIZATIVAS]\nGO\n\n-- Crear FACT_PRESUPUESTO\nCREATE TABLE [Transversal].[FACT_PRESUPUESTO](\n    [ID_CEBE] [bigint] NOT NULL,\n    [ID_CUENTA] [bigint] NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [ID_TIPO_PRESUPUESTO] [int] NOT NULL,\n    [SEGMENT] [bigint] NOT NULL,\n    [VALOR] [decimal](28, 2) NOT NULL,\n    [INGRESOS] [decimal](28, 2) NOT NULL,\n    [INGRESOS_OPERACIONALES] [decimal](28, 2) NOT NULL,\n    [GASTOS] [decimal](28, 2) NOT NULL,\n    [GASTOS_OPERACIONALES] [decimal](28, 2) NOT NULL,\n    [GASTOS_OPERACIONALES_ADMIN] [decimal](28, 2) NOT NULL,\n    [COSTOS] [decimal](28, 2) NOT NULL,\n    [GASTOS_CON_DISTRIBUCION] [decimal](28, 2) NOT NULL,\n    [GASTOS_SIN_DISTRIBUCION] [decimal](28, 2) NOT NULL,\n    [FECHA_PROCESO] [datetime] NOT NULL,\n    [USUARIO_PROCESO] [varchar](50) NOT NULL\n) ON [PRIMARY]\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_CUENTA_CONTABLE] FOREIGN KEY([ID_CUENTA])\nREFERENCES [Transversal].[DIM_CUENTA_CONTABLE] ([ID_CUENTA])\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO] CHECK CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_CUENTA_CONTABLE]\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_PRESUPUESTO_Dim_TIEMPO] FOREIGN KEY([ID_FECHA])\nREFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO] CHECK CONSTRAINT [FK_FACT_PRESUPUESTO_Dim_TIEMPO]\nGO\n\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_UNIDADES_ORGANIZATIVAS] FOREIGN KEY([ID_CEBE])\nREFERENCES [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] ([ID_CEBE])\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO] CHECK CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_UNIDADES_ORGANIZATIVAS]\nGO\n\n-- Crear DIM_SERVICIOS\n /*CREATE TABLE [Transversal].[DIM_SERVICIOS] (\n    [ID_SERVICIO] [int] IDENTITY(1,1) NOT NULL,\n    [SERVICIO] [nvarchar](40) NOT NULL,\n    [ID_UNIDAD] [int]  NOT NULL,\n    [CON_OBJETO_TARIFA] [nvarchar](40) NOT NULL,\n    [VAL_TARIFA] [decimal](28, 2) NOT NULL,\n    [COD_CATEGORIA] [nvarchar](40) NOT NULL,\n    [CATEGORIA] [nvarchar](40) NOT NULL,\n    [LINEA_INTERVENCION] [nvarchar](40),\n    [CUPOS_DISPONIBLES] [int] NOT NULL,\n    [ANIO_TARIFA] [varchar](10) NOT NULL,\n    [CIUDAD] [nvarchar](40) NOT NULL,\n    [ID_ESTABLECIMIENTO] [nvarchar](40) NOT NULL,\n    [NOMBRE_ESTABLECIMIENTO] [nvarchar](40) NOT NULL,\n    [SEDE_ESTABLECIMIENTO] [nvarchar](40) NOT NULL,\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](40) NOT NULL,\n    CONSTRAINT [PK_DIM_SERVICIOS] PRIMARY KEY CLUSTERED ([ID_SERVICIO]),\n    CONSTRAINT [FK_DIM_SERVICIOS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO*/\n\n-- Crear DIM_INFRAESTRUCTURA_CCF\n CREATE TABLE [Transversal].[DIM_INFRAESTRUCTURA_CCF] (\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](40) NOT NULL,\n    [DESCRIPCION] [nvarchar](40) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5,\n    CONSTRAINT [PK_DIM_INFRAESTRUCTURA_CCF] PRIMARY KEY CLUSTERED ([COD_INFRAESTRUCTURA_CCF]),\n    CONSTRAINT [FK_COD_INFRAESTRUCTURA_CCF_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO\n-- Crear DIM_CATEGORIA\n CREATE TABLE [Transversal].[DIM_CATEGORIA] (\n    [COD_CATEGORIA] [nvarchar](40) NOT NULL,\n    [DESCRIPCION] [nvarchar](40) NOT NULL,\n    CONSTRAINT [PK_DIM_CATEGORIA] PRIMARY KEY CLUSTERED ([COD_CATEGORIA])\n)\nGO\n\n-- Crear DIM_TARIFA_SERVICIOS\n CREATE TABLE [Transversal].[DIM_TARIFAS_SERVICIOS] (\n    [ID_TARIFA] [int] IDENTITY(1,1) NOT NULL,\n    [COD_SERVICIO] [int] NOT NULL,\n    [CON_OBJETO_TARIFA] [nvarchar](255) NOT NULL,\n    [COS_UNITARIO_CONCEPTO] [decimal](28, 2) NOT NULL,\n    [VAL_TARIFA] [decimal](28, 2) NOT NULL,\n    [COD_CATEGORIA] [nvarchar](40) NULL DEFAULT 3, -- Asignar valor por defecto de 3 categoria C,\n    [ANIO_TARIFA] [varchar](10) NOT NULL,\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](40) NOT NULL,\n    [ID_TARIFA_AUXILIAR] AS ( [ANIO_TARIFA] + '_' + [COD_INFRAESTRUCTURA_CCF] + '_' + CAST([COD_SERVICIO] AS NVARCHAR(10)) + '_' + [COD_CATEGORIA] ) PERSISTED,\n    CONSTRAINT [PK_DIM_TARIFA_SERVICIOS] PRIMARY KEY CLUSTERED ([ID_TARIFA]),\n    CONSTRAINT [FK_DIM_TARIFA_SERVICIOS_DIM_CATEGORIA] FOREIGN KEY ([COD_CATEGORIA]) REFERENCES [Transversal].[DIM_CATEGORIA]([COD_CATEGORIA]),\n    CONSTRAINT [FK_DIM_TARIFA_SERVICIOS_DIM_INFRAESTRUCTURA_CCF] FOREIGN KEY ([COD_INFRAESTRUCTURA_CCF]) REFERENCES [Transversal].[DIM_INFRAESTRUCTURA_CCF]([COD_INFRAESTRUCTURA_CCF])\n)\nGO\n\n-- Crear DIM_PERSONAL\n CREATE TABLE [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL] [int] IDENTITY(1,1) NOT NULL,\n    [COD_PERSONA_UNIDAD] [nvarchar](40),\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5,\n    [SERVICIO] [nvarchar](255),\n    [NOMBRE] [nvarchar](255),\n    [TELEFONO] [nvarchar](40),\n    [CELULAR] [nvarchar](40),\n    [CORREO] [nvarchar](255),\n    [DIRECCION] [nvarchar](300),\n    [CIUDAD] [nvarchar](255),\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [FECHA_NACIMIENTO] [datetime],\n    [GENERO] [nvarchar](40),\n    [HORAS_CONTRATADAS_MENSUAL] [decimal](18, 2) ,\n    [HORAS_CONTRATADAS_TOTALES] [decimal](18, 2) ,\n    [VALOR_TOTAL] [decimal](18, 2) ,\n    [TIPO_CONTRATACION] [nvarchar](40),\n    [FECHA_INICIO_CONTRATACION] [datetime],\n    [FECHA_FIN_CONTRATACION] [datetime],\n    [CAUSA_TERMINACION_CONTRATO] [nvarchar](40),\n    [PREGRADO] [nvarchar](255),\n    [POSGRADO_ESPECIALIDAD] [nvarchar](255),\n    [POSGRADO_MAESTRIA] [nvarchar](255),\n    [POSGRADO_DOCTORADO] [nvarchar](255),\n    [NIVEL_INGLES] [nvarchar](40),\n    [AREA] [nvarchar](255),\n    CONSTRAINT [PK_DIM_PERSONAL] PRIMARY KEY CLUSTERED ([ID_PERSONAL]),\n    CONSTRAINT [FK_DIM_PERSONAL_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO\n-- Crear FACT_ENCUESTAS\n CREATE TABLE [Transversal].[FACT_ENCUESTAS] (\n    [ID_ENCUESTA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [FECHA_ENCUESTA] [datetime] NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](40),\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [PREGUNTA] [nvarchar](255) NOT NULL,\n    [SERVICIO] [nvarchar](40) NOT NULL,\n    [NPS] [nvarchar](40) NOT NULL,\n    [CALIFICACION] [nvarchar](255) NOT NULL,\n    CONSTRAINT [PK_FACT_ENCUESTAS] PRIMARY KEY CLUSTERED ([ID_ENCUESTA]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear FACT_ENCUESTAS_PSR\n CREATE TABLE [Transversal].[FACT_ENCUESTAS_PSR] (\n    [ID_ENCUESTA_PSR] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [FECHA_ENCUESTA] [datetime] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [PROGRAMA] [nvarchar](40) NOT NULL,\n    [ACTIVIDAD_PREGUNTA] [nvarchar](255) NOT NULL,\n    [CALIFICACION] [nvarchar](40) NOT NULL,\n    CONSTRAINT [PK_FACT_ENCUESTAS_PSR] PRIMARY KEY CLUSTERED ([ID_ENCUESTA_PSR]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear DIM_SEDES\n CREATE TABLE [Transversal].[DIM_SEDES] (\n    [ID_SEDE] [int] IDENTITY(1,1) NOT NULL,\n    [SEDE] [nvarchar](60),\n    CONSTRAINT [PK_DIM_SEDES] PRIMARY KEY CLUSTERED ([ID_SEDE])\n)\nGO\n-- Crear DIM_CAPACIDAD_FISICA\n CREATE TABLE [Transversal].[DIM_CAPACIDAD_FISICA] (\n    [ID_CAPACIDAD] [int] IDENTITY(1,1) NOT NULL,\n    [ID_SALON] [nvarchar](10) NOT NULL,\n    [CAPACIDAD] [int] NOT NULL,\n    [DESCRIPCION_ESPACIO] [nvarchar](255),\n    [JORNADA] [nvarchar](40),\n    [BLOQUE] [nvarchar](40),\n    [GRUPO] [nvarchar](40),\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [ID_SEDE] [int] NOT NULL,\n    [SEDE] [nvarchar](40),\n    [ESTADO] [nvarchar](40),\n    [FECHA_ESTADO] [datetime] NOT NULL,\n    [ID_CAPACIDAD_AUXILIAR] AS ( [ID_SALON] + '_' + [JORNADA] + '_' + CAST([ID_UNIDAD] AS NVARCHAR(10)) ) PERSISTED,\n    CONSTRAINT [PK_DIM_CAPACIDAD_FISICA] PRIMARY KEY CLUSTERED ([ID_CAPACIDAD]),\n    CONSTRAINT [FK_DIM_CAPACIDAD_FISICA_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_DIM_CAPACIDAD_FISICA_DIM_SEDES] FOREIGN KEY ([ID_SEDE]) REFERENCES [Transversal].[DIM_SEDES]([ID_SEDE])\n)\nGO\n\n\n-- Crear FACT_INICIATIVAS\n CREATE TABLE [Transversal].[FACT_INICIATIVAS] (\n    [ID_INICIATIVA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [FECHA_INICIO] [datetime] NOT NULL,\n    [FECHA_FIN] [datetime] NOT NULL,\n    [NOMBRE_INICIATIVA] [nvarchar](255),\n    [DESCRIPCION_INICIATIVA] [nvarchar](255),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_FACT_INICIATIVAS] PRIMARY KEY CLUSTERED ([ID_INICIATIVA]),\n    CONSTRAINT [FK_FACT_INICIATIVAS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_INICIATIVAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear FACT_PQRS\n CREATE TABLE [Transversal].[FACT_PQRS] (\n    [ID_PQR] [nvarchar](40) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [ASUNTO] [nvarchar](255),\n    [CREADO_POR] [nvarchar](255),\n    [ASIGNADO_A] [nvarchar](255),\n    [ESTADO] [nvarchar](40),\n    [TIPO_DOCUMENTO] [nvarchar](40),\n    [DOCUMENTO] [nvarchar](20),\n    [NOMBRE] [nvarchar](255),\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [FECHA_CREACION] [datetime] NOT NULL,\n    [FECHA_RESOLUCION] [datetime] NOT NULL,\n    [FECHA_VENCIMIENTO] [datetime] NOT NULL,\n    [EQUIPO] [nvarchar](40),\n    [UNIDAD] [nvarchar](255),\n    [PROGRAMA_INCIDENTE] [nvarchar](255),\n    [ID_CAUSA] [nvarchar](40),\n    [CAUSA] [nvarchar](40),\n    [TIPO_PQRS] [nvarchar](40),\n    [TIPO_RESOLUCION] [nvarchar](40),\n    [UBICACION] [nvarchar](255),\n    CONSTRAINT [PK_FACT_PQRS] PRIMARY KEY CLUSTERED ([ID_PQR]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE]),\n    CONSTRAINT [FK_FACT_PQRS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear FACT_CONVENIOS\n CREATE TABLE [Transversal].[FACT_CONVENIOS] (\n    [ID_CONVENIO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [ID_UNIDAD] [int],-- NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    [PROGRAMA] [nvarchar](40),\n    [NOMBRE_CONVENIO] [nvarchar](255),\n    [IDENTIFICACION_ACTO_CONVENIO] [nvarchar](255),\n    [ENTIDAD_CONVENIO] [nvarchar](255),\n    [COD_MUNICIPIO] [nvarchar](40),\n    [VALOR_CONVENIO] [decimal](28, 2) NOT NULL,\n    [APORTE_COMFENALCO] [nvarchar](40),\n    [ESTADO_CONVENIO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NOT NULL,\n    [FECHA_FIN] [datetime] NOT NULL,\n    CONSTRAINT [PK_FACT_CONVENIOS] PRIMARY KEY CLUSTERED ([ID_CONVENIO]),\n    --CONSTRAINT [FK_FACT_CONVENIOS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_CONVENIOS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\n\nGO\n-- Tablas para el cubo\nCREATE TABLE [Transversal].[FACT_MINERIA](\n    [BP] [nvarchar](20) NULL,\n    [ID_FECHA_MENSUAL] [int] NULL,\n    [ID_ANIO_ACADEMICO] [nvarchar](4) NULL,\n    [ID_UNIDAD] [int] NULL,\n    [FECHA_INICIAL] [datetime] NULL,\n    [FECHA_FINAL] [datetime] NULL,\n    [ACTIVIDAD] [nvarchar](100) NULL,\n    [TIEMPO_SEGUNDOS] [int] NULL,\n    [VALOR_PAGADO] [int] NULL,\n    [ID_CATEGORIA] [int] NULL,\n    [ID_CURSO] [int] NULL,\n    [ID_TIPO_ESTUDIANTE] [int] NULL,\n    [ID_PROGRAMA] [int] NULL DEFAULT -1,\n    [FUENTE_PRINCIPAL] NVARCHAR(250) NULL\n) ON [PRIMARY]\nGO\nCREATE TABLE [Transversal].[DIM_TIEMPO_MENSUAL](\n    [ID_FECHA] [int] NULL,\n    [FECHA] [datetime] NULL,\n    [DESC_FECHA] [nvarchar](50) NULL,\n    [ID_SEMANA] [int] NULL,\n    [DESC_SEMANA] [nvarchar](50) NULL,\n    [ID_NO_MES] [int] NULL,\n    [DESC_NO_MES] [nvarchar](50) NULL,\n    [ID_MES] [int] NULL,\n    [DESC_MES] [nvarchar](50) NULL,\n    [DESC_MES_CORTA] [nvarchar](50) NULL,\n    [ID_BIMESTRE] [int] NULL,\n    [DESC_BIMESTRE] [nvarchar](50) NULL,\n    [ID_TRIMESTRE] [int] NULL,\n    [DESC_TRIMESTRE] [nvarchar](50) NULL,\n    [ID_CUATRIMESTRE] [int] NULL,\n    [DESC_CUATRIMESTRE] [nvarchar](50) NULL,\n    [ID_SEMESTRE] [int] NULL,\n    [DESC_SEMESTRE] [nvarchar](50) NULL,\n    [ID_ANIO] [int] NULL,\n    [ID_ANIO_ANT] [int] NULL,\n    [NUM_DIA_SEMANA] [int] NULL,\n    [FESTIVO] [int] NULL,\n    [FECHA_CORTA] [date] NULL,\n    [FUENTE_PRINCIPAL] NVARCHAR(250) NULL\n) ON [PRIMARY]\nGO\nCREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_UNIDADES] (\n    ID_CURSO INT,\n    GRADO VARCHAR(255),\n    ID_UNIDAD INT,\n    CATEGORIA VARCHAR(255),\n    ID_PLAN_COBERTURA INT,\n    ID_ESTABLECIMIENTO_EDUCATIVO VARCHAR(255),\n    ID_PROGRAMA INT,\n    ID_FECHA_MENSUAL INT,\n    POBLACION_PROYECTADA INT,\n    ORIGEN VARCHAR(255),\n    ACTIVIDAD VARCHAR(255),\n    RESULTADO VARCHAR(255),\n    CATEGORIA_SABER11 VARCHAR(255),\n    CAUSA VARCHAR(255),\n    NUM_POBLACION INT,\n    CALIFICACION VARCHAR(255),\n    DOCUMENTOS_COMPLETOS VARCHAR(255),\n    NUM_ESTUDIANTES INT,\n    NUM_MAYOR_250 INT,\n    TEMATICA VARCHAR(255),\n    [FUENTE_PRINCIPAL] NVARCHAR(250) NULL\n)\nGO\n CREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_PERSONAL] (\n    ID_FECHA INT NULL,\n    ID_PERSONAL INT NULL,\n    NOMBRE NVARCHAR(255) ,\n    CONCEPTO NVARCHAR(50) NULL,\n    DESCRIPCION NVARCHAR(255) ,\n    FECHA_FIN DATETIME ,\n    HORAS_CONTRATADAS_MENSUAL INT ,\n    ID_UNIDAD INT,\n    [FUENTE_PRINCIPAL] NVARCHAR(250) NULL\n)\nGO\nCREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA] (\n    [ID_FECHA] [int] NULL,\n    [ID_ANIO] [int] NULL,\n    [ID_MES] [int] NULL,\n    [ID_CEBE] [bigint] NULL,\n    [CEBE] [nvarchar](10) NULL,\n    [DESCRIPCION_CEBE] [nvarchar](131) NULL,\n    [DEPARTAMENTO] [nvarchar](100) NULL,\n    [AREA] [nvarchar](100) NULL,\n    [SUBAREA] [nvarchar](100) NULL,\n    [SEGMENTO] [bigint] NULL,\n    [DESCRIPCION_SEGMENTO] [nvarchar](50) NULL,\n    [CODIGO_SSF] [int] NULL,\n    [NOMBRE_SSF] [nvarchar](100) NULL,\n    [ID_CUENTA] [bigint] NULL,\n    [CUENTA] [nvarchar](10) NULL,\n    [CUENTA_HOMOLOGA] [nvarchar](10) NULL,\n    [DESCRIPCION] [nvarchar](50) NULL,\n    [TIPO_CUENTA] [nvarchar](100) NULL,\n    [TIPO_OPERACION] [nvarchar](100) NULL,\n    [GRUPO_CUENTA] [nvarchar](100) NULL,\n    [SUBGRUPO_CUENTA] [nvarchar](50) NULL,\n    [GRUPO_OPERACION] [nvarchar](100) NULL,\n    [CUENTA_SSF] [int] NULL,\n    [DESCRIPCION_SSF] [nvarchar](255) NULL,\n    [CUENTA_DESCRIPCION] [nvarchar](61) NULL,\n    [CUENTA_DESCRIPCION_SSF] [nvarchar](286) NULL,\n    [SIGNO_INGRESOS] [int] NULL,\n    [CLASIFICACION] [int] NULL,\n    [SEGMENT] [bigint] NULL,\n    [IMPORTE] [numeric](18, 0) NULL,\n    [INGRESOS] [numeric](18, 0) NULL,\n    [INGRESOS_OPERACIONALES] [numeric](18, 0) NULL,\n    [GASTOS] [numeric](18, 0) NULL,\n    [GASTOS_OPERACIONALES] [numeric](18, 0) NULL,\n    [GASTOS_OPERACIONALES_ADMIN] [numeric](18, 0) NULL,\n    [RESULTADO_EJERCICIO] [numeric](18, 0) NULL,\n    [COSTOS] [numeric](18, 0) NULL,\n    [ACTIVO] [numeric](18, 0) NULL,\n    [PASIVO] [numeric](18, 0) NULL,\n    [PATRIMONIO] [numeric](18, 0) NULL,\n    [GASTOS_CON_DISTRIBUCION] [numeric](18, 0) NULL,\n    [GASTOS_SIN_DISTRIBUCION] [numeric](18, 0) NULL,\n    [TIPO] [nvarchar](7) NULL,\n    [ACTIVIDAD] [nvarchar](20) NULL,\n    [FUENTE_PRINCIPAL] [nvarchar](36) NULL,\n    [ID_UNIDAD] int NULL\n) ON [PRIMARY]\nGO\n CREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE] (\n PERIODO_ACADEMICO NVARCHAR(50)\n,ID_UNIDAD INT\n,ID_PERSONAL INT NULL\n,NOMBRE_DOCENTE NVARCHAR(255)\n,CALIFICACION_DEFINITIVA NVARCHAR(50)\n, ID_FECHA INT NULL\n,[FUENTE_PRINCIPAL] NVARCHAR(250) NULL\n)\nGO\nCREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES] (\n    [ACTIVIDAD] NVARCHAR(255),\n    [ADEUDA] DECIMAL(18, 2) NULL,\n    [ANIO_ACADEMICO] INT NULL,\n    [CANTIDAD_MATERIAL] INT NULL,\n    [CALIFICACION] NVARCHAR(255) NULL,\n    [CAUSA] NVARCHAR(255) NULL,\n    [CATEGORIA_VENTA] NVARCHAR(255) NULL,\n    [COSTO] DECIMAL(18, 2) NULL,\n    [CURSO] NVARCHAR(255) NULL,\n    [DESCRIPCION] NVARCHAR(255) NULL,\n    [ESTADO] NVARCHAR(255) NULL,\n    [ESTADOREGISTRO] NVARCHAR(50),\n    [ESTADO_PAGO] NVARCHAR(255) NULL,\n    [ESTRATO] INT NULL,\n    [DISCAPACIDAD] NVARCHAR (10) NULL,\n    [EDAD] INT NULL,\n    [FECHA_NACIMIENTO] DATETIME NULL,\n    [FECHA_AFILIACION] DATE NULL,\n    [FECHA_MENSUAL] DATE,\n    [FECHA_RETIRO] DATE NULL,\n    [FECHA_ADMISION] DATE NULL,\n    [ID_AFILIADO] INT NULL,\n    [ID_CATEGORIA] INT NULL,\n    [ID_CIUDAD] INT NULL,\n    [ID_CONCEPTO] INT NULL,\n    [ID_CURSO] INT NULL,\n    [ID_EMPRESA] INT NULL,\n    [ID_ESTADO_CIVIL] INT NULL,\n    [ID_ESTADO_GESTION] INT NULL,\n    [ID_FACTOR_VULNERABILIDAD] INT NULL,\n    [ID_FECHA] INT,\n    [ID_GENERO] INT NULL,\n    [ID_GRADO] INT NULL,\n    [ID_MATERIAL] INT NULL,\n    [ID_PERTENENCIA_ETNICA] INT NULL,\n    [ID_POBLACION] INT NULL,\n    [ID_PROGRAMA] INT NULL,\n    [ID_PREGUNTA] INT NULL,\n    [ID_TIPO_AFILIADO] INT NULL,\n    [ID_UNIDAD] INT NULL,\n    [NO_PRESTAMOS] INT NULL,\n    [NUMERO_APORTES] INT,\n    [PARTNER] NVARCHAR(50),\n    [PARTNER_AFILIADO] NVARCHAR(50) NULL,\n    [PARTNER_EMPRESA] NVARCHAR(50) NULL,\n    [RESPUESTA] NVARCHAR(255) NULL,\n    [SALARIO_BASICO] DECIMAL(18, 2) NULL,\n    [SERVICIO_TRANSPORTE] NVARCHAR(255) NULL,\n    [SUBSIDIO] DECIMAL(20, 2) NULL,\n    [TIPO_AFILIADO] NVARCHAR(255) NULL,\n    [TIPO_POBLACION] NVARCHAR(50),\n    [TOTAL_APORTES] DECIMAL(18, 2),\n    [VALOR_FACTURADO] DECIMAL(18, 2) NULL,\n    [VALOR_MATERIAL] DECIMAL(18, 2) NULL,\n    [VALOR_PAGADO] DECIMAL(18, 2) NULL,\n    [VALOR_PAGADO_SIN_IMP] DECIMAL(18, 2) NULL,\n    [POBLACION_EDUCACION] NVARCHAR(50) NULL,\n    [POBLACION_EDUCACION_FORMAL] NVARCHAR(50) NULL,\n    [POBLACION_EDUCACION_TECNICA] NVARCHAR(50) NULL,\n    [POBLACION_EDUCACION_CONTINUA] NVARCHAR(50) NULL,\n    [POBLACION_EDUCACION_PROTECCION] NVARCHAR(50) NULL,\n    [FUENTE_PRINCIPAL] NVARCHAR(250) NULL,\n    [ID_PQR] [nvarchar](40) NULL DEFAULT -1,\n    [ESTADO_PQR] [nvarchar](40),\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1,\n    [CAUSA_PQR] [nvarchar](40),\n    [TIPO_PQRS] [nvarchar](40),\n    [ID_TARIFA] [int] NULL DEFAULT -1,\n    [ID_MATRICULA] [int] NULL DEFAULT -1,\n    [ID_GRADUADO] [int] NULL DEFAULT -1,\n    [ID_DESERCION] [int] NULL DEFAULT -1\n)\nGO\n\n-- Tabla DIM_GENERO\nCREATE TABLE [Transversal].[DIM_GENERO] (\n    [ID_GENERO] INT PRIMARY KEY,\n    [GENERO] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_GENERO] ([ID_GENERO], [GENERO])\nSELECT DISTINCT\n    [ID_GENERO],\n    [GENERO]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_ORIENTACION_SEXUAL\nCREATE TABLE [Transversal].[DIM_ORIENTACION_SEXUAL] (\n    [ID_ORIENTACION_SEXUAL] INT PRIMARY KEY,\n    [ORIENTACION_SEXUAL] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_ORIENTACION_SEXUAL] ([ID_ORIENTACION_SEXUAL], [ORIENTACION_SEXUAL])\nSELECT DISTINCT\n    [ID_ORIENTACION_SEXUAL],\n    [ORIENTACION_SEXUAL]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_ESTADO_CIVIL\nCREATE TABLE [Transversal].[DIM_ESTADO_CIVIL] (\n    [ID_ESTADO_CIVIL] INT PRIMARY KEY,\n    [ESTADO_CIVIL] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_ESTADO_CIVIL] ([ID_ESTADO_CIVIL], [ESTADO_CIVIL])\nSELECT DISTINCT\n    [ID_ESTADO_CIVIL],\n    [ESTADO_CIVIL]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_FACTOR_DE_VULNERABILIDAD\nCREATE TABLE [Transversal].[DIM_FACTOR_DE_VULNERABILIDAD] (\n    [ID_FACTOR_VULNERABILIDAD] INT PRIMARY KEY,\n    [FACTOR_VULNERABILIDAD] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_FACTOR_DE_VULNERABILIDAD] ([ID_FACTOR_VULNERABILIDAD], [FACTOR_VULNERABILIDAD])\nSELECT DISTINCT\n    [ID_FACTOR_VULNERABILIDAD],\n    [FACTOR_VULNERABILIDAD]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_PERTENENCIA_ETNICA\nCREATE TABLE [Transversal].[DIM_PERTENENCIA_ETNICA] (\n    [ID_PERTENENCIA_ETNICA] INT PRIMARY KEY,\n    [PERTENENCIA_ETNICA] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_PERTENENCIA_ETNICA] ([ID_PERTENENCIA_ETNICA], [PERTENENCIA_ETNICA])\nSELECT DISTINCT\n    [ID_PERTENENCIA_ETNICA]\n      ,[PERTENENCIA_ETNICA]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n</code></pre>"},{"location":"01.scripts/02.Cedesarrollo%20copy/","title":"Documentaci\u00f3n SQL para el Esquema <code>Cedesarrollo</code>","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL implementa el esquema <code>Cedesarrollo</code> dentro del Data Warehouse <code>DWH_COMFENALCO</code>. El modelo sigue las mejores pr\u00e1cticas de modelado dimensional, con tablas de dimensiones (<code>DIM</code>) y hechos (<code>FACT</code>) que permiten un an\u00e1lisis integral de datos relacionados con estudiantes, personal, programas acad\u00e9micos, y evaluaciones.</p>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li>Limpieza del Esquema:</li> <li> <p>Eliminaci\u00f3n de tablas, restricciones de claves for\u00e1neas y el esquema existente para asegurar una implementaci\u00f3n limpia.</p> </li> <li> <p>Creaci\u00f3n de un Modelo Dimensional:</p> </li> <li>Tablas de Dimensiones (<code>DIM</code>): Almacenan datos descriptivos y categorizados de estudiantes, programas, periodos acad\u00e9micos, etc.</li> <li> <p>Tablas de Hechos (<code>FACT</code>): Contienen m\u00e9tricas y relaciones con dimensiones, enfoc\u00e1ndose en datos transaccionales y anal\u00edticos.</p> </li> <li> <p>Integridad Referencial:</p> </li> <li>Relaciones estrictas mediante claves for\u00e1neas entre las dimensiones y los hechos.</li> </ol>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#tablas-dimensionales","title":"Tablas Dimensionales","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#1-dim_estudiantes","title":"1. DIM_ESTUDIANTES","text":"<p>Informaci\u00f3n b\u00e1sica de los estudiantes, como su tipo de documento y relaciones con otras dimensiones.</p> Columna Tipo Descripci\u00f3n <code>ID_ESTUDIANTE</code> <code>int</code> Identificador \u00fanico del estudiante. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento del estudiante. <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero de documento del estudiante. <code>ID_EMPRESA</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_EMPRESAS</code>. <code>ID_AFILIADO</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_AFILIADOS</code>."},{"location":"01.scripts/02.Cedesarrollo%20copy/#2-dim_periodo_academico","title":"2. DIM_PERIODO_ACADEMICO","text":"<p>Define los periodos acad\u00e9micos asociados a programas y estudiantes.</p> Columna Tipo Descripci\u00f3n <code>ID_PERIODO</code> <code>int</code> Identificador \u00fanico del periodo acad\u00e9mico. <code>PERIODO_ACADEMICO</code> <code>nvarchar</code> Descripci\u00f3n del periodo acad\u00e9mico. <code>FECHA_INICIO</code> <code>datetime</code> Fecha de inicio del periodo acad\u00e9mico. <code>FECHA_FIN</code> <code>datetime</code> Fecha de finalizaci\u00f3n del periodo acad\u00e9mico."},{"location":"01.scripts/02.Cedesarrollo%20copy/#3-dim_programa","title":"3. DIM_PROGRAMA","text":"<p>Programas acad\u00e9micos asociados a estudiantes.</p> Columna Tipo Descripci\u00f3n <code>ID_PROGRAMA</code> <code>int</code> Identificador \u00fanico del programa. <code>PROGRAMA</code> <code>nvarchar</code> Nombre del programa."},{"location":"01.scripts/02.Cedesarrollo%20copy/#tablas-de-hechos","title":"Tablas de Hechos","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#1-fact_notas","title":"1. FACT_NOTAS","text":"<p>Registra las notas de estudiantes por periodos acad\u00e9micos y m\u00f3dulos.</p> Columna Tipo Descripci\u00f3n <code>ID_NOTA</code> <code>int</code> Identificador \u00fanico de la nota. <code>ID_ESTUDIANTE</code> <code>int</code> Relaci\u00f3n con <code>DIM_ESTUDIANTES</code>. <code>ID_PERIODO</code> <code>int</code> Relaci\u00f3n con <code>DIM_PERIODO_ACADEMICO</code>. <code>PRIMER_CORTE</code> <code>decimal</code> Nota del primer corte. <code>SEGUNDO_CORTE</code> <code>decimal</code> Nota del segundo corte. <code>TERCER_CORTE</code> <code>decimal</code> Nota del tercer corte. <code>NOTA_FINAL</code> <code>decimal</code> Nota final acumulada."},{"location":"01.scripts/02.Cedesarrollo%20copy/#2-fact_horario","title":"2. FACT_HORARIO","text":"<p>Registra los horarios acad\u00e9micos por estudiante y m\u00f3dulo.</p> Columna Tipo Descripci\u00f3n <code>ID_HORARIO</code> <code>int</code> Identificador \u00fanico del horario. <code>ID_MODULO</code> <code>int</code> Relaci\u00f3n con <code>DIM_PLAN_CURRICULAR</code>. <code>ID_JORNADA</code> <code>int</code> Relaci\u00f3n con <code>DIM_JORNADA</code>. <code>DIA</code> <code>nvarchar</code> D\u00eda de la clase. <code>HORA_INICIO</code> <code>nvarchar</code> Hora de inicio de la clase. <code>HORA_FIN</code> <code>nvarchar</code> Hora de fin de la clase."},{"location":"01.scripts/02.Cedesarrollo%20copy/#relaciones-dimensionales-y-tablas-de-hechos","title":"Relaciones Dimensionales y Tablas de Hechos","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#diagrama-general-del-modelo","title":"Diagrama General del Modelo","text":"<pre><code>erDiagram\n    DIM_ESTUDIANTES {\n        int ID_ESTUDIANTE PK\n        nvarchar TIPO_DOCUMENTO\n        nvarchar DOCUMENTO\n    }\n\n    DIM_PROGRAMA {\n        int ID_PROGRAMA PK\n        nvarchar PROGRAMA\n    }\n\n    DIM_PERIODO_ACADEMICO {\n        int ID_PERIODO PK\n        nvarchar PERIODO_ACADEMICO\n        datetime FECHA_INICIO\n        datetime FECHA_FIN\n    }\n\n    DIM_JORNADA {\n        int ID_JORNADA PK\n        nvarchar JORNADA\n    }\n\n    DIM_PLAN_CURRICULAR {\n        int ID_MODULO PK\n        nvarchar MODULO\n    }\n\n    FACT_NOTAS {\n        int ID_NOTA PK\n        int ID_ESTUDIANTE FK\n        int ID_PERIODO FK\n        int ID_MODULO FK\n        decimal PRIMER_CORTE\n        decimal NOTA_FINAL\n    }\n\n    FACT_HORARIO {\n        int ID_HORARIO PK\n        int ID_PERIODO FK\n        int ID_MODULO FK\n        int ID_JORNADA FK\n    }\n\n    DIM_ESTUDIANTES ||--o{ FACT_NOTAS : \"ID_ESTUDIANTE\"\n    DIM_PERIODO_ACADEMICO ||--o{ FACT_NOTAS : \"ID_PERIODO\"\n    DIM_PLAN_CURRICULAR ||--o{ FACT_NOTAS : \"ID_MODULO\"\n    DIM_PLAN_CURRICULAR ||--o{ FACT_HORARIO : \"ID_MODULO\"\n    DIM_PERIODO_ACADEMICO ||--o{ FACT_HORARIO : \"ID_PERIODO\"\n    DIM_JORNADA ||--o{ FACT_HORARIO : \"ID_JORNADA\"</code></pre>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li>Integridad Referencial:</li> <li> <p>Uso de claves for\u00e1neas para mantener la consistencia entre dimensiones y hechos.</p> </li> <li> <p>Eficiencia del Modelo:</p> </li> <li>Modelado dimensional para facilitar consultas anal\u00edticas.</li> <li> <p>Separaci\u00f3n entre datos descriptivos (<code>DIM</code>) y m\u00e9tricas (<code>FACT</code>).</p> </li> <li> <p>Flexibilidad y Escalabilidad:</p> </li> <li> <p>Las tablas permiten agregar nuevas dimensiones y hechos sin afectar el esquema general.</p> </li> <li> <p>Normalizaci\u00f3n:</p> </li> <li>Uso de dimensiones comunes para evitar redundancia.</li> </ol>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#conclusion","title":"Conclusi\u00f3n","text":"<p>El esquema <code>Cedesarrollo</code> ofrece un modelo integral y escalable para gestionar datos acad\u00e9micos y administrativos en un entorno anal\u00edtico. La estructura permite un an\u00e1lisis detallado de estudiantes, programas y resultados acad\u00e9micos, con un dise\u00f1o flexible para futuros requerimientos.</p>"},{"location":"01.scripts/02.Cedesarrollo/","title":"02. Cedesarrollo","text":""},{"location":"01.scripts/02.Cedesarrollo/#documentacion-del-esquema-cedesarrollo","title":"Documentaci\u00f3n del Esquema <code>Cedesarrollo</code>","text":""},{"location":"01.scripts/02.Cedesarrollo/#1-proposito-del-esquema","title":"1. Prop\u00f3sito del Esquema","text":"<p>El esquema <code>Cedesarrollo</code> est\u00e1 dise\u00f1ado para gestionar datos acad\u00e9micos y operativos de una instituci\u00f3n educativa dentro de un Data Warehouse. Su estructura dimensional facilita el an\u00e1lisis de:</p> <ul> <li>Rendimiento acad\u00e9mico (notas, asistencia, deserci\u00f3n).</li> <li>Gesti\u00f3n docente (ausentismo, evaluaci\u00f3n de desempe\u00f1o).</li> <li>Procesos administrativos (matr\u00edculas, facturaci\u00f3n, horarios).</li> <li>Planificaci\u00f3n curricular (programas, m\u00f3dulos, jornadas).</li> </ul>"},{"location":"01.scripts/02.Cedesarrollo/#2-estructura-del-esquema","title":"2. Estructura del Esquema","text":""},{"location":"01.scripts/02.Cedesarrollo/#21-tablas-de-dimensiones-dim_","title":"2.1. Tablas de Dimensiones (<code>DIM_*</code>)","text":"Tabla Descripci\u00f3n Columnas Clave Relaciones DIM_ESTUDIANTES Registra estudiantes y sus v\u00ednculos con entidades externas. <code>ID_ESTUDIANTE</code> (PK) <code>DIM_EMPRESAS</code>, <code>DIM_AFILIADOS</code>, <code>DIM_BENEFICIARIOS</code>, <code>DIM_APORTANTE_NOAFILIADO</code> DIM_PERIODO_ACADEMICO Define per\u00edodos acad\u00e9micos (ej. semestres). <code>ID_PERIODO</code> (PK) <code>DIM_UNIDAD</code> DIM_PROGRAMA Cataloga programas acad\u00e9micos ofrecidos. <code>ID_PROGRAMA</code> (PK) - DIM_JORNADA Jornadas disponibles (diurna, nocturna). <code>ID_JORNADA</code> (PK) - DIM_PLAN_CURRICULAR Detalla m\u00f3dulos/cursos de cada programa. <code>ID_MODULO</code> (PK) <code>DIM_PROGRAMA</code> DIM_PREGUNTAS_COTIZACION Preguntas relacionadas con cotizaciones. <code>ID_PREGUNTA</code> (PK) -"},{"location":"01.scripts/02.Cedesarrollo/#22-tablas-de-hechos-fact_","title":"2.2. Tablas de Hechos (<code>FACT_*</code>)","text":"Tabla Descripci\u00f3n M\u00e9tricas Principales Relaciones FACT_NOTAS Calificaciones por m\u00f3dulo y per\u00edodo. <code>PRIMER_CORTE</code>, <code>NOTA_FINAL</code> <code>DIM_ESTUDIANTES</code>, <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_JORNADA</code> FACT_HORARIO Horarios de clases. <code>HORA_INICIO</code>, <code>HORA_FIN</code> <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_JORNADA</code>, <code>DIM_PERSONAL</code> FACT_AUSENTISMO_DOCENTE Ausencias del personal docente. <code>AUSENCIA_HORAS</code>, <code>TIPO_AUSENCIA</code> <code>DIM_PERSONAL</code>, <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_TIEMPO</code> FACT_DESERCION Deserci\u00f3n estudiantil. <code>TIPO</code>, <code>CAUSA</code> <code>DIM_ESTUDIANTES</code>, <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_JORNADA</code>, <code>DIM_TIEMPO</code> FACT_FACTURACION Transacciones financieras (matr\u00edculas, pagos). <code>VALOR_FACTURADO</code>, <code>ADEUDA</code> <code>DIM_TIEMPO</code>, <code>DIM_TARIFAS_SERVICIOS</code> FACT_DESEMPENHO_DOCENTE_DE Evaluaci\u00f3n docente por estudiantes. <code>CALIFICACION</code> <code>DIM_PERSONAL</code>, <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_TIEMPO</code> FACT_GRADUADOS Informaci\u00f3n de estudiantes graduados. <code>FECHA_GRADUADO</code>, <code>ACTA_GRADUADO</code> <code>DIM_ESTUDIANTES</code>, <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PROGRAMA</code>, <code>DIM_JORNADA</code> FACT_COTIZACIONES Registro de cotizaciones realizadas. <code>ESTADO_COTIZACION</code>, <code>RESPUESTA</code> <code>DIM_ESTUDIANTES</code>, <code>DIM_PREGUNTAS_COTIZACION</code>, <code>DIM_TIEMPO</code>, <code>DIM_TARIFAS_SERVICIOS</code> FACT_PLAN_COBERTURA Planificaci\u00f3n de cobertura acad\u00e9mica. <code>USOS_PROYECTADOS</code> <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PROGRAMA</code> FACT_EVALUACION_FORMACION Evaluaci\u00f3n de eventos de formaci\u00f3n. <code>ASPECTO_1</code>, <code>ASPECTO_9</code> -"},{"location":"01.scripts/02.Cedesarrollo/#3-diagrama-de-relaciones-clave","title":"3. Diagrama de Relaciones Clave","text":"<pre><code>erDiagram\n    DIM_ESTUDIANTES ||--o{ FACT_NOTAS : \"ID_ESTUDIANTE\"\n    DIM_PERIODO_ACADEMICO ||--o{ FACT_NOTAS : \"ID_PERIODO\"\n    DIM_PLAN_CURRICULAR ||--o{ FACT_NOTAS : \"ID_MODULO\"\n    DIM_JORNADA ||--o{ FACT_HORARIO : \"ID_JORNADA\"\n    DIM_PROGRAMA ||--o{ DIM_PLAN_CURRICULAR : \"ID_PROGRAMA\"\n    DIM_PERSONAL ||--o{ FACT_AUSENTISMO_DOCENTE : \"ID_PERSONAL\"\n    DIM_TIEMPO ||--o{ FACT_DESERCION : \"ID_FECHA\"\n    DIM_PREGUNTAS_COTIZACION ||--o{ FACT_COTIZACIONES : \"ID_PREGUNTA\"</code></pre>"},{"location":"01.scripts/02.Cedesarrollo/#4-buenas-practicas-implementadas","title":"4. Buenas Pr\u00e1cticas Implementadas","text":"<ul> <li>Valores por Defecto: <ul> <li><code>-1</code> para claves for\u00e1neas no definidas (ej. <code>ID_EMPRESA</code> en <code>DIM_ESTUDIANTES</code>).</li> <li>Registro <code>ID_ESTUDIANTE = -1</code> para casos de datos faltantes.</li> </ul> </li> <li>Integridad Referencial: <ul> <li>Claves for\u00e1neas en todas las tablas de hechos.</li> <li>Eliminaci\u00f3n segura del esquema previo (<code>DROP</code> de constraints antes de tablas).</li> </ul> </li> <li>Normalizaci\u00f3n: <ul> <li>Separaci\u00f3n clara entre dimensiones (entidades est\u00e1ticas) y hechos (eventos din\u00e1micos).</li> </ul> </li> <li>Inserci\u00f3n Controlada:<ul> <li>Uso de <code>SET IDENTITY_INSERT</code> para insertar valores espec\u00edficos en columnas con identidad.</li> </ul> </li> </ul>"},{"location":"01.scripts/02.Cedesarrollo/#5-script","title":"5. Script","text":"<pre><code>USE DWH_COMFENALCO\nGO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- Eliminar restricciones de clave for\ufffdnea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Cedesarrollo';\nEXEC sp_executesql @sql;\n-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Cedesarrollo';\nEXEC sp_executesql @sql;\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Cedesarrollo')\nBEGIN\n    DROP SCHEMA Cedesarrollo;\nEND\nGO\n-- Crear el esquema Cedesarrollo\nCREATE SCHEMA Cedesarrollo;\nGO \n-- Crear Cedesarrollo.DIM_ESTUDIANTES\nCREATE TABLE [Cedesarrollo].[DIM_ESTUDIANTES] (\n    [ID_ESTUDIANTE] [int] IDENTITY(1,1) NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    CONSTRAINT [PK_DIM_ESTUDIANTES] PRIMARY KEY CLUSTERED ([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE])\n)\nGO\n-- Crear Cedesarrollo.DIM_PERIODO_ACADEMICO\nCREATE TABLE [Cedesarrollo].[DIM_PERIODO_ACADEMICO] (\n    [ID_PERIODO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [PERIODO_ACADEMICO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NULL, -- QUITE NOT\n    [FECHA_FIN] [datetime] NULL, -- QUITE NOT\n    CONSTRAINT [PK_DIM_PERIODO_ACADEMICO] PRIMARY KEY CLUSTERED ([ID_PERIODO]),\n    CONSTRAINT [FK_DIM_PERIODO_ACADEMICO_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO\n-- Crear Cedesarrollo.DIM_PROGRAMA\nCREATE TABLE [Cedesarrollo].[DIM_PROGRAMA] (\n    [ID_PROGRAMA] [int] IDENTITY(1,1) NOT NULL,\n    [PROGRAMA] [nvarchar](255)\n    CONSTRAINT [PK_DIM_PROGRAMA] PRIMARY KEY CLUSTERED ([ID_PROGRAMA])\n)\nGO\n\n-- Crear Cedesarrollo.DIM_JORNADA\nCREATE TABLE [Cedesarrollo].[DIM_JORNADA] (\n    [ID_JORNADA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [JORNADA] [nvarchar](40),\n    CONSTRAINT [PK_DIM_JORNADA] PRIMARY KEY CLUSTERED ([ID_JORNADA])\n)\nGO\n\n-- Crear Cedesarrollo.DIM_PLAN_CURRICULAR\nCREATE TABLE [Cedesarrollo].[DIM_PLAN_CURRICULAR] (\n    [ID_MODULO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PROGRAMA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [MODULO] [nvarchar](200), \n    --[ID_PERIODO] [int] NOT NULL,\n    [INTENSIDAD_HORARIA] [nvarchar](40),\n    [INTENSIDAD_HORARIA_SEMANAL] [nvarchar](40),\n    [NO_CREDITOS] [nvarchar](40),\n    [SEMESTRE] [nvarchar](40),\n    CONSTRAINT [PK_DIM_PLAN_CURRICULAR] PRIMARY KEY CLUSTERED ([ID_MODULO]),\n    CONSTRAINT [FK_DIM_PLAN_CURRICULAR_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_NOTAS\nCREATE TABLE [Cedesarrollo].[FACT_NOTAS] (\n    [ID_NOTA] [int] IDENTITY(1,1) NOT NULL,\n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NOT NULL,\n    [ID_MODULO] [int] NULL,  -- QUITE NULL\n    [CURSO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NULL, -- QUITE NULL\n    [ID_PERIODO] [int] NOT NULL,\n    --[PROGRAMA_ACADEMICO] [nvarchar](60),\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [FECHA_FIN] [datetime] NULL, -- QUITE NULL\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [NOMBRE_ESTUDIANTE] [nvarchar](200),\n    [PRIMER_CORTE] [decimal](10, 2),\n    [PRIMER_CORTE_CP1] [decimal](10, 2),\n    [PRIMER_CORTE_CP2] [decimal](10, 2),\n    [PRIMER_CORTE_CT1] [decimal](10, 2),\n    [PRIMER_CORTE_CT2] [decimal](10, 2),\n    [SEGUNDO_CORTE] [decimal](10, 2),\n    [SEGUNDO_CORTE_CP1] [decimal](10, 2),\n    [SEGUNDO_CORTE_CP2] [decimal](10, 2),\n    [SEGUNDO_CORTE_CT1] [decimal](10, 2),\n    [SEGUNDO_CORTE_CT2] [decimal](10, 2),\n    [TERCER_CORTE] [decimal](10, 2),\n    [TERCER_CORTE_CP1] [decimal](10, 2),\n    [TERCER_CORTE_CP2] [decimal](10, 2),\n    [TERCER_CORTE_CT1] [decimal](10, 2),\n    [TERCER_CORTE_CT2] [decimal](10, 2),\n    [NOTA_FINAL] [decimal](10, 2),\n    [PESO_CORTE] [decimal](10, 2),\n    CONSTRAINT [PK_FACT_NOTAS] PRIMARY KEY CLUSTERED ([ID_NOTA]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_PLAN_CURRICULAR] FOREIGN KEY ([ID_MODULO]) REFERENCES [Cedesarrollo].[DIM_PLAN_CURRICULAR]([ID_MODULO]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA])\n\n)\nGO\n\n-- Crear Cedesarrollo.FACT_HORARIO\nCREATE TABLE [Cedesarrollo].[FACT_HORARIO] (\n    [ID_HORARIO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [ID_MODULO] [int] NULL,\n    --[MODULO] [nvarchar](40),\n    [ID_JORNADA] [int] NULL,\n    --[JORNADA] [nvarchar](40),\n    [SEMESTRE] [nvarchar](40),\n    [GRUPO] [nvarchar](40),\n    [DIA] [nvarchar](40),\n    [SALON] [nvarchar](40),\n    [HORA_INICIO] [nvarchar](40),\n    [HORA_FIN] [nvarchar](40),\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [COD_ESTABLECIMIENTO] [nvarchar](40),\n    CONSTRAINT [PK_FACT_HORARIO] PRIMARY KEY CLUSTERED ([ID_HORARIO]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_PLAN_CURRICULAR] FOREIGN KEY ([ID_MODULO]) REFERENCES [Cedesarrollo].[DIM_PLAN_CURRICULAR]([ID_MODULO]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA])\n)\nGO\n\n\n\n-- Crear Cedesarrollo.FACT_AUSENTISMO_DOCENTE\nCREATE TABLE [Cedesarrollo].[FACT_AUSENTISMO_DOCENTE] (\n    [ID_AUSENTISMO_DOCENTE] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [FECHA] [datetime] NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [CARGO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NOT NULL,\n    [FECHA_FIN] [datetime] NOT NULL,\n    [AUSENCIA_HORAS] [nvarchar](40),\n    [AUSENCIA_DIAS] [nvarchar](40),\n    [TIPO_AUSENCIA] [nvarchar](40),\n    [PERMISO] [nvarchar](40),\n    [MOTIVO_AUSENCIA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_AUSENTISMO_DOCENTE] PRIMARY KEY CLUSTERED ([ID_AUSENTISMO_DOCENTE]),\n    CONSTRAINT [FK_FACT_AUSENTISMO_DOCENTE_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_AUSENTISMO_DOCENTE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_AUSENTISMO_DOCENTE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_PERMISO_ESTUDIANTE\nCREATE TABLE [Cedesarrollo].[FACT_PERMISO_ESTUDIANTE] (\n    [ID_PERMISO_ESTUDIANTE] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [MODULO] [nvarchar](40),\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [HORA] [nvarchar](40),\n    [MOTIVO_AUSENCIA] [nvarchar](40),\n    [SOPORTE_AUSENCIA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_PERMISO_ESTUDIANTE] PRIMARY KEY CLUSTERED ([ID_PERMISO_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_PERMISO_ESTUDIANTE_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_PERMISO_ESTUDIANTE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_PERMISO_ESTUDIANTE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_INASISTENCIAS\nCREATE TABLE [Cedesarrollo].[FACT_INASISTENCIAS] (\n    [ID_INASISTENCIAS] [int] IDENTITY(1,1) NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NOT NULL,\n    --[JORNADA] [nvarchar](40),\n    [ID_MODULO] [int] NULL, -- QUITE NOT\n    --[MODULO] [nvarchar](40),\n    [CURSO] [nvarchar](40) NULL,\n    [CORTE] [nvarchar](40) NULL,\n    [ID_FECHA] [int] NULL, -- QUITE NOT\n    [FECHA] [datetime] NULL, -- QUITE NOT\n    [HORA] [nvarchar](40) NULL,\n    [TOTAL_INASISTENCIA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_INASISTENCIAS] PRIMARY KEY CLUSTERED ([ID_INASISTENCIAS]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_PLAN_CURRICULAR] FOREIGN KEY ([ID_MODULO]) REFERENCES [Cedesarrollo].[DIM_PLAN_CURRICULAR]([ID_MODULO]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_DESERCION\nCREATE TABLE [Cedesarrollo].[FACT_DESERCION] (\n    [ID_DESERCION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL, /* NOT lo quite temporalmente ya que se llena posteriormente en la ETL*/\n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NULL, /* NOT lo quite temporalmente ya que se llena posteriormente en la ETL*/\n    --[JORNADA] [nvarchar](40),\n    --[PROGRAMA] [nvarchar](40),\n    [ID_PROGRAMA] [int] NULL DEFAULT -1,\n    [NOMBRE_ESTUDIANTE] [nvarchar](255),\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [GRUPO] [nvarchar](40),\n    --[MODULO] [nvarchar](40),\n    [SEMESTRE] [nvarchar](40),\n    [ID_FECHA] [int] NULL, /* NOT lo quite temporalmente*/\n    [FECHA] [datetime] NOT NULL,\n    [TIPO] [nvarchar](40),\n    [CAUSA] [nvarchar](40),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_FACT_DESERCION] PRIMARY KEY CLUSTERED ([ID_DESERCION]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_DESERCION_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_ESTADO_MATRICULAS\nCREATE TABLE [Cedesarrollo].[FACT_ESTADO_MATRICULAS] (\n    [ID_MATRICULA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL,\n    [ID_PROGRAMA] [int] NULL, -- QUITE NOT  \n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NULL, -- QUITE NOT  \n    --[JORNADA] [nvarchar](40),\n    [NOMBRE_ESTUDIANTE] [nvarchar](200),\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [ID_FECHA] [int] NULL, -- QUITE NOT  \n    [FECHA_MATRICULA] [datetime] NOT NULL,\n    [TELEFONO] [nvarchar](40),\n    [CELULAR] [nvarchar](40),\n    [CORREO] [nvarchar](200),\n    [FECHA_OPORTUNA] [datetime] NULL, -- QUITE NOT  \n    [FECHA_ACTUALIZACION] [datetime] NULL, -- QUITE NOT  \n    [DOCUMENTOS_COMPLETOS] [nvarchar](20) NULL, -- QUITE NOT  \n    [SEMESTRE] [nvarchar](40),\n    CONSTRAINT [PK_FACT_ESTADO_MATRICULAS] PRIMARY KEY CLUSTERED ([ID_MATRICULA]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_INSCRIPCION_MATRICULAS\nCREATE TABLE [Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] (\n    [ID_INSCRIPCION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL, -- QUITE NOT  \n    [ID_PROGRAMA] [int] NOT NULL,\n    --[TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    --[DOCUMENTO_ESTUDIANTE] [nvarchar](20) NOT NULL,\n    --[JORNADA] [nvarchar](40),\n    --[PROGRAMA] [nvarchar](40),\n    [ID_FECHA] [int] NULL, -- QUITE NOT  \n    [FECHA] [datetime] NOT NULL,\n    [ID_JORNADA] [int] NOT NULL,\n    [ESTADO] [nvarchar](40),\n    [TIPO_ESTUDIANTE] [nvarchar](40),\n    [CATEGORIA_COBERTURA] [nvarchar](40),\n    [CATEGORIA_SUBSIDIO] [nvarchar](40),\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    CONSTRAINT [PK_FACT_INSCRIPCION_MATRICULAS] PRIMARY KEY CLUSTERED ([ID_INSCRIPCION]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_FACTURACION\nCREATE TABLE [Cedesarrollo].[FACT_FACTURACION] (\n    [ID_FACTURACION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int]  NULL, -- NO HAY UN CAMPO ELEGIBLE\n    [TIPO_DOCUMENTO_PAGO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO_PAGO] [nvarchar](20) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA_CONTABLE] [datetime] NOT NULL,\n    [ID_TARIFA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_CONCEPTO] [int] NOT NULL,\n    [CONCEPTO] [nvarchar](255),\n    [VALOR_FACTURADO] [decimal](28, 2),\n    [SUBSIDIO] [decimal](28, 2),\n    [VALOR_PAGADO] [decimal](28, 2),\n    [ADEUDA] [nvarchar](40),\n    [ESTADO_PAGO] [nvarchar](40),\n    [FECHA_OPORTUNA_PAGO] [datetime] NULL,\n    [NO_RECIBO] [nvarchar](40),\n    [CATEGORIA] [nvarchar](40),\n    [FUENTE_RECURSOS] [nvarchar](40) NULL DEFAULT 'PROPIOS'\n    CONSTRAINT [PK_FACT_FACTURACION] PRIMARY KEY CLUSTERED ([ID_FACTURACION]),\n    --CONSTRAINT [FK_FACT_FACTURACION_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_FACTURACION_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear Cedesarrollo.DIM_PREGUNTAS_COTIZACION\nCREATE TABLE [Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] (\n    [ID_PREGUNTA] [int] IDENTITY(1,1) NOT NULL,\n    [PREGUNTA] [nvarchar](255),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_DIM_PREGUNTAS_COTIZACION] PRIMARY KEY CLUSTERED ([ID_PREGUNTA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_COTIZACIONES\nCREATE TABLE [Cedesarrollo].[FACT_COTIZACIONES] (\n    [ID_COTIZACION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA_REGISTRO] [datetime] NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [NOMBRE] [nvarchar](200),\n    [ID_TARIFA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ESTADO_COTIZACION] [nvarchar](40),\n    [ID_PREGUNTA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [RESPUESTA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_COTIZACIONES] PRIMARY KEY CLUSTERED ([ID_COTIZACION]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_DIM_PREGUNTAS_COTIZACION] FOREIGN KEY ([ID_PREGUNTA]) REFERENCES [Cedesarrollo].[DIM_PREGUNTAS_COTIZACION]([ID_PREGUNTA]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_DIM_TARIFAS_SERVICIOS] FOREIGN KEY ([ID_TARIFA]) REFERENCES [Transversal].[DIM_TARIFAS_SERVICIOS]([ID_TARIFA]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n\n-- Crear Cedesarrollo.FACT_PLAN_COBERTURA\nCREATE TABLE [Cedesarrollo].[FACT_PLAN_COBERTURA] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    [MODALIDAD] [nvarchar](40),\n    [CATEGORIA] [nvarchar](40),\n    [ID_PROGRAMA] [int] NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [USOS_PROYECTADOS] [nvarchar](40),\n    [USUARIOS_PROYECTADOS] [nvarchar](40),\n    CONSTRAINT [PK_FACT_PLAN_COBERTURA] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_PLAN_COBERTURA_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    --CONSTRAINT [FK_FACT_PLAN_COBERTURA_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE\nCREATE TABLE [Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_DE] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 3, -- Asignar valor por defecto de 3\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_PERIODO] [int] NOT NULL,\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [TIPO_DOCUMENTO_ENCUESTADO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO_ENCUESTADO] [nvarchar](20) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [PROGRAMA] [nvarchar](40),\n    [CALIFICACION] [nvarchar](40),\n    CONSTRAINT [PK_FACT_DESEMPENHO_DOCENTE_DE] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_DE_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_DE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_DE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE\nCREATE TABLE [Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_CE] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 2, -- Asignar valor por defecto de 2\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_PERIODO] [int] NOT NULL,\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [TIPO_CONTRATACION] [nvarchar](40),\n    [CALIFICACION_ESTUDIANTES] [nvarchar](40),\n    [CALIFICACION_UNIDAD] [nvarchar](40),\n    [CALIFICACION_DOCENTE] [nvarchar](40),\n    [CALIFICACION_DEFINITIVA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_DESEMPENHO_DOCENTE_CE] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_CE_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_CE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_GRADUADOS\nCREATE TABLE [Cedesarrollo].[FACT_GRADUADOS] (\n    [ID_GRADUADO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_JORNADA] [int] NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    [GRUPO] [nvarchar](40),\n    [ESTADO] [nvarchar](40),\n    [ZONA] [nvarchar](40),\n    [NIVEL_FORMACION] [nvarchar](40),\n    [OCUPACION] [nvarchar](40),\n    [SEDE] [nvarchar](255),\n    [JORNADA] [nvarchar](40),\n    [PROGRAMA] [nvarchar](255),\n    [SEMESTRE] [nvarchar](40),\n    [FECHA_ACTUALIZACION] [datetime] NOT NULL,\n    [FECHA_GRADUADO] [datetime] NOT NULL,\n    [ACTA_GRADUADO] [nvarchar](40),\n    [FOLIO_GRADUADO] [nvarchar](40),\n    [DIPLOMA_GRADUADO] [nvarchar](40),\n    CONSTRAINT [PK_FACT_GRADUADOS] PRIMARY KEY CLUSTERED ([ID_GRADUADO]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR\nCREATE TABLE [Cedesarrollo].[FACT_ASISTENCIA_ACT_BIENESTAR] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [ACTIVIDAD] [nvarchar](40),\n    [ASISTIO] [nvarchar](40),\n    CONSTRAINT [PK_FACT_ASISTENCIA_ACT_BIENESTAR] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_ASISTENCIA_ACT_BIENESTAR_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_ASISTENCIA_ACT_BIENESTAR_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_ASISTENCIA_ACT_BIENESTAR_DE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR\nCREATE TABLE [Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    [ID_PERIODO] [int] NOT NULL,\n    [CALIFICACION] [nvarchar](40),\n    [OBSERVACIONES] [nvarchar](40),\n    CONSTRAINT [PK_FACT_EVALUACION_PLAN_CURRICULAR] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_EVALUACION_PLAN_CURRICULAR_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_EVALUACION_FORMACION\nCREATE TABLE [Cedesarrollo].[FACT_EVALUACION_FORMACION] (\n    [ID_EVALUACION_FORMACION] [int] IDENTITY(1,1) NOT NULL,\n    [TIPO_DOCUMENTO_ENCUESTADO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO_ENCUESTADO] [nvarchar](20) NOT NULL,\n    [FECHA_REALIZACION_EVENTO] [datetime] NOT NULL,\n    [ASPECTO_1] [nvarchar](40),\n    [ASPECTO_2] [nvarchar](40),\n    [ASPECTO_3] [nvarchar](40),\n    [ASPECTO_4] [nvarchar](40),\n    [ASPECTO_5] [nvarchar](40),\n    [ASPECTO_6] [nvarchar](40),\n    [ASPECTO_7] [nvarchar](40),\n    [ASPECTO_8] [nvarchar](40),\n    [ASPECTO_9] [nvarchar](40),\n    CONSTRAINT [PK_FACT_EVALUACION_FORMACION] PRIMARY KEY CLUSTERED ([ID_EVALUACION_FORMACION]),\n)\nGO\n\n-- Disable identity insert to manually insert -1 in the identity column\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_ESTUDIANTES] ON;\n\nINSERT INTO [Cedesarrollo].[DIM_ESTUDIANTES] ([ID_ESTUDIANTE], [TIPO_DOCUMENTO], [DOCUMENTO], [ID_EMPRESA], [ID_AFILIADO], [ID_BENEFICIARIO], [ID_APORTANTE])\nVALUES (-1, 'N/A', 'N/A', -1, -1, -1, -1);\n\n-- Enable identity insert back\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_ESTUDIANTES] OFF;\n</code></pre>"},{"location":"01.scripts/03.Proteccion/","title":"03. Proteccion","text":""},{"location":"01.scripts/03.Proteccion/#documentacion-sql-para-el-esquema-proteccion","title":"Documentaci\u00f3n SQL para el Esquema <code>Protecci\u00f3n</code>","text":""},{"location":"01.scripts/03.Proteccion/#introduccion","title":"Introducci\u00f3n","text":"<p>El script SQL establece el esquema <code>Protecci\u00f3n</code> en el Data Warehouse <code>DWH_COMFENALCO</code>. Este esquema est\u00e1 dise\u00f1ado para gestionar informaci\u00f3n relacionada con poblaci\u00f3n, establecimientos educativos, programas, caracterizaci\u00f3n y actividades relacionadas con protecci\u00f3n y visitas.</p>"},{"location":"01.scripts/03.Proteccion/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li> <p>Limpieza del Esquema Existente:</p> <ul> <li>Elimina restricciones de claves for\u00e1neas, tablas y el esquema si ya existe, para permitir una implementaci\u00f3n limpia.</li> </ul> </li> <li> <p>Creaci\u00f3n de Estructuras Dimensionales:</p> <ul> <li>Tablas Dimensionales (<code>DIM</code>): Almacenan datos est\u00e1ticos o descriptivos relacionados con poblaci\u00f3n, programas, y caracter\u00edsticas.</li> <li>Tablas de Hechos (<code>FACT</code>): Contienen registros transaccionales y m\u00e9tricas relacionadas con actividades de protecci\u00f3n.</li> </ul> </li> <li> <p>Gesti\u00f3n de Integridad:</p> <ul> <li>Claves for\u00e1neas y primarias para garantizar relaciones consistentes entre dimensiones y hechos.</li> </ul> </li> </ol>"},{"location":"01.scripts/03.Proteccion/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/03.Proteccion/#tablas-dimensionales","title":"Tablas Dimensionales","text":""},{"location":"01.scripts/03.Proteccion/#1-dim_poblacion","title":"1. DIM_POBLACION","text":"<p>Contiene informaci\u00f3n b\u00e1sica de la poblaci\u00f3n objeto de an\u00e1lisis.</p> Columna Tipo Descripci\u00f3n <code>ID_POBLACION</code> <code>int</code> Identificador \u00fanico de la poblaci\u00f3n. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento de identidad. <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero de documento de identidad. <code>ID_EMPRESA</code> <code>int</code> Relaci\u00f3n con empresas en otros esquemas. <code>ID_AFILIADO</code> <code>int</code> Relaci\u00f3n con afiliados en otros esquemas. <code>ID_BENEFICIARIO</code> <code>int</code> Relaci\u00f3n con beneficiarios en otros esquemas. <code>ID_APORTANTE</code> <code>int</code> Relaci\u00f3n con aportantes en otros esquemas."},{"location":"01.scripts/03.Proteccion/#2-dim_establecimiento_educativo","title":"2. DIM_ESTABLECIMIENTO_EDUCATIVO","text":"<p>Informaci\u00f3n sobre los establecimientos educativos vinculados al sistema.</p> Columna Tipo Descripci\u00f3n <code>ID_ESTABLECIMIENTO_EDUCATIVO</code> <code>int</code> Identificador \u00fanico del establecimiento. <code>NOMBRE_ESTABLECIMIENTO</code> <code>nvarchar</code> Nombre del establecimiento. <code>REPRESENTANTE_LEGAL</code> <code>nvarchar</code> Representante legal del establecimiento. <code>DIRECCION</code> <code>nvarchar</code> Direcci\u00f3n del establecimiento. <code>MUNICIPIO</code> <code>nvarchar</code> Municipio donde se encuentra el establecimiento."},{"location":"01.scripts/03.Proteccion/#3-dim_programa","title":"3. DIM_PROGRAMA","text":"<p>Programas asociados a actividades de protecci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_PROGRAMA</code> <code>int</code> Identificador \u00fanico del programa. <code>PROGRAMA</code> <code>nvarchar</code> Nombre del programa."},{"location":"01.scripts/03.Proteccion/#4-dim_campos_caract","title":"4. DIM_CAMPOS_CARACT","text":"<p>Contiene las preguntas utilizadas en caracterizaciones.</p> Columna Tipo Descripci\u00f3n <code>ID_PREGUNTA</code> <code>int</code> Identificador \u00fanico de la pregunta. <code>PREGUNTA</code> <code>nvarchar</code> Texto de la pregunta. <code>OBSERVACIONES</code> <code>nvarchar</code> Observaciones relacionadas con la pregunta."},{"location":"01.scripts/03.Proteccion/#5-dim_preguntas_ee_jec","title":"5. DIM_PREGUNTAS_EE_JEC","text":"<p>Preguntas espec\u00edficas para diagn\u00f3sticos de establecimientos educativos.</p> Columna Tipo Descripci\u00f3n <code>ID_PREGUNTA</code> <code>int</code> Identificador \u00fanico de la pregunta. <code>PREGUNTA</code> <code>nvarchar</code> Texto de la pregunta. <code>ID_PROGRAMA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de programas."},{"location":"01.scripts/03.Proteccion/#6-dim_respuestas_ee_jec","title":"6. DIM_RESPUESTAS_EE_JEC","text":"<p>Respuestas asociadas a las preguntas de establecimientos educativos.</p> Columna Tipo Descripci\u00f3n <code>ID_RESPUESTA</code> <code>int</code> Identificador \u00fanico de la respuesta. <code>RESPUESTA</code> <code>nvarchar</code> Texto de la respuesta. <code>ID_PREGUNTA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de preguntas."},{"location":"01.scripts/03.Proteccion/#tablas-de-hechos","title":"Tablas de Hechos","text":""},{"location":"01.scripts/03.Proteccion/#1-fact_caracterizacion","title":"1. FACT_CARACTERIZACION","text":"<p>Registra las respuestas y observaciones relacionadas con la caracterizaci\u00f3n de la poblaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_CARACTERIZACION</code> <code>int</code> Identificador \u00fanico del registro de caracterizaci\u00f3n. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO</code>). <code>ID_POBLACION</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de poblaci\u00f3n. <code>ID_PROGRAMA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de programas. <code>ID_PREGUNTA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de preguntas. <code>RESPUESTA</code> <code>nvarchar</code> Respuesta de la caracterizaci\u00f3n. <code>OBSERVACIONES</code> <code>nvarchar</code> Observaciones adicionales."},{"location":"01.scripts/03.Proteccion/#2-fact_venta","title":"2. FACT_VENTA","text":"<p>Registro de ventas asociadas a servicios y poblaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_VENTA</code> <code>int</code> Identificador \u00fanico de la venta. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO</code>). <code>ID_POBLACION</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de poblaci\u00f3n. <code>ID_TARIFA</code> <code>int</code> Relaci\u00f3n con tarifas de servicios. <code>SERVICIO</code> <code>nvarchar</code> Nombre del servicio. <code>COSTO</code> <code>decimal</code> Costo asociado al servicio. <code>SUBSIDIO</code> <code>decimal</code> Subsidio aplicado al servicio. <code>VALOR_PAGADO_SIN_IMP</code> <code>decimal</code> Valor pagado sin impuestos."},{"location":"01.scripts/03.Proteccion/#3-fact_desercion","title":"3. FACT_DESERCION","text":"<p>Registra casos de deserci\u00f3n en establecimientos educativos.</p> Columna Tipo Descripci\u00f3n <code>ID_REGISTRO</code> <code>int</code> Identificador \u00fanico del registro de deserci\u00f3n. <code>ID_ESTABLECIMIENTO_EDUCATIVO</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de establecimientos educativos. <code>ID_POBLACION</code> <code>int</code> Relaci\u00f3n con la poblaci\u00f3n. <code>ANIO_ACADEMICO</code> <code>nvarchar</code> A\u00f1o acad\u00e9mico de la deserci\u00f3n. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo. <code>CAUSA</code> <code>nvarchar</code> Causa de la deserci\u00f3n."},{"location":"01.scripts/03.Proteccion/#relaciones-dimensionales-y-tablas-de-hechos","title":"Relaciones Dimensionales y Tablas de Hechos","text":""},{"location":"01.scripts/03.Proteccion/#diagrama-general-del-modelo","title":"Diagrama General del Modelo","text":"<pre><code>erDiagram\n    DIM_POBLACION {\n        int ID_POBLACION PK\n        nvarchar TIPO_DOCUMENTO\n        nvarchar DOCUMENTO\n    }\n\n    DIM_ESTABLECIMIENTO_EDUCATIVO {\n        int ID_ESTABLECIMIENTO_EDUCATIVO PK\n        nvarchar NOMBRE_ESTABLECIMIENTO\n    }\n\n    DIM_PROGRAMA {\n        int ID_PROGRAMA PK\n        nvarchar PROGRAMA\n    }\n\n    DIM_CAMPOS_CARACT {\n        int ID_PREGUNTA PK\n        nvarchar PREGUNTA\n    }\n\n    FACT_CARACTERIZACION {\n        int ID_CARACTERIZACION PK\n        int ID_POBLACION FK\n        int ID_PROGRAMA FK\n        int ID_FECHA FK\n    }\n\n    FACT_DESERCION {\n        int ID_REGISTRO PK\n        int ID_ESTABLECIMIENTO_EDUCATIVO FK\n        int ID_POBLACION FK\n        int ID_PROGRAMA FK\n    }\n\n    FACT_VENTA {\n        int ID_VENTA PK\n        int ID_POBLACION FK\n        int ID_TARIFA FK\n        int ID_FECHA FK\n    }\n\n    DIM_POBLACION ||--o{ FACT_CARACTERIZACION : \"ID_POBLACION\"\n    DIM_PROGRAMA ||--o{ FACT_CARACTERIZACION : \"ID_PROGRAMA\"\n    DIM_ESTABLECIMIENTO_EDUCATIVO ||--o{ FACT_DESERCION : \"ID_ESTABLECIMIENTO_EDUCATIVO\"\n    DIM_POBLACION ||--o{ FACT_DESERCION : \"ID_POBLACION\"\n    DIM_PROGRAMA ||--o{ FACT_DESERCION : \"ID_PROGRAMA\"\n    DIM_POBLACION ||--o{ FACT_VENTA : \"ID_POBLACION\"\n    DIM_PROGRAMA ||--o{ FACT_VENTA : \"ID_TARIFA\"</code></pre>"},{"location":"01.scripts/03.Proteccion/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li> <p>Modularidad:</p> <ul> <li>Separaci\u00f3n clara entre datos descriptivos (<code>DIM</code>) y registros transaccionales (<code>FACT</code>).</li> </ul> </li> <li> <p>Integridad Referencial:</p> <ul> <li>Uso de claves for\u00e1neas para garantizar la consistencia entre las tablas.</li> </ul> </li> <li> <p>Escalabilidad:</p> <ul> <li>Permite la adici\u00f3n de nuevas dimensiones y hechos sin impactar la estructura existente.</li> </ul> </li> <li> <p>Eficiencia:</p> <ul> <li>\u00cdndices primarios y relaciones bien definidas para optimizar las consultas.</li> </ul> </li> </ol>"},{"location":"01.scripts/03.Proteccion/#script","title":"Script","text":"<pre><code>USE DWH_COMFENALCO\nGO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- Eliminar restricciones de clave for\ufffdnea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Proteccion';\nEXEC sp_executesql @sql;\n-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Proteccion';\nEXEC sp_executesql @sql;\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Proteccion')\nBEGIN\n    DROP SCHEMA Proteccion;\nEND\nGO\n-- Crear el esquema Proteccion\nCREATE SCHEMA Proteccion;\nGO \n-- Crear Proteccion.DIM_POBLACION\nCREATE TABLE [Proteccion].[DIM_POBLACION] (\n    [ID_POBLACION] [int] IDENTITY(1,1) NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](20) NOT NULL,\n    [DOCUMENTO] [nvarchar](50) NOT NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    CONSTRAINT [PK_DIM_POBLACION] PRIMARY KEY CLUSTERED ([ID_POBLACION])\n)\nGO\n-- Crear Proteccion.DIM_ESTABLECIMIENTO_EDUCATIVO\nCREATE TABLE [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (\n    [ID_ESTABLECIMIENTO_EDUCATIVO] [int] IDENTITY(1,1) NOT NULL,\n    --[COD_ESTABLECIMIENTO_EDUCATIVO] [int] NOT NULL,\n    [NOMBRE_ESTABLECIMIENTO] [nvarchar](255) NOT NULL,\n    --[TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    --[DOCUMENTO] [nvarchar](20) NOT NULL,\n    [REPRESENTANTE_LEGAL] [nvarchar](255) ,--NOT NULL\n    --[NO_SEDES] [int] NOT NULL,\n    [DIRECCION] [nvarchar](300) ,--NOT NULL\n    --[COD_CIUDAD] [nvarchar](5) NULL\n    [MUNICIPIO] [nvarchar](255) ,\n    CONSTRAINT [PK_DIM_ESTABLECIMIENTO_EDUCATIVO] PRIMARY KEY CLUSTERED ([ID_ESTABLECIMIENTO_EDUCATIVO])\n)\n-- Crear Proteccion.DIM_PROGRAMA\nCREATE TABLE [Proteccion].[DIM_PROGRAMA] (\n    [ID_PROGRAMA] [int] IDENTITY(1,1) NOT NULL,\n    [PROGRAMA] [nvarchar](40)\n    CONSTRAINT [PK_DIM_PROGRAMA] PRIMARY KEY CLUSTERED ([ID_PROGRAMA])\n)\nGO\n-- Crear Proteccion.DIM_CAMPOS_CARACT\nCREATE TABLE [Proteccion].[DIM_CAMPOS_CARACT] (\n    [ID_PREGUNTA] [int] IDENTITY(1,1) NOT NULL,\n    [PREGUNTA] [nvarchar](255) NOT NULL,\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_DIM_CAMPOS_CARACT] PRIMARY KEY CLUSTERED ([ID_PREGUNTA])\n)\nGO\n-- Crear Proteccion.FACT_CARACTERIZACION\nCREATE TABLE [Proteccion].[FACT_CARACTERIZACION] (\n    [ID_CARACTERIZACION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] , --NOT NULL\n    [FECHA] [datetime] NOT NULL,\n    [ID_POBLACION] [int] NOT NULL,\n    --[TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    --[DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    [ID_PREGUNTA] [int] NOT NULL, \n    [RESPUESTA] [nvarchar](255),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_FACT_CARACTERIZACION] PRIMARY KEY CLUSTERED ([ID_CARACTERIZACION]),\n    CONSTRAINT [FK_FACT_CARACTERIZACION_DIM_POBLACION] FOREIGN KEY ([ID_POBLACION]) REFERENCES [Proteccion].[DIM_POBLACION]([ID_POBLACION]),\n    CONSTRAINT [FK_FACT_CARACTERIZACION_DIM_CAMPOS_CARACT] FOREIGN KEY ([ID_PREGUNTA]) REFERENCES [Proteccion].[DIM_CAMPOS_CARACT]([ID_PREGUNTA]),\n    CONSTRAINT [FK_FACT_CARACTERIZACION_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Proteccion].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_CARACTERIZACION_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear Proteccion.FACT_PLAN_COBERTURA\nCREATE TABLE [Proteccion].[FACT_PLAN_COBERTURA] (\n    [ID_PLAN_COBERTURA] [int] IDENTITY(1,1) NOT NULL,\n    --[ID_FECHA] [int] NOT NULL,\n    [ANIO] [nvarchar](40),\n    --[ZONA] [nvarchar](40),\n    [MUNICIPIO] [nvarchar](40),\n    [ID_ESTABLECIMIENTO_EDUCATIVO] [int] NOT NULL,\n    --[NOMBRE_EE] [nvarchar](200),\n    [ID_PROGRAMA] [int] NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [LINEA_INTERVENCION] [nvarchar](255),\n    --[SEDE] [nvarchar](40),\n    [COBERTURA_PROYECTADA] [nvarchar](255),\n    CONSTRAINT [PK_FACT_PLAN_COBERTURA] PRIMARY KEY CLUSTERED ([ID_PLAN_COBERTURA]),\n    CONSTRAINT [FK_FACT_PLAN_COBERTURA_DIM_ESTABLECIMIENTO_EDUCATIVO] FOREIGN KEY ([ID_ESTABLECIMIENTO_EDUCATIVO]) REFERENCES [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO]([ID_ESTABLECIMIENTO_EDUCATIVO]),\n    CONSTRAINT [FK_FACT_PLAN_COBERTURA_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Proteccion].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    --CONSTRAINT [FK_FACT_PLAN_COBERTURA_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear Proteccion.FACT_VENTA\nCREATE TABLE [Proteccion].[FACT_VENTA] (\n    [ID_VENTA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [ID_POBLACION] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [NOMBRE_USUARIO] [nvarchar](200),\n    [CATEGORIA_VENTA] [nvarchar](40),\n    [ID_TARIFA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    --[COD_SERVICIO] [nvarchar](40),\n    [SERVICIO] [nvarchar](200),\n    [COSTO] [decimal](28, 2),\n    [SUBSIDIO] [decimal](28, 2),\n    [VALOR_PAGADO_SIN_IMP] [decimal](28, 2),\n    CONSTRAINT [PK_FACT_VENTA] PRIMARY KEY CLUSTERED ([ID_VENTA]),\n    CONSTRAINT [FK_FACT_VENTA_DIM_POBLACION] FOREIGN KEY ([ID_POBLACION]) REFERENCES [Proteccion].[DIM_POBLACION]([ID_POBLACION]),\n    CONSTRAINT [FK_FACT_VENTA_DIM_SERVICIOS] FOREIGN KEY ([ID_TARIFA]) REFERENCES [Transversal].[DIM_TARIFAS_SERVICIOS]([ID_TARIFA]),\n    CONSTRAINT [FK_FACT_VENTA_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear Proteccion.DIM_PREGUNTAS_EE_JEC\nCREATE TABLE [Proteccion].[DIM_PREGUNTAS_EE_JEC] (\n    [ID_PREGUNTA] [int] IDENTITY(1,1) NOT NULL,\n    [PREGUNTA] [nvarchar](255),\n    [ID_PROGRAMA] [int] NOT NULL,\n    CONSTRAINT [PK_DIM_PREGUNTAS_EE_JEC] PRIMARY KEY CLUSTERED ([ID_PREGUNTA]),\n    CONSTRAINT [FK_DIM_PREGUNTAS_EE_JEC_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Proteccion].[DIM_PROGRAMA]([ID_PROGRAMA])\n)\nGO\n-- Crear Proteccion.DIM_RESPUESTAS_EE_JEC\nCREATE TABLE [Proteccion].[DIM_RESPUESTAS_EE_JEC] (\n    [ID_RESPUESTA] [int] IDENTITY(1,1) NOT NULL,\n    [RESPUESTA] [nvarchar](255),\n    [ID_PREGUNTA] [int] NOT NULL,\n    CONSTRAINT [PK_DIM_RESPUESTAS_EE_JEC] PRIMARY KEY CLUSTERED ([ID_RESPUESTA]),\n    CONSTRAINT [FK_DIM_RESPUESTAS_EE_JEC_DIM_PREGUNTAS_EE_JEC] FOREIGN KEY ([ID_PREGUNTA]) REFERENCES [Proteccion].[DIM_PREGUNTAS_EE_JEC]([ID_PREGUNTA])\n)\nGO\n/*\n--INSERT -1 values------------------------------------------------------------------------------\n--USE DWH_COMFENALCO\n--GO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] ON\nGO\n-- Eliminar restricciones de clave for\ufffdnea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Proteccion';\nEXEC sp_executesql @sql;\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC];\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_JEC] (ID_RESPUESTA,RESPUESTA,ID_PREGUNTA)\nVALUES (-1,'RESPUESTA_PREGUNTA_ABIERTA',-1);\n\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] OFF \n------------------------------------------------------------------------------------------------\nGO*/\n-- Crear Proteccion.FACT_DIAGNOSTICOS_EE_JEC\nCREATE TABLE [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [FECHA_HORA_INICIO] [datetime] NOT NULL,\n    [FECHA_HORA_FIN] [datetime] NOT NULL,\n    [CORREO_FUNCIONARIO] [nvarchar](200),\n    [NOMBRE_FUNCIONARIO] [nvarchar](200),\n    [TOTAL_PUNTOS] [nvarchar](40),\n    [FECHA_ULT_MODIF] [datetime] ,\n    --[ID_ESTABLECIMIENTO_EDUCATIVO] [int] NOT NULL,\n    --[NOMBRE_EE] [nvarchar](200),\n    [RECTOR] [nvarchar](40),\n    [ID_FECHA] [int] , -- NOT NULL\n    [FECHA] [datetime] NOT NULL, \n    [ID_PREGUNTA] [int] NOT NULL, -- \n    --[PREGUNTA] [nvarchar](255),-- PRUEBA\n    [RESPUESTA] [nvarchar](255),\n    [ID_RESPUESTA] [int] ,\n    [OBSERVACION] [nvarchar](40),\n    CONSTRAINT [PK_FACT_DIAGNOSTICOS_EE_JEC] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_DIAGNOSTICOS_EE_JEC_DIM_PREGUNTAS_EE_JEC] FOREIGN KEY ([ID_PREGUNTA]) REFERENCES [Proteccion].[DIM_PREGUNTAS_EE_JEC]([ID_PREGUNTA]),\n    CONSTRAINT [FK_FACT_DIAGNOSTICOS_EE_JEC_DIM_RESPUESTAS_EE_JEC] FOREIGN KEY ([ID_RESPUESTA]) REFERENCES [Proteccion].[DIM_RESPUESTAS_EE_JEC]([ID_RESPUESTA]),\n    --CONSTRAINT [FK_FACT_DIAGNOSTICOS_EE_JEC_DIM_ESTABLECIMIENTO_EDUCATIVO] FOREIGN KEY ([ID_ESTABLECIMIENTO_EDUCATIVO]) REFERENCES [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO]([ID_ESTABLECIMIENTO_EDUCATIVO]),\n    CONSTRAINT [FK_FACT_DIAGNOSTICOS_EE_JEC_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Proteccion.DIM_PREGUNTAS_EE_AIPI\nCREATE TABLE [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (\n    [ID_PREGUNTA] [int] IDENTITY(1,1) NOT NULL,\n    [PREGUNTA] [nvarchar](255),\n    [ID_PROGRAMA] [int] NOT NULL,\n    CONSTRAINT [PK_DIM_PREGUNTAS_EE_AIPI] PRIMARY KEY CLUSTERED ([ID_PREGUNTA]),\n    CONSTRAINT [FK_DIM_PREGUNTAS_EE_AIPI_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Proteccion].[DIM_PROGRAMA]([ID_PROGRAMA])\n)\nGO\n-- Crear Proteccion.DIM_RESPUESTAS_EE_AIPI\nCREATE TABLE [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (\n    [ID_RESPUESTA] [int] IDENTITY(1,1) NOT NULL,\n    [RESPUESTA] [nvarchar](255),\n    [ID_PREGUNTA] [int] NOT NULL,\n    CONSTRAINT [PK_DIM_RESPUESTAS_EE_AIPI] PRIMARY KEY CLUSTERED ([ID_RESPUESTA]),\n    CONSTRAINT [FK_DIM_RESPUESTAS_EE_AIPI_DIM_PREGUNTAS_EE_AIPI] FOREIGN KEY ([ID_PREGUNTA]) REFERENCES [Proteccion].[DIM_PREGUNTAS_EE_AIPI]([ID_PREGUNTA])\n)\nGO\n/*\n--INSERT -1 values------------------------------------------------------------------------------\n--USE DWH_COMFENALCO\n--GO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] ON\nGO\n-- Eliminar restricciones de clave for\ufffdnea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Proteccion';\nEXEC sp_executesql @sql;\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI];\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (ID_RESPUESTA,RESPUESTA,ID_PREGUNTA)\nVALUES (-1,'RESPUESTA_PREGUNTA_ABIERTA',-1);\n\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] OFF \n------------------------------------------------------------------------------------------------\nGO*/\n-- Crear Proteccion.FACT_DIAGNOSTICOS_EE_AIPI\nCREATE TABLE [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [ID_ESTABLECIMIENTO_EDUCATIVO] [int]  NOT NULL,\n    --[NOMBRE_EE] [nvarchar](200),\n    --[NO_SEDES] [nvarchar](40),\n    [NOMBRE_SEDE] [nvarchar](200),\n    [MUNICIPIO] [nvarchar](255),\n    [ENTIDAD_ADMINISTRADORA] [nvarchar](255),\n    [DIRECCION] [nvarchar](300),\n    [ID_PREGUNTA] [int] NOT NULL,--NOT NULL\n    [PREGUNTA] [nvarchar](255) ,\n    [ID_RESPUESTA] [int] , --NOT NULL\n    [RESPUESTA] [nvarchar](255) NOT NULL,\n    CONSTRAINT [PK_FACT_DIAGNOSTICOS_EE_AIPI] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_DIAGNOSTICOS_EE_AIPI_DIM_PREGUNTAS_EE_AIPI] FOREIGN KEY ([ID_PREGUNTA]) REFERENCES [Proteccion].[DIM_PREGUNTAS_EE_AIPI]([ID_PREGUNTA]),\n    CONSTRAINT [FK_FACT_DIAGNOSTICOS_EE_AIPI_DIM_RESPUESTAS_EE_AIPI] FOREIGN KEY ([ID_RESPUESTA]) REFERENCES [Proteccion].[DIM_RESPUESTAS_EE_AIPI]([ID_RESPUESTA]),\n    CONSTRAINT [FK_FACT_DIAGNOSTICOS_EE_AIPI_DIM_ESTABLECIMIENTO_EDUCATIVO] FOREIGN KEY ([ID_ESTABLECIMIENTO_EDUCATIVO]) REFERENCES [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO]([ID_ESTABLECIMIENTO_EDUCATIVO]),\n    CONSTRAINT [FK_FACT_DIAGNOSTICOS_EE_AIPI_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n\n-- Crear Proteccion.FACT_ENTREGA_MATERIAL\nCREATE TABLE [Proteccion].[FACT_ENTREGA_MATERIAL] (\n    [ID_ENTREGA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA_ENTREGA] [datetime] NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [ID_PERSONAL] [int] NOT NULL,\n    [ID_MATERIAL] [int] NOT NULL,\n    [NOMBRE_MATERIAL] [nvarchar](200),\n    [TIPO_MATERIAL] [nvarchar](255),\n    [CANTIDAD_MATERIAL] [int],\n    [VALOR_MATERIAL] [decimal](28, 2),\n    [ID_POBLACION] [int] NOT NULL,\n    --[TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    --[DOCUMENTO] [nvarchar](20) NOT NULL,\n    CONSTRAINT [PK_FACT_ENTREGA_MATERIAL] PRIMARY KEY CLUSTERED ([ID_ENTREGA]),\n    CONSTRAINT [FK_FACT_ENTREGA_MATERIAL_DIM_POBLACION] FOREIGN KEY ([ID_POBLACION]) REFERENCES [Proteccion].[DIM_POBLACION]([ID_POBLACION]),\n    CONSTRAINT [FK_FACT_ENTREGA_MATERIAL_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_ENTREGA_MATERIAL_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Proteccion].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_ENTREGA_MATERIAL_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Proteccion.FACT_VISITAS\nCREATE TABLE [Proteccion].[FACT_VISITAS] (\n    [ID_VISITA] [int] IDENTITY(1,1) NOT NULL,\n    [MUNICIPIO] [nvarchar](40),\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA_PLANEADA] [datetime] NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [PERSONAL] [nvarchar](255),\n    [ACTIVIDAD] [nvarchar](255),\n    [LUGAR] [nvarchar](255),\n    [FECHA_EJECUTADA] [datetime] NOT NULL,\n    CONSTRAINT [PK_FACT_VISITAS] PRIMARY KEY CLUSTERED ([ID_VISITA]),\n    CONSTRAINT [FK_FACT_VISITAS_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_VISITAS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Proteccion].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_VISITAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Proteccion.FACT_DESERCION\nCREATE TABLE [Proteccion].[FACT_DESERCION] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_ESTABLECIMIENTO_EDUCATIVO] [int]  NOT NULL,\n    --[NOMBRE_EE] [nvarchar](200),\n    [ID_POBLACION] [int] NOT NULL,\n    --[TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    --[DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ANIO_ACADEMICO] [nvarchar](40),\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA_REGISTRO] [datetime] NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    [CAUSA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_DESERCION] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_POBLACION] FOREIGN KEY ([ID_POBLACION]) REFERENCES [Proteccion].[DIM_POBLACION]([ID_POBLACION]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_ESTABLECIMIENTO_EDUCATIVO] FOREIGN KEY ([ID_ESTABLECIMIENTO_EDUCATIVO]) REFERENCES [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO]([ID_ESTABLECIMIENTO_EDUCATIVO]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Proteccion].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_DESERCION_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear Proteccion.FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD\nCREATE TABLE [Proteccion].[FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD](\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ANIO] [int] NULL,\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](255) NULL,\n    [SERVICIO] [float] NULL,\n    [CATEGORIA_CCF] [float] NULL,\n    [NUM_PERSONAS_COBERTURA_SERVICIOS] [float] NULL,\n    [MES_PROYECTADO] [int] NULL,\n    [ID_UNIDAD] [int] NULL,\n    [ID_PROGRAMA] [int] NULL,\n    [ID_FECHA] [int] NULL\n) ON [PRIMARY]\nGO\n</code></pre>"},{"location":"01.scripts/04.Colegio/","title":"Documentaci\u00f3n SQL para el Esquema <code>Colegio</code>","text":""},{"location":"01.scripts/04.Colegio/#introduccion","title":"Introducci\u00f3n","text":"<p>El script SQL crea un modelo de datos en el esquema <code>Colegio</code> dentro del Data Warehouse <code>DWH_COMFENALCO</code>. Este modelo est\u00e1 dise\u00f1ado para gestionar informaci\u00f3n educativa, incluyendo datos sobre matr\u00edcula, planes curriculares, evaluaciones, ausencias, bibliotecas, y resultados acad\u00e9micos.</p>"},{"location":"01.scripts/04.Colegio/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li> <p>Eliminaci\u00f3n de estructuras previas:</p> <ul> <li>Limpia el esquema <code>Colegio</code> eliminando tablas y claves for\u00e1neas existentes si ya est\u00e1n definidas.</li> </ul> </li> <li> <p>Creaci\u00f3n del esquema <code>Colegio</code>:</p> <ul> <li>Construcci\u00f3n de un modelo dimensional con tablas de hechos (<code>FACT</code>) y dimensiones (<code>DIM</code>) para representar datos educativos.</li> </ul> </li> <li> <p>Establecimiento de relaciones:</p> <ul> <li>Configuraci\u00f3n de claves for\u00e1neas para garantizar la integridad referencial y las conexiones l\u00f3gicas entre entidades.</li> </ul> </li> </ol>"},{"location":"01.scripts/04.Colegio/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/04.Colegio/#tablas-dimensionales-dim","title":"Tablas Dimensionales (<code>DIM</code>)","text":""},{"location":"01.scripts/04.Colegio/#1-dim_anio_academico","title":"1. DIM_ANIO_ACADEMICO","text":"<p>Registra los a\u00f1os acad\u00e9micos.</p> Columna Tipo Descripci\u00f3n <code>ANIO_ACADEMICO</code> <code>numeric(4,0)</code> A\u00f1o acad\u00e9mico (ejemplo: 2024)."},{"location":"01.scripts/04.Colegio/#2-dim_plan_curricular","title":"2. DIM_PLAN_CURRICULAR","text":"<p>Define las asignaturas ofrecidas en un curso espec\u00edfico.</p> Columna Tipo Descripci\u00f3n <code>ID_ASIGNATURA</code> <code>int</code> Identificador \u00fanico de la asignatura. <code>ID_CURSO</code> <code>int</code> Relaci\u00f3n con el curso. <code>ANIO_ACADEMICO</code> <code>numeric(4,0)</code> A\u00f1o acad\u00e9mico. <code>ASIGNATURA</code> <code>nvarchar</code> Nombre de la asignatura."},{"location":"01.scripts/04.Colegio/#3-dim_libros","title":"3. DIM_LIBROS","text":"<p>Informaci\u00f3n sobre libros disponibles en la biblioteca.</p> Columna Tipo Descripci\u00f3n <code>ID_LIBRO</code> <code>int</code> Identificador \u00fanico del libro. <code>NOMBRE_LIBRO</code> <code>nvarchar</code> T\u00edtulo del libro. <code>AUTOR</code> <code>nvarchar</code> Autor del libro."},{"location":"01.scripts/04.Colegio/#tablas-de-hechos-fact","title":"Tablas de Hechos (<code>FACT</code>)","text":""},{"location":"01.scripts/04.Colegio/#1-fact_legalizacion","title":"1. FACT_LEGALIZACION","text":"<p>Almacena informaci\u00f3n sobre procesos de legalizaci\u00f3n de instituciones educativas.</p> Columna Tipo Descripci\u00f3n <code>ID_LEGALIZACION</code> <code>int</code> Identificador \u00fanico del registro. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo. <code>RAZON_SOCIAL</code> <code>nvarchar</code> Raz\u00f3n social de la instituci\u00f3n educativa."},{"location":"01.scripts/04.Colegio/#2-fact_transporte","title":"2. FACT_TRANSPORTE","text":"<p>Gesti\u00f3n del uso del transporte escolar.</p> Columna Tipo Descripci\u00f3n <code>ID_REGISTRO</code> <code>int</code> Identificador \u00fanico del registro. <code>ID_POBLACION_MATRICULA</code> <code>int</code> Relaci\u00f3n con la poblaci\u00f3n matriculada. <code>ANIO_ACADEMICO</code> <code>numeric(4,0)</code> A\u00f1o acad\u00e9mico relacionado."},{"location":"01.scripts/04.Colegio/#3-fact_notas","title":"3. FACT_NOTAS","text":"<p>Registra las calificaciones de los estudiantes.</p> Columna Tipo Descripci\u00f3n <code>ID_NOTA</code> <code>int</code> Identificador \u00fanico de la nota. <code>ID_ASIGNATURA</code> <code>int</code> Relaci\u00f3n con la asignatura. <code>NOTA_FINAL</code> <code>decimal</code> Nota final obtenida por el estudiante."},{"location":"01.scripts/04.Colegio/#4-fact_biblioteca","title":"4. FACT_BIBLIOTECA","text":"<p>Registra pr\u00e9stamos de libros en la biblioteca.</p> Columna Tipo Descripci\u00f3n <code>ID_REGISTRO</code> <code>int</code> Identificador \u00fanico del registro. <code>ID_LIBRO</code> <code>int</code> Relaci\u00f3n con la tabla de libros. <code>FECHA_PRESTAMO</code> <code>datetime</code> Fecha en que se realiz\u00f3 el pr\u00e9stamo."},{"location":"01.scripts/04.Colegio/#relaciones-entre-tablas","title":"Relaciones entre Tablas","text":""},{"location":"01.scripts/04.Colegio/#diagrama-relacional","title":"Diagrama Relacional","text":"<pre><code>erDiagram\n    DIM_ANIO_ACADEMICO {\n        numeric ANIO_ACADEMICO PK\n    }\n\n    DIM_PLAN_CURRICULAR {\n        int ID_ASIGNATURA PK\n        int ID_CURSO FK\n        numeric ANIO_ACADEMICO FK\n    }\n\n    DIM_LIBROS {\n        int ID_LIBRO PK\n        nvarchar NOMBRE_LIBRO\n        nvarchar AUTOR\n    }\n\n    FACT_TRANSPORTE {\n        int ID_REGISTRO PK\n        int ID_POBLACION_MATRICULA FK\n        numeric ANIO_ACADEMICO FK\n    }\n\n    FACT_NOTAS {\n        int ID_NOTA PK\n        int ID_ASIGNATURA FK\n        decimal NOTA_FINAL\n    }\n\n    FACT_BIBLIOTECA {\n        int ID_REGISTRO PK\n        int ID_LIBRO FK\n        datetime FECHA_PRESTAMO\n    }\n\n    DIM_ANIO_ACADEMICO ||--o{ DIM_PLAN_CURRICULAR : AnioAcademico\n    DIM_PLAN_CURRICULAR ||--o{ FACT_NOTAS : Asignatura\n    DIM_LIBROS ||--o{ FACT_BIBLIOTECA : Libro</code></pre>"},{"location":"01.scripts/04.Colegio/#consideraciones-tecnicas","title":"Consideraciones T\u00e9cnicas","text":"<ol> <li> <p>Integridad Referencial:</p> <ul> <li>Uso de claves for\u00e1neas para relacionar hechos con dimensiones.</li> </ul> </li> <li> <p>Eficiencia:</p> <ul> <li>\u00cdndices primarios en todas las tablas para optimizar consultas.</li> </ul> </li> <li> <p>Escalabilidad:</p> <ul> <li>Modelo adaptable para incluir nuevas dimensiones y hechos.</li> </ul> </li> <li> <p>Separaci\u00f3n L\u00f3gica:</p> <ul> <li>Diferenciaci\u00f3n clara entre tablas de hechos y dimensiones para an\u00e1lisis OLAP.</li> </ul> </li> </ol>"},{"location":"01.scripts/04.Colegio/#conclusion","title":"Conclusi\u00f3n","text":"<p>El esquema <code>Colegio</code> proporciona una estructura robusta para almacenar y analizar datos relacionados con la gesti\u00f3n escolar, facilitando la generaci\u00f3n de reportes y an\u00e1lisis avanzados de rendimiento acad\u00e9mico, recursos educativos y actividades administrativas.</p>"},{"location":"01.scripts/05.Tablas_Stage_Area/","title":"05. Tablas Stage Area","text":""},{"location":"01.scripts/05.Tablas_Stage_Area/#documentacion-sql-para-el-esquema-stage-area","title":"Documentaci\u00f3n SQL para el Esquema <code>Stage Area</code>","text":""},{"location":"01.scripts/05.Tablas_Stage_Area/#introduccion","title":"Introducci\u00f3n","text":"<p>El script SQL establece las tablas necesarias en el esquema <code>Stage Area</code> dentro de la base de datos <code>STAGE_AREA</code>. Este esquema est\u00e1 dise\u00f1ado para almacenar datos temporales y de staging relacionados con procesos de integraci\u00f3n y an\u00e1lisis en el Data Warehouse.</p>"},{"location":"01.scripts/05.Tablas_Stage_Area/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li>Creaci\u00f3n de Tablas Temporales y de Staging:</li> <li> <p>Tablas dise\u00f1adas para almacenar datos intermedios o temporales antes de ser procesados y cargados en las \u00e1reas definitivas del Data Warehouse.</p> </li> <li> <p>Gesti\u00f3n de Datos de Integraci\u00f3n:</p> </li> <li> <p>Tablas que soportan procesos de carga, transformaci\u00f3n y validaci\u00f3n de datos provenientes de diferentes fuentes.</p> </li> <li> <p>Flexibilidad y Escalabilidad:</p> </li> <li>Estructuras que permiten la integraci\u00f3n de nuevos datos y procesos sin afectar las \u00e1reas definitivas.</li> </ol>"},{"location":"01.scripts/05.Tablas_Stage_Area/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/05.Tablas_Stage_Area/#tablas-principales","title":"Tablas Principales","text":""},{"location":"01.scripts/05.Tablas_Stage_Area/#1-dim_poblacion_proteccion","title":"1. DIM_POBLACION_PROTECCION","text":"<p>Tabla que almacena informaci\u00f3n b\u00e1sica de la poblaci\u00f3n relacionada con protecci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento de identidad. <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero de documento de identidad."},{"location":"01.scripts/05.Tablas_Stage_Area/#2-fact_caracterizacion_proteccion","title":"2. FACT_CARACTERIZACION_PROTECCION","text":"<p>Tabla que registra las respuestas y observaciones relacionadas con la caracterizaci\u00f3n de la poblaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>FECHA</code> <code>varchar</code> Fecha de la caracterizaci\u00f3n. <code>TIPO_DOCUMENTO</code> <code>varchar</code> Tipo de documento de identidad. <code>DOCUMENTO</code> <code>varchar</code> N\u00famero de documento de identidad. <code>PROGRAMA</code> <code>varchar</code> Programa asociado a la caracterizaci\u00f3n. <code>PREGUNTA</code> <code>varchar</code> Pregunta realizada en la caracterizaci\u00f3n. <code>RESPUESTA</code> <code>varchar</code> Respuesta proporcionada. <code>OBSERVACIONES</code> <code>varchar</code> Observaciones adicionales."},{"location":"01.scripts/05.Tablas_Stage_Area/#3-tmp_acudientes_sap","title":"3. TMP_ACUDIENTES_SAP","text":"<p>Tabla temporal que almacena informaci\u00f3n de acudientes y estudiantes provenientes de SAP.</p> Columna Tipo Descripci\u00f3n <code>BP_ACUDIENTE</code> <code>nvarchar</code> Identificador del acudiente en SAP. <code>OBJETO_SAP_ESTUDIANTE</code> <code>nvarchar</code> Identificador del estudiante en SAP. <code>BP_ESTUDIANTE</code> <code>nvarchar</code> Identificador del estudiante en SAP. <code>NUMERO_MATRICULA</code> <code>nvarchar</code> N\u00famero de matr\u00edcula del estudiante. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento del estudiante. <code>NUMERO_DOCUMENTO</code> <code>nvarchar</code> N\u00famero de documento del estudiante. <code>PRIMER_APELLIDO</code> <code>nvarchar</code> Primer apellido del estudiante. <code>SEGUNDO_APELLIDO</code> <code>nvarchar</code> Segundo apellido del estudiante. <code>PRIMER_NOMBRE</code> <code>nvarchar</code> Primer nombre del estudiante. <code>SEGUNDO_NOMBRE</code> <code>nvarchar</code> Segundo nombre del estudiante. <code>GENERO</code> <code>nvarchar</code> G\u00e9nero del estudiante. <code>ESTADO_CIVIL</code> <code>nvarchar</code> Estado civil del estudiante. <code>PROFESION</code> <code>nvarchar</code> Profesi\u00f3n del estudiante. <code>FECHA_NACIMIENTO</code> <code>nvarchar</code> Fecha de nacimiento del estudiante. <code>PARENTESCO</code> <code>nvarchar</code> Parentesco del acudiente con el estudiante. <code>RESPONSABLE_JURIDICO</code> <code>nvarchar</code> Indicador de responsabilidad jur\u00eddica. <code>TELEFONO</code> <code>nvarchar</code> Tel\u00e9fono del estudiante o acudiente. <code>PAIS</code> <code>nvarchar</code> Pa\u00eds de residencia. <code>CIUDAD</code> <code>nvarchar</code> Ciudad de residencia. <code>DIRECCION</code> <code>nvarchar</code> Direcci\u00f3n de residencia. <code>CORREO</code> <code>nvarchar</code> Correo electr\u00f3nico."},{"location":"01.scripts/05.Tablas_Stage_Area/#4-tmp_desertores_cedesarrollo","title":"4. TMP_DESERTORES_CEDESARROLLO","text":"<p>Tabla temporal que almacena informaci\u00f3n de estudiantes desertores en el esquema <code>Cedesarrollo</code>.</p> Columna Tipo Descripci\u00f3n <code>PROGRAMA</code> <code>nvarchar</code> Programa acad\u00e9mico del estudiante. <code>NOMBRE_ESTUDIANTE</code> <code>nvarchar</code> Nombre completo del estudiante. <code>FECHA</code> <code>datetime</code> Fecha de la deserci\u00f3n. <code>TIPO</code> <code>nvarchar</code> Tipo de deserci\u00f3n. <code>CAUSA</code> <code>nvarchar</code> Causa de la deserci\u00f3n. <code>OBSERVACIONES</code> <code>nvarchar</code> Observaciones adicionales. <code>SEDE</code> <code>nvarchar</code> Sede acad\u00e9mica del estudiante. <code>JORNADA</code> <code>nvarchar</code> Jornada acad\u00e9mica del estudiante."},{"location":"01.scripts/05.Tablas_Stage_Area/#5-tmp_encuestas","title":"5. TMP_ENCUESTAS","text":"<p>Tabla temporal que almacena informaci\u00f3n de encuestas realizadas.</p> Columna Tipo Descripci\u00f3n <code>FECHA_ENCUESTA</code> <code>varchar</code> Fecha en que se realiz\u00f3 la encuesta. <code>DOCUMENTO</code> <code>varchar</code> Documento del encuestado. <code>PREGUNTA</code> <code>varchar</code> Pregunta realizada en la encuesta. <code>CALIFICACION</code> <code>varchar</code> Calificaci\u00f3n proporcionada. <code>SERVICIO</code> <code>varchar</code> Servicio evaluado en la encuesta. <code>TIPO_DOCUMENTO</code> <code>varchar</code> Tipo de documento del encuestado. <code>NPS</code> <code>varchar</code> Indicador de satisfacci\u00f3n (Net Promoter Score). <code>ID_UNIDAD</code> <code>int</code> Identificador de la unidad asociada."},{"location":"01.scripts/05.Tablas_Stage_Area/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li>Modularidad:</li> <li> <p>Separaci\u00f3n clara entre tablas temporales y definitivas para facilitar la gesti\u00f3n de datos.</p> </li> <li> <p>Flexibilidad:</p> </li> <li> <p>Estructuras dise\u00f1adas para soportar m\u00faltiples procesos de integraci\u00f3n y transformaci\u00f3n.</p> </li> <li> <p>Eficiencia:</p> </li> <li> <p>Uso de tipos de datos adecuados para optimizar el almacenamiento y las consultas.</p> </li> <li> <p>Escalabilidad:</p> </li> <li>Tablas dise\u00f1adas para permitir la adici\u00f3n de nuevas columnas o registros sin afectar la estructura existente.</li> </ol>"},{"location":"01.scripts/05.Tablas_Stage_Area/#script","title":"Script","text":"<pre><code>USE [STAGE_AREA]\nGO\n\nSET ANSI_NULLS ON\nGO\n\nSET QUOTED_IDENTIFIER ON\nGO\n\nCREATE TABLE [Transversal].[DIM_POBLACION_PROTECCION](\n    [TIPO_DOCUMENTO] [nvarchar](20) NOT NULL,\n    [DOCUMENTO] [nvarchar](50) NOT NULL\n) ON [PRIMARY]\nGO\n\nCREATE TABLE [Transversal].[FACT_CARACTERIZACION_PROTECCION](\n    [FECHA] [varchar](50) NULL,\n    [TIPO_DOCUMENTO] [varchar](50) NULL,\n    [DOCUMENTO] [varchar](50) NULL,\n    [PROGRAMA] [varchar](255) NULL,\n    [PREGUNTA] [varchar](255) NULL,\n    [RESPUESTA] [varchar](255) NULL,\n    [OBSERVACIONES] [varchar](255) NULL\n) ON [PRIMARY]\nGO\n\nCREATE TABLE [Transversal].[TMP_ACUDIENTES_SAP](\n    [BP_ACUDIENTE] [nvarchar](10) NULL,\n    [OBJETO_SAP_ESTUDIANTE] [nvarchar](8) NULL,\n    [BP_ESTUDIANTE] [nvarchar](10) NULL,\n    [NUMERO_MATRICULA] [nvarchar](12) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [NUMERO_DOCUMENTO] [nvarchar](20) NULL,\n    [PRIMER_APELLIDO] [nvarchar](40) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](40) NULL,\n    [PRIMER_NOMBRE] [nvarchar](40) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](40) NULL,\n    [GENERO] [nvarchar](15) NULL,\n    [ESTADO_CIVIL] [nvarchar](20) NULL,\n    [PROFESION] [nvarchar](70) NULL,\n    [FECHA_NACIMIENTO] [nvarchar](8) NULL,\n    [PARENTESCO] [nvarchar](9) NULL,\n    [RESPONSABLE_JURIDICO] [nvarchar](2) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [PAIS] [nvarchar](3) NULL,\n    [CIUDAD] [nvarchar](40) NULL,\n    [DIRECCION] [nvarchar](60) NULL,\n    [CORREO] [nvarchar](255) NULL\n) ON [PRIMARY]\nGO\n\nCREATE TABLE [Transversal].[TMP_DESERTORES_CEDESARROLLO](\n    [PROGRAMA] [nvarchar](255) NULL,\n    [NOMBRE_ESTUDIANTE] [nvarchar](255) NULL,\n    [FECHA] [datetime] NULL,\n    [TIPO] [nvarchar](255) NULL,\n    [CAUSA] [nvarchar](255) NULL,\n    [OBSERVACIONES] [nvarchar](255) NULL,\n    [SEDE] [nvarchar](255) NULL,\n    [JORNADA] [nvarchar](255) NULL\n) ON [PRIMARY]\nGO\n\nCREATE TABLE [Transversal].[TMP_ENCUESTAS](\n    [FECHA_ENCUESTA] [varchar](50) NULL,\n    [DOCUMENTO] [varchar](50) NULL,\n    [PREGUNTA] [varchar](255) NULL,\n    [CALIFICACION] [varchar](255) NULL,\n    [SERVICIO] [varchar](50) NULL,\n    [TIPO_DOCUMENTO] [varchar](50) NULL,\n    [NPS] [varchar](40) NULL,\n    [ID_UNIDAD] [int] NULL\n) ON [PRIMARY]\nGO\n\nCREATE TABLE [Transversal].[TMP_ESTUDIANTES_CEDESARROLLO](\n    [TIPO_DOCUMENTO] [nvarchar](255) NULL,\n    [DOCUMENTO_ESTUDIANTE] [nvarchar](255) NULL,\n    [NOMBRE_ESTUDIANTE] [nvarchar](255) NULL\n) ON [PRIMARY]\nGO\n\nCREATE TABLE [Transversal].[TMP_LISTADO_MATRICULAS_Q10](\n    [JORNADA] [nvarchar](255) NULL,\n    [NOMBRE_ESTUDIANTE] [nvarchar](255) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](255) NULL,\n    [DOCUMENTO_ESTUDIANTE] [nvarchar](255) NULL,\n    [FECHA_MATRICULA] [datetime] NULL,\n    [TELEFONO] [nvarchar](255) NULL,\n    [CELULAR] [nvarchar](255) NULL,\n    [CORREO] [nvarchar](255) NULL,\n    [SEMESTRE] [nvarchar](255) NULL,\n    [ESTADO] [nvarchar](255) NULL,\n    [SEDE] [nvarchar](255) NULL,\n    [PROGRAMA] [nvarchar](255) NULL,\n    [ID_UNIDAD] [int] NULL\n) ON [PRIMARY]\nGO\nCREATE TABLE [Transversal].[TMP_MATRICULAS_CEDESARROLLO](\n    [NOMBRE_ESTUDIANTE] [nvarchar](200) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](255) NULL,\n    [DOCUMENTO_ESTUDIANTE] [nvarchar](255) NULL,\n    [FECHA_MATRICULA] [datetime] NULL,\n    [TELEFONO] [nvarchar](40) NULL,\n    [CELULAR] [nvarchar](40) NULL,\n    [CORREO] [nvarchar](200) NULL,\n    [SEMESTRE] [nvarchar](40) NULL,\n    [ESTADO] [nvarchar](255) NULL,\n    [SEDE] [nvarchar](255) NULL,\n    [PROGRAMA] [nvarchar](255) NULL,\n    [ID_UNIDAD] [int] NULL,\n    [DOCUMENTOS_COMPLETOS] [nvarchar](2) NULL,\n    [JORNADA] [nvarchar](255) NULL,\n    [ID_JORNADA] [int] NULL,\n    [ID_PROGRAMA] [int] NULL,\n    [FECHA_INICIO_PERIODO] [date] NULL\n) ON [PRIMARY]\nGO\nCREATE TABLE [Transversal].[TMP_POBLACION_EDUCACION](\n    [TIPO_DOCUMENTO_SIGLAS] [nvarchar](3) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL\n) ON [PRIMARY]\nGO\nCREATE TABLE [Transversal].[TMP_PROCESO_MATRICULA_COLEGIO](\n    [ID_FECHA] [int] NULL,\n    [ID_ANIO_ACADEMICO] [nvarchar](4) NULL,\n    [BP] [nvarchar](20) NULL,\n    [ID_CATEGORIA] [int] NULL,\n    [ID_CURSO] [int] NULL,\n    [ID_TIPO_ESTUDIANTE] [int] NULL,\n    [IND_CODEUDOR] [int] NULL,\n    [P_CODEUDOR] [int] NULL,\n    [T_CODEUDOR] [int] NULL,\n    [IND_SECRETARIA_ACADEMICA] [int] NULL,\n    [P_SECRETARIA_ACADEMICA] [int] NULL,\n    [T_SECRETARIA_ACADEMICA] [int] NULL,\n    [IND_PSICOLOGIA] [int] NULL,\n    [P_PSICOLOGIA] [int] NULL,\n    [T_PSICOLOGIA] [int] NULL,\n    [IND_COORDINACION_ACADEMICA] [int] NULL,\n    [P_COORDINACION_ACADEMICA] [int] NULL,\n    [T_COORDINACION_ACADEMICA] [int] NULL,\n    [INDICADOR] [int] NULL,\n    [T_TOTAL_GESTION] [int] NULL,\n    [IND_CUMPLIMIENTO] [int] NULL,\n    [IND_EN_PROCESO] [int] NULL,\n    [IND_ADMITIDO] [int] NULL,\n    [IND_NO_ADMITIDO] [int] NULL,\n    [IND_DESISTIDO] [int] NULL\n) ON [PRIMARY]\nGO\n\nCREATE TABLE [Transversal].[STG_FACT_AFILIACIONES] (\n    [ACTIVIDAD] NVARCHAR(255),\n    [ADEUDA] DECIMAL(18, 2) NULL,\n    [ANIO_ACADEMICO] INT NULL,\n    [CANTIDAD_MATERIAL] INT NULL,\n    [CALIFICACION] NVARCHAR(255) NULL,\n    [CAUSA] NVARCHAR(255) NULL,\n    [CATEGORIA_VENTA] NVARCHAR(255) NULL,\n    [COSTO] DECIMAL(18, 2) NULL,\n    [CURSO] NVARCHAR(255) NULL,\n    [DESCRIPCION] NVARCHAR(255) NULL,\n    [ESTADO] NVARCHAR(255) NULL,\n    [ESTADOREGISTRO] NVARCHAR(50),\n    [ESTADO_PAGO] NVARCHAR(255) NULL,\n    [ESTRATO] INT NULL,\n    [DISCAPACIDAD] NVARCHAR (10) NULL,\n    [EDAD] INT NULL,\n    [FECHA_NACIMIENTO] DATETIME NULL,\n    [FECHA_AFILIACION] DATE NULL,\n    [FECHA_MENSUAL] DATE,\n    [FECHA_RETIRO] DATE NULL,\n    [FECHA_ADMISION] DATE NULL,\n    [ID_AFILIADO] INT NULL,\n    [ID_CATEGORIA] INT NULL,\n    [ID_CIUDAD] INT NULL,\n    [ID_CONCEPTO] INT NULL,\n    [ID_CURSO] INT NULL,\n    [ID_EMPRESA] INT NULL,\n    [ID_ESTADO_CIVIL] INT NULL,\n    [ID_ESTADO_GESTION] INT NULL,\n    [ID_FACTOR_VULNERABILIDAD] INT NULL,\n    [ID_FECHA] INT,\n    [ID_GENERO] INT NULL,\n    [ID_GRADO] INT NULL,\n    [ID_MATERIAL] INT NULL,\n    [ID_PERTENENCIA_ETNICA] INT NULL,\n    [ID_POBLACION] INT NULL,\n    [ID_PROGRAMA] INT NULL,\n    [ID_PREGUNTA] INT NULL,\n    [ID_TIPO_AFILIADO] INT NULL,\n    [ID_UNIDAD] INT NULL,\n    [NO_PRESTAMOS] INT NULL,\n    [NUMERO_APORTES] INT,\n    [PARTNER] NVARCHAR(50),\n    [PARTNER_AFILIADO] NVARCHAR(50) NULL,\n    [PARTNER_EMPRESA] NVARCHAR(50) NULL,\n    [RESPUESTA] NVARCHAR(255) NULL,\n    [SALARIO_BASICO] DECIMAL(18, 2) NULL,\n    [SERVICIO_TRANSPORTE] NVARCHAR(255) NULL,\n    [SUBSIDIO] DECIMAL(20, 2) NULL,\n    [TIPO_AFILIADO] NVARCHAR(255) NULL,\n    [TIPO_POBLACION] NVARCHAR(50),\n    [TOTAL_APORTES] DECIMAL(18, 2),\n    [VALOR_FACTURADO] DECIMAL(18, 2) NULL,\n    [VALOR_MATERIAL] DECIMAL(18, 2) NULL,\n    [VALOR_PAGADO] DECIMAL(18, 2) NULL,\n    [VALOR_PAGADO_SIN_IMP] DECIMAL(18, 2) NULL,\n    [FUENTE_PRINCIPAL] NVARCHAR(250) NULL,\n    [ID_PQR] [nvarchar](40) NULL DEFAULT -1,\n    [ESTADO_PQR] [nvarchar](40),\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1,\n    [CAUSA_PQR] [nvarchar](40),\n    [TIPO_PQRS] [nvarchar](40),\n    [ID_TARIFA] [int] NULL DEFAULT -1\n)\nGO\n\nCREATE TABLE [Transversal].[STG_PLAN_COBERTURA_ADULTO_DISCAPACIDAD](\n    [ANIO] [nvarchar](255) NULL,\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](255) NULL,\n    [SERVICIO] [float] NULL,\n    [CATEGORIA_CCF] [float] NULL,\n    [NUM_PERSONAS_COBERTURA_SERVICIOS] [float] NULL,\n    [MES_PROYECTADO] [float] NULL\n) ON [PRIMARY]\nGO\n\nCREATE TABLE [Transversal].[TMP_DESERTORES_DESARROLLO](\n    [PROGRAMA] [nvarchar](255) NULL,\n    [NOMBRE_ESTUDIANTE] [nvarchar](255) NULL,\n    [GRUPO] [nvarchar](255) NULL,\n    [MODULO] [nvarchar](255) NULL,\n    [SEMESTRE] [nvarchar](255) NULL,\n    [CREDITOS] [float] NULL,\n    [PORCENTAJE _INASISTENCIA] [float] NULL,\n    [SEDE] [nvarchar](255) NULL,\n    [JORNADA] [nvarchar](255) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](255) NULL,\n    [DOCUMENTO_ESTUDIANTE] [float] NULL,\n    [FECHA] [datetime] NULL\n) ON [PRIMARY]\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/","title":"06.Index Cedesarrollo","text":""},{"location":"01.scripts/06.Index_Cedesarrollo/#indices-cedesarrollo","title":"Indices Cedesarrollo","text":""},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_estudiantes","title":"DIM_ESTUDIANTES","text":"<ol> <li> <p>\u00cdndice \u00fanico no cl\u00faster en el campo <code>DOCUMENTO</code>:    Garantiza consultas r\u00e1pidas y \u00fanicas basadas en el n\u00famero de documento, generalmente usado para identificar estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_EMPRESA</code>:    Optimiza consultas relacionadas con empresas asociadas a los estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_AFILIADO</code>:    Mejora la eficiencia de las b\u00fasquedas relacionadas con afiliados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_BENEFICIARIO</code>:    Facilita las consultas relacionadas con beneficiarios de estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_APORTANTE</code>:    Aumenta la velocidad de las consultas que usan el campo de aportantes no afiliados.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster en <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Se orienta a optimizar b\u00fasquedas que combinen ambos campos, usados frecuentemente como filtro conjunto.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li>Eficiencia en consultas frecuentes: Los \u00edndices en campos individuales (<code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, etc.) y combinados (<code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>) aceleran las operaciones de b\u00fasqueda y filtros.</li> <li>Evitar redundancias: Los \u00edndices se dise\u00f1an para no replicar informaci\u00f3n ya cubierta por \u00edndices primarios o claves for\u00e1neas.</li> <li>Mejorar la unicidad: El \u00edndice \u00fanico en <code>DOCUMENTO</code> asegura que este campo no contenga duplicados, previniendo inconsistencias.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice \u00fanico no cl\u00faster en el campo DOCUMENTO\nCREATE UNIQUE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_DOCUMENTO\nON Cedesarrollo.DIM_ESTUDIANTES (DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_EMPRESA\nON Cedesarrollo.DIM_ESTUDIANTES (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_AFILIADO\nON Cedesarrollo.DIM_ESTUDIANTES (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_BENEFICIARIO\nON Cedesarrollo.DIM_ESTUDIANTES (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_APORTANTE\nON Cedesarrollo.DIM_ESTUDIANTES (ID_APORTANTE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster en TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_TIPO_DOCUMENTO_DOCUMENTO\nON Cedesarrollo.DIM_ESTUDIANTES (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_jornada","title":"DIM_JORNADA","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Optimiza las b\u00fasquedas y filtros relacionados con la unidad asociada a la jornada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>JORNADA</code>:    Facilita y acelera las consultas basadas en el nombre de la jornada, como b\u00fasquedas por texto.</p> </li> </ol> <p>**Justificaci\u00f3nDIM_JORNADA</p> <ul> <li><code>ID_UNIDAD</code>: Este campo es clave para unir esta tabla con otras que dependan de la identificaci\u00f3n de la unidad. Las b\u00fasquedas frecuentes en relaciones o filtros sobre unidades se beneficiar\u00e1n de este \u00edndice.</li> <li><code>JORNADA</code>: Usualmente, las consultas por nombre son comunes y al tratarse de un campo <code>nvarchar</code>, un \u00edndice espec\u00edfico mejora significativamente el rendimiento en b\u00fasquedas textuales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_JORNADA_ID_UNIDAD\nON Cedesarrollo.DIM_JORNADA (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo JORNADA\nCREATE NONCLUSTERED INDEX IX_DIM_JORNADA_NOMBRE\nON Cedesarrollo.DIM_JORNADA (JORNADA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_periodo_academico","title":"DIM_PERIODO_ACADEMICO","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Mejora el rendimiento de consultas relacionadas con las unidades asociadas a los per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>PERIODO_ACADEMICO</code>:    Optimiza b\u00fasquedas y filtros basados en el nombre o descripci\u00f3n del per\u00edodo acad\u00e9mico.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Dise\u00f1ado para acelerar consultas relacionadas con rangos de fechas, como per\u00edodos activos o hist\u00f3ricos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>: Este campo es clave en las relaciones con la tabla [DIM_UNIDAD]. Un \u00edndice en esta columna agiliza consultas de uni\u00f3n o b\u00fasquedas relacionadas.</li> <li><code>PERIODO_ACADEMICO</code>: Al tratarse de un campo descriptivo, puede usarse com\u00fanmente en filtros por texto, por lo que un \u00edndice acelera estas b\u00fasquedas.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Al ser campos utilizados frecuentemente para filtrar per\u00edodos dentro de un rango de tiempo, el \u00edndice compuesto asegura eficiencia en este tipo de consultas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_PERIODO_ACADEMICO_ID_UNIDAD\nON Cedesarrollo.DIM_PERIODO_ACADEMICO (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PERIODO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_DIM_PERIODO_ACADEMICO_NOMBRE\nON Cedesarrollo.DIM_PERIODO_ACADEMICO (PERIODO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_DIM_PERIODO_ACADEMICO_FECHAS\nON Cedesarrollo.DIM_PERIODO_ACADEMICO (FECHA_INICIO, FECHA_FIN);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_plan_curricular","title":"DIM_PLAN_CURRICULAR","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Mejora las consultas y uniones relacionadas con los programas a los que pertenece cada m\u00f3dulo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MODULO</code>:    Optimiza las b\u00fasquedas de m\u00f3dulos espec\u00edficos por su nombre o descripci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Facilita la recuperaci\u00f3n de datos agrupados o filtrados por semestre.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>INTENSIDAD_HORARIA</code> y <code>INTENSIDAD_HORARIA_SEMANAL</code>:    Acelera las consultas que involucren filtros o an\u00e1lisis relacionados con las intensidades horarias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PROGRAMA</code>: Este campo es clave en la relaci\u00f3n con [DIM_PROGRAMA] y es com\u00fanmente utilizado en uniones o filtros.</li> <li><code>MODULO</code>: Al ser descriptivo, es probable que se utilice para b\u00fasquedas directas o comparativas.</li> <li><code>SEMESTRE</code>: Las consultas que involucren planes curriculares por semestre se beneficiar\u00e1n del \u00edndice en este campo.</li> <li><code>INTENSIDAD_HORARIA</code> y <code>INTENSIDAD_HORARIA_SEMANAL</code>: Un \u00edndice compuesto en estos campos es \u00fatil para an\u00e1lisis o filtros relacionados con la carga horaria de los m\u00f3dulos.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_ID_PROGRAMA\nON Cedesarrollo.DIM_PLAN_CURRICULAR (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MODULO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_MODULO\nON Cedesarrollo.DIM_PLAN_CURRICULAR (MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_SEMESTRE\nON Cedesarrollo.DIM_PLAN_CURRICULAR (SEMESTRE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos INTENSIDAD_HORARIA y INTENSIDAD_HORARIA_SEMANAL\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_INTENSIDADES\nON Cedesarrollo.DIM_PLAN_CURRICULAR (INTENSIDAD_HORARIA, INTENSIDAD_HORARIA_SEMANAL);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_preguntas_cotizacion","title":"DIM_PREGUNTAS_COTIZACION","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>PREGUNTA</code>:    Facilita b\u00fasquedas y filtros basados en el texto de las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>OBSERVACIONES</code>:    Optimiza consultas que necesiten filtrar o analizar observaciones relacionadas con las preguntas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>PREGUNTA</code>: Este campo, al ser descriptivo, es probable que se utilice en consultas textuales para b\u00fasquedas directas o parciales de preguntas.</li> <li><code>OBSERVACIONES</code>: Aunque menos com\u00fan, este campo puede ser relevante en an\u00e1lisis que requieran obtener detalles adicionales relacionados con las preguntas, como comentarios o especificaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_COTIZACION_PREGUNTA\nON Cedesarrollo.DIM_PREGUNTAS_COTIZACION (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_COTIZACION_OBSERVACIONES\nON Cedesarrollo.DIM_PREGUNTAS_COTIZACION (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_programa","title":"DIM_PROGRAMA","text":"<ol> <li>\u00cdndice no cl\u00faster para el campo <code>PROGRAMA</code>:    Optimiza las b\u00fasquedas y filtros basados en el nombre o descripci\u00f3n del programa.</li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>PROGRAMA</code>: Al ser un campo descriptivo, es utilizado frecuentemente en b\u00fasquedas textuales o filtros para identificar programas espec\u00edficos.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PROGRAMA_NOMBRE\nON Cedesarrollo.DIM_PROGRAMA (PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_asistencia_act_bienestar","title":"FACT_ASISTENCIA_ACT_BIENESTAR","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza las consultas que involucren filtros o uniones basadas en fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora el rendimiento en consultas relacionadas con la asistencia de estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Dise\u00f1ado para b\u00fasquedas y filtros que combinen ambos campos como identificadores \u00fanicos del estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ACTIVIDAD</code>:    Facilita consultas y filtros basados en actividades espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ASISTIO</code>:    \u00datil para consultas relacionadas con el registro de asistencia.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>, <code>ID_ESTUDIANTE</code>, <code>ID_PERIODO</code>: Estos campos est\u00e1n com\u00fanmente relacionados con uniones y filtros en tablas de dimensi\u00f3n, optimizando las consultas frecuentes.</li> <li><code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>: Este \u00edndice compuesto permite b\u00fasquedas r\u00e1pidas utilizando estos identificadores \u00fanicos de los estudiantes.</li> <li><code>ACTIVIDAD</code> y <code>ASISTIO</code>: Estos \u00edndices optimizan an\u00e1lisis relacionados con las actividades y asistencia registrada en las mismas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ID_FECHA\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ID_ESTUDIANTE\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ID_PERIODO\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_TIPO_DOCUMENTO_DOCUMENTO\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ACTIVIDAD\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ACTIVIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ASISTIO\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ASISTIO\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ASISTIO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_ausentismo_docente","title":"FACT_AUSENTISMO_DOCENTE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora la eficiencia de las consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con el personal docente afectado por ausentismo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Dise\u00f1ado para mejorar el rendimiento en b\u00fasquedas por rangos de fechas relacionadas con ausencias.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO_AUSENCIA</code>:    Facilita consultas y an\u00e1lisis basados en el tipo de ausencia registrada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MOTIVO_AUSENCIA</code>:    Acelera consultas relacionadas con los motivos espec\u00edficos de las ausencias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_PERSONAL</code>, <code>ID_FECHA</code>: Estos campos son claves en uniones con tablas de dimensi\u00f3n y filtros comunes.</li> <li><code>FECHA_INICIO</code>, <code>FECHA_FIN</code>: Un \u00edndice compuesto en estos campos es crucial para b\u00fasquedas por rangos de fechas de ausencias.</li> <li><code>TIPO_AUSENCIA</code> y <code>MOTIVO_AUSENCIA</code>: Estos campos son \u00fatiles en an\u00e1lisis descriptivos o consultas sobre ausencias espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_PERIODO\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_PERSONAL\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_FECHA\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_FECHAS\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_TIPO_AUSENCIA\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (TIPO_AUSENCIA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_MOTIVO_AUSENCIA\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (MOTIVO_AUSENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_cotizaciones","title":"FACT_COTIZACIONES","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza las consultas basadas en fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Dise\u00f1ado para b\u00fasquedas r\u00e1pidas de cotizaciones basadas en la identificaci\u00f3n del estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora la eficiencia de consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_SERVICIO</code>:    Acelera consultas relacionadas con servicios espec\u00edficos asociados a las cotizaciones.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PREGUNTA</code>:    Facilita las b\u00fasquedas y an\u00e1lisis de cotizaciones basados en preguntas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO_COTIZACION</code>:    Mejora consultas relacionadas con los estados de las cotizaciones.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Campo clave en consultas basadas en tiempo y filtros por fechas.</li> <li><code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>: La identificaci\u00f3n compuesta de los estudiantes permite b\u00fasquedas precisas y r\u00e1pidas.</li> <li><code>ID_ESTUDIANTE</code>: Es esencial para relaciones y filtros basados en estudiantes espec\u00edficos.</li> <li><code>ID_SERVICIO</code>: Las consultas sobre servicios ofrecidos est\u00e1n directamente optimizadas con este \u00edndice.</li> <li><code>ID_PREGUNTA</code>: Facilita an\u00e1lisis espec\u00edficos relacionados con preguntas asociadas a cotizaciones.</li> <li><code>ESTADO_COTIZACION</code>: \u00datil para analizar y filtrar cotizaciones por sus estados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_FECHA\nON Cedesarrollo.FACT_COTIZACIONES (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_TIPO_DOCUMENTO_DOCUMENTO\nON Cedesarrollo.FACT_COTIZACIONES (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_ESTUDIANTE\nON Cedesarrollo.FACT_COTIZACIONES (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_SERVICIO\nON Cedesarrollo.FACT_COTIZACIONES (ID_SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_PREGUNTA\nON Cedesarrollo.FACT_COTIZACIONES (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO_COTIZACION\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ESTADO_COTIZACION\nON Cedesarrollo.FACT_COTIZACIONES (ESTADO_COTIZACION);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_desempenho_docente_ce","title":"FACT_DESEMPENHO_DOCENTE_CE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Mejora la eficiencia de consultas relacionadas con las unidades acad\u00e9micas asociadas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Optimiza las consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>CALIFICACION_ESTUDIANTES</code>, <code>CALIFICACION_UNIDAD</code> y <code>CALIFICACION_DOCENTE</code>:    Mejora el rendimiento en an\u00e1lisis relacionados con las calificaciones en los diferentes niveles.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO_CONTRATACION</code>:    Facilita las consultas basadas en el tipo de contrataci\u00f3n del personal docente.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>, <code>ID_PERSONAL</code>, <code>ID_PERIODO</code>: Estos campos son clave en uniones y filtros comunes en consultas relacionadas con dimensiones acad\u00e9micas y personal docente.</li> <li><code>CALIFICACION_ESTUDIANTES</code>, <code>CALIFICACION_UNIDAD</code>, <code>CALIFICACION_DOCENTE</code>: Este \u00edndice compuesto agiliza consultas anal\u00edticas y comparativas de calificaciones en diferentes categor\u00edas.</li> <li><code>TIPO_CONTRATACION</code>: \u00datil para an\u00e1lisis espec\u00edficos o filtros relacionados con las modalidades de contrataci\u00f3n.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_ID_UNIDAD\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_ID_PERSONAL\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_ID_PERIODO\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CALIFICACION_ESTUDIANTES, CALIFICACION_UNIDAD y CALIFICACION_DOCENTE\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_CALIFICACIONES\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (CALIFICACION_ESTUDIANTES, CALIFICACION_UNIDAD, CALIFICACION_DOCENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_CONTRATACION\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_TIPO_CONTRATACION\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (TIPO_CONTRATACION);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_desempenho_docente_de","title":"FACT_DESEMPENHO_DOCENTE_DE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Optimiza consultas relacionadas con las unidades acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Mejora b\u00fasquedas relacionadas con el desempe\u00f1o de docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>:    Optimiza b\u00fasquedas que combinen ambos campos para identificar encuestados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora el rendimiento en consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>PROGRAMA</code>:    Facilita b\u00fasquedas y an\u00e1lisis basados en programas acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CALIFICACION</code>:    Acelera consultas relacionadas con el an\u00e1lisis de calificaciones.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>, <code>ID_PERSONAL</code>, <code>ID_PERIODO</code>: Son claves en consultas relacionadas con las dimensiones acad\u00e9micas y personal docente.</li> <li><code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>: Un \u00edndice compuesto asegura b\u00fasquedas r\u00e1pidas y precisas de encuestados.</li> <li><code>ID_FECHA</code>: Este \u00edndice es esencial para optimizar consultas relacionadas con tiempo y filtros por fechas.</li> <li><code>PROGRAMA</code> y <code>CALIFICACION</code>: Estos \u00edndices mejoran el an\u00e1lisis y filtrado por programas y desempe\u00f1o en las evaluaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_UNIDAD\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_PERSONAL\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_PERIODO\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO_ENCUESTADO y DOCUMENTO_ENCUESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_DOCUMENTO_ENCUESTADO\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (TIPO_DOCUMENTO_ENCUESTADO, DOCUMENTO_ENCUESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_FECHA\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_PROGRAMA\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_CALIFICACION\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (CALIFICACION);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_desercion","title":"FACT_DESERCION","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera consultas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza el rendimiento en consultas basadas en fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO</code>:    Facilita consultas y an\u00e1lisis relacionados con el tipo de deserci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CAUSA</code>:    Acelera b\u00fasquedas relacionadas con las causas de deserci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Mejora consultas relacionadas con los semestres afectados por la deserci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_JORNADA</code>, <code>ID_ESTUDIANTE</code>, <code>ID_FECHA</code>: Estos campos son claves en consultas comunes relacionadas con per\u00edodos, jornadas, estudiantes y fechas.</li> <li><code>TIPO</code> y <code>CAUSA</code>: Son fundamentales para an\u00e1lisis descriptivos y consultas relacionadas con categor\u00edas de deserci\u00f3n.</li> <li><code>SEMESTRE</code>: Optimiza consultas espec\u00edficas sobre semestres impactados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_PERIODO\nON Cedesarrollo.FACT_DESERCION (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_JORNADA\nON Cedesarrollo.FACT_DESERCION (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_ESTUDIANTE\nON Cedesarrollo.FACT_DESERCION (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_FECHA\nON Cedesarrollo.FACT_DESERCION (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_TIPO\nON Cedesarrollo.FACT_DESERCION (TIPO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CAUSA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_CAUSA\nON Cedesarrollo.FACT_DESERCION (CAUSA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_SEMESTRE\nON Cedesarrollo.FACT_DESERCION (SEMESTRE);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_estado_matriculas","title":"FACT_ESTADO_MATRICULAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Optimiza las b\u00fasquedas relacionadas con programas acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera consultas basadas en jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Facilita b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora el rendimiento en consultas relacionadas con fechas de matr\u00edcula.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TELEFONO</code>, <code>CELULAR</code> y <code>CORREO</code>:    Acelera b\u00fasquedas o filtros relacionados con informaci\u00f3n de contacto.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Facilita consultas basadas en el semestre acad\u00e9mico.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>DOCUMENTOS_COMPLETOS</code>:    Mejora b\u00fasquedas relacionadas con el estado de documentaci\u00f3n de los estudiantes.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_PROGRAMA</code>, <code>ID_JORNADA</code>, <code>ID_ESTUDIANTE</code>, <code>ID_FECHA</code>: Campos clave para uniones y filtros en consultas frecuentes relacionadas con dimensiones acad\u00e9micas y estudiantes.</li> <li><code>TELEFONO</code>, <code>CELULAR</code>, <code>CORREO</code>: Facilitan an\u00e1lisis y consultas basadas en datos de contacto de los estudiantes.</li> <li><code>SEMESTRE</code> y <code>DOCUMENTOS_COMPLETOS</code>: Optimizan an\u00e1lisis espec\u00edficos de estado y organizaci\u00f3n acad\u00e9mica.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_PERIODO\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_PROGRAMA\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_JORNADA\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_FECHA\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TELEFONO, CELULAR y CORREO\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_CONTACTO\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (TELEFONO, CELULAR, CORREO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_SEMESTRE\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (SEMESTRE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTOS_COMPLETOS\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_DOCUMENTOS_COMPLETOS\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (DOCUMENTOS_COMPLETOS);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_evaluacion_formacion","title":"FACT_EVALUACION_FORMACION","text":"<ol> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>:    Mejora la eficiencia de b\u00fasquedas basadas en la identificaci\u00f3n del encuestado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_SERVICIO</code>:    Acelera consultas relacionadas con servicios espec\u00edficos evaluados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>FECHA_REALIZACION_EVENTO</code>:    Optimiza consultas basadas en la fecha de realizaci\u00f3n de los eventos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>ASPECTO_1</code> a <code>ASPECTO_9</code>:    Facilita an\u00e1lisis y b\u00fasquedas relacionadas con las evaluaciones de m\u00faltiples aspectos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>: Permiten identificar de manera eficiente al encuestado en consultas combinadas.</li> <li><code>ID_SERVICIO</code>: Es clave para filtrar o analizar evaluaciones basadas en servicios espec\u00edficos.</li> <li><code>FECHA_REALIZACION_EVENTO</code>: Facilita consultas relacionadas con el an\u00e1lisis temporal de las evaluaciones.</li> <li><code>ASPECTO_1</code> a <code>ASPECTO_9</code>: Estos campos son cr\u00edticos para an\u00e1lisis descriptivos y de calidad en evaluaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO_ENCUESTADO y DOCUMENTO_ENCUESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_DOCUMENTO_ENCUESTADO\nON Cedesarrollo.FACT_EVALUACION_FORMACION (TIPO_DOCUMENTO_ENCUESTADO, DOCUMENTO_ENCUESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_ID_SERVICIO\nON Cedesarrollo.FACT_EVALUACION_FORMACION (ID_SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_REALIZACION_EVENTO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_FECHA_REALIZACION_EVENTO\nON Cedesarrollo.FACT_EVALUACION_FORMACION (FECHA_REALIZACION_EVENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ASPECTO_1 a ASPECTO_9\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_ASPECTOS\nON Cedesarrollo.FACT_EVALUACION_FORMACION (ASPECTO_1, ASPECTO_2, ASPECTO_3, ASPECTO_4, ASPECTO_5, ASPECTO_6, ASPECTO_7, ASPECTO_8, ASPECTO_9);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_evaluacion_plan_curricular","title":"FACT_EVALUACION_PLAN_CURRICULAR","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Optimiza consultas relacionadas con unidades acad\u00e9micas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera b\u00fasquedas y an\u00e1lisis relacionados con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CALIFICACION</code>:    Mejora el rendimiento en consultas basadas en las calificaciones asignadas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>OBSERVACIONES</code>:    Facilita b\u00fasquedas relacionadas con comentarios o notas adicionales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>: Este \u00edndice es esencial para optimizar consultas relacionadas con la evaluaci\u00f3n de unidades acad\u00e9micas espec\u00edficas.</li> <li><code>ID_PERIODO</code>: Clave en an\u00e1lisis temporales y filtros basados en per\u00edodos acad\u00e9micos.</li> <li><code>CALIFICACION</code>: Facilita consultas relacionadas con m\u00e9tricas de desempe\u00f1o o an\u00e1lisis de resultados.</li> <li><code>OBSERVACIONES</code>: \u00datil para b\u00fasquedas y an\u00e1lisis de comentarios asociados con las evaluaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_ID_UNIDAD\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_ID_PERIODO\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_CALIFICACION\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (CALIFICACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_OBSERVACIONES\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_facturacion","title":"FACT_FACTURACION","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO_PAGO</code> y <code>DOCUMENTO_PAGO</code>:    Acelera b\u00fasquedas relacionadas con las identificaciones de los pagadores.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora consultas basadas en fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_SERVICIO</code>:    Facilita an\u00e1lisis relacionados con servicios facturados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_CONCEPTO</code>:    Optimiza consultas basadas en conceptos espec\u00edficos de facturaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO_PAGO</code>:    Mejora consultas relacionadas con el estado de los pagos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>NO_RECIBO</code>:    Facilita b\u00fasquedas espec\u00edficas por n\u00famero de recibo.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_FECHA</code>: Estos \u00edndices son esenciales para optimizar an\u00e1lisis temporales y b\u00fasquedas relacionadas con per\u00edodos y fechas espec\u00edficas.</li> <li><code>TIPO_DOCUMENTO_PAGO</code>, <code>DOCUMENTO_PAGO</code>: Permiten identificar de manera eficiente a los pagadores.</li> <li><code>ID_SERVICIO</code>, <code>ID_CONCEPTO</code>: Facilitan consultas espec\u00edficas sobre servicios y conceptos facturados.</li> <li><code>ESTADO_PAGO</code>, <code>NO_RECIBO</code>: Son claves para b\u00fasquedas relacionadas con el seguimiento de pagos y recibos.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_PERIODO\nON Cedesarrollo.FACT_FACTURACION (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO_PAGO y DOCUMENTO_PAGO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_DOCUMENTO_PAGO\nON Cedesarrollo.FACT_FACTURACION (TIPO_DOCUMENTO_PAGO, DOCUMENTO_PAGO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_FECHA\nON Cedesarrollo.FACT_FACTURACION (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_SERVICIO\nON Cedesarrollo.FACT_FACTURACION (ID_SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CONCEPTO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_CONCEPTO\nON Cedesarrollo.FACT_FACTURACION (ID_CONCEPTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO_PAGO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ESTADO_PAGO\nON Cedesarrollo.FACT_FACTURACION (ESTADO_PAGO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NO_RECIBO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_NO_RECIBO\nON Cedesarrollo.FACT_FACTURACION (NO_RECIBO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_graduados","title":"FACT_GRADUADOS","text":"<ol> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Optimiza b\u00fasquedas relacionadas con la identificaci\u00f3n de los graduados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Facilita b\u00fasquedas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Optimiza consultas basadas en programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>FECHA_GRADUADO</code>:    Mejora el rendimiento de consultas basadas en la fecha de graduaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO</code>:    Facilita an\u00e1lisis relacionados con el estado de los graduados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ZONA</code>:    Acelera b\u00fasquedas relacionadas con la zona geogr\u00e1fica de los graduados.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ID_ESTUDIANTE</code>: Claves esenciales para identificar y consultar informaci\u00f3n espec\u00edfica de los graduados.</li> <li><code>ID_PERIODO</code>, <code>ID_JORNADA</code>, <code>ID_PROGRAMA</code>: Estos \u00edndices optimizan consultas relacionadas con dimensiones acad\u00e9micas clave.</li> <li><code>FECHA_GRADUADO</code>: Facilita el an\u00e1lisis temporal de las graduaciones.</li> <li><code>ESTADO</code>, <code>ZONA</code>: Estos \u00edndices son \u00fatiles para an\u00e1lisis geogr\u00e1ficos y de estado del graduado.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_DOCUMENTO\nON Cedesarrollo.FACT_GRADUADOS (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_GRADUADOS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_PERIODO\nON Cedesarrollo.FACT_GRADUADOS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_JORNADA\nON Cedesarrollo.FACT_GRADUADOS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_PROGRAMA\nON Cedesarrollo.FACT_GRADUADOS (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_GRADUADO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_FECHA_GRADUADO\nON Cedesarrollo.FACT_GRADUADOS (FECHA_GRADUADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ESTADO\nON Cedesarrollo.FACT_GRADUADOS (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ZONA\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ZONA\nON Cedesarrollo.FACT_GRADUADOS (ZONA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_horario","title":"FACT_HORARIO","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora el rendimiento en consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_MODULO</code>:    Optimiza consultas relacionadas con m\u00f3dulos espec\u00edficos del plan curricular.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera b\u00fasquedas basadas en jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Facilita consultas relacionadas con docentes asignados al horario.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Optimiza an\u00e1lisis relacionados con horarios organizados por semestre.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>DIA</code>:    Mejora consultas relacionadas con horarios organizados por d\u00edas espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>HORA_INICIO</code> y <code>HORA_FIN</code>:    Facilita an\u00e1lisis y consultas basadas en intervalos horarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>COD_ESTABLECIMIENTO</code>:    Acelera b\u00fasquedas espec\u00edficas por c\u00f3digo de establecimiento.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_MODULO</code>, <code>ID_JORNADA</code>, <code>ID_PERSONAL</code>: Estos campos son claves para optimizar consultas relacionadas con dimensiones acad\u00e9micas y personal.</li> <li><code>SEMESTRE</code>, <code>DIA</code>: Facilitan el an\u00e1lisis de horarios basados en organizaci\u00f3n acad\u00e9mica y d\u00edas espec\u00edficos.</li> <li><code>HORA_INICIO</code>, <code>HORA_FIN</code>: Un \u00edndice compuesto en estos campos mejora an\u00e1lisis de intervalos horarios.</li> <li><code>COD_ESTABLECIMIENTO</code>: Este \u00edndice permite b\u00fasquedas eficientes en consultas relacionadas con ubicaciones espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_PERIODO\nON Cedesarrollo.FACT_HORARIO (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_MODULO\nON Cedesarrollo.FACT_HORARIO (ID_MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_JORNADA\nON Cedesarrollo.FACT_HORARIO (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_PERSONAL\nON Cedesarrollo.FACT_HORARIO (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_SEMESTRE\nON Cedesarrollo.FACT_HORARIO (SEMESTRE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DIA\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_DIA\nON Cedesarrollo.FACT_HORARIO (DIA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos HORA_INICIO y HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_HORAS\nON Cedesarrollo.FACT_HORARIO (HORA_INICIO, HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_ESTABLECIMIENTO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_COD_ESTABLECIMIENTO\nON Cedesarrollo.FACT_HORARIO (COD_ESTABLECIMIENTO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_inasistencias","title":"FACT_INASISTENCIAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Optimiza consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera b\u00fasquedas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>DOCUMENTO</code>:    Facilita b\u00fasquedas basadas en la identificaci\u00f3n del estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Mejora el rendimiento en consultas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_MODULO</code>:    Optimiza b\u00fasquedas relacionadas con m\u00f3dulos espec\u00edficos del plan curricular.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora el rendimiento en consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>CURSO</code> y <code>CORTE</code>:    Facilita an\u00e1lisis y b\u00fasquedas relacionadas con cursos y cortes acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TOTAL_INASISTENCIA</code>:    Optimiza an\u00e1lisis basados en la cantidad total de inasistencias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTUDIANTE</code>, <code>DOCUMENTO</code>, <code>ID_PERIODO</code>: Claves principales para identificar estudiantes y sus per\u00edodos relacionados con inasistencias.</li> <li><code>ID_JORNADA</code>, <code>ID_MODULO</code>, <code>ID_FECHA</code>: Campos clave para consultas relacionadas con dimensiones acad\u00e9micas y temporales.</li> <li><code>CURSO</code>, <code>CORTE</code>: Un \u00edndice compuesto facilita b\u00fasquedas organizadas por estructura acad\u00e9mica.</li> <li><code>TOTAL_INASISTENCIA</code>: Es clave para an\u00e1lisis y m\u00e9tricas sobre inasistencias totales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_INASISTENCIAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_PERIODO\nON Cedesarrollo.FACT_INASISTENCIAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_DOCUMENTO\nON Cedesarrollo.FACT_INASISTENCIAS (DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_JORNADA\nON Cedesarrollo.FACT_INASISTENCIAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_MODULO\nON Cedesarrollo.FACT_INASISTENCIAS (ID_MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_FECHA\nON Cedesarrollo.FACT_INASISTENCIAS (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CURSO y CORTE\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_CURSO_CORTE\nON Cedesarrollo.FACT_INASISTENCIAS (CURSO, CORTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TOTAL_INASISTENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_TOTAL_INASISTENCIA\nON Cedesarrollo.FACT_INASISTENCIAS (TOTAL_INASISTENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_inscripcion_matriculas","title":"FACT_INSCRIPCION_MATRICULAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora el rendimiento en consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Optimiza b\u00fasquedas relacionadas con programas acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Facilita an\u00e1lisis y b\u00fasquedas basadas en fechas de inscripci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Mejora consultas relacionadas con jornadas acad\u00e9micas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Acelera b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO</code>:    Facilita an\u00e1lisis y b\u00fasquedas relacionadas con el estado de las inscripciones.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO_ESTUDIANTE</code>:    Mejora el rendimiento de consultas basadas en las categor\u00edas de tipo de estudiante.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>CATEGORIA_COBERTURA</code> y <code>CATEGORIA_SUBSIDIO</code>:    Optimiza an\u00e1lisis y b\u00fasquedas relacionadas con la cobertura y subsidios.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_PROGRAMA</code>, <code>ID_FECHA</code>, <code>ID_JORNADA</code>, <code>ID_ESTUDIANTE</code>: Estos \u00edndices son claves para optimizar consultas frecuentes relacionadas con dimensiones acad\u00e9micas y temporales.</li> <li><code>ESTADO</code>, <code>TIPO_ESTUDIANTE</code>: Facilitan an\u00e1lisis descriptivos y filtros en el estado y tipo de estudiante inscrito.</li> <li><code>CATEGORIA_COBERTURA</code>, <code>CATEGORIA_SUBSIDIO</code>: Un \u00edndice compuesto mejora an\u00e1lisis detallados relacionados con subsidios y coberturas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_PERIODO\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_PROGRAMA\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_FECHA\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_JORNADA\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ESTADO\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_TIPO_ESTUDIANTE\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (TIPO_ESTUDIANTE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CATEGORIA_COBERTURA y CATEGORIA_SUBSIDIO\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_CATEGORIAS\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (CATEGORIA_COBERTURA, CATEGORIA_SUBSIDIO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_notas","title":"FACT_NOTAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera b\u00fasquedas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_MODULO</code>:    Optimiza consultas relacionadas con m\u00f3dulos del plan curricular.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora el rendimiento en consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Facilita an\u00e1lisis relacionados con docentes asignados a los cursos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Optimiza b\u00fasquedas basadas en intervalos temporales para analizar notas en per\u00edodos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>NOTA_FINAL</code>:    Mejora consultas relacionadas con an\u00e1lisis de desempe\u00f1o acad\u00e9mico.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>PRIMER_CORTE</code>, <code>SEGUNDO_CORTE</code> y <code>TERCER_CORTE</code>:    Facilita an\u00e1lisis detallados de las notas por cortes acad\u00e9micos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTUDIANTE</code>, <code>ID_JORNADA</code>, <code>ID_MODULO</code>, <code>ID_PERIODO</code>, <code>ID_PERSONAL</code>: Claves esenciales para optimizar consultas frecuentes relacionadas con dimensiones acad\u00e9micas y estudiantes.</li> <li><code>FECHA_INICIO</code>, <code>FECHA_FIN</code>: Cruciales para an\u00e1lisis temporales y segmentaci\u00f3n de notas.</li> <li><code>NOTA_FINAL</code>: Facilita an\u00e1lisis de resultados globales de los estudiantes.</li> <li><code>PRIMER_CORTE</code>, <code>SEGUNDO_CORTE</code>, <code>TERCER_CORTE</code>: Un \u00edndice compuesto mejora el an\u00e1lisis de desempe\u00f1o por cortes.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_NOTAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_JORNADA\nON Cedesarrollo.FACT_NOTAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_MODULO\nON Cedesarrollo.FACT_NOTAS (ID_MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_PERIODO\nON Cedesarrollo.FACT_NOTAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_PERSONAL\nON Cedesarrollo.FACT_NOTAS (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_FECHAS\nON Cedesarrollo.FACT_NOTAS (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOTA_FINAL\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_NOTA_FINAL\nON Cedesarrollo.FACT_NOTAS (NOTA_FINAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_CORTE, SEGUNDO_CORTE y TERCER_CORTE\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_CORTES\nON Cedesarrollo.FACT_NOTAS (PRIMER_CORTE, SEGUNDO_CORTE, TERCER_CORTE);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_permiso_estudiante","title":"FACT_PERMISO_ESTUDIANTE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>    Facilita las consultas y filtros relacionados con permisos de estudiantes espec\u00edficos, as\u00ed como uniones con la tabla de dimensiones [DIM_ESTUDIANTES].</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>    Optimiza el rendimiento en consultas que agrupan o filtran los datos por per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>    Mejora el acceso a los registros relacionados con fechas espec\u00edficas, especialmente en an\u00e1lisis cronol\u00f3gicos o uniones con la tabla de dimensi\u00f3n [DIM_TIEMPO].</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MODULO</code>    Acelera las consultas que necesitan identificar m\u00f3dulos asociados con los permisos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MOTIVO_AUSENCIA</code>    Facilita el an\u00e1lisis y b\u00fasqueda de registros basados en las razones de ausencia.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SOPORTE_AUSENCIA</code>    Optimiza las b\u00fasquedas relacionadas con documentos o justificaciones de las ausencias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTUDIANTE</code>: Usualmente, las consultas incluyen uniones con la tabla de estudiantes o filtros para permisos espec\u00edficos de un estudiante.</li> <li><code>ID_PERIODO</code>: Este campo es clave para an\u00e1lisis por per\u00edodos acad\u00e9micos o tendencias relacionadas con ausencias en un per\u00edodo.</li> <li><code>ID_FECHA</code>: Al ser un campo relacionado con fechas, permite optimizar consultas que buscan patrones temporales o filtros de rangos.</li> <li><code>MODULO</code>: Las ausencias pueden ser analizadas en relaci\u00f3n con m\u00f3dulos espec\u00edficos, haciendo relevante este \u00edndice.</li> <li><code>MOTIVO_AUSENCIA</code>: Es \u00fatil para an\u00e1lisis descriptivos o categorizaci\u00f3n de razones de ausencias.</li> <li><code>SOPORTE_AUSENCIA</code>: Permite identificar r\u00e1pidamente los registros asociados con un tipo espec\u00edfico de soporte.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_ESTUDIANTE\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_PERIODO\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_FECHA\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_MODULO\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_MOTIVO_AUSENCIA\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (MOTIVO_AUSENCIA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SOPORTE_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_SOPORTE_AUSENCIA\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (SOPORTE_AUSENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_plan_cobertura","title":"FACT_PLAN_COBERTURA","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>    Optimiza consultas y an\u00e1lisis relacionados con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>    Mejora el rendimiento de las consultas asociadas a las unidades que forman parte del plan de cobertura.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>    Facilita las b\u00fasquedas y uniones relacionadas con programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MODALIDAD</code>    Acelera consultas que involucren an\u00e1lisis o filtrados por modalidades del plan.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CATEGORIA</code>    Optimiza b\u00fasquedas y agrupaciones relacionadas con categor\u00edas espec\u00edficas dentro del plan.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>USOS_PROYECTADOS</code> y <code>USUARIOS_PROYECTADOS</code>    Mejora el rendimiento de las consultas y an\u00e1lisis basados en las proyecciones de uso y usuarios.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>: Es clave en las relaciones con per\u00edodos acad\u00e9micos y permite optimizar consultas agrupadas o filtradas por per\u00edodos.</li> <li><code>ID_UNIDAD</code>: Asociado a las unidades del plan, es crucial para consultas sobre cobertura por unidad.</li> <li><code>ID_PROGRAMA</code>: Facilita las consultas relacionadas con los programas que componen el plan.</li> <li><code>MODALIDAD</code> y <code>CATEGORIA</code>: Campos descriptivos frecuentemente usados en filtros y an\u00e1lisis de agrupaci\u00f3n.</li> <li><code>USOS_PROYECTADOS</code> y <code>USUARIOS_PROYECTADOS</code>: Los \u00edndices compuestos en estos campos son \u00fatiles para an\u00e1lisis combinados de las proyecciones de uso y usuarios.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_PERIODO\nON Cedesarrollo.FACT_PLAN_COBERTURA (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_UNIDAD\nON Cedesarrollo.FACT_PLAN_COBERTURA (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_PROGRAMA\nON Cedesarrollo.FACT_PLAN_COBERTURA (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MODALIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_MODALIDAD\nON Cedesarrollo.FACT_PLAN_COBERTURA (MODALIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_CATEGORIA\nON Cedesarrollo.FACT_PLAN_COBERTURA (CATEGORIA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos USOS_PROYECTADOS y USUARIOS_PROYECTADOS\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_PROYECCIONES\nON Cedesarrollo.FACT_PLAN_COBERTURA (USOS_PROYECTADOS, USUARIOS_PROYECTADOS);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/","title":"07.Index Colegio","text":""},{"location":"01.scripts/07.Index_Colegio/#indices-colegio","title":"\u00cdndices Colegio","text":""},{"location":"01.scripts/07.Index_Colegio/#dim_anio_academico","title":"DIM_ANIO_ACADEMICO","text":"<ol> <li>\u00cdndice cl\u00faster existente para <code>ANIO_ACADEMICO</code> (PRIMARY KEY):    Este \u00edndice asegura acceso eficiente y ordenado mediante el identificador \u00fanico de cada a\u00f1o acad\u00e9mico.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ANIO_ACADEMICO\n-- (No requiere creaci\u00f3n adicional)\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_curso","title":"DIM_CURSO","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CURSO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de cada curso.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DESC_CURSO</code>:    Facilita b\u00fasquedas relacionadas con descripciones de cursos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>:    Optimiza consultas relacionadas con el estado de los cursos y su fecha de creaci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CURSO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>DESC_CURSO</code>: Mejora el rendimiento en b\u00fasquedas textuales.</li> <li><code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>: Mejora an\u00e1lisis combinados por estado y fecha.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CURSO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DESC_CURSO\nCREATE NONCLUSTERED INDEX IX_DIM_CURSO_DESC_CURSO\nON [Colegio].[DIM_CURSO] (DESC_CURSO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para ESTADO_REGISTRO y FECHA_CREACION\nCREATE NONCLUSTERED INDEX IX_DIM_CURSO_ESTADO_FECHA\nON [Colegio].[DIM_CURSO] (ESTADO_REGISTRO, FECHA_CREACION);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_grado","title":"DIM_GRADO","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_GRADO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DESC_GRADO</code>:    Facilita b\u00fasquedas relacionadas con descripciones de grados.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>:    Optimiza consultas combinadas por estado y fecha.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_GRADO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>DESC_GRADO</code>: Mejora el rendimiento en b\u00fasquedas textuales.</li> <li><code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>: Mejora an\u00e1lisis combinados por estado y fecha.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_GRADO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DESC_GRADO\nCREATE NONCLUSTERED INDEX IX_DIM_GRADO_DESC_GRADO\nON [Colegio].[DIM_GRADO] (DESC_GRADO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para ESTADO_REGISTRO y FECHA_CREACION\nCREATE NONCLUSTERED INDEX IX_DIM_GRADO_ESTADO_FECHA\nON [Colegio].[DIM_GRADO] (ESTADO_REGISTRO, FECHA_CREACION);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_libros","title":"DIM_LIBROS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_LIBRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_LIBRO</code>:    Mejora b\u00fasquedas relacionadas con el nombre del libro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>AUTOR</code>:    Optimiza consultas relacionadas con autores.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>NOMBRE_LIBRO</code> y <code>AUTOR</code>:    Mejora b\u00fasquedas combinadas por nombre y autor.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_LIBRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>NOMBRE_LIBRO</code>: Mejora b\u00fasquedas textuales relacionadas con los libros.</li> <li><code>AUTOR</code>: Optimiza b\u00fasquedas textuales relacionadas con autores.</li> <li><code>NOMBRE_LIBRO</code> y <code>AUTOR</code>: Mejora an\u00e1lisis combinados por nombre y autor.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_LIBRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_LIBRO\nCREATE NONCLUSTERED INDEX IX_DIM_LIBROS_NOMBRE_LIBRO\nON [Colegio].[DIM_LIBROS] (NOMBRE_LIBRO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo AUTOR\nCREATE NONCLUSTERED INDEX IX_DIM_LIBROS_AUTOR\nON [Colegio].[DIM_LIBROS] (AUTOR);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para NOMBRE_LIBRO y AUTOR\nCREATE NONCLUSTERED INDEX IX_DIM_LIBROS_NOMBRE_AUTOR\nON [Colegio].[DIM_LIBROS] (NOMBRE_LIBRO, AUTOR);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_plan_curricular","title":"DIM_PLAN_CURRICULAR","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_ASIGNATURA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de las asignaturas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Optimiza b\u00fasquedas relacionadas con cursos y uniones con la tabla [DIM_CURSO].</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos y uniones con la tabla [DIM_ANIO_ACADEMICO].</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PERIODO</code> y <code>GRADO</code>:    Facilita an\u00e1lisis combinados por per\u00edodo y grado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>INTENSIDAD_HORARIA</code>:    Mejora consultas relacionadas con la intensidad horaria de las asignaturas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ASIGNATURA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_CURSO</code>: Optimiza consultas relacionadas con los cursos.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en consultas por a\u00f1os acad\u00e9micos.</li> <li><code>PERIODO</code> y <code>GRADO</code>: Facilita an\u00e1lisis combinados relacionados con per\u00edodos y grados.</li> <li><code>INTENSIDAD_HORARIA</code>: Acelera b\u00fasquedas relacionadas con este atributo.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_ASIGNATURA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_ID_CURSO\nON [Colegio].[DIM_PLAN_CURRICULAR] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_ANIO_ACADEMICO\nON [Colegio].[DIM_PLAN_CURRICULAR] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para PERIODO y GRADO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_PERIODO_GRADO\nON [Colegio].[DIM_PLAN_CURRICULAR] (PERIODO, GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo INTENSIDAD_HORARIA\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_INTENSIDAD\nON [Colegio].[DIM_PLAN_CURRICULAR] (INTENSIDAD_HORARIA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_poblacion_matricula","title":"DIM_POBLACION_MATRICULA","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_POBLACION_MATRICULA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de la poblaci\u00f3n matriculada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PARTNER</code>:    Optimiza b\u00fasquedas relacionadas con socios o identificadores externos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code>:    Mejora b\u00fasquedas relacionadas con documentos de identificaci\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>GENERO</code> y <code>FECHA_NACIMIENTO</code>:    Facilita an\u00e1lisis demogr\u00e1ficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code>:    Mejora consultas relacionadas con direcciones de correo electr\u00f3nico.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_POBLACION_MATRICULA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>PARTNER</code>: Mejora b\u00fasquedas relacionadas con identificadores externos.</li> <li><code>DOCUMENTO</code>: Optimiza consultas relacionadas con identificadores \u00fanicos de estudiantes.</li> <li><code>GENERO</code> y <code>FECHA_NACIMIENTO</code>: Facilita an\u00e1lisis demogr\u00e1ficos y de grupos etarios.</li> <li><code>CORREO</code>: Acelera b\u00fasquedas relacionadas con direcciones de correo.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_POBLACION_MATRICULA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PARTNER\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_PARTNER\nON [Colegio].[DIM_POBLACION_MATRICULA] (PARTNER);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_DOCUMENTO\nON [Colegio].[DIM_POBLACION_MATRICULA] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para GENERO y FECHA_NACIMIENTO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_GENERO_FECHA\nON [Colegio].[DIM_POBLACION_MATRICULA] (GENERO, FECHA_NACIMIENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_CORREO\nON [Colegio].[DIM_POBLACION_MATRICULA] (CORREO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_ausentismo_docente","title":"FACT_AUSENTISMO_DOCENTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_AUSENTISMO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de cada registro de ausentismo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Mejora consultas relacionadas con docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza b\u00fasquedas por a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Mejora consultas relacionadas con per\u00edodos de ausencia.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_AUSENCIA</code>:    Acelera b\u00fasquedas relacionadas con tipos espec\u00edficos de ausencia.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_AUSENTISMO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_PERSONAL</code>: Facilita b\u00fasquedas por docente.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_FECHA</code>: Optimiza consultas espec\u00edficas por fechas.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Facilita an\u00e1lisis por rangos de fechas.</li> <li><code>TIPO_AUSENCIA</code>: Mejora b\u00fasquedas categ\u00f3ricas por tipo de ausencia.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_AUSENTISMO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_PERSONAL\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ANIO_ACADEMICO\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_FECHA\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_FECHAS\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_TIPO_AUSENCIA\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (TIPO_AUSENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_biblioteca","title":"FACT_BIBLIOTECA","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de biblioteca.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Mejora consultas relacionadas con personal asociado a registros de biblioteca.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_LIBRO</code>:    Facilita b\u00fasquedas relacionadas con libros espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza consultas por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_PRESTAMO</code>, <code>FECHA_VENCIMIENTO</code> y <code>FECHA_ENTREGA</code>:    Mejora an\u00e1lisis relacionados con el ciclo de pr\u00e9stamo de libros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>BIBLIOTECA</code>:    Mejora consultas relacionadas con nombres de bibliotecas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Optimiza uniones y consultas relacionadas con estudiantes.</li> <li><code>ID_PERSONAL</code>: Mejora b\u00fasquedas por personal responsable.</li> <li><code>ID_LIBRO</code>: Facilita consultas relacionadas con libros espec\u00edficos.</li> <li><code>ID_FECHA</code>: Acelera an\u00e1lisis por fechas.</li> <li><code>FECHA_PRESTAMO</code>, <code>FECHA_VENCIMIENTO</code> y <code>FECHA_ENTREGA</code>: Mejora rendimiento en an\u00e1lisis temporales de pr\u00e9stamos.</li> <li><code>BIBLIOTECA</code>: Acelera b\u00fasquedas categ\u00f3ricas por nombre de biblioteca.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_POBLACION\nON [Colegio].[FACT_BIBLIOTECA] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_PERSONAL\nON [Colegio].[FACT_BIBLIOTECA] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_LIBRO\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_LIBRO\nON [Colegio].[FACT_BIBLIOTECA] (ID_LIBRO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_FECHA\nON [Colegio].[FACT_BIBLIOTECA] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_PRESTAMO, FECHA_VENCIMIENTO y FECHA_ENTREGA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_FECHAS\nON [Colegio].[FACT_BIBLIOTECA] (FECHA_PRESTAMO, FECHA_VENCIMIENTO, FECHA_ENTREGA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo BIBLIOTECA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_BIBLIOTECA\nON [Colegio].[FACT_BIBLIOTECA] (BIBLIOTECA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_biblioteca_virtual","title":"FACT_BIBLIOTECA_VIRTUAL","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de biblioteca virtual.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Mejora consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Optimiza b\u00fasquedas relacionadas con personal asociado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Optimiza consultas relacionadas con per\u00edodos de uso de la biblioteca virtual.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ACTIVIDAD</code>:    Mejora b\u00fasquedas relacionadas con actividades espec\u00edficas realizadas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita uniones con la dimensi\u00f3n de poblaci\u00f3n matriculada.</li> <li><code>ID_PERSONAL</code>: Mejora b\u00fasquedas relacionadas con personal responsable.</li> <li><code>ID_FECHA</code>: Acelera consultas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Facilita an\u00e1lisis temporales sobre per\u00edodos de uso.</li> <li><code>ACTIVIDAD</code>: Optimiza b\u00fasquedas relacionadas con actividades espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ID_POBLACION\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ID_PERSONAL\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ID_FECHA\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ANIO_ACADEMICO\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_FECHAS\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ACTIVIDAD\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ACTIVIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_desempenho_docente","title":"FACT_DESEMPENHO_DOCENTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de desempe\u00f1o docente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Optimiza b\u00fasquedas relacionadas con docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>ID_PERSONAL</code>:    Mejora b\u00fasquedas combinadas por fecha y docente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TOTAL_GENERAL</code>:    Optimiza consultas relacionadas con calificaciones totales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_PERSONAL</code>: Facilita b\u00fasquedas por docente.</li> <li><code>ANIO_ACADEMICO</code>: Mejora rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_FECHA</code>: Acelera an\u00e1lisis por fechas espec\u00edficas.</li> <li><code>FECHA</code> y <code>ID_PERSONAL</code>: Mejora an\u00e1lisis combinados por fecha y docente.</li> <li><code>TOTAL_GENERAL</code>: Optimiza b\u00fasquedas relacionadas con el desempe\u00f1o total.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_ID_PERSONAL\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_ANIO_ACADEMICO\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_ID_FECHA\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_FECHA_PERSONAL\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (FECHA, ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TOTAL_GENERAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_TOTAL_GENERAL\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (TOTAL_GENERAL);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_enfermeria","title":"FACT_ENFERMERIA","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CASO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada caso de enfermer\u00eda.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>:    Optimiza b\u00fasquedas relacionadas con los rangos temporales de los casos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO</code>:    Acelera b\u00fasquedas relacionadas con estados espec\u00edficos del caso.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CAUSA_ACCIDENTE</code>:    Mejora consultas relacionadas con las causas de accidentes reportados.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CASO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita uniones y b\u00fasquedas relacionadas con estudiantes.</li> <li><code>ID_FECHA</code>: Mejora el rendimiento en an\u00e1lisis por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Optimiza b\u00fasquedas por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>: Acelera an\u00e1lisis relacionados con los per\u00edodos de atenci\u00f3n y soluci\u00f3n.</li> <li><code>ESTADO</code>: Facilita b\u00fasquedas por estado del caso.</li> <li><code>CAUSA_ACCIDENTE</code>: Mejora el rendimiento en an\u00e1lisis de causas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CASO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ID_POBLACION\nON [Colegio].[FACT_ENFERMERIA] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ID_FECHA\nON [Colegio].[FACT_ENFERMERIA] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ANIO_ACADEMICO\nON [Colegio].[FACT_ENFERMERIA] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_ATENCION y FECHA_SOLUCION\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_FECHAS\nON [Colegio].[FACT_ENFERMERIA] (FECHA_ATENCION, FECHA_SOLUCION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ESTADO\nON [Colegio].[FACT_ENFERMERIA] (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CAUSA_ACCIDENTE\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_CAUSA_ACCIDENTE\nON [Colegio].[FACT_ENFERMERIA] (CAUSA_ACCIDENTE);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_horario_grupos","title":"FACT_HORARIO_GRUPOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_HORARIO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de horario de grupos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Optimiza b\u00fasquedas relacionadas con grados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Facilita consultas relacionadas con cursos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SALON</code>:    Mejora b\u00fasquedas relacionadas con salones.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>HORA_INICIO</code> y <code>HORA_FIN</code>:    Acelera b\u00fasquedas relacionadas con intervalos horarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Optimiza b\u00fasquedas relacionadas con docentes.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>NUMERO_DIA</code> y <code>BLOQUE_HORARIO</code>:    Mejora an\u00e1lisis relacionados con d\u00edas y bloques horarios.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_HORARIO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ANIO_ACADEMICO</code>: Facilita b\u00fasquedas y an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_GRADO</code>: Mejora consultas relacionadas con grados.</li> <li><code>ID_CURSO</code>: Acelera b\u00fasquedas espec\u00edficas por cursos.</li> <li><code>ID_SALON</code>: Mejora el rendimiento en consultas relacionadas con salones.</li> <li><code>HORA_INICIO</code> y <code>HORA_FIN</code>: Facilita an\u00e1lisis de horarios.</li> <li><code>ID_PERSONAL</code>: Optimiza consultas relacionadas con docentes espec\u00edficos.</li> <li><code>NUMERO_DIA</code> y <code>BLOQUE_HORARIO</code>: Mejora b\u00fasquedas relacionadas con d\u00edas espec\u00edficos y bloques horarios.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_HORARIO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ANIO_ACADEMICO\nON [Colegio].[FACT_HORARIO_GRUPOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_GRADO\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_CURSO\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SALON\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_SALON\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_SALON);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para HORA_INICIO y HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_HORAS\nON [Colegio].[FACT_HORARIO_GRUPOS] (HORA_INICIO, HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_PERSONAL\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para NUMERO_DIA y BLOQUE_HORARIO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_BLOQUE_DIA\nON [Colegio].[FACT_HORARIO_GRUPOS] (NUMERO_DIA, BLOQUE_HORARIO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_legalizacion","title":"FACT_LEGALIZACION","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_LEGALIZACION</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de legalizaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO_DE_IDENTIDAD</code>:    Facilita b\u00fasquedas relacionadas con identificadores legales.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RAZON_SOCIAL</code>:    Optimiza b\u00fasquedas relacionadas con razones sociales espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>CODIGO_DANE</code>:    Acelera consultas relacionadas con fechas y c\u00f3digos institucionales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_LEGALIZACION</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_FECHA</code>: Facilita an\u00e1lisis por fechas.</li> <li><code>DOCUMENTO_DE_IDENTIDAD</code>: Mejora b\u00fasquedas relacionadas con identificaci\u00f3n de personas o instituciones.</li> <li><code>RAZON_SOCIAL</code>: Optimiza b\u00fasquedas por razones sociales.</li> <li><code>FECHA</code> y <code>CODIGO_DANE</code>: Mejora consultas combinadas relacionadas con fechas y c\u00f3digos institucionales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_LEGALIZACION\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_ID_FECHA\nON [Colegio].[FACT_LEGALIZACION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO_DE_IDENTIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_DOCUMENTO\nON [Colegio].[FACT_LEGALIZACION] (DOCUMENTO_DE_IDENTIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RAZON_SOCIAL\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_RAZON_SOCIAL\nON [Colegio].[FACT_LEGALIZACION] (RAZON_SOCIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y CODIGO_DANE\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_FECHA_DANE\nON [Colegio].[FACT_LEGALIZACION] (FECHA, CODIGO_DANE);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_notas","title":"FACT_NOTAS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_NOTA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada nota registrada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Facilita an\u00e1lisis por estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Mejora b\u00fasquedas relacionadas con cursos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Optimiza consultas relacionadas con grados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ASIGNATURA</code>:    Mejora b\u00fasquedas relacionadas con asignaturas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_LOGRO</code>:    Facilita consultas relacionadas con logros acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PERIODO</code> y <code>NOTA_FINAL</code>:    Acelera b\u00fasquedas relacionadas con per\u00edodos y calificaciones finales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_NOTA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_FECHA</code>: Mejora b\u00fasquedas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita consultas agrupadas por a\u00f1os acad\u00e9micos.</li> <li><code>ID_POBLACION_MATRICULA</code>: Optimiza an\u00e1lisis relacionados con estudiantes.</li> <li><code>ID_CURSO</code>: Mejora el rendimiento de b\u00fasquedas por cursos.</li> <li><code>ID_GRADO</code>: Acelera b\u00fasquedas relacionadas con grados.</li> <li><code>ID_ASIGNATURA</code>: Facilita consultas por asignaturas espec\u00edficas.</li> <li><code>ID_LOGRO</code>: Mejora b\u00fasquedas relacionadas con logros.</li> <li><code>PERIODO</code> y <code>NOTA_FINAL</code>: Optimiza consultas de an\u00e1lisis por per\u00edodo y resultados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_NOTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_FECHA\nON [Colegio].[FACT_NOTAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ANIO_ACADEMICO\nON [Colegio].[FACT_NOTAS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_POBLACION\nON [Colegio].[FACT_NOTAS] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_CURSO\nON [Colegio].[FACT_NOTAS] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_GRADO\nON [Colegio].[FACT_NOTAS] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ASIGNATURA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_ASIGNATURA\nON [Colegio].[FACT_NOTAS] (ID_ASIGNATURA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_LOGRO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_LOGRO\nON [Colegio].[FACT_NOTAS] (ID_LOGRO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para PERIODO y NOTA_FINAL\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_PERIODO_NOTA\nON [Colegio].[FACT_NOTAS] (PERIODO, NOTA_FINAL);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_permiso_estudiante","title":"FACT_PERMISO_ESTUDIANTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PERMISO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada permiso de estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Mejora b\u00fasquedas relacionadas con grados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Facilita an\u00e1lisis por cursos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza b\u00fasquedas por a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>HORA</code>:    Acelera b\u00fasquedas relacionadas con registros de permisos en momentos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO_ACUDIENTE</code>:    Mejora consultas relacionadas con documentos de acudientes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>MOTIVO_SALIDA</code>:    Facilita b\u00fasquedas relacionadas con motivos de salida.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERMISO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora el rendimiento en b\u00fasquedas relacionadas con estudiantes.</li> <li><code>ID_GRADO</code>: Optimiza b\u00fasquedas relacionadas con grados espec\u00edficos.</li> <li><code>ID_CURSO</code>: Facilita consultas por cursos.</li> <li><code>ID_FECHA</code>: Acelera b\u00fasquedas relacionadas con fechas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA</code> y <code>HORA</code>: Mejora consultas relacionadas con horarios de permisos.</li> <li><code>DOCUMENTO_ACUDIENTE</code>: Optimiza b\u00fasquedas relacionadas con acudientes.</li> <li><code>MOTIVO_SALIDA</code>: Acelera b\u00fasquedas por motivos de salida.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PERMISO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_POBLACION\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_GRADO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_CURSO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_FECHA\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ANIO_ACADEMICO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y HORA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_FECHA_HORA\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (FECHA, HORA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO_ACUDIENTE\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_DOCUMENTO_ACUDIENTE\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (DOCUMENTO_ACUDIENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_SALIDA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_MOTIVO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (MOTIVO_SALIDA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_psicorientacion","title":"FACT_PSICORIENTACION","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CASO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada caso de psicorientaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Facilita b\u00fasquedas agrupadas por a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>:    Acelera an\u00e1lisis relacionados con per\u00edodos de atenci\u00f3n y soluci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO</code>:    Mejora b\u00fasquedas relacionadas con estados espec\u00edficos del caso.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>MOTIVO_ATENCION</code>:    Facilita b\u00fasquedas relacionadas con motivos de atenci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CASO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita uniones y consultas relacionadas con estudiantes.</li> <li><code>ID_FECHA</code>: Optimiza b\u00fasquedas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>: Acelera consultas relacionadas con per\u00edodos temporales.</li> <li><code>ESTADO</code>: Facilita an\u00e1lisis y filtros relacionados con estados de los casos.</li> <li><code>MOTIVO_ATENCION</code>: Mejora b\u00fasquedas relacionadas con motivos espec\u00edficos de atenci\u00f3n.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CASO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ID_POBLACION\nON [Colegio].[FACT_PSICORIENTACION] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ID_FECHA\nON [Colegio].[FACT_PSICORIENTACION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ANIO_ACADEMICO\nON [Colegio].[FACT_PSICORIENTACION] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_ATENCION y FECHA_SOLUCION\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_FECHAS\nON [Colegio].[FACT_PSICORIENTACION] (FECHA_ATENCION, FECHA_SOLUCION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ESTADO\nON [Colegio].[FACT_PSICORIENTACION] (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_ATENCION\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_MOTIVO\nON [Colegio].[FACT_PSICORIENTACION] (MOTIVO_ATENCION);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_reemplazo_docente","title":"FACT_REEMPLAZO_DOCENTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REEMPLAZO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de reemplazo docente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL_AUSENTE</code>:    Mejora b\u00fasquedas relacionadas con docentes ausentes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL_REEMPLAZA</code>:    Optimiza b\u00fasquedas relacionadas con docentes reemplazantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Acelera consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Facilita b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_GRADO</code> y <code>ID_CURSO</code>:    Mejora consultas relacionadas con grados y cursos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>BLOQUE_HORARIO</code>:    Optimiza an\u00e1lisis relacionados con fechas y bloques horarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCENTE_AUSENTE</code>:    Facilita b\u00fasquedas relacionadas con nombres de docentes ausentes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCENTE_REEMPLAZA</code>:    Mejora b\u00fasquedas relacionadas con nombres de docentes que reemplazan.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REEMPLAZO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_PERSONAL_AUSENTE</code>: Facilita an\u00e1lisis por docentes ausentes.</li> <li><code>ID_PERSONAL_REEMPLAZA</code>: Mejora b\u00fasquedas relacionadas con reemplazos.</li> <li><code>ID_FECHA</code>: Acelera b\u00fasquedas relacionadas con fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_GRADO</code> y <code>ID_CURSO</code>: Optimiza consultas combinadas relacionadas con grados y cursos.</li> <li><code>FECHA</code> y <code>BLOQUE_HORARIO</code>: Facilita an\u00e1lisis de bloques horarios por fechas espec\u00edficas.</li> <li><code>DOCENTE_AUSENTE</code>: Acelera b\u00fasquedas relacionadas con los nombres de docentes ausentes.</li> <li><code>DOCENTE_REEMPLAZA</code>: Mejora consultas relacionadas con docentes que reemplazan.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REEMPLAZO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL_AUSENTE\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_PERSONAL_AUSENTE\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_PERSONAL_AUSENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL_REEMPLAZA\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_PERSONAL_REEMPLAZA\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_PERSONAL_REEMPLAZA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_ID_FECHA\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_ANIO_ACADEMICO\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para ID_GRADO y ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_GRADO_CURSO\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_GRADO, ID_CURSO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y BLOQUE_HORARIO\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_FECHA_BLOQUE\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (FECHA, BLOQUE_HORARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCENTE_AUSENTE\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_DOCENTE_AUSENTE\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (DOCENTE_AUSENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCENTE_REEMPLAZA\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_DOCENTE_REEMPLAZA\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (DOCENTE_REEMPLAZA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_reserva_espacios","title":"FACT_RESERVA_ESPACIOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESERVA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de reserva.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_SOLICITUD</code> y <code>FECHA_RESERVA</code>:    Facilita an\u00e1lisis relacionados con el tiempo de solicitud y la reserva.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RECURSO_RESERVA</code>:    Mejora b\u00fasquedas relacionadas con recursos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con los responsables de la reserva.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>HORA_INICIO</code> y <code>HORA_FIN</code>:    Optimiza consultas relacionadas con intervalos de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO_DOCENTE</code>:    Facilita an\u00e1lisis por correos electr\u00f3nicos de los docentes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ACTIVIDAD_PLANEADA</code>:    Mejora b\u00fasquedas relacionadas con actividades espec\u00edficas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESERVA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_FECHA</code>: Mejora el rendimiento de b\u00fasquedas relacionadas con fechas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita consultas relacionadas con agrupaciones por a\u00f1os.</li> <li><code>FECHA_SOLICITUD</code> y <code>FECHA_RESERVA</code>: Optimiza el an\u00e1lisis de tiempos entre solicitud y ejecuci\u00f3n.</li> <li><code>RECURSO_RESERVA</code>: Mejora b\u00fasquedas relacionadas con recursos espec\u00edficos.</li> <li><code>ID_PERSONAL</code>: Acelera consultas relacionadas con responsables de la reserva.</li> <li><code>HORA_INICIO</code> y <code>HORA_FIN</code>: Facilita an\u00e1lisis relacionados con horarios espec\u00edficos.</li> <li><code>CORREO_DOCENTE</code>: Optimiza b\u00fasquedas por docentes en funci\u00f3n de sus correos electr\u00f3nicos.</li> <li><code>ACTIVIDAD_PLANEADA</code>: Mejora consultas relacionadas con actividades registradas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESERVA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ID_FECHA\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ANIO_ACADEMICO\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_SOLICITUD y FECHA_RESERVA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_FECHAS\nON [Colegio].[FACT_RESERVA_ESPACIOS] (FECHA_SOLICITUD, FECHA_RESERVA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RECURSO_RESERVA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_RECURSO\nON [Colegio].[FACT_RESERVA_ESPACIOS] (RECURSO_RESERVA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ID_PERSONAL\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para HORA_INICIO y HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_HORAS\nON [Colegio].[FACT_RESERVA_ESPACIOS] (HORA_INICIO, HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO_DOCENTE\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_CORREO\nON [Colegio].[FACT_RESERVA_ESPACIOS] (CORREO_DOCENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD_PLANEADA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ACTIVIDAD\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ACTIVIDAD_PLANEADA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_resultados","title":"FACT_RESULTADOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESULTADO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada resultado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Facilita an\u00e1lisis relacionados con cursos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Acelera b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>RESULTADO</code>:    Mejora an\u00e1lisis relacionados con resultados y fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GRADUADO</code>:    Optimiza b\u00fasquedas relacionadas con el estado de graduaci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESULTADO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ANIO_ACADEMICO</code>: Facilita agrupaciones y consultas por a\u00f1os.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora an\u00e1lisis relacionados con estudiantes.</li> <li><code>ID_CURSO</code>: Optimiza consultas relacionadas con cursos espec\u00edficos.</li> <li><code>ID_FECHA</code>: Acelera b\u00fasquedas por fechas de registro.</li> <li><code>FECHA</code> y <code>RESULTADO</code>: Facilita an\u00e1lisis de tendencias y resultados por fechas.</li> <li><code>GRADUADO</code>: Mejora b\u00fasquedas relacionadas con estados de graduaci\u00f3n.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESULTADO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ANIO_ACADEMICO\nON [Colegio].[FACT_RESULTADOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ID_POBLACION\nON [Colegio].[FACT_RESULTADOS] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ID_CURSO\nON [Colegio].[FACT_RESULTADOS] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ID_FECHA\nON [Colegio].[FACT_RESULTADOS] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y RESULTADO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_FECHA_RESULTADO\nON [Colegio].[FACT_RESULTADOS] (FECHA, RESULTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GRADUADO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_GRADUADO\nON [Colegio].[FACT_RESULTADOS] (GRADUADO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_servicio_social","title":"FACT_SERVICIO_SOCIAL","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Facilita b\u00fasquedas relacionadas con grados acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Mejora an\u00e1lisis relacionados con cursos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>HORARIO</code>:    Acelera b\u00fasquedas relacionadas con horarios asignados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PROYECTO</code>:    Optimiza b\u00fasquedas relacionadas con proyectos asociados al servicio social.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PAZ_Y_SALVO</code>:    Mejora an\u00e1lisis relacionados con el estado del estudiante respecto a sus requisitos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>HORAS_EJECUTADAS</code>:    Acelera consultas relacionadas con las horas acumuladas en el servicio social.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ANIO_ACADEMICO</code>: Facilita an\u00e1lisis por per\u00edodos acad\u00e9micos.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora b\u00fasquedas por estudiantes espec\u00edficos.</li> <li><code>ID_GRADO</code>: Optimiza an\u00e1lisis relacionados con niveles educativos.</li> <li><code>ID_CURSO</code>: Mejora b\u00fasquedas por grupos acad\u00e9micos.</li> <li><code>HORARIO</code>: Facilita consultas relacionadas con la asignaci\u00f3n de horarios.</li> <li><code>PROYECTO</code>: Mejora an\u00e1lisis por proyectos espec\u00edficos del servicio social.</li> <li><code>PAZ_Y_SALVO</code>: Acelera b\u00fasquedas relacionadas con el cumplimiento de requisitos.</li> <li><code>HORAS_EJECUTADAS</code>: Optimiza el an\u00e1lisis de acumulaci\u00f3n de horas en el servicio social.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ANIO_ACADEMICO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ID_POBLACION\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ID_GRADO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ID_CURSO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo HORARIO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_HORARIO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (HORARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PROYECTO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_PROYECTO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (PROYECTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PAZ_Y_SALVO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_PAZ_Y_SALVO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (PAZ_Y_SALVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo HORAS_EJECUTADAS\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_HORAS\nON [Colegio].[FACT_SERVICIO_SOCIAL] (HORAS_EJECUTADAS);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_transporte","title":"FACT_TRANSPORTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Mejora b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza consultas relacionadas con fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Facilita b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Mejora an\u00e1lisis relacionados con rangos de fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SERVICIO_TRANSPORTE</code>:    Acelera consultas relacionadas con tipos de transporte.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SERVICIO</code>:    Facilita b\u00fasquedas relacionadas con identificadores de servicios espec\u00edficos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora b\u00fasquedas por estudiantes.</li> <li><code>ID_FECHA</code>: Optimiza an\u00e1lisis por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita agrupaciones por per\u00edodos acad\u00e9micos.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Acelera b\u00fasquedas por rangos de fechas.</li> <li><code>SERVICIO_TRANSPORTE</code>: Mejora b\u00fasquedas relacionadas con tipos de servicios.</li> <li><code>ID_SERVICIO</code>: Facilita an\u00e1lisis por identificadores de servicios.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ID_POBLACION\nON [Colegio].[FACT_TRANSPORTE] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ID_FECHA\nON [Colegio].[FACT_TRANSPORTE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ANIO_ACADEMICO\nON [Colegio].[FACT_TRANSPORTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_FECHAS\nON [Colegio].[FACT_TRANSPORTE] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SERVICIO_TRANSPORTE\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_SERVICIO\nON [Colegio].[FACT_TRANSPORTE] (SERVICIO_TRANSPORTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ID_SERVICIO\nON [Colegio].[FACT_TRANSPORTE] (ID_SERVICIO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_saber11_colegios","title":"FACT_SABER11_COLEGIOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>COD_ESTABLECIMIENTO_EDUCATIVO</code>:    Facilita b\u00fasquedas relacionadas con el c\u00f3digo del establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_EE</code>:    Acelera b\u00fasquedas por el nombre del establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESULTADO</code>:    Optimiza consultas relacionadas con los resultados espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CATEGORIA_SABER11</code>:    Mejora an\u00e1lisis relacionados con las categor\u00edas asignadas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura acceso eficiente.</li> <li><code>ID_FECHA</code>: Optimiza b\u00fasquedas por fechas espec\u00edficas en an\u00e1lisis temporales.</li> <li><code>ANIO_ACADEMICO</code>: Mejora agrupaciones por per\u00edodos acad\u00e9micos.</li> <li><code>COD_ESTABLECIMIENTO_EDUCATIVO</code>: Facilita consultas relacionadas con c\u00f3digos de instituciones.</li> <li><code>NOMBRE_EE</code>: Acelera b\u00fasquedas relacionadas con nombres de instituciones educativas.</li> <li><code>RESULTADO</code>: Mejora an\u00e1lisis y agrupaciones por resultados obtenidos.</li> <li><code>CATEGORIA_SABER11</code>: Optimiza b\u00fasquedas relacionadas con las clasificaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_ID_FECHA\nON [Colegio].[FACT_SABER11_COLEGIOS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_ANIO_ACADEMICO\nON [Colegio].[FACT_SABER11_COLEGIOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_COD_ESTABLECIMIENTO\nON [Colegio].[FACT_SABER11_COLEGIOS] (COD_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_EE\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_NOMBRE_EE\nON [Colegio].[FACT_SABER11_COLEGIOS] (NOMBRE_EE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RESULTADO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_RESULTADO\nON [Colegio].[FACT_SABER11_COLEGIOS] (RESULTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA_SABER11\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_CATEGORIA\nON [Colegio].[FACT_SABER11_COLEGIOS] (CATEGORIA_SABER11);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_saber11_individual","title":"FACT_SABER11_INDIVIDUAL","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Facilita b\u00fasquedas relacionadas con los estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TEMATICA</code>:    Mejora an\u00e1lisis relacionados con tem\u00e1ticas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESULTADO</code>:    Optimiza b\u00fasquedas relacionadas con resultados obtenidos por los estudiantes.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura acceso eficiente.</li> <li><code>ID_FECHA</code>: Acelera consultas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora an\u00e1lisis agrupados por per\u00edodos acad\u00e9micos.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita b\u00fasquedas relacionadas con estudiantes individuales.</li> <li><code>TEMATICA</code>: Acelera an\u00e1lisis por \u00e1reas tem\u00e1ticas espec\u00edficas.</li> <li><code>RESULTADO</code>: Mejora consultas relacionadas con los puntajes individuales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_ID_FECHA\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_ANIO_ACADEMICO\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_ID_POBLACION\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TEMATICA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_TEMATICA\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (TEMATICA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RESULTADO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_RESULTADO\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (RESULTADO);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/","title":"08.Index Proteccion","text":""},{"location":"01.scripts/08.Index_Proteccion/#indices-proteccion","title":"Indices Protecci\u00f3n","text":""},{"location":"01.scripts/08.Index_Proteccion/#dim_campos_caract","title":"[DIM_CAMPOS_CARACT]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PREGUNTA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PREGUNTA</code>:    Optimiza b\u00fasquedas y filtros basados en el texto de la pregunta.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>OBSERVACIONES</code>:    Facilita b\u00fasquedas y consultas relacionadas con observaciones espec\u00edficas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PREGUNTA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>PREGUNTA</code>: Campo clave para b\u00fasquedas o filtros basados en el texto de la pregunta.</li> <li><code>OBSERVACIONES</code>: Mejora la velocidad de an\u00e1lisis y b\u00fasquedas cuando se necesitan filtros o an\u00e1lisis basados en observaciones espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PREGUNTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_CAMPOS_CARACT_PREGUNTA\nON [Proteccion].[DIM_CAMPOS_CARACT] (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_DIM_CAMPOS_CARACT_OBSERVACIONES\nON [Proteccion].[DIM_CAMPOS_CARACT] (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_establecimiento_educativo","title":"[DIM_ESTABLECIMIENTO_EDUCATIVO]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>COD_ESTABLECIMIENTO_EDUCATIVO</code>:    Optimiza b\u00fasquedas relacionadas con el c\u00f3digo del establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_ESTABLECIMIENTO</code>:    Facilita b\u00fasquedas y filtros por el nombre del establecimiento.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code>:    Mejora consultas relacionadas con documentos espec\u00edficos de los establecimientos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>REPRESENTANTE_LEGAL</code>:    Acelera b\u00fasquedas relacionadas con los representantes legales de los establecimientos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>COD_CIUDAD</code>:    Optimiza an\u00e1lisis y filtros basados en la ciudad de ubicaci\u00f3n del establecimiento.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Clave primaria para garantizar un acceso r\u00e1pido y ordenado.</li> <li><code>COD_ESTABLECIMIENTO_EDUCATIVO</code>: Es un identificador alternativo usado frecuentemente en consultas.</li> <li><code>NOMBRE_ESTABLECIMIENTO</code>: Se utiliza para b\u00fasquedas textuales en an\u00e1lisis y reportes.</li> <li><code>DOCUMENTO</code>: Permite b\u00fasquedas espec\u00edficas para identificar establecimientos.</li> <li><code>REPRESENTANTE_LEGAL</code>: Optimiza consultas basadas en responsables legales.</li> <li><code>COD_CIUDAD</code>: Mejora an\u00e1lisis agrupados por ubicaci\u00f3n geogr\u00e1fica.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_ESTABLECIMIENTO_EDUCATIVO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo COD_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_COD_ESTABLECIMIENTO\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (COD_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_ESTABLECIMIENTO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_NOMBRE\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (NOMBRE_ESTABLECIMIENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_DOCUMENTO\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo REPRESENTANTE_LEGAL\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_REPRESENTANTE\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (REPRESENTANTE_LEGAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_CIUDAD\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_COD_CIUDAD\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (COD_CIUDAD);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_poblacion","title":"[DIM_POBLACION]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_POBLACION</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Optimiza consultas basadas en la combinaci\u00f3n del tipo de documento y su n\u00famero.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code>:    Mejora b\u00fasquedas relacionadas con la empresa asociada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_AFILIADO</code>:    Facilita consultas relacionadas con los afiliados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_BENEFICIARIO</code>:    Acelera an\u00e1lisis relacionados con los beneficiarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_APORTANTE</code>:    Optimiza b\u00fasquedas relacionadas con aportantes espec\u00edficos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_POBLACION</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>: La combinaci\u00f3n de estos campos permite b\u00fasquedas r\u00e1pidas de individuos espec\u00edficos.</li> <li><code>ID_EMPRESA</code>: Facilita el an\u00e1lisis de datos a nivel empresarial.</li> <li><code>ID_AFILIADO</code>: Optimiza consultas relacionadas con individuos afiliados.</li> <li><code>ID_BENEFICIARIO</code>: Mejora el acceso a datos de beneficiarios en reportes y an\u00e1lisis.</li> <li><code>ID_APORTANTE</code>: Permite b\u00fasquedas r\u00e1pidas relacionadas con quienes realizan aportes.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_POBLACION\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_TIPO_DOCUMENTO_DOCUMENTO\nON [Proteccion].[DIM_POBLACION] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_EMPRESA\nON [Proteccion].[DIM_POBLACION] (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_AFILIADO\nON [Proteccion].[DIM_POBLACION] (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_BENEFICIARIO\nON [Proteccion].[DIM_POBLACION] (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_APORTANTE\nON [Proteccion].[DIM_POBLACION] (ID_APORTANTE);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_preguntas_ee_aipi","title":"[DIM_PREGUNTAS_EE_AIPI]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PREGUNTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PREGUNTA</code>:    Optimiza b\u00fasquedas basadas en el texto de las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Mejora la eficiencia de consultas relacionadas con programas espec\u00edficos, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PREGUNTA</code>: Es la clave primaria que asegura un acceso eficiente a cada registro de manera \u00fanica.</li> <li><code>PREGUNTA</code>: Este campo puede ser usado en b\u00fasquedas textuales o filtros en reportes.</li> <li><code>ID_PROGRAMA</code>: Como clave for\u00e1nea, se usa en uniones y an\u00e1lisis vinculados con programas, lo que justifica su \u00edndice para mejorar el rendimiento.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PREGUNTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_AIPI_PREGUNTA\nON [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_AIPI_ID_PROGRAMA\nON [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (ID_PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_preguntas_ee_jec","title":"[DIM_PREGUNTAS_EE_JEC]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PREGUNTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PREGUNTA</code>:    Facilita b\u00fasquedas y an\u00e1lisis basados en el texto de las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Mejora la eficiencia de consultas relacionadas con programas espec\u00edficos, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PREGUNTA</code>: Es la clave primaria que asegura un acceso eficiente a cada registro de manera \u00fanica.</li> <li><code>PREGUNTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales y reportes relacionados con las preguntas.</li> <li><code>ID_PROGRAMA</code>: Como clave for\u00e1nea, este campo se utiliza para unir o filtrar datos basados en los programas asociados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PREGUNTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_JEC_PREGUNTA\nON [Proteccion].[DIM_PREGUNTAS_EE_JEC] (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_JEC_ID_PROGRAMA\nON [Proteccion].[DIM_PREGUNTAS_EE_JEC] (ID_PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_programa","title":"[DIM_PROGRAMA]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PROGRAMA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PROGRAMA</code>:    Optimiza consultas relacionadas con el nombre o descripci\u00f3n de los programas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PROGRAMA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>PROGRAMA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales, reportes y an\u00e1lisis relacionados con los programas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PROGRAMA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PROGRAMA_PROGRAMA\nON [Proteccion].[DIM_PROGRAMA] (PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_respuestas_ee_aipi","title":"[DIM_RESPUESTAS_EE_AIPI]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESPUESTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESPUESTA</code>:    Optimiza b\u00fasquedas relacionadas con el texto de las respuestas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de consultas que relacionan respuestas con preguntas espec\u00edficas, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESPUESTA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>RESPUESTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales y reportes relacionados con las respuestas.</li> <li><code>ID_PREGUNTA</code>: Como clave for\u00e1nea, es importante para unir o filtrar datos basados en preguntas asociadas a las respuestas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESPUESTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo RESPUESTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_AIPI_RESPUESTA\nON [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (RESPUESTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_AIPI_ID_PREGUNTA\nON [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (ID_PREGUNTA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_respuestas_ee_jec","title":"[DIM_RESPUESTAS_EE_JEC]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESPUESTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESPUESTA</code>:    Optimiza b\u00fasquedas relacionadas con el texto de las respuestas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de consultas que relacionan respuestas con preguntas espec\u00edficas, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESPUESTA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>RESPUESTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales y an\u00e1lisis relacionados con las respuestas.</li> <li><code>ID_PREGUNTA</code>: Como clave for\u00e1nea, facilita uniones y filtros en consultas que relacionan respuestas con preguntas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESPUESTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo RESPUESTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_JEC_RESPUESTA\nON [Proteccion].[DIM_RESPUESTAS_EE_JEC] (RESPUESTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_JEC_ID_PREGUNTA\nON [Proteccion].[DIM_RESPUESTAS_EE_JEC] (ID_PREGUNTA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_caracterizacion","title":"[FACT_CARACTERIZACION]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CARACTERIZACION</code> (PRIMARY KEY):    Garantiza un acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora el rendimiento de consultas que utilizan la fecha para an\u00e1lisis o relaciones con otras tablas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code>:    Optimiza consultas relacionadas con la poblaci\u00f3n asociada a cada caracterizaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Acelera b\u00fasquedas y relaciones con programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de uniones o filtros relacionados con preguntas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>RESPUESTA</code>:    Optimiza b\u00fasquedas textuales relacionadas con las respuestas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_FECHA</code> y <code>ID_PROGRAMA</code>:    Dise\u00f1ado para consultas frecuentes que combinen fechas y programas en filtros o an\u00e1lisis.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CARACTERIZACION</code>: Clave primaria que asegura un acceso eficiente y ordenado a los registros.</li> <li><code>ID_FECHA</code>: Frecuentemente utilizado para an\u00e1lisis basados en tiempo o relaciones con la tabla de tiempo.</li> <li><code>ID_POBLACION</code>: Como clave for\u00e1nea, se utiliza para uniones y an\u00e1lisis relacionados con datos de poblaci\u00f3n.</li> <li><code>ID_PROGRAMA</code>: Fundamental para consultas que filtran o agrupan por programas asociados.</li> <li><code>ID_PREGUNTA</code>: Importante para relacionar y analizar preguntas espec\u00edficas.</li> <li><code>RESPUESTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales o an\u00e1lisis relacionados con respuestas espec\u00edficas.</li> <li>\u00cdndice compuesto para <code>ID_FECHA</code> y <code>ID_PROGRAMA</code>: Facilita an\u00e1lisis multidimensionales en escenarios con m\u00faltiples dimensiones (fecha y programa).</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CARACTERIZACION\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_FECHA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_POBLACION\nON [Proteccion].[FACT_CARACTERIZACION] (ID_POBLACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_PROGRAMA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_PREGUNTA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_RESPUESTA\nON [Proteccion].[FACT_CARACTERIZACION] (RESPUESTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_FECHA y ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_FECHA_PROGRAMA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_FECHA, ID_PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_desercion","title":"[FACT_DESERCION]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Optimiza las consultas relacionadas con establecimientos educativos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code>:    Mejora el rendimiento de b\u00fasquedas o uniones relacionadas con poblaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Acelera las consultas relacionadas con programas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora el rendimiento en an\u00e1lisis basados en tiempo y uniones con la tabla de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ANIO_ACADEMICO</code>:    Optimiza consultas que analizan registros por a\u00f1o acad\u00e9mico.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CAUSA</code>:    Acelera b\u00fasquedas y agrupaciones relacionadas con las causas de deserci\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_FECHA</code> y <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Dise\u00f1ado para consultas que filtran por tiempo y establecimiento educativo.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code> y <code>ID_POBLACION</code>: Claves for\u00e1neas usadas frecuentemente en uniones y an\u00e1lisis relacionados con datos espec\u00edficos.</li> <li><code>ID_PROGRAMA</code>: Usado en consultas para agrupar o filtrar datos por programa.</li> <li><code>ID_FECHA</code>: Clave for\u00e1nea que permite uniones r\u00e1pidas con la dimensi\u00f3n de tiempo para an\u00e1lisis temporales.</li> <li><code>ANIO_ACADEMICO</code> y <code>CAUSA</code>: Campos comunes en an\u00e1lisis y agrupaciones espec\u00edficas sobre deserci\u00f3n.</li> <li>\u00cdndice compuesto para <code>ID_FECHA</code> y <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Acelera consultas multidimensionales que incluyen filtros por tiempo y establecimiento.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_DESERCION] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_POBLACION\nON [Proteccion].[FACT_DESERCION] (ID_POBLACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_PROGRAMA\nON [Proteccion].[FACT_DESERCION] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_FECHA\nON [Proteccion].[FACT_DESERCION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ANIO_ACADEMICO\nON [Proteccion].[FACT_DESERCION] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CAUSA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_CAUSA\nON [Proteccion].[FACT_DESERCION] (CAUSA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_FECHA y ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_FECHA_ESTABLECIMIENTO\nON [Proteccion].[FACT_DESERCION] (ID_FECHA, ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_diagnosticos_ee_aipi","title":"[FACT_DIAGNOSTICOS_EE_AIPI]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza las consultas relacionadas con el tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Acelera las b\u00fasquedas relacionadas con establecimientos educativos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de consultas relacionadas con las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_RESPUESTA</code>:    Optimiza b\u00fasquedas o an\u00e1lisis relacionados con las respuestas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_FECHA</code> y <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Dise\u00f1ado para acelerar consultas que filtran por tiempo y establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CIUDAD</code>:    Acelera b\u00fasquedas y agrupaciones por ciudad.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>:    Optimiza las consultas que cruzan las preguntas con sus respuestas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Utilizado en uniones con la dimensi\u00f3n de tiempo para an\u00e1lisis temporales.</li> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Com\u00fan en uniones y an\u00e1lisis espec\u00edficos por establecimiento educativo.</li> <li><code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>: Claves for\u00e1neas para enlazar preguntas y respuestas, necesarias para an\u00e1lisis detallados.</li> <li><code>CIUDAD</code>: Campo usado en agrupaciones y an\u00e1lisis geogr\u00e1ficos.</li> <li>\u00cdndices compuestos: Aceleran consultas multidimensionales, como las que combinan fechas con establecimientos educativos o preguntas con respuestas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_FECHA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_PREGUNTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_RESPUESTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_FECHA y ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_FECHA_ESTABLECIMIENTO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_FECHA, ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CIUDAD\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_CIUDAD\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (CIUDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_PREGUNTA y ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_PREGUNTA_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_PREGUNTA, ID_RESPUESTA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_diagnosticos_ee_jec","title":"[FACT_DIAGNOSTICOS_EE_JEC]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Acelera consultas relacionadas con la dimensi\u00f3n de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Optimiza b\u00fasquedas y uniones relacionadas con establecimientos educativos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento en consultas relacionadas con preguntas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_RESPUESTA</code>:    Facilita el an\u00e1lisis y recuperaci\u00f3n de datos basados en respuestas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_HORA_INICIO</code> y <code>FECHA_HORA_FIN</code>:    Dise\u00f1ado para consultas que analizan rangos de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CORREO_FUNCIONARIO</code>:    Acelera b\u00fasquedas espec\u00edficas relacionadas con el correo de los funcionarios.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>:    Optimiza el an\u00e1lisis cruzado de preguntas y respuestas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>RECTOR</code>:    Acelera consultas relacionadas con los rectores.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Utilizado para uniones con la dimensi\u00f3n de tiempo y an\u00e1lisis temporales.</li> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Com\u00fan en an\u00e1lisis espec\u00edficos por establecimiento educativo.</li> <li><code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>: Campos esenciales para uniones y an\u00e1lisis cruzados entre preguntas y respuestas.</li> <li>Campos de tiempo (<code>FECHA_HORA_INICIO</code>, <code>FECHA_HORA_FIN</code>): Importantes para an\u00e1lisis basados en periodos.</li> <li>Campos relacionados con funcionarios (<code>CORREO_FUNCIONARIO</code>, <code>RECTOR</code>): \u00datiles para segmentaciones y an\u00e1lisis detallados por personal.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_FECHA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_PREGUNTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_RESPUESTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_HORA_INICIO y FECHA_HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_FECHA_RANGO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (FECHA_HORA_INICIO, FECHA_HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO_FUNCIONARIO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_CORREO_FUNCIONARIO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (CORREO_FUNCIONARIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_PREGUNTA y ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_PREGUNTA_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_PREGUNTA, ID_RESPUESTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RECTOR\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_RECTOR\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (RECTOR);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_entrega_material","title":"[FACT_ENTREGA_MATERIAL]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_ENTREGA</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza uniones y consultas basadas en la dimensi\u00f3n de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Mejora el rendimiento de consultas relacionadas con programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con personal asignado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_MATERIAL</code>:    Facilita b\u00fasquedas espec\u00edficas por material.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_MATERIAL</code> y <code>CANTIDAD_MATERIAL</code>:    Dise\u00f1ado para consultas que analizan tipos y cantidades de material.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>VALOR_MATERIAL</code> y <code>ID_FECHA</code>:    Mejora an\u00e1lisis financieros relacionados con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code>:    Optimiza consultas y an\u00e1lisis centrados en poblaci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Utilizado para uniones y an\u00e1lisis relacionados con periodos de tiempo.  </li> <li><code>ID_PROGRAMA</code> y <code>ID_PERSONAL</code>: Campos claves para an\u00e1lisis por programa y personal.  </li> <li><code>ID_MATERIAL</code>: Esencial para identificar materiales entregados.  </li> <li>Campos compuestos (<code>TIPO_MATERIAL</code>, <code>CANTIDAD_MATERIAL</code> y <code>VALOR_MATERIAL</code>): Relevantes para an\u00e1lisis detallados de distribuci\u00f3n y valor.  </li> <li><code>ID_POBLACION</code>: Clave en consultas relacionadas con la poblaci\u00f3n beneficiaria.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_ENTREGA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_FECHA\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_PROGRAMA\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_PERSONAL\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MATERIAL\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_MATERIAL\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_MATERIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_MATERIAL y CANTIDAD_MATERIAL\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_TIPO_CANTIDAD\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (TIPO_MATERIAL, CANTIDAD_MATERIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos VALOR_MATERIAL y ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_VALOR_FECHA\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (VALOR_MATERIAL, ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_POBLACION\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_POBLACION);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_plan_cobertura","title":"[FACT_PLAN_COBERTURA]","text":"<p>Justificaci\u00f3n</p> <ol> <li>\u00cdndice cl\u00faster existente para <code>ID_PLAN_COBERTURA</code></li> <li> <p>La clave primaria asegura acceso ordenado y r\u00e1pido a los registros mediante un \u00edndice cl\u00faster.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> </li> <li> <p>Mejora las consultas relacionadas con el tiempo y permite uniones r\u00e1pidas con la dimensi\u00f3n temporal.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code></p> </li> <li> <p>Optimiza consultas relacionadas con establecimientos educativos y permite uniones eficientes con la dimensi\u00f3n correspondiente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code></p> </li> <li> <p>Facilita el acceso r\u00e1pido a los datos relacionados con programas espec\u00edficos y optimiza las uniones con su dimensi\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ZONA</code> y <code>MUNICIPIO</code></p> </li> <li> <p>Optimiza las consultas que analizan datos por zona y municipio.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>LINEA_INTERVENCION</code></p> </li> <li> <p>Mejora el rendimiento en consultas que filtran o agrupan datos por l\u00ednea de intervenci\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>SEDE</code> y <code>COBERTURA_PROYECTADA</code></p> </li> <li>Acelera las b\u00fasquedas y an\u00e1lisis relacionados con las sedes y su cobertura proyectada.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PLAN_COBERTURA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_FECHA\nON [Proteccion].[FACT_PLAN_COBERTURA] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_PLAN_COBERTURA] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_PROGRAMA\nON [Proteccion].[FACT_PLAN_COBERTURA] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ZONA y MUNICIPIO\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ZONA_MUNICIPIO\nON [Proteccion].[FACT_PLAN_COBERTURA] (ZONA, MUNICIPIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo LINEA_INTERVENCION\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_LINEA_INTERVENCION\nON [Proteccion].[FACT_PLAN_COBERTURA] (LINEA_INTERVENCION);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos SEDE y COBERTURA_PROYECTADA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_SEDE_COBERTURA\nON [Proteccion].[FACT_PLAN_COBERTURA] (SEDE, COBERTURA_PROYECTADA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_venta","title":"[FACT_VENTA]","text":"<p>Justificaci\u00f3n</p> <ol> <li>\u00cdndice cl\u00faster existente para <code>ID_VENTA</code></li> <li> <p>Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> </li> <li> <p>Optimiza consultas relacionadas con el tiempo y permite uniones r\u00e1pidas con la dimensi\u00f3n temporal.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code></p> </li> <li> <p>Mejora el rendimiento de consultas centradas en la poblaci\u00f3n objetivo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SERVICIO</code></p> </li> <li> <p>Acelera b\u00fasquedas relacionadas con servicios y permite uniones r\u00e1pidas con la dimensi\u00f3n de servicios.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code></p> </li> <li> <p>Facilita b\u00fasquedas r\u00e1pidas basadas en documentos espec\u00edficos de usuarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CATEGORIA_VENTA</code></p> </li> <li> <p>Permite consultas eficientes sobre las categor\u00edas de ventas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>COSTO</code>, <code>SUBSIDIO</code>, y <code>VALOR_PAGADO_SIN_IMP</code></p> </li> <li>Optimiza an\u00e1lisis relacionados con valores econ\u00f3micos de las ventas.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_VENTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_ID_FECHA\nON [Proteccion].[FACT_VENTA] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_ID_POBLACION\nON [Proteccion].[FACT_VENTA] (ID_POBLACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_ID_SERVICIO\nON [Proteccion].[FACT_VENTA] (ID_SERVICIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_DOCUMENTOS\nON [Proteccion].[FACT_VENTA] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA_VENTA\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_CATEGORIA\nON [Proteccion].[FACT_VENTA] (CATEGORIA_VENTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos COSTO, SUBSIDIO, y VALOR_PAGADO_SIN_IMP\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_VALORES\nON [Proteccion].[FACT_VENTA] (COSTO, SUBSIDIO, VALOR_PAGADO_SIN_IMP);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_visitas","title":"[FACT_VISITAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li>\u00cdndice cl\u00faster existente para <code>ID_VISITA</code></li> <li> <p>La clave primaria asegura acceso ordenado y r\u00e1pido a los registros mediante un \u00edndice cl\u00faster.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> </li> <li> <p>Optimiza las consultas relacionadas con fechas y permite uniones eficientes con la dimensi\u00f3n temporal.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code></p> </li> <li> <p>Mejora el rendimiento en consultas que agrupan o filtran datos por programas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code></p> </li> <li> <p>Acelera las b\u00fasquedas relacionadas con el personal involucrado en las visitas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>MUNICIPIO</code> y <code>LUGAR</code></p> </li> <li> <p>Facilita an\u00e1lisis y b\u00fasquedas basadas en la ubicaci\u00f3n de las visitas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_PLANEADA</code> y <code>FECHA_EJECUTADA</code></p> </li> <li> <p>Permite comparar las fechas planeadas con las ejecutadas, optimizando las consultas relacionadas con la ejecuci\u00f3n de visitas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ACTIVIDAD</code></p> </li> <li>Mejora el rendimiento de consultas que filtran o agrupan datos por actividades.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_VISITA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ID_FECHA\nON [Proteccion].[FACT_VISITAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ID_PROGRAMA\nON [Proteccion].[FACT_VISITAS] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ID_PERSONAL\nON [Proteccion].[FACT_VISITAS] (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos MUNICIPIO y LUGAR\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_MUNICIPIO_LUGAR\nON [Proteccion].[FACT_VISITAS] (MUNICIPIO, LUGAR);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_PLANEADA y FECHA_EJECUTADA\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_FECHAS\nON [Proteccion].[FACT_VISITAS] (FECHA_PLANEADA, FECHA_EJECUTADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ACTIVIDAD\nON [Proteccion].[FACT_VISITAS] (ACTIVIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/","title":"09.Index Transversal","text":""},{"location":"01.scripts/09.Index_Transversal/#indices-transversal","title":"Indices Transversal","text":""},{"location":"01.scripts/09.Index_Transversal/#dim_afiliados","title":"[DIM_AFILIADOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_AFILIADO</code></p> <ul> <li>La clave primaria garantiza un acceso eficiente y ordenado a los registros.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NUMERO_DOCUMENTO</code></p> <ul> <li>Este \u00edndice es esencial para las b\u00fasquedas frecuentes por el n\u00famero de documento, ya que suele ser un identificador \u00fanico en sistemas de afiliados.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>NUMERO_DOCUMENTO</code></p> <ul> <li>Optimiza las consultas que combinan tipo y n\u00famero de documento para validar registros.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code></p> <ul> <li>Facilita las b\u00fasquedas y uniones con la dimensi\u00f3n de empresas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code></p> <ul> <li>Mejora las b\u00fasquedas por correo electr\u00f3nico, a menudo usado como identificador \u00fanico o para comunicaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PRIMER_APELLIDO</code> y <code>SEGUNDO_APELLIDO</code></p> <ul> <li>Optimiza las consultas de b\u00fasqueda y agrupaci\u00f3n por apellidos, comunes en an\u00e1lisis demogr\u00e1ficos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GENERO</code></p> <ul> <li>Mejora el rendimiento en an\u00e1lisis de g\u00e9nero, com\u00fan en reportes de afiliados.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_AFILIACION</code> y <code>FECHA_AFILIACION</code></p> <ul> <li>Facilita el an\u00e1lisis y la segmentaci\u00f3n por estado y fecha de afiliaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FEC_DESDE</code> y <code>FEC_HASTA</code></p> <ul> <li>Optimiza consultas de rangos temporales, como la validez de afiliaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADOREGISTRO</code></p> <ul> <li>Mejora el rendimiento de consultas que filtran registros activos o inactivos.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_AFILIADO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_NUMERO_DOCUMENTO\nON [Transversal].[DIM_AFILIADOS] (NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_TIPO_Y_DOCUMENTO\nON [Transversal].[DIM_AFILIADOS] (TIPO_DOCUMENTO, NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_ID_EMPRESA\nON [Transversal].[DIM_AFILIADOS] (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_CORREO\nON [Transversal].[DIM_AFILIADOS] (CORREO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_APELLIDO y SEGUNDO_APELLIDO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_APELLIDOS\nON [Transversal].[DIM_AFILIADOS] (PRIMER_APELLIDO, SEGUNDO_APELLIDO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GENERO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_GENERO\nON [Transversal].[DIM_AFILIADOS] (GENERO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ESTADO_AFILIACION y FECHA_AFILIACION\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_ESTADO_FECHA\nON [Transversal].[DIM_AFILIADOS] (ESTADO_AFILIACION, FECHA_AFILIACION);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FEC_DESDE y FEC_HASTA\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_FECHAS\nON [Transversal].[DIM_AFILIADOS] (FEC_DESDE, FEC_HASTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADOREGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_ESTADOREGISTRO\nON [Transversal].[DIM_AFILIADOS] (ESTADOREGISTRO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_aportante_noafiliado","title":"[DIM_APORTANTE_NOAFILIADO]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_APORTANTE</code> </p> <ul> <li>Clave primaria que garantiza un acceso r\u00e1pido y ordenado.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code> </p> <ul> <li>Optimiza b\u00fasquedas frecuentes por el documento, clave com\u00fan en registros de aportantes.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code> </p> <ul> <li>Mejora el rendimiento en validaciones combinadas por tipo y documento, frecuentemente usadas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RAZON_SOCIAL</code> </p> <ul> <li>Facilita b\u00fasquedas por la raz\u00f3n social, \u00fatil para identificar aportantes empresariales.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTADO</code> y <code>ESTADO</code> </p> <ul> <li>Optimiza filtros por estado del aportante, comunes en an\u00e1lisis de activos/inactivos.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>SECTOR</code> y <code>CLASE</code> </p> <ul> <li>Mejora la eficiencia de consultas relacionadas con caracter\u00edsticas sectoriales y clasificaciones.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_DESDE</code> y <code>FECHA_HASTA</code> </p> <ul> <li>Facilita an\u00e1lisis y consultas en rangos temporales sobre periodos de validez.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code> </p> <ul> <li>Mejora el rendimiento de b\u00fasquedas por correo electr\u00f3nico.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PRIMER_APELLIDO</code> y <code>SEGUNDO_APELLIDO</code> </p> <ul> <li>\u00datil para b\u00fasquedas por nombres y apellidos en casos de aportantes individuales.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADOREGISTRO</code> </p> <ul> <li>Filtra registros seg\u00fan su estado actual, \u00fatil para segmentaciones de datos.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_APORTANTE\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_DOCUMENTO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_TIPO_Y_DOCUMENTO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RAZON_SOCIAL\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_RAZON_SOCIAL\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (RAZON_SOCIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_ESTADO y ESTADO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_ESTADO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (ID_ESTADO, ESTADO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos SECTOR y CLASE\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_SECTOR_CLASE\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (SECTOR, CLASE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_DESDE y FECHA_HASTA\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_FECHAS\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (FECHA_DESDE, FECHA_HASTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_CORREO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (CORREO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_APELLIDO y SEGUNDO_APELLIDO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_APELLIDOS\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (PRIMER_APELLIDO, SEGUNDO_APELLIDO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADOREGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_ESTADOREGISTRO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (ESTADOREGISTRO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_beneficiarios","title":"[DIM_BENEFICIARIOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_BENEFICIARIO</code> </p> <ul> <li>Clave primaria que garantiza acceso r\u00e1pido a registros \u00fanicos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NUMERO_DOCUMENTO</code> </p> <ul> <li>Optimiza b\u00fasquedas frecuentes por el documento del beneficiario.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>NUMERO_DOCUMENTO</code> </p> <ul> <li>Mejora el rendimiento en consultas que combinan tipo y n\u00famero de documento.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_AFILIADO</code> </p> <ul> <li>Facilita consultas relacionadas con afiliados vinculados a beneficiarios.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PRIMER_NOMBRE</code> y <code>PRIMER_APELLIDO</code> </p> <ul> <li>\u00datil en b\u00fasquedas por nombres y apellidos, especialmente en beneficiarios individuales.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_AFILIACION</code> y <code>FECHA_RETIRO</code> </p> <ul> <li>Mejora an\u00e1lisis temporales relacionados con la afiliaci\u00f3n y retiro de beneficiarios.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GENERO</code> </p> <ul> <li>Permite segmentar y filtrar beneficiarios por g\u00e9nero.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADOREGISTRO</code> </p> <ul> <li>Facilita la segmentaci\u00f3n y an\u00e1lisis por estado del registro.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FEC_DESDE</code> y <code>FEC_HASTA</code> </p> <ul> <li>Optimiza consultas en rangos temporales sobre la validez del beneficiario.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DIRECCION</code> </p> <ul> <li>Mejora b\u00fasquedas relacionadas con la localizaci\u00f3n de beneficiarios.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_BENEFICIARIO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_DOCUMENTO\nON [Transversal].[DIM_BENEFICIARIOS] (NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_TIPO_Y_DOCUMENTO\nON [Transversal].[DIM_BENEFICIARIOS] (TIPO_DOCUMENTO, NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_AFILIADO\nON [Transversal].[DIM_BENEFICIARIOS] (ID_AFILIADO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_NOMBRE y PRIMER_APELLIDO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_NOMBRES\nON [Transversal].[DIM_BENEFICIARIOS] (PRIMER_NOMBRE, PRIMER_APELLIDO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_AFILIACION y FECHA_RETIRO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_FECHAS\nON [Transversal].[DIM_BENEFICIARIOS] (FECHA_AFILIACION, FECHA_RETIRO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GENERO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_GENERO\nON [Transversal].[DIM_BENEFICIARIOS] (GENERO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADOREGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_ESTADOREGISTRO\nON [Transversal].[DIM_BENEFICIARIOS] (ESTADOREGISTRO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FEC_DESDE y FEC_HASTA\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_FECHAS_VALIDACION\nON [Transversal].[DIM_BENEFICIARIOS] (FEC_DESDE, FEC_HASTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DIRECCION\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_DIRECCION\nON [Transversal].[DIM_BENEFICIARIOS] (DIRECCION);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_capacidad_fisica","title":"[DIM_CAPACIDAD_FISICA]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_SALON</code> </p> <ul> <li>Clave primaria que asegura el acceso \u00fanico y r\u00e1pido a los registros de la tabla.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CAPACIDAD</code> </p> <ul> <li>Optimiza b\u00fasquedas y an\u00e1lisis basados en la capacidad f\u00edsica de los salones.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>JORNADA</code> y <code>BLOQUE_HORARIO</code> </p> <ul> <li>Facilita consultas relacionadas con horarios y turnos en una jornada espec\u00edfica.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GRUPO</code> </p> <ul> <li>Mejora las consultas que filtran por el grupo asignado al sal\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SEDE</code> </p> <ul> <li>Ayuda a optimizar las consultas relacionadas con sedes espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code> </p> <ul> <li>Mejora el rendimiento en consultas que relacionan las capacidades f\u00edsicas con unidades espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_SEDE</code> y <code>ID_UNIDAD</code> </p> <ul> <li>Permite consultas eficientes que cruzan datos de sedes y unidades.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_SALON\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo CAPACIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_CAPACIDAD\nON [Transversal].[DIM_CAPACIDAD_FISICA] (CAPACIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos JORNADA y BLOQUE_HORARIO\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_JORNADA_BLOQUE\nON [Transversal].[DIM_CAPACIDAD_FISICA] (JORNADA, BLOQUE_HORARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GRUPO\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_GRUPO\nON [Transversal].[DIM_CAPACIDAD_FISICA] (GRUPO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SEDE\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_ID_SEDE\nON [Transversal].[DIM_CAPACIDAD_FISICA] (ID_SEDE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_ID_UNIDAD\nON [Transversal].[DIM_CAPACIDAD_FISICA] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_SEDE y ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_SEDE_UNIDAD\nON [Transversal].[DIM_CAPACIDAD_FISICA] (ID_SEDE, ID_UNIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_cuenta_contable","title":"[DIM_CUENTA_CONTABLE]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CUENTA</code></p> <ul> <li>Es la clave primaria y asegura el acceso \u00fanico y eficiente a los registros.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CUENTA_NUMERO</code></p> <ul> <li>Optimiza consultas que filtran o agrupan por el n\u00famero de cuenta.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>CUENTA</code> y <code>CUENTA_HOMOLOGA</code></p> <ul> <li>Facilita b\u00fasquedas relacionadas con la cuenta y su homologaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_CUENTA</code></p> <ul> <li>Mejora el rendimiento de consultas que analizan o filtran cuentas por tipo.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>GRUPO_CUENTA</code> y <code>SUBGRUPO_CUENTA</code></p> <ul> <li>Acelera consultas que cruzan datos entre grupos y subgrupos de cuentas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO_REGISTRO</code></p> <ul> <li>Permite consultas r\u00e1pidas relacionadas con el estado de registro de las cuentas.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CUENTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo CUENTA_NUMERO\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_CUENTA_NUMERO\nON [Transversal].[DIM_CUENTA_CONTABLE] (CUENTA_NUMERO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CUENTA y CUENTA_HOMOLOGA\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_CUENTA_HOMOLOGA\nON [Transversal].[DIM_CUENTA_CONTABLE] (CUENTA, CUENTA_HOMOLOGA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_CUENTA\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_TIPO_CUENTA\nON [Transversal].[DIM_CUENTA_CONTABLE] (TIPO_CUENTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos GRUPO_CUENTA y SUBGRUPO_CUENTA\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_GRUPO_SUBGRUPO\nON [Transversal].[DIM_CUENTA_CONTABLE] (GRUPO_CUENTA, SUBGRUPO_CUENTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO_REGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_ESTADO_REGISTRO\nON [Transversal].[DIM_CUENTA_CONTABLE] (ESTADO_REGISTRO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_empresas","title":"[DIM_EMPRESAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_EMPRESA</code></p> <ul> <li>Es la clave primaria y permite b\u00fasquedas r\u00e1pidas por el identificador \u00fanico de empresa.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code></p> <ul> <li>Optimiza b\u00fasquedas y validaciones de empresas por n\u00famero de documento.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>RAZON_SOCIAL</code> y <code>SECTOR</code></p> <ul> <li>Facilita las b\u00fasquedas combinadas de empresas por raz\u00f3n social y sector.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>FECHA_AFILIACION</code></p> <ul> <li>Mejora el rendimiento en consultas relacionadas con la fecha de afiliaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADOREGISTRO</code> y <code>ESTADO</code></p> <ul> <li>Acelera consultas que filtran por el estado del registro y el estado de la empresa.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ACT_ECONOMICA</code></p> <ul> <li>Permite b\u00fasquedas m\u00e1s eficientes al filtrar por actividad econ\u00f3mica.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_EMPRESA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_DOCUMENTO\nON [Transversal].[DIM_EMPRESAS] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos RAZON_SOCIAL y SECTOR\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_RAZON_SOCIAL_SECTOR\nON [Transversal].[DIM_EMPRESAS] (RAZON_SOCIAL, SECTOR);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_AFILIACION\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_FECHA_AFILIACION\nON [Transversal].[DIM_EMPRESAS] (FECHA_AFILIACION);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ESTADOREGISTRO y ESTADO\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_ESTADO_REGISTRO_ESTADO\nON [Transversal].[DIM_EMPRESAS] (ESTADOREGISTRO, ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ACT_ECONOMICA\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_ID_ACT_ECONOMICA\nON [Transversal].[DIM_EMPRESAS] (ID_ACT_ECONOMICA);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_personal","title":"[DIM_PERSONAL]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PERSONAL</code></p> <ul> <li>Es la clave primaria que permite b\u00fasquedas r\u00e1pidas por el identificador \u00fanico del personal.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code></p> <ul> <li>Facilita b\u00fasquedas frecuentes por n\u00famero de documento, que es una consulta com\u00fan en sistemas de personal.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_UNIDAD</code> y <code>ID_SERVICIO</code></p> <ul> <li>Mejora la eficiencia de consultas relacionadas con la asignaci\u00f3n de personal a unidades y servicios.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO_CONTRATACION</code> y <code>FECHA_FIN_CONTRATACION</code></p> <ul> <li>Optimiza consultas que filtran registros por periodos de contrataci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code></p> <ul> <li>Permite b\u00fasquedas r\u00e1pidas por correo electr\u00f3nico, \u00fatil en sistemas de contacto.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>GENERO</code> y <code>NIVEL_INGLES</code></p> <ul> <li>Acelera consultas relacionadas con la demograf\u00eda del personal y sus habilidades ling\u00fc\u00edsticas.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PERSONAL\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_DOCUMENTO\nON [Transversal].[DIM_PERSONAL] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_UNIDAD e ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_ID_UNIDAD_ID_SERVICIO\nON [Transversal].[DIM_PERSONAL] (ID_UNIDAD, ID_SERVICIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO_CONTRATACION y FECHA_FIN_CONTRATACION\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_FECHA_CONTRATACION\nON [Transversal].[DIM_PERSONAL] (FECHA_INICIO_CONTRATACION, FECHA_FIN_CONTRATACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_CORREO\nON [Transversal].[DIM_PERSONAL] (CORREO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos GENERO y NIVEL_INGLES\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_GENERO_NIVEL_INGLES\nON [Transversal].[DIM_PERSONAL] (GENERO, NIVEL_INGLES);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_sedes","title":"[DIM_SEDES]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_SEDE</code></p> <ul> <li>Es la clave primaria que asegura la unicidad de cada sede y permite b\u00fasquedas r\u00e1pidas por su identificador.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SEDE</code></p> <ul> <li>Optimiza consultas que filtran o buscan registros por el nombre de la sede, lo cual es com\u00fan en reportes o visualizaciones.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_SEDE\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo SEDE\nCREATE NONCLUSTERED INDEX IX_DIM_SEDES_SEDE\nON [Transversal].[DIM_SEDES] (SEDE);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_servicios","title":"[DIM_SERVICIOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_SERVICIO</code></p> <ul> <li>Es la clave primaria que asegura la unicidad de cada servicio y permite b\u00fasquedas r\u00e1pidas por este identificador.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SERVICIO</code></p> <ul> <li>Optimiza consultas que buscan informaci\u00f3n espec\u00edfica por el nombre del servicio, com\u00fan en reportes y an\u00e1lisis.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CATEGORIA</code> y <code>COD_CATEGORIA</code></p> <ul> <li>Mejora el rendimiento de las consultas que agrupan o filtran servicios por categor\u00eda o c\u00f3digo de categor\u00eda.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ANIO_TARIFA</code> y <code>VAL_TARIFA</code></p> <ul> <li>Facilita las consultas que analizan las tarifas anuales de los servicios.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Permite relacionar eficientemente los servicios con su unidad correspondiente.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>CIUDAD</code> y <code>NOMBRE_ESTABLECIMIENTO</code></p> <ul> <li>Optimiza consultas relacionadas con la ubicaci\u00f3n y establecimiento del servicio.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_SERVICIO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo SERVICIO\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_SERVICIO\nON [Transversal].[DIM_SERVICIOS] (SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_CATEGORIA\nON [Transversal].[DIM_SERVICIOS] (CATEGORIA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_CATEGORIA\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_COD_CATEGORIA\nON [Transversal].[DIM_SERVICIOS] (COD_CATEGORIA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ANIO_TARIFA y VAL_TARIFA\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_ANIO_VAL_TARIFA\nON [Transversal].[DIM_SERVICIOS] (ANIO_TARIFA, VAL_TARIFA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_ID_UNIDAD\nON [Transversal].[DIM_SERVICIOS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CIUDAD y NOMBRE_ESTABLECIMIENTO\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_CIUDAD_ESTABLECIMIENTO\nON [Transversal].[DIM_SERVICIOS] (CIUDAD, NOMBRE_ESTABLECIMIENTO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_unidad","title":"[DIM_UNIDAD]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_UNIDAD</code></p> <ul> <li>Es la clave primaria, garantiza la unicidad de cada unidad y optimiza las b\u00fasquedas por este identificador.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>UNIDAD</code></p> <ul> <li>Facilita las consultas que filtran o buscan datos espec\u00edficos por el nombre de la unidad, com\u00fan en reportes y an\u00e1lisis.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_UNIDAD\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDAD_UNIDAD\nON [Transversal].[DIM_UNIDAD] (UNIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_unidades_organizativas","title":"[DIM_UNIDADES_ORGANIZATIVAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CEBE</code></p> <ul> <li>Es la clave primaria, asegura unicidad y optimiza b\u00fasquedas espec\u00edficas por el identificador de unidad organizativa.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CEBE</code></p> <ul> <li>Facilita b\u00fasquedas r\u00e1pidas y filtrados por el c\u00f3digo de la unidad organizativa (<code>CEBE</code>).</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DESCRIPCION_BREVE</code> y <code>DESCRIPCION_COMPLETA</code></p> <ul> <li>Acelera las consultas que buscan por descripciones espec\u00edficas o detalladas de la unidad.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>DEPARTAMENTO</code>, <code>AREA</code>, y <code>SUBAREA</code></p> <ul> <li>Optimiza consultas relacionadas con la jerarqu\u00eda organizativa (departamentos, \u00e1reas, sub\u00e1reas).</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>SEGMENTO</code> y <code>DESCRIPCION_SEGMENTO</code></p> <ul> <li>Mejora el rendimiento de consultas segmentadas por estos campos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CODIGO_SSF</code> y <code>NOMBRE_SSF</code></p> <ul> <li>Soporta b\u00fasquedas relacionadas con los c\u00f3digos y nombres del sistema de soporte financiero.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CEBE\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo CEBE\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_CEBE\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (CEBE);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos DESCRIPCION_BREVE y DESCRIPCION_COMPLETA\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_DESCRIPCION\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (DESCRIPCION_BREVE, DESCRIPCION_COMPLETA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos DEPARTAMENTO, AREA y SUBAREA\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_DEPARTAMENTO_AREA\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (DEPARTAMENTO, AREA, SUBAREA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos SEGMENTO y DESCRIPCION_SEGMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_SEGMENTO\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (SEGMENTO, DESCRIPCION_SEGMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos CODIGO_SSF y NOMBRE_SSF\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_CODIGO_SSF\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (CODIGO_SSF, NOMBRE_SSF);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_aportes_shr_det","title":"[FACT_APORTES_SHR_DET]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code> y <code>ID_AFILIADO</code></p> <ul> <li>Optimiza las b\u00fasquedas y relaciones con las tablas de dimensiones relacionadas como DIM_EMPRESAS y DIM_AFILIADOS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PERIODO</code></p> <ul> <li>Mejora las consultas que filtran o agrupan por periodos espec\u00edficos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Acelera las b\u00fasquedas y an\u00e1lisis de datos basados en fechas, que suelen ser comunes en tablas de hechos.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>OPBEL</code>, <code>BELNR</code> y <code>MOVIMIENTO</code></p> <ul> <li>Facilita la recuperaci\u00f3n de datos relacionados con transacciones espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_CONTABLE</code> y <code>NUM_CUENTA</code></p> <ul> <li>Optimiza consultas basadas en las cuentas contables y fechas asociadas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>APORTE</code> y <code>INTERES</code></p> <ul> <li>Acelera consultas que analizan montos de aportes e intereses.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>FECHA_ACTUALIZACION</code></p> <ul> <li>Mejora el rendimiento en la detecci\u00f3n de cambios recientes.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para los campos ID_EMPRESA y ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_EMPRESA_AFILIADO\nON [Transversal].[FACT_APORTES_SHR_DET] (ID_EMPRESA, ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_PERIODO\nON [Transversal].[FACT_APORTES_SHR_DET] (PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_FECHA\nON [Transversal].[FACT_APORTES_SHR_DET] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos OPBEL, BELNR y MOVIMIENTO\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_TRANSACCION\nON [Transversal].[FACT_APORTES_SHR_DET] (OPBEL, BELNR, MOVIMIENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_CONTABLE y NUM_CUENTA\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_CONTABLE_CUENTA\nON [Transversal].[FACT_APORTES_SHR_DET] (FECHA_CONTABLE, NUM_CUENTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos APORTE y INTERES\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_APORTE_INTERES\nON [Transversal].[FACT_APORTES_SHR_DET] (APORTE, INTERES);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_ACTUALIZACION\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_FECHA_ACTUALIZACION\nON [Transversal].[FACT_APORTES_SHR_DET] (FECHA_ACTUALIZACION);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_convenios","title":"[FACT_CONVENIOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Acelera consultas basadas en fechas, especialmente aquellas relacionadas con la dimensi\u00f3n de tiempo.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza consultas que filtran por unidad, en relaci\u00f3n con la tabla de dimensi\u00f3n DIM_UNIDAD.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code></p> <ul> <li>Mejora la eficiencia de b\u00fasquedas relacionadas con programas espec\u00edficos, permitiendo una mejor integraci\u00f3n con las consultas de an\u00e1lisis.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code></p> <ul> <li>Facilita consultas que involucren rangos de fechas, comunes en an\u00e1lisis de duraci\u00f3n de convenios.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>VALOR_CONVENIO</code></p> <ul> <li>Acelera consultas que analizan valores monetarios de los convenios.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_CONVENIO</code> y <code>MUNICIPIO</code></p> <ul> <li>Permite consultas r\u00e1pidas que filtran por estado y ubicaci\u00f3n de los convenios.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_FECHA\nON [Transversal].[FACT_CONVENIOS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_UNIDAD\nON [Transversal].[FACT_CONVENIOS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_PROGRAMA\nON [Transversal].[FACT_CONVENIOS] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_FECHAS\nON [Transversal].[FACT_CONVENIOS] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo VALOR_CONVENIO\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_VALOR\nON [Transversal].[FACT_CONVENIOS] (VALOR_CONVENIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ESTADO_CONVENIO y MUNICIPIO\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_ESTADO_MUNICIPIO\nON [Transversal].[FACT_CONVENIOS] (ESTADO_CONVENIO, MUNICIPIO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_detalle_contable","title":"[FACT_DETALLE_CONTABLE]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CUENTA</code></p> <ul> <li>Facilita consultas y uniones relacionadas con cuentas contables en la dimensi\u00f3n DIM_CUENTA_CONTABLE.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora la eficiencia de consultas relacionadas con la dimensi\u00f3n de tiempo para an\u00e1lisis contable por per\u00edodos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CEBE</code></p> <ul> <li>Optimiza las b\u00fasquedas relacionadas con unidades organizativas en la dimensi\u00f3n DIM_UNIDADES_ORGANIZATIVAS.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_REGISTRO_SAP</code> y <code>FECHA_PROCESO</code></p> <ul> <li>Acelera las consultas que analizan registros por rangos de fechas o estados de proceso.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>IMPORTE</code> y <code>RESULTADO_EJERCICIO</code></p> <ul> <li>Mejora el rendimiento de an\u00e1lisis de resultados financieros y balances.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_CUENTA\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_ID_CUENTA\nON [Transversal].[FACT_DETALLE_CONTABLE] (ID_CUENTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_ID_FECHA\nON [Transversal].[FACT_DETALLE_CONTABLE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CEBE\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_ID_CEBE\nON [Transversal].[FACT_DETALLE_CONTABLE] (ID_CEBE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_REGISTRO_SAP y FECHA_PROCESO\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_FECHAS\nON [Transversal].[FACT_DETALLE_CONTABLE] (FECHA_REGISTRO_SAP, FECHA_PROCESO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos IMPORTE y RESULTADO_EJERCICIO\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_IMPORTE_RESULTADO\nON [Transversal].[FACT_DETALLE_CONTABLE] (IMPORTE, RESULTADO_EJERCICIO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_encuestas","title":"[FACT_ENCUESTAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora el rendimiento en consultas relacionadas con an\u00e1lisis temporales y de periodos de encuestas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza las consultas relacionadas con unidades y servicios prestados.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_AFILIADO</code>, <code>ID_EMPRESA</code>, <code>ID_BENEFICIARIO</code>, y <code>ID_APORTANTE</code></p> <ul> <li>Cada uno mejora las b\u00fasquedas en las relaciones con las respectivas dimensiones.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code></p> <ul> <li>Acelera consultas espec\u00edficas por identificaci\u00f3n de los encuestados.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SERVICIO</code> y <code>CALIFICACION</code></p> <ul> <li>Mejora el rendimiento en consultas anal\u00edticas sobre el servicio y su evaluaci\u00f3n.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_FECHA\nON [Transversal].[FACT_ENCUESTAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_UNIDAD\nON [Transversal].[FACT_ENCUESTAS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_AFILIADO\nON [Transversal].[FACT_ENCUESTAS] (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_EMPRESA\nON [Transversal].[FACT_ENCUESTAS] (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_BENEFICIARIO\nON [Transversal].[FACT_ENCUESTAS] (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_APORTANTE\nON [Transversal].[FACT_ENCUESTAS] (ID_APORTANTE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_TIPO_DOCUMENTO_DOCUMENTO\nON [Transversal].[FACT_ENCUESTAS] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_SERVICIO\nON [Transversal].[FACT_ENCUESTAS] (SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_CALIFICACION\nON [Transversal].[FACT_ENCUESTAS] (CALIFICACION);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_encuestas_psr","title":"[FACT_ENCUESTAS_PSR]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora el rendimiento de consultas por fechas y an\u00e1lisis temporales de encuestas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PROGRAMA</code> y <code>ACTIVIDAD_PREGUNTA</code></p> <ul> <li>Optimiza las b\u00fasquedas y an\u00e1lisis por tipo de programa y actividades asociadas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code></p> <ul> <li>Acelera consultas espec\u00edficas por identificaci\u00f3n de los encuestados.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CALIFICACION</code></p> <ul> <li>Mejora el rendimiento en consultas que analicen resultados por calificaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndices no cl\u00faster para <code>ID_AFILIADO</code>, <code>ID_BENEFICIARIO</code>, <code>ID_APORTANTE</code>, y <code>ID_EMPRESA</code></p> <ul> <li>Cada uno optimiza consultas que relacionen la tabla con sus dimensiones correspondientes.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_FECHA\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos PROGRAMA y ACTIVIDAD_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_PROGRAMA_ACTIVIDAD\nON [Transversal].[FACT_ENCUESTAS_PSR] (PROGRAMA, ACTIVIDAD_PREGUNTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_TIPO_DOCUMENTO_DOCUMENTO\nON [Transversal].[FACT_ENCUESTAS_PSR] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_CALIFICACION\nON [Transversal].[FACT_ENCUESTAS_PSR] (CALIFICACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_AFILIADO\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_BENEFICIARIO\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_APORTANTE\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_APORTANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_EMPRESA\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_EMPRESA);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_iniciativas","title":"[FACT_INICIATIVAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora las consultas basadas en tiempo, como filtrados por fechas de inicio o fin de iniciativas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza las b\u00fasquedas y relaciones con la dimensi\u00f3n de unidades organizativas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code></p> <ul> <li>Facilita las consultas basadas en rangos de fechas para iniciativas activas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_INICIATIVA</code></p> <ul> <li>Mejora el rendimiento de b\u00fasquedas basadas en el nombre de iniciativas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>OBSERVACIONES</code></p> <ul> <li>Optimiza las b\u00fasquedas por notas o comentarios asociados a las iniciativas.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_ID_FECHA\nON [Transversal].[FACT_INICIATIVAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_ID_UNIDAD\nON [Transversal].[FACT_INICIATIVAS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_FECHA_INICIO_FIN\nON [Transversal].[FACT_INICIATIVAS] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_INICIATIVA\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_NOMBRE_INICIATIVA\nON [Transversal].[FACT_INICIATIVAS] (NOMBRE_INICIATIVA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_OBSERVACIONES\nON [Transversal].[FACT_INICIATIVAS] (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_pqrs","title":"[FACT_PQRS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora las consultas basadas en tiempo, como filtros por fechas de creaci\u00f3n, resoluci\u00f3n o vencimiento.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza las b\u00fasquedas relacionadas con unidades espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_CREACION</code>, <code>FECHA_RESOLUCION</code> y <code>FECHA_VENCIMIENTO</code></p> <ul> <li>Acelera las consultas que involucran rangos de fechas para seguimiento de PQRS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO</code></p> <ul> <li>Incrementa la eficiencia en consultas relacionadas con el estado de las PQRS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_PQRS</code></p> <ul> <li>Facilita la b\u00fasqueda y clasificaci\u00f3n por tipo de PQRS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>ID_BENEFICIARIO</code>, <code>ID_APORTANTE</code></p> <ul> <li>Optimiza las relaciones con dimensiones relacionadas para an\u00e1lisis detallados.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_ID_FECHA\nON [Transversal].[FACT_PQRS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_ID_UNIDAD\nON [Transversal].[FACT_PQRS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos de fechas\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_FECHAS\nON [Transversal].[FACT_PQRS] (FECHA_CREACION, FECHA_RESOLUCION, FECHA_VENCIMIENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_ESTADO\nON [Transversal].[FACT_PQRS] (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_PQRS\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_TIPO_PQRS\nON [Transversal].[FACT_PQRS] (TIPO_PQRS);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos de dimensiones relacionadas\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_RELACIONES\nON [Transversal].[FACT_PQRS] (ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_presupuesto","title":"[FACT_PRESUPUESTO]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora la eficiencia en consultas que analizan presupuestos basados en periodos de tiempo.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CUENTA</code></p> <ul> <li>Optimiza la b\u00fasqueda y an\u00e1lisis de presupuestos asociados a cuentas contables espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CEBE</code></p> <ul> <li>Aumenta el rendimiento en consultas relacionadas con unidades organizativas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_TIPO_PRESUPUESTO</code> y <code>SEGMENT</code></p> <ul> <li>Facilita el an\u00e1lisis de presupuestos seg\u00fan el tipo y segmento.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para campos relacionados con valores (<code>INGRESOS</code>, <code>GASTOS</code>, <code>COSTOS</code>)</p> <ul> <li>Mejora el rendimiento de c\u00e1lculos financieros basados en estos campos.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_ID_FECHA\nON [Transversal].[FACT_PRESUPUESTO] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CUENTA\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_ID_CUENTA\nON [Transversal].[FACT_PRESUPUESTO] (ID_CUENTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CEBE\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_ID_CEBE\nON [Transversal].[FACT_PRESUPUESTO] (ID_CEBE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_TIPO_PRESUPUESTO y SEGMENT\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_TIPO_SEGMENT\nON [Transversal].[FACT_PRESUPUESTO] (ID_TIPO_PRESUPUESTO, SEGMENT);\nGO\n\n-- \u00cdndices no cl\u00faster para campos relacionados con valores\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_INGRESOS\nON [Transversal].[FACT_PRESUPUESTO] (INGRESOS, INGRESOS_OPERACIONALES);\nGO\n\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_GASTOS\nON [Transversal].[FACT_PRESUPUESTO] (GASTOS, GASTOS_OPERACIONALES, GASTOS_OPERACIONALES_ADMIN);\nGO\n\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_COSTOS\nON [Transversal].[FACT_PRESUPUESTO] (COSTOS);\nGO\n</code></pre>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/","title":"00. WEB SCRAPING","text":"<p>El contenido proporcionado documenta una amplia variedad de componentes y tareas en una soluci\u00f3n SSIS. Aqu\u00ed se integran scripts de Python como tareas externas para realizar operaciones espec\u00edficas. A continuaci\u00f3n, se detalla la actualizaci\u00f3n del modelo con base en este contenido.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#introduccion","title":"Introducci\u00f3n","text":"<p>El modelo de integraci\u00f3n documentado combina tareas de procesamiento de datos en SSIS con la ejecuci\u00f3n de scripts de Python externos. Estos scripts permiten realizar validaciones avanzadas, procesamiento din\u00e1mico y conexiones con sistemas externos como SharePoint. La soluci\u00f3n garantiza una ejecuci\u00f3n eficiente, flexible y configurable gracias al uso de expresiones del proyecto para adaptar rutas de trabajo y ejecutables a diferentes entornos.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#resumen-general","title":"Resumen General","text":"<p>Objetivos:</p> <ol> <li>Automatizaci\u00f3n: Integrar tareas repetitivas mediante scripts de Python.</li> <li>Estandarizaci\u00f3n: Establecer configuraciones din\u00e1micas para adaptabilidad en entornos variados.</li> <li>Escalabilidad: Dise\u00f1ar un modelo modular para incorporar nuevos flujos.</li> </ol> <p>Componentes Clave:</p> <ul> <li>Scripts Python:<ul> <li>Conexi\u00f3n y extracci\u00f3n desde SharePoint.</li> <li>Procesamiento de datos educativos, administrativos y financieros.</li> </ul> </li> <li>Tareas SSIS:<ul> <li>Ejecuci\u00f3n de scripts externos con configuraciones din\u00e1micas.</li> <li>Validaci\u00f3n y carga en el Data Warehouse.</li> </ul> </li> </ul> <p>Fuentes y Destinos:</p> <ul> <li>Fuentes:<ul> <li>Archivos planos, Excel y bases de datos relacionales.</li> <li>Sistemas externos a trav\u00e9s de scripts Python.</li> </ul> </li> <li>Destinos:<ul> <li>Tablas de hechos y dimensiones en el Data Warehouse <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as Python Executable\n    participant Script as Python Script\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; Python: Ejecuta script con configuraciones din\u00e1micas\n    Python -&gt;&gt; Script: Procesa datos o conecta con sistemas externos\n    Script -&gt;&gt; Python: Devuelve resultado\n    Python -&gt;&gt; SSIS: C\u00f3digo de retorno\n    SSIS -&gt;&gt; DWH: Carga datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#buenas-practicas","title":"Buenas Pr\u00e1cticas","text":"<ol> <li> <p>Configuraci\u00f3n Din\u00e1mica:</p> <ul> <li>Definir ejecutables y directorios mediante variables de proyecto.</li> <li>Adaptar las rutas seg\u00fan los entornos de desarrollo, pruebas y producci\u00f3n.</li> </ul> </li> <li> <p>Registro de Logs:</p> <ul> <li>Capturar la salida de los scripts Python para auditor\u00eda y resoluci\u00f3n de errores.</li> <li>Configurar registros detallados en SSIS.</li> </ul> </li> <li> <p>Compatibilidad:</p> <ul> <li>Validar la versi\u00f3n de Python y las dependencias necesarias para cada script.</li> <li>Probar la ejecuci\u00f3n en entornos similares al de producci\u00f3n.</li> </ul> </li> <li> <p>Ejecuci\u00f3n Segura:</p> <ul> <li>Establecer manejadores para c\u00f3digos de retorno inesperados.</li> <li>Asegurar la idempotencia de los scripts para evitar duplicidades.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-tecnicos","title":"Detalles T\u00e9cnicos","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componentes-principales","title":"Componentes Principales:","text":"<p>1. Ejecuci\u00f3n de Scripts Python:</p> <ul> <li>Propiedades Clave:<ul> <li>Ejecutable: Ruta del ejecutable de Python.</li> <li>Argumentos: Nombre del script y par\u00e1metros adicionales.</li> <li>Directorio de Trabajo: Ruta base configurada din\u00e1micamente.</li> </ul> </li> <li>C\u00f3digo de Retorno:<ul> <li>Configurado para no marcar fallos autom\u00e1ticamente.</li> </ul> </li> </ul> <p>2. Conexiones con Sistemas Externos:</p> <ul> <li>Scripts dedicados para conectar y extraer datos desde SharePoint.</li> <li>Generaci\u00f3n de registros detallados durante el proceso.</li> </ul> <p>3. Tareas de Procesamiento:</p> <ul> <li>Scripts que procesan datos educativos (docentes, matr\u00edculas, egresados).</li> <li>Scripts para consolidar datos operativos (ausencias, ingresos).</li> </ul>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#secuencia-de-operaciones","title":"Secuencia de Operaciones","text":"<ol> <li>Lee el valor de las expresiones del proyecto para determinar el ejecutable y el directorio de trabajo.</li> <li>Construye la instrucci\u00f3n de ejecuci\u00f3n del script.</li> <li>Ejecuta el script en el contexto del directorio especificado.</li> <li>Verifica el c\u00f3digo de retorno para determinar el estado de la tarea, pero no marca como fallo si no es un valor de \u00e9xito.</li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Executable\n    participant Script as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecutar `python.exe archivo_python.py`\n    Python -&gt;&gt; Script: Inicia ejecuci\u00f3n\n    Script -&gt;&gt; Python: Devuelve resultado\n    Python -&gt;&gt; SSIS: C\u00f3digo de retorno (no se fuerza fallo)</code></pre>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#consideraciones","title":"Consideraciones","text":"<ol> <li>Versiones de Python: El ejecutable especificado debe ser compatible con el script, asegurando que las bibliotecas y dependencias est\u00e9n instaladas.</li> <li>Errores en el Script: La tarea no fallar\u00e1 autom\u00e1ticamente si el c\u00f3digo de retorno no es exitoso. Si se requiere manejar este comportamiento, se debe incluir l\u00f3gica adicional en el flujo de trabajo.</li> <li>Configuraci\u00f3n Din\u00e1mica: Las expresiones del proyecto permiten adaptar el ejecutable y el directorio de trabajo seg\u00fan las configuraciones del entorno, facilitando portabilidad y mantenimiento.</li> <li>Control de Log: Configurar un registro adecuado para capturar la salida del script, especialmente si se omiten errores de retorno.</li> </ol> <p>Este componente es ideal para integrar scripts externos de Python en el flujo de ETL de SSIS, proporcionando flexibilidad para realizar tareas avanzadas o espec\u00edficas fuera del entorno nativo de SSIS.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#desarrollo-empresarial","title":"Desarrollo Empresarial","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01-docentes_desarrollo_empresarial","title":"Componente <code>Ejecutar Proceso: 01 Docentes_desarrollo_empresarial</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.Docentes_desarrollo_empresarial.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_docentes","title":"Componente <code>Ejecutar Proceso: emp_Docentes</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_1","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_01_Docentes.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-02preinscritospy","title":"Componente <code>Ejecutar Proceso: 02.Preinscritos.py</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_2","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>02.Preinscritos.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_03_preinscritos","title":"Componente <code>Ejecutar Proceso: emp_03_preinscritos</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_3","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_03_preinscritos.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-03listado_matriculas_emp","title":"Componente <code>Ejecutar Proceso: 03.Listado_matriculas_emp</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_4","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>03.Listado_matriculas_emp.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_02_listado_matriculas","title":"Componente <code>Ejecutar Proceso: emp_02_listado_matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_5","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_02_listado_matriculas.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04consolidado_inasistencias","title":"Componente <code>Ejecutar Proceso: 04.Consolidado_inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_6","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_06_consolidado_inasistencias","title":"Componente <code>Ejecutar Proceso: emp_06_consolidado_Inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_7","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_06_consolidado_Inasistencias.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-06egresados_graduados_empresarial","title":"Componente <code>Ejecutar Proceso: 06.Egresados_graduados_empresarial</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_8","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>06.Egresados_graduados_empresarial.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_04_egresados_graduados","title":"Componente <code>Ejecutar Proceso: emp_04_egresados_Graduados</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_9","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_04_egresados_Graduados.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-05estudiantes_inasistencias","title":"Componente <code>Ejecutar Proceso: 05.Estudiantes_inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_10","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>05.Estudiantes_inasistencias.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_05_estudiantes_inasistencias","title":"Componente <code>Ejecutar Proceso: emp_05_Estudiantes_inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_11","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_05_Estudiantes_inasistencias.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#desarrollo-empresarial-ejecucion-de-nodos-en-paralelo","title":"Desarrollo Empresarial <code>Ejecucion de nodos en paralelo</code>","text":"<p>Para optimizar los tiempos de procesamiento del scraping, los siguientes nodos del paquete se ejecutan en paralelo:</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-tarde-c-p","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Tarde \"c, p\"</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Tarde para el grupo identificado con el par\u00e1metro \"c, p\". La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python definido mediante variables de proyecto, lo que permite adaptar la configuraci\u00f3n a diferentes entornos.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_12","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py</code> con el par\u00e1metro <code>--alfabeto \"c, p\"</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py --alfabeto \"c, p\"</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no marca error si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, lo que permite centralizar y actualizar esta configuraci\u00f3n seg\u00fan el entorno.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts, la cual se concatena con la ruta relativa <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-tarde-lote-1","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Tarde Lote 1</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias del turno Tarde, espec\u00edficamente para el \u201cLote 1\u201d. Se utiliza un conjunto particular de par\u00e1metros para definir el alfabeto de procesamiento, que en este caso incluye caracteres especiales, d\u00edgitos y letras. La tarea se ejecuta desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python configurado a trav\u00e9s de variables de proyecto, lo que permite su adaptaci\u00f3n a distintos entornos.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_13","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py</code> con el par\u00e1metro <code>--alfabeto \"\u00bf, 1, 2, 3, 4, 5, a, b, d, e, f, g, h, i, j, k, l\"</code>     desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   La ruta del ejecutable se determina din\u00e1micamente a trav\u00e9s de la variable de proyecto <code>@[$Project::Python_Executable]</code>, que en tiempo de ejecuci\u00f3n corresponde a: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py --alfabeto \"\u00bf, 1, 2, 3, 4, 5, a, b, d, e, f, g, h, i, j, k, l\"</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no se marca como fallida si el c\u00f3digo de retorno no indica \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>):   Se utiliza un valor de 3, lo que sugiere que la tarea puede beneficiarse de mayor paralelismo en su ejecuci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python. Permite centralizar la configuraci\u00f3n del int\u00e9rprete, facilitando su actualizaci\u00f3n en distintos entornos (desarrollo, pruebas o producci\u00f3n).</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Esta variable se concatena con la ruta relativa <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-tarde-lote-3","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Tarde Lote 3</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias del turno Tarde para el \u201cLote 3\u201d. La tarea se ejecuta desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python definido mediante variables de proyecto, lo que facilita la configuraci\u00f3n adaptable a distintos entornos. Se configura para que, en caso de que el c\u00f3digo de retorno del proceso no indique \u00e9xito, el flujo ETL no se interrumpa.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_14","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py</code> con el par\u00e1metro <code>--alfabeto \"m, n, \u00f1, o, q, r, s, t, u, v, w, x, y, z\"</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py --alfabeto \"m, n, \u00f1, o, q, r, s, t, u, v, w, x, y, z\"</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura mediante la expresi\u00f3n: <code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\01.Q10\\\\02.Educacion_Continua\"</code></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea contin\u00faa el flujo ETL aunque el proceso retorne un c\u00f3digo diferente al de \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>):   Se utiliza un valor de 1, lo que indica que la ejecuci\u00f3n se realizar\u00e1 en un \u00fanico hilo.</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python. Esta configuraci\u00f3n centralizada permite actualizar la ubicaci\u00f3n del int\u00e9rprete sin modificar la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se concatena con la ruta relativa <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-manana-c","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Ma\u00f1ana c</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Ma\u00f1ana para el grupo identificado con el par\u00e1metro \"c\". La tarea se ejecuta desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python definido a trav\u00e9s de variables de proyecto, permitiendo adaptar la configuraci\u00f3n a distintos entornos. Adem\u00e1s, se ha configurado para que, incluso si el proceso retorna un c\u00f3digo de error, el flujo ETL contin\u00fae sin marcar la tarea como fallida.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_15","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py</code> con el par\u00e1metro <code>--alfabeto c</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se establece mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>, la cual, en tiempo de ejecuci\u00f3n, corresponde a la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py --alfabeto c</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no se marca como fallida si el c\u00f3digo de retorno del proceso no indica \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>6</code> (sugiere que la tarea est\u00e1 optimizada para aprovechar hasta 6 hilos durante su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, permitiendo centralizar y actualizar esta configuraci\u00f3n sin modificar directamente la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se utiliza para establecer el contexto de ejecuci\u00f3n mediante la concatenaci\u00f3n con la ruta relativa <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-manana-p","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Ma\u00f1ana p</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Ma\u00f1ana para el grupo identificado con el par\u00e1metro \"p\". La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python configurado mediante variables de proyecto, lo que permite adaptar la tarea a diferentes entornos. Adem\u00e1s, se ha configurado para que, en caso de que el c\u00f3digo de retorno del proceso no indique \u00e9xito, el flujo ETL contin\u00fae sin marcar la tarea como fallida.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_16","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py</code> con el par\u00e1metro <code>--alfabeto p</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Definido a trav\u00e9s de la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py --alfabeto p</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Configurado din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea contin\u00faa el flujo ETL aunque el proceso retorne un c\u00f3digo diferente al de \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>7</code> (sugiere que la tarea puede beneficiarse de un mayor paralelismo durante su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, lo que permite centralizar y actualizar esta configuraci\u00f3n sin modificar la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se utiliza para establecer el contexto de ejecuci\u00f3n al concatenarse con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-manana-lote-1","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Ma\u00f1ana Lote 1</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Ma\u00f1ana para el \"Lote 1\". La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python configurado mediante variables de proyecto, permitiendo su adaptaci\u00f3n a distintos entornos. La tarea est\u00e1 dise\u00f1ada para continuar el flujo ETL incluso si el proceso retorna un c\u00f3digo de error.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_17","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py</code> con el par\u00e1metro <code>--alfabeto a, b, d, e, f, g, h, i, j, k, l</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>, que en tiempo de ejecuci\u00f3n corresponde a: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py --alfabeto a, b, d, e, f, g, h, i, j, k, l</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Configurado din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea contin\u00faa el flujo ETL aunque el proceso retorne un c\u00f3digo de error).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>8</code> (se sugiere que la tarea puede aprovechar el paralelismo utilizando hasta 8 hilos durante su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, centralizando la configuraci\u00f3n para facilitar su actualizaci\u00f3n y adaptaci\u00f3n a diferentes entornos (desarrollo, pruebas, producci\u00f3n).</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se concatena con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto adecuado de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-manana-lote-2","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Ma\u00f1ana Lote 2</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias del turno Ma\u00f1ana, espec\u00edficamente para el \"Lote 2\". La tarea se ejecuta desde un directorio de trabajo espec\u00edfico y utiliza el ejecutable de Python definido a trav\u00e9s de variables de proyecto, lo que permite adaptar la configuraci\u00f3n a distintos entornos. Adem\u00e1s, la tarea est\u00e1 configurada para que el flujo ETL contin\u00fae su ejecuci\u00f3n incluso si el proceso retorna un c\u00f3digo de error.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_18","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py</code> con el par\u00e1metro <code>--alfabeto m, n, \u00f1, o, q, r, s, t, u, v, w, x, y, z</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py --alfabeto m, n, \u00f1, o, q, r, s, t, u, v, w, x, y, z</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura mediante la expresi\u00f3n: <code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\01.Q10\\\\02.Educacion_Continua\"</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no marca error si el proceso retorna un c\u00f3digo diferente al de \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>9</code> (sugiere que la tarea puede aprovechar hasta 9 hilos para mejorar el procesamiento paralelo).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, permitiendo centralizar y actualizar esta configuraci\u00f3n seg\u00fan el entorno (desarrollo, pruebas, producci\u00f3n).</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts, la cual se concatena con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto adecuado de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-sabado","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Sabado</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondiente al d\u00eda S\u00e1bado. La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python configurado a trav\u00e9s de variables de proyecto, lo que permite la adaptabilidad a distintos entornos. Adem\u00e1s, la tarea est\u00e1 dise\u00f1ada para continuar el flujo ETL incluso si el proceso retorna un c\u00f3digo de error.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_19","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Parametro.py</code> con el par\u00e1metro <code>--programa Sabado</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, la ruta del ejecutable es: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Parametro.py --programa Sabado</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Configurado din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no se marca como fallida si el proceso retorna un c\u00f3digo de error).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>5</code> (sugiere que la tarea puede aprovechar hasta 5 hilos durante su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, permitiendo centralizar y actualizar esta configuraci\u00f3n sin modificar directamente la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts, la cual se concatena con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto adecuado de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-noche","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Noche</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Noche. La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza el ejecutable de Python definido mediante variables de proyecto, lo que permite adaptar la configuraci\u00f3n a distintos entornos. Adem\u00e1s, la tarea est\u00e1 configurada para que el flujo ETL contin\u00fae ejecut\u00e1ndose incluso si el proceso retorna un c\u00f3digo de error.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_20","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Parametro.py</code> con el par\u00e1metro <code>--programa Noche</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Definido mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Parametro.py --programa Noche</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Configurado din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no se marca como fallida si el proceso retorna un c\u00f3digo de error).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>4</code> (sugiere que la tarea est\u00e1 configurada para utilizar hasta 4 hilos en su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, permitiendo centralizar y actualizar esta configuraci\u00f3n seg\u00fan el entorno (desarrollo, pruebas, producci\u00f3n).</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se utiliza para establecer el contexto de ejecuci\u00f3n mediante la concatenaci\u00f3n con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_consolidado_inasistencias","title":"Componente <code>Ejecutar Proceso: emp_consolidado_Inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias a nivel empresarial. El proceso se ejecuta desde un directorio configurado para SharePoint, lo que indica que el script probablemente interact\u00faa con recursos o archivos alojados en un entorno SharePoint. La ejecuci\u00f3n se realiza utilizando un ejecutable de Python definido mediante variables de proyecto, lo que permite centralizar la configuraci\u00f3n y adaptarla a diferentes entornos sin modificaciones manuales.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_21","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>emp_06_consolidado_Inasistencias.py</code> desde el directorio configurado para SharePoint. Este script se encarga de consolidar y procesar datos de inasistencias en el \u00e1mbito empresarial.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, la ruta del ejecutable es: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>emp_06_consolidado_Inasistencias.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint</code>, lo que establece el contexto de ejecuci\u00f3n en el entorno Sharepoint.</li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea contin\u00faa el flujo ETL aunque el proceso retorne un c\u00f3digo de error).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>1</code> (la tarea se ejecuta de manera secuencial en un \u00fanico hilo).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que centraliza la ruta del ejecutable de Python, permitiendo actualizarla de manera global sin modificar la configuraci\u00f3n individual de la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se utiliza para establecer el contexto de ejecuci\u00f3n, en este caso, apuntando al directorio SharePoint.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#cedesarrollo","title":"Cedesarrollo","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01docentes_cedesarrollo","title":"Componente <code>Ejecutar Proceso: 01.Docentes_Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_22","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.Docentes_Cedesarrollo.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_01_procesar_docentes","title":"Componente <code>Ejecutar Proceso: cede_01_procesar_docentes</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_23","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_01_procesar_docentes.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-02disenio_curricular","title":"Componente <code>Ejecutar Proceso:  02.Disenio_curricular</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_24","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_24","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>02.Disenio_curricular.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_02_procesar_diseno_curricular","title":"Componente <code>Ejecutar Proceso: cede_02_procesar_Dise\u00f1o_Curricular</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_25","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_25","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_02_procesar_Dise\u00f1o_Curricular.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-03listado_matriculas","title":"Componente <code>Ejecutar Proceso: 03.Listado_matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_26","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_26","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>03.Listado_matriculas.py --semestre True</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_03_procesar_listado_matriculas","title":"Componente <code>Ejecutar Proceso: cede_03_procesar_listado_matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_27","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_27","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_03_procesar_listado_matriculas.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04ingresos","title":"Componente <code>Ejecutar Proceso: 04.Ingresos</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_28","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_28","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Ingresos.py --semestre True</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_04_procesar_cede_ingresos","title":"Componente <code>Ejecutar Proceso: cede_04_procesar_cede_Ingresos</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_29","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_29","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_04_procesar_cede_Ingresos.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-05historico_notas_cedesarrollo","title":"Componente <code>Ejecutar Proceso: 05.Historico_notas_Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_30","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_30","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>05.Historico_notas_Cedesarrollo.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_05_cede_historico_notas","title":"Componente <code>Ejecutar Proceso:  cede_05_cede_Historico_Notas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_31","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_31","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_05_cede_Historico_Notas.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-06egresados_graduados_cedesarrollo","title":"Componente <code>Ejecutar Proceso: 06.Egresados_graduados_Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_32","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_32","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>06.Egresados_graduados_Cedesarrollo.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_06_cede_egresados_graduados","title":"Componente <code>Ejecutar Proceso: cede_06_cede_Egresados_Graduados</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_33","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_33","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_06_cede_Egresados_Graduados.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-07desertorespy","title":"Componente <code>Ejecutar Proceso: 07.Desertores.py</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_34","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_34","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>07.Desertores.py --semestre True</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_07_cancelados_desertores","title":"Componente <code>Ejecutar Proceso: cede_07_Cancelados_Desertores</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_35","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_35","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_07_Cancelados_Desertores.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#c4c","title":"C4C","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01c4c_webscraping_v4_actualizablepy","title":"Componente <code>Ejecutar Proceso: 01.C4C_webscraping_v4_Actualizable.py</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_36","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_36","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.C4C_webscraping_v4_Actualizable.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/","title":"Introduccion","text":"<p>La presente soluci\u00f3n SSIS constituye un conjunto integral de paquetes ETL cuidadosamente dise\u00f1ados para consolidar, transformar y cargar datos provenientes de fuentes heterog\u00e9neas hacia el Data Warehouse <code>DWH_COMFENALCO</code>. Cada paquete aborda dominios espec\u00edficos, como educaci\u00f3n, protecci\u00f3n social, finanzas y operaciones transversales, maximizando la calidad, consistencia y accesibilidad de los datos con el prop\u00f3sito de sustentar decisiones estrat\u00e9gicas.</p>"},{"location":"02.Paquetes_SSIS/00.params/#resumen-general","title":"Resumen General","text":"<p>Prop\u00f3sitos Estrat\u00e9gicos:</p> <ol> <li>Centralizar y estandarizar datos multisectoriales.</li> <li>Proveer informaci\u00f3n verificada y estructurada para an\u00e1lisis operativos y de inteligencia empresarial.</li> <li>Implementar transformaciones avanzadas que optimicen la confiabilidad y el valor de los datos.</li> </ol> <p>Componentes Fundamentales:</p> <ul> <li>Dimensiones:<ul> <li>Educativas: <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_LIBROS</code>, <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Administrativas: <code>DIM_CUENTA_CONTABLE</code>, <code>DIM_PERSONAL</code>, <code>DIM_INFRAESTRUCTURA_CCF</code>.</li> <li>Temporales: <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Hechos:<ul> <li>Operativos: <code>FACT_TRANSPORTE</code>, <code>FACT_PERMISO_ESTUDIANTE</code>, <code>FACT_DIAGNOSTICOS_EE_JEC</code>.</li> <li>Financieros: <code>FACT_DETALLE_CONTABLE</code>, <code>FACT_CONVENIOS</code>, <code>FACT_PRESUPUESTO</code>.</li> </ul> </li> <li>Automatizaci\u00f3n:<ul> <li>Scripts Python para descargas y validaciones din\u00e1micas.</li> </ul> </li> </ul> <p>Paquetes Principales y Tablas Asociadas:</p> <ol> <li> <p>01-TRANSVERSAL_DIMENSIONES:</p> <ul> <li>Tablas clave: <code>DIM_CUENTA_CONTABLE</code>, <code>DIM_PERSONAL</code>, <code>DIM_INFRAESTRUCTURA_CCF</code>.</li> <li>Fuentes: Archivos Excel y bases de datos SQL Server.</li> </ul> </li> <li> <p>02-TRANSVERSAL_FACT:</p> <ul> <li>Tablas clave: <code>FACT_DETALLE_CONTABLE</code>, <code>FACT_ENCUESTAS_PSR</code>, <code>FACT_INICIATIVAS</code>.</li> <li>Fuentes: Archivos CSV, bases de datos SAP.</li> </ul> </li> <li> <p>03-COLEGIO_DIMENSIONES y 03-COLEGIO_DIMENSIONES_AUXILIAR:</p> <ul> <li>Tablas clave: <code>DIM_CURSO</code>, <code>DIM_GRADO</code>, <code>DIM_PLAN_CURRICULAR</code>.</li> <li>Fuentes: Bases remotas y archivos Excel.</li> </ul> </li> <li> <p>04-COLEGIO_FACT:</p> <ul> <li>Tablas clave: <code>FACT_TRANSPORTE</code>, <code>FACT_CUPOS_NEGADOS</code>, <code>FACT_BIBLIOTECA</code>.</li> <li>Fuentes: Bases SAP y datos operativos.</li> </ul> </li> <li> <p>05-CEDESARROLLO_DIMENSIONES:</p> <ul> <li>Tablas clave: <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_JORNADA</code>.</li> <li>Fuentes: Archivos Excel y bases SQL Server.</li> </ul> </li> <li> <p>06-CEDESARROLLO_FACT:</p> <ul> <li>Tablas clave: <code>FACT_NOTAS</code>, <code>FACT_TRANSPORTE</code>, <code>FACT_PERMISO_ESTUDIANTE</code>.</li> <li>Fuentes: Bases de datos acad\u00e9micas.</li> </ul> </li> <li> <p>07-PROTECCION_DIMENSIONES y 08-PROTECCION_FACT:</p> <ul> <li>Tablas clave: <code>DIM_PREGUNTAS_EE_JEC</code>, <code>FACT_ENTREGA_MATERIAL</code>, <code>FACT_DESERCION</code>.</li> <li>Fuentes: Archivos planos y bases SQL Server.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#detalles-tecnicos-generales","title":"Detalles T\u00e9cnicos Generales","text":""},{"location":"02.Paquetes_SSIS/00.params/#extraccion-de-datos","title":"Extracci\u00f3n de Datos","text":"<ul> <li>Fuentes Primarias:<ul> <li>Bases SAP y SQL Server.</li> <li>Archivos CSV y Excel.</li> <li>Conexiones SharePoint para datos remotos.</li> </ul> </li> <li>Instrumentos:<ul> <li>ADO.NET para bases estructuradas.</li> <li>Scripts Python para descargas program\u00e1ticas.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#transformaciones","title":"Transformaciones","text":"<ul> <li>Validaciones:<ul> <li>Uso extensivo de <code>Lookup</code> para garantizar integridad referencial.</li> </ul> </li> <li>Transformaciones Especializadas:<ul> <li>Columnas derivadas para claves auxiliares y valores predeterminados.</li> <li>Clasificaci\u00f3n con <code>Conditional Split</code>.</li> <li>Conversi\u00f3n de tipos para alineaci\u00f3n de esquemas.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#carga-de-datos","title":"Carga de Datos","text":"<ul> <li>Tablas de Dimensiones:<ul> <li><code>DIM_CUENTA_CONTABLE</code>, <code>DIM_PROGRAMA</code>, <code>DIM_ESTUDIANTES</code>.</li> </ul> </li> <li>Tablas de Hechos:<ul> <li><code>FACT_TRANSPORTE</code>, <code>FACT_CONVENIOS</code>, <code>FACT_DIAGNOSTICOS_EE_JEC</code>.</li> </ul> </li> <li>Optimizaci\u00f3n:<ul> <li>Inserciones masivas (<code>Bulk Insert</code>) configuradas para alto rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#automatizacion","title":"Automatizaci\u00f3n","text":"<ul> <li>Scripts Python:<ul> <li>Validaciones din\u00e1micas en tiempo de ejecuci\u00f3n.</li> <li>Descarga de archivos con integraci\u00f3n SharePoint.</li> </ul> </li> <li>Procedimientos Almacenados:<ul> <li>Restauraci\u00f3n automatizada de reglas de integridad referencial.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#herramientas-y-tecnologias-utilizadas","title":"Herramientas y Tecnolog\u00edas Utilizadas","text":"<ul> <li>SSIS (SQL Server Integration Services):<ul> <li>Para dise\u00f1ar y ejecutar flujos de datos y procesos de control.</li> </ul> </li> <li>Python:<ul> <li>Automatizaci\u00f3n y validaci\u00f3n de datos mediante scripts personalizados.</li> </ul> </li> <li>ADO.NET:<ul> <li>Conexiones robustas a bases de datos relacionales.</li> </ul> </li> <li>OLE DB:<ul> <li>Lectura y transformaci\u00f3n de datos desde archivos Excel y CSV.</li> </ul> </li> <li>SQL Server:<ul> <li>Plataforma de destino para almacenar datos procesados.</li> </ul> </li> <li>Visual Studio:<ul> <li>Desarrollo y configuraci\u00f3n de paquetes SSIS.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#buenas-practicas","title":"Buenas Pr\u00e1cticas","text":"<ol> <li> <p>Estandarizaci\u00f3n:</p> <ul> <li>Nombrado uniforme para conexiones y componentes.</li> <li>Plantillas comunes en transformaciones y cargas.</li> </ul> </li> <li> <p>Optimizaci\u00f3n:</p> <ul> <li>Configuraci\u00f3n de cach\u00e9 para <code>Lookup</code>.</li> <li>Paralelizaci\u00f3n en flujos intensivos de datos.</li> </ul> </li> <li> <p>Automatizaci\u00f3n:</p> <ul> <li>Scripts Python para minimizar intervenciones manuales.</li> <li>Uso de variables din\u00e1micas para parametrizaci\u00f3n.</li> </ul> </li> <li> <p>Mantenimiento:</p> <ul> <li>Validaciones exhaustivas previas a la carga.</li> <li>Auditor\u00edas peri\u00f3dicas de consistencia.</li> </ul> </li> <li> <p>Seguridad:</p> <ul> <li>Eliminaci\u00f3n temporal de restricciones durante cargas masivas.</li> <li>Restauraci\u00f3n autom\u00e1tica tras completarse las operaciones.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#conclusion","title":"Conclusi\u00f3n","text":"<p>La soluci\u00f3n SSIS documentada constituye un pilar estrat\u00e9gico para la gesti\u00f3n y explotaci\u00f3n de datos organizacionales. Su dise\u00f1o modular y altamente automatizado no solo garantiza eficiencia operativa, sino que tambi\u00e9n habilita a la organizaci\u00f3n para responder \u00e1gilmente a desaf\u00edos futuros. La implementaci\u00f3n de buenas pr\u00e1cticas y recomendaciones adicionales potenciar\u00e1 su valor y sostenibilidad en el tiempo.</p> <p>A continuaci\u00f3n, se presentan diagramas en formato Mermaid que representan flujos de datos y relaciones entre tablas de la soluci\u00f3n SSIS:</p>"},{"location":"02.Paquetes_SSIS/00.params/#diagramas-ssis","title":"Diagramas SSIS","text":""},{"location":"02.Paquetes_SSIS/00.params/#diagrama-de-flujo-de-datos-general","title":"Diagrama de Flujo de Datos (General)","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel/CSV\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extrae datos desde fuentes remotas y locales\n    SSIS -&gt;&gt; Excel: Procesa datos adicionales desde archivos planos\n    SSIS -&gt;&gt; Python: Automatiza tareas de validaci\u00f3n y descarga\n    SSIS -&gt;&gt; DWH: Carga datos procesados en tablas destino</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#diagrama-de-transformaciones-ejemplo-para-dimensiones","title":"Diagrama de Transformaciones (Ejemplo para Dimensiones)","text":"<pre><code>graph TD\n    A1[Datos Crudos de Dimensiones] --&gt; T1[Validaci\u00f3n con Lookup]\n    T1 --&gt; T2[Conversi\u00f3n de Tipos]\n    T2 --&gt; T3[Columnas Derivadas]\n    T3 --&gt; T4[Filtrado con Conditional Split]\n    T4 --&gt; C1[Carga en Tablas de Dimensiones]</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#diagrama-er-para-tablas-de-dimensiones","title":"Diagrama ER para Tablas de Dimensiones","text":"<pre><code>erDiagram\n    DIM_CUENTA_CONTABLE {\n        int ID_CUENTA\n        string CUENTA_NUMERO\n        string DESCRIPCION\n    }\n    DIM_PERSONAL {\n        int ID_PERSONAL\n        string NOMBRE\n        string DIRECCION\n    }\n    DIM_INFRAESTRUCTURA_CCF {\n        int ID_INFRAESTRUCTURA\n        string DESCRIPCION\n    }\n    DIM_SEDES {\n        int ID_SEDE\n        string NOMBRE_SEDE\n    }\n    DIM_TIEMPO {\n        int ID_FECHA\n        date FECHA\n        string DESC_FECHA\n    }\n    DIM_CUENTA_CONTABLE ||--|| DIM_PERSONAL : \"Asociaci\u00f3n por Clave For\u00e1nea\"\n    DIM_INFRAESTRUCTURA_CCF ||--|| DIM_SEDES : \"Relaci\u00f3n Infraestructura-Sede\"\n    DIM_SEDES ||--|| DIM_TIEMPO : \"Relaci\u00f3n Temporal\"</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#diagrama-er-para-tablas-de-hechos-y-dimensiones","title":"Diagrama ER para Tablas de Hechos y Dimensiones","text":"<pre><code>erDiagram\n    FACT_TRANSPORTE {\n        string PARTNER_ESTUDIANTE\n        date FECHA_SERVICIO\n        int ANIO_ACADEMICO\n        string CATEGORIA_SERVICIO\n    }\n    FACT_CUPOS_NEGADOS {\n        string PARTNER_ESTUDIANTE\n        int ANIO_ACADEMICO\n        date FECHA_ESTADO\n    }\n    FACT_BIBLIOTECA {\n        string ITEM_LIBRO\n        date FECHA_PRESTAMO\n        string BP_ESTUDIANTE\n    }\n    FACT_PERMISO_ESTUDIANTE {\n        string BP_ESTUDIANTE\n        date FECHA_PERMISO\n        string MOTIVO\n    }\n    FACT_TRANSPORTE ||--|| FACT_CUPOS_NEGADOS : \"Relaci\u00f3n de estudiantes\"\n    FACT_BIBLIOTECA ||--|| FACT_PERMISO_ESTUDIANTE : \"Conexi\u00f3n por estudiantes\"\n    DIM_ESTUDIANTES ||--|| FACT_TRANSPORTE : \"Detalles de Estudiantes\"\n    DIM_LIBROS ||--|| FACT_BIBLIOTECA : \"Informaci\u00f3n de Libros\"</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#parametros-clave-en-la-solucion-ssis","title":"Par\u00e1metros Clave en la Soluci\u00f3n SSIS","text":""},{"location":"02.Paquetes_SSIS/00.params/#documentacion-del-archivo-projectparams","title":"Documentaci\u00f3n del Archivo <code>project.params</code>","text":"<p>El archivo <code>project.params</code> es un componente esencial en las soluciones de SQL Server Integration Services (SSIS), dise\u00f1ado para centralizar y administrar los par\u00e1metros utilizados globalmente en los paquetes de la soluci\u00f3n. Su prop\u00f3sito principal es facilitar la configuraci\u00f3n y gesti\u00f3n de variables cr\u00edticas, proporcionando un punto \u00fanico de control para ajustar valores clave sin necesidad de modificar cada paquete individualmente.</p> <p>Los par\u00e1metros definidos en este archivo son utilizados para:</p> <ol> <li> <p>Cadenas de conexi\u00f3n:</p> <ul> <li>Administrar el acceso a bases de datos y servicios externos.</li> <li>Establecer conexiones consistentes y seguras mediante cadenas configuradas que pueden ser reutilizadas en m\u00faltiples paquetes.</li> </ul> </li> <li> <p>Rutas de trabajo:</p> <ul> <li>Definir directorios y ubicaciones clave para archivos de entrada, salida o temporales.</li> <li>Estandarizar las rutas utilizadas en scripts y procesos, reduciendo la posibilidad de errores debido a inconsistencias.</li> </ul> </li> <li> <p>Configuraciones de tiempo de espera:</p> <ul> <li>Establecer valores predeterminados para manejar operaciones que requieren l\u00edmites temporales, como conexiones a bases de datos o transferencias de datos.</li> </ul> </li> <li> <p>Par\u00e1metros sensibles:</p> <ul> <li>Incluir contrase\u00f1as, claves de acceso y otras credenciales protegidas mediante la propiedad <code>Sensitive</code> que oculta estos valores en registros y exportaciones.</li> </ul> </li> <li> <p>Compatibilidad multi-entorno:</p> <ul> <li>Facilitar la portabilidad y configuraci\u00f3n de los paquetes SSIS en diferentes entornos (desarrollo, prueba, producci\u00f3n) mediante valores f\u00e1cilmente ajustables en un \u00fanico archivo.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#ventajas-del-uso-de-projectparams","title":"Ventajas del Uso de <code>project.params</code>","text":"<ol> <li>Centralizaci\u00f3n: Permite un punto \u00fanico de configuraci\u00f3n para par\u00e1metros globales, simplificando la administraci\u00f3n.</li> <li>Flexibilidad: Cambiar valores en el archivo afecta autom\u00e1ticamente todos los paquetes que dependen de estos par\u00e1metros, eliminando la necesidad de ediciones manuales en m\u00faltiples archivos.</li> <li>Estandarizaci\u00f3n: Garantiza consistencia en la configuraci\u00f3n entre paquetes, reduciendo errores y aumentando la mantenibilidad.</li> <li>Seguridad: Los par\u00e1metros sensibles pueden ser protegidos para evitar la exposici\u00f3n de informaci\u00f3n confidencial.</li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#estructura-del-archivo","title":"Estructura del Archivo","text":"<p>Cada par\u00e1metro en el archivo incluye: - Nombre: Identificador \u00fanico del par\u00e1metro. - Descripci\u00f3n: Informaci\u00f3n opcional que detalla el prop\u00f3sito del par\u00e1metro. - Propiedades clave:   - Sensitive: Indica si el par\u00e1metro contiene informaci\u00f3n sensible que debe ser protegida.   - DataType: Especifica el tipo de dato (e.g., cadena, n\u00famero).   - Valor: El valor asignado al par\u00e1metro, que puede ser una cadena de conexi\u00f3n, ruta, n\u00famero, entre otros.</p> <p>El dise\u00f1o del archivo <code>project.params</code> permite a los equipos de desarrollo y operaciones trabajar de manera eficiente y segura, garantizando que los procesos de integraci\u00f3n de datos sean robustos y escalables.</p>"},{"location":"02.Paquetes_SSIS/00.params/#1-dwh_comfenalco_connectionstring","title":"1. DWH_COMFENALCO_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para la base de datos principal <code>DWH_COMFENALCO</code>, utilizada para operaciones de carga y extracci\u00f3n de datos.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Initial Catalog=DWH_COMFENALCO;Persist Security Info=True;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code> (No contiene informaci\u00f3n sensible).</li> <li>DataType: <code>18</code> (Texto).</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#2-dwh_comfenalco_destino_connectionstring","title":"2. DWH_COMFENALCO_Destino_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para la base de datos de destino <code>DWH_COMFENALCO</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=QCSCONS19;Initial Catalog=DWH_COMFENALCO;Integrated Security=True;Encrypt=False;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#3-dwh_comfenalco_destino_oledb_connectionstring","title":"3. DWH_COMFENALCO_Destino_OLEDB_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n OLEDB para operaciones espec\u00edficas en la base de datos <code>DWH_COMFENALCO</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=QCSCONS19;Initial Catalog=DWH_COMFENALCO;Provider=MSOLEDBSQL.1;Integrated Security=SSPI;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#4-dwh_comfenalco_oledb_connectionstring","title":"4. DWH_COMFENALCO_OLEDB_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n OLEDB para la base de datos principal <code>DWH_COMFENALCO</code>, dise\u00f1ada para compatibilidad con aplicaciones que utilizan este proveedor.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Provider=MSOLEDBSQL.1;Persist Security Info=True;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#5-dwh_comfenalco_oledb_username","title":"5. DWH_COMFENALCO_OLEDB_UserName","text":"<ul> <li>Prop\u00f3sito: Nombre de usuario utilizado para la autenticaci\u00f3n en la conexi\u00f3n OLEDB de <code>DWH_COMFENALCO</code>.</li> <li>Ejemplo de Valor: <code>prov_quality1</code>.</li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#6-python_executable","title":"6. Python_Executable","text":"<ul> <li>Prop\u00f3sito: Ruta al ejecutable de Python que se utiliza en los scripts del proyecto.</li> <li>Ejemplo de Valor:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#7-sap_erp_connectionstring","title":"7. SAP_ERP_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para acceder al sistema SAP ERP.</li> <li>Ejemplo de Valor:   <pre><code>Server=10.5.4.51:30013;User ID=CONSULTAHANA;Database=HEQ;\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#8-stage_area_connectionstring","title":"8. STAGE_AREA_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para la base de datos <code>STAGE_AREA</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Initial Catalog=STAGE_AREA;Persist Security Info=True;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#9-stage_area_oledb_connectionstring","title":"9. STAGE_AREA_OLEDB_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n OLEDB para operaciones en <code>STAGE_AREA</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Initial Catalog=STAGE_AREA;Provider=SQLNCLI11.1;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#10-stage_area_oledb_username","title":"10. STAGE_AREA_OLEDB_UserName","text":"<ul> <li>Prop\u00f3sito: Nombre de usuario utilizado en la autenticaci\u00f3n para la conexi\u00f3n OLEDB de <code>STAGE_AREA</code>.</li> <li>Ejemplo de Valor: <code>prov_quality1</code>.</li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#11-tiempo_espera_segundos","title":"11. Tiempo_Espera_Segundos","text":"<ul> <li>Prop\u00f3sito: Configuraci\u00f3n del tiempo de espera (en segundos) para operaciones de conexi\u00f3n.</li> <li>Ejemplo de Valor: <code>600</code>.</li> <li>Propiedades Clave:</li> <li>DataType: <code>9</code> (Entero).</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#12-working_directory","title":"12. Working_Directory","text":"<ul> <li>Prop\u00f3sito: Directorio de trabajo utilizado para guardar archivos temporales y otros datos procesados por los paquetes de SSIS.</li> <li>Ejemplo de Valor:   <pre><code>\\\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/","title":"01. TRANSVERSAL_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#transversal_dimensiones","title":"TRANSVERSAL_DIMENSIONES","text":"<p>El paquete SSIS \"01-TRANSVERSAL_DIMENSIONES\" est\u00e1 dise\u00f1ado para gestionar flujos ETL enfocados en la consolidaci\u00f3n y estructuraci\u00f3n de datos de dimensiones transversales, como cuentas contables, infraestructura, sedes, poblaci\u00f3n educativa, y personal. Este paquete asegura la integraci\u00f3n eficiente de informaci\u00f3n desde m\u00faltiples fuentes en el Data Warehouse <code>DWH_COMFENALCO</code>, permitiendo an\u00e1lisis detallados y toma de decisiones estrat\u00e9gicas.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es centralizar, transformar y cargar datos relacionados con dimensiones transversales que impactan diferentes \u00e1reas operativas, asegurando su consistencia y calidad para an\u00e1lisis en plataformas de inteligencia de negocios.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes utilizadas:<ul> <li>Bases de Datos:<ul> <li><code>DIM_CUENTA_CONTABLE</code></li> <li><code>DIM_UNIDADES_ORGANIZATIVAS</code></li> <li><code>DIM_SEDES</code></li> </ul> </li> <li>Archivos Excel:<ul> <li>Informaci\u00f3n sobre poblaci\u00f3n educativa, infraestructura, y personal.</li> </ul> </li> </ul> </li> <li>Herramientas:<ul> <li>ADO.NET y OLE DB para conexiones eficientes.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Crea claves auxiliares y campos calculados.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Garantiza consistencia mediante b\u00fasquedas en tablas maestras.</li> </ul> </li> <li>Clasificaci\u00f3n (<code>Conditional Split</code>):<ul> <li>Segmentaci\u00f3n de datos seg\u00fan condiciones espec\u00edficas.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad entre columnas de entrada y destino.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_CUENTA_CONTABLE</code></li> <li><code>DIM_PERSONAL</code></li> <li><code>DIM_INFRAESTRUCTURA_CCF</code></li> <li><code>DIM_SEDES</code></li> </ul> </li> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python para integrar flujos de trabajo automatizados y procesar datos de SharePoint.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_CUENTA_CONTABLE:</p> <ul> <li><code>ID_CUENTA</code>: Identificador \u00fanico.</li> <li><code>CUENTA_NUMERO</code>: N\u00famero de cuenta.</li> <li><code>DESCRIPCION</code>: Descripci\u00f3n de la cuenta.</li> </ul> </li> <li> <p>DIM_PERSONAL:</p> <ul> <li><code>ID_PERSONAL</code>: Identificador \u00fanico.</li> <li><code>NOMBRE</code>: Nombre del personal.</li> <li><code>DIRECCION</code>: Direcci\u00f3n.</li> </ul> </li> <li> <p>DIM_INFRAESTRUCTURA_CCF:</p> <ul> <li><code>ID_INFRAESTRUCTURA</code>: Identificador \u00fanico.</li> <li><code>DESCRIPCION</code>: Descripci\u00f3n de la infraestructura.</li> </ul> </li> <li> <p>DIM_SEDES:</p> <ul> <li><code>ID_SEDE</code>: Identificador \u00fanico.</li> <li><code>NOMBRE_SEDE</code>: Nombre de la sede.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extrae datos de cuentas, personal, y sedes\n    SSIS -&gt;&gt; Excel: Procesa datos de infraestructura y poblaci\u00f3n\n    SSIS -&gt;&gt; Python: Ejecuta scripts para descargas\n    SSIS -&gt;&gt; DWH: Carga datos en tablas destino</code></pre> <ol> <li>Diagrama de Transformaciones y Validaciones</li> </ol> <pre><code>graph TD\n    A1[Datos de cuentas y sedes] --&gt; T1[Conversi\u00f3n de Datos]\n    A2[Datos de infraestructura y poblaci\u00f3n] --&gt; T2[Derived Column: Claves Auxiliares]\n    T1 --&gt; L1[Lookup en Tablas Maestras]\n    T2 --&gt; C1[Clasificaci\u00f3n por Condicional Split]\n    L1 --&gt; C2[Cargar datos transformados]</code></pre> <ol> <li>Diagrama ER para Tablas de Dimensiones</li> </ol> <pre><code>erDiagram\n    DIM_CUENTA_CONTABLE {\n        int ID_CUENTA\n        string CUENTA_NUMERO\n        string DESCRIPCION\n    }\n    DIM_PERSONAL {\n        int ID_PERSONAL\n        string NOMBRE\n        string DIRECCION\n    }\n    DIM_INFRAESTRUCTURA_CCF {\n        int ID_INFRAESTRUCTURA\n        string DESCRIPCION\n    }\n    DIM_SEDES {\n        int ID_SEDE\n        string NOMBRE_SEDE\n    }\n    DIM_CUENTA_CONTABLE ||--|| DIM_PERSONAL : \"Asociaci\u00f3n por Clave For\u00e1nea\"\n    DIM_INFRAESTRUCTURA_CCF ||--|| DIM_SEDES : \"Relaci\u00f3n Infraestructura-Sede\"</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-guardar-las-llaves-foraneas","title":"Componente: <code>Guardar las Llaves For\u00e1neas</code>","text":"<p>Prop\u00f3sito Esta tarea dentro de la soluci\u00f3n SSIS tiene como objetivo:</p> <ol> <li> <p>Crear tablas persistentes para almacenar definiciones de llaves for\u00e1neas en varios esquemas: <code>Transversal</code>, <code>Cedesarrollo</code>, <code>Proteccion</code> y <code>Colegio</code>.</p> </li> <li> <p>Insertar las definiciones de llaves for\u00e1neas en las tablas persistentes a partir de la metadata del sistema (<code>sys.foreign_keys</code> y tablas relacionadas).</p> </li> <li> <p>Eliminar restricciones de llaves for\u00e1neas existentes en los esquemas mencionados, prepar\u00e1ndose para un entorno donde no se necesiten dichas restricciones durante procesos espec\u00edficos (e.g., migraci\u00f3n o transformaci\u00f3n de datos).</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-tecnicos","title":"Detalles T\u00e9cnicos","text":"<ol> <li> <p>Tipo de Tarea: </p> <ul> <li><code>Microsoft.ExecuteSQLTask</code> (Tarea Ejecutar SQL).</li> </ul> </li> <li> <p>Descripci\u00f3n:</p> <ul> <li>La tarea ejecuta comandos SQL que realizan varias operaciones en los esquemas <code>Transversal</code>, <code>Cedesarrollo</code>, <code>Proteccion</code> y <code>Colegio</code>.</li> </ul> </li> <li> <p>Identificador de la Tarea:</p> <ul> <li>DTSID: <code>{86fe2b15-f28c-4064-b542-2d2ad2594a04}</code>.</li> </ul> </li> <li> <p>Nombre de la Tarea:</p> <ul> <li><code>Guardar las llaves foraneas</code>.</li> </ul> </li> <li> <p>Conexi\u00f3n Utilizada:</p> <ul> <li>Referenciada por el ID: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-codigo-sql","title":"Descripci\u00f3n del C\u00f3digo SQL","text":"<ol> <li> <p>Creaci\u00f3n de Tablas Persistentes:</p> <ul> <li>Para cada esquema (<code>Transversal</code>, <code>Cedesarrollo</code>, <code>Proteccion</code>, <code>Colegio</code>), se verifica la existencia previa de la tabla y se elimina si ya existe:  <pre><code>IF OBJECT_ID('dbo.ForeignKeys_&lt;Esquema&gt;', 'U') IS NOT NULL\n    DROP TABLE dbo.ForeignKeys_&lt;Esquema&gt;;\n</code></pre></li> <li>Posteriormente, se crea una nueva tabla con la estructura necesaria para almacenar las definiciones de las llaves for\u00e1neas:  <pre><code>CREATE TABLE dbo.ForeignKeys_&lt;Esquema&gt; (\n    TableName NVARCHAR(256),\n    ConstraintName NVARCHAR(256),\n    ColumnName NVARCHAR(256),\n    ReferencedTableName NVARCHAR(256),\n    ReferencedColumnName NVARCHAR(256)\n);\n</code></pre></li> </ul> </li> <li> <p>Inserci\u00f3n de Definiciones de Llaves For\u00e1neas:     .foreign_key_columns<code>,</code>sys.tables<code>,</code>sys.columns<code>,</code>sys.schemas`) y se insertan en las tablas persistentes:     <pre><code>INSERT INTO dbo.ForeignKeys_&lt;Esquema&gt; (TableName, ConstraintName, ColumnName, ReferencedTableName, ReferencedColumnName)\nSELECT \n    t.name AS TableName,\n    f.name AS ConstraintName,\n    c.name AS ColumnName,\n    rt.name AS ReferencedTableName,\n    rc.name AS ReferencedColumnName\nFROM sys.foreign_keys f\nINNER JOIN sys.foreign_key_columns fc ON f.object_id = fc.constraint_object_id\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\n...\nWHERE s.name = '&lt;Esquema&gt;';\n</code></pre></p> </li> <li> <p>Eliminaci\u00f3n de Restricciones de Llaves For\u00e1neas:     Se generan din\u00e1micamente comandos SQL para eliminar todas las restricciones de llaves for\u00e1neas en las tablas de cada esquema:         <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; '\nFROM sys.foreign_keys f\n...\nWHERE s.name = '&lt;Esquema&gt;';\nEXEC sp_executesql @sql;\n</code></pre></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#esquemas-procesados","title":"Esquemas Procesados","text":"<ol> <li>Transversal.</li> <li>Cedesarrollo.</li> <li>Proteccion.</li> <li>Colegio.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#ventajas-de-la-implementacion","title":"Ventajas de la Implementaci\u00f3n","text":"<ol> <li>Centralizaci\u00f3n de definiciones: Las tablas persistentes almacenan todas las llaves for\u00e1neas en un lugar accesible para auditor\u00edas o referencias futuras.</li> <li>Flexibilidad: Elimina restricciones en los esquemas, permitiendo procesos m\u00e1s \u00e1giles como migraciones de datos.</li> <li>Reutilizaci\u00f3n: La l\u00f3gica puede ser ajustada para nuevos esquemas simplemente actualizando el c\u00f3digo SQL y par\u00e1metros en el SSIS.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-de-datos","title":"Diagrama de flujo de proceso de datos","text":"<pre><code>sequenceDiagram\n    participant SQL_TASK\n    participant TRANSVERSAL_SCHEMA\n    participant CEDESARROLLO_SCHEMA\n    participant PROTECCION_SCHEMA\n    participant COLEGIO_SCHEMA\n\n    SQL_TASK-&gt;&gt;TRANSVERSAL_SCHEMA: Crear tablas y definir llaves for\u00e1neas\n    SQL_TASK-&gt;&gt;CEDESARROLLO_SCHEMA: Crear tablas y definir llaves for\u00e1neas\n    SQL_TASK-&gt;&gt;PROTECCION_SCHEMA: Crear tablas y definir llaves for\u00e1neas\n    SQL_TASK-&gt;&gt;COLEGIO_SCHEMA: Crear tablas y definir llaves for\u00e1neas</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_cuenta_contable","title":"Componente <code>Cargar_DIM_CUENTA_CONTABLE</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Cargar_DIM_CUENTA_CONTABLE</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de cargar datos en la dimensi\u00f3n <code>DIM_CUENTA_CONTABLE</code>. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-y-funcionalidades","title":"Componentes y Funcionalidades","text":"<ol> <li> <p>Variables y Opciones de Registro</p> <ul> <li>No se definen variables espec\u00edficas.</li> <li>Opciones de registro configuradas con <code>DTS:FilterKind=\"0\"</code>.</li> </ul> </li> <li> <p>Pipeline</p> <ul> <li>Versi\u00f3n: 1</li> </ul> </li> <li> <p>Componentes del Pipeline</p> <ul> <li> <p>Conditional Split</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos utilizando expresiones SSIS.</li> <li>Entradas: <ul> <li>Columnas de entrada incluyen <code>CUENTA_NUMERO</code>, <code>CUENTA</code>, <code>CUENTA_HOMOLOGA</code>, <code>DESCRIPCION</code>, <code>TIPO_CUENTA</code>, <code>TIPO_OPERACION</code>, <code>GRUPO_CUENTA</code>, <code>SUBGRUPO_CUENTA</code>, <code>GRUPO_OPERACION</code>, <code>FEC_PROCESO</code>, <code>UDATE</code>, <code>CUENTA_SSF</code>, <code>DESCRIPCION_SSF</code>, <code>NUMERO_PROCESO_SQL</code>, <code>CLASIFICACION</code>, <code>USUARIO_PROCESO</code>, <code>ESTADO_REGISTRO</code>, <code>ID_CUENTA</code>.</li> </ul> </li> <li>Salidas:<ul> <li><code>Agregar</code>: Filtra filas donde <code>ID_CUENTA</code> es nulo.</li> <li><code>Modificar</code>: Filtra filas donde hay diferencias entre las columnas de origen y las columnas de b\u00fasqueda.</li> <li><code>Sin Cambios</code>: Salida por defecto para filas sin cambios.</li> <li><code>Conditional Split Error Output</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Carga datos en una base de datos compatible con ADO.NET.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_CUENTA_CONTABLE\"</code></li> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> <li>Entradas: Columnas de entrada incluyen <code>ID_CUENTA</code>, <code>CUENTA_NUMERO</code>, <code>CUENTA</code>, <code>CUENTA_HOMOLOGA</code>, <code>DESCRIPCION</code>, <code>TIPO_CUENTA</code>, <code>TIPO_OPERACION</code>, <code>GRUPO_CUENTA</code>, <code>SUBGRUPO_CUENTA</code>, <code>GRUPO_OPERACION</code>, <code>FEC_PROCESO</code>, <code>UDATE</code>, <code>CUENTA_SSF</code>, <code>DESCRIPCION_SSF</code>, <code>NUMERO_PROCESO_SQL</code>, <code>CLASIFICACION</code>, <code>USUARIO_PROCESO</code>, <code>ESTADO_REGISTRO</code>.</li> <li>Salidas:<ul> <li><code>Salida de error de destino de ADO NET</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>DIM_CUENTA_CONTABLE_ORIG</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server utilizando una instrucci\u00f3n Transact-SQL.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>SELECT [ID_CUENTA], [CUENTA_NUMERO], [CUENTA], [CUENTA_HOMOLOGA], [DESCRIPCION], [TIPO_CUENTA], [TIPO_OPERACION], [GRUPO_CUENTA], [SUBGRUPO_CUENTA], [GRUPO_OPERACION], [FEC_PROCESO], [UDATE], [CUENTA_SSF], [DESCRIPCION_SSF], [NUMERO_PROCESO_SQL], [CLASIFICACION], [USUARIO_PROCESO], [ESTADO_REGISTRO] FROM [DWH_COMFENALCO].[Financiera].[DIM_CUENTA_CONTABLE]</code></li> <li><code>CommandTimeout</code>: 30</li> <li><code>AllowImplicitStringConversion</code>: true</li> <li><code>TableOrViewName</code>: <code>\"Financiera\".\"DIM_CUENTA_CONTABLE\"</code></li> <li><code>AccessMode</code>: 2</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code></li> <li>Salidas:<ul> <li><code>Salida de origen de ADO NET</code>: Salida principal.</li> <li><code>Salida de error de origen de ADO NET</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda de valores en una tabla para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>SELECT [ID_CUENTA], [CUENTA_NUMERO], [CUENTA], [CUENTA_HOMOLOGA], [DESCRIPCION], [TIPO_CUENTA], [TIPO_OPERACION], [GRUPO_CUENTA], [SUBGRUPO_CUENTA], [GRUPO_OPERACION], [FEC_PROCESO], [UDATE], [CUENTA_SSF], [DESCRIPCION_SSF], [NUMERO_PROCESO_SQL], [CLASIFICACION], [USUARIO_PROCESO], [ESTADO_REGISTRO] FROM [Transversal].[DIM_CUENTA_CONTABLE]</code></li> <li><code>SqlCommandParam</code>: <code>select * from (SELECT [ID_CUENTA], [CUENTA_NUMERO], [CUENTA], [CUENTA_HOMOLOGA], [DESCRIPCION], [TIPO_CUENTA], [TIPO_OPERACION], [GRUPO_CUENTA], [SUBGRUPO_CUENTA], [GRUPO_OPERACION], [FEC_PROCESO], [UDATE], [CUENTA_SSF], [DESCRIPCION_SSF], [NUMERO_PROCESO_SQL], [CLASIFICACION], [USUARIO_PROCESO], [ESTADO_REGISTRO] FROM [Transversal].[DIM_CUENTA_CONTABLE]) [refTable] where [refTable].[ID_CUENTA] = ?</code></li> <li><code>ConnectionType</code>: 0</li> <li><code>CacheType</code>: 0</li> <li><code>NoMatchBehavior</code>: 0</li> <li><code>NoMatchCachePercentage</code>: 0</li> <li><code>MaxMemoryUsage</code>: 25</li> <li><code>MaxMemoryUsage64</code>: 25</li> <li><code>ReferenceMetadataXml</code>: <code>&lt;referenceMetadata&gt;...&lt;/referenceMetadata&gt;</code></li> <li><code>ParameterMap</code>: <code>#{Package\\Cargar_DIM_CUENTA_CONTABLE\\DIM_CUENTA_CONTABLE_ORIG.Outputs[Salida de origen de ADO NET].Columns[ID_CUENTA]};</code></li> <li><code>DefaultCodePage</code>: 1252</li> <li><code>TreatDuplicateKeysAsError</code>: false</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code></li> <li>Entradas: <code>ID_CUENTA</code></li> <li>Salidas:<ul> <li><code>Lookup Match Output</code>: Salida para filas con coincidencias.</li> <li><code>Lookup No Match Output</code>: Salida para filas sin coincidencias.</li> <li><code>Lookup Error Output</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>OLE DB Command</p> <ul> <li>Descripci\u00f3n: Ejecuta una instrucci\u00f3n SQL para cada fila en un flujo de datos.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>SqlCommand</code>: <code>UPDATE [Transversal].[DIM_CUENTA_CONTABLE] SET [CUENTA_NUMERO] = ?, [CUENTA] = ?, [CUENTA_HOMOLOGA] = ?, [DESCRIPCION] = ?, [TIPO_CUENTA] = ?, [TIPO_OPERACION] = ?, [GRUPO_CUENTA] = ?, [SUBGRUPO_CUENTA] = ?, [GRUPO_OPERACION] = ?, [FEC_PROCESO] = ?, [UDATE] = ?, [CUENTA_SSF] = ?, [DESCRIPCION_SSF] = ?, [NUMERO_PROCESO_SQL] = ?, [CLASIFICACION] = ?, [USUARIO_PROCESO] = ?, [ESTADO_REGISTRO] = ? WHERE [ID_CUENTA] = ?</code></li> <li><code>DefaultCodePage</code>: 1252</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code></li> <li>Entradas: Columnas de entrada incluyen <code>CUENTA_NUMERO</code>, <code>CUENTA</code>, <code>CUENTA_HOMOLOGA</code>,      <code>DESCRIPCION</code>, <code>TIPO_CUENTA</code>, <code>TIPO_OPERACION</code>, <code>GRUPO_CUENTA</code>, <code>SUBGRUPO_CUENTA</code>, <code>GRUPO_OPERACION</code>, <code>FEC_PROCESO</code>, <code>UDATE</code>, <code>CUENTA_SSF</code>, <code>DESCRIPCION_SSF</code>, <code>NUMERO_PROCESO_SQL</code>, <code>CLASIFICACION</code>, <code>USUARIO_PROCESO</code>, <code>ESTADO_REGISTRO</code>, <code>ID_CUENTA</code>.</li> <li>Salidas:<ul> <li><code>OLE DB Command Output</code>: Salida principal.</li> <li><code>OLE DB Command Error Output</code>: Salida de error.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Rutas del Pipeline</p> <ul> <li><code>Agregar</code>: Desde <code>Conditional Split.Outputs[Agregar]</code> hasta <code>Destino de ADO NET.Inputs[Entrada de destino de ADO NET]</code>.</li> <li><code>Lookup Match Output</code>: Desde <code>Lookup.Outputs[Lookup Match Output]</code> hasta <code>Conditional Split.Inputs[Conditional Split Input]</code>.</li> <li><code>Modificar</code>: Desde <code>Conditional Split.Outputs[Modificar]</code> hasta <code>OLE DB Command.Inputs[OLE DB Command Input]</code>.</li> <li><code>Salida de origen de ADO NET</code>: Desde <code>DIM_CUENTA_CONTABLE_ORIG.Outputs[Salida de origen de ADO NET]</code> hasta <code>Lookup.Inputs[Lookup Input]</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-de-datos_1","title":"Diagrama de flujo de proceso de datos","text":"<pre><code>sequenceDiagram\n    participant DIM_CUENTA_CONTABLE_ORIG\n    participant Lookup\n    participant Conditional_Split\n    participant Destino_de_ADO_NET\n    participant OLE_DB_Command\n\n    DIM_CUENTA_CONTABLE_ORIG-&gt;&gt;Lookup: Salida de origen de ADO NET\n    Lookup-&gt;&gt;Conditional_Split: Lookup Match Output\n    Conditional_Split-&gt;&gt;Destino_de_ADO_NET: Agregar\n    Conditional_Split-&gt;&gt;OLE_DB_Command: Modificar</code></pre> <p>&lt;!-- ### Componente <code>Cargar_DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIAS</code></p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Cargar_DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIAS</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de cargar datos en las dimensiones <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code> y <code>DIM_CATEGORIAS</code>. Esta tarea realiza operaciones de eliminaci\u00f3n, truncado e inserci\u00f3n de datos en las tablas correspondientes del Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{117A40D1-E1F3-4DF6-9457-B49F2D971A3B}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Descripci\u00f3n: Tarea Ejecutar SQL</li> <li>Conexi\u00f3n: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code></li> <li>Declaraciones SQL:<ul> <li>Eliminar restricciones de clave for\u00e1nea en el esquema <code>Transversal</code>.</li> <li>Truncar las tablas <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code> y <code>DIM_CATEGORIAS</code>.</li> <li>Insertar registros en las tablas <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code> y <code>DIM_CATEGORIAS</code>.</li> <li>Insertar un registro para el personal sin datos en la tabla <code>DIM_PERSONAL</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Cargar_DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIAS\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant SQL as Script SQL\n  participant DWH as Data Warehouse\n\n  SSIS-&gt;&gt;SQL: Ejecutar eliminaci\u00f3n de restricciones de clave for\u00e1nea\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de eliminaci\u00f3n\n  SSIS-&gt;&gt;SQL: Ejecutar truncado de tablas\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registros en DIM_UNIDAD\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_UNIDAD\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registros en DIM_INFRAESTRUCTURA_CCF\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_INFRAESTRUCTURA_CCF\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registros en DIM_CATEGORIAS\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_CATEGORIAS\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registro en DIM_PERSONAL\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_PERSONAL</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo","title":"C\u00f3digo","text":"<pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON; -- Configura el manejo est\u00e1ndar de valores nulos.\nGO\nSET QUOTED_IDENTIFIER ON; -- Permite usar comillas dobles para nombres de objetos.\nGO\n\n-- Eliminar restricciones de clave for\u00e1nea del esquema 'Transversal'.\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n\n-- Limpiar las tablas mediante truncado para eliminar datos existentes.\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDAD]; -- Tabla de unidades.\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_INFRAESTRUCTURA_CCF]; -- Infraestructura CCF.\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CATEGORIA]; -- Categor\u00edas.\n\n-- Insertar registros iniciales en la tabla DIM_UNIDAD.\nINSERT INTO [Transversal].[DIM_UNIDAD] (UNIDAD)\nVALUES ('EDUCACI\u00d3N FORMAL'), -- Representa Educaci\u00f3n Formal.\n       ('EDUCACI\u00d3N T\u00c9CNICA'), -- Representa Educaci\u00f3n T\u00e9cnica.\n       ('EDUCACI\u00d3N CONTINUA'), -- Representa Educaci\u00f3n Continua.\n       ('PROTECCI\u00d3N SOCIAL'), -- Representa Protecci\u00f3n Social.\n       ('SIN UNIDAD'); -- Valor predeterminado para datos sin unidad.\n\n-- Insertar registros en DIM_INFRAESTRUCTURA_CCF con valores asociados a unidades espec\u00edficas.\nINSERT INTO [Transversal].[DIM_INFRAESTRUCTURA_CCF] ([COD_INFRAESTRUCTURA_CCF], [DESCRIPCION], [ID_UNIDAD]) VALUES\n('CCF008-12-00001', 'Educaci\u00f3n formal', 1), -- Educaci\u00f3n formal asociada a ID 1.\n('CCF008-13-00001', 'Educaci\u00f3n para el trabajo', 2), -- Educaci\u00f3n t\u00e9cnica asociada a ID 2.\n('CCF008-15-00001', 'Desarrollo empresarial', 3), -- Desarrollo empresarial asociado a ID 3.\n('CCF008-26-00001', 'Protecci\u00f3n social', 4); -- Protecci\u00f3n social asociada a ID 4.\n\n-- Insertar registros en DIM_CATEGORIA con las categor\u00edas disponibles.\nINSERT INTO [Transversal].[DIM_CATEGORIA] ([COD_CATEGORIA], [DESCRIPCION]) VALUES\n('1', 'Categor\u00eda A'), -- Categor\u00eda A.\n('2', 'Categor\u00eda B'), -- Categor\u00eda B.\n('3', 'Categor\u00eda C'), -- Categor\u00eda C.\n('4', 'Categor\u00eda D'), -- Categor\u00eda D.\n('5', 'Empresas'), -- Categor\u00eda para empresas.\n('6', 'Fondos de Ley'), -- Fondos de ley.\n('10', 'Convenios y Facultativos'), -- Convenios.\n('12', 'Empresa no afiliada'); -- Empresas no afiliadas.\n\n-- Insertar un registro en la tabla DIM_PERSONAL para representar datos gen\u00e9ricos o no disponibles.\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] ON; -- Permite insertar valores en la columna IDENTITY.\nINSERT INTO [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL], \n    [COD_PERSONA_UNIDAD], \n    [ID_UNIDAD], \n    [SERVICIO], \n    [NOMBRE], \n    [TELEFONO], \n    [CELULAR], \n    [CORREO], \n    [DIRECCION], \n    [CIUDAD], \n    [TIPO_DOCUMENTO], \n    [DOCUMENTO], \n    [FECHA_NACIMIENTO], \n    [GENERO], \n    [HORAS_CONTRATADAS_MENSUAL], \n    [HORAS_CONTRATADAS_TOTALES], \n    [VALOR_TOTAL], \n    [TIPO_CONTRATACION], \n    [FECHA_INICIO_CONTRATACION], \n    [FECHA_FIN_CONTRATACION], \n    [CAUSA_TERMINACION_CONTRATO], \n    [PREGRADO], \n    [POSGRADO_ESPECIALIDAD], \n    [POSGRADO_MAESTRIA], \n    [POSGRADO_DOCTORADO], \n    [NIVEL_INGLES], \n    [AREA]\n) \nVALUES (\n    -1, -- ID predeterminado para datos gen\u00e9ricos.\n    -1, -- C\u00f3digo gen\u00e9rico.\n    5, -- Unidad asociada a \"SIN UNIDAD\".\n    NULL, NULL, NULL, NULL, NULL, NULL, NULL, -- Datos personales no disponibles.\n    'CC', '-1', NULL, NULL, NULL, NULL, NULL, -- Documento y tipo predeterminado.\n    NULL, '1900-01-01', '1900-01-01', NULL, NULL, NULL, NULL, NULL, NULL, NULL\n);\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] OFF; -- Finaliza la inserci\u00f3n de IDENTITY.\nGO\n``` --&gt;\n\n### Componente **`Limpiar_DIM_UNIDADES_ORGANIZATIVAS`**\n\n#### Descripci\u00f3n General\n\nLa tarea `Limpiar_DIM_UNIDADES_ORGANIZATIVAS` es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de limpiar la tabla `DIM_UNIDADES_ORGANIZATIVAS` en el Data Warehouse. Esta tarea realiza operaciones de eliminaci\u00f3n de restricciones de clave for\u00e1nea y truncado de la tabla correspondiente.\n\n#### Detalles de la Tarea\n\n- **ID de la Tarea**: `{047c1578-c938-442e-8b96-1f6a3417d0a2}`\n- **Tipo de Tarea**: `Microsoft.ExecuteSQLTask`\n- **Descripci\u00f3n**: Tarea Ejecutar SQL\n- **Conexi\u00f3n**: `{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}`\n- **Declaraciones SQL**:\n    - Eliminar restricciones de clave for\u00e1nea en el esquema `Transversal`.\n    - Truncar la tabla `DIM_UNIDADES_ORGANIZATIVAS`.\n\n#### Diagrama de Secuencia del Proceso ETL\n\n```mermaid\nsequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Limpiar_DIM_UNIDADES_ORGANIZATIVAS\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant SQL as Script SQL\n  participant DWH as Data Warehouse\n\n  SSIS-&gt;&gt;SQL: Ejecutar eliminaci\u00f3n de restricciones de clave for\u00e1nea\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de eliminaci\u00f3n\n  SSIS-&gt;&gt;SQL: Ejecutar truncado de tabla DIM_UNIDADES_ORGANIZATIVAS\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql","title":"C\u00f3digo SQL","text":"<pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n\n-- Eliminar restricciones de clave for\u00e1nea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n\n-- Truncar tabla DIM_UNIDADES_ORGANIZATIVAS\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDADES_ORGANIZATIVAS];\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar-valores-nulos-por-defecto-para-todos-los-esquemas","title":"Componente <code>Cargar Valores nulos por defecto para todos los esquemas</code>","text":"<p>El paquete SSIS \"Cargar Valores nulos por defecto para todos los esquemas\" se encarga de inicializar y estandarizar los datos en m\u00faltiples esquemas del Data Warehouse <code>DWH_COMFENALCO</code> mediante la ejecuci\u00f3n de un proceso SQL. Este componente se encarga de eliminar restricciones, truncar tablas y cargar registros predeterminados (con valores nulos o -1) en diversas tablas de las \u00e1reas Transversal, Cedesarrollo, Protecci\u00f3n y Colegio. La implementaci\u00f3n de esta tarea garantiza que, en ausencia de datos v\u00e1lidos, se disponga de registros por defecto que faciliten las consultas y an\u00e1lisis posteriores en plataformas de inteligencia de negocios.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete_1","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del componente es:</p> <ol> <li>Eliminar restricciones de clave for\u00e1nea en el esquema <code>Transversal</code> para permitir la carga de datos sin conflictos.</li> <li>Truncar tablas en las \u00e1reas correspondientes para limpiar datos obsoletos o inconsistentes.</li> <li>Insertar registros por defecto en las dimensiones clave, utilizando valores nulos o identificadores especiales (como -1) para representar datos no disponibles o gen\u00e9ricos.</li> <li>Estandarizar la carga de informaci\u00f3n en las \u00e1reas Transversal, Cedesarrollo, Protecci\u00f3n y Colegio, asegurando la integridad y consistencia de los datos en el Data Warehouse.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-paquete_1","title":"Descripci\u00f3n del Paquete","text":"<p>La tarea se realiza a trav\u00e9s de una Tarea Ejecutar SQL (Execute SQL Task) que contiene un bloque de c\u00f3digo SQL con las siguientes operaciones:</p> <ol> <li> <p>Eliminaci\u00f3n de restricciones de clave for\u00e1nea:  </p> <ul> <li>Se genera y ejecuta un comando din\u00e1mico que elimina todas las restricciones de llave for\u00e1nea en el esquema <code>Transversal</code>.</li> </ul> </li> <li> <p>Truncado e inserci\u00f3n en la dimensi\u00f3n de Unidades:  </p> <ul> <li>Se trunca la tabla <code>DIM_UNIDAD</code> y se insertan registros que representan las diferentes unidades operativas: Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua, Protecci\u00f3n Social y un valor por defecto (\"SIN UNIDAD\").</li> </ul> </li> <li> <p>Cargar datos en DIM_INFRAESTRUCTURA_CCF:  </p> <ul> <li>Se trunca la tabla y se insertan registros que incluyen un valor por defecto (con c\u00f3digo -1 y descripci\u00f3n 'SinDato') y registros reales asociados a cada unidad.</li> </ul> </li> <li> <p>Cargar registros en DIM_CATEGORIA:  </p> <ul> <li>Se trunca la tabla <code>DIM_CATEGORIA</code> y se insertan categor\u00edas predefinidas, abarcando desde categor\u00edas est\u00e1ndar hasta aquellas para empresas y convenios.</li> </ul> </li> <li> <p>Inicializaci\u00f3n de la tabla DIM_PERSONAL:  </p> <ul> <li>Se trunca la tabla y se inserta un registro para el personal sin datos (con ID -1), permitiendo que exista un valor por defecto en situaciones donde no se disponga de informaci\u00f3n personal.</li> </ul> </li> <li> <p>Carga de registros por defecto en DIM_TARIFAS_SERVICIOS:  </p> <ul> <li>Se trunca la tabla y se inserta un registro con ID_TARIFA -1, utilizando valores de ejemplo para los campos que definen el servicio, objeto, costo, tarifa, categor\u00eda, a\u00f1o y c\u00f3digo de infraestructura.</li> </ul> </li> <li> <p>Carga de registros en el esquema Cedesarrollo:  </p> <ul> <li>Se truncan las tablas DIM_PROGRAMA y DIM_PERIODO_ACADEMICO, insert\u00e1ndose un registro por defecto en cada una (con ID -1) para representar programas y periodos sin datos.</li> </ul> </li> <li> <p>Carga de registros en el esquema Protecci\u00f3n:  </p> <ul> <li>Se actualizan las tablas DIM_PROGRAMA, DIM_PREGUNTAS_EE_JEC, DIM_RESPUESTAS_EE_JEC, DIM_PREGUNTAS_EE_AIPI y DIM_RESPUESTAS_EE_AIPI, insertando registros predeterminados (con valores -1 y descripciones como 'PREGUNTA_ABIERTA' o 'RESPUESTA_PREGUNTA_ABIERTA') para manejar datos no disponibles.</li> </ul> </li> <li> <p>Verificaci\u00f3n e inserci\u00f3n en el esquema Colegio:  </p> <ul> <li>Se verifica la existencia de un registro por defecto en la tabla <code>DIM_POBLACION_MATRICULA</code>. Si no existe, se trunca la tabla y se inserta un registro con ID -1, que utiliza valores \"N/A\" y un mensaje descriptivo para representar a estudiantes sin cruce de datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#tablas-y-columnas-clave_1","title":"Tablas y Columnas Clave","text":"<p>A continuaci\u00f3n se enumeran algunas de las tablas afectadas y el prop\u00f3sito de los valores por defecto:</p> <ol> <li> <p>DIM_UNIDAD:</p> <ul> <li>Columna: <code>UNIDAD</code></li> <li>Valores Insertados: 'EDUCACI\u00d3N FORMAL', 'EDUCACI\u00d3N T\u00c9CNICA', 'EDUCACI\u00d3N CONTINUA', 'PROTECCI\u00d3N SOCIAL', 'SIN UNIDAD'</li> </ul> </li> <li> <p>DIM_INFRAESTRUCTURA_CCF:</p> <ul> <li>Columnas: <code>COD_INFRAESTRUCTURA_CCF</code>, <code>DESCRIPCION</code>, <code>ID_UNIDAD</code></li> <li>Valores Insertados: Incluye un registro por defecto con <code>'-1'</code>, 'SinDato', y 5, adem\u00e1s de registros reales asociados a cada unidad.</li> </ul> </li> <li> <p>DIM_CATEGORIA:</p> <ul> <li>Columnas: <code>COD_CATEGORIA</code>, <code>DESCRIPCION</code></li> <li>Valores Insertados: '1' a '12' con descripciones como 'Categor\u00eda A', 'Categor\u00eda B', etc.</li> </ul> </li> <li> <p>DIM_PERSONAL:</p> <ul> <li>Columnas: Incluye <code>ID_PERSONAL</code>, <code>COD_PERSONA_UNIDAD</code>, <code>ID_UNIDAD</code>, entre otras.</li> <li>Valores Insertados: Un registro con <code>ID_PERSONAL = -1</code> para representar datos gen\u00e9ricos.</li> </ul> </li> <li> <p>DIM_TARIFAS_SERVICIOS:</p> <ul> <li>Columnas: Incluye <code>ID_TARIFA</code>, <code>COD_SERVICIO</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>VAL_TARIFA</code>, <code>COD_CATEGORIA</code>, <code>ANIO_TARIFA</code>, <code>COD_INFRAESTRUCTURA_CCF</code></li> <li>Valores Insertados: Un registro con <code>ID_TARIFA = -1</code> que establece valores predeterminados para definir un servicio sin datos.</li> </ul> </li> <li> <p>DIM_PROGRAMA (Cedesarrollo) y DIM_PERIODO_ACADEMICO (Cedesarrollo):</p> <ul> <li>Valores Insertados: Se insertan registros con <code>ID_PROGRAMA = -1</code> y <code>ID_PERIODO = -1</code> respectivamente, indicando ausencia de datos.</li> </ul> </li> <li> <p>Tablas en Protecci\u00f3n (DIM_PROGRAMA, DIM_PREGUNTAS_EE_JEC, DIM_RESPUESTAS_EE_JEC, DIM_PREGUNTAS_EE_AIPI, DIM_RESPUESTAS_EE_AIPI):</p> <ul> <li>Valores Insertados: Se insertan registros que utilizan el valor -1 para representar preguntas y respuestas predeterminadas.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA (Colegio):</p> <ul> <li>Valores Insertados: Se inserta un registro con <code>ID_POBLACION_MATRICULA = -1</code> en caso de que no exista, utilizando valores \"N/A\" y una descripci\u00f3n para estudiantes sin cruce.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas_1","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-de-carga-de-valores-nulos-por-defecto","title":"Diagrama de Flujo de Proceso de Carga de Valores Nulos por Defecto","text":"<pre><code>sequenceDiagram\n    participant SQL_TASK as Tarea Ejecutar SQL\n    participant Transversal as Esquema Transversal\n    participant Cedesarrollo as Esquema Cedesarrollo\n    participant Proteccion as Esquema Proteccion\n    participant Colegio as Esquema Colegio\n\n    SQL_TASK-&gt;&gt;Transversal: Eliminar restricciones y truncar tablas DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF, DIM_CATEGORIA y DIM_PERSONAL\n    Transversal--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de eliminaci\u00f3n y truncado\n    SQL_TASK-&gt;&gt;Transversal: Insertar registros por defecto en DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIA\n    Transversal--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Transversal: Insertar registro por defecto en DIM_PERSONAL\n    Transversal--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Transversal: Insertar registro por defecto en DIM_TARIFAS_SERVICIOS\n    Transversal--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Cedesarrollo: Truncar e insertar registro por defecto en DIM_PROGRAMA y DIM_PERIODO_ACADEMICO\n    Cedesarrollo--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Proteccion: Truncar e insertar registros predeterminados en DIM_PROGRAMA, DIM_PREGUNTAS_EE_JEC, DIM_RESPUESTAS_EE_JEC, DIM_PREGUNTAS_EE_AIPI y DIM_RESPUESTAS_EE_AIPI\n    Proteccion--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Colegio: Verificar e insertar registro por defecto en DIM_POBLACION_MATRICULA\n    Colegio--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito","title":"Prop\u00f3sito:","text":"<p>Este componente tiene como objetivo inicializar y estandarizar los datos en m\u00faltiples esquemas del Data Warehouse mediante la carga de valores predeterminados en caso de ausencia de informaci\u00f3n. Esto facilita la integraci\u00f3n de datos y evita problemas en las consultas y an\u00e1lisis posteriores.</p> <p>Operaciones Principales:</p> <ol> <li> <p>Eliminaci\u00f3n de Restricciones:  </p> <ul> <li>Genera y ejecuta un script din\u00e1mico para eliminar todas las restricciones de clave for\u00e1nea en el esquema <code>Transversal</code>, permitiendo la inserci\u00f3n de datos sin conflictos.</li> </ul> </li> <li> <p>Limpieza de Tablas:  </p> <ul> <li>Se truncan las tablas cr\u00edticas en los esquemas involucrados (por ejemplo, <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code>, <code>DIM_CATEGORIA</code>, <code>DIM_PERSONAL</code>, <code>DIM_TARIFAS_SERVICIOS</code>, entre otras) para asegurar que no existan datos obsoletos o inconsistentes.</li> </ul> </li> <li> <p>Carga de Registros Predeterminados:  </p> <ul> <li>Inserta registros con valores especiales (usualmente -1 o 'N/A') en cada tabla para representar datos no disponibles.  </li> <li>Se incluyen registros para \u00e1reas operativas como Transversal, Cedesarrollo, Protecci\u00f3n y Colegio, garantizando que cada \u00e1rea disponga de un registro por defecto.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_1","title":"C\u00f3digo SQL","text":"<pre><code>USE DWH_COMFENALCO\nGO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- Eliminar restricciones de clave for\u00e1nea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDAD];\nINSERT INTO [Transversal].[DIM_UNIDAD] (UNIDAD)\nVALUES ('EDUCACI\u00d3N FORMAL'), ('EDUCACI\u00d3N T\u00c9CNICA'), ('EDUCACI\u00d3N CONTINUA'), ('PROTECCI\u00d3N SOCIAL'), ('SIN UNIDAD');\n-- Insertar registros en DIM_INFRAESTRUCTURA\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_INFRAESTRUCTURA_CCF];\nINSERT INTO [Transversal].[DIM_INFRAESTRUCTURA_CCF] ([COD_INFRAESTRUCTURA_CCF], [DESCRIPCION], [ID_UNIDAD]) VALUES\n('-1', 'SinDato', 5),\n('CCF008-12-00001', 'Educaci\u00f3n formal', 1),\n('CCF008-13-00001', 'Educaci\u00f3n para el trabajo', 2),\n('CCF008-15-00001', 'Desarrollo empresarial', 3),\n('CCF008-26-00001', 'Protecci\u00f3n social', 4);\n-- Insertar registros DIM_CATEGORIA\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CATEGORIA];\nINSERT INTO [Transversal].[DIM_CATEGORIA] ([COD_CATEGORIA], [DESCRIPCION]) VALUES\n('1', 'Categor\u00eda A'),\n('2', 'Categor\u00eda B'),\n('3', 'Categor\u00eda C'),\n('4', 'Categor\u00eda D'),\n('5', 'Empresas'),\n('6', 'Fondos de Ley'),\n('10', 'Convenios y Facultativos'),\n('12', 'Empresa no afiliada');\n\n-- Insertar un registro para el personal sin datos\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL];\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] ON;\nINSERT INTO [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL], \n    [COD_PERSONA_UNIDAD], \n    [ID_UNIDAD], \n    [SERVICIO], \n    [NOMBRE], \n    [TELEFONO], \n    [CELULAR], \n    [CORREO], \n    [DIRECCION], \n    [CIUDAD], \n    [TIPO_DOCUMENTO], \n    [DOCUMENTO], \n    [FECHA_NACIMIENTO], \n    [GENERO], \n    [HORAS_CONTRATADAS_MENSUAL], \n    [HORAS_CONTRATADAS_TOTALES], \n    [VALOR_TOTAL], \n    [TIPO_CONTRATACION], \n    [FECHA_INICIO_CONTRATACION], \n    [FECHA_FIN_CONTRATACION], \n    [CAUSA_TERMINACION_CONTRATO], \n    [PREGRADO], \n    [POSGRADO_ESPECIALIDAD], \n    [POSGRADO_MAESTRIA], \n    [POSGRADO_DOCTORADO], \n    [NIVEL_INGLES], \n    [AREA]\n) \nVALUES (\n    -1, \n    -1, \n    5,\n    NULL, NULL, NULL, NULL, NULL, NULL, NULL, \n    'CC', '-1', NULL, NULL, NULL, NULL, NULL, \n    NULL, '1900-01-01', '1900-01-01', NULL, NULL, NULL, NULL, NULL, NULL, NULL\n);\n\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] OFF;\nGO\n\n-- Insertar registro con ID_TARIFA -1\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_TARIFAS_SERVICIOS]\nSET IDENTITY_INSERT [Transversal].[DIM_TARIFAS_SERVICIOS] ON;\nINSERT INTO [Transversal].[DIM_TARIFAS_SERVICIOS] (\n    [ID_TARIFA],\n    [COD_SERVICIO],\n    [CON_OBJETO_TARIFA],\n    [COS_UNITARIO_CONCEPTO],\n    [VAL_TARIFA],\n    [COD_CATEGORIA],\n    [ANIO_TARIFA],\n    [COD_INFRAESTRUCTURA_CCF]\n)\nVALUES (\n    -1,\n    0, -- Ejemplo de servicio\n    'default object', -- Ejemplo de objeto\n    0, -- Ejemplo de costo unitario\n    0, -- Ejemplo de valor de tarifa\n    '3', -- Debe coincidir con el valor en DIM_CATEGORIA\n    '2024', -- Ejemplo de a\u00f1o de tarifa\n    '-1' -- Debe coincidir con el valor en DIM_INFRAESTRUCTURA_CCF\n);\n\nSET IDENTITY_INSERT [Transversal].[DIM_TARIFAS_SERVICIOS] OFF;\n\n-- Insertar registro con ID_PROGRAMA -1\nTRUNCATE TABLE [DWH_COMFENALCO].[Cedesarrollo].[DIM_PROGRAMA] \nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PROGRAMA] ON;\nINSERT INTO [Cedesarrollo].[DIM_PROGRAMA] (\n    [ID_PROGRAMA],\n    [PROGRAMA]\n)\nVALUES (\n    -1,\n    'Sin Programa' -- Ejemplo de nombre de programa\n);\n\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PROGRAMA] OFF;\n\n-- Insertar un registro para el periodo sin datos\nTRUNCATE TABLE [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO];\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] ON;\n\nINSERT INTO [Cedesarrollo].[DIM_PERIODO_ACADEMICO] (\n    [ID_PERIODO], \n    [ID_UNIDAD], \n    [PERIODO_ACADEMICO], \n    [FECHA_INICIO], \n    [FECHA_FIN]\n) \nVALUES (\n    -1, \n    5, \n    'Sin datos', \n    NULL, \n    NULL\n);\n\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] OFF;\nGO\n\n-- Insertar registros de programas Proteccion\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] ON\nINSERT INTO [Proteccion].[DIM_PROGRAMA] (ID_PROGRAMA,PROGRAMA)\nVALUES (1,'ADULTO_MAYOR'),\n(2,'DISCAPACIDAD'),\n(3,'JEC'),\n(4,'AIPI');\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] OFF;\n\n\n-- Insertar -1 para preguntas proteccion JEC\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC] ON\nINSERT INTO [Proteccion].[DIM_PREGUNTAS_EE_JEC] (ID_PREGUNTA,PREGUNTA,ID_PROGRAMA)\nVALUES (-1,'PREGUNTA_ABIERTA',3);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC] OFF;\n\n-- Insertar -1 para respuestas proteccion JEC\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] ON\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_JEC] (ID_RESPUESTA,RESPUESTA,ID_PREGUNTA)\nVALUES (-1,'RESPUESTA_PREGUNTA_ABIERTA',-1);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] OFF;\n\n\n-- Insertar -1 para preguntas proteccion AIPI\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI] ON\nINSERT INTO [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (ID_PREGUNTA,PREGUNTA,ID_PROGRAMA)\nVALUES (-1,'PREGUNTA_ABIERTA',4);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI] OFF;\n\n\n-- Insertar -1 para respuestas proteccion AIPI\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] ON\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (ID_RESPUESTA,RESPUESTA,ID_PREGUNTA)\nVALUES (-1,'RESPUESTA_PREGUNTA_ABIERTA',-1);\n\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] OFF; \n\n\n\n-- Verificar si el registro ya existe\nIF NOT EXISTS (\n    SELECT 1\n    FROM [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA]\n    WHERE [ID_POBLACION_MATRICULA] = -1\n)\nBEGIN\n    -- Activar IDENTITY_INSERT para la tabla\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] ON;\n\n-- Insertar el registro con ID_POBLACION_MATRICULA = -1 para colegio\n    INSERT INTO [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] \n    (\n        [ID_POBLACION_MATRICULA],\n        [PARTNER],\n        [TIPO_DOCUMENTO],\n        [DOCUMENTO],\n        [NOMBRE_COMPLETO],\n        [GENERO],\n        [DIRECCION],\n        [TELEFONO],\n        [CORREO],\n        [FECHA_NACIMIENTO]\n    )\n    VALUES \n    (\n        -1,\n        'N/A', -- PARTNER\n        'N/A', -- TIPO_DOCUMENTO\n        'N/A', -- DOCUMENTO\n        'Estudiantes sin cruce', -- NOMBRE_COMPLETO\n        'N/A', -- GENERO\n        'N/A', -- DIRECCION\n        'N/A', -- TELEFONO\n        'N/A', -- CORREO\n        NULL -- FECHA_NACIMIENTO\n    );\n\n    -- Desactivar IDENTITY_INSERT para la tabla\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] OFF;\nEND\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_unidades_organizativas","title":"Componente <code>Cargar_DIM_UNIDADES_ORGANIZATIVAS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente <code>Cargar_DIM_UNIDADES_ORGANIZATIVAS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de cargar datos en la tabla <code>DIM_UNIDADES_ORGANIZATIVAS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Cargar_DIM_UNIDADES_ORGANIZATIVAS</code></li> <li>DTSID: <code>{2b52324e-63da-4f09-aadd-80b248ece527}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen de Datos ADO.NET (<code>DIM_UNIDADES_ORGANIZATIVAS_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server, OLE DB, ODBC u Oracle mediante el correspondiente proveedor de datos de .NET Framework.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_CEBE], [CEBE], [DESCRIPCION_BREVE], [DESCRIPCION_COMPLETA], [DEPARTAMENTO], [AREA], [SUBAREA], [SEGMENTO], [DESCRIPCION_SEGMENTO], [CODIGO_SSF], [NOMBRE_SSF], [UDATE], [NUMERO_PROCESO_SQL], [FEC_PROCESO], [USUARIO_PROCESO], [GRUPO_CEBE], \nCASE \n    WHEN [DEPARTAMENTO] = 'EDUCACION FORMAL' THEN 1\n    WHEN [DEPARTAMENTO] = 'EDUCACION PARA EL TRABAJO' THEN 2\n    WHEN [DEPARTAMENTO] = 'DESARROLLO EMPRESARIAL' THEN 3\n    WHEN [DEPARTAMENTO] = 'PROGRAMAS Y CONVENIOS ESPECIALES' AND [AREA] IN ('Adulto Mayor', 'Discapacidad', 'Atencion integral a la Ninez', 'Jornada Escolar Complementaria') THEN 4\n    ELSE 5\nEND AS [ID_UNIDAD]\nFROM [DWH_COMFENALCO].[Financiera].[DIM_UNIDADES_ORGANIZATIVAS]\nWHERE DEPARTAMENTO IN ('EDUCACION FORMAL', 'EDUCACION PARA EL TRABAJO', 'DESARROLLO EMPRESARIAL')\nOR (DEPARTAMENTO IN ('PROGRAMAS Y CONVENIOS ESPECIALES') AND AREA IN ('Adulto Mayor', 'Discapacidad','Atencion integral a la Ninez','Jornada Escolar Complementaria'))\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>AllowImplicitStringConversion</code>: <code>true</code></li> <li><code>TableOrViewName</code>: <code>\"Financiera\".\"DIM_CUENTA_CONTABLE\"</code></li> <li><code>AccessMode</code>: <code>2</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_CEBE</code>, <code>CEBE</code>, <code>DESCRIPCION_BREVE</code>, <code>DESCRIPCION_COMPLETA</code>, <code>DEPARTAMENTO</code>, <code>AREA</code>, <code>SUBAREA</code>, <code>SEGMENTO</code>, <code>DESCRIPCION_SEGMENTO</code>, <code>CODIGO_SSF</code>, <code>NOMBRE_SSF</code>, <code>UDATE</code>, <code>NUMERO_PROCESO_SQL</code>, <code>FEC_PROCESO</code>, <code>USUARIO_PROCESO</code>, <code>GRUPO_CEBE</code></li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_UNIDADES_ORGANIZATIVAS_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en una base de datos compatible con ADO.NET que use una vista o tabla de base de datos.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_UNIDADES_ORGANIZATIVAS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_CEBE</code>, <code>CEBE</code>, <code>DESCRIPCION_BREVE</code>, <code>DESCRIPCION_COMPLETA</code>, <code>DEPARTAMENTO</code>, <code>AREA</code>, <code>SUBAREA</code>, <code>SEGMENTO</code>, <code>DESCRIPCION_SEGMENTO</code>, <code>CODIGO_SSF</code>, <code>NOMBRE_SSF</code>, <code>UDATE</code>, <code>NUMERO_PROCESO_SQL</code>, <code>FEC_PROCESO</code>, <code>USUARIO_PROCESO</code>, <code>GRUPO_CEBE</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-descargar_am-tra-08","title":"Componente <code>Descargar_AM-TRA-08</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_AM-TRA-08</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para la conexi\u00f3n a SharePoint y la descarga de archivos manuales.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_1","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_1","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Descargar_AM-TRA-08</code></li> <li>DTSID: <code>{16C2FBC1-E5C9-472A-BE1E-3575DAEF56C3}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar proceso</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteProcess</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Executable: <code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>01.SharePoint_Connection_AM-TRA-08.py</code></li> <li>WorkingDirectory: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_1","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Descargar_AM-TRA-08\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Script as Script Python\n    participant SharePoint as SharePoint\n\n    SSIS-&gt;&gt;Script: Ejecutar 01.SharePoint_Connection_AM-TRA-08.py\n    Script-&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de conexi\u00f3n\n    Script-&gt;&gt;SharePoint: Descargar archivos manuales\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de descarga\n    Script--&gt;&gt;SSIS: Proceso completado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_servicios","title":"Componente <code>Procesar_DIM_SERVICIOS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_SERVICIOS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_TARIFAS_SERVICIOS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_2","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_2","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_SERVICIOS</code></li> <li>DTSID: <code>{0EC61E46-C061-4440-8E8D-2704CC9AD0D4}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>AM-TRA-08_Manual_Tarifario</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: <code>0</code></li> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[Excel_Connection_Dim_Servicios]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ANIO_TARIFA</code>, <code>COD_INFRAESTRUCTURA_CCF</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>COD_CATEGORIA</code>, <code>VAL_TARIFA</code>, <code>COD_SERVICIO</code></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Verificar Tipos de Datos</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> <li>Columnas de Entrada:     <code>ANIO_TARIFA</code>, <code>COD_INFRAESTRUCTURA_CCF</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>COD_CATEGORIA</code>, <code>VAL_TARIFA</code>, <code>COD_SERVICIO</code></li> <li>Columnas de Salida:     <code>ANIO_TARIFA_v</code>, <code>COD_INFRAESTRUCTURA_CCF_v</code>, <code>CON_OBJETO_TARIFA_v</code>, <code>COS_UNITARIO_CONCEPTO_v</code>, <code>COD_CATEGORIA_v</code>, <code>VAL_TARIFA_v</code>, <code>COD_SERVICIO_v</code></li> </ul> </li> <li> <p>Columna Derivada (<code>Crear ID_SERVICIO_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_TARIFA_AUXILIAR</code> concatenando varias columnas de entrada.</li> <li>Columnas de Entrada:<ul> <li><code>ANIO_TARIFA_v</code></li> <li><code>COD_INFRAESTRUCTURA_CCF_v</code></li> <li><code>COD_SERVICIO_v</code></li> <li><code>COD_CATEGORIA_v</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_TARIFAS_SERVICIOS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>select * from [Transversal].[DIM_TARIFAS_SERVICIOS]</code></li> <li><code>SqlCommandParam</code>: <code>select * from (select * from [Transversal].[DIM_TARIFAS_SERVICIOS]) [refTable] where [refTable].[ID_TARIFA_AUXILIAR] = ?</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>COD_SERVICIO</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>VAL_TARIFA</code>, <code>COD_CATEGORIA</code></li> <li><code>ANIO_TARIFA</code>,  <code>COD_INFRAESTRUCTURA_CCF</code>, <code>ID_TARIFA</code>, <code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> <li>Salidas:<ul> <li><code>Agregar</code>: Filas donde <code>ID_TARIFA_AUXILIAR</code> es nulo.</li> <li><code>Sin Cambios</code>: Filas donde <code>ID_TARIFA_AUXILIAR</code> no es nulo.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_SERVICIOS_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_TARIFAS_SERVICIOS</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_TARIFAS_SERVICIOS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>COD_SERVICIO_v</code>, <code>CON_OBJETO_TARIFA_v</code>, <code>COS_UNITARIO_CONCEPTO_v</code>, <code>VAL_TARIFA_v</code>, <code>COD_CATEGORIA_v</code>, <code>ANIO_TARIFA_v</code>, <code>COD_INFRAESTRUCTURA_CCF_v</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_sedes","title":"Componente <code>Cargar_DIM_SEDES</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente <code>Cargar_DIM_SEDES</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de truncar y cargar datos en la tabla <code>DIM_SEDES</code> en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_3","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_3","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Cargar_DIM_SEDES</code></li> <li>DTSID: <code>{fbd7f70d-08d3-4da5-a641-f28f431909b7}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar SQL</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteSQLTask</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_1","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Connection: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_1","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>SQL Statement:   <pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_SEDES];\nINSERT INTO [Transversal].[DIM_SEDES] (SEDE)\nVALUES ('CEC'), ('CEDESARROLLO');\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_2","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Cargar_DIM_SEDES\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant SQL as Base de Datos SQL\n\n    SSIS-&gt;&gt;SQL: TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_SEDES]\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n    SSIS-&gt;&gt;SQL: INSERT INTO [Transversal].[DIM_SEDES] (SEDE) VALUES ('CEC'), ('CEDESARROLLO')\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso","title":"Descripci\u00f3n del Proceso","text":"<ol> <li>Truncar Tabla: La tarea ejecuta una instrucci\u00f3n SQL para truncar la tabla <code>DIM_SEDES</code>, eliminando todos los registros existentes.</li> <li>Insertar Datos: La tarea ejecuta una instrucci\u00f3n SQL para insertar nuevos registros en la tabla <code>DIM_SEDES</code> con los valores <code>'CEC'</code> y <code>'CEDESARROLLO'</code>.</li> </ol> <p>Este proceso asegura que la tabla <code>DIM_SEDES</code> se actualice con los datos m\u00e1s recientes, eliminando cualquier dato anterior y cargando los nuevos valores especificados.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-descargar_ep-tra-12","title":"Componente <code>Descargar_EP-TRA-12</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_EP-TRA-12</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para la conexi\u00f3n a SharePoint y la descarga de archivos manuales.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_4","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_4","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Descargar_EP-TRA-12</code></li> <li>DTSID: <code>{56e49c08-d0c9-4678-8e9c-27288db94c3b}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar proceso</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteProcess</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_2","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Executable: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_2","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>02.SharePoint_Connection_EP-TRA-12.py</code></li> <li>WorkingDirectory: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_3","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Descargar_EP-TRA-12\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Script as Script Python\n    participant SharePoint as SharePoint\n\n    SSIS-&gt;&gt;Script: Ejecutar 02.SharePoint_Connection_EP-TRA-12.py\n    Script-&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de conexi\u00f3n\n    Script-&gt;&gt;SharePoint: Descargar archivos manuales\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de descarga\n    Script--&gt;&gt;SSIS: Proceso completado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso_1","title":"Descripci\u00f3n del Proceso","text":"<ol> <li>Ejecutar Script Python: La tarea ejecuta el script <code>02.SharePoint_Connection_EP-TRA-12.py</code> utilizando el int\u00e9rprete de Python especificado.</li> <li>Conectar a SharePoint: El script se conecta a SharePoint para acceder a los archivos manuales.</li> <li>Descargar Archivos: El script descarga los archivos manuales desde SharePoint al directorio de trabajo especificado.</li> <li>Confirmaci\u00f3n de Descarga: El script confirma la descarga exitosa de los archivos y finaliza el proceso.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_capacidad_fisica","title":"Componente <code>Procesar_DIM_CAPACIDAD_FISICA</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_CAPACIDAD_FISICA</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_CAPACIDAD_FISICA</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_5","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_5","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_CAPACIDAD_FISICA</code></li> <li>DTSID: <code>{592bbecc-5b7f-44ef-b177-462c29ca7233}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>EP-TRA-12_Capacidad Fisica</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: <code>0</code></li> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[Excel_Connection_Dim_Capacidad]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>JORNADA</code>, <code>DESCRIPCION_ESPACIO</code>, <code>ID_UNIDAD</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> <li> <p>Columnas de Entrada:     <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>JORNADA</code>, <code>DESCRIPCION_ESPACIO</code>, <code>ID_UNIDAD</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code></p> </li> <li> <p>Columnas de Salida:     <code>Copy of ID_SALON</code>, <code>Copy of CAPACIDAD</code>, <code>Copy of JORNADA</code>, <code>Copy of DESCRIPCION_ESPACIO</code>, <code>Copy of ID_UNIDAD</code>, <code>Copy of BLOQUE</code>, <code>Copy of GRUPO</code>, <code>Copy of ID_SEDE</code>, <code>Copy of SEDE</code>, <code>Copy of ESTADO</code>, <code>Copy of FECHA_ESTADO</code></p> </li> </ul> </li> <li> <p>Columna Derivada (<code>Crear_ID_CAPACIDAD_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_CAPACIDAD_AUXILIAR</code> concatenando varias columnas de entrada.</li> <li>Columnas de Entrada:     <code>Copy of ID_SALON</code>,  <code>Copy of JORNADA</code>, <code>Copy of ID_UNIDAD</code></li> <li>Columnas de Salida:     <code>ID_CAPACIDAD_AUXILIAR</code></li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_CAPACIDAD_FISICA</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>select * from [Transversal].[DIM_CAPACIDAD_FISICA]</code></li> <li><code>SqlCommandParam</code>: <code>select * from (select * from [Transversal].[DIM_CAPACIDAD_FISICA]) [refTable] where [refTable].[ID_CAPACIDAD_AUXILIAR] = ?</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_CAPACIDAD_AUXILIAR</code></li> <li>Columnas de Salida:     <code>ID_CAPACIDAD</code>, <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>DESCRIPCION_ESPACIO</code>, <code>JORNADA</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_UNIDAD</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code>, <code>ID_CAPACIDAD_AUXILIAR</code></li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li> <p>Columnas de Entrada:     <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>JORNADA</code>, <code>DESCRIPCION_ESPACIO</code>, <code>ID_UNIDAD</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code>, <code>ID_CAPACIDAD</code></p> </li> <li> <p>Salidas:</p> <ul> <li><code>Agregar</code>: Filas donde <code>ID_CAPACIDAD</code> es nulo.</li> <li><code>Modificar</code>: Filas donde hay diferencias entre las columnas de entrada y las columnas de b\u00fasqueda.</li> <li><code>Sin Cambios</code>: Filas donde no hay diferencias.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_CAPACIDAD_FISICA_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_CAPACIDAD_FISICA</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_CAPACIDAD_FISICA\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>Copy of ID_SALON</code>, <code>Copy of CAPACIDAD</code>, <code>Copy of DESCRIPCION_ESPACIO</code>, <code>Copy of JORNADA</code>, <code>Copy of BLOQUE</code>, <code>Copy of GRUPO</code>, <code>Copy of ID_UNIDAD</code>, <code>Copy of ID_SEDE</code>, <code>Copy of SEDE</code>, <code>Copy of ESTADO</code>, <code>Copy of FECHA_ESTADO</code></li> </ul> </li> <li> <p>Comando OLE DB (<code>OLE DB Command 1</code>)</p> <ul> <li>Descripci\u00f3n: Ejecuta una instrucci\u00f3n SQL para cada fila en el flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>UPDATE [Transversal].[DIM_CAPACIDAD_FISICA]\n   SET [ID_SALON] = ?\n      ,[CAPACIDAD] = ?\n      ,[DESCRIPCION_ESPACIO] = ?\n      ,[JORNADA] = ?\n      ,[BLOQUE] = ?\n      ,[GRUPO] = ?\n      ,[ID_UNIDAD] = ?\n      ,[ID_SEDE] = ?\n      ,[SEDE] = ?\n      ,[ESTADO] = ?\n      ,[FECHA_ESTADO] = ?\n WHERE [ID_CAPACIDAD] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>DESCRIPCION_ESPACIO</code>, <code>JORNADA</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_UNIDAD</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code>, <code>ID_CAPACIDAD</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as EP-TRA-12_Capacidad Fisica\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Crear_ID_CAPACIDAD_AUXILIAR\n    participant Lookup as Lookup\n    participant ConditionalSplit as Conditional Split\n    participant AdoNetDestination as DIM_CAPACIDAD_FISICA_DEST\n    participant OleDbCommand as OLE DB Command 1\n\n    ExcelSource -&gt;&gt; DataConversion: Excel Source Output\n    DataConversion -&gt;&gt; DerivedColumn: Data Conversion Output\n    DerivedColumn -&gt;&gt; Lookup: Derived Column Output\n    Lookup -&gt;&gt; ConditionalSplit: Lookup Match Output\n    ConditionalSplit -&gt;&gt; AdoNetDestination: Agregar\n    ConditionalSplit -&gt;&gt; OleDbCommand: Modificar</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-tabla-temporal-dim_estudiantes-educacion-continua-y-tecnica","title":"Componente <code>Tabla Temporal DIM_ESTUDIANTES Educaci\u00f3n Continua y T\u00e9cnica</code>","text":"<p>El paquete SSIS \"Tabla Temporal DIM_ESTUDIANTES Educaci\u00f3n Continua y T\u00e9cnica\" se encarga de gestionar flujos ETL que permiten consolidar, transformar y cargar datos temporales relacionados con los estudiantes de Educaci\u00f3n Continua y T\u00e9cnica. Este paquete se utiliza para integrar, depurar y unificar informaci\u00f3n proveniente de diversas fuentes (Excel, bases de datos, etc.) en una tabla temporal que sirve de staging para procesos posteriores en el Data Warehouse. La soluci\u00f3n abarca desde la actualizaci\u00f3n de datos de egresados, inasistencias, matr\u00edculas y registros de estudiantes hasta la ejecuci\u00f3n de procesos adicionales para descargar informaci\u00f3n complementaria.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete_2","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es:</p> <ul> <li>Consolidar y Unificar Datos Temporales: Recopilar informaci\u00f3n de estudiantes procedente de diversas fuentes (Excel, bases de datos, etc.) y depositarla en una tabla temporal para facilitar su procesamiento posterior.</li> <li>Depurar y Transformar Datos: Aplicar conversiones, derivaciones y validaciones sobre los datos le\u00eddos para garantizar su integridad y calidad.</li> <li>Integrar Fuentes Adicionales: Ejecutar procesos externos (scripts en Python) para descargar informaci\u00f3n complementaria (egresados, matr\u00edculas, preinscritos, etc.) que permita actualizar y enriquecer la tabla temporal.</li> <li>Limpiar el Staging Area: Truncar la tabla temporal al inicio del proceso para evitar la acumulaci\u00f3n de registros obsoletos.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-paquete_2","title":"Descripci\u00f3n del Paquete","text":"<p>El paquete se compone de varios componentes que realizan operaciones ETL espec\u00edficas:</p> <ol> <li> <p>Actualizar Tabla Temporal Egresados </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Extrae datos desde una hoja de Excel (Fuente: \"Egresados\") para actualizar la informaci\u00f3n de egresados en la tabla temporal.  </li> <li>Conexi\u00f3n: Utiliza un administrador de conexiones para Excel.</li> </ul> </li> <li> <p>Actualizar Tabla Temporal Inasistencias </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Procesa informaci\u00f3n de inasistencias extra\u00edda desde Excel, aplicando transformaciones y derivaciones para adecuar los campos (como DOCUMENTO, TIPO_DOCUMENTO, ESTUDIANTE) y luego carga los datos en la tabla temporal.  </li> <li>Componentes clave: Excel Source, Transformaci\u00f3n de Columnas (Derived Column) y ADO.NET Destination.</li> </ul> </li> <li> <p>Actualizar Tabla Temporal Matr\u00edculas </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Extrae datos de matr\u00edculas desde Excel para actualizar la informaci\u00f3n en la tabla temporal, incluyendo campos como TIPO_DOCUMENTO, DOCUMENTO_ESTUDIANTE y NOMBRE_ESTUDIANTE.  </li> <li>Conexi\u00f3n: Se conecta a Excel mediante un administrador de conexiones espec\u00edfico.</li> </ul> </li> <li> <p>Actualizar Tabla Temporal Matr\u00edculas Emp </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Similar al componente anterior, pero orientado a consolidar datos de matr\u00edculas empresariales (Emp), utilizando informaci\u00f3n de una fuente Excel y cargando la informaci\u00f3n en la tabla temporal.</li> </ul> </li> <li> <p>dim_Estudiantes py </p> <ul> <li>Tipo: Execute Process Task  </li> <li>Funcionalidad: Ejecuta un script de Python (<code>dim_Estudiantes.py</code>) que procesa y consolida los datos de estudiantes a nivel general, utilizando un ejecutable de Python configurado mediante variables de proyecto.  </li> <li>Directorio de trabajo: Se configura para ejecutarse en la carpeta de utilidades.</li> </ul> </li> <li> <p>Fuentes Adicionales de Estudiantes </p> <ul> <li>Tipo: Contenedor de secuencias (Sequence)  </li> <li>Funcionalidad: Agrupa varios procesos externos para complementar la informaci\u00f3n de estudiantes. Entre ellos se encuentran:  </li> <li>Tarea cede_Egresados_Graduados: Ejecuta un script de Python para descargar informaci\u00f3n de egresados y graduados desde una fuente definida (probablemente SharePoint o similar).  </li> <li>Tarea cede_Listado_Matriculas: Ejecuta un script de Python para descargar un listado de matr\u00edculas.  </li> <li>Tarea emp_Consolidado_inasistencias: Ejecuta un script de Python para consolidar inasistencias a nivel empresarial.  </li> <li>Tarea emp_Egresados_Graduados: Ejecuta un script para procesar datos de egresados en el \u00e1mbito empresarial.  </li> <li>Tarea emp_Listado_Matriculas: Ejecuta un script para descargar informaci\u00f3n del listado de matr\u00edculas empresariales.  </li> <li>Tarea emp_Preinscritos: Ejecuta un script para procesar los  preinscritos.  </li> <li>Tarea fact_graduados py: Ejecuta un script que procesa la informaci\u00f3n de graduados.</li> </ul> </li> <li> <p>Actualizar Tabla Temporal Inscripciones </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Procesa y consolida los datos de inscripciones, extray\u00e9ndolos de Excel, aplicando transformaciones y carg\u00e1ndolos en la tabla temporal.</li> </ul> </li> <li> <p>Limpiar Tabla Temporal </p> <ul> <li>Tipo: Execute SQL Task  </li> <li>Funcionalidad: Ejecuta una instrucci\u00f3n SQL para truncar la tabla temporal <code>TMP_ESTUDIANTES_CEDESARROLLO</code>, asegurando que el proceso ETL comience sin datos previos y evite la duplicidad de registros.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas_2","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-etl","title":"Diagrama de Flujo de Proceso ETL","text":"<pre><code>sequenceDiagram\n    participant Egresados as Actualizar Tabla Temporal Egresados\n    participant Inasistencias as Actualizar Tabla Temporal Inasistencias\n    participant Matriculas as Actualizar Tabla Temporal Matr\u00edculas\n    participant MatriculasEmp as Actualizar Tabla Temporal Matr\u00edculas Emp\n    participant DimEstudiantes as dim_Estudiantes py\n    participant FuentesAdic as Fuentes adicionales de Estudiantes\n    participant Inscripciones as Actualizar Tabla Temporal Inscripciones\n    participant Limpiar as Limpiar Tabla Temporal\n\n    Egresados-&gt;&gt;Inasistencias: Proceso de consolidado de egresados y inasistencias\n    Inasistencias-&gt;&gt;Matriculas: Integraci\u00f3n de datos de inasistencias y matr\u00edculas\n    Matriculas-&gt;&gt;MatriculasEmp: Consolidaci\u00f3n de matr\u00edculas empresariales\n    MatriculasEmp-&gt;&gt;DimEstudiantes: Complemento de datos de estudiantes\n    DimEstudiantes-&gt;&gt;FuentesAdic: Ejecuci\u00f3n de procesos adicionales\n    FuentesAdic-&gt;&gt;Inscripciones: Unificaci\u00f3n de datos de inscripciones\n    Inscripciones-&gt;&gt;Limpiar: Truncado y limpieza de la tabla temporal</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-precedencia","title":"Diagrama de Precedencia","text":"<pre><code>sequenceDiagram\n    participant DimEst as dim_Estudiantes py\n    participant Fuentes as Fuentes adicionales de Estudiantes\n    participant Matriculas as Actualizar Tabla Temporal Matr\u00edculas\n    participant Inscripciones as Actualizar Tabla Temporal Inscripciones\n    participant Limpiar as Limpiar Tabla Temporal\n\n    DimEst-&gt;&gt;Fuentes: Ejecutar procesos adicionales (egresados, preinscritos, etc.)\n    Fuentes-&gt;&gt;Matriculas: Consolidar listado de matr\u00edculas\n    Matriculas-&gt;&gt;Inscripciones: Actualizar inscripciones\n    Inscripciones-&gt;&gt;Limpiar: Finalizar proceso con limpieza de la tabla temporal</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave-del-proceso","title":"Componentes Clave del Proceso","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-consolidacion-y-actualizacion-de-datos-temporales","title":"1. Consolidaci\u00f3n y Actualizaci\u00f3n de Datos Temporales","text":"<ul> <li> <p>Actualizaci\u00f3n de Datos de Egresados e Inasistencias:   Se extraen datos de fuentes Excel y se transforman para consolidar la informaci\u00f3n de egresados e inasistencias. Estos datos se integran en la tabla temporal para su posterior an\u00e1lisis.</p> </li> <li> <p>Actualizaci\u00f3n de Matr\u00edculas e Inscripciones:   Se procesan registros de matr\u00edculas e inscripciones a trav\u00e9s de m\u00faltiples Data Flow Tasks, que incluyen conversiones de datos y transformaciones derivadas para unificar la informaci\u00f3n.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-ejecucion-de-procesos-externos-con-python","title":"2. Ejecuci\u00f3n de Procesos Externos con Python","text":"<ul> <li> <p>dim_Estudiantes py:   Ejecuta un script de Python para procesar datos generales de estudiantes, sirviendo como punto de partida para la consolidaci\u00f3n.</p> </li> <li> <p>Fuentes Adicionales de Estudiantes:   Contiene m\u00faltiples tareas de proceso que descargan y actualizan informaci\u00f3n complementaria, como egresados, listado de matr\u00edculas, preinscritos y datos consolidados empresariales.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-limpieza-del-area-de-staging","title":"3. Limpieza del \u00c1rea de Staging","text":"<ul> <li>Limpiar Tabla Temporal:   Una tarea de SQL se encarga de truncar la tabla temporal <code>TMP_ESTUDIANTES_CEDESARROLLO</code>, garantizando un entorno limpio para cada ejecuci\u00f3n del proceso ETL.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_2","title":"C\u00f3digo SQL","text":"<p>El siguiente c\u00f3digo SQL se utiliza en la tarea de \"Cargar Valores nulos por defecto para todos los esquemas\" para inicializar las dimensiones con registros predeterminados:</p> <pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n\n-- Eliminar restricciones de clave for\u00e1nea en el esquema Transversal\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n\n-- Truncar y cargar datos en DIM_UNIDAD\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDAD];\nINSERT INTO [Transversal].[DIM_UNIDAD] (UNIDAD)\nVALUES ('EDUCACI\u00d3N FORMAL'), ('EDUCACI\u00d3N T\u00c9CNICA'), ('EDUCACI\u00d3N CONTINUA'), ('PROTECCI\u00d3N SOCIAL'), ('SIN UNIDAD');\n\n-- Truncar y cargar datos en DIM_INFRAESTRUCTURA_CCF\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_INFRAESTRUCTURA_CCF];\nINSERT INTO [Transversal].[DIM_INFRAESTRUCTURA_CCF] ([COD_INFRAESTRUCTURA_CCF], [DESCRIPCION], [ID_UNIDAD]) VALUES\n('-1', 'SinDato', 5),\n('CCF008-12-00001', 'Educaci\u00f3n formal', 1),\n('CCF008-13-00001', 'Educaci\u00f3n para el trabajo', 2),\n('CCF008-15-00001', 'Desarrollo empresarial', 3),\n('CCF008-26-00001', 'Protecci\u00f3n social', 4);\n\n-- Truncar y cargar datos en DIM_CATEGORIA\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CATEGORIA];\nINSERT INTO [Transversal].[DIM_CATEGORIA] ([COD_CATEGORIA], [DESCRIPCION]) VALUES\n('1', 'Categor\u00eda A'),\n('2', 'Categor\u00eda B'),\n('3', 'Categor\u00eda C'),\n('4', 'Categor\u00eda D'),\n('5', 'Empresas'),\n('6', 'Fondos de Ley'),\n('10', 'Convenios y Facultativos'),\n('12', 'Empresa no afiliada');\n\n-- Truncar y cargar datos en DIM_PERSONAL\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL];\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] ON;\nINSERT INTO [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL], \n    [COD_PERSONA_UNIDAD], \n    [ID_UNIDAD], \n    [SERVICIO], \n    [NOMBRE], \n    [TELEFONO], \n    [CELULAR], \n    [CORREO], \n    [DIRECCION], \n    [CIUDAD], \n    [TIPO_DOCUMENTO], \n    [DOCUMENTO], \n    [FECHA_NACIMIENTO], \n    [GENERO], \n    [HORAS_CONTRATADAS_MENSUAL], \n    [HORAS_CONTRATADAS_TOTALES], \n    [VALOR_TOTAL], \n    [TIPO_CONTRATACION], \n    [FECHA_INICIO_CONTRATACION], \n    [FECHA_FIN_CONTRATACION], \n    [CAUSA_TERMINACION_CONTRATO], \n    [PREGRADO], \n    [POSGRADO_ESPECIALIDAD], \n    [POSGRADO_MAESTRIA], \n    [POSGRADO_DOCTORADO], \n    [NIVEL_INGLES], \n    [AREA]\n) \nVALUES (\n    -1, -1, 5, NULL, NULL, NULL, NULL, NULL, NULL, NULL, \n    'CC', '-1', NULL, NULL, NULL, NULL, NULL, NULL, '1900-01-01', '1900-01-01', \n    NULL, NULL, NULL, NULL, NULL, NULL, NULL\n);\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] OFF;\n\n-- Truncar y cargar datos en DIM_TARIFAS_SERVICIOS\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_TARIFAS_SERVICIOS];\nSET IDENTITY_INSERT [Transversal].[DIM_TARIFAS_SERVICIOS] ON;\nINSERT INTO [Transversal].[DIM_TARIFAS_SERVICIOS] (\n    [ID_TARIFA], [COD_SERVICIO], [CON_OBJETO_TARIFA], [COS_UNITARIO_CONCEPTO],\n    [VAL_TARIFA], [COD_CATEGORIA], [ANIO_TARIFA], [COD_INFRAESTRUCTURA_CCF]\n)\nVALUES (\n    -1, 0, 'default object', 0, 0, '3', '2024', '-1'\n);\nSET IDENTITY_INSERT [Transversal].[DIM_TARIFAS_SERVICIOS] OFF;\n\n-- Truncar y cargar datos en DIM_PROGRAMA (Cedesarrollo)\nTRUNCATE TABLE [DWH_COMFENALCO].[Cedesarrollo].[DIM_PROGRAMA];\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PROGRAMA] ON;\nINSERT INTO [Cedesarrollo].[DIM_PROGRAMA] ([ID_PROGRAMA], [PROGRAMA])\nVALUES (-1, 'Sin Programa');\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PROGRAMA] OFF;\n\n-- Truncar y cargar datos en DIM_PERIODO_ACADEMICO (Cedesarrollo)\nTRUNCATE TABLE [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO];\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] ON;\nINSERT INTO [Cedesarrollo].[DIM_PERIODO_ACADEMICO] (\n    [ID_PERIODO], [ID_UNIDAD], [PERIODO_ACADEMICO], [FECHA_INICIO], [FECHA_FIN]\n)\nVALUES (\n    -1, 5, 'Sin datos', NULL, NULL\n);\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] OFF;\n\n-- Truncar e insertar registros en las tablas de Protecci\u00f3n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] ON;\nINSERT INTO [Proteccion].[DIM_PROGRAMA] (ID_PROGRAMA, PROGRAMA)\nVALUES (1, 'ADULTO_MAYOR'), (2, 'DISCAPACIDAD'), (3, 'JEC'), (4, 'AIPI');\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] OFF;\n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC] ON;\nINSERT INTO [Proteccion].[DIM_PREGUNTAS_EE_JEC] (ID_PREGUNTA, PREGUNTA, ID_PROGRAMA)\nVALUES (-1, 'PREGUNTA_ABIERTA', 3);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC] OFF;\n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] ON;\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_JEC] (ID_RESPUESTA, RESPUESTA, ID_PREGUNTA)\nVALUES (-1, 'RESPUESTA_PREGUNTA_ABIERTA', -1);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] OFF;\n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI] ON;\nINSERT INTO [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (ID_PREGUNTA, PREGUNTA, ID_PROGRAMA)\nVALUES (-1, 'PREGUNTA_ABIERTA', 4);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI] OFF;\n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] ON;\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (ID_RESPUESTA, RESPUESTA, ID_PREGUNTA)\nVALUES (-1, 'RESPUESTA_PREGUNTA_ABIERTA', -1);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] OFF;\n\n-- Verificar e insertar registro en DIM_POBLACION_MATRICULA (Colegio)\nIF NOT EXISTS (\n    SELECT 1\n    FROM [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA]\n    WHERE [ID_POBLACION_MATRICULA] = -1\n)\nBEGIN\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] ON;\n    INSERT INTO [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] (\n        [ID_POBLACION_MATRICULA], [PARTNER], [TIPO_DOCUMENTO], [DOCUMENTO],\n        [NOMBRE_COMPLETO], [GENERO], [DIRECCION], [TELEFONO], [CORREO], [FECHA_NACIMIENTO]\n    )\n    VALUES (\n        -1, 'N/A', 'N/A', 'N/A', 'Estudiantes sin cruce', 'N/A', 'N/A', 'N/A', 'N/A', NULL\n    );\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] OFF;\nEND;\nGO\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componende-agregar-registros-con-id-1-para-tablas-de-poblacion","title":"Componende <code>Agregar registros con ID -1 para tablas de poblaci\u00f3n</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion","title":"Descripci\u00f3n","text":"<p>Este proceso en la soluci\u00f3n SSIS se encarga de agregar registros con el ID <code>-1</code> en las tablas de poblaci\u00f3n. Este ID se utiliza para representar datos gen\u00e9ricos o no disponibles en las tablas de destino.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-proceso","title":"Detalles del Proceso","text":"<ol> <li>Truncar Tabla: Se ejecuta una instrucci\u00f3n SQL para truncar las tablas de poblaci\u00f3n, eliminando todos los registros existentes.</li> <li>Insertar Datos: Se ejecuta una instrucci\u00f3n SQL para insertar nuevos registros en las tablas de poblaci\u00f3n con el ID <code>-1</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_4","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Agregar registros con ID -1 para tablas de poblaci\u00f3n\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant SQL as Script SQL\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;SQL: Ejecutar truncado de tablas de poblaci\u00f3n\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n    SSIS-&gt;&gt;SQL: Insertar registros con ID -1 en tablas de poblaci\u00f3n\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_3","title":"C\u00f3digo SQL","text":"<pre><code>-- Truncar tablas de poblaci\u00f3n\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_POBLACION];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_ESTABLECIMIENTO_EDUCATIVO];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_PROGRAMA];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CAMPOS_CARACT];\n\n-- Insertar registros con ID -1\nINSERT INTO [Transversal].[DIM_POBLACION] (ID_POBLACION, TIPO_DOCUMENTO, DOCUMENTO)\nVALUES (-1, 'N/A', 'N/A');\n\nINSERT INTO [Transversal].[DIM_ESTABLECIMIENTO_EDUCATIVO] (ID_ESTABLECIMIENTO_EDUCATIVO, NOMBRE_ESTABLECIMIENTO)\nVALUES (-1, 'N/A');\n\nINSERT INTO [Transversal].[DIM_PROGRAMA] (ID_PROGRAMA, PROGRAMA)\nVALUES (-1, 'N/A');\n\nINSERT INTO [Transversal].[DIM_CAMPOS_CARACT] (ID_PREGUNTA, PREGUNTA)\nVALUES (-1, 'N/A');\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-vaciar-tabla-temporal-de-poblacion-educacion","title":"Componente <code>Vaciar tabla temporal de Poblacion Educacion</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Vaciar tabla temporal de Poblacion Educacion</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de vaciar la tabla temporal <code>TMP_POBLACION_EDUCACION</code> en el Data Warehouse. Esta tarea realiza una operaci\u00f3n de truncado en la tabla correspondiente.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea_1","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{C1C8514E-6B9D-448B-B2C4-085047066756}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Descripci\u00f3n: Tarea Ejecutar SQL</li> <li>Conexi\u00f3n: <code>{878C9AA8-681C-4799-9C30-34C49CD01857}</code></li> <li>Declaraci\u00f3n SQL:<ul> <li>Truncar la tabla <code>TMP_POBLACION_EDUCACION</code> en el esquema <code>Transversal</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_5","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Vaciar tabla temporal de Poblacion Educacion\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant SQL as Script SQL\n  participant DWH as Data Warehouse\n\n  SSIS-&gt;&gt;SQL: Ejecutar truncado de tabla TMP_POBLACION_EDUCACION\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_4","title":"C\u00f3digo SQL","text":"<pre><code>TRUNCATE TABLE [Transversal].[TMP_POBLACION_EDUCACION];\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-poblacion-prs","title":"Componente <code>Procesar Poblacion PRS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Procesar Poblacion PRS</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para procesar la poblaci\u00f3n PRS. Esta tarea utiliza el ejecutable de Python y un script espec\u00edfico para realizar el procesamiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea_2","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{7f11d36d-f826-44f0-8b89-e04825763509}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteProcess</code></li> <li>Descripci\u00f3n: Tarea Ejecutar proceso</li> <li>Conexi\u00f3n: No aplica (ejecuci\u00f3n de proceso)</li> <li>Propiedades del Componente:<ul> <li>Executable: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_3","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>03.PoblacionProteccion.py</code></li> <li>WorkingDirectory: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_6","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Procesar Poblacion PRS\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant Python as Script Python\n  participant FileSystem as Sistema de Archivos\n\n  SSIS-&gt;&gt;Python: Ejecutar script 03.PoblacionProteccion.py\n  Python--&gt;&gt;FileSystem: Leer y procesar datos\n  FileSystem--&gt;&gt;Python: Datos procesados\n  Python--&gt;&gt;SSIS: Confirmaci\u00f3n de ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-identificar-poblacion-educacion","title":"Componente <code>Identificar Poblacion Educaci\u00f3n</code>","text":"<p>El paquete SSIS \"Identificar Poblaci\u00f3n Educaci\u00f3n\" est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con la poblaci\u00f3n educativa. Este proceso ETL consolida informaci\u00f3n proveniente de diversas fuentes, como bases de datos y archivos Excel, para generar un conjunto de datos limpio y estandarizado en el \u00e1rea de staging. La soluci\u00f3n permite identificar y unir registros de estudiantes utilizando transformaciones, conversiones y b\u00fasquedas, facilitando la integraci\u00f3n y an\u00e1lisis de la informaci\u00f3n en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete_3","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es:</p> <ul> <li>Extraer y Unificar Datos: Recopilar informaci\u00f3n sobre la poblaci\u00f3n educativa desde distintas fuentes (por ejemplo, registros de inscripciones en el colegio y datos adicionales en archivos Excel).</li> <li>Transformar y Estandarizar Informaci\u00f3n: Aplicar conversiones de datos y crear columnas derivadas para asegurar la consistencia y calidad de la informaci\u00f3n.</li> <li>Realizar B\u00fasquedas y Combinar Datos: Utilizar transformaciones de Lookup y Merge para integrar y asociar datos provenientes de diferentes or\u00edgenes.</li> <li>Cargar la Informaci\u00f3n en el \u00c1rea de Staging: Depositar los datos consolidados en la tabla temporal <code>TMP_POBLACION_EDUCACION</code> para su uso posterior en el Data Warehouse.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-paquete_3","title":"Descripci\u00f3n del Paquete","text":"<p>El proceso ETL de \"Identificar Poblaci\u00f3n Educaci\u00f3n\" se compone de varios pasos:</p> <ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Se obtienen datos de dos fuentes principales:</li> <li>Origen de ADO NET: Extrae datos de la tabla <code>DIM_POBLACION_MATRICULA</code> del colegio, obteniendo columnas como <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> <li>Poblaci\u00f3n PRS: Extrae informaci\u00f3n desde un archivo Excel para complementar los datos de poblaci\u00f3n.</li> </ul> </li> <li> <p>Transformaci\u00f3n y Conversi\u00f3n:</p> <ul> <li>Data Conversion: Se aplican dos transformaciones de datos para convertir los tipos de datos de las columnas de entrada (por ejemplo, <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>) y generar versiones copiadas con longitudes y formatos requeridos.</li> <li>Derived Column: Se utiliza para crear una nueva columna (como la conversi\u00f3n o ajuste de valores nulos) mediante expresiones que aplican funciones como REPLACENULL.</li> </ul> </li> <li> <p>Uni\u00f3n y Combinaci\u00f3n de Datos:</p> <ul> <li>Lookup: Se utiliza para buscar y unir informaci\u00f3n adicional de la tabla de referencia <code>DIM_TIPO_DOCUMENTO</code>, asignando identificadores como <code>ID_TIPODOC_AFILIADO</code> y las siglas correspondientes.</li> <li>Merge: Se combinan los datos provenientes de la fuente de ADO NET y de la fuente Excel (Poblaci\u00f3n PRS) para unificar la informaci\u00f3n en un flujo ordenado.</li> <li>Sort: Se aplican transformaciones de ordenaci\u00f3n para asegurar que los flujos de datos est\u00e9n correctamente ordenados antes de ser combinados.</li> </ul> </li> <li> <p>Carga en el \u00c1rea de Staging:</p> <ul> <li>Los datos resultantes se cargan en la tabla temporal <code>TMP_POBLACION_EDUCACION</code> del esquema Transversal, utilizando un destino ADO NET.</li> <li>Adem\u00e1s, se env\u00edan registros err\u00f3neos a un archivo plano para su revisi\u00f3n y  depuraci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave-del-proceso_1","title":"Componentes Clave del Proceso","text":"<ol> <li> <p>Data Conversion y Data Conversion 1:    Se utilizan para convertir y formatear las columnas <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code> de las fuentes de datos. La primera transformaci\u00f3n opera sobre datos provenientes de un flujo combinado (Merge Output), y la segunda se encarga de convertir datos extra\u00eddos directamente del origen ADO NET.</p> </li> <li> <p>Derived Column:    Crea nuevas columnas a partir de las existentes, aplicando funciones que aseguran que los valores nulos se reemplacen por valores por defecto (por ejemplo, utilizando la funci\u00f3n REPLACENULL).</p> </li> <li> <p>Lookup:    Realiza una b\u00fasqueda en la tabla de referencia <code>DIM_TIPO_DOCUMENTO</code> para asociar a cada registro el <code>ID_TIPODOC_AFILIADO</code> correspondiente, bas\u00e1ndose en el valor convertido de <code>TIPO_DOCUMENTO</code>.</p> </li> <li> <p>Merge y Sort:    Se utilizan transformaciones de ordenaci\u00f3n y fusi\u00f3n para combinar los datos de las diferentes fuentes (origen ADO NET y Excel) en un flujo \u00fanico, asegurando la integridad del ordenamiento para la posterior uni\u00f3n.</p> </li> <li> <p>Origen de ADO NET (Estudiantes Colegio):    Extrae los datos clave de la poblaci\u00f3n educativa directamente de la base de datos del colegio, sirviendo de referencia principal para la identificaci\u00f3n de registros.</p> </li> <li> <p>Flat File Destination:    Permite la escritura de los registros que generen errores durante las transformaciones, facilitando la auditor\u00eda y depuraci\u00f3n de la informaci\u00f3n.</p> </li> <li> <p>Poblaci\u00f3n Educaci\u00f3n (Stage Area):    Carga el flujo de datos resultante en la tabla temporal <code>TMP_POBLACION_EDUCACION</code>, que servir\u00e1 de base para los procesos posteriores de integraci\u00f3n en el Data Warehouse.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas_3","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos_1","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant ADO as Origen de ADO NET\n    participant Excel as Poblaci\u00f3n PRS\n    participant DC as Data Conversion\n    participant DC1 as Data Conversion 1\n    participant DerCol as Derived Column\n    participant Lookup as Lookup\n    participant Sort as Sort\n    participant Sort1 as Sort 1\n    participant Sort2 as Sort 2\n    participant Merge as Merge\n    participant Merge1 as Merge 1\n    participant Stage as Poblacion Educacion (Stage Area)\n    participant Flat as Flat File Destination\n\n    ADO-&gt;&gt;DC1: Extraer datos de DIM_POBLACION_MATRICULA\n    Excel-&gt;&gt;Sort2: Extraer datos desde Excel\n    DC-&gt;&gt;Lookup: Convertir y formatear columnas (TIPO_DOCUMENTO, DOCUMENTO)\n    DC1-&gt;&gt;Sort1: Convertir datos del origen ADO NET\n    Sort1-&gt;&gt;Merge: Ordenar datos del origen ADO NET\n    Sort2-&gt;&gt;Merge1: Ordenar datos de Excel\n    Merge-&gt;&gt;Merge1: Fusionar flujos ordenados\n    Merge1-&gt;&gt;DerCol: Aplicar columna derivada para reemplazar nulos\n    DerCol-&gt;&gt;Stage: Cargar datos en TMP_POBLACION_EDUCACION\n    DC-&gt;&gt;Flat: Enviar filas con error a archivo plano</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-precedencia_1","title":"Diagrama de Precedencia","text":"<pre><code>sequenceDiagram\n    participant ADO as Estudiantes Colegio (Origen ADO NET)\n    participant Excel as Poblaci\u00f3n PRS (Excel)\n    participant Conv as Data Conversion\n    participant Conv1 as Data Conversion 1\n    participant Look as Lookup\n    participant M1 as Merge 1\n    participant Flat as Flat File Destination\n    participant Stage as Poblacion Educacion (Stage Area)\n\n    ADO-&gt;&gt;Conv1: Extraer y convertir datos del origen ADO NET\n    Excel-&gt;&gt;Conv: Extraer y convertir datos de Excel\n    Conv-&gt;&gt;Look: Enviar datos convertidos al Lookup\n    Look-&gt;&gt;M1: Combinar datos mediante Merge\n    M1-&gt;&gt;Stage: Cargar datos consolidados en el \u00e1rea de staging\n    Conv-&gt;&gt;Flat: Redirigir registros con error a archivo plano</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_beneficiarios","title":"Componente <code>Procesar DIM_BENEFICIARIOS</code>","text":"<p>El paquete SSIS \"Procesar DIM_BENEFICIARIOS\" se encarga de la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con los beneficiarios en el Data Warehouse. Este proceso se centra en consolidar y actualizar la dimensi\u00f3n de beneficiarios en el esquema Transversal, asegurando que la informaci\u00f3n sea precisa y est\u00e9 estandarizada para su an\u00e1lisis y toma de decisiones.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete_4","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del proceso es:</p> <ul> <li>Extraer y Unificar Datos: Recopilar informaci\u00f3n sobre beneficiarios desde diversas fuentes, incluyendo datos provenientes del \u00e1rea de staging donde se almacenan los registros temporales.</li> <li>Transformar y Estandarizar la Informaci\u00f3n: Aplicar conversiones de datos y transformar los valores para garantizar la consistencia de la dimensi\u00f3n, incluyendo el formateo de tipos de datos y la integraci\u00f3n de identificadores clave.</li> <li>Cargar la Informaci\u00f3n en la Dimensi\u00f3n: Insertar o actualizar los registros en la tabla <code>DIM_BENEFICIARIOS</code> dentro del esquema Transversal, asegurando la integridad y calidad de los datos.</li> <li>Manejar Errores: Redirigir cualquier fila que genere error durante la transformaci\u00f3n a un destino de error para su posterior an\u00e1lisis y depuraci\u00f3n.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso_2","title":"Descripci\u00f3n del Proceso","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Origen de Datos Temporal: Se extraen datos desde la tabla temporal en el \u00e1rea de staging (<code>TMP POBLACION EDUCACION</code>), la cual contiene registros de beneficiarios identificados a partir de procesos previos.</li> <li>Origen de Datos Adicional: Se utiliza el componente \"Estudiantes Colegio\" para obtener informaci\u00f3n complementaria desde la base de datos del colegio, la cual incluye columnas clave como <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Conversi\u00f3n de Datos:  Se aplican dos transformaciones de Data Conversion para convertir los valores de columnas cr\u00edticas (por ejemplo, <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>) al formato y longitud requeridos.  </li> <li>La primera transformaci\u00f3n crea copias de las columnas con la longitud adecuada para facilitar las operaciones de Lookup y Merge.</li> <li> <p>La segunda transformaci\u00f3n, aplicada directamente sobre el flujo de datos extra\u00eddo, garantiza que los datos sean consistentes.</p> </li> <li> <p>Lookup:  Se utiliza una transformaci\u00f3n Lookup para unir los datos del flujo con la tabla de referencia <code>DIM_TIPO_DOCUMENTO</code>. Esta uni\u00f3n permite asignar a cada registro el <code>ID_TIPODOC_AFILIADO</code> y las siglas correspondientes a partir de la columna <code>COD_TIPO_DOCUMENTO</code>, facilitando la identificaci\u00f3n y categorizaci\u00f3n de los beneficiarios.</p> </li> <li> <p>Fusi\u00f3n (Merge):  Las transformaciones Sort y Merge se utilizan para combinar y ordenar los registros provenientes de las diversas fuentes. Este paso asegura que el flujo final de datos est\u00e9 correctamente ordenado y listo para la carga.</p> </li> </ul> </li> <li> <p>Carga de Datos en la Dimensi\u00f3n:</p> <ul> <li> <p>Destino ADO.NET:  Los datos transformados se cargan en la tabla <code>DIM_BENEFICIARIOS</code> ubicada en el esquema Transversal del Data Warehouse. La configuraci\u00f3n del destino ADO.NET permite la inserci\u00f3n masiva, optimizando el rendimiento del proceso.</p> </li> <li> <p>Manejo de Errores:  Se definen salidas de error que capturan cualquier fila que no cumpla con las conversiones o validaciones establecidas, permitiendo que los errores sean redirigidos a un destino espec\u00edfico para su an\u00e1lisis.</p> </li> </ul> </li> <li> <p>Integraci\u00f3n Final:</p> <ul> <li>Los registros actualizados y/o nuevos se integran en la dimensi\u00f3n <code>DIM_BENEFICIARIOS</code>, lo cual facilita la realizaci\u00f3n de an\u00e1lisis sobre la poblaci\u00f3n de beneficiarios y su impacto en las operaciones de la organizaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave-del-proceso_2","title":"Componentes Clave del Proceso","text":"<ol> <li> <p>Destino de ADO NET:    Utiliza un componente ADO.NET para cargar los datos finales en la tabla <code>\"Transversal\".\"DIM_BENEFICIARIOS\"</code>, configurado con propiedades que optimizan la inserci\u00f3n masiva (BatchSize = 0, CommandTimeout = 30, UseBulkInsertWhenPossible = true).</p> </li> <li> <p>Transformaciones de Data Conversion:    Dos transformaciones de Data Conversion se aplican para asegurar que las columnas <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code> tengan el formato correcto para su posterior procesamiento. La primera transformaci\u00f3n trabaja sobre datos combinados, mientras que la segunda opera sobre datos provenientes directamente del origen.</p> </li> <li> <p>Transformaci\u00f3n Lookup:    Realiza la uni\u00f3n entre el flujo de datos y la tabla de referencia <code>DIM_TIPO_DOCUMENTO</code>, permitiendo obtener el <code>ID_TIPODOC_AFILIADO</code> y las siglas de tipo de documento para cada registro.</p> </li> <li> <p>Componentes de Sort y Merge:    Se utilizan para ordenar y combinar registros provenientes de diferentes or\u00edgenes, asegurando que la fusi\u00f3n de datos se realice de forma coherente y ordenada.</p> </li> <li> <p>Origen de ADO NET (TMP POBLACION EDUCACION):    Extrae los datos de la tabla temporal donde se consolidaron previamente los registros de beneficiarios, sirviendo de base para identificar los registros nuevos o faltantes en la dimensi\u00f3n.</p> </li> <li> <p>Destino de Error:    Los errores detectados durante la conversi\u00f3n y transformaci\u00f3n se redirigen a una salida de error, permitiendo su revisi\u00f3n y correcci\u00f3n sin interrumpir el proceso principal.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas_4","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos_2","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant TMP as TMP POBLACION EDUCACION (Origen)\n    participant ADO as Estudiantes Colegio (Origen ADO NET)\n    participant DC as Data Conversion\n    participant DC1 as Data Conversion 1\n    participant Lookup as Lookup\n    participant Sort as Sort\n    participant Sort1 as Sort 1\n    participant Sort2 as Sort 2\n    participant Merge as Merge\n    participant Stage as Destino de ADO NET (DIM_BENEFICIARIOS)\n    participant Error as Salida de error de destino de ADO NET\n\n    TMP-&gt;&gt;DC1: Extrae datos de TMP POBLACION EDUCACION\n    ADO-&gt;&gt;DC: Extrae datos de Estudiantes Colegio\n    DC-&gt;&gt;Lookup: Convierte y formatea columnas (TIPO_DOCUMENTO, DOCUMENTO)\n    DC1-&gt;&gt;Sort1: Convierte datos del origen TMP\n    Sort1-&gt;&gt;Merge: Ordena datos del origen TMP\n    Sort2-&gt;&gt;Merge: Ordena datos de Excel (Poblaci\u00f3n PRS)\n    Merge-&gt;&gt;Lookup: Combina flujos de datos para Lookup\n    Lookup-&gt;&gt;Stage: Carga datos en DIM_BENEFICIARIOS\n    DC-&gt;&gt;Error: Redirige filas con errores</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-precedencia_2","title":"Diagrama de Precedencia","text":"<pre><code>sequenceDiagram\n    participant Origen as TMP POBLACION EDUCACION\n    participant ADO as Estudiantes Colegio\n    participant Conv as Data Conversion\n    participant Look as Lookup\n    participant Merge as Merge\n    participant Destino as Destino de ADO NET (DIM_BENEFICIARIOS)\n\n    Origen-&gt;&gt;Conv: Extraer y convertir datos desde TMP\n    ADO-&gt;&gt;Conv: Extraer datos complementarios desde ADO NET\n    Conv-&gt;&gt;Look: Enviar datos convertidos al Lookup\n    Look-&gt;&gt;Merge: Unir datos con referencia de DIM_TIPO_DOCUMENTO\n    Merge-&gt;&gt;Destino: Cargar registros consolidados en DIM_BENEFICIARIOS</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_beneficiarios-por-bp","title":"Componente <code>Procesar DIM_BENEFICIARIOS por BP</code>","text":"<p>Este flujo de datos de SSIS se encarga de extraer y procesar informaci\u00f3n de la poblaci\u00f3n de matr\u00edcula del Colegio para identificar beneficiarios asociados a un determinado \u201cBP\u201d (Business Partner). El objetivo es detectar registros nuevos que no se encuentren en la dimensi\u00f3n de beneficiarios transversal y, a partir de esa comparaci\u00f3n, enriquecer la informaci\u00f3n utilizando datos de las \u00e1reas de Aportes y Afiliados.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-flujo","title":"Prop\u00f3sito del Flujo","text":"<ul> <li> <p>Identificar Beneficiarios Nuevos:   Se extraen los registros de la poblaci\u00f3n de matr\u00edcula del Colegio y se comparan con la dimensi\u00f3n de beneficiarios existente. Se identifican aquellos registros que a\u00fan no han sido cargados en la dimensi\u00f3n.</p> </li> <li> <p>Integrar Informaci\u00f3n de Aportes:   Se realiza una uni\u00f3n con los datos provenientes de la dimensi\u00f3n de beneficiarios del \u00e1rea de Aportes (DIM_BENEFICIARIOS de Aportes) y la informaci\u00f3n de afiliados para complementar la informaci\u00f3n del beneficiario.</p> </li> <li> <p>Cargar la Dimensi\u00f3n Transversal:   Finalmente, se cargan los registros resultantes en la dimensi\u00f3n de beneficiarios del esquema Transversal, asegurando la actualizaci\u00f3n y consistencia de la informaci\u00f3n.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso_3","title":"Descripci\u00f3n del Proceso","text":"<ol> <li>Extracci\u00f3n de Datos \u2013 Origen DIM POBLACION MATRICULA Colegio:    Se utiliza un componente de origen ADO.NET que ejecuta una consulta SQL con m\u00faltiples CTEs (Common Table Expressions).  <ul> <li>CTE PobMatricula: Extrae la columna <code>PARTNER</code> desde la tabla <code>[DIM_POBLACION_MATRICULA]</code> del Colegio.  </li> <li>CTE Beneficiarios: Extrae todos los registros existentes en la dimensi\u00f3n de beneficiarios transversal.  </li> <li>CTE BenNuevos: Selecciona los registros de la poblaci\u00f3n de matr\u00edcula que no tienen correspondencia en la dimensi\u00f3n de beneficiarios.  </li> <li>CTEs BENEFICIARIOS2 y AFILIADOS: Extraen informaci\u00f3n desde las dimensiones de Aportes y Afiliados, respectivamente, considerando \u00fanicamente registros activos (con <code>ESTADOREGISTRO = 'CURRENT'</code> y condiciones espec\u00edficas en <code>TIPO_APORTANTE</code> y <code>EMPRESA_PRINCIPAL</code>).  </li> <li>CTE LastLookUp: Realiza la uni\u00f3n entre la informaci\u00f3n de Aportes y Afiliados para obtener los registros completos de beneficiarios.</li> </ul> </li> </ol> <p>La consulta final realiza una uni\u00f3n (LEFT JOIN) entre los registros identificados como nuevos y la informaci\u00f3n consolidada en LastLookUp, filtrando aquellos que tengan un <code>ID_BENEFICIARIO</code> v\u00e1lido.</p> <ol> <li> <p>Salida del Origen:    Los datos extra\u00eddos contienen columnas clave como:</p> <ul> <li><code>ID_BENEFICIARIO</code></li> <li><code>PARTNER</code></li> <li><code>TITULAR</code></li> <li><code>ID_TIPO_DOCUMENTO</code></li> <li><code>COD_TIPO_DOCUMENTO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NUMERO_DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>PRIMER_APELLIDO</code></li> <li><code>SEGUNDO_APELLIDO</code></li> <li><code>PRIMER_NOMBRE</code></li> <li><code>SEGUNDO_NOMBRE</code></li> <li><code>ID_PARENTESCO</code></li> <li><code>PARENTESCO</code></li> <li><code>FECHA_AFILIACION</code></li> <li><code>FECHA_RETIRO</code></li> <li><code>ID_GENERO</code></li> <li><code>GENERO</code></li> <li><code>ID_NIVEL_EDUCATIVO</code></li> <li><code>NIVEL_EDUCATIVO</code></li> <li><code>ID_ESTADO_CIVIL</code></li> <li><code>ESTADO_CIVIL</code></li> <li><code>DISCAPACIDAD</code></li> <li><code>FECHA_NACIMIENTO</code></li> <li><code>DIRECCION</code></li> <li><code>TELEFONO</code></li> <li><code>BARRIO</code></li> <li><code>ESTRATO</code></li> <li><code>ID_CIUDAD</code></li> <li><code>ID_AREA_GEOGRAFICA</code></li> <li><code>AREA_GEOGRAFICA</code></li> <li><code>FEC_CREACION</code></li> <li><code>USUARIO_PROCESO</code></li> <li><code>FEC_ACTUALIZACION</code></li> </ul> </li> <li> <p>Carga en la Dimensi\u00f3n \u2013 DIM_BENEFICIARIOS Transversal:    Los datos procesados se env\u00edan al destino ADO.NET configurado para insertar (o actualizar) los registros en la tabla <code>\"Transversal\".\"DIM_BENEFICIARIOS\"</code>. Se utilizan configuraciones que optimizan la inserci\u00f3n masiva (BatchSize = 0, CommandTimeout = 30, UseBulkInsertWhenPossible = true).</p> </li> <li> <p>Manejo de Errores:    Cualquier fila que genere error en el proceso de carga se redirige a una salida de error para su posterior an\u00e1lisis, asegurando que el flujo principal no se detenga por datos inv\u00e1lidos.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos_3","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant Origen as DIM POBLACION MATRICULA Colegio (Origen ADO.NET)\n    participant Transform as Proceso SQL con CTEs (BenNuevos, LastLookUp)\n    participant Salida as Salida de Origen de ADO.NET\n    participant Destino as DIM_BENEFICIARIOS Transversal (Destino ADO.NET)\n    participant Error as Salida de Error de Origen de ADO.NET\n\n    Origen-&gt;&gt;Transform: Ejecuta consulta SQL con CTEs\n    Transform-&gt;&gt;Salida: Devuelve registros nuevos identificados\n    Salida-&gt;&gt;Destino: Carga registros en DIM_BENEFICIARIOS Transversal\n    Salida-&gt;&gt;Error: Redirige filas con errores</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_afiliados","title":"Componente <code>Procesar_DIM_AFILIADOS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_AFILIADOS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_AFILIADOS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_6","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_6","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_AFILIADOS</code></li> <li>DTSID: <code>{UNIQUE-DTSID}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_3","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Afiliados</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_AFILIADOS\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#columnas-de-entrada","title":"Columnas de Entrada","text":"<ul> <li><code>ID_AFILIADO</code></li> <li><code>NOMBRE</code></li> <li><code>APELLIDO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NUMERO_DOCUMENTO</code></li> <li><code>FECHA_NACIMIENTO</code></li> <li><code>GENERO</code></li> <li><code>ESTADO_CIVIL</code></li> <li><code>DIRECCION</code></li> <li><code>CIUDAD</code></li> <li><code>TELEFONO</code></li> <li><code>EMAIL</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_7","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_AFILIADOS\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Convertir datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_AFILIADO_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_AFILIADOS`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Modificar`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_AFILIADOS`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Sheet1$</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>CommandTimeout</code>: <code>0</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Verifica y convierte los tipos de datos de las columnas de entrada.</li> </ul> </li> <li> <p>Columna Derivada (<code>Crear ID_AFILIADO_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_AFILIADO_AUXILIAR</code> concatenando varias columnas de entrada.</li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_AFILIADOS</code> para unir columnas adicionales al flujo de datos.</li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> </ul> </li> <li> <p>Destino ADO.NET (<code>DIM_AFILIADOS_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_AFILIADOS</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_AFILIADOS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_afiliados","title":"Componente <code>Procesar DIM_AFILIADOS</code>","text":"<p>Corresponde a un flujo de datos dentro del paquete SSIS dise\u00f1ado para procesar la dimensi\u00f3n de afiliados. El flujo extrae informaci\u00f3n relevante desde una fuente de datos en la zona de staging (TMP POBLACION EDUCACION) y la transforma para finalmente cargarla en la tabla destino <code>\"Transversal\".\"DIM_AFILIADOS\"</code> en el Data Warehouse de destino.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-principales","title":"Componentes Principales","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-componente-origen-tmp-poblacion-educacion","title":"1. Componente Origen: TMP POBLACION EDUCACION","text":"<ul> <li>Funci\u00f3n:   Utiliza un adaptador DataReader para conectarse a la base de datos de staging (STAGE_AREA) y ejecutar una consulta SQL compleja que utiliza m\u00faltiples CTEs (Common Table Expressions).  </li> <li> <p>Proceso de la Consulta: </p> <ul> <li>PobEducacion: Extrae datos de la tabla temporal <code>[TMP_POBLACION_EDUCACION]</code>, seleccionando columnas como <code>TIPO_DOCUMENTO_SIGLAS</code>, <code>DOCUMENTO</code> y <code>ID_TIPO_DOCUMENTO</code>.  </li> <li>AFILIADOS: Obtiene la informaci\u00f3n actual de afiliados desde la dimensi\u00f3n <code>[DIM_AFILIADOS]</code> del esquema Transversal, filtrando por registros con <code>ESTADOREGISTRO = 'CURRENT'</code> y que tengan <code>EMPRESA_PRINCIPAL = 'X'</code>.  </li> <li>afiliadoNuevos: Identifica registros nuevos comparando la informaci\u00f3n extra\u00edda de la zona de staging con la existente en <code>[DIM_AFILIADOS]</code>, utilizando una operaci\u00f3n LEFT JOIN.  </li> <li>EMPRESASCaja y AFILIADOSCaja: Se extrae informaci\u00f3n desde las dimensiones de Aportes para relacionar a los afiliados con las empresas correspondientes.  </li> <li>AFILIADOS_CON_EMPRESA y AfiliadosCajaIdEmpresa: Se realiza una uni\u00f3n y se selecciona la \u00faltima coincidencia (utilizando ROW_NUMBER) para garantizar que cada afiliado quede asociado a un \u00fanico <code>ID_EMPRESA</code>.</li> <li>Consulta Final:   Se efect\u00faa un LEFT JOIN entre los registros nuevos (<code>afiliadoNuevos</code>) y la informaci\u00f3n consolidada de afiliados con empresa (<code>AfiliadosCajaIdEmpresa</code>), filtrando aquellos registros que tienen un <code>ID_AFILIADO</code> v\u00e1lido.</li> </ul> </li> <li> <p>Conexi\u00f3n:   Se utiliza un administrador de conexiones externo apuntando al ambiente <code>STAGE_AREA</code>.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-componente-destino-destino-de-ado-net","title":"2. Componente Destino: Destino de ADO NET","text":"<ul> <li>Funci\u00f3n:   Este componente carga los datos procesados en la tabla destino <code>\"Transversal\".\"DIM_AFILIADOS\"</code> del Data Warehouse.</li> <li>Configuraci\u00f3n Clave: <ul> <li>TableOrViewName: <code>\"Transversal\".\"DIM_AFILIADOS\"</code> </li> <li>BatchSize: 0 (utiliza el tama\u00f1o del b\u00fafer interno de SSIS)  </li> <li>CommandTimeout: 30 segundos  </li> <li>UseBulkInsertWhenPossible: true (mejora el rendimiento al usar inserci\u00f3n masiva)</li> </ul> </li> <li>Conexi\u00f3n:   Se conecta a trav\u00e9s de un administrador de conexiones configurado con <code>DWH_COMFENALCO_Destino</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-flujo-de-conexion","title":"3. Flujo de Conexi\u00f3n","text":"<p>El flujo conecta el origen (TMP POBLACION EDUCACION) con el destino (DIM_AFILIADOS Transversal) mediante una ruta de datos:</p> <pre><code>sequenceDiagram\n    participant Origen as TMP POBLACION EDUCACION (Origen ADO.NET)\n    participant Destino as DIM_AFILIADOS Transversal (Destino ADO.NET)\n\n    Origen -&gt;&gt; Destino: Transfiere datos procesados para cargar en la dimensi\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proceso-general","title":"Proceso General","text":"<ol> <li> <p>Extracci\u00f3n de Datos:    La consulta SQL del componente origen ejecuta m\u00faltiples CTEs para:</p> <ul> <li>Extraer datos de la zona de staging.</li> <li>Comparar y detectar registros nuevos de afiliados.</li> <li>Relacionar la informaci\u00f3n con datos de empresas y afiliados desde \u00e1reas de aportes.</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:     Los registros nuevos son identificados a partir de la ausencia de coincidencias en la dimensi\u00f3n actual. Se aplican transformaciones y validaciones impl\u00edcitas para asegurar la calidad de los datos.</p> </li> <li> <p>Carga de Datos:     Los datos resultantes se env\u00edan al componente destino, que inserta la informaci\u00f3n en la tabla <code>\"Transversal\".\"DIM_AFILIADOS\"</code>, utilizando configuraciones optimizadas para cargas masivas.</p> </li> <li> <p>Manejo de Errores:     Cualquier fila que genere error en la extracci\u00f3n o transformaci\u00f3n se redirige a una salida de error, permitiendo el an\u00e1lisis y correcci\u00f3n sin detener el flujo principal.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#procesar-dim-afiliados-desde-beneficiarios","title":"Procesar <code>DIM AFILIADOS desde BENEFICIARIOS</code>","text":"<p>Este nodo un Data Flow Task dentro del paquete SSIS, cuyo objetivo es procesar y actualizar la dimensi\u00f3n de afiliados a partir de datos provenientes de beneficiarios. Los datos se extraen a trav\u00e9s de una consulta SQL compleja que utiliza varias CTEs para identificar los registros de beneficiarios que a\u00fan no se encuentran en la dimensi\u00f3n de afiliados y, posteriormente, se cargan en la tabla destino <code>\"Transversal\".\"DIM_AFILIADOS\"</code>.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave","title":"Componentes Clave","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-origen-transversal_dim_beneficiarios","title":"1. Origen: TRANSVERSAL_DIM_BENEFICIARIOS","text":"<ul> <li>Funci\u00f3n:   Este componente extrae datos usando un adaptador ADO.NET (DataReaderSource) que ejecuta una consulta SQL.  </li> <li> <p>Consulta SQL:     La consulta utiliza varias CTEs para:</p> <ul> <li>Seleccionar los <code>ID_AFILIADO</code> \u00fanicos de la tabla <code>[DIM_BENEFICIARIOS]</code> en el esquema Transversal.</li> <li>Compararlos con los <code>ID_AFILIADO</code> ya presentes en la tabla <code>[DIM_AFILIADOS]</code> del mismo esquema.</li> <li>Identificar los registros que est\u00e1n en beneficiarios pero faltan en la dimensi\u00f3n de afiliados.</li> <li>Adem\u00e1s, se unen con las dimensiones de empresas y se filtran por registros actuales (por ejemplo, donde <code>[ESTADOREGISTRO] = 'CURRENT'</code>) y por la condici\u00f3n de empresa principal.</li> <li>Se asigna un n\u00famero de fila (rn) para seleccionar el registro final por cada afiliado.</li> </ul> </li> <li> <p>Conexi\u00f3n:   Utiliza el administrador de conexiones configurado con <code>DWH_COMFENALCO_Destino</code>.</p> </li> <li> <p>Salida:   La salida (Salida de origen de ADO NET) expone columnas relevantes, incluyendo:</p> <ul> <li><code>ID_AFILIADO</code></li> <li><code>PARTNER</code></li> <li><code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code></li> <li><code>NUMERO_DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code></li> <li>Y otros campos relacionados con la afiliaci\u00f3n, caracter\u00edsticas demogr\u00e1ficas, estado civil, ocupaci\u00f3n, entre otros.</li> </ul> </li> </ul> <p>Adem\u00e1s, se genera la columna <code>rn</code> para identificar el registro principal en caso de m\u00faltiples coincidencias.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-destino-destino-de-ado-net","title":"2. Destino: Destino de ADO NET","text":"<ul> <li>Funci\u00f3n:   Este componente se encarga de cargar los datos procesados en la tabla destino <code>\"Transversal\".\"DIM_AFILIADOS\"</code>.</li> <li>Configuraci\u00f3n Importante: <ul> <li>TableOrViewName: <code>\"Transversal\".\"DIM_AFILIADOS\"</code></li> <li>BatchSize: 0 (lo que indica que se usar\u00e1 el tama\u00f1o del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true (habilita la inserci\u00f3n masiva para mejorar el rendimiento)</li> </ul> </li> <li>Conexi\u00f3n:   Se conecta a trav\u00e9s del administrador de conexiones <code>DWH_COMFENALCO_Destino</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-flujo-de-datos","title":"3. Flujo de Datos","text":"<p>El flujo de datos conecta la salida del componente de origen (TRANSVERSAL_DIM_BENEFICIARIOS) con la entrada del componente destino (Destino de ADO NET). Esto garantiza que los registros identificados se transfieran y se inserten en la tabla de afiliados.</p> <pre><code>sequenceDiagram\n    participant Origen as TRANSVERSAL_DIM_BENEFICIARIOS (Salida de origen de ADO NET)\n    participant Destino as Destino de ADO NET (Entrada de destino de ADO NET)\n\n    Origen -&gt;&gt; Destino: Transfiere los datos para actualizar DIM_AFILIADOS</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proceso-general_1","title":"Proceso General","text":"<ol> <li> <p>Extracci\u00f3n: </p> <ul> <li>La consulta SQL del componente origen extrae los <code>ID_AFILIADO</code> de la dimensi\u00f3n de beneficiarios que no se encuentran en la dimensi\u00f3n de afiliados.</li> <li>Se realizan uniones y se filtra la informaci\u00f3n para garantizar la calidad de los datos (por ejemplo, considerando solo registros actuales y los de empresa principal).</li> </ul> </li> <li> <p>Transformaci\u00f3n: </p> <ul> <li>Se realiza la asignaci\u00f3n de un n\u00famero de fila (<code>rn</code>) para seleccionar el registro final en caso de m\u00faltiples coincidencias para un mismo afiliado.</li> <li>La consulta prepara los datos para ser consistentes con el esquema de la tabla destino, convirtiendo tipos de datos y asegurando la integridad de la informaci\u00f3n.</li> </ul> </li> <li> <p>Carga: </p> <ul> <li>El componente destino recibe los datos y los inserta en la tabla <code>\"Transversal\".\"DIM_AFILIADOS\"</code>, utilizando Bulk Insert cuando sea posible para mejorar el rendimiento.</li> <li>En caso de errores, los registros problem\u00e1ticos se redirigen a una salida de  error, permitiendo el an\u00e1lisis posterior sin detener el flujo completo.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_empresas","title":"Componente <code>Procesar DIM_EMPRESAS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_EMPRESAS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_EMPRESAS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_7","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_7","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_EMPRESAS</code></li> <li>DTSID: <code>{DTSID_DEL_COMPONENTE}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_4","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Empresas</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino_1","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_EMPRESAS\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_8","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_EMPRESAS\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Verificar tipos de datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_EMPRESA_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_EMPRESAS`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Modificar`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_EMPRESAS`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_empresas-desde-afiliados","title":"Componente <code>Procesar DIM_EMPRESAS desde AFILIADOS</code>","text":"<p>Flujo de datos (Data Flow Task) dentro del paquete SSIS cuyo objetivo es procesar informaci\u00f3n relacionada con empresas a partir de datos provenientes de afiliados. La informaci\u00f3n se extrae de una fuente (un componente de origen basado en ADO.NET que ejecuta una consulta SQL) y se carga en la tabla destino <code>\"Transversal\".\"DIM_EMPRESAS\"</code> en el Data Warehouse de destino.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave_1","title":"Componentes Clave","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-origen-transversal-dim-afiliados","title":"1. Origen: TRANSVERSAL DIM AFILIADOS","text":"<ul> <li>Funci\u00f3n:   Este componente extrae datos utilizando un adaptador ADO.NET (DataReaderSource) que ejecuta una consulta SQL.  </li> <li> <p>Consulta SQL:     La consulta utiliza CTEs (Common Table Expressions) para:</p> <ul> <li>Seleccionar de la dimensi\u00f3n de afiliados (<code>[DIM_AFILIADOS]</code>) del esquema Transversal.</li> <li>Identificar los <code>ID_EMPRESA</code> que est\u00e1n presentes en la dimensi\u00f3n de afiliados pero que no se encuentran en la dimensi\u00f3n de empresas actual (<code>[DIM_EMPRESAS]</code>).</li> <li>Luego, se hace un LEFT JOIN con la tabla <code>[DIM_EMPRESAS]</code> del esquema Aportes, filtrando registros actuales (<code>ESTADOREGISTRO = 'CURRENT'</code>).</li> </ul> </li> <li> <p>Conexi\u00f3n:   Se utiliza un administrador de conexiones configurado con <code>DWH_COMFENALCO_Destino</code>.</p> </li> <li> <p>Salida:   El componente expone una salida de datos (Salida de origen de ADO NET) con columnas relevantes como <code>ID_EMPRESA</code>, <code>PARTNER</code>, <code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>RAZON_SOCIAL</code>, <code>ID_ESTADO</code>, <code>ESTADO</code>, entre otras, que se utilizar\u00e1n en la carga final.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-destino-destino-de-ado-net_1","title":"2. Destino: Destino de ADO NET","text":"<ul> <li>Funci\u00f3n:   Este componente carga los datos procesados en la tabla destino <code>\"Transversal\".\"DIM_EMPRESAS\"</code>.  </li> <li> <p>Configuraci\u00f3n Importante: </p> <ul> <li>TableOrViewName: <code>\"Transversal\".\"DIM_EMPRESAS\"</code></li> <li>BatchSize: 0 (utiliza el tama\u00f1o del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true (habilita la inserci\u00f3n masiva para mejorar el rendimiento)</li> </ul> </li> <li> <p>Conexi\u00f3n:   Utiliza el administrador de conexiones <code>DWH_COMFENALCO_Destino</code>.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-flujo-de-datos_1","title":"3. Flujo de Datos","text":"<p>El flujo de datos conecta la salida del componente de origen (TRANSVERSAL DIM AFILIADOS) con la entrada del componente destino (Destino de ADO NET), de manera que los datos extra\u00eddos y transformados se inserten en la tabla <code>\"Transversal\".\"DIM_EMPRESAS\"</code>.</p> <pre><code>sequenceDiagram\n    participant Origen as TRANSVERSAL DIM AFILIADOS (Salida de origen de ADO NET)\n    participant Destino as Destino de ADO NET (Entrada de destino de ADO NET)\n\n    Origen -&gt;&gt; Destino: Transfiere los datos para cargar en DIM_EMPRESAS</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proceso-general_2","title":"Proceso General","text":"<ol> <li> <p>Extracci\u00f3n: </p> <ul> <li>Se ejecuta la consulta SQL del componente origen que identifica los <code>ID_EMPRESA</code> presentes en la dimensi\u00f3n de afiliados y que a\u00fan no existen en la dimensi\u00f3n de empresas.  </li> <li>La consulta se apoya en CTEs para estructurar y filtrar los datos, garantizando que s\u00f3lo se seleccionen empresas relevantes que deben ser cargadas.</li> </ul> </li> <li> <p>Transformaci\u00f3n: </p> <ul> <li>Los datos extra\u00eddos se transforman impl\u00edcitamente a trav\u00e9s de la configuraci\u00f3n del flujo, garantizando la correcta conversi\u00f3n de tipos (por ejemplo, cadenas, enteros y marcas de tiempo).</li> </ul> </li> <li> <p>Carga: </p> <ul> <li>El componente destino recibe los datos y los inserta en la tabla <code>\"Transversal\".\"DIM_EMPRESAS\"</code>.  </li> <li>La opci\u00f3n de Bulk Insert est\u00e1 activada para optimizar el rendimiento de la carga masiva.</li> </ul> </li> <li> <p>Manejo de Errores: </p> <ul> <li>Cualquier error durante la carga se redirige a una salida de error (Salida de error de destino de ADO NET), lo que permite analizar y corregir problemas sin detener el flujo completo.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_aportante_no_afiliado","title":"Componente <code>Procesar_DIM_APORTANTE_NO_AFILIADO</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_APORTANTE_NO_AFILIADO</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_APORTANTE_NO_AFILIADO</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_8","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_8","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_APORTANTE_NO_AFILIADO</code></li> <li>DTSID: <code>{DTSID_DEL_COMPONENTE}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_5","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Aportante</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino_2","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_APORTANTE_NO_AFILIADO\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#columnas-de-entrada_1","title":"Columnas de Entrada","text":"<ul> <li><code>ID_APORTANTE</code></li> <li><code>NOMBRE_APORTANTE</code></li> <li><code>TIPO_APORTANTE</code></li> <li><code>FECHA_REGISTRO</code></li> <li><code>ESTADO</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_9","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_APORTANTE_NO_AFILIADO\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Convertir datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_APORTANTE_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_APORTANTE_NO_AFILIADO`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Modificar`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_APORTANTE_NO_AFILIADO`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Sheet1$</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>CommandTimeout</code>: <code>0</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> </ul> </li> <li> <p>Columna Derivada (<code>Crear_ID_APORTANTE_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_APORTANTE_AUXILIAR</code> concatenando varias columnas de entrada.</li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_APORTANTE_NO_AFILIADO</code> para unir columnas adicionales al flujo de datos.</li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> </ul> </li> <li> <p>Destino ADO.NET (<code>DIM_APORTANTE_NO_AFILIADO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_APORTANTE_NO_AFILIADO</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_APORTANTE_NO_AFILIADO\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-descargar_ep-tra-05","title":"Componente <code>Descargar_EP-TRA-05</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_EP-TRA-05</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script de Python para descargar archivos desde SharePoint. Este componente utiliza la tarea <code>Execute Process</code> para ejecutar el script.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_9","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_9","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Descargar_EP-TRA-05</code></li> <li>DTSID: <code>{769c3094-28c7-44e9-9e36-9e9bc371b279}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar proceso</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteProcess</code></li> <li>TaskContact: <code>Execute Process Task;Microsoft Corporation; SQL Server 2022; \u00a9 2022 Microsoft Corporation; All Rights Reserved;http://www.microsoft.com/sql/support/default.asp;1</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-proceso","title":"Propiedades del Proceso","text":"<ul> <li>Executable: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> <li>Arguments: <code>04.SharePoint_Connection_EP-TRA-05.py</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso","title":"Diagrama de Secuencia del Proceso","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso - Descargar_EP-TRA-05\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Python as Script de Python\n    participant SharePoint as Servidor SharePoint\n\n    SSIS-&gt;&gt;Python: Ejecutar script `04.SharePoint_Connection_EP-TRA-05.py`\n    Python--&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Python: Confirmar conexi\u00f3n\n    Python-&gt;&gt;SharePoint: Descargar archivos\n    SharePoint--&gt;&gt;Python: Retornar archivos descargados\n    Python--&gt;&gt;SSIS: Confirmar finalizaci\u00f3n del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-proceso","title":"Componentes del Proceso","text":"<ol> <li> <p>Tarea Ejecutar Proceso (<code>Descargar_EP-TRA-05</code>)</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python para descargar archivos desde SharePoint.</li> <li>Propiedades:<ul> <li><code>Executable</code>: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li><code>WorkingDirectory</code>: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> <li><code>Arguments</code>: <code>04.SharePoint_Connection_EP-TRA-05.py</code></li> </ul> </li> </ul> </li> <li> <p>Script de Python (<code>04.SharePoint_Connection_EP-TRA-05.py</code>)</p> <ul> <li>Descripci\u00f3n: Script que se conecta a SharePoint y descarga los archivos necesarios.</li> </ul> </li> <li> <p>Servidor SharePoint</p> <ul> <li>Descripci\u00f3n: Servidor desde el cual se descargan los archivos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_personal","title":"Componente <code>Procesar_DIM_PERSONAL</code>","text":"<p>Este Data Flow Task dentro del paquete SSIS est\u00e1 dise\u00f1ado para procesar la dimensi\u00f3n del personal. El flujo de datos extrae informaci\u00f3n de una fuente Excel, la transforma a trav\u00e9s de conversiones y derivaciones, y la enriquece mediante una operaci\u00f3n de b\u00fasqueda (Lookup), para finalmente cargar los datos transformados en la tabla destino <code>\"Transversal\".\"DIM_PERSONAL\"</code>.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-principales_1","title":"Componentes Principales","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-excel-source-leer-ep-tra-05","title":"1. Excel Source \u2013 Leer EP-TRA-05","text":"<ul> <li>Funci\u00f3n:   Extrae datos desde un archivo Excel (hoja \"Sheet1$\").  </li> <li>Columnas Extra\u00eddas:   Incluye columnas como <code>COD_PERSONA_UNIDAD</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>NOMBRE</code>, <code>TELEFONO</code>, <code>CELULAR</code>, <code>CORREO</code>, <code>DIRECCION</code>, <code>CIUDAD</code>, <code>FECHA_NACIMIENTO</code>, <code>GENERO</code>, <code>ID_UNIDAD</code>, <code>SERVICIO</code>, <code>AREA</code>, <code>TIPO_CONTRATACION</code>, <code>FECHA_INICIO_CONTRATACION</code>, <code>FECHA_FIN_CONTRATACION</code>, entre otras.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-data-conversion","title":"2. Data Conversion","text":"<ul> <li>Funci\u00f3n:   Convierte los datos extra\u00eddos del Excel a los tipos requeridos para las siguientes transformaciones.  </li> <li>Ejemplos de Conversiones: </li> <li>Convierte cadenas de texto a cadenas con longitudes ajustadas (por ejemplo, <code>COD_PERSONA_UNIDAD</code> a 40 caracteres).  </li> <li>Convierte fechas almacenadas como cadenas a tipo <code>date</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-crear-id_personal_auxiliar-derived-column","title":"3. Crear ID_PERSONAL_AUXILIAR (Derived Column)","text":"<ul> <li>Funci\u00f3n:   Crea una columna derivada denominada <code>ID_PERSONAL_AUXILIAR</code>.  </li> <li>L\u00f3gica de la Expresi\u00f3n:   Concatena la columna <code>COD_PERSONA_UNIDAD</code> y <code>ID_UNIDAD</code>, separadas por un guion bajo, para formar un identificador \u00fanico que se utilizar\u00e1 en la comparaci\u00f3n y enriquecimiento posterior.</li> </ul> <p>Expresi\u00f3n: <code>COD_PERSONA_UNIDAD + \"_\" + (DT_WSTR,10)ID_UNIDAD</code></p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#4-lookup","title":"4. Lookup","text":"<ul> <li>Funci\u00f3n:   Realiza una b\u00fasqueda en la tabla de referencia <code>[Transversal].[DIM_PERSONAL]</code> para obtener columnas adicionales, en este caso, para obtener el campo <code>ID_PERSONAL_AUXILIAR</code>.  </li> <li>Consulta SQL de Referencia: <pre><code>SELECT \n    [COD_PERSONA_UNIDAD],\n    [ID_UNIDAD],\n    [COD_PERSONA_UNIDAD] + '_' + CAST([ID_UNIDAD] AS NVARCHAR(10)) AS [ID_PERSONAL_AUXILIAR]\nFROM \n    [Transversal].[DIM_PERSONAL];\n</code></pre></li> <li>Par\u00e1metro de Uni\u00f3n:   Se utiliza el resultado generado en el componente derivado (<code>ID_PERSONAL_AUXILIAR</code>) para comparar con la columna correspondiente del conjunto de referencia.  </li> <li>Salidas del Lookup: </li> <li>Lookup Match Output: Registros donde se encuentra la coincidencia en la referencia.  </li> <li>Lookup No Match Output: Registros sin coincidencia (en este flujo, estos datos se redirigen para la evaluaci\u00f3n en el Conditional Split).</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#5-conditional-split","title":"5. Conditional Split","text":"<ul> <li>Funci\u00f3n:   Divide el flujo de datos en dos rutas bas\u00e1ndose en una condici\u00f3n.</li> <li>Condici\u00f3n Especificada (\"Agregar\"):   La condici\u00f3n eval\u00faa si el valor de <code>ID_PERSONAL_AUXILIAR</code> obtenido del Lookup es nulo y si el campo <code>Copy of DOCUMENTO</code> (resultado del Data Conversion) no es nulo: <p>Expresi\u00f3n (versi\u00f3n con nombres de columna): <code>ISNULL(Lookup.ID_PERSONAL_AUXILIAR) &amp;&amp; !ISNULL([Copy of DOCUMENTO])</code></p> </li> <li>Salidas: </li> <li>Agregar: Registros que cumplen la condici\u00f3n y que, por lo tanto, deben ser tratados como nuevos registros para agregarlos a la dimensi\u00f3n.</li> <li>Sin Cambios (Default): Registros que no cumplen la condici\u00f3n de agregaci\u00f3n.</li> <li>Conditional Split Error Output: Manejo de errores.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#6-destino-de-ado-net","title":"6. Destino de ADO NET","text":"<ul> <li>Funci\u00f3n:   Carga los datos transformados y filtrados en la tabla destino <code>\"Transversal\".\"DIM_PERSONAL\"</code>.</li> <li>Configuraci\u00f3n Clave: </li> <li>TableOrViewName: <code>\"Transversal\".\"DIM_PERSONAL\"</code> </li> <li>BatchSize: 0 (usa el tama\u00f1o del b\u00fafer interno de SSIS)  </li> <li>CommandTimeout: 30 segundos  </li> <li>UseBulkInsertWhenPossible: true (para mejorar el rendimiento en inserciones masivas)  </li> <li>Conexi\u00f3n:   Utiliza un administrador de conexiones configurado (<code>DWH_COMFENALCO_Destino</code>).</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#flujo-general-del-proceso","title":"Flujo General del Proceso","text":"<ol> <li> <p>Extracci\u00f3n de Datos:    Los datos se leen desde un archivo Excel mediante el componente Excel Source.</p> </li> <li> <p>Conversi\u00f3n y Transformaci\u00f3n:    Se aplican conversiones de datos (Data Conversion) y se crea un identificador \u00fanico (<code>ID_PERSONAL_AUXILIAR</code>) mediante el componente Derived Column.</p> </li> <li> <p>Enriquecimiento con Lookup:    El componente Lookup compara el <code>ID_PERSONAL_AUXILIAR</code> generado con la referencia de la dimensi\u00f3n existente para identificar registros nuevos o sin cambios.</p> </li> <li> <p>Divisi\u00f3n Condicional:    Mediante el Conditional Split, se enrutan los registros a la salida \"Agregar\" para aquellos registros nuevos (donde no se encontr\u00f3 coincidencia en la tabla de referencia) y \"Sin Cambios\" para los registros ya existentes.</p> </li> <li> <p>Carga de Datos:    Finalmente, los registros identificados para agregaci\u00f3n se cargan en la tabla <code>\"Transversal\".\"DIM_PERSONAL\"</code> a trav\u00e9s del componente de destino ADO.NET.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/","title":"02. TRANSVERSAL_FACT","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#transversal_fact","title":"TRANSVERSAL_FACT","text":"<p>El paquete SSIS \"02-TRANSVERSAL_FACT\" est\u00e1 dise\u00f1ado para procesar y consolidar datos financieros, educativos y operativos relacionados con diversas \u00e1reas estrat\u00e9gicas. Este paquete facilita la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos, asegurando que se integren de manera efectiva en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es gestionar datos transversales cr\u00edticos, desde detalles contables y presupuestarios hasta encuestas y convenios. Este paquete asegura que los datos cargados en el Data Warehouse est\u00e9n preparados para an\u00e1lisis estrat\u00e9gicos, garantizando calidad, consistencia y precisi\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>FACT_DETALLE_CONTABLE</code></li> <li><code>FACT_PRESUPUESTO</code></li> <li><code>FACT_ENCUESTAS_PSR</code></li> <li><code>FACT_CONVENIOS</code></li> <li><code>FACT_INICIATIVAS</code></li> <li>Archivos Excel y CSV:</li> <li>Encuestas, PQRS, y otros registros de entrada.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB para acceso eficiente.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaciones (<code>Lookup</code>):<ul> <li>Garantiza la consistencia comparando con tablas maestras (<code>DIM_TIEMPO</code>, <code>DIM_AFILIADOS</code>, <code>DIM_EMPRESAS</code>).</li> </ul> </li> <li>Divisi\u00f3n Condicional (<code>Conditional Split</code>):<ul> <li>Clasifica registros en v\u00e1lidos y no v\u00e1lidos seg\u00fan criterios espec\u00edficos.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con el destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Genera claves auxiliares y valores predeterminados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas destino:<ul> <li><code>FACT_DETALLE_CONTABLE</code></li> <li><code>FACT_PRESUPUESTO</code></li> <li><code>FACT_ENCUESTAS_PSR</code></li> <li><code>FACT_CONVENIOS</code></li> <li><code>FACT_INICIATIVAS</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python para automatizar tareas relacionadas con conexiones a SharePoint y procesamiento din\u00e1mico de datos.</li> </ul> </li> <li> <p>Mantenimiento de Restricciones:</p> <ul> <li>Restauraci\u00f3n din\u00e1mica de llaves for\u00e1neas utilizando SQL din\u00e1mico para mantener integridad referencial.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>FACT_DETALLE_CONTABLE:</p> <ul> <li><code>ID_CEBE</code>, <code>ID_CUENTA</code>, <code>ID_FECHA</code>, <code>IMPORTE</code>, <code>GASTOS</code>, <code>ACTIVO</code>, <code>PASIVO</code>, entre otros.</li> </ul> </li> <li> <p>FACT_PRESUPUESTO:</p> <ul> <li><code>ID_CEBE</code>, <code>ID_FECHA</code>, <code>ID_TIPO_PRESUPUESTO</code>, <code>SEGMENT</code>, <code>VALOR</code>, <code>GASTOS</code>, <code>COSTOS</code>.</li> </ul> </li> <li> <p>FACT_ENCUESTAS_PSR:</p> <ul> <li><code>ID_FECHA</code>, <code>ID_EMPRESA</code>, <code>ID_BENEFICIARIO</code>, <code>DOCUMENTO</code>, <code>CALIFICACION</code>.</li> </ul> </li> <li> <p>FACT_CONVENIOS:</p> <ul> <li><code>ID_FECHA</code>, <code>NOMBRE_CONVENIO</code>, <code>VALOR_CONVENIO</code>, <code>ID_PROGRAMA</code>, <code>ID_UNIDAD</code>.</li> </ul> </li> <li> <p>FACT_INICIATIVAS:</p> <ul> <li><code>ID_INICIATIVA</code>, <code>ID_FECHA</code>, <code>NOMBRE_INICIATIVA</code>, <code>DESCRIPCION_INICIATIVA</code>, <code>OBSERVACIONES</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel y CSV\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de tablas maestras y transaccionales\n    SSIS -&gt;&gt; Excel: Leer datos de encuestas y PQRS\n    SSIS -&gt;&gt; Python: Ejecutar scripts de automatizaci\u00f3n\n    SSIS -&gt;&gt; DWH: Cargar datos procesados en tablas destino</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#2-diagrama-de-transformaciones-y-validaciones","title":"2. Diagrama de Transformaciones y Validaciones","text":"<pre><code>graph TD\n    A1[Fuente de Datos] --&gt; T1[Conversi\u00f3n de Datos]\n    A2[Tablas Maestras] --&gt; T2[Validaci\u00f3n mediante Lookup]\n    T1 --&gt; C1[Divisi\u00f3n por Condicional Split]\n    T2 --&gt; L1[Agregar Columnas Derivadas]\n    C1 --&gt; C2[Cargar datos transformados]</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#3-diagrama-er-para-tablas-de-hechos","title":"3. Diagrama ER para Tablas de Hechos","text":"<pre><code>erDiagram\n    FACT_DETALLE_CONTABLE {\n        int ID_CEBE\n        int ID_CUENTA\n        int ID_FECHA\n        float IMPORTE\n    }\n    FACT_PRESUPUESTO {\n        int ID_CEBE\n        int ID_FECHA\n        int ID_TIPO_PRESUPUESTO\n        float VALOR\n    }\n    FACT_ENCUESTAS_PSR {\n        int ID_FECHA\n        int ID_EMPRESA\n        int ID_BENEFICIARIO\n        string DOCUMENTO\n    }\n    FACT_CONVENIOS {\n        int ID_FECHA\n        string NOMBRE_CONVENIO\n        float VALOR_CONVENIO\n    }\n    FACT_INICIATIVAS {\n        int ID_INICIATIVA\n        int ID_FECHA\n        string NOMBRE_INICIATIVA\n    }\n    FACT_DETALLE_CONTABLE ||--|| FACT_PRESUPUESTO : \"Relaci\u00f3n Financiera\"\n    FACT_PRESUPUESTO ||--|| FACT_CONVENIOS : \"Conexi\u00f3n por Programas\"\n    FACT_ENCUESTAS_PSR ||--|| FACT_INICIATIVAS : \"An\u00e1lisis de Impacto\"</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-ejecucion-etl-c4c_sharepoint","title":"Componente <code>Ejecuci\u00f3n ETL C4C_SharePoint</code>","text":"<p>Este componente es una tarea de proceso (Execute Process Task) dentro del paquete SSIS, dise\u00f1ado para automatizar la ejecuci\u00f3n de un script Python que extrae y procesa datos desde SharePoint, espec\u00edficamente para la integraci\u00f3n con la soluci\u00f3n C4C. La tarea se configura din\u00e1micamente mediante expresiones de proyecto, lo que permite adaptar el ejecutable y el directorio de trabajo a diferentes entornos (por ejemplo, desarrollo, pruebas y producci\u00f3n).</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>c4c_from_sharepoint.py</code> que se encarga de conectarse a SharePoint para descargar y procesar datos relacionados con la soluci\u00f3n C4C.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar de manera automatizada la extracci\u00f3n de datos de SharePoint dentro del flujo de trabajo ETL de la soluci\u00f3n SSIS, facilitando la consolidaci\u00f3n y actualizaci\u00f3n de la informaci\u00f3n en el Data Warehouse.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute Process Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>Executable:   Se utiliza una expresi\u00f3n de propiedad para definir din\u00e1micamente la ruta del ejecutable de Python:   <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory:   La ruta de trabajo se define tambi\u00e9n de forma din\u00e1mica, estableciendo el directorio base donde se encuentra el script:   <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments:   El script a ejecutar es:   <pre><code>c4c_from_sharepoint.py\n</code></pre></li> </ul> </li> <li> <p>Datos del Objeto:</p> </li> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso sigue los siguientes pasos:</p> <ol> <li> <p>Inicio de la Tarea:    El paquete SSIS inicia la tarea de ejecuci\u00f3n de proceso.</p> </li> <li> <p>Ejecuci\u00f3n del Script Python:    Se ejecuta el ejecutable de Python con el argumento <code>c4c_from_sharepoint.py</code> en el directorio especificado. El script se conecta a SharePoint para realizar las operaciones de extracci\u00f3n y procesamiento de datos.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Una vez finalizada la ejecuci\u00f3n del script, la tarea devuelve el c\u00f3digo de retorno y el flujo ETL contin\u00faa con las siguientes operaciones definidas en el paquete.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant PythonScript as c4c_from_sharepoint.py\n\n    SSIS -&gt;&gt; ExecProcess: Inicia Ejecuci\u00f3n ETL C4C_SharePoint\n    ExecProcess -&gt;&gt; PythonScript: Ejecuta script de Python\n    PythonScript --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza la tarea ETL</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-ejecucion-etls","title":"Componente <code>Ejecuci\u00f3n ETLs</code>","text":"<p>Tarea de proceso (Execute Process Task) dentro del paquete SSIS, dise\u00f1ada para ejecutar un script Python que se encarga de establecer la conexi\u00f3n con SharePoint desde el entorno Transversal. El prop\u00f3sito es automatizar la extracci\u00f3n y el procesamiento de datos desde SharePoint, integr\u00e1ndolos en el flujo ETL global del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_1","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Conexi\u00f3n y Extracci\u00f3n de Datos desde SharePoint:   Ejecutar el script <code>05.SharePoint_Connection_Transversal.py</code> que establece la conexi\u00f3n a SharePoint para extraer y procesar datos espec\u00edficos del entorno Transversal.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar de forma automatizada la conexi\u00f3n y extracci\u00f3n de datos en el flujo ETL, asegurando la consolidaci\u00f3n y actualizaci\u00f3n continua de la informaci\u00f3n en el Data Warehouse.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_1","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute Process Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>Executable:   Se utiliza una expresi\u00f3n de propiedad para definir din\u00e1micamente la ruta del ejecutable de Python:   <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory:   La ruta de trabajo se define din\u00e1micamente con la siguiente expresi\u00f3n:   <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"\n</code></pre></li> <li>Arguments:   El script a ejecutar es:   <pre><code>05.SharePoint_Connection_Transversal.py\n</code></pre></li> </ul> </li> <li> <p>Datos del Objeto:</p> <ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_1","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso sigue estos pasos:</p> <ol> <li> <p>Inicio de la Tarea:    El paquete SSIS inicia la tarea de proceso que ejecuta el script.</p> </li> <li> <p>Ejecuci\u00f3n del Script Python:    Se invoca el ejecutable de Python con el argumento <code>05.SharePoint_Connection_Transversal.py</code> en el directorio de trabajo especificado. El script se encarga de conectarse a SharePoint, extraer y procesar los datos requeridos para el entorno Transversal.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Tras la ejecuci\u00f3n del script, la tarea finaliza y retorna el c\u00f3digo de retorno, permitiendo que el flujo ETL contin\u00fae con las siguientes operaciones.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Ejecuci\u00f3n ETLs\n    participant PythonScript as 05.SharePoint_Connection_Transversal.py\n\n    SSIS -&gt;&gt; ExecProcess: Inicia tarea de proceso\n    ExecProcess -&gt;&gt; PythonScript: Ejecuta script de Python\n    PythonScript --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_aportes_shr_det","title":"Componente <code>FACT_APORTES_SHR_DET</code>","text":"<p>El componente FACT_APORTES_SHR_DET es una tarea de flujo de datos (Data Flow Task) en el paquete SSIS dise\u00f1ada para procesar y consolidar datos relacionados con los aportes. Este flujo de datos forma parte de la soluci\u00f3n de integraci\u00f3n ETL del Data Warehouse <code>DWH_COMFENALCO</code> y se encarga de extraer datos desde la fuente de aportes, aplicar transformaciones y validaciones, y cargar la informaci\u00f3n final en la tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_2","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n y Consolidaci\u00f3n de Datos de Aportes:   Obtiene informaci\u00f3n financiera y operativa de aportes, considerando aportes, intereses y otros campos relevantes, para garantizar que los datos financieros est\u00e9n correctamente integrados en el Data Warehouse.</p> </li> <li> <p>Transformaci\u00f3n y Validaci\u00f3n de Datos:   Realiza conversiones de tipos de datos y cruces (lookups) para verificar la existencia y consistencia de registros en tablas relacionadas (por ejemplo, validaci\u00f3n de datos de afiliados y empresas). Adem\u00e1s, se asegura que solo se inserten nuevos registros mediante la comparaci\u00f3n con datos ya existentes.</p> </li> <li> <p>Carga de Datos con Rendimiento Optimizado:   Utiliza inserciones masivas (bulk insert) para la carga en la tabla <code>\"Transversal\".\"FACT_APORTES_SHR_DET\"</code>, garantizando una alta performance durante el proceso de ETL.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_2","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos del componente FACT_APORTES_SHR_DET se estructura en dos grandes grupos de componentes:</p> <ol> <li> <p>Fuente y Transformaci\u00f3n de Datos:</p> <ul> <li>Fuente de Datos ADO.NET:     Se extrae la informaci\u00f3n de aportes mediante una consulta SQL definida en el componente. La consulta obtiene campos como <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code>, <code>APORTE</code>, <code>INTERES</code>, <code>ESTADOREGISTRO</code>, <code>FECHA_ACTUALIZACION</code>, <code>DESDE</code>, <code>HASTA</code>, <code>PROCESO</code>, <code>BP_EMPRESA</code>, <code>BP_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>SW_AJUSTE</code> y <code>APORTE_NUEVO</code> de la tabla <code>[Aportes].[FACT_APORTES_SHR_DET]</code> para registros a partir del a\u00f1o 2022.</li> <li>Transformaciones y Cruces:     Se realizan conversiones de datos (por ejemplo, el campo <code>FECHA_CONTABLE</code> se utiliza en su formato num\u00e9rico) y se aplican lookups adicionales en tablas relacionadas para:<ul> <li>Validar y enriquecer la informaci\u00f3n con datos de afiliados y empresas.</li> <li>Comparar los datos extra\u00eddos con los registros existentes en el esquema transversal para evitar duplicidades. El uso de condiciones en los lookups permite identificar registros nuevos (aquellos que no se encuentran en el destino) que ser\u00e1n insertados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Destino de Datos ADO.NET:     La informaci\u00f3n procesada se carga en la tabla destino <code>\"Transversal\".\"FACT_APORTES_SHR_DET\"</code>. Se configura el destino para usar inserciones masivas (bulk insert) y se establecen par\u00e1metros como el tama\u00f1o del lote (BatchSize=0) y el tiempo de espera (CommandTimeout=600 segundos) para optimizar el rendimiento.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_2","title":"Flujo de Ejecuci\u00f3n","text":"<p>El flujo de datos del componente FACT_APORTES_SHR_DET se describe a continuaci\u00f3n:</p> <ol> <li> <p>Extracci\u00f3n de Datos:    El componente de origen ADO.NET ejecuta la consulta SQL para extraer los registros de aportes desde la base de datos <code>DWH_COMFENALCO</code>.</p> </li> <li> <p>Transformaci\u00f3n y Enriquecimiento: </p> </li> <li>Se aplican conversiones de datos para asegurar la correcta tipificaci\u00f3n (por ejemplo, conversi\u00f3n de <code>FECHA_CONTABLE</code>).</li> <li>Se realizan b\u00fasquedas (lookups) en las tablas DIM_AFILIADOS y DIM_EMPRESAS para validar que los registros de afiliados y empresas existan.  </li> <li> <p>Se efect\u00faa una comparaci\u00f3n (mediante un lookup con par\u00e1metros m\u00faltiples) contra la tabla ya cargada en el esquema Transversal para identificar registros nuevos.</p> </li> <li> <p>Carga de Datos:    Los registros que no coinciden con los existentes en el destino se cargan en la tabla <code>\"Transversal\".\"FACT_APORTES_SHR_DET\"</code> utilizando la configuraci\u00f3n de inserci\u00f3n masiva, asegurando una transferencia eficiente y confiable.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as Fuente de ADO.NET (FACT_APORTES_SHR_DET)\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup en DIM_AFILIADOS\n    participant ConditionalSplit as Divisi\u00f3n Condicional\n    participant Lookup2 as Lookup en DIM_EMPRESAS\n    participant ConditionalSplit1 as Segunda Divisi\u00f3n Condicional\n    participant Lookup as Lookup en FACT_APORTES_SHR_DET Transversal\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; DataConversion: Extrae datos de aportes\n    DataConversion -&gt;&gt; Lookup1: Aplica conversi\u00f3n de datos\n    Lookup1 -&gt;&gt; ConditionalSplit: Cruza con DIM_AFILIADOS\n    ConditionalSplit -&gt;&gt; Lookup2: Filtra registros v\u00e1lidos (ID_AFILIADO existe)\n    Lookup2 -&gt;&gt; ConditionalSplit1: Cruza con DIM_EMPRESAS\n    ConditionalSplit1 -&gt;&gt; Lookup: Compara con registros existentes en Transversal\n    Lookup -&gt;&gt; AdoNetDestination: Inserta registros nuevos</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_detalle_contable","title":"Componente <code>FACT_DETALLE_CONTABLE</code>","text":"<p>El componente FACT_DETALLE_CONTABLE es una tarea de flujo de datos (Data Flow Task) del paquete SSIS dise\u00f1ada para extraer, transformar y cargar datos financieros provenientes de la tabla <code>FACT_DETALLE_CONTABLE</code> ubicada en el esquema <code>Financiera</code> del Data Warehouse <code>DWH_COMFENALCO</code>. Este proceso forma parte del conjunto de operaciones ETL que alimentan la capa transversal del Data Warehouse, asegurando que los datos financieros se integren de manera precisa y sin duplicidades.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_3","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos Financieros:   Recuperar informaci\u00f3n detallada relacionada con cuentas, fechas, importes, ingresos, gastos, activos, pasivos y otros indicadores financieros de la tabla <code>FACT_DETALLE_CONTABLE</code>.</p> </li> <li> <p>Transformaci\u00f3n y Validaci\u00f3n:   Aplicar conversiones de tipos de datos, especialmente para fechas (por ejemplo, <code>FECHA_REGISTRO_SAP</code> y <code>FECHA_PROCESO</code>), y validar que la informaci\u00f3n extra\u00edda no se encuentre duplicada en el esquema transversal. Esto se logra mediante un cruce (lookup) con la tabla <code>[Transversal].[FACT_DETALLE_CONTABLE]</code>.</p> </li> <li> <p>Carga de Datos con Alta Performance:   Insertar \u00fanicamente los registros nuevos (aquellos que no existen en la tabla de destino) en la tabla <code>\"Transversal\".\"FACT_DETALLE_CONTABLE\"</code>, utilizando inserciones masivas (bulk insert) para optimizar el rendimiento del proceso.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_3","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos de FACT_DETALLE_CONTABLE se compone de los siguientes pasos:</p> <ol> <li> <p>Fuente de Datos ADO.NET: </p> <ul> <li>Se ejecuta una consulta SQL que extrae las columnas relevantes de la tabla <code>[Financiera].[FACT_DETALLE_CONTABLE]</code>.  </li> <li>La consulta incluye la conversi\u00f3n de los campos <code>FECHA_REGISTRO_SAP</code> y <code>FECHA_PROCESO</code> al tipo <code>smalldatetime</code> para facilitar su procesamiento.</li> </ul> </li> <li> <p>Conversi\u00f3n de Datos: </p> <ul> <li>Se utilizan componentes de Data Conversion para generar copias de las columnas de fecha (<code>Copy of FECHA_REGISTRO_SAP</code> y <code>Copy of FECHA_PROCESO</code>), asegurando que el formato y tipo de datos sean compatibles con los componentes de destino.</li> </ul> </li> <li> <p>Lookup para Validaci\u00f3n de Duplicidad: </p> <ul> <li>Se realiza un cruce (lookup) con la tabla <code>[Transversal].[FACT_DETALLE_CONTABLE]</code> para comparar los registros extra\u00eddos.  </li> <li>La uni\u00f3n se efect\u00faa mediante las claves: <code>ID_CEBE</code>, <code>ID_CUENTA</code>, <code>ID_FECHA</code>, <code>SEGMENT</code>, <code>IMPORTE</code> y <code>FECHA_REGISTRO_SAP</code>.  </li> <li>Solo se consideran los registros que no encuentran coincidencia en el destino (es decir, aquellos para los cuales el lookup devuelve un valor nulo).</li> </ul> </li> <li> <p>Destino de Datos ADO.NET: </p> <ul> <li>Los registros resultantes, considerados nuevos, se cargan en la tabla <code>\"Transversal\".\"FACT_DETALLE_CONTABLE\"</code>.  </li> <li>Se configuran par\u00e1metros de inserci\u00f3n masiva (Bulk Insert) con un tama\u00f1o de lote predeterminado (BatchSize=0) y un CommandTimeout de 300 segundos para optimizar la operaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_3","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso ETL se puede resumir en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    La fuente ADO.NET ejecuta la consulta para recuperar los datos financieros desde la tabla origen en el esquema <code>Financiera</code>.</p> </li> <li> <p>Transformaci\u00f3n: </p> <ul> <li>Se convierten los campos de fecha a un formato adecuado.  </li> <li>Se realiza un cruce (lookup) para verificar la existencia de cada registro en la tabla destino del esquema <code>Transversal</code>.</li> </ul> </li> <li> <p>Carga:    Los registros que no est\u00e1n presentes en la tabla de destino se insertan en <code>\"Transversal\".\"FACT_DETALLE_CONTABLE\"</code>, garantizando la integraci\u00f3n de solo datos nuevos y evitando duplicidades.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as Fuente de ADO.NET (FACT_DETALLE_CONTABLE)\n    participant DataConversion as Componente Data Conversion\n    participant Lookup as Componente Lookup (Validaci\u00f3n en Transversal)\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; DataConversion: Extrae datos financieros\n    DataConversion -&gt;&gt; Lookup: Aplica conversi\u00f3n de fechas\n    Lookup -&gt;&gt; AdoNetDestination: Filtra registros nuevos (Lookup sin coincidencias)</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_convenios","title":"Componente <code>FACT_CONVENIOS</code>","text":"<p>El componente FACT_CONVENIOS es una tarea de flujo de datos (Data Flow Task) del paquete SSIS que se encarga de procesar y cargar datos de convenios extra\u00eddos de archivos Excel hacia el Data Warehouse <code>DWH_COMFENALCO</code>. Este proceso forma parte de la integraci\u00f3n transversal y se encarga de transformar la informaci\u00f3n para enriquecer la capa anal\u00edtica con datos de convenios, sus entidades y condiciones asociadas.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_4","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos desde Excel:   Se leen datos de convenios provenientes de un archivo Excel. Entre la informaci\u00f3n extra\u00edda se encuentran los nombres de convenios, la identificaci\u00f3n del acto del convenio, la entidad responsable, el c\u00f3digo del municipio, el valor del convenio, el aporte de Comfenalco, el estado del convenio, las fechas de inicio y fin, y los identificadores relacionados con el programa y la unidad.</p> </li> <li> <p>Transformaci\u00f3n y Conversi\u00f3n de Datos:   Se aplican conversiones de datos para adecuar los tipos de datos a los requeridos por el destino. Por ejemplo, se convierten las fechas de inicio y fin a un tipo de fecha (timestamp) y se transforma el identificador del programa y la unidad a tipos num\u00e9ricos compatibles.</p> </li> <li> <p>Carga de Datos con Alta Performance:   Los datos transformados se insertan en la tabla <code>\"Transversal\".\"FACT_CONVENIOS\"</code> utilizando inserciones masivas (Bulk Insert) para optimizar el rendimiento del proceso.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_4","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos del componente FACT_CONVENIOS se estructura en los siguientes pasos:</p> <ol> <li> <p>Fuente de Datos Excel: </p> <ul> <li>Objetivo: Leer la informaci\u00f3n de convenios desde una hoja de Excel (por ejemplo, <code>Sheet1$</code>).  </li> <li>Columnas Extra\u00eddas: <ul> <li><code>NOMBRE_CONVENIO</code>,  </li> <li><code>IDENTIFICACION_ACTO_CONVENIO</code>,  </li> <li><code>ENTIDAD_CONVENIO</code>,  </li> <li><code>COD_MUNICIPIO</code>,  </li> <li><code>VALOR_CONVENIO</code>,  </li> <li><code>APORTE_COMFENALCO</code>,  </li> <li><code>ESTADO_CONVENIO</code>,  </li> <li><code>FECHA_INICIO</code>,  </li> <li><code>FECHA_FIN</code>,  </li> <li><code>PROGRAMA</code>,  </li> <li><code>ID_PROGRAMA</code>,  </li> <li><code>ID_UNIDAD</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos: </p> <ul> <li>Objetivo: Transformar y ajustar los tipos de datos de las columnas extra\u00eddas para que sean compatibles con los procesos posteriores.  </li> <li>Conversiones Espec\u00edficas: <ul> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code> se convierten a un formato de fecha/hora (timestamp) y se renombran como <code>Copy of FECHA_INICIO</code> y <code>Copy of FECHA_FIN</code>.  </li> <li><code>ID_PROGRAMA</code> se transforma a formato num\u00e9rico y se guarda en <code>Copy of ID_PROGRAMA</code>.  </li> <li>Se crea una versi\u00f3n reducida (por ejemplo, de 40 caracteres) de la columna <code>PROGRAMA</code> denominada <code>Copy of PROGRAMA</code>.  </li> <li>De igual manera se generan copias de <code>NOMBRE_CONVENIO</code>, <code>ENTIDAD_CONVENIO</code> y <code>IDENTIFICACION_ACTO_CONVENIO</code> con el tama\u00f1o adecuado.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET: </p> <ul> <li>Objetivo: Cargar la informaci\u00f3n transformada en la tabla de destino <code>\"Transversal\".\"FACT_CONVENIOS\"</code>.  </li> <li>Configuraci\u00f3n: <ul> <li>Se utiliza inserci\u00f3n masiva (Bulk Insert) para optimizar el rendimiento.  </li> <li>El componente se conecta a la base de datos destino mediante el administrador de conexiones <code>DWH_COMFENALCO_Destino</code>.</li> </ul> </li> <li>Columnas Cargadas: <ul> <li>Se incluyen tanto las columnas transformadas (por ejemplo, <code>Copy of FECHA_INICIO</code>, <code>Copy of FECHA_FIN</code>, <code>Copy of ID_PROGRAMA</code>, <code>Copy of PROGRAMA</code>, <code>Copy of NOMBRE_CONVENIO</code>, <code>Copy of ENTIDAD_CONVENIO</code>, <code>Copy of IDENTIFICACION_ACTO_CONVENIO</code>) como aquellas que provienen directamente de la fuente (por ejemplo, <code>COD_MUNICIPIO</code>, <code>VALOR_CONVENIO</code>, <code>APORTE_COMFENALCO</code>, <code>ESTADO_CONVENIO</code>).</li> </ul> </li> </ul> </li> <li> <p>Integraci\u00f3n con el Proceso ETL: </p> <ul> <li>La salida del componente Excel se une a la transformaci\u00f3n (Data Conversion) y, posteriormente, el flujo se conecta directamente al destino de ADO.NET.  </li> <li>Se garantiza que la informaci\u00f3n cargada en la tabla de destino est\u00e9 normalizada y lista para su an\u00e1lisis en el contexto transversal.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_4","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso ETL en FACT_CONVENIOS se puede resumir en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    La fuente de datos Excel extrae los registros de convenios de la hoja configurada.</p> </li> <li> <p>Transformaci\u00f3n:    Los datos se pasan a trav\u00e9s de un componente de Data Conversion, donde se aplican las conversiones necesarias (fechas, identificadores y textos) para normalizar la informaci\u00f3n.</p> </li> <li> <p>Carga:    Los registros transformados se insertan en la tabla <code>\"Transversal\".\"FACT_CONVENIOS\"</code> utilizando un destino ADO.NET configurado para inserciones masivas.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Fuente de Excel (FACT_CONVENIOS)\n    participant DataConversion as Componente Data Conversion\n    participant AdoNetDestination as Destino de ADO NET\n\n    ExcelSource -&gt;&gt; DataConversion: Extrae datos desde Excel\n    DataConversion -&gt;&gt; AdoNetDestination: Transforma y pasa datos\n    AdoNetDestination -&gt;&gt; AdoNetDestination: Inserta registros en \"Transversal\".\"FACT_CONVENIOS\"</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_presupuesto","title":"Componente <code>FACT_PRESUPUESTO</code>","text":"<p>El componente FACT_PRESUPUESTO es una tarea de flujo de datos (Data Flow Task) del paquete SSIS dise\u00f1ado para extraer, transformar y cargar datos financieros del presupuesto. Este componente extrae registros de la tabla <code>FACT_PRESUPUESTO</code> del esquema <code>Financiera</code> en el Data Warehouse <code>DWH_COMFENALCO</code>, y posteriormente inserta los registros nuevos en la tabla de destino <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code>. El proceso garantiza que la informaci\u00f3n presupuestal se integre de forma precisa y sin duplicidades en la capa transversal.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_5","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos Financieros:   Se obtienen los registros de la tabla <code>[DWH_COMFENALCO].[Financiera].[FACT_PRESUPUESTO]</code>, que contienen indicadores como valor, ingresos, gastos y otros datos relevantes para el an\u00e1lisis presupuestal.</p> </li> <li> <p>Transformaci\u00f3n y Validaci\u00f3n: </p> <ul> <li>Se realiza la conversi\u00f3n de los datos extra\u00eddos para asegurar la compatibilidad de tipos, especialmente en campos num\u00e9ricos y de fecha.</li> <li>Se efect\u00faa una validaci\u00f3n mediante un cruce (lookup) para verificar que los registros a cargar sean nuevos, comparando la informaci\u00f3n existente en la tabla de destino del esquema <code>Transversal</code>.</li> </ul> </li> <li> <p>Carga de Datos con Alta Performance:   Se insertan los registros nuevos en la tabla <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code> utilizando inserciones masivas (bulk insert) para maximizar el rendimiento del proceso ETL.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_5","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos del componente FACT_PRESUPUESTO se compone de los siguientes pasos:</p> <ol> <li> <p>Fuente de Datos ADO.NET: </p> <ul> <li> <p>Consulta SQL:     Se ejecuta una instrucci\u00f3n que extrae los datos de la tabla <code>[DWH_COMFENALCO].[Financiera].[FACT_PRESUPUESTO]</code> y que filtra los registros mediante una uni\u00f3n con la tabla <code>[Transversal].[DIM_UNIDADES_ORGANIZATIVAS]</code> para asegurar que se consideren solo aquellos registros que correspondan a unidades organizativas v\u00e1lidas.</p> <p>La consulta utiliza la cl\u00e1usula <code>WITH</code> para definir un conjunto intermedio de datos (fact presupuestario) y, posteriormente, se realiza un cruce con la tabla destino para seleccionar \u00fanicamente los registros nuevos (aquellos para los que no existe coincidencia en <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code>).</p> </li> </ul> </li> <li> <p>Transformaci\u00f3n y Conversi\u00f3n de Datos: </p> <ul> <li>Se garantiza que los tipos de datos sean compatibles con el destino, incluyendo conversiones necesarias para campos num\u00e9ricos y fechas.</li> <li>La transformaci\u00f3n asegura que los datos sean limpios y listos para su integraci\u00f3n en la capa transversal.</li> </ul> </li> <li> <p>Destino de Datos ADO.NET: </p> <ul> <li>Configuraci\u00f3n: <ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code>.</li> <li>Par\u00e1metros: </li> <li><code>BatchSize</code> se configura a 0 para utilizar el tama\u00f1o de b\u00fafer interno de SSIS.</li> <li><code>CommandTimeout</code> se establece en 600 segundos para procesos de alta carga.</li> <li>Se utiliza la opci\u00f3n de Bulk Insert para optimizar la inserci\u00f3n de grandes vol\u00famenes de datos.</li> </ul> </li> <li>Carga de Registros Nuevos:     Solo se insertan aquellos registros que no han sido previamente cargados en el destino, de acuerdo al cruce (lookup) realizado en la consulta SQL.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_5","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso ETL del componente FACT_PRESUPUESTO se resume en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    Se ejecuta la consulta SQL en la fuente ADO.NET para recuperar los datos financieros del presupuesto desde la tabla en el esquema <code>Financiera</code>.</p> </li> <li> <p>Transformaci\u00f3n:    Se aplican conversiones y validaciones para asegurar que los datos cumplan con los requisitos de la capa transversal.</p> </li> <li> <p>Carga:    Los registros validados y que no existen en la tabla destino se insertan en <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code>, integr\u00e1ndose al Data Warehouse para an\u00e1lisis y reportes estrat\u00e9gicos.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as Fuente de ADO.NET (FACT_PRESUPUESTO)\n    participant Lookup as Componente Lookup (Validaci\u00f3n y filtrado)\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; Lookup: Extrae datos de FACT_PRESUPUESTO\n    Lookup -&gt;&gt; AdoNetDestination: Filtra e inserta registros nuevos</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_iniciativas","title":"Componente <code>FACT_INICIATIVAS</code>","text":"<p>El componente FACT_INICIATIVAS es una tarea de flujo de datos (Data Flow Task) del paquete SSIS que se encarga de extraer, transformar y cargar informaci\u00f3n relacionada con iniciativas. Esta informaci\u00f3n se obtiene principalmente desde un archivo Excel y, mediante una transformaci\u00f3n de datos y b\u00fasquedas (lookup), se enriquece con informaci\u00f3n adicional de la dimensi\u00f3n de tiempo para asignar el identificador de fecha correspondiente. Finalmente, los datos transformados se insertan en la tabla <code>\"Transversal\".\"FACT_INICIATIVAS\"</code> del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_6","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos:   Se leen los registros de iniciativas desde un archivo Excel. Entre los datos extra\u00eddos se encuentran los identificadores de la iniciativa, la unidad, la fecha de inicio, la fecha de fin, el nombre de la iniciativa, la descripci\u00f3n y observaciones.</p> </li> <li> <p>Transformaci\u00f3n y Conversi\u00f3n: </p> <ul> <li>Se aplican conversiones de datos para asegurar la correcta transformaci\u00f3n de los campos de fecha (de texto a timestamp) y la normalizaci\u00f3n de los campos de texto.</li> <li>Estas conversiones permiten trabajar con formatos adecuados para la integraci\u00f3n en la base de datos.</li> </ul> </li> <li> <p>Enriquecimiento mediante Lookup:   Se realiza una b\u00fasqueda (lookup) en la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO</code>) para obtener el valor de <code>ID_FECHA</code> correspondiente a la fecha de inicio de la iniciativa, lo que facilita la integraci\u00f3n de la informaci\u00f3n temporal en el proceso ETL.</p> </li> <li> <p>Carga de Datos:   Los datos transformados y enriquecidos se insertan en la tabla destino <code>\"Transversal\".\"FACT_INICIATIVAS\"</code>, garantizando la integraci\u00f3n de la informaci\u00f3n de iniciativas en la capa transversal del Data Warehouse para posteriores an\u00e1lisis estrat\u00e9gicos.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_6","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos del componente FACT_INICIATIVAS se compone de los siguientes pasos:</p> <ol> <li> <p>Excel Source: </p> <ul> <li>Funci\u00f3n: Extraer los datos de iniciativas desde un archivo Excel.</li> <li>Datos Extra\u00eddos: <ul> <li><code>ID_INICIATIVA</code></li> <li><code>ID_UNIDAD</code></li> <li><code>FECHA_INICIO</code></li> <li><code>FECHA_FIN</code></li> <li><code>NOMBRE_INICIATIVA</code></li> <li><code>DESCRIPCION_INICIATIVA</code></li> <li><code>OBSERVACIONES</code></li> </ul> </li> <li>Conexi\u00f3n: Se utiliza el administrador de conexiones configurado para Excel.</li> </ul> </li> <li> <p>Data Conversion: </p> <ul> <li>Funci\u00f3n: Convertir los datos extra\u00eddos a tipos compatibles con el procesamiento posterior.</li> <li>Conversiones Realizadas: <ul> <li>Se convierten los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code> de texto a tipo dbTimeStamp.</li> <li>Se realizan copias de los campos <code>NOMBRE_INICIATIVA</code>, <code>DESCRIPCION_INICIATIVA</code> y <code>OBSERVACIONES</code> para mantener la integridad de la informaci\u00f3n durante la transformaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_TIEMPO): </p> <ul> <li>Funci\u00f3n: Enriquecer los datos del flujo mediante una b\u00fasqueda en la tabla <code>DIM_TIEMPO</code> para obtener el valor de <code>ID_FECHA</code>.</li> <li>Par\u00e1metros: <ul> <li>Se utiliza el campo convertido <code>Copy of FECHA_INICIO</code> para unir con la columna <code>FECHA</code> de la tabla <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Resultado: <ul> <li>Se obtiene el <code>ID_FECHA</code> que se agregar\u00e1 al flujo de datos para relacionar la iniciativa con la dimensi\u00f3n de tiempo.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET: </p> <ul> <li>Funci\u00f3n: Insertar los datos transformados y enriquecidos en la tabla de destino.</li> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_INICIATIVAS\"</code>.</li> <li>Configuraci\u00f3n: <ul> <li>Se emplea Bulk Insert para mejorar el rendimiento.</li> <li>Los par\u00e1metros de lote (BatchSize) y tiempo de espera (CommandTimeout) se configuran para optimizar la inserci\u00f3n de grandes vol\u00famenes de datos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_6","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso ETL del componente FACT_INICIATIVAS se resume en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    Los datos se leen desde un archivo Excel mediante el componente Excel Source.</p> </li> <li> <p>Transformaci\u00f3n:    Se aplican conversiones a los campos de fecha y texto usando el componente Data Conversion.</p> </li> <li> <p>Enriquecimiento:    El componente Lookup consulta la tabla <code>DIM_TIEMPO</code> para asignar a cada registro el valor correspondiente de <code>ID_FECHA</code> bas\u00e1ndose en la fecha de inicio.</p> </li> <li> <p>Carga:    Los registros resultantes se insertan en la tabla <code>\"Transversal\".\"FACT_INICIATIVAS\"</code> utilizando el destino ADO.NET.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup (DIM_TIEMPO)\n    participant AdoNetDestination as Destino de ADO NET\n\n    ExcelSource -&gt;&gt; DataConversion: Extrae datos desde Excel\n    DataConversion -&gt;&gt; Lookup: Convierte y env\u00eda datos (p.ej., Copy of FECHA_INICIO)\n    Lookup -&gt;&gt; AdoNetDestination: Enrich &amp; Filtra datos (asigna ID_FECHA) y carga registros nuevos</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-truncar-tmp_encuestas","title":"Componente <code>Truncar TMP_ENCUESTAS</code>","text":"<p>El componente Truncar TMP_ENCUESTAS es una tarea de ejecuci\u00f3n de SQL (Execute SQL Task) en un paquete SSIS. Su funci\u00f3n principal es limpiar la tabla temporal <code>[STAGE_AREA].[Transversal].[TMP_ENCUESTAS]</code> antes de cargar nuevos datos durante el proceso ETL. Esta acci\u00f3n es fundamental para garantizar que la tabla no contenga datos residuales de ejecuciones anteriores, asegurando as\u00ed la calidad y consistencia de la informaci\u00f3n que se insertar\u00e1 posteriormente.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_7","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Limpieza de Datos:   El objetivo principal es truncar (vaciar) la tabla <code>[STAGE_AREA].[Transversal].[TMP_ENCUESTAS]</code> para eliminar todos los registros existentes, preparando la tabla para una nueva carga de datos.</p> </li> <li> <p>Garantizar Integridad:   Al vaciar la tabla temporal, se evita la mezcla de datos antiguos y nuevos, lo que contribuye a la precisi\u00f3n del proceso ETL y facilita el manejo de la informaci\u00f3n en etapas posteriores.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_7","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea: Execute SQL Task \u2013 Permite la ejecuci\u00f3n de sentencias SQL directamente desde el paquete SSIS.</p> </li> <li> <p>Instrucci\u00f3n SQL:   La tarea ejecuta la siguiente sentencia:   <pre><code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ENCUESTAS]\n</code></pre>   Esta sentencia elimina de forma r\u00e1pida y eficiente todos los registros de la tabla, sin registrar cada eliminaci\u00f3n individualmente (a diferencia de una sentencia DELETE).</p> </li> <li> <p>Conexi\u00f3n:   Se utiliza una conexi\u00f3n preconfigurada (identificada mediante el GUID <code>{5972EC76-2533-4771-BB68-A92E1CDD645D}</code>) que apunta a la base de datos de destino, asegurando que la operaci\u00f3n se realice sobre el entorno correcto.</p> </li> <li> <p>Tiempo de Espera:   La configuraci\u00f3n predeterminada de tiempo de espera se aplica, aunque este par\u00e1metro puede ajustarse seg\u00fan las necesidades del entorno.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_7","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    Al ejecutar el paquete SSIS, se inicia la tarea de SQL que contiene la sentencia de truncamiento.</p> </li> <li> <p>Ejecuci\u00f3n de la Sentencia SQL:    La sentencia <code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ENCUESTAS]</code> se env\u00eda a la base de datos a trav\u00e9s del administrador de conexiones configurado.</p> </li> <li> <p>Limpieza de la Tabla:    Todos los registros en la tabla temporal se eliminan, dej\u00e1ndola vac\u00eda y lista para la nueva carga de datos.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Una vez completada la operaci\u00f3n, la tarea finaliza y el proceso ETL puede continuar con las siguientes etapas de carga y transformaci\u00f3n.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SQLTask as Truncar TMP_ENCUESTAS\n    participant DB as Base de Datos\n\n    SQLTask -&gt;&gt; DB: Ejecuta \"TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ENCUESTAS]\"\n    DB --&gt;&gt; SQLTask: Confirmaci\u00f3n de limpieza</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-tmp_encuestas","title":"Componente <code>TMP_ENCUESTAS</code>","text":"<p>El paquete SSIS \"TMP_ENCUESTAS\" es un flujo de datos (Data Flow Task) dise\u00f1ado para extraer, transformar y cargar informaci\u00f3n proveniente de un archivo plano (CSV) hacia la tabla <code>[Transversal].[TMP_ENCUESTAS]</code> en la base de datos de staging. Este flujo se encarga de convertir datos de entrada, aplicar expresiones para derivar nuevos valores (por ejemplo, el identificador de unidad basado en el servicio) y, finalmente, cargar la informaci\u00f3n limpia y transformada en el destino.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-paquete_1","title":"Prop\u00f3sito del Paquete","text":"<ul> <li> <p>Extracci\u00f3n de Datos:   Se leen los registros de un archivo CSV que contiene informaci\u00f3n de encuestas, incluyendo columnas como FECHA_ENCUESTA, DOCUMENTO, TIPO_DOCUMENTO, CALIFICACION, SERVICIO, PREGUNTA y NPS.</p> </li> <li> <p>Transformaci\u00f3n de Datos:     El proceso incluye:</p> <ul> <li>Conversi\u00f3n de Datos: Se transforma la informaci\u00f3n extra\u00edda (por ejemplo, se convierte la fecha de encuesta a formato de fecha/hora compatible con la base de datos).</li> <li>Derivaci\u00f3n de Columnas: Se utiliza una transformaci\u00f3n Derivada para calcular la columna ID_UNIDAD a partir del valor de la columna SERVICIO. La expresi\u00f3n asigna diferentes valores num\u00e9ricos seg\u00fan el contenido de SERVICIO (por ejemplo, \u201cConsultorias\u201d \u2192 3, \u201cEgresados\u201d \u2192 2, etc.).</li> </ul> </li> <li> <p>Carga de Datos:   La informaci\u00f3n transformada se carga en la tabla <code>[Transversal].[TMP_ENCUESTAS]</code> del \u00e1rea de staging, utilizando un destino ADO.NET optimizado para inserciones masivas.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_8","title":"Descripci\u00f3n T\u00e9cnica","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-principales","title":"Componentes Principales:","text":"<ol> <li> <p>Flat File Source: </p> <ul> <li>Funci\u00f3n: Extrae los datos del archivo CSV.</li> <li>Columnas de Origen: <ul> <li>FECHA_ENCUESTA  </li> <li>DOCUMENTO  </li> <li>PREGUNTA  </li> <li>CALIFICACION  </li> <li>SERVICIO  </li> <li>TIPO_DOCUMENTO  </li> <li>NPS  </li> </ul> </li> <li>Configuraci\u00f3n: Se utiliza una conexi\u00f3n definida (Csv_Connection_Fact_Encuestas) y se lee la hoja o secci\u00f3n definida en el archivo.</li> </ul> </li> <li> <p>Data Conversion: </p> <ul> <li>Funci\u00f3n: Convierte las columnas de datos extra\u00eddos a tipos de datos compatibles para operaciones posteriores.</li> <li>Conversiones Realizadas: <ul> <li>FECHA_ENCUESTA se convierte a tipo dbTimeStamp (formato fecha/hora).  </li> <li>DOCUMENTO, TIPO_DOCUMENTO, CALIFICACION, SERVICIO, PREGUNTA y NPS se convierten a cadenas de caracteres (wstr) con longitudes espec\u00edficas.</li> </ul> </li> </ul> </li> <li> <p>Derived Column (ID_UNIDAD): </p> <ul> <li>Funci\u00f3n: Genera la columna ID_UNIDAD mediante una expresi\u00f3n derivada que asigna un valor num\u00e9rico seg\u00fan el valor de la columna SERVICIO.  </li> <li>Expresi\u00f3n Utilizada: <pre><code>(DT_I4)(SERVICIO == \"Consultorias\" ? 3 :\n        SERVICIO == \"Egresados\" ? 2 :\n        SERVICIO == \"Proteccion social\" ? 4 :\n        SERVICIO == \"Cedesarrollo convenios\" ? 2 :\n        SERVICIO == \"CEC\" ? 1 :\n        SERVICIO == \"Estudiantes Activos\" ? 2 :\n        SERVICIO == \"Cursos y diplomados\" ? 3 : 5)\n</code></pre>     Esta l\u00f3gica clasifica el servicio en diferentes categor\u00edas y asigna un identificador num\u00e9rico que se utilizar\u00e1 en el sistema.</li> </ul> </li> <li> <p>Destino de ADO.NET: </p> <ul> <li>Funci\u00f3n: Carga los datos finales transformados en la tabla <code>[Transversal].[TMP_ENCUESTAS]</code>.  </li> <li>Configuraci\u00f3n: <ul> <li>Tabla de Destino: <code>\"Transversal\".\"TMP_ENCUESTAS\"</code> </li> <li>BatchSize: 0 (usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS)  </li> <li>CommandTimeout: 30 segundos  </li> <li>Uso de Bulk Insert: Activado para mejorar el rendimiento en la carga de datos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant FlatFile as Flat File Source\n    participant DataConv as Data Conversion\n    participant Derived as Derived Column (ID_UNIDAD)\n    participant Destination as Destino ADO.NET\n\n    FlatFile -&gt;&gt; DataConv: Extrae y convierte datos del CSV\n    DataConv -&gt;&gt; Derived: Env\u00eda datos convertidos\n    Derived -&gt;&gt; Destination: Carga datos transformados en la tabla TMP_ENCUESTAS</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-actualizacion-fact_encuestas","title":"Componente <code>Actualizacion FACT_ENCUESTAS</code>","text":"<p>El paquete SSIS \"Actualizacion FACT_ENCUESTAS\" es un flujo de datos (Data Flow Task) dise\u00f1ado para actualizar la tabla de encuestas en el entorno transversal. Su funci\u00f3n es comparar y actualizar los registros de encuestas en la tabla de destino <code>[Transversal].[FACT_ENCUESTAS]</code> con la informaci\u00f3n procesada proveniente de la etapa de staging. El proceso se centra en identificar registros nuevos o modificados que a\u00fan no existan en el sistema y actualizarlos, garantizando la integridad y consistencia de los datos.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-paquete_2","title":"Prop\u00f3sito del Paquete","text":"<ul> <li> <p>Extracci\u00f3n de Datos:   Se consumen datos de la etapa de staging, previamente cargados en la tabla temporal, que contienen informaci\u00f3n consolidada de encuestas. Las columnas extra\u00eddas incluyen FECHA_ENCUESTA, ID_FECHA, DOCUMENTO, PREGUNTA, CALIFICACION, SERVICIO, TIPO_DOCUMENTO, NPS, ID_UNIDAD, ID_AFILIADO, ID_BENEFICIARIO e ID_APORTANTE.</p> </li> <li> <p>Transformaci\u00f3n de Datos:     El paquete se basa en una consulta SQL que utiliza expresiones comunes y t\u00e9cnicas de uni\u00f3n para:</p> <ul> <li>Transformar y normalizar la informaci\u00f3n.</li> <li>Realizar joins con tablas de referencia (como DIM_TIEMPO, DIM_EMPRESAS, DIM_AFILIADOS, DIM_BENEFICIARIOS y DIM_APORTANTE_NOAFILIADO) para enriquecer el dataset.</li> <li>Filtrar registros que ya existen en la tabla final, de modo que s\u00f3lo se inserten aquellos que son nuevos (es decir, aquellos cuya clave primaria o identificador no se encuentra en <code>[Transversal].[FACT_ENCUESTAS]</code>).</li> </ul> </li> <li> <p>Carga de Datos:   La informaci\u00f3n resultante se inserta en la tabla <code>[Transversal].[FACT_ENCUESTAS]</code> usando un destino ADO.NET optimizado para cargas masivas. Esto permite actualizar el repositorio de encuestas de forma eficiente y con alta performance.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_9","title":"Descripci\u00f3n T\u00e9cnica","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-principales_1","title":"Componentes Principales:","text":"<ol> <li> <p>Consulta de Origen (Consulta): </p> <ul> <li>Funci\u00f3n:     Consume datos de la tabla temporal en el \u00e1rea de staging (<code>[STAGE_AREA].[Transversal].[TMP_ENCUESTAS]</code>), aplicando una serie de transformaciones y agregaciones para obtener un conjunto de resultados limpio y consolidado.  </li> <li>Detalles:     La consulta utiliza Common Table Expressions (CTE) para:<ul> <li>Definir la subconsulta Encuestas que selecciona columnas transformadas (incluyendo la conversi\u00f3n de FECHA_ENCUESTA a un formato num\u00e9rico para obtener el ID_FECHA).</li> <li>Calcular la informaci\u00f3n de poblaci\u00f3n (IdPoblacion) mediante joins con las dimensiones de empresas, afiliados, beneficiarios y aportantes.</li> <li>Filtrar aquellos registros que a\u00fan no existen en la tabla <code>[Transversal].[FACT_ENCUESTAS]</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET (Actualizacion): </p> <ul> <li>Funci\u00f3n:     Inserta los registros nuevos obtenidos de la consulta en la tabla de destino <code>[Transversal].[FACT_ENCUESTAS]</code>.</li> <li>Configuraci\u00f3n: <ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_ENCUESTAS\"</code></li> <li>BatchSize: 0 (utiliza el tama\u00f1o predeterminado del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>Uso de Bulk Insert: Activado para mejorar el rendimiento en la carga de grandes vol\u00famenes de datos.</li> </ul> </li> </ul> </li> <li> <p>Flujo de Datos y Conexiones: </p> <ul> <li>Origen:     La salida de la consulta SQL (definida en el componente \"Consulta\") provee las columnas transformadas:<ul> <li>FECHA_ENCUESTA</li> <li>ID_FECHA</li> <li>DOCUMENTO</li> <li>PREGUNTA</li> <li>CALIFICACION</li> <li>SERVICIO</li> <li>TIPO_DOCUMENTO</li> <li>NPS</li> <li>ID_UNIDAD</li> <li>ID_AFILIADO</li> <li>ID_BENEFICIARIO</li> <li>ID_APORTANTE</li> </ul> </li> <li>Destino:     La informaci\u00f3n se canaliza hacia el componente de destino ADO.NET, que actualiza la tabla de encuestas, asegurando que s\u00f3lo se inserten los registros que no tengan coincidencias en la tabla de destino.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Consulta as Componente \"Consulta\"\n    participant Destination as Componente \"Actualizacion\" (Destino ADO.NET)\n\n    Consulta -&gt;&gt; Destination: Env\u00eda registros nuevos (sin coincidencias)\n    Destination -&gt;&gt; Destination: Inserta datos en [Transversal].[FACT_ENCUESTAS]</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_encuestas_psr","title":"Componente <code>FACT_ENCUESTAS_PSR</code>,","text":"<p>Forma parte del proceso ETL para la consolidaci\u00f3n de datos de encuestas del \u00e1rea transversal. Este flujo de datos extrae informaci\u00f3n de archivos planos, la transforma y la enriquece mediante diversas conversiones y b\u00fasquedas (Lookups) para, finalmente, cargar los registros resultantes en la tabla destino <code>[Transversal].[FACT_ENCUESTAS_PSR]</code>.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-paquete_3","title":"Prop\u00f3sito del Paquete","text":"<ul> <li> <p>Extracci\u00f3n:   Se utiliza un origen de archivo plano (Flat File Source) que lee datos de encuestas, obteniendo columnas como FECHA_ENCUESTA, DOCUMENTO, TIPO_DOCUMENTO, CALIFICACION, PROGRAMA, ACTIVIDAD_PREGUNTA, NPS, entre otras.</p> </li> <li> <p>Transformaci\u00f3n: </p> <ul> <li>Data Conversion: Convierte los valores de texto (por ejemplo, FECHA_ENCUESTA) a tipos de datos nativos, como <code>dbTimeStamp</code> para fechas, y ajusta la longitud de columnas num\u00e9ricas y de texto.  </li> <li>Lookup:   Se implementan varios componentes de Lookup para enriquecer los datos:</li> <li>Lookup: Consulta la tabla de referencia DIM_TIEMPO para obtener el ID_FECHA bas\u00e1ndose en la FECHA.</li> <li>Lookup 1: Busca en la dimensi\u00f3n de empresas para obtener el ID_EMPRESA, utilizando los campos TIPO_DOCUMENTO y DOCUMENTO.</li> <li>Lookup 2: Une con la dimensi\u00f3n de beneficiarios para extraer el ID_BENEFICIARIO, comparando DOCUMENTO y TIPO_DOCUMENTO.</li> <li>Lookup 3: Se conecta a la dimensi\u00f3n de afiliados para obtener el ID_AFILIADO.</li> <li>Lookup 4: Realiza la b\u00fasqueda en la dimensi\u00f3n de aportantes no afiliados para obtener el ID_APORTANTE, utilizando tambi\u00e9n DOCUMENTO y TIPO_DOCUMENTO.</li> </ul> <p>Cada Lookup compara los registros del flujo de datos con las tablas de referencia y, seg\u00fan la configuraci\u00f3n, env\u00eda las filas sin coincidencias (No Match) a la salida para que puedan ser procesadas o insertadas.</p> </li> <li> <p>Carga:   Los datos transformados y enriquecidos se env\u00edan a un destino ADO.NET, que inserta los registros en la tabla <code>[Transversal].[FACT_ENCUESTAS_PSR]</code>. Este componente utiliza la carga masiva (Bulk Insert) para optimizar el rendimiento, con un CommandTimeout configurado a 30 segundos y sin l\u00edmites en el tama\u00f1o del lote.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant FlatFile as Flat File Source\n    participant Convert as Data Conversion\n    participant Lookup as Varios Lookups\n    participant Destination as Destino ADO.NET\n\n    FlatFile -&gt;&gt; Convert: Lee y convierte datos (FECHA_ENCUESTA, DOCUMENTO, etc.)\n    Convert -&gt;&gt; Lookup: Env\u00eda datos para enriquecimiento mediante Lookups\n    Lookup -&gt;&gt; Destination: Env\u00eda registros enriquecidos (con ID_FECHA, ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE)\n    Destination -&gt;&gt; Destination: Inserta datos en [Transversal].[FACT_ENCUESTAS_PSR]</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/","title":"03. COLEGIO_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#colegio_dimensiones","title":"COLEGIO_DIMENSIONES","text":"<p>El paquete SSIS \"03-COLEGIO_DIMENSIONES\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar informaci\u00f3n relacionada con dimensiones clave del \u00e1mbito educativo, tales como a\u00f1os acad\u00e9micos, planes curriculares, poblaci\u00f3n matriculada y libros. Este paquete asegura un flujo de trabajo robusto y automatizado que consolida datos provenientes de m\u00faltiples fuentes, garantizando su calidad e integridad en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El prop\u00f3sito principal del paquete es estructurar y centralizar datos educativos cr\u00edticos, asegurando su disponibilidad y consistencia para an\u00e1lisis estrat\u00e9gicos y toma de decisiones operativas.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>FACT_ESTADO_MATRICULAS</code>, <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_LIBROS</code>, <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Archivos Excel:</li> <li>Informaci\u00f3n sobre libros (<code>AM-EDF-153</code>).</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB para extracci\u00f3n y carga.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>B\u00fasquedas (<code>Lookup</code>):<ul> <li>Garantiza la consistencia mediante validaciones en tablas maestras como <code>DIM_PLAN_CURRICULAR</code> y <code>DIM_LIBROS</code>.</li> </ul> </li> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Genera claves auxiliares y valores predeterminados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_ANIO_ACADEMICO</code></li> <li><code>DIM_PLAN_CURRICULAR</code></li> <li><code>DIM_LIBROS</code></li> <li><code>DIM_POBLACION_MATRICULA</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Uso de scripts Python para automatizar tareas de descarga y validaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_ANIO_ACADEMICO:</p> <ul> <li><code>ANIO_ACADEMICO</code>: A\u00f1os acad\u00e9micos \u00fanicos extra\u00eddos de <code>FACT_ESTADO_MATRICULAS</code>.</li> </ul> </li> <li> <p>DIM_PLAN_CURRICULAR:</p> <ul> <li><code>COD_ASIGNATURA_SAP</code>, <code>ANIO_ACADEMICO</code>, <code>ASIGNATURA</code>, <code>PLAN_ESTUDIOS</code>.</li> </ul> </li> <li> <p>DIM_LIBROS:</p> <ul> <li><code>CODIGO_BARRAS</code>, <code>ITEM</code>, <code>TITULO</code>, <code>AUTOR</code>.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA:</p> <ul> <li><code>ID_POBLACION_MATRICULA</code>, <code>PARTNER</code>, <code>DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant FACT as FACT_ESTADO_MATRICULAS\n    participant PLAN as DIM_PLAN_CURRICULAR\n    participant LIBROS as DIM_LIBROS\n    participant POBLACION as DIM_POBLACION_MATRICULA\n\n    FACT -&gt;&gt; PLAN: Validaci\u00f3n de a\u00f1os acad\u00e9micos\n    PLAN -&gt;&gt; DIM_PLAN_CURRICULAR: Transformaci\u00f3n y carga\n    LIBROS -&gt;&gt; DIM_LIBROS: Datos transformados\n    POBLACION -&gt;&gt; DIM_POBLACION_MATRICULA: Inserci\u00f3n de datos</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#2-diagrama-er-para-tablas-de-dimensiones","title":"2. Diagrama ER para Tablas de Dimensiones","text":"<pre><code>erDiagram\n    DIM_ANIO_ACADEMICO {\n        int ANIO_ACADEMICO\n    }\n    DIM_PLAN_CURRICULAR {\n        string COD_ASIGNATURA_SAP\n        int ANIO_ACADEMICO\n        string ASIGNATURA\n        string PLAN_ESTUDIOS\n    }\n    DIM_LIBROS {\n        string CODIGO_BARRAS\n        string ITEM\n        string TITULO\n        string AUTOR\n    }\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION_MATRICULA\n        string PARTNER\n        string DOCUMENTO\n        string NOMBRE_COMPLETO\n    }\n    DIM_ANIO_ACADEMICO ||--|| DIM_PLAN_CURRICULAR : \"Relaciona a\u00f1os acad\u00e9micos\"\n    DIM_PLAN_CURRICULAR ||--|| DIM_LIBROS : \"Relaci\u00f3n con libros\"\n    DIM_LIBROS ||--|| DIM_POBLACION_MATRICULA : \"Asociaci\u00f3n de datos\"</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-poblar-dim_anio_academico","title":"Componente <code>Poblar DIM_ANIO_ACADEMICO</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Poblar DIM_ANIO_ACADEMICO</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_ANIO_ACADEMICO</code>. Este flujo incluye procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL) para garantizar datos limpios y estructurados en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>FACT_ESTADO_MATRICULAS</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde la tabla <code>FACT_ESTADO_MATRICULAS</code> en el esquema <code>Colegio</code> para generar un conjunto de a\u00f1os acad\u00e9micos \u00fanicos.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT DISTINCT [CA20_ANO_ACADEMICO] AS ANIO_ACADEMICO \nFROM [DWH_COMFENALCO].[Colegio].[FACT_ESTADO_MATRICULAS]\nORDER BY [CA20_ANO_ACADEMICO] ASC\n</code></pre></li> <li>Tiempo de espera: <code>30 segundos</code>.</li> <li>Permitir conversi\u00f3n impl\u00edcita de cadenas: <code>true</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code> (Tipo: Numeric, Precisi\u00f3n: 4).</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_ANIO_ACADEMICO</code> para determinar si un registro ya existe.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Colegio].[DIM_ANIO_ACADEMICO]\n</code></pre></li> <li>Comportamiento para filas sin coincidencias: Enviar filas a la salida sin coincidencias.</li> <li>Porcentaje de cach\u00e9 para filas sin coincidencias: <code>0%</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>ANIO_ACADEMICO</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code> (Coincidencias y sin coincidencias).</li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Separa los registros en diferentes flujos de datos seg\u00fan la existencia de coincidencias en el paso de b\u00fasqueda.</li> <li>Condiciones:<ul> <li><code>Agregar</code>: Filas donde <code>ANIO_ACADEMICO</code> es nulo (filas nuevas).</li> <li><code>Ya incluido</code>: Filas donde <code>ANIO_ACADEMICO</code> ya existe.</li> <li><code>Conditional Split Error Output</code>: Filas con errores o problemas.</li> </ul> </li> <li>Expresi\u00f3n de condici\u00f3n:     <pre><code>ISNULL(Lookup.ANIO_ACADEMICO)\n</code></pre></li> </ul> </li> <li>Destino de Datos ADO.NET (<code>DIM_ANIO_ACADEMICO</code>)<ul> <li>Descripci\u00f3n: Carga los registros nuevos en la tabla <code>DIM_ANIO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Colegio\".\"DIM_ANIO_ACADEMICO\"</code>.</li> <li>Tama\u00f1o del lote: <code>0</code> (por defecto).</li> <li>Tiempo de espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n masiva: Activada.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>ANIO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-procesar-dim_plan_curricular","title":"Componente <code>Procesar DIM_PLAN_CURRICULAR</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente <code>DIM_PLAN_CURRICULAR</code> es una tarea de flujo de datos en un paquete SSIS que procesa informaci\u00f3n relacionada con el plan curricular de asignaturas. Este flujo realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) para consolidar los datos desde un sistema fuente hacia una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>PLAN_CURRICULAR SAP</code>)</p> <ul> <li>Descripci\u00f3n: Este componente extrae datos desde el sistema SAP ERP, relacionado con asignaturas y planes de estudio.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>WITH Curriculum AS (\nSELECT\n    objid AS ID_PLAN_ESTUDIOS,\n    CASE\n        WHEN objid = '02000000' THEN 'PREESCOLAR'\n        WHEN objid = '02000001' THEN 'PRIMARIA'\n        WHEN objid = '02000003' THEN 'BASICA/MEDIA SECUNDARIA'\n        ELSE 'OTROS'\n    END AS PLAN_ESTUDIOS\nFROM SAPABAP1.HRP1000\nWHERE plvar = '01' -- Plan activos\n    AND Otype = 'SC' -- Plan de estudios\n    AND langu = 'S' -- Espa\u00f1ol\n),\nSubjects as(\nSELECT\n  a.objid AS OBJETO_SAP_ASIGNATURA,\n  a.sobid AS ID_PLAN_ESTUDIOS,\n  b.peryr AS ANIO_ACADEMICO\n FROM SAPABAP1.HRP1001 as a\n INNER join\n  SAPABAP1.HRP1739 as b On a.otype = b.otype AND  A.objid = b.objid\n WHERE a.plvar = '01' and --\u201cPlan activo\n  A.otype = 'SM' and --\u201cEstudios\n  a.sclas = 'SC' and\n  --a.sobid = PE and --(Par\u00e1metros)\n  b.peryr &gt;= 2021 and --(Par\u00e1metro\n  b.perid = '001'-- \u201cPer. Comfenalco\n),\nCurriculumDetails AS (\nSelect\n  aclevelvar AS PROGRAMA_PLAN_ESTUDIOS\n From SAPABAP1.HRP1730\n Where plvar = '01'\n),\nSubjectDetails AS (\n SELECT\n  objid AS OBJETO_SAP_ASIGNATURA,\n  short,\n  stext,\n  --*,\n  CASE\n    WHEN SUBSTRING(SHORT, 1, 2) IN ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11','JD','PJ','TR') THEN\n        CASE SUBSTRING(SHORT, 1, 2)\n            WHEN '01' THEN 1\n            WHEN '02' THEN 2\n            WHEN '03' THEN 3\n            WHEN '04' THEN 4\n            WHEN '05' THEN 5\n            WHEN '06' THEN 6\n            WHEN '07' THEN 10\n            WHEN '08' THEN 11\n            WHEN '09' THEN 12\n            WHEN '10' THEN 13\n            WHEN '11' THEN 14\n            WHEN 'JD' THEN 7\n            WHEN 'PJ' THEN 8\n            WHEN 'TR' THEN 9\n        END\n    ELSE '-1'\nEND AS ID_CURSO,\nCASE\n    WHEN SUBSTRING(SHORT, 1, 2) IN ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11','JD','PJ','TR') THEN\n        CASE SUBSTRING(SHORT, 1, 2)\n            WHEN '01' THEN 'PRIMERO'\n            WHEN '02' THEN 'SEGUNDO'\n            WHEN '03' THEN 'TERCERO'\n            WHEN '04' THEN 'CUARTO'\n            WHEN '05' THEN 'QUINTO'\n            WHEN '06' THEN 'SEXTO'\n            WHEN '07' THEN 'SEPTIMO'\n            WHEN '08' THEN 'OCTAVO'\n            WHEN '09' THEN 'NOVENO'\n            WHEN '10' THEN 'DECIMO'\n            WHEN '11' THEN 'ONCE'\n            WHEN 'JD' THEN 'PREJARD\u00cdN'\n            WHEN 'PJ' THEN 'JARD\u00cdN'\n            WHEN 'TR' THEN 'TRANSICI\u00d3N'\n        END\n    ELSE 'TRANSVERSAL'\nEND AS CURSO\n FROM SAPABAP1.hrp1000\n WHERE otype = 'SM'\n AND plvar = '01'\n)\nSELECT\nsd.short AS COD_ASIGNATURA_SAP,\ns.ANIO_ACADEMICO,\ns.OBJETO_SAP_ASIGNATURA,\nsd.stext AS ASIGNATURA,\nsd.ID_CURSO,\n--sd.CURSO,\ns.ID_PLAN_ESTUDIOS,\nc.PLAN_ESTUDIOS,\nsd.short || '_' || s.ANIO_ACADEMICO AS ID_ASIGNATURA_AUXILIAR\nFROM Subjects AS s\nINNER JOIN Curriculum AS c ON s.ID_PLAN_ESTUDIOS = c.ID_PLAN_ESTUDIOS\nINNER JOIN SubjectDetails AS sd ON s.OBJETO_SAP_ASIGNATURA = sd.OBJETO_SAP_ASIGNATURA\nORDER BY s.ANIO_ACADEMICO,sd.short\n</code></pre></li> <li>Tiempo de espera: <code>30 segundos</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[SAP_ERP]</code>.</li> <li>Columnas de Salida:<ul> <li><code>COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>OBJETO_SAP_ASIGNATURA</code></li> <li><code>ASIGNATURA</code></li> <li><code>ID_CURSO</code></li> <li><code>ID_PLAN_ESTUDIOS</code></li> <li><code>PLAN_ESTUDIOS</code></li> <li><code>ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada para garantizar la compatibilidad con las transformaciones posteriores.</li> <li>Columnas Convertidas:<ul> <li><code>COD_ASIGNATURA_SAP</code> \u2192 <code>Copy of COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code> \u2192 <code>Copy of ANIO_ACADEMICO</code></li> <li><code>OBJETO_SAP_ASIGNATURA</code> \u2192 <code>Copy of OBJETO_SAP_ASIGNATURA</code></li> <li><code>ASIGNATURA</code> \u2192 <code>Copy of ASIGNATURA</code></li> <li><code>ID_CURSO</code> \u2192 <code>Copy of ID_CURSO</code></li> <li><code>ID_PLAN_ESTUDIOS</code> \u2192 <code>Copy of ID_PLAN_ESTUDIOS</code></li> <li><code>PLAN_ESTUDIOS</code> \u2192 <code>Copy of PLAN_ESTUDIOS</code></li> <li><code>ID_ASIGNATURA_AUXILIAR</code> \u2192 <code>Copy of ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una comparaci\u00f3n de los datos con la tabla <code>DIM_PLAN_CURRICULAR</code> para enriquecer los datos en el flujo de trabajo.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT\n    [ID_ASIGNATURA],\n    [COD_ASIGNATURA_SAP],\n    [ANIO_ACADEMICO],\n    [COD_ASIGNATURA_SAP] + '_' + CAST([ANIO_ACADEMICO] AS NVARCHAR) AS ID_ASIGNATURA_AUXILIAR\nFROM [DWH_COMFENALCO].[Colegio].[DIM_PLAN_CURRICULAR]\n</code></pre></li> <li>Comportamiento para filas sin coincidencias: Enviar a la salida \"No Match Output\".</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>Copy of ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_ASIGNATURA</code></li> <li><code>COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_PLAN_CURRICULAR</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>DIM_PLAN_CURRICULAR</code> dentro del esquema <code>Colegio</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>\"Colegio\".\"DIM_PLAN_CURRICULAR\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code>.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activado (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>OBJETO_SAP_ASIGNATURA</code></li> <li><code>ASIGNATURA</code></li> <li><code>ID_CURSO</code></li> <li><code>ID_PLAN_ESTUDIOS</code></li> <li><code>PLAN_ESTUDIOS</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as PLAN_CURRICULAR SAP\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup\n    participant AdoNetDestination as DIM_PLAN_CURRICULAR\n\n    AdoNetSource -&gt;&gt; DataConversion: Salida de origen de ADO NET\n    DataConversion -&gt;&gt; Lookup: Data Conversion Output\n    Lookup -&gt;&gt; AdoNetDestination: Lookup No Match Output</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-truncar-tabla-temporal","title":"Componente <code>Truncar Tabla Temporal</code>","text":"<p>Este componente es una tarea de ejecuci\u00f3n de SQL (Execute SQL Task) en el paquete SSIS, dise\u00f1ada para limpiar la tabla temporal utilizada en el proceso ETL del m\u00f3dulo de Acudientes. Su funci\u00f3n principal es eliminar todos los registros de la tabla <code>[STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]</code> antes de iniciar la carga de nuevos datos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Limpieza de Datos:   El objetivo principal es vaciar la tabla temporal para eliminar registros residuales de ejecuciones anteriores, garantizando que la nueva carga de datos se realice sobre una tabla limpia.</p> </li> <li> <p>Garantizar la Integridad:   Al eliminar todos los datos anteriores, se evita la mezcla de informaci\u00f3n vieja y nueva, lo que contribuye a mantener la precisi\u00f3n y consistencia en el proceso ETL.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute SQL Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>SQL Statement: <pre><code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]\n</code></pre></li> <li>Conexi\u00f3n:   Se utiliza una conexi\u00f3n preconfigurada identificada por el GUID <code>{5972EC76-2533-4771-BB68-A92E1CDD645D}</code>, que apunta a la base de datos de destino.</li> </ul> </li> <li> <p>Datos del Objeto:</p> </li> <li>Conexi\u00f3n Utilizada: <code>{5972EC76-2533-4771-BB68-A92E1CDD645D}</code></li> <li>Sentencia SQL (c\u00f3digo): <pre><code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    Al iniciar el paquete SSIS, se ejecuta la tarea de SQL correspondiente.</p> </li> <li> <p>Ejecuci\u00f3n de la Sentencia SQL:    La sentencia <code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]</code> se env\u00eda a la base de datos mediante el administrador de conexiones configurado.</p> </li> <li> <p>Limpieza de la Tabla:    La tabla temporal se vac\u00eda de forma r\u00e1pida y eficiente, sin registrar individualmente cada eliminaci\u00f3n, lo que mejora el rendimiento.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Una vez completada la operaci\u00f3n, la tarea finaliza, permitiendo que el proceso ETL contin\u00fae con las etapas siguientes de carga y transformaci\u00f3n.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SQLTask as Truncar Tabla Temporal\n    participant DB as Base de Datos\n\n    SQLTask -&gt;&gt; DB: Ejecuta \"TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]\"\n    DB --&gt;&gt; SQLTask: Confirmaci\u00f3n de limpieza</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-consulta-sap","title":"Componente <code>Consulta SAP</code>","text":"<p>Este componente es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS, dise\u00f1ada para extraer y consolidar datos provenientes del sistema SAP. Utiliza una consulta SQL compleja (con m\u00faltiples CTE) para obtener informaci\u00f3n detallada de los acudientes y estudiantes, integrando datos de diversas tablas de SAP y enriqueciendo la informaci\u00f3n mediante c\u00e1lculos y conversiones. La salida de este componente se utiliza para alimentar procesos de integraci\u00f3n posteriores en el flujo ETL.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente_1","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos desde SAP:   Recuperar informaci\u00f3n relevante de acudientes y estudiantes a partir de m\u00faltiples fuentes de datos en el sistema SAP. Esto incluye datos personales, detalles de contactos (tel\u00e9fonos, direcciones y correos electr\u00f3nicos) y claves de identificaci\u00f3n para su posterior vinculaci\u00f3n en el proceso ETL.</p> </li> <li> <p>Consolidaci\u00f3n y Enriquecimiento:   Unir y transformar datos mediante CTEs para combinar informaci\u00f3n de tablas como HRP1001, BUT000, y otras, integrando adem\u00e1s datos de contactos recientes (tel\u00e9fonos, direcciones y emails) y claves de estudiantes. Esto permite obtener un dataset completo que relaciona la informaci\u00f3n de acudientes con la de estudiantes y sus datos asociados.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica_1","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Data Flow Task (Pipeline).</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>SQL Command:   Se utiliza una instrucci\u00f3n SQL avanzada que emplea Common Table Expressions (CTE) para:</li> <li>PartnerDetails: Extraer detalles del acudiente, incluyendo datos personales, estado civil, profesi\u00f3n y fecha de nacimiento.  </li> <li>RecentPhones, RecentAddresses y RecentEmails: Obtener la informaci\u00f3n de contacto m\u00e1s reciente para cada acudiente.  </li> <li>StudentKeys: Relacionar el acudiente con el estudiante mediante claves SAP.</li> </ul> <p>La consulta finaliza uniendo estos conjuntos de datos para producir un resultado consolidado con campos tales como:   - <code>BP_ACUDIENTE</code>, <code>OBJETO_SAP_ESTUDIANTE</code>, <code>BP_ESTUDIANTE</code>, <code>NUMERO_MATRICULA</code>   - <code>TIPO_DOCUMENTO</code>, <code>NUMERO_DOCUMENTO</code>   - <code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code>   - <code>GENERO</code>, <code>ESTADO_CIVIL</code>, <code>PROFESION</code>, <code>FECHA_NACIMIENTO</code>   - <code>PARENTESCO</code>, <code>RESPONSABLE_JURIDICO</code>   - <code>TELEFONO</code>, <code>PAIS</code>, <code>CIUDAD</code>, <code>DIRECCION</code>, <code>CORREO</code></p> </li> <li> <p>Datos del Objeto:</p> <ul> <li>Conexi\u00f3n Utilizada:   Se conecta al sistema SAP a trav\u00e9s del administrador de conexiones configurado con el identificador de conexi\u00f3n <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code> y el nombre de conexi\u00f3n <code>SAP_ERP</code>.</li> <li>Modo de Acceso:   Utiliza el proveedor de datos .NET (DataReaderSourceAdapter) para ejecutar la consulta y extraer el conjunto de resultados.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion_1","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    El componente inicia la ejecuci\u00f3n de la consulta SQL definida en la propiedad <code>SqlCommand</code>.</p> </li> <li> <p>Extracci\u00f3n y Transformaci\u00f3n:    La consulta se ejecuta contra el sistema SAP y, mediante el uso de CTEs, extrae y transforma los datos, uniendo informaci\u00f3n de diferentes or\u00edgenes (detalles del acudiente, datos de contacto y claves de estudiante).</p> </li> <li> <p>Salida de Datos:    El conjunto de resultados, con las columnas transformadas y consolidadas, se expone en la salida del componente (\"Salida de origen de ADO NET\"), que posteriormente alimenta otros procesos o destinos dentro del flujo ETL.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SAPData as Componente ACUDIENTES SAP\n    participant SAP as Sistema SAP (ERP)\n    participant Dest as Destino de datos (TMP_ACUDIENTES_SAP)\n\n    SAPData -&gt;&gt; SAP: Ejecuta consulta SQL consolidada\n    SAP --&gt;&gt; SAPData: Retorna conjunto de resultados con datos de acudientes y estudiantes\n    SAPData -&gt;&gt; Dest: Transfiere datos transformados para carga posterior</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-actualizar-dim_acudientes","title":"Componente <code>Actualizar DIM_ACUDIENTES</code>","text":"<p>Este componente es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS, dise\u00f1ada para actualizar la dimensi\u00f3n de acudientes en el \u00e1mbito Colegio. Su funci\u00f3n principal es leer los datos consolidados en la tabla temporal de staging (<code>TMP_ACUDIENTES_SAP</code>), compararlos con la dimensi\u00f3n existente (<code>DIM_ACUDIENTES</code>) y cargar \u00fanicamente los registros nuevos o actualizados en la tabla de destino. Esto garantiza la integridad y actualizaci\u00f3n de la informaci\u00f3n de acudientes en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente_2","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Integraci\u00f3n de Datos de Acudientes:   Actualizar la dimensi\u00f3n <code>DIM_ACUDIENTES</code> en el esquema Colegio, asegur\u00e1ndose de que s\u00f3lo se inserten los registros nuevos o modificados que no est\u00e9n ya presentes en la dimensi\u00f3n. Esto permite mantener una base de datos actualizada y libre de duplicidades.</p> </li> <li> <p>Validaci\u00f3n y Consolidaci\u00f3n de la Informaci\u00f3n:   El proceso realiza una comparaci\u00f3n entre los datos provenientes de la tabla temporal en staging y la dimensi\u00f3n existente para filtrar registros ya cargados, permitiendo la actualizaci\u00f3n s\u00f3lo de la informaci\u00f3n faltante o modificada.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica_2","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Data Flow Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>Destino de ADO NET:   Se utiliza un componente de destino ADO.NET para cargar los registros en la tabla de destino.</li> <li>TableOrViewName:     La tabla destino se define mediante la expresi\u00f3n:     <pre><code>\"Colegio\".\"DIM_ACUDIENTES\"\n</code></pre></li> <li>BatchSize:     Se configura a <code>0</code>, utilizando el tama\u00f1o del b\u00fafer interno de SSIS.</li> <li>CommandTimeout:     Establecido en <code>30</code> segundos.</li> <li>UseBulkInsertWhenPossible:     Activado para mejorar el rendimiento durante la inserci\u00f3n masiva de datos.</li> </ul> </li> <li> <p>Conexi\u00f3n:     La tarea se conecta a la base de datos destino mediante el administrador de conexiones configurado con el identificador <code>{C2A27DDB-56C2-4889-8A4B-7AA7124DFFD7}</code> y el nombre de conexi\u00f3n <code>DWH_COMFENALCO_Destino</code>.</p> </li> <li> <p>Origen de Datos:     El componente extrae los datos desde la tabla temporal <code>[STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]</code> mediante un origen ADO.NET. La consulta de origen realiza un LEFT JOIN con la dimensi\u00f3n existente <code>[Colegio].[DIM_ACUDIENTES]</code> y un INNER JOIN con <code>[DIM_POBLACION_MATRICULA]</code> para asegurar que:</p> <ul> <li>Se seleccionen \u00fanicamente los registros en los que no existe coincidencia en <code>DIM_ACUDIENTES</code> (es decir, los registros nuevos).</li> <li>Se asegure que el campo <code>ID_POBLACION_MATRICULA</code> tenga un valor v\u00e1lido.</li> </ul> </li> <li> <p>Flujo de Datos:   Los datos fluyen desde el origen (la consulta en la tabla temporal) hacia el destino de ADO.NET, garantizando que s\u00f3lo se carguen los registros que a\u00fan no han sido incorporados en la dimensi\u00f3n.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion_2","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Extracci\u00f3n de Datos:    El componente de origen ADO.NET ejecuta la consulta SQL para leer los datos desde <code>[STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]</code> que cumplen las condiciones de actualizaci\u00f3n.</p> </li> <li> <p>Validaci\u00f3n de Registros:    Se realiza un cruce impl\u00edcito (mediante la consulta SQL) que descarta los registros cuyo <code>BP_ESTUDIANTE</code> ya existe en la dimensi\u00f3n <code>[Colegio].[DIM_ACUDIENTES]</code> y que garantiza que <code>ID_POBLACION_MATRICULA</code> sea v\u00e1lido.</p> </li> <li> <p>Carga de Datos:    Los registros que cumplen con las condiciones (nuevos o no encontrados en la dimensi\u00f3n) se cargan en la tabla <code>\"Colegio\".\"DIM_ACUDIENTES\"</code> utilizando la opci\u00f3n de Bulk Insert para optimizar el rendimiento.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen de ADO NET (TMP_ACUDIENTES_SAP)\n    participant Transform as Proceso de Validaci\u00f3n y Filtrado\n    participant Dest as Destino de ADO NET (DIM_ACUDIENTES)\n\n    Origen -&gt;&gt; Transform: Extrae datos desde TMP_ACUDIENTES_SAP\n    Transform -&gt;&gt; Transform: Compara registros con DIM_ACUDIENTES y DIM_POBLACION_MATRICULA\n    Transform -&gt;&gt; Dest: Env\u00eda registros nuevos para inserci\u00f3n\n    Dest -&gt;&gt; Dest: Inserta datos en \"Colegio\".\"DIM_ACUDIENTES\"</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-descargar_am-edf-153","title":"Componente <code>Descargar_AM-EDF-153</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_AM-EDF-153</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para conectar a SharePoint y descargar archivos manuales relacionados con el proyecto. Esta tarea utiliza la funcionalidad <code>Execute Process</code> de SSIS para garantizar una integraci\u00f3n fluida con sistemas externos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#detalles-del-componente","title":"Detalles del Componente","text":"<ol> <li> <p>Identificador del Componente:</p> <ul> <li>DTSID: <code>{dc092a95-1b4b-442c-9f34-b34054bbb72d}</code></li> </ul> </li> <li> <p>Tipo de Componente:</p> <ul> <li><code>Microsoft.ExecuteProcess</code></li> </ul> </li> <li> <p>Descripci\u00f3n:</p> <ul> <li>Tarea dise\u00f1ada para ejecutar un proceso externo, en este caso, un script Python que se conecta a SharePoint y descarga los archivos requeridos.</li> </ul> </li> <li> <p>Propiedades:</p> <ul> <li>Executable:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>WorkingDirectory:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\04.Colegio\n</code></pre></li> <li>Arguments:      <pre><code>01.SharePoint_Connection_AM-EDF-153.py\n</code></pre></li> </ul> </li> </ol> <p>Propiedades Avanzadas</p> <ol> <li> <p>Configuraciones de Expresi\u00f3n:</p> <ul> <li>Executable:      <pre><code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"\n</code></pre></li> <li>WorkingDirectory:      <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\04.Colegio\"\n</code></pre></li> </ul> </li> <li> <p>Detalles del Proceso:</p> <ul> <li>Ejecutable:<ul> <li>Ubicaci\u00f3n del script de Python a ejecutar.</li> </ul> </li> <li>Argumentos:<ul> <li>Nombre del archivo de script: <code>01.SharePoint_Connection_AM-EDF-153.py</code>.</li> </ul> </li> <li>Directorio de Trabajo:<ul> <li>Ruta donde se encuentra el script y los archivos necesarios para su ejecuci\u00f3n.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as Script de Python\n    participant SharePoint as Servidor SharePoint\n\n    SSIS-&gt;&gt;Python: Ejecutar `01.SharePoint_Connection_AM-EDF-153.py`\n    Python-&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Python: Confirmar conexi\u00f3n\n    Python-&gt;&gt;SharePoint: Descargar archivos\n    SharePoint--&gt;&gt;Python: Retornar archivos descargados\n    Python--&gt;&gt;SSIS: Confirmar finalizaci\u00f3n del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-procesar-dim_libros","title":"Componente <code>Procesar DIM_LIBROS</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar DIM_LIBROS</code> es una tarea de flujo de datos en un paquete SSIS que realiza operaciones ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) sobre informaci\u00f3n de libros. Los datos son extra\u00eddos desde un archivo de Excel, transformados mediante conversiones y columnas derivadas, y finalmente cargados en una base de datos destino. Adicionalmente, el flujo incluye una operaci\u00f3n de b\u00fasqueda (<code>Lookup</code>) para enriquecer los datos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>AM-EDF-153</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde una hoja de c\u00e1lculo Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code> (Modo de acceso directo)</li> <li><code>CommandTimeout</code>: <code>0</code> (Sin l\u00edmite de tiempo)</li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: Conexi\u00f3n a Excel referenciada por el administrador de conexiones <code>Excel_Connection_Dim_Libros</code>.</li> </ul> </li> <li>Columnas de Salida:     <code>CODIGO_BARRAS</code>, <code>ITEM</code>, <code>AUTOR</code>, <code>TITULO</code>.</li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte las columnas de datos para garantizar compatibilidad con los componentes posteriores.</li> <li>Columnas de Entrada:     <code>CODIGO_BARRAS</code>, <code>ITEM</code>, <code>AUTOR</code>, <code>TITULO</code>.</li> <li>Columnas de Salida:     <code>Copy of CODIGO_BARRAS</code>, <code>Copy of ITEM</code>, <code>Copy of AUTOR</code>, <code>Copy of TITULO</code>.</li> </ul> </li> <li> <p>Columna Derivada (<code>ID_LIBRO_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_LIBRO_AUXILIAR</code> combinando <code>CODIGO_BARRAS</code> e <code>ITEM</code>.</li> <li>Expresi\u00f3n Derivada:      <pre><code>CODIGO_BARRAS + \"_\" + ITEM\n</code></pre></li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_LIBROS</code> para enriquecer los datos con informaci\u00f3n adicional.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_LIBRO], [CODIGO_BARRAS]+'_'+[ITEM] AS ID_LIBRO_AUXILIAR\nFROM [DWH_COMFENALCO].[Colegio].[DIM_LIBROS]\n</code></pre></li> </ul> </li> <li>Columnas de Salida:     <code>ID_LIBRO</code>, <code>ID_LIBRO_AUXILIAR</code>.</li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_LIBROS</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>DIM_LIBROS</code> en la base de datos destino.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"DIM_LIBROS\"</code></li> <li><code>BatchSize</code>: <code>0</code> (Predeterminado)</li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Columnas de Entrada:     <code>Copy of CODIGO_BARRAS</code>, <code>Copy of ITEM</code>, <code>Copy of AUTOR</code>, <code>Copy of TITULO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as AM-EDF-153 (Fuente Excel)\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as ID_LIBRO_AUXILIAR\n    participant Lookup as Lookup\n    participant AdoNetDestination as DIM_LIBROS (Destino)\n\n    ExcelSource-&gt;&gt;DataConversion: Salida de datos Excel\n    DataConversion-&gt;&gt;DerivedColumn: Salida de datos convertidos\n    DerivedColumn-&gt;&gt;Lookup: Salida de columna derivada\n    Lookup-&gt;&gt;AdoNetDestination: Salida de b\u00fasqueda no coincidente</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-validar-si-existe-tabla-para-guardar","title":"Componente <code>Validar si existe tabla para guardar</code>","text":"<p>Este componente es una tarea de ejecuci\u00f3n de SQL (Execute SQL Task) dentro del paquete SSIS \"Procedimiento y Tabla para FACT_RETIROS\". Su funci\u00f3n es verificar si existe una tabla denominada RESULTS en el esquema actual y, en caso de que no exista, crearla. Esto asegura que, antes de iniciar el proceso de carga de datos para FACT_RETIROS, exista la estructura necesaria para almacenar los resultados.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente_3","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Verificaci\u00f3n y Creaci\u00f3n de Estructura:   Asegurarse de que la tabla RESULTS est\u00e9 presente en el entorno, creando la tabla si no existe, para evitar errores en fases posteriores del proceso ETL.</p> </li> <li> <p>Preparaci\u00f3n del Entorno de Carga:   Automatizar la validaci\u00f3n y provisi\u00f3n de la infraestructura de datos necesaria para la integraci\u00f3n y almacenamiento de la informaci\u00f3n de FACT_RETIROS.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica_3","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute SQL Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>SqlStatementSource:   El componente ejecuta la siguiente sentencia SQL para validar y crear la tabla en caso de ausencia:   <pre><code>-- Verificar si la tabla 'RESULTS' existe y crearla si no es as\u00ed\nDO\nBEGIN\n    DECLARE table_count INT;\n\n    SELECT COUNT(*) INTO table_count\n    FROM TABLES\n    WHERE TABLE_NAME = 'RESULTS' AND SCHEMA_NAME = CURRENT_SCHEMA;\n\n    IF table_count = 0 THEN\n        EXEC 'CREATE TABLE RESULTS (\n                OBJETO_SAP_ESTUDIANTE VARCHAR(20),\n                NUMERO_MATRICULA VARCHAR(20),\n                PARTNER_ESTUDIANTE VARCHAR(20),\n                ANIO_ACADEMICO VARCHAR(20),\n                APELLIDOS VARCHAR(50),\n                NOMBRES VARCHAR(50),\n                CURSO VARCHAR(20),\n                GRADO VARCHAR(20),\n                FECHA_RETIRO_SAP DATE,\n                FECHA_VALIDO_DESDE DATE,\n                FECHA_VALIDO_HASTA DATE\n              );';\n    END IF;\nEND;\n</code></pre></li> <li>Conexi\u00f3n:   Utiliza una conexi\u00f3n preconfigurada (identificada mediante el GUID <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>) que apunta al servidor de base de datos adecuado para ejecutar la sentencia SQL.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion_3","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    Al iniciar el paquete, se ejecuta la tarea de SQL para validar la existencia de la tabla RESULTS.</p> </li> <li> <p>Verificaci\u00f3n en la Base de Datos:    La tarea consulta el sistema de tablas para contar cu\u00e1ntas tablas con el nombre RESULTS existen en el esquema actual.</p> </li> <li> <p>Creaci\u00f3n Condicional:    Si el resultado es 0 (es decir, la tabla no existe), se ejecuta el comando SQL para crear la tabla con las columnas especificadas.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Tras la verificaci\u00f3n (y creaci\u00f3n, de ser necesaria), la tarea finaliza, permitiendo que el flujo ETL contin\u00fae con los siguientes pasos.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQLTask as Execute SQL Task\n    participant DB as Base de Datos\n\n    SSIS -&gt;&gt; SQLTask: Inicia \"Validar si existe tabla para guardar\"\n    SQLTask -&gt;&gt; DB: Ejecuta SQL para verificar existencia de \"RESULTS\"\n    DB --&gt;&gt; SQLTask: Devuelve el conteo de tablas\n    SQLTask -&gt;&gt; DB: Si no existe, ejecuta comando CREATE TABLE\n    DB --&gt;&gt; SQLTask: Confirma creaci\u00f3n (o existencia) de la tabla\n    SQLTask -&gt;&gt; SSIS: Finaliza la tarea</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-crear-procedimiento-anual","title":"Componente <code>Crear procedimiento anual</code>","text":"<p>Este componente es una tarea de ejecuci\u00f3n de SQL (Execute SQL Task) dentro del paquete SSIS \"Procedimiento y Tabla para FACT_RETIROS\". Su funci\u00f3n es verificar si existe el procedimiento almacenado GetRetirosByYear en el esquema actual y, de no existir, crearlo. Este procedimiento se utiliza para obtener los retiros filtrados por a\u00f1o, lo cual es fundamental para el proceso ETL relacionado con FACT_RETIROS.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente_4","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Verificaci\u00f3n y Creaci\u00f3n de Procedimiento:   Se asegura que el procedimiento GetRetirosByYear est\u00e9 definido en la base de datos antes de proceder con las operaciones de carga y procesamiento de datos de retiros.</p> </li> <li> <p>Preparaci\u00f3n del Entorno ETL:   Automatiza la creaci\u00f3n del procedimiento almacenado en caso de ausencia, lo que evita fallos en etapas posteriores del flujo ETL.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica_4","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute SQL Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>SqlStatementSource:   El componente ejecuta la siguiente sentencia SQL para verificar y crear el procedimiento:   <pre><code>-- Verificar si el procedimiento 'GetRetirosByYear' existe y crearlo si no es as\u00ed\nDO\nBEGIN\n    DECLARE proc_count INT;\n\n    SELECT COUNT(*) INTO proc_count\n    FROM PROCEDURES\n    WHERE PROCEDURE_NAME = 'GETRETIROSBYYEAR' AND SCHEMA_NAME = CURRENT_SCHEMA;\n\n    IF proc_count = 0 THEN\n        EXEC 'CREATE PROCEDURE GetRetirosByYear (IN P_YEAR INT)\n               LANGUAGE SQLSCRIPT\n               AS\n               BEGIN\n                   DECLARE valid_from_date NVARCHAR(8); \n                   valid_from_date := CONCAT(P_YEAR, ''0101'');\n                   INSERT INTO RESULTS\n                   SELECT \n                       DISTINCT \n                       h.objid AS OBJETO_SAP_ESTUDIANTE,\n                       p.short AS NUMERO_MATRICULA,\n                       b.PARTNER AS PARTNER_ESTUDIANTE,\n                       o.ayear AS ANIO_ACADEMICO,\n                       h.nachn AS APELLIDOS,\n                       h.vorna AS NOMBRES,\n                       i.prcl AS ID_CURSO,\n                       j.matrikel AS GRADO,\n                       m.END_KEY_DATE AS FECHA_RETIRO_SAP,\n                       i.mc_valid_from AS FECHA_VALIDO_DESDE,\n                       i.mc_valid_to AS FECHA_VALIDO_HASTA\n                   FROM SAPABAP1.hrp1702 AS h\n                   INNER JOIN SAPABAP1.hrp1000 AS p ON h.plvar = p.plvar AND h.otype = p.otype AND h.objid = p.objid AND h.endda = p.endda\n                   INNER JOIN SAPABAP1.hrp1705 AS j ON h.plvar = j.plvar AND h.otype = j.otype AND h.objid = j.objid AND h.endda = j.endda\n                   INNER JOIN SAPABAP1.hrp1737 AS k ON j.plvar = k.plvar AND j.otype = k.otype AND j.objid = k.objid AND j.endda = k.endda\n                   INNER JOIN SAPABAP1.hrt1737 AS i ON k.tabnr = i.tabnr\n                   INNER JOIN SAPABAP1.hrp1001 AS l ON l.plvar = h.plvar AND l.otype = h.otype AND l.objid = h.objid AND l.endda = h.endda\n                   INNER JOIN SAPABAP1.hrp1001 AS n ON n.plvar = l.plvar AND n.otype = l.sclas AND n.objid = l.sobid AND n.endda = l.endda\n                   INNER JOIN SAPABAP1.hrp1769 AS m ON m.plvar = n.plvar AND m.otype = n.otype AND m.objid = n.objid\n                   INNER JOIN SAPABAP1.hrp1771 AS o ON o.plvar = n.plvar AND o.otype = n.otype AND o.objid = n.objid\n                   INNER JOIN SAPABAP1.CMACBPST as b On p.objid = b.stobjid\n                   WHERE\n                       l.sclas = ''CS'' AND\n                       n.sclas = ''SC'' AND\n                       p.otype = ''ST'' AND\n                       p.plvar = ''01'' AND\n                       i.mc_valid_to &gt;= CURDATE() AND\n                       i.prog_type = ''4'' AND\n                       i.valid_from = valid_from_date AND\n                       m.begda &lt;= CURDATE() AND\n                       m.endda &lt;= CURDATE() AND\n                       o.prs_state = ''A'' AND\n                       o.ayear = P_YEAR AND\n                       m.END_PROCESS = ''RW01'' AND\n                       m.END_KEY_DATE &gt;= i.valid_from;\n               END;';\n    END IF;\nEND;\n</code></pre></li> <li>Conexi\u00f3n:   Se utiliza una conexi\u00f3n preconfigurada (identificada mediante el GUID <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>) que apunta al servidor de base de datos donde se encuentra el procedimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion_4","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    El paquete SSIS inicia la tarea de SQL \"Crear procedimiento anual\".</p> </li> <li> <p>Verificaci\u00f3n del Procedimiento:    La tarea consulta el cat\u00e1logo de procedimientos para determinar si GETRETIROSBYYEAR ya existe en el esquema actual.</p> </li> <li> <p>Creaci\u00f3n Condicional: </p> <ul> <li>Si el procedimiento no existe (conteo igual a 0), se ejecuta el comando SQL para crear el procedimiento almacenado con la definici\u00f3n especificada.</li> <li>Si ya existe, no se realiza ninguna acci\u00f3n adicional.</li> </ul> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    La tarea finaliza y el proceso ETL puede continuar con las siguientes etapas, sabiendo que la estructura necesaria para procesar los retiros est\u00e1 en su lugar.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQLTask as Execute SQL Task\n    participant DB as Base de Datos\n\n    SSIS -&gt;&gt; SQLTask: Inicia \"Crear procedimiento anual\"\n    SQLTask -&gt;&gt; DB: Ejecuta SQL para verificar existencia de 'GETRETIROSBYYEAR'\n    DB --&gt;&gt; SQLTask: Devuelve conteo de procedimientos\n    SQLTask -&gt;&gt; DB: Si no existe, ejecuta comando CREATE PROCEDURE\n    DB --&gt;&gt; SQLTask: Confirma creaci\u00f3n (o existencia) del procedimiento\n    SQLTask -&gt;&gt; SSIS: Finaliza la tarea</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/","title":"03 COLEGIO DIMENSIONES AUXILIAR","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#colegio_dimensiones_auxiliar","title":"COLEGIO_DIMENSIONES_AUXILIAR","text":"<p>El paquete SSIS \"03-COLEGIO_DIMENSIONES_AUXILIAR\" est\u00e1 dise\u00f1ado para gestionar la transferencia, transformaci\u00f3n y carga (ETL) de datos educativos relacionados con cursos, grados, poblaciones matriculadas y dimensiones de tiempo. Este paquete asegura que los datos provenientes de ambientes remotos se integren eficientemente en el Data Warehouse <code>DWH_COMFENALCO</code>, garantizando su calidad y disponibilidad para an\u00e1lisis.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es sincronizar y centralizar datos de dimensiones educativas clave, asegurando la consistencia y calidad de la informaci\u00f3n en el Data Warehouse. Esto facilita la toma de decisiones basada en datos para an\u00e1lisis operativos y estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos Remotas:</li> <li><code>DIM_CURSO</code>, <code>DIM_GRADO</code>, <code>DIM_POBLACION_MATRICULA</code>, <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET para lectura de datos remotos.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaci\u00f3n de Registros:<ul> <li>Se asegura que los datos est\u00e9n completos antes de cargarlos.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con las tablas destino.</li> </ul> </li> <li>Inserciones Masivas (<code>Bulk Insert</code>):<ul> <li>Habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_CURSO</code></li> <li><code>DIM_GRADO</code></li> <li><code>DIM_POBLACION_MATRICULA</code></li> <li><code>DIM_TIEMPO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_CURSO:</p> <ul> <li><code>ID_CURSO</code>, <code>DESC_CURSO</code>, <code>FECHA_CREACION</code>, <code>ESTADO_REGISTRO</code>.</li> </ul> </li> <li> <p>DIM_GRADO:</p> <ul> <li><code>ID_GRADO</code>, <code>DESC_GRADO</code>, <code>FECHA_CREACION</code>, <code>ESTADO_REGISTRO</code>.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA:</p> <ul> <li><code>ID_POBLACION_MATRICULA</code>, <code>PARTNER</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>, <code>GENERO</code>, <code>DIRECCION</code>, <code>TELEFONO</code>, <code>CORREO</code>, <code>FECHA_NACIMIENTO</code>.</li> </ul> </li> <li> <p>DIM_TIEMPO:</p> <ul> <li><code>ID_FECHA</code>, <code>FECHA</code>, <code>DESC_FECHA</code>, <code>ID_SEMANA</code>, <code>DESC_SEMANA</code>, <code>ID_MES</code>, <code>DESC_MES</code>, <code>ID_ANIO</code>, <code>FESTIVO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant CURSO_ORIG as DIM_CURSO_ORIG\n    participant CURSO_DEST as DIM_CURSO_DEST\n    participant GRADO_ORIG as DIM_GRADO_ORIG\n    participant GRADO_DEST as DIM_GRADO_DEST\n    participant POB_ORIG as DIM_POBLACION_MATRICULA_ORIG\n    participant POB_DEST as DIM_POBLACION_MATRICULA_DEST\n    participant TIEMPO_ORIG as DIM_TIEMPO_ORIG\n    participant TIEMPO_DEST as DIM_TIEMPO_DEST\n\n    CURSO_ORIG -&gt;&gt; CURSO_DEST: Transferir datos de DIM_CURSO\n    GRADO_ORIG -&gt;&gt; GRADO_DEST: Transferir datos de DIM_GRADO\n    POB_ORIG -&gt;&gt; POB_DEST: Transferir datos de DIM_POBLACION_MATRICULA\n    TIEMPO_ORIG -&gt;&gt; TIEMPO_DEST: Transferir datos de DIM_TIEMPO</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#2-diagrama-er-para-tablas-de-dimensiones","title":"2. Diagrama ER para Tablas de Dimensiones","text":"<pre><code>erDiagram\n    DIM_CURSO {\n        int ID_CURSO\n        string DESC_CURSO\n        date FECHA_CREACION\n        string ESTADO_REGISTRO\n    }\n    DIM_GRADO {\n        int ID_GRADO\n        string DESC_GRADO\n        date FECHA_CREACION\n        string ESTADO_REGISTRO\n    }\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION_MATRICULA\n        string PARTNER\n        string TIPO_DOCUMENTO\n        string DOCUMENTO\n        string NOMBRE_COMPLETO\n        string GENERO\n        string DIRECCION\n        string TELEFONO\n        string CORREO\n        date FECHA_NACIMIENTO\n    }\n    DIM_TIEMPO {\n        int ID_FECHA\n        date FECHA\n        string DESC_FECHA\n        int ID_SEMANA\n        string DESC_SEMANA\n        int ID_MES\n        string DESC_MES\n        int ID_ANIO\n        boolean FESTIVO\n    }</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componente-traer-a-local-tablas-disponibles-en-ambiente-comfenalco","title":"Componente <code>Traer a local tablas disponibles en ambiente Comfenalco</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Traer a local tablas disponibles en ambiente Comfenalco</code> es una tarea de flujo de datos en un paquete SSIS que transfiere datos desde un origen en un ambiente remoto hacia tablas de destino en un ambiente local. Est\u00e1 dise\u00f1ado para extraer, transformar y cargar (ETL) datos de m\u00faltiples tablas relacionadas con cursos, grados y poblaciones matriculadas.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>DIM_CURSO_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de la tabla <code>[Colegio].[DIM_CURSO]</code> en un origen remoto utilizando ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Colegio].[DIM_CURSO]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_CURSO</code></li> <li><code>DESC_CURSO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_CURSO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos transformados en la tabla <code>[Colegio].[DIM_CURSO]</code> del ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Colegio\".\"DIM_CURSO\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_CURSO</code></li> <li><code>DESC_CURSO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos ADO.NET (<code>DIM_GRADO_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de la tabla <code>[Colegio].[DIM_GRADO]</code> en un origen remoto utilizando ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Colegio].[DIM_GRADO]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_GRADO</code></li> <li><code>DESC_GRADO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_GRADO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos transformados en la tabla <code>[Colegio].[DIM_GRADO]</code> del ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Colegio\".\"DIM_GRADO\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_GRADO</code></li> <li><code>DESC_GRADO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos ADO.NET (<code>DIM_POBLACION_MATRICULA_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code> en un origen remoto utilizando ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_POBLACION_MATRICULA</code></li> <li><code>PARTNER</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>GENERO</code></li> <li><code>DIRECCION</code></li> <li><code>TELEFONO</code></li> <li><code>CORREO</code></li> <li><code>FECHA_NACIMIENTO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_POBLACION_MATRICULA_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos transformados en la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code> del ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Colegio\".\"DIM_POBLACION_MATRICULA\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_POBLACION_MATRICULA</code></li> <li><code>PARTNER</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>GENERO</code></li> <li><code>DIRECCION</code></li> <li><code>TELEFONO</code></li> <li><code>CORREO</code></li> <li><code>FECHA_NACIMIENTO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#conexiones-entre-componentes","title":"Conexiones entre Componentes","text":"<ol> <li>DIM_CURSO_ORIG \u2192 DIM_CURSO_DEST </li> <li>DIM_GRADO_ORIG \u2192 DIM_GRADO_DEST </li> <li>DIM_POBLACION_MATRICULA_ORIG \u2192 DIM_POBLACION_MATRICULA_DEST</li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant CURSO_ORIG as DIM_CURSO_ORIG\n    participant CURSO_DEST as DIM_CURSO_DEST\n    participant GRADO_ORIG as DIM_GRADO_ORIG\n    participant GRADO_DEST as DIM_GRADO_DEST\n    participant POB_ORIG as DIM_POBLACION_MATRICULA_ORIG\n    participant POB_DEST as DIM_POBLACION_MATRICULA_DEST\n\n    CURSO_ORIG -&gt;&gt; CURSO_DEST: Transferencia de datos DIM_CURSO\n    GRADO_ORIG -&gt;&gt; GRADO_DEST: Transferencia de datos DIM_GRADO\n    POB_ORIG -&gt;&gt; POB_DEST: Transferencia de datos DIM_POBLACION_MATRICULA</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componente-traer-dim-tiempo-a-local","title":"Componente <code>Traer Dim Tiempo a Local</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente <code>Traer Dim Tiempo a Local</code> es un flujo de datos en SSIS dise\u00f1ado para transferir y cargar datos de la dimensi\u00f3n <code>DIM_TIEMPO</code> desde un ambiente remoto hacia un ambiente local. Este flujo est\u00e1 deshabilitado por defecto (<code>Disabled=\"True\"</code>), y su objetivo principal es mantener sincronizados los datos de tiempo.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>DIM_TIEMPO_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos de la tabla <code>[Dwh].[DIM_TIEMPO]</code> en un origen remoto utilizando una conexi\u00f3n ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Dwh].[DIM_TIEMPO]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:  <code>ID_FECHA</code>, <code>FECHA</code>, <code>DESC_FECHA</code>, <code>ID_SEMANA</code>, <code>DESC_SEMANA</code>, <code>ID_NO_MES</code>, <code>DESC_NO_MES</code>, <code>ID_MES</code>, <code>DESC_MES</code>, <code>DESC_MES_CORTA</code>, <code>ID_BIMESTRE</code>, <code>DESC_BIMESTRE</code>, <code>ID_TRIMESTRE</code>, <code>DESC_TRIMESTRE</code>, <code>ID_CUATRIMESTRE</code>, <code>DESC_CUATRIMESTRE</code>, <code>ID_SEMESTRE</code>, <code>DESC_SEMESTRE</code>, <code>ID_ANIO</code>, <code>ID_ANIO_ANT</code>, <code>NUM_DIA_SEMANA</code>, <code>FESTIVO</code>, <code>FECHA_CORTA</code></li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_TIEMPO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos extra\u00eddos y transformados en la tabla <code>[Dwh].[DIM_TIEMPO]</code> en el ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Dwh\".\"DIM_TIEMPO\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada: <code>ID_FECHA</code>, <code>FECHA</code>, <code>DESC_FECHA</code>, <code>ID_SEMANA</code>, <code>DESC_SEMANA</code>, <code>ID_NO_MES</code>, <code>DESC_NO_MES</code>, <code>ID_MES</code>, <code>DESC_MES</code>, <code>DESC_MES_CORTA</code>, <code>ID_BIMESTRE</code>, <code>DESC_BIMESTRE</code>, <code>ID_TRIMESTRE</code>, <code>DESC_TRIMESTRE</code>, <code>ID_CUATRIMESTRE</code>, <code>DESC_CUATRIMESTRE</code>, <code>ID_SEMESTRE</code>, <code>DESC_SEMESTRE</code>, <code>ID_ANIO</code>, <code>ID_ANIO_ANT</code>, <code>NUM_DIA_SEMANA</code>, <code>FESTIVO</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#conexiones-entre-componentes_1","title":"Conexiones entre Componentes","text":"<ol> <li>DIM_TIEMPO_ORIG \u2192 DIM_TIEMPO_DEST</li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant TIEMPO_ORIG as DIM_TIEMPO_ORIG\n    participant TIEMPO_DEST as DIM_TIEMPO_DEST\n\n    TIEMPO_ORIG -&gt;&gt; TIEMPO_DEST: Transferencia de datos DIM_TIEMPO</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/","title":"04. COLEGIO_FACT","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#colegio_fact","title":"COLEGIO_FACT","text":"<p>El paquete SSIS \"04-COLEGIO_FACT\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar datos cr\u00edticos relacionados con operaciones educativas en diversas \u00e1reas como matr\u00edculas, transporte, biblioteca y evaluaciones. Este paquete asegura la integraci\u00f3n efectiva de datos en el Data Warehouse <code>DWH_COMFENALCO</code>, garantizando su calidad y disponibilidad para an\u00e1lisis y reportes estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es consolidar informaci\u00f3n operativa y educativa para apoyar la toma de decisiones basada en datos. Esto incluye la transformaci\u00f3n de datos de diversas fuentes, su validaci\u00f3n y enriquecimiento antes de su carga en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos SAP y SQL Server:</li> <li><code>FACT_TRANSPORTE</code>, <code>FACT_CUPOS_NEGADOS</code>, <code>FACT_AUSENTISMO_DOCENTE</code>, <code>FACT_BIBLIOTECA</code>.</li> <li>Archivos Excel:</li> <li>Informaci\u00f3n de permisos, ausentismo, y evaluaciones.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB para extracci\u00f3n y carga.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaci\u00f3n de Datos (<code>Lookup</code>):<ul> <li>Comprobaci\u00f3n en tablas maestras como <code>DIM_POBLACION_MATRICULA</code>, <code>DIM_CURSO</code>, y <code>DIM_LIBROS</code>.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>C\u00e1lculo de identificadores \u00fanicos y asignaciones condicionales.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>FACT_TRANSPORTE</code></li> <li><code>FACT_CUPOS_NEGADOS</code></li> <li><code>FACT_BIBLIOTECA</code></li> <li><code>FACT_PERMISO_ESTUDIANTE</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Uso de scripts Python para automatizaci\u00f3n de descargas y validaci\u00f3n de datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>FACT_TRANSPORTE:</p> <ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ID_FECHA</code>, <code>ANIO_ACADEMICO</code>, <code>CATEGORIA_SERVICIO</code>.</li> </ul> </li> <li> <p>FACT_CUPOS_NEGADOS:</p> <ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_ESTADO</code>.</li> </ul> </li> <li> <p>FACT_BIBLIOTECA:</p> <ul> <li><code>ITEM_LIBRO</code>, <code>FECHA_PRESTAMO</code>, <code>FECHA_DEVOLUCION</code>, <code>BP_ESTUDIANTE</code>.</li> </ul> </li> <li> <p>FACT_PERMISO_ESTUDIANTE:</p> <ul> <li><code>BP_ESTUDIANTE</code>, <code>FECHA_PERMISO</code>, <code>MOTIVO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de SAP y SQL Server\n    SSIS -&gt;&gt; Excel: Leer informaci\u00f3n operativa y educativa\n    SSIS -&gt;&gt; Python: Automatizar descargas\n    SSIS -&gt;&gt; DWH: Cargar datos procesados</code></pre> <ol> <li>Diagrama ER para Tablas de Hechos</li> </ol> <pre><code>erDiagram\n    FACT_TRANSPORTE {\n        string PARTNER_ESTUDIANTE\n        date FECHA_INICIO_SERVICIO\n        int ANIO_ACADEMICO\n        string CATEGORIA_SERVICIO\n    }\n    FACT_CUPOS_NEGADOS {\n        string PARTNER_ESTUDIANTE\n        int ANIO_ACADEMICO\n        date FECHA_ESTADO\n    }\n    FACT_BIBLIOTECA {\n        string ITEM_LIBRO\n        date FECHA_PRESTAMO\n        string BP_ESTUDIANTE\n    }\n    FACT_PERMISO_ESTUDIANTE {\n        string BP_ESTUDIANTE\n        date FECHA_PERMISO\n        string MOTIVO\n    }\n    FACT_TRANSPORTE ||--|| FACT_CUPOS_NEGADOS : \"Relaci\u00f3n de estudiantes\"\n    FACT_BIBLIOTECA ||--|| FACT_PERMISO_ESTUDIANTE : \"Conexi\u00f3n por estudiantes\"</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-01-fact_enfermeria","title":"Componente <code>EP-EDF-01 FACT_ENFERMERIA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-01 FACT_ENFERMERIA</code> es un proceso de ejecuci\u00f3n en un paquete SSIS dise\u00f1ado para correr un script de Python que realiza tareas relacionadas con la descarga de informaci\u00f3n para la facturaci\u00f3n de enfermer\u00eda. El componente utiliza una ruta espec\u00edfica y argumentos para ejecutar el script.</p> <p>Detalles del Componente</p> <ul> <li>Nombre del Componente: EP-EDF-01 FACT_ENFERMERIA</li> <li>Tipo: Execute Process Task</li> <li>Descripci\u00f3n: Ejecuta un script de Python encargado de descargar datos espec\u00edficos relacionados con el proceso <code>EP-EDF-01</code>.</li> <li>ID del Componente: <code>{4412de09-7ca0-4c06-ab1a-20e07c589832}</code></li> </ul> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-01</code> Tiempo de Espera No especificado (valor predeterminado) ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-01</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-01`\n    Python -&gt;&gt; Python: Descarga datos de `EP-EDF-01`\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-02-fact_ausentismo_docente","title":"Componente <code>EP-EDF-02 FACT_AUSENTISMO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-02 FACT_AUSENTISMO_DOCENTE</code> es un proceso dise\u00f1ado para ejecutar un script de Python que gestiona la descarga de informaci\u00f3n relacionada con el ausentismo docente. El componente utiliza configuraciones din\u00e1micas para el ejecutable y el directorio de trabajo, maximizando la flexibilidad y portabilidad dentro del entorno del proyecto.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-02 FACT_AUSENTISMO_DOCENTE Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python que descarga datos relacionados con el ausentismo docente. ID del Componente <code>{34225bf4-f1be-4808-9dfa-a648f4e220fc}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-02</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_1","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-02</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-02`\n    Python -&gt;&gt; Python: Descarga datos relacionados con ausentismo docente\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-03-fact_reemplazo_docente","title":"Componente <code>EP-EDF-03 FACT_REEMPLAZO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-03 FACT_REEMPLAZO_DOCENTE</code> es un componente dise\u00f1ado para ejecutar un script de Python. Su prop\u00f3sito es gestionar la descarga de informaci\u00f3n relacionada con el reemplazo docente. Utiliza configuraciones din\u00e1micas a trav\u00e9s de variables de proyecto, lo que garantiza flexibilidad y adaptabilidad dentro del entorno de desarrollo.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-03 FACT_REEMPLAZO_DOCENTE Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python que descarga datos relacionados con el reemplazo docente. ID del Componente <code>{df155a7f-6a3b-4e31-af0d-7b07113807e9}</code> <p>Propiedades Principales Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-03</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_2","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-03</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-03`\n    Python -&gt;&gt; Python: Descarga datos relacionados con reemplazo docente\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-04-fact_permiso_estudiante","title":"Componente <code>EP-EDF-04 FACT_PERMISO_ESTUDIANTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-04 FACT_PERMISO_ESTUDIANTE</code> es un componente que ejecuta un script de Python para descargar datos relacionados con permisos estudiantiles. Este componente utiliza variables din\u00e1micas de proyecto para definir tanto el ejecutable como el directorio de trabajo, asegurando flexibilidad y adaptabilidad al entorno.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-04 FACT_PERMISO_ESTUDIANTE Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python que descarga datos relacionados con permisos estudiantiles. ID del Componente <code>{2c32b9c0-798a-4bd5-a1e9-8b0351f2e222}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-04</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_3","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-04</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-04`\n    Python -&gt;&gt; Python: Descarga datos relacionados con permisos estudiantiles\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-05-fact_biblioteca","title":"Componente <code>EP-EDF-05 FACT_BIBLIOTECA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-05 FACT_BIBLIOTECA</code> es un componente que ejecuta un script de Python dise\u00f1ado para gestionar datos relacionados con la biblioteca del sistema. Este componente utiliza variables din\u00e1micas de proyecto para configurar el ejecutable y el directorio de trabajo, proporcionando flexibilidad en diferentes entornos.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-05 FACT_BIBLIOTECA Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python para gestionar datos de la biblioteca. ID del Componente <code>{93de8c31-f735-482b-9d44-ae33924b8a70}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-05</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_4","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-05</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-05`\n    Python -&gt;&gt; Python: Descarga datos de la biblioteca\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-06-fact_biblioteca_virtual","title":"Componente <code>EP-EDF-06 FACT_BIBLIOTECA_VIRTUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente <code>EP-EDF-06 FACT_BIBLIOTECA_VIRTUAL</code> est\u00e1 dise\u00f1ado para ejecutar un script de Python que gestiona la descarga de datos relacionados con la biblioteca virtual en el sistema. Este componente utiliza propiedades din\u00e1micas configuradas a nivel de proyecto, lo que permite flexibilidad en su uso en diferentes entornos.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-06 FACT_BIBLIOTECA_VIRTUAL Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python para gestionar datos de la biblioteca virtual. ID del Componente <code>{d22a6787-565a-4722-8ab0-acea586c4bfd}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-06</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_5","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-06</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-06`\n    Python -&gt;&gt; Python: Descarga datos de la biblioteca virtual\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-07-fact_saber11_individual","title":"Componente <code>EP-EDF-07 FACT_SABER11_INDIVIDUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente <code>EP-EDF-07 FACT_SABER11_INDIVIDUAL</code> ejecuta un script de Python que gestiona la descarga y procesamiento de informaci\u00f3n relacionada con las evaluaciones Saber 11 individuales. Este componente utiliza variables de proyecto para configurar el ejecutable y el directorio de trabajo, lo que garantiza flexibilidad en diferentes entornos.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-07 FACT_SABER11_INDIVIDUAL Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python para gestionar datos de evaluaciones Saber 11 individuales. ID del Componente <code>{47f926b0-8b2b-497d-bed6-90dc0e6f9d7c}</code> <p>Propiedades Principales</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-07</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_6","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-07</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-07`\n    Python -&gt;&gt; Python: Descarga y procesa datos de evaluaciones Saber 11\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-08-fact_saber11_colegios","title":"Componente <code>EP-EDF-08 FACT_SABER11_COLEGIOS</code>","text":"<p>Este componente es una tarea de proceso (Execute Process Task) dentro del paquete SSIS, dise\u00f1ado para ejecutar un script de Python que gestiona la descarga y procesamiento de datos relacionados con las evaluaciones SABER 11 a nivel de colegios. La tarea se configura din\u00e1micamente mediante expresiones de proyecto, lo que permite adaptar la ruta del ejecutable y el directorio de trabajo a diferentes entornos (por ejemplo, desarrollo, pruebas y producci\u00f3n).</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-08</code> que se encarga de conectarse a la fuente de datos (por ejemplo, un servicio o archivo remoto) para extraer informaci\u00f3n de evaluaciones SABER 11 de colegios.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar de manera automatizada la extracci\u00f3n y transformaci\u00f3n de datos en el flujo ETL de la soluci\u00f3n SSIS, facilitando la consolidaci\u00f3n y actualizaci\u00f3n de la informaci\u00f3n en el Data Warehouse.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-tecnica","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute Process Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>Executable:   Se define din\u00e1micamente la ruta del ejecutable de Python mediante la siguiente expresi\u00f3n:   <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory:   Se establece la ruta de trabajo din\u00e1mica para el script, concatenando la variable de proyecto correspondiente:   <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments:   El script a ejecutar es:   <pre><code>download.py --key EP-EDF-08\n</code></pre></li> </ul> </li> <li> <p>Datos del Objeto:</p> <ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#flujo-de-ejecucion","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso sigue los siguientes pasos:</p> <ol> <li> <p>Inicio de la Tarea:    El paquete SSIS inicia la tarea de proceso configurada para ejecutar el script.</p> </li> <li> <p>Ejecuci\u00f3n del Script Python:    Se invoca el ejecutable de Python con el argumento <code>download.py --key EP-EDF-08</code> en el directorio de trabajo especificado. El script se encarga de conectarse al sistema de origen, extraer y procesar los datos de evaluaciones SABER 11 para colegios.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Una vez finalizada la ejecuci\u00f3n del script, la tarea devuelve el c\u00f3digo de retorno y el flujo ETL contin\u00faa con las siguientes operaciones definidas en el paquete.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant PythonScript as download.py --key EP-EDF-08\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-08 FACT_SABER11_COLEGIOS\n    ExecProcess -&gt;&gt; PythonScript: Ejecuta script de Python\n    PythonScript --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-09-fact_desempenho_docente","title":"Componente <code>EP-EDF-09 FACT_DESEMPENHO_DOCENTE</code>","text":"<p>Este componente ejecuta un script de Python encargado de descargar y procesar datos relacionados con el desempe\u00f1o docente. El script se invoca mediante la tarea de proceso, facilitando la integraci\u00f3n de la informaci\u00f3n de evaluaciones docentes en el flujo ETL.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-09</code> para obtener informaci\u00f3n sobre el desempe\u00f1o docente desde la fuente de datos, facilitando su an\u00e1lisis en el Data Warehouse.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar de manera automatizada la extracci\u00f3n de datos sobre desempe\u00f1o docente dentro del proceso ETL global, garantizando la actualizaci\u00f3n continua de la informaci\u00f3n.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <pre><code>download.py --key EP-EDF-09\n</code></pre></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-09\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-09 FACT_DESEMPENHO_DOCENTE\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-10-fact_legalizacion","title":"Componente <code>EP-EDF-10 FACT_LEGALIZACION</code>","text":"<p>Este componente ejecuta un script de Python que gestiona la descarga y procesamiento de datos relacionados con la legalizaci\u00f3n. Es parte de la consolidaci\u00f3n de informaci\u00f3n que alimenta el Data Warehouse, permitiendo la verificaci\u00f3n y validaci\u00f3n de registros legales.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-10</code> para obtener informaci\u00f3n legal desde la fuente, asegurando su preparaci\u00f3n para la integraci\u00f3n en el Data Warehouse.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Facilitar la actualizaci\u00f3n y consolidaci\u00f3n de datos de legalizaci\u00f3n mediante la automatizaci\u00f3n del proceso de extracci\u00f3n.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <code>plaintext   download.py --key EP-EDF-10</code></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-10\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-10 FACT_LEGALIZACION\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-11-fact_psiorientacion","title":"Componente <code>EP-EDF-11 FACT_PSIORIENTACION</code>","text":"<p>Este componente ejecuta un script de Python destinado a procesar datos de orientaci\u00f3n psicol\u00f3gica. Permite la extracci\u00f3n y transformaci\u00f3n de informaci\u00f3n que posteriormente se integrar\u00e1 en el Data Warehouse para el an\u00e1lisis de atenci\u00f3n psicol\u00f3gica.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-11</code> para extraer datos de orientaci\u00f3n psicol\u00f3gica, facilitando su posterior an\u00e1lisis y reporte.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Asegurar la actualizaci\u00f3n peri\u00f3dica de los datos de orientaci\u00f3n psicol\u00f3gica dentro del flujo ETL.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <pre><code>download.py --key EP-EDF-11\n</code></pre></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-11\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-11 FACT_PSIORIENTACION\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-12-fact_reserva_espacios","title":"Componente <code>EP-EDF-12 FACT_RESERVA_ESPACIOS</code>","text":"<p>Este componente ejecuta un script de Python que se encarga de la descarga y procesamiento de datos relacionados con la reserva de espacios educativos. El script facilita la consolidaci\u00f3n de la informaci\u00f3n de reservas para su posterior an\u00e1lisis y reporte.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-12</code> para obtener informaci\u00f3n de reservas de espacios, asegurando que los datos sean precisos y est\u00e9n listos para ser cargados en el Data Warehouse.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar autom\u00e1ticamente la extracci\u00f3n y transformaci\u00f3n de datos de reservas dentro del flujo ETL.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <pre><code>download.py --key EP-EDF-12\n</code></pre></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-12\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-12 FACT_RESERVA_ESPACIOS\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-13-fact_servicio_social","title":"Componente <code>EP-EDF-13 FACT_SERVICIO_SOCIAL</code>","text":"<p>Este componente ejecuta un script de Python encargado de descargar y procesar datos relacionados con el servicio social de los estudiantes. La tarea automatiza la integraci\u00f3n de estos datos en el flujo ETL, permitiendo su an\u00e1lisis y reporte en el Data Warehouse.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-13</code> para extraer informaci\u00f3n sobre el servicio social, transformarla y prepararla para su carga en el sistema.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Asegurar que la extracci\u00f3n de datos de servicio social se ejecute de forma autom\u00e1tica y peri\u00f3dica, integr\u00e1ndose en el proceso ETL global.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <pre><code>download.py --key EP-EDF-13\n</code></pre></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-13\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-13 FACT_SERVICIO_SOCIAL\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_transporte","title":"Componente <code>Procesar FACT_TRANSPORTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_TRANSPORTE</code> es una tarea de flujo de datos en un paquete SSIS que realiza procesos ETL para gestionar informaci\u00f3n de transporte. Este flujo extrae datos de SAP, realiza transformaciones mediante conversiones, divisiones condicionales y b\u00fasquedas, y finalmente carga los datos procesados en una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li>Fuente de Datos ADO.NET (<code>FACT_TRANSPORTE SAP</code>)<ul> <li>Descripci\u00f3n: Extrae datos de SAP mediante una consulta SQL.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>WITH TransportDetails AS (\n    SELECT OBJID AS OBJETO_SAP_ESTUDIANTE, BEGDA AS FECHA_INICIO_SERVICIO, \n           ENDDA AS FECHA_FIN_SERVICIO, BENCAT AS CATEGORIA_SERVICIO\n    FROM SAPABAP1.hrp1706 hh\n    WHERE PLVAR = '01' AND otype = 'ST' AND PDISCT2 = 'TRAN'\n), \nStudentKeys AS (\n    SELECT a.objid AS OBJETO_SAP_ESTUDIANTE, a.short AS NUMERO_MATRICULA,\n           b.PARTNER AS PARTNER_ESTUDIANTE\n    FROM SAPABAP1.HRP1000 AS a\n    INNER JOIN SAPABAP1.CMACBPST AS b ON a.objid = b.stobjid\n    WHERE a.plvar = 01 AND a.otype = 'ST' AND a.endda &gt;= CURDATE()\n)\nSELECT s.PARTNER_ESTUDIANTE, t.FECHA_INICIO_SERVICIO AS ID_FECHA,\n       YEAR(TO_DATE(t.FECHA_INICIO_SERVICIO, 'YYYYMMDD')) AS ANIO_ACADEMICO,\n       TO_DATE(t.FECHA_INICIO_SERVICIO, 'YYYYMMDD') AS FECHA_INICIO_SERVICIO,\n       TO_DATE(t.FECHA_FIN_SERVICIO, 'YYYYMMDD') AS FECHA_FIN_SERVICIO,\n       t.CATEGORIA_SERVICIO, 'SI' AS SERVICIO_TRANSPORTE,\n       s.PARTNER_ESTUDIANTE || '_' || TO_CHAR(t.FECHA_INICIO_SERVICIO, 'YYYYMMDD') AS ID_REGISTRO_AUXILIAR\nFROM TransportDetails AS t\nINNER JOIN StudentKeys AS S ON t.OBJETO_SAP_ESTUDIANTE = s.OBJETO_SAP_ESTUDIANTE\nWHERE t.FECHA_INICIO_SERVICIO &gt;= '20230101'\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: Conexi\u00f3n a SAP referenciada por <code>SAP_ERP</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ID_FECHA</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_INICIO_SERVICIO</code>, <code>FECHA_FIN_SERVICIO</code>, <code>CATEGORIA_SERVICIO</code>, <code>SERVICIO_TRANSPORTE</code>, <code>ID_REGISTRO_AUXILIAR</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>)<ul> <li>Descripci\u00f3n: Convierte columnas de entrada para garantizar compatibilidad con componentes posteriores.</li> <li>Columnas de Entrada:<ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ID_FECHA</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_INICIO_SERVICIO</code>, <code>FECHA_FIN_SERVICIO</code>, <code>SERVICIO_TRANSPORTE</code>, <code>ID_REGISTRO_AUXILIAR</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_INICIO_SERVICIO</code>, <code>Copy of FECHA_FIN_SERVICIO</code>, <code>Copy of SERVICIO_TRANSPORTE</code>, <code>Copy of ID_REGISTRO_AUXILIAR</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>B\u00fasquedas (<code>Lookup</code>)<ul> <li>Lookup <code>1</code>:<ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_TARIFAS_SERVICIOS</code>.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:   <pre><code>SELECT [ID_TARIFA], [CON_OBJETO_TARIFA], CAST([ANIO_TARIFA] AS INT) AS [ANIO_TARIFA]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_TARIFAS_SERVICIOS]\nWHERE [COD_INFRAESTRUCTURA_CCF] = 'CCF008-12-00001' AND UPPER([CON_OBJETO_TARIFA]) LIKE '%TRANSPORTE%'\n</code></pre></li> </ul> </li> </ul> </li> <li>Lookup <code>2</code>:<ul> <li>Descripci\u00f3n: Busca en <code>FACT_TRANSPORTE</code> utilizando la columna <code>ID_REGISTRO_AUXILIAR</code>.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:   <pre><code>SELECT [ID_REGISTRO], [BP_ESTUDIANTE], [ID_FECHA], [BP_ESTUDIANTE] + '_' + CONVERT(VARCHAR, [ID_FECHA], 112) AS [ID_REGISTRO_AUXILIAR]\nFROM [DWH_COMFENALCO].[Colegio].[FACT_TRANSPORTE]\n</code></pre></li> </ul> </li> </ul> </li> </ul> </li> </ol> <ol> <li>Divisi\u00f3n Condicional (<code>Conditional Split</code>)<ul> <li>Descripci\u00f3n: Separa filas en salidas distintas seg\u00fan condiciones espec\u00edficas.</li> <li>Condiciones:<ul> <li>Agregar: <code>!ISNULL(ID_TARIFA)</code></li> <li>No Agregar: Filas que no cumplen con la condici\u00f3n anterior.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Destino de Datos ADO.NET (<code>FACT_TRANSPORTE_DEST</code>)<ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_TRANSPORTE</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"FACT_TRANSPORTE\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_INICIO_SERVICIO</code>, <code>Copy of FECHA_FIN_SERVICIO</code>, <code>Copy of SERVICIO_TRANSPORTE</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Source as FACT_TRANSPORTE SAP (Fuente)\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup 1\n    participant ConditionalSplit as Conditional Split\n    participant Lookup2 as Lookup 2\n    participant Destination as FACT_TRANSPORTE_DEST (Destino)\n\n    Source -&gt;&gt; DataConversion: Datos extra\u00eddos\n    DataConversion -&gt;&gt; Lookup1: Datos convertidos\n    Lookup1 -&gt;&gt; ConditionalSplit: Datos enriquecidos\n    ConditionalSplit -&gt;&gt; Lookup2: Filas seleccionadas\n    Lookup2 -&gt;&gt; Destination: Datos finales</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_cupos_negados","title":"Componente <code>Procesar FACT_CUPOS_NEGADOS</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_CUPOS_NEGADOS</code> es un flujo de datos en un paquete SSIS que gestiona el procesamiento de informaci\u00f3n relacionada con cupos negados para estudiantes. Este flujo incluye extracci\u00f3n de datos desde SAP, transformaciones mediante conversiones, b\u00fasquedas y derivaci\u00f3n de columnas, finalizando con la carga de datos en una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li>Fuente de Datos ADO.NET (<code>FACT_CUPOS NEGADOS SAP</code>)<ul> <li>Descripci\u00f3n: Extrae datos desde SAP utilizando una consulta SQL.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>WITH StudentKeys AS (\n    SELECT a.objid AS OBJETO_SAP_ESTUDIANTE, \n           a.short AS NUMERO_MATRICULA,\n           b.PARTNER AS PARTNER_ESTUDIANTE,\n           a.STEXT AS NOMBRE_ESTUDIANTE\n    FROM SAPABAP1.HRP1000 AS a\n    INNER JOIN SAPABAP1.CMACBPST AS b ON a.objid = b.stobjid\n    WHERE a.plvar = 01 AND a.otype = 'ST' AND a.endda &gt;= CURDATE()\n),\nDeniedStudents AS (\n    SELECT OBJID AS OBJETO_SAP_ESTUDIANTE, \n           HS_PERYR AS ANIO_ACADEMICO, \n           AEDTM AS FECHA_ESTADO\n    FROM SAPABAP1.HRP1728 AS h\n    WHERE plvar = '01' AND otype = 'ST' AND SUBTY = '9060' AND HS_STATE = 'A'\n)\nSELECT sk.NUMERO_MATRICULA, sk.PARTNER_ESTUDIANTE, sk.OBJETO_SAP_ESTUDIANTE, \n       sk.NOMBRE_ESTUDIANTE, d.ANIO_ACADEMICO, \n       TO_DATE(d.FECHA_ESTADO, 'YYYYMMDD') AS FECHA_ESTADO, d.FECHA_ESTADO AS ID_FECHA\nFROM DeniedStudents AS d\nINNER JOIN StudentKeys AS sk ON d.OBJETO_SAP_ESTUDIANTE = sk.OBJETO_SAP_ESTUDIANTE\n</code></pre></li> <li>Conexi\u00f3n: Referencia a <code>SAP_ERP</code>.</li> <li>Tiempo de espera: <code>30</code> segundos.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>NUMERO_MATRICULA</code>, <code>PARTNER_ESTUDIANTE</code>, <code>OBJETO_SAP_ESTUDIANTE</code>, <code>NOMBRE_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_ESTADO</code>, <code>ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>)<ul> <li>Descripci\u00f3n: Convierte columnas de entrada a tipos y longitudes compatibles con otros componentes.</li> <li>Columnas de Entrada:<ul> <li><code>NUMERO_MATRICULA</code>, <code>PARTNER_ESTUDIANTE</code>, <code>OBJETO_SAP_ESTUDIANTE</code>, <code>NOMBRE_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_ESTADO</code>, <code>ID_FECHA</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Copy of NUMERO_MATRICULA</code>, <code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of OBJETO_SAP_ESTUDIANTE</code>, <code>Copy of NOMBRE_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_ESTADO</code>, <code>Copy of ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>B\u00fasqueda (<code>Lookup</code>)<ul> <li>Descripci\u00f3n: Busca datos adicionales en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li>Columna de Uni\u00f3n: <code>PARTNER</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_POBLACION_MATRICULA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Columna Derivada (<code>Derived Column</code>)<ul> <li>Descripci\u00f3n: Calcula o asigna valores a columnas existentes o nuevas bas\u00e1ndose en condiciones.</li> <li>Expresi\u00f3n:   <pre><code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA\n</code></pre></li> <li>Columna Derivada:<ul> <li><code>ID_POBLACION_MATRICULA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)<ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_CUPOS_NEGADOS</code>.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Colegio\".\"FACT_CUPOS_NEGADOS\"</code>.</li> <li>BatchSize: <code>0</code> (tama\u00f1o predeterminado del b\u00fafer interno).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of NUMERO_MATRICULA</code>, <code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of OBJETO_SAP_ESTUDIANTE</code>, <code>Copy of NOMBRE_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_ESTADO</code>, <code>Copy of ID_FECHA</code>, <code>ID_POBLACION_MATRICULA</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia-del-flujo","title":"Diagrama de Secuencia del Flujo","text":"<pre><code>sequenceDiagram\n    participant Source as FACT_CUPOS NEGADOS SAP (Fuente)\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup (DIM_POBLACION_MATRICULA)\n    participant DerivedColumn as Derived Column\n    participant Destination as FACT_CUPOS_NEGADOS (Destino)\n\n    Source -&gt;&gt; DataConversion: Extrae datos y los convierte\n    DataConversion -&gt;&gt; Lookup: Enriquecimiento con b\u00fasqueda\n    Lookup -&gt;&gt; DerivedColumn: Asigna valores derivados\n    DerivedColumn -&gt;&gt; Destination: Carga datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-truncar-tabla","title":"Componente: <code>Truncar tabla</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>El componente \"Truncar tabla\" es una tarea de ejecuci\u00f3n de SQL que elimina todos los datos de la tabla <code>RESULTS</code> antes de ejecutar cualquier procedimiento o carga posterior, asegurando que la tabla est\u00e9 vac\u00eda y preparada para nuevos datos. Utiliza el comando <code>TRUNCATE TABLE</code> para eliminar de forma eficiente los registros, sin generar registros de transacci\u00f3n para cada fila eliminada.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-detallados","title":"Componentes Detallados","text":"<p>Descripci\u00f3n - Nombre del componente: Truncar tabla - Tipo: Tarea Ejecutar SQL - Descripci\u00f3n: Limpia la tabla <code>RESULTS</code> para evitar conflictos o duplicados en cargas posteriores.</p> <p>Propiedades</p> Propiedad Valor Connection <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code> SqlStatementSource <code>TRUNCATE TABLE RESULTS;</code> LocaleID <code>-1</code> CreationName <code>Microsoft.ExecuteSQLTask</code> TaskContact <code>Execute SQL Task; Microsoft Corporation; SQL Server 2022; \u00a9 2022 Microsoft Corporation</code> <p>Script SQL <pre><code>-- Limpiar la tabla antes de ejecutar el procedimiento\nTRUNCATE TABLE RESULTS;\n</code></pre></p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-calcular-retiros","title":"Componente <code>Calcular retiros</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente \"Calcular retiros\" es una tarea de flujo de datos en SSIS dise\u00f1ada para procesar, transformar y almacenar informaci\u00f3n relacionada con retiros de estudiantes. Este flujo extrae datos de una fuente SAP, realiza conversiones de datos, derivaciones de columnas, y finalmente almacena los resultados en la tabla de destino <code>FACT_RETIROS</code>.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>FACT_RETIROS SAP (Origen de datos)</p> <ul> <li>Descripci\u00f3n: Extrae informaci\u00f3n de estudiantes y retiros desde SAP usando un bloque SQL que recorre a\u00f1os desde 2023 hasta el a\u00f1o actual.</li> <li>Propiedades principales:<ul> <li>Consulta SQL: <pre><code>DO\nBEGIN\n    DECLARE year INT := 2023;\n    DECLARE current_year INT := YEAR(CURRENT_DATE);\n    WHILE year &lt;= current_year DO\n        CALL GetRetirosByYear(year);\n        year := year + 1;\n    END WHILE;\n    SELECT * FROM RESULTS;\nEND\n</code></pre></li> <li>Conexi\u00f3n: <code>SAP_ERP</code></li> <li>Timeout: 30 segundos.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos extra\u00eddos a los tipos requeridos para las siguientes transformaciones y el destino.</li> <li>Entrada:<ul> <li>Columnas: <code>OBJETO_SAP_ESTUDIANTE</code>, <code>NUMERO_MATRICULA</code>, <code>PARTNER_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>APELLIDOS</code>, <code>NOMBRES</code>, <code>CURSO</code>, <code>GRADO</code>, <code>FECHA_RETIRO_SAP</code>, <code>FECHA_VALIDO_DESDE</code>, <code>FECHA_VALIDO_HASTA</code>.</li> </ul> </li> <li>Salida:<ul> <li>Columnas convertidas como <code>Copy of &lt;nombre original&gt;</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Enlaza informaci\u00f3n adicional de la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Propiedades principales:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li>Comportamiento de no coincidencia: Ignorar filas sin coincidencias.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code>.</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas a partir de las existentes. Por ejemplo, se genera la columna <code>ID_FECHA</code> utilizando <code>FECHA_RETIRO_SAP</code>.</li> <li>Expresi\u00f3n derivada: <pre><code>(DT_I4)(YEAR([Copy of FECHA_RETIRO_SAP]) * 10000 + MONTH([Copy of FECHA_RETIRO_SAP]) * 100 + DAY([Copy of FECHA_RETIRO_SAP]))\n</code></pre></li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Almacena los resultados procesados en la tabla <code>FACT_RETIROS</code> en la base de datos de destino.</li> <li>Propiedades principales:<ul> <li>Tabla de destino: <code>Colegio.FACT_RETIROS</code></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#flujo-del-proceso","title":"Flujo del Proceso","text":"<ol> <li>Extraer datos desde SAP mediante <code>FACT_RETIROS SAP</code>.</li> <li>Convertir datos en el componente <code>Data Conversion</code>.</li> <li>Realizar un lookup para enriquecer datos desde <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Derivar nuevas columnas usando <code>Derived Column</code>.</li> <li>Almacenar los datos procesados en la tabla <code>FACT_RETIROS</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia-del-flujo_1","title":"Diagrama de Secuencia del Flujo","text":"<pre><code>sequenceDiagram\n    participant SAP as FACT_RETIROS SAP\n    participant DC as Data Conversion\n    participant LKP as Lookup\n    participant DCOL as Derived Column\n    participant DEST as Destino de ADO NET\n\n    SAP-&gt;&gt;DC: Extraer datos desde SAP\n    DC-&gt;&gt;LKP: Convertir datos y realizar Lookup\n    LKP-&gt;&gt;DCOL: Enviar datos enriquecidos\n    DCOL-&gt;&gt;DEST: Derivar columnas y guardar en destino\n    DEST--&gt;&gt;SAP: Fin del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_ausentismo_docente","title":"Componente <code>Procesar FACT_AUSENTISMO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>El componente \"Procesar FACT_AUSENTISMO_DOCENTE\" es una tarea de flujo de datos en SSIS destinada a procesar, transformar y almacenar informaci\u00f3n relacionada con el ausentismo docente. El flujo de datos incluye una fuente de datos Excel, transformaciones como conversi\u00f3n de datos y derivaci\u00f3n de columnas, enriquecimiento con datos adicionales mediante <code>Lookup</code>, y finalmente el almacenamiento en la tabla <code>FACT_AUSENTISMO_DOCENTE</code>.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Leer EP-EDF-02 (Excel Source)</p> <ul> <li>Descripci\u00f3n: Lee los datos desde un archivo Excel ubicado en la conexi\u00f3n <code>Excel_Connection_Fact_Ausentismo_Docente</code>.</li> <li>Propiedades principales:<ul> <li>Nombre de la hoja: <code>Hoja1$</code>.</li> <li>Columnas: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_REGISTRO</code>, <code>NOMBRE_DOCENTE</code>, <code>CARGO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>, <code>AUSENCIA_HORAS</code>, <code>AUSENCIA_DIAS</code>, <code>TIPO_AUSENCIA</code>, <code>PERMISO</code>, <code>MOTIVO_AUSENCIA</code>.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos extra\u00eddos a los tipos requeridos para las siguientes transformaciones y el destino.</li> <li>Entrada:<ul> <li>Columnas del archivo Excel.</li> </ul> </li> <li>Salida:<ul> <li>Columnas convertidas, con prefijo <code>Copy of</code>.</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas basadas en c\u00e1lculos sobre las columnas existentes. Por ejemplo, se genera <code>ID_FECHA</code> utilizando <code>FECHA_REGISTRO</code>.</li> <li>Expresi\u00f3n derivada: <pre><code>(DT_I4)(YEAR([Copy of FECHA_REGISTRO]) * 10000 + MONTH([Copy of FECHA_REGISTRO]) * 100 + DAY([Copy of FECHA_REGISTRO]))\n</code></pre></li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Enlaza informaci\u00f3n adicional desde la tabla <code>DIM_PERSONAL</code> en la base de datos <code>DWH_COMFENALCO</code>.</li> <li>Propiedades principales:<ul> <li>Consulta SQL: <pre><code>SELECT [ID_PERSONAL], CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO, [ID_UNIDAD], [TIPO_DOCUMENTO], [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1\n</code></pre></li> <li>Claves de uni\u00f3n: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ANIO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Almacena los datos procesados en la tabla <code>FACT_AUSENTISMO_DOCENTE</code>.</li> <li>Propiedades principales:<ul> <li>Tabla de destino: <code>Colegio.FACT_AUSENTISMO_DOCENTE</code>.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Leer EP-EDF-02 (Excel Source)\n    participant DC as Data Conversion\n    participant LKP as Lookup\n    participant DCOL as Derived Column\n    participant DEST as Destino de ADO NET\n\n    Excel-&gt;&gt;DC: Leer datos desde Excel\n    DC-&gt;&gt;DCOL: Convertir datos y derivar columnas\n    DCOL-&gt;&gt;LKP: Enviar datos para enriquecimiento\n    LKP-&gt;&gt;DEST: Guardar en base de datos\n    DEST--&gt;&gt;Excel: Fin del proceso</code></pre> <p>Flujo del Proceso</p> <ol> <li>Leer datos desde el archivo Excel (<code>Leer EP-EDF-02</code>).</li> <li>Convertir tipos de datos con el componente <code>Data Conversion</code>.</li> <li>Derivar nuevas columnas usando <code>Derived Column</code>.</li> <li>Enriquecer datos con informaci\u00f3n adicional mediante <code>Lookup</code>.</li> <li>Almacenar los datos procesados en la tabla <code>FACT_AUSENTISMO_DOCENTE</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_biblioteca","title":"Componente <code>Procesar FACT_BIBLIOTECA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos procesa la informaci\u00f3n de pr\u00e9stamos de biblioteca desde un archivo Excel hasta un destino en la base de datos relacional mediante transformaciones como conversiones de datos, columnas derivadas y b\u00fasquedas para enriquecer los datos con informaci\u00f3n adicional.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<p>1. Fuente: Leer EP-EDF-05</p> <ul> <li>Descripci\u00f3n: Extrae datos de un archivo Excel que contiene registros de pr\u00e9stamos de biblioteca.</li> <li>Propiedades:<ul> <li>Nombre de la hoja: <code>Hoja1$</code>.</li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Biblioteca</code>.</li> <li>Tiempo de espera del comando: <code>0</code> (sin l\u00edmite).</li> </ul> </li> <li>Columnas extra\u00eddas:<ul> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>BP_ESTUDIANTE</code>, <code>TIPO_USUARIO</code>, <code>FECHA_PRESTAMO</code>, <code>FECHA_VENCIMIENTO</code>, <code>FECHA_ENTREGA</code>, <code>BIBLIOTECA</code>, <code>ITEM_LIBRO</code>, <code>NO_PRESTAMOS</code>.</li> </ul> </li> </ul> <p>2. Transformaci\u00f3n: Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte las columnas extra\u00eddas en tipos compatibles con los destinos y procesos posteriores.</li> <li>Propiedades:<ul> <li>Conversi\u00f3n de tipos: <code>wstr</code> a tipos espec\u00edficos como <code>date</code> e <code>i4</code>.</li> <li>Columnas convertidas: <ul> <li>Ejemplo: <code>FECHA_PRESTAMO</code> a tipo <code>date</code>, <code>ITEM_LIBRO</code> a tipo <code>wstr</code> con longitud espec\u00edfica.</li> </ul> </li> <li>Disposici\u00f3n en caso de error: <code>FailComponent</code>.</li> </ul> </li> </ul> <p>3. Transformaci\u00f3n: Derived Column</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas de las existentes, como <code>ID_FECHA</code> y <code>ANIO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Expresiones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)(YEAR([FECHA_PRESTAMO])*10000 + MONTH([FECHA_PRESTAMO])*100 + DAY([FECHA_PRESTAMO]))</code>.</li> <li><code>ANIO_ACADEMICO</code>: <code>(DT_I4)(YEAR([FECHA_PRESTAMO]))</code>.</li> </ul> </li> <li>Manejo de errores: <code>FailComponent</code>.</li> </ul> </li> </ul> <p>4. Transformaci\u00f3n: Lookup</p> <ul> <li> <p>Lookup 1: Datos de matr\u00edcula (<code>DIM_POBLACION_MATRICULA</code>)</p> <ul> <li>Descripci\u00f3n: Asocia datos de estudiantes a partir de la columna <code>BP_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA];\n</code></pre></li> <li>Mapeo de par\u00e1metros: <code>BP_ESTUDIANTE \u2192 PARTNER</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup 2: Datos de libros (<code>DIM_LIBROS</code>)</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_LIBRO</code> usando el c\u00f3digo de barras o \u00edtem del libro.</li> <li>Propiedades:<ul> <li>Consulta SQL (con CTE para manejar duplicados): <pre><code>WITH CTE AS (\n    SELECT [ID_LIBRO], [ITEM],\n            ROW_NUMBER() OVER (PARTITION BY [ITEM] ORDER BY [ID_LIBRO]) AS rn\n    FROM [DWH_COMFENALCO].[Colegio].[DIM_LIBROS]\n)\nSELECT [ID_LIBRO], [ITEM] FROM CTE WHERE rn = 1;\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Lookup 3: Verificaci\u00f3n de registros existentes (<code>FACT_BIBLIOTECA</code>)</p> <ul> <li>Descripci\u00f3n: Verifica si ya existe un registro similar en la tabla destino.</li> <li>Propiedades:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[FACT_BIBLIOTECA];\n</code></pre></li> </ul> </li> </ul> </li> </ul> <p>5. Destino: Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados en la tabla <code>FACT_BIBLIOTECA</code> del esquema <code>Colegio</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Colegio\".\"FACT_BIBLIOTECA\"</code>.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code>.</li> <li>Tama\u00f1o de lotes: <code>0</code> (uso del tama\u00f1o de buffer interno).</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-05\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupMatricula as Lookup: DIM_POBLACION_MATRICULA\n    participant LookupLibros as Lookup: DIM_LIBROS\n    participant LookupFact as Lookup: FACT_BIBLIOTECA\n    participant Destino as ADO.NET Destination\n\n    ExcelSource -&gt;&gt; DataConversion: Extraer columnas y convertir tipos\n    DataConversion -&gt;&gt; DerivedColumn: Generar columnas derivadas\n    DerivedColumn -&gt;&gt; LookupMatricula: Buscar ID de matr\u00edcula\n    LookupMatricula -&gt;&gt; LookupLibros: Buscar ID de libro\n    LookupLibros -&gt;&gt; LookupFact: Verificar duplicados\n    LookupFact -&gt;&gt; Destino: Insertar registros finales</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_biblioteca_virtual","title":"Componente <code>Procesar FACT_BIBLIOTECA_VIRTUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) para los registros de la biblioteca virtual. Incluye conversiones de datos, derivaci\u00f3n de columnas, b\u00fasquedas y carga en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<p>1. Componente <code>Leer EP-EDF-06</code></p> <ul> <li>Descripci\u00f3n: Fuente de datos Excel que extrae informaci\u00f3n de la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0 (infinito).</li> <li><code>AccessMode</code>: 0 (tabla directa).</li> <li><code>OpenRowset</code>: <code>Hoja1$</code>.</li> </ul> </li> </ul> <p>2. Componente <code>Data Conversion</code></p> <ul> <li>Descripci\u00f3n: Convierte las columnas de entrada para ajustarlas a los tipos requeridos.</li> <li>Columnas Convertidas:<ul> <li><code>TIPO_DOCUMENTO</code>: <code>wstr</code> (40).</li> <li><code>DOCUMENTO</code>: <code>wstr</code> (20).</li> <li><code>FECHA_INICIO</code>: <code>date</code>.</li> </ul> </li> <li>Propiedades Adicionales:<ul> <li><code>FastParse</code>: <code>false</code> en todas las columnas.</li> </ul> </li> </ul> <p>3. Componente <code>Derived Column</code></p> <ul> <li>Descripci\u00f3n: Deriva columnas calculadas como <code>ID_FECHA</code> y <code>ANIO_ACADEMICO</code>.</li> <li>Columnas Derivadas:<ul> <li><code>ID_FECHA</code>: Combina a\u00f1o, mes y d\u00eda de <code>FECHA_INICIO</code>.</li> <li><code>ANIO_ACADEMICO</code>: Extrae solo el a\u00f1o.</li> </ul> </li> </ul> <p>4. Componente <code>Lookup</code></p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_POBLACION_MATRICULA</code> para obtener <code>ID_POBLACION_MATRICULA</code>.</li> <li>SQL de B\u00fasqueda: <pre><code>SELECT * FROM Colegio.DIM_POBLACION_MATRICULA WHERE TIPO_DOCUMENTO = ? AND DOCUMENTO = ?\n</code></pre></li> <li>Propiedades:<ul> <li><code>CacheType</code>: Completo.</li> <li><code>NoMatchBehavior</code>: Ignorar filas sin coincidencia.</li> </ul> </li> </ul> <p>5. Componente <code>Destino de ADO NET</code></p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>Colegio.FACT_BIBLIOTECA</code>.</li> <li>Propiedades:<ul> <li><code>BatchSize</code>: 0 (usa tama\u00f1o de b\u00fafer).</li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code>.</li> <li><code>CommandTimeout</code>: 30 segundos.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_11","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    Leer EP-EDF-06 -&gt;&gt; Data Conversion: Exporta datos Excel\n    Data Conversion -&gt;&gt; Derived Column: Convierte columnas\n    Derived Column -&gt;&gt; Lookup: Realiza b\u00fasquedas\n    Lookup -&gt;&gt; Derived Column 1: Agrega nuevas columnas derivadas\n    Derived Column 1 -&gt;&gt; Destino de ADO NET: Carga datos en la tabla FACT_BIBLIOTECA</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_desempenho_docente","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_DESEMPENHO_DOCENTE</code> es un flujo de datos dise\u00f1ado para extraer informaci\u00f3n desde un archivo Excel, realizar transformaciones y cargar los datos procesados en una base de datos. Este flujo incluye transformaciones clave como conversi\u00f3n de datos, derivaci\u00f3n de columnas, y consultas de b\u00fasqueda para enriquecer la informaci\u00f3n antes de almacenarla en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos:","text":"<ol> <li> <p>Leer EP-EDF-09 (Excel Source):</p> <ul> <li>Descripci\u00f3n: Fuente de datos que extrae informaci\u00f3n desde un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja: <code>Hoja1$</code></li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Desempenho_Colegio</code></li> <li>Columnas: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ANIO_ACADEMICO</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion:</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipos de datos de las columnas extra\u00eddas.</li> <li>Columnas Convertidas:<ul> <li><code>TIPO_DOCUMENTO</code> a <code>wstr(40)</code></li> <li><code>FECHA</code> a <code>date</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column:</p> <ul> <li>Descripci\u00f3n: Genera la columna <code>ID_FECHA</code> basada en la fecha en formato <code>YYYYMMDD</code>.</li> <li>Expresi\u00f3n: <code>(DT_I4)(YEAR([Copy of FECHA]) * 10000 + MONTH([Copy of FECHA]) * 100 + DAY([Copy of FECHA]))</code></li> </ul> </li> <li> <p>Lookup:</p> <ul> <li>Descripci\u00f3n: Enlaza los datos con la tabla <code>DIM_PERSONAL</code> para obtener el <code>ID_PERSONAL</code>.</li> <li>Consulta SQL: <pre><code>SELECT [ID_PERSONAL], CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1\n</code></pre></li> </ul> </li> <li> <p>Derived Column 1:</p> <ul> <li>Descripci\u00f3n: Asigna <code>-1</code> al <code>ID_PERSONAL</code> si no se encuentra un valor correspondiente.</li> <li>Expresi\u00f3n: <code>ISNULL(ID_PERSONAL) ? -1 : ID_PERSONAL</code></li> </ul> </li> <li> <p>Lookup 1:</p> <ul> <li>Descripci\u00f3n: Verifica duplicados en la tabla <code>FACT_DESEMPENHO_DOCENTE</code> para evitar registros repetidos.</li> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[FACT_DESEMPENHO_DOCENTE]\nWHERE [ID_FECHA] = ? AND [ID_PERSONAL] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de ADO NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_DESEMPENHO_DOCENTE</code>.</li> <li>Tabla Destino: <code>\"Colegio\".\"FACT_DESEMPENHO_DOCENTE\"</code></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_12","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel_Source as Leer EP-EDF-09 (Excel Source)\n    participant Data_Conversion as Data Conversion\n    participant Derived_Column as Derived Column\n    participant Lookup as Lookup\n    participant Lookup_1 as Lookup 1\n    participant Derived_Column_1 as Derived Column 1\n    participant ADO_NET as Destino de ADO NET\n\n    Excel_Source -&gt;&gt; Data_Conversion: Env\u00edo de datos\n    Data_Conversion -&gt;&gt; Derived_Column: Conversi\u00f3n de tipos\n    Derived_Column -&gt;&gt; Lookup: Relaciona datos con DIM_PERSONAL\n    Lookup -&gt;&gt; Derived_Column_1: Combina resultados\n    Derived_Column_1 -&gt;&gt; Lookup_1: Valida duplicados en FACT_DESEMPENHO_DOCENTE\n    Lookup_1 -&gt;&gt; ADO_NET: Inserta datos \u00fanicos\n    Note right of ADO_NET: Datos procesados y almacenados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_enfermeria","title":"Componente <code>Procesar FACT_ENFERMERIA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_ENFERMERIA</code> gestiona el flujo de datos para transformar, enriquecer y almacenar informaci\u00f3n relacionada con casos de atenci\u00f3n en enfermer\u00eda. Este flujo extrae datos de un archivo Excel, realiza conversiones y c\u00e1lculos, enriquece los datos con informaci\u00f3n adicional, y los carga en una tabla de base de datos mediante un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos:","text":"<ol> <li> <p>Leer EP-EDF-01 (Excel Source):</p> <ul> <li>Descripci\u00f3n: Fuente de datos que extrae informaci\u00f3n desde un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja: <code>Hoja1$</code></li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Enfermeria</code></li> <li>Columnas: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>IDCASO</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion:</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipos de datos de las columnas extra\u00eddas.</li> <li>Columnas Convertidas:<ul> <li><code>TIPO_DOCUMENTO</code> a <code>wstr(40)</code></li> <li><code>FECHA_ATENCION</code> a <code>date</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column:</p> <ul> <li>Descripci\u00f3n: Genera la columna <code>ID_FECHA</code> basada en la fecha de atenci\u00f3n en formato <code>YYYYMMDD</code>.</li> <li>Expresi\u00f3n: <code>(DT_I4)(YEAR([Copy of FECHA_ATENCION]) * 10000 + MONTH([Copy of FECHA_ATENCION]) * 100 + DAY([Copy of FECHA_ATENCION]))</code></li> </ul> </li> <li> <p>Lookup:</p> <ul> <li>Descripci\u00f3n: Enlaza los datos con la tabla <code>DIM_POBLACION_MATRICULA</code> para obtener el <code>ID_POBLACION_MATRICULA</code>.</li> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]\nWHERE [TIPO_DOCUMENTO] = ? AND [DOCUMENTO] = ?\n</code></pre></li> </ul> </li> <li> <p>Derived Column 1:</p> <ul> <li>Descripci\u00f3n: Asigna <code>-1</code> al <code>ID_POBLACION_MATRICULA</code> si no se encuentra un valor correspondiente.</li> <li>Expresi\u00f3n: <code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA</code></li> </ul> </li> <li> <p>Lookup 1:</p> <ul> <li>Descripci\u00f3n: Verifica duplicados en la tabla <code>FACT_ENFERMERIA</code> para evitar registros repetidos.</li> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[FACT_ENFERMERIA]\nWHERE [ID_CASO] = ? AND [ID_FECHA] = ? AND [ID_POBLACION_MATRICULA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de ADO NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_ENFERMERIA</code>.</li> <li>Tabla Destino: <code>\"Colegio\".\"FACT_ENFERMERIA\"</code></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_13","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel_Source as Leer EP-EDF-01 (Excel Source)\n    participant Data_Conversion as Data Conversion\n    participant Derived_Column as Derived Column\n    participant Lookup as Lookup\n    participant Lookup_1 as Lookup 1\n    participant Derived_Column_1 as Derived Column 1\n    participant ADO_NET as Destino de ADO NET\n\n    Excel_Source -&gt;&gt; Data_Conversion: Env\u00edo de datos\n    Data_Conversion -&gt;&gt; Derived_Column: Conversi\u00f3n de tipos\n    Derived_Column -&gt;&gt; Lookup: Relaciona datos con DIM_POBLACION_MATRICULA\n    Lookup -&gt;&gt; Derived_Column_1: Combina resultados\n    Derived_Column_1 -&gt;&gt; Lookup_1: Verifica duplicados en FACT_ENFERMERIA\n    Lookup_1 -&gt;&gt; ADO_NET: Inserta datos \u00fanicos\n    Note right of ADO_NET: Almacena datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_legalizacion","title":"Componente <code>Procesar FACT_LEGALIZACION</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos del paquete SSIS tiene como objetivo procesar y cargar datos relacionados con FACT_LEGALIZACION desde una fuente de datos Excel hacia una base de datos compatible con ADO.NET. Los datos se someten a diversas transformaciones antes de ser insertados en la tabla destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<p>1. Leer EP-EDF-10</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel llamada <code>Sheet1$</code> usando un origen de datos Excel.</li> <li>Propiedades:<ul> <li>Tiempo de espera: <code>0</code> (sin l\u00edmite).</li> <li>Modo de acceso: <code>0</code> (por defecto).</li> </ul> </li> <li>Columnas de salida:<ul> <li><code>RAZON_SOCIAL</code>: Ancho de 255 caracteres.</li> <li><code>FECHA</code>: Tipo de dato <code>date</code>.</li> <li><code>CODIGO_DANE</code>, <code>CODIGO_ICFES</code>: Tipo de dato <code>r8</code>.</li> <li>Otras columnas incluyen detalles como <code>CALENDARIO</code>, <code>NATURALEZA</code>, <code>CARACTER</code>, <code>TOTAL_ESTUDIANTES</code>, entre otros.</li> </ul> </li> </ul> <p>2. Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos y realiza ajustes necesarios en las columnas del flujo de datos para asegurar la compatibilidad con el destino.</li> <li>Propiedades:<ul> <li>Utiliza la opci\u00f3n <code>FailComponent</code> para manejar errores.</li> <li>Genera copias de las columnas le\u00eddas con ajustes de longitud y tipo de datos.</li> </ul> </li> <li>Columnas procesadas:<ul> <li>Ejemplo: <code>Copy of RAZON_SOCIAL</code> (tipo <code>wstr</code>, longitud: 40), <code>Copy of FECHA</code> (tipo <code>date</code>).</li> </ul> </li> </ul> <p>3. Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas a partir de transformaciones sobre las columnas existentes.</li> <li>Propiedades:<ul> <li>Calcula el campo <code>ID_FECHA</code> combinando valores de <code>A\u00f1o</code>, <code>Mes</code> y <code>D\u00eda</code> provenientes de <code>Copy of FECHA</code>.</li> <li>Ejemplo de expresi\u00f3n: <code>(DT_I4)(YEAR([Copy of FECHA]) * 10000 + MONTH([Copy of FECHA]) * 100 + DAY([Copy of FECHA]))</code>.</li> </ul> </li> </ul> <p>4. Lookup</p> <ul> <li>Descripci\u00f3n: Realiza b\u00fasquedas en la tabla de destino para verificar si los registros ya existen.</li> <li>Propiedades:<ul> <li>Usa la consulta SQL: <code>SELECT * FROM [Colegio].[FACT_LEGALIZACION]</code>.</li> <li>Maneja filas sin coincidencias envi\u00e1ndolas al flujo de datos.</li> <li>Coincidencias basadas en <code>RAZON_SOCIAL</code>, <code>CODIGO_DANE</code> y <code>ID_FECHA</code>.</li> </ul> </li> </ul> <p>5. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados en la tabla destino <code>FACT_LEGALIZACION</code> dentro de la base de datos del Colegio.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Colegio\".\"FACT_LEGALIZACION\"</code>.</li> <li>Tama\u00f1o del lote: <code>0</code> (uso de tama\u00f1o predeterminado).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Usa <code>SqlBulkCopy</code> para mejorar el rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_14","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-10\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant Lookup as Lookup\n    participant ADODestination as Destino de ADO.NET\n\n    ExcelSource-&gt;&gt;DataConversion: Flujo de datos\n    DataConversion-&gt;&gt;DerivedColumn: Datos convertidos\n    DerivedColumn-&gt;&gt;Lookup: Datos transformados\n    Lookup-&gt;&gt;ADODestination: Datos validados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_permiso_estudiante","title":"Componente <code>Procesar FACT_PERMISO_ESTUDIANTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>El flujo de datos del paquete SSIS procesa y carga informaci\u00f3n relacionada con permisos de estudiantes desde un archivo Excel hacia la base de datos del Colegio en la tabla <code>FACT_PERMISO_ESTUDIANTE</code>. El proceso incluye la validaci\u00f3n, transformaci\u00f3n y enriquecimiento de los datos.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_9","title":"Componentes del Flujo de Datos","text":"<p>1. Leer EP-EDF-04</p> <ul> <li>Descripci\u00f3n: Origen de datos Excel que lee los registros desde la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li>Tiempo de espera: <code>0</code> (sin l\u00edmite).</li> <li>Modo de acceso: <code>0</code> (predeterminado).</li> </ul> </li> <li>Columnas de salida: Incluye datos como <code>FECHA</code>, <code>BP_ESTUDIANTE</code>, <code>NOMBRE_ESTUDIANTE</code>, <code>GRADO</code>, <code>CURSO</code>, entre otros.</li> </ul> <p>2. Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos y ajusta las columnas para la compatibilidad con los pasos posteriores.</li> <li>Propiedades:<ul> <li>Asigna un prefijo <code>Copy of</code> a las columnas convertidas.</li> <li>Convierte columnas como <code>BP_ESTUDIANTE</code> (tipo <code>wstr</code>) y <code>FECHA</code> (tipo <code>date</code>).</li> </ul> </li> <li>Manejo de errores: Disposici\u00f3n <code>FailComponent</code>.</li> </ul> <p>3. Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas utilizando expresiones matem\u00e1ticas y l\u00f3gicas.</li> <li>Columnas generadas:<ul> <li><code>ID_FECHA</code>: Calculada como una combinaci\u00f3n de <code>A\u00f1o</code>, <code>Mes</code> y <code>D\u00eda</code>.</li> <li><code>ANIO_ACADEMICO</code>: Extra\u00eddo del a\u00f1o de la columna <code>Copy of FECHA</code>.</li> </ul> </li> </ul> <p>4. Lookup</p> <ul> <li>Descripci\u00f3n: Busca informaci\u00f3n adicional en la tabla de dimensiones <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> <li>Filtra filas bas\u00e1ndose en la columna <code>BP_ESTUDIANTE</code>.</li> </ul> </li> </ul> <p>5. Lookup 1 y Lookup 2</p> <ul> <li>Descripci\u00f3n: <ul> <li><code>Lookup 1</code>: Busca en <code>DIM_CURSO</code> para obtener el <code>ID_CURSO</code>.</li> <li><code>Lookup 2</code>: Busca en <code>DIM_GRADO</code> para obtener el <code>ID_GRADO</code>.</li> </ul> </li> <li>Propiedades:<ul> <li>Ambas operaciones utilizan columnas como <code>CURSO</code> y <code>GRADO</code> para realizar las coincidencias.</li> </ul> </li> </ul> <p>6. Lookup 3</p> <ul> <li>Descripci\u00f3n: Verifica si ya existen registros en la tabla destino <code>FACT_PERMISO_ESTUDIANTE</code> bas\u00e1ndose en las columnas <code>HORA</code>, <code>ID_FECHA</code> e <code>ID_POBLACION_MATRICULA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Colegio].[FACT_PERMISO_ESTUDIANTE]</code>.</li> </ul> </li> </ul> <p>7. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>FACT_PERMISO_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Colegio\".\"FACT_PERMISO_ESTUDIANTE\"</code>.</li> <li>Inserci\u00f3n masiva habilitada con <code>SqlBulkCopy</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_15","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-04\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant Lookup1 as Lookup DIM_POBLACION_MATRICULA\n    participant Lookup2 as Lookup DIM_CURSO\n    participant Lookup3 as Lookup DIM_GRADO\n    participant LookupFinal as Lookup FACT_PERMISO_ESTUDIANTE\n    participant Destination as Destino ADO.NET\n\n    ExcelSource-&gt;&gt;DataConversion: Datos le\u00eddos\n    DataConversion-&gt;&gt;DerivedColumn: Datos convertidos\n    DerivedColumn-&gt;&gt;Lookup1: Validaci\u00f3n de BP_ESTUDIANTE\n    Lookup1-&gt;&gt;Lookup2: Validaci\u00f3n de CURSO\n    Lookup2-&gt;&gt;Lookup3: Validaci\u00f3n de GRADO\n    Lookup3-&gt;&gt;Destination: Inserci\u00f3n en tabla destino</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_psiorientacion","title":"Componente <code>Procesar FACT_PSIORIENTACION</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>El flujo de datos del paquete SSIS procesa y carga informaci\u00f3n de orientaci\u00f3n psicol\u00f3gica de estudiantes desde un archivo Excel hacia la tabla de destino <code>FACT_PSICORIENTACION</code> en la base de datos. Incluye transformaciones de datos, validaciones y enriquecimientos utilizando varias transformaciones de SSIS.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_10","title":"Componentes del Flujo de Datos","text":"<p>1. Leer EP-EDF-11</p> <ul> <li>Descripci\u00f3n: Origen de datos Excel que lee la hoja <code>Hoja1$</code> para obtener la informaci\u00f3n.</li> <li>Propiedades:<ul> <li>Tiempo de espera: 0 (sin l\u00edmite).</li> <li>Modo de acceso: Predeterminado.</li> </ul> </li> <li>Columnas de salida:<ul> <li><code>BP_ESTUDIANTE</code>, <code>IDCASO</code>, <code>ANIO_ACADEMICO</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>FECHA_ATENCION</code>, <code>FECHA_SOLUCION</code>, <code>ESTADO</code>, <code>QUIEN_REMITE</code>, <code>NOTIFICACION_A_PADRES</code>, <code>MOTIVO_ATENCION</code>.</li> </ul> </li> </ul> <p>2. Data Conversion</p> <ul> <li>Descripci\u00f3n: Conversi\u00f3n de tipos de datos y ajuste de columnas.</li> <li>Propiedades:<ul> <li>Agrega un prefijo <code>Copy of</code> a las columnas convertidas.</li> <li>Convierte tipos de datos a <code>wstr</code>, <code>i4</code>, o <code>date</code> seg\u00fan corresponda.</li> </ul> </li> <li>Manejo de errores: <ul> <li>Disposici\u00f3n de error: <code>FailComponent</code>.</li> </ul> </li> </ul> <p>3. Derived Column</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas a partir de las columnas de entrada.</li> <li>Columnas creadas:<ul> <li><code>ID_FECHA</code>: Construido a partir del a\u00f1o, mes y d\u00eda de <code>Copy of FECHA_ATENCION</code>.</li> <li><code>ANIO_ACADEMICO</code>: Extra\u00eddo del a\u00f1o de <code>Copy of FECHA_ATENCION</code>.</li> </ul> </li> </ul> <p>4. Lookup</p> <ul> <li>Descripci\u00f3n: Busca en la tabla <code>DIM_POBLACION_MATRICULA</code> para enriquecer los datos con el identificador <code>ID_POBLACION_MATRICULA</code>.</li> <li>Consulta SQL: <code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> <li>Condiciones de b\u00fasqueda: <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> </ul> <p>5. Derived Column 1</p> <ul> <li>Descripci\u00f3n: Valida y ajusta el valor de <code>ID_POBLACION_MATRICULA</code> derivado.</li> <li>Expresi\u00f3n derivada:<ul> <li>Si el valor de <code>ID_POBLACION_MATRICULA</code> es nulo, asigna <code>-1</code>.</li> </ul> </li> </ul> <p>6. Lookup 1</p> <ul> <li>Descripci\u00f3n: Valida si el registro ya existe en la tabla <code>FACT_PSICORIENTACION</code> en funci\u00f3n de <code>ID_CASO</code>, <code>ID_FECHA</code>, y <code>ID_POBLACION_MATRICULA</code>.</li> <li>Consulta SQL: <pre><code>SELECT * \nFROM [Colegio].[FACT_PSICORIENTACION]\nWHERE ID_CASO = ? AND ID_FECHA = ? AND ID_POBLACION_MATRICULA = ?\n</code></pre></li> </ul> <p>7. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>FACT_PSICORIENTACION</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Colegio\".\"FACT_PSICORIENTACION\"</code>.</li> <li>Tama\u00f1o de lote: 0 (predeterminado, utiliza el tama\u00f1o del buffer interno).</li> <li>Tiempo de espera del comando: 30 segundos.</li> <li>Uso de <code>SqlBulkCopy</code>: Activado para mejorar el rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_16","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-11\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant Lookup1 as Lookup DIM_POBLACION_MATRICULA\n    participant DerivedColumn2 as Derived Column Ajustado\n    participant Lookup2 as Lookup FACT_PSICORIENTACION\n    participant Destination as Destino ADO.NET\n\n    ExcelSource-&gt;&gt;DataConversion: Leer datos desde Excel\n    DataConversion-&gt;&gt;DerivedColumn: Convertir datos y crear ID_FECHA\n    DerivedColumn-&gt;&gt;Lookup1: Validar informaci\u00f3n con DIM_POBLACION_MATRICULA\n    Lookup1-&gt;&gt;DerivedColumn2: Validar ID_POBLACION_MATRICULA\n    DerivedColumn2-&gt;&gt;Lookup2: Verificar existencia en FACT_PSICORIENTACION\n    Lookup2-&gt;&gt;Destination: Insertar en la tabla destino</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_reemplazo_docente","title":"Componente <code>Procesar FACT_REEMPLAZO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>Este paquete SSIS realiza la extracci\u00f3n, transformaci\u00f3n y carga de datos relacionados con la facturaci\u00f3n del reemplazo de docentes. Incluye tareas de conversi\u00f3n de datos, columnas derivadas, b\u00fasquedas en tablas de dimensiones y la carga en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_11","title":"Componentes del Flujo de Datos","text":"<ul> <li>Leer EP-EDF-03 Descripci\u00f3n: Fuente de datos que lee informaci\u00f3n desde un archivo Excel en la hoja \"Hoja1$\". Propiedades:         - <code>CommandTimeout</code>: 0         - <code>OpenRowset</code>: \"Hoja1$\" Columnas de Salida:  ID_REEMPLAZO, TIPO_DOCUMENTO_DOCENTE_AUSENTE, DOCUMENTO_DOCENTE_AUSENTE, GRADO, FECHA, BLOQUE_HORARIO, NUMERO_HORAS, CURSO, DOCENTE_AUSENTE, DOCENTE_REEMPLAZA, TIPO_DOCUMENTO_DOCENTE_REEMPLAZA, DOCUMENTO_DOCENTE_REEMPLAZA</li> <li> <p>Data Conversion Descripci\u00f3n: Realiza conversiones de tipos de datos para columnas espec\u00edficas. Columnas Transformadas:  </p> <ul> <li><code>ANIO_ACADEMICO \u2192 DT_I4</code></li> <li><code>TIPO_DOCUMENTO_DOCENTE_AUSENTE \u2192 wstr (longitud 20)</code></li> <li><code>DOCUMENTO_DOCENTE_AUSENTE \u2192 wstr (longitud 40)</code></li> <li><code>FECHA \u2192 date</code></li> <li><code>BLOQUE_HORARIO \u2192 wstr (longitud 40)</code></li> </ul> </li> <li> <p>Derived Column Descripci\u00f3n: Genera nuevas columnas basadas en expresiones. Columnas Derivadas:         ID_FECHA: Calculado como <code>(DT_I4)(YEAR([Copy of FECHA]) * 10000 + MONTH([Copy of FECHA]) * 100 + DAY([Copy of FECHA]))</code>.</p> </li> <li> <p>Lookup (DIM_PERSONAL) Descripci\u00f3n: Busca informaci\u00f3n de personal docente ausente en la tabla <code>[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]</code>. SQL Utilizado: <pre><code>SELECT [ID_PERSONAL],\n    CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO,\n    [ID_UNIDAD],\n    [TIPO_DOCUMENTO],\n    [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1;\n</code></pre> Columnas Vinculadas:         - Copy of TIPO_DOCUMENTO_DOCENTE_AUSENTE \u2192 TIPO_DOCUMENTO         - Copy of DOCUMENTO_DOCENTE_AUSENTE \u2192 DOCUMENTO         - Copy of ANIO_ACADEMICO \u2192 ANIO_ACADEMICO  </p> </li> <li> <p>Lookup (DIM_GRADO) Descripci\u00f3n: Busca informaci\u00f3n del grado en la tabla <code>[Colegio].[DIM_GRADO]</code>. SQL Utilizado: <pre><code>SELECT * FROM [Colegio].[DIM_GRADO];\n</code></pre> Columnas Vinculadas:         - Copy of GRADO \u2192 DESC_GRADO  </p> </li> <li> <p>Destino ADO.NET Descripci\u00f3n: Carga los datos transformados en la tabla <code>\"Colegio\".\"FACT_REEMPLAZO_DOCENTE\"</code>. Propiedades:         - <code>BatchSize</code>: 0         - <code>CommandTimeout</code>: 30         - <code>UseBulkInsertWhenPossible</code>: true Columnas de Entrada:  ID_FECHA  , ID_PERSONAL_AUSENTE  , ID_PERSONAL_REEMPLAZA  , ID_CURSO  , ID_GRADO  , ANIO_ACADEMICO  , FECHA  </p> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_17","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-03\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupDimPersonal as Lookup DIM_PERSONAL\n    participant LookupDimGrado as Lookup DIM_GRADO\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Transformaci\u00f3n de datos\n    DataConversion -&gt;&gt; DerivedColumn: Generaci\u00f3n de columnas derivadas\n    DerivedColumn -&gt;&gt; LookupDimPersonal: B\u00fasqueda de personal\n    LookupDimPersonal -&gt;&gt; LookupDimGrado: B\u00fasqueda de grado\n    LookupDimGrado -&gt;&gt; ADONETDestination: Carga de datos</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_reserva_espacios","title":"Componente <code>Procesar FACT_RESERVA_ESPACIOS</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>Este paquete SSIS procesa los datos relacionados con la reserva de espacios educativos. Realiza la extracci\u00f3n desde un archivo Excel, transforma los datos mediante conversiones y c\u00e1lculos, realiza b\u00fasquedas de informaci\u00f3n adicional en tablas de dimensiones y carga los datos transformados en una tabla de destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_12","title":"Componentes del Flujo de Datos","text":"<ul> <li> <p>Leer EP-EDF-12</p> <ul> <li>Descripci\u00f3n: Este componente extrae los datos desde un archivo Excel. Utiliza la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida:<code>ANIO_ACADEMICO</code>, <code>ID_RESERVA</code>, <code>FECHA_SOLICITUD</code>, <code>FECHA_RESERVA</code>, <code>TIPO_DOCUMENTO_DOCENTO</code>, <code>DOCUMENTO_DOCENTE</code>, <code>CORREO_DOCENTE</code>, <code>HORA_INICIO</code>, <code>HORA_FIN</code>, <code>ACTIVIDAD_PLANEADA</code>, <code>PLACA_PORTATIL</code>, <code>VIDEOBEAM</code></li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipos de datos para asegurar la compatibilidad con los componentes posteriores.</li> <li>Transformaciones:<ul> <li>ANIO_ACADEMICO \u2192 <code>DT_I4</code></li> <li>ID_RESERVA \u2192 <code>DT_I4</code></li> <li>FECHA_SOLICITUD \u2192 <code>DT_DATE</code></li> <li>FECHA_RESERVA \u2192 <code>DT_DATE</code></li> <li>TIPO_DOCUMENTO_DOCENTE \u2192 <code>wstr</code> (40)</li> <li>DOCUMENTO_DOCENTE \u2192 <code>wstr</code> (20)</li> <li>CORREO_DOCENTE \u2192 <code>wstr</code> (200)</li> <li>HORA_INICIO \u2192 <code>wstr</code> (40)</li> <li>HORA_FIN \u2192 <code>wstr</code> (40)</li> <li>ACTIVIDAD_PLANEADA \u2192 <code>wstr</code> (40)</li> <li>PLACA_PORTATIL \u2192 <code>wstr</code> (40)</li> <li>VIDEOBEAM \u2192 <code>wstr</code> (40)</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas a partir de c\u00e1lculos con las columnas existentes.</li> <li>Transformaciones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)(YEAR([Copy of FECHA_RESERVA]) * 10000 + MONTH([Copy of FECHA_RESERVA]) * 100 + DAY([Copy of FECHA_RESERVA]))</code></li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_PERSONAL)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]</code> para obtener informaci\u00f3n adicional del personal docente.</li> <li>SQL Utilizado:     <pre><code>SELECT [ID_PERSONAL],\n       CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO,\n       [ID_UNIDAD],\n       [TIPO_DOCUMENTO],\n       [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1;\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li>Copy of ANIO_ACADEMICO \u2192 ANIO_ACADEMICO</li> <li>Copy of TIPO_DOCUMENTO_DOCENTE \u2192 TIPO_DOCUMENTO</li> <li>Copy of DOCUMENTO_DOCENTE \u2192 DOCUMENTO</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>\"Colegio\".\"FACT_RESERVA_ESPACIOS\"</code>.</li> <li>Propiedades:<ul> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Columnas de Entrada:     <code>ID_FECHA</code>, <code>ID_PERSONAL</code>, <code>Copy of ID_RESERVA</code>, <code>Copy of DOCUMENTO_DOCENTE</code>, <code>Copy of FECHA_SOLICITUD</code>, <code>Copy of FECHA_RESERVA</code>, <code>Copy of CORREO_DOCENTE</code>, <code>Copy of HORA_INICIO</code>, <code>Copy of HORA_FIN</code>, <code>Copy of ACTIVIDAD_PLANEADA</code>, <code>Copy of PLACA_PORTATIL</code>, <code>Copy of VIDEOBEAM</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_18","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-12\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupDimPersonal as Lookup DIM_PERSONAL\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Transformaci\u00f3n de datos\n    DataConversion -&gt;&gt; DerivedColumn: Generaci\u00f3n de columnas derivadas\n    DerivedColumn -&gt;&gt; LookupDimPersonal: B\u00fasqueda de datos adicionales\n    LookupDimPersonal -&gt;&gt; ADONETDestination: Carga de datos transformados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_saber11_colegios","title":"Componente <code>Procesar FACT_SABER11_COLEGIOS</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>Este paquete de SSIS procesa datos relacionados con las evaluaciones del SABER 11 para colegios, extrayendo informaci\u00f3n de un archivo Excel, transformando y enriqueciendo los datos con c\u00e1lculos derivados y b\u00fasquedas, y carg\u00e1ndolos en una tabla de destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_13","title":"Componentes del Flujo de Datos","text":"<ul> <li> <p>Leer EP-EDF-08</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel ubicado en <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code> (a\u00f1o acad\u00e9mico del registro)</li> <li><code>ID_REGISTRO</code> (identificador del registro)</li> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> (c\u00f3digo DANE del establecimiento educativo)</li> <li><code>NOMBRE_ESTABLECIMIENTO_EDUCATIVO</code> (nombre del establecimiento)</li> <li><code>RESULTADO</code> (resultado del examen SABER 11)</li> <li><code>CATEGORIA_SABER11</code> (categor\u00eda del colegio seg\u00fan el SABER 11)</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipo de datos para asegurar la compatibilidad con los siguientes pasos del flujo de datos.</li> <li>Transformaciones:<ul> <li><code>ANIO_ACADEMICO</code> \u2192 <code>DT_I4</code></li> <li><code>ID_REGISTRO</code> \u2192 <code>wstr</code> (255)</li> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> \u2192 <code>wstr</code> (40)</li> <li><code>NOMBRE_ESTABLECIMIENTO_EDUCATIVO</code> \u2192 <code>wstr</code> (200)</li> <li><code>RESULTADO</code> \u2192 <code>wstr</code> (40)</li> <li><code>CATEGORIA_SABER11</code> \u2192 <code>wstr</code> (40)</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>[DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS]</code> para enriquecer los datos con informaci\u00f3n adicional.</li> <li>SQL Utilizado:     <pre><code>SELECT [ID_REGISTRO],\n       [ID_FECHA],\n       CAST([ANIO_ACADEMICO] AS INT) AS ANIO_ACADEMICO,\n       [COD_ESTABLECIMIENTO_EDUCATIVO],\n       [NOMBRE_EE],\n       [RESULTADO],\n       [CATEGORIA_SABER11]\nFROM [DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS];\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> \u2192 <code>COD_ESTABLECIMIENTO_EDUCATIVO</code></li> <li><code>ANIO_ACADEMICO</code> \u2192 <code>ANIO_ACADEMICO</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Calcula una columna derivada para el identificador de fecha.</li> <li>Transformaciones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)((DT_STR,4,1252)ANIO_ACADEMICO + \"1201\")</code></li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino <code>\"Colegio\".\"FACT_SABER11_COLEGIOS\"</code>.</li> <li>Propiedades:<ul> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_FECHA</code> (identificador \u00fanico para la fecha derivada)</li> <li><code>ANIO_ACADEMICO</code> (a\u00f1o acad\u00e9mico)</li> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> (c\u00f3digo DANE del establecimiento)</li> <li><code>NOMBRE_ESTABLECIMIENTO_EDUCATIVO</code> (nombre del establecimiento)</li> <li><code>RESULTADO</code> (resultado del examen)</li> <li><code>CATEGORIA_SABER11</code> (categor\u00eda seg\u00fan el examen SABER 11)</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_19","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-08\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup SABER11\n    participant DerivedColumn as Derived Column\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Transformaci\u00f3n de datos\n    DataConversion -&gt;&gt; Lookup: Enriquecimiento de datos\n    Lookup -&gt;&gt; DerivedColumn: Generaci\u00f3n de columnas derivadas\n    DerivedColumn -&gt;&gt; ADONETDestination: Carga de datos transformados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_saber11_individual","title":"Componente <code>Procesar FACT_SABER11_INDIVIDUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>Este paquete de SSIS procesa datos individuales del SABER 11, extrayendo informaci\u00f3n desde un archivo Excel, transformando y enriqueciendo los datos mediante conversiones, columnas derivadas y b\u00fasquedas, para finalmente almacenarlos en una tabla de destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_14","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Leer EP-EDF-07</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel ubicado en <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida: <code>ANIO_ACADEMICO</code>, <code>ID_REGISTRO</code>, <code>RESULTADO</code>, <code>BP_ESTUDIANTE</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>FECHA</code>, <code>TEMATICA</code></li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas para asegurar la compatibilidad con el resto del flujo.</li> <li>Transformaciones:<ul> <li><code>ANIO_ACADEMICO</code> \u2192 <code>DT_I4</code></li> <li><code>RESULTADO</code> \u2192 <code>wstr</code> (40)</li> <li><code>BP_ESTUDIANTE</code> \u2192 <code>wstr</code> (40)</li> <li><code>TIPO_DOCUMENTO</code> \u2192 <code>wstr</code> (40)</li> <li><code>DOCUMENTO</code> \u2192 <code>wstr</code> (20)</li> <li><code>FECHA</code> \u2192 <code>date</code></li> <li><code>TEMATICA</code> \u2192 <code>wstr</code> (40)</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Genera un identificador \u00fanico para las fechas en formato <code>YYYYMMDD</code>.</li> <li>Transformaciones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)(YEAR([FECHA]) * 10000 + MONTH([FECHA]) * 100 + DAY([FECHA]))</code></li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_POBLACION_MATRICULA)</p> <ul> <li>Descripci\u00f3n: Enriquecer los datos con informaci\u00f3n de la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li><code>BP_ESTUDIANTE</code> \u2192 <code>PARTNER</code></li> </ul> </li> <li>Salida:<ul> <li><code>ID_POBLACION_MATRICULA</code></li> </ul> </li> </ul> </li> <li> <p>Lookup (FACT_SABER11_INDIVIDUAL)</p> <ul> <li>Descripci\u00f3n: Verifica si los datos ya existen en la tabla de destino <code>[Colegio].[FACT_SABER11_INDIVIDUAL]</code>.</li> <li>Consulta SQL:     <pre><code>SELECT \n    [ID_REGISTRO],\n    [ID_FECHA],\n    CAST([ANIO_ACADEMICO] AS INT) AS ANIO_ACADEMICO,\n    [ID_POBLACION_MATRICULA],\n    [TEMATICA],\n    [RESULTADO]\nFROM [Colegio].[FACT_SABER11_INDIVIDUAL]\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li><code>ANIO_ACADEMICO</code></li> <li><code>TEMATICA</code></li> <li><code>ID_POBLACION_MATRICULA</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column (Validaci\u00f3n de ID_POBLACION_MATRICULA)</p> <ul> <li>Descripci\u00f3n: Agrega una validaci\u00f3n para la columna <code>ID_POBLACION_MATRICULA</code>.</li> <li>Transformaciones:<ul> <li><code>ID_POBLACION_MATRICULA</code>: <code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA</code></li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>\"Colegio\".\"FACT_SABER11_INDIVIDUAL\"</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"FACT_SABER11_INDIVIDUAL\"</code></li> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_FECHA</code></li> <li><code>ID_POBLACION_MATRICULA</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>TEMATICA</code></li> <li><code>RESULTADO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_20","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-07\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column (Fecha)\n    participant LookupDIM as Lookup DIM_POBLACION_MATRICULA\n    participant LookupFACT as Lookup FACT_SABER11_INDIVIDUAL\n    participant DerivedColumn2 as Derived Column (Validaci\u00f3n)\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Convertir tipos de datos\n    DataConversion -&gt;&gt; DerivedColumn: Crear ID_FECHA\n    DerivedColumn -&gt;&gt; LookupDIM: Enriquecer datos con ID_POBLACION_MATRICULA\n    LookupDIM -&gt;&gt; LookupFACT: Verificar existencia en FACT_SABER11_INDIVIDUAL\n    LookupFACT -&gt;&gt; DerivedColumn2: Validar ID_POBLACION_MATRICULA\n    DerivedColumn2 -&gt;&gt; ADONETDestination: Insertar datos en tabla de destino</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_servicio_social","title":"Componente <code>Procesar FACT_SERVICIO_SOCIAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>Este paquete de SSIS procesa datos relacionados con el servicio social de estudiantes, transformando y enriqueciendo la informaci\u00f3n desde un archivo Excel para almacenarla en una base de datos relacional. Incluye conversiones de datos, b\u00fasqueda de informaci\u00f3n relacionada y validaciones, y finalmente inserta los datos en una tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_15","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Leer EP-EDF-13</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel, ubicado en la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code>, <code>BP_ESTUDIANTE</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>GRADO</code>, <code>CURSO</code>, <code>HORARIO</code>, <code>PROYECTO</code>, <code>PAZ_Y_SALVO</code>, <code>HORAS_EJECUTADAS</code>, <code>AUTORIZACION_ACUDIENTE</code></li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte las columnas para asegurar compatibilidad en el flujo.</li> <li>Transformaciones:<ul> <li><code>ANIO_ACADEMICO</code> \u2192 <code>DT_I4</code></li> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>GRADO</code>, <code>CURSO</code>, <code>HORARIO</code>, <code>PROYECTO</code>, <code>PAZ_Y_SALVO</code>, <code>HORAS_EJECUTADAS</code>, <code>AUTORIZACION_ACUDIENTE</code> \u2192 <code>wstr</code></li> </ul> </li> <li>Columnas Convertidas: Todas las columnas del componente de entrada.</li> </ul> </li> <li> <p>Lookup: DIM_POBLACION_MATRICULA</p> <ul> <li>Descripci\u00f3n: Busca el identificador de poblaci\u00f3n en la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code> usando <code>BP_ESTUDIANTE</code>.</li> <li>Consulta SQL:     <pre><code>SELECT *\nFROM [Colegio].[DIM_POBLACION_MATRICULA]\nWHERE [PARTNER] = ?\n</code></pre></li> <li>Columnas de Salida: <code>ID_POBLACION_MATRICULA</code></li> </ul> </li> <li> <p>Lookup: DIM_CURSO</p> <ul> <li>Descripci\u00f3n: Busca el identificador del curso en la tabla <code>[Colegio].[DIM_CURSO]</code> usando <code>DESC_CURSO</code>.</li> <li>Consulta SQL:     <pre><code>SELECT *\nFROM [Colegio].[DIM_CURSO]\nWHERE [DESC_CURSO] = ?\n</code></pre></li> <li>Columnas de Salida: <code>ID_CURSO</code></li> </ul> </li> <li> <p>Lookup: DIM_GRADO</p> <ul> <li>Descripci\u00f3n: Busca el identificador del grado en la tabla <code>[Colegio].[DIM_GRADO]</code> usando <code>DESC_GRADO</code>.</li> <li>Consulta SQL:     <pre><code>SELECT *\nFROM [Colegio].[DIM_GRADO]\nWHERE [DESC_GRADO] = ?\n</code></pre></li> <li>Columnas de Salida: <code>ID_GRADO</code></li> </ul> </li> <li> <p>Lookup: FACT_SERVICIO_SOCIAL</p> <ul> <li>Descripci\u00f3n: Verifica la existencia de registros en la tabla <code>[Colegio].[FACT_SERVICIO_SOCIAL]</code>.</li> <li>Consulta SQL:     <pre><code>SELECT [ID_REGISTRO], [ANIO_ACADEMICO], [ID_POBLACION_MATRICULA], [ID_CURSO], [ID_GRADO]\nFROM [Colegio].[FACT_SERVICIO_SOCIAL]\nWHERE [ANIO_ACADEMICO] = ? AND [ID_POBLACION_MATRICULA] = ? AND [ID_CURSO] = ? AND [ID_GRADO] = ?\n</code></pre></li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Agrega validaciones para columnas enriquecidas.</li> <li>Transformaciones:<ul> <li><code>ID_POBLACION_MATRICULA</code>: <code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA</code></li> <li><code>ID_CURSO</code>: <code>ISNULL(ID_CURSO) ? -1 : ID_CURSO</code></li> <li><code>ID_GRADO</code>: <code>ISNULL(ID_GRADO) ? -1 : ID_GRADO</code></li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>\"Colegio\".\"FACT_SERVICIO_SOCIAL\"</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"FACT_SERVICIO_SOCIAL\"</code></li> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_21","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-13\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup DIM_POBLACION_MATRICULA\n    participant Lookup2 as Lookup DIM_CURSO\n    participant Lookup3 as Lookup DIM_GRADO\n    participant Lookup4 as Lookup FACT_SERVICIO_SOCIAL\n    participant DerivedColumn as Derived Column\n    participant ADO as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Convertir datos\n    DataConversion -&gt;&gt; Lookup1: Buscar ID_POBLACION_MATRICULA\n    Lookup1 -&gt;&gt; Lookup2: Buscar ID_CURSO\n    Lookup2 -&gt;&gt; Lookup3: Buscar ID_GRADO\n    Lookup3 -&gt;&gt; Lookup4: Verificar existencia\n    Lookup4 -&gt;&gt; DerivedColumn: Validar IDs\n    DerivedColumn -&gt;&gt; ADO: Insertar datos en FACT_SERVICIO_SOCIAL</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/","title":"05. CEDESARROLLO_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#cedesarrollo_dimensiones","title":"CEDESARROLLO_DIMENSIONES","text":"<p>El paquete SSIS \"05-CEDESARROLLO_DIMENSIONES\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar datos esenciales relacionados con dimensiones clave como per\u00edodos acad\u00e9micos, programas educativos, jornadas, y poblaci\u00f3n matriculada. Este paquete asegura la calidad e integridad de los datos consolidados en el Data Warehouse <code>DWH_COMFENALCO</code>, proporcionando una base s\u00f3lida para an\u00e1lisis estrat\u00e9gicos y toma de decisiones.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El prop\u00f3sito principal es gestionar, transformar y cargar datos relacionados con dimensiones transversales del \u00e1mbito educativo y administrativo, garantizando su consistencia y disponibilidad para an\u00e1lisis detallados en plataformas de inteligencia de negocios.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PROGRAMA</code>, <code>DIM_JORNADA</code>, <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Archivos Excel:</li> <li>Informaci\u00f3n de jornadas y programas.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaciones (<code>Lookup</code>):<ul> <li>Asegura consistencia mediante b\u00fasquedas en tablas maestras como <code>DIM_ESTUDIANTES</code> y <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Garantiza compatibilidad con las tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Genera identificadores y valores predeterminados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_PERIODO_ACADEMICO</code></li> <li><code>DIM_PROGRAMA</code></li> <li><code>DIM_JORNADA</code></li> <li><code>DIM_POBLACION_MATRICULA</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python para automatizar tareas de descarga y validaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_PERIODO_ACADEMICO:</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_UNIDAD</code>, <code>PERIODO_ACADEMICO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>.</li> </ul> </li> <li> <p>DIM_PROGRAMA:</p> <ul> <li><code>ID_PROGRAMA</code>, <code>NOMBRE_PROGRAMA</code>, <code>DESCRIPCION</code>.</li> </ul> </li> <li> <p>DIM_JORNADA:</p> <ul> <li><code>ID_JORNADA</code>, <code>NOMBRE_JORNADA</code>, <code>HORARIO</code>.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA:</p> <ul> <li><code>ID_POBLACION</code>, <code>NOMBRE</code>, <code>DOCUMENTO</code>, <code>GENERO</code>, <code>FECHA_NACIMIENTO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagramas","title":"Diagramas","text":"<p>1. Diagrama de Flujo de Datos</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de dimensiones\n    SSIS -&gt;&gt; Excel: Leer informaci\u00f3n adicional\n    SSIS -&gt;&gt; Python: Ejecutar scripts de validaci\u00f3n\n    SSIS -&gt;&gt; DWH: Cargar datos procesados</code></pre> <p>2. Diagrama ER para Tablas de Dimensiones</p> <pre><code>erDiagram\n    DIM_PERIODO_ACADEMICO {\n        int ID_PERIODO\n        int ID_UNIDAD\n        string PERIODO_ACADEMICO\n        date FECHA_INICIO\n        date FECHA_FIN\n    }\n    DIM_PROGRAMA {\n        int ID_PROGRAMA\n        string NOMBRE_PROGRAMA\n        string DESCRIPCION\n    }\n    DIM_JORNADA {\n        int ID_JORNADA\n        string NOMBRE_JORNADA\n        string HORARIO\n    }\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION\n        string NOMBRE\n        string DOCUMENTO\n        string GENERO\n        date FECHA_NACIMIENTO\n    }\n    DIM_PERIODO_ACADEMICO ||--|| DIM_JORNADA : \"Relaci\u00f3n de Per\u00edodo con Jornadas\"\n    DIM_JORNADA ||--|| DIM_PROGRAMA : \"Asociaci\u00f3n a Programas\"\n    DIM_POBLACION_MATRICULA ||--|| DIM_PROGRAMA : \"Estudiantes en Programas\"</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-actualizar-dim-estudiantes","title":"Componente <code>Actualizar Dim Estudiantes</code>","text":"<p>Este componente es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS dise\u00f1ado para actualizar la dimensi\u00f3n de estudiantes en la base de datos. La tarea toma como entrada los datos extra\u00eddos y transformados (provenientes del componente \"Consulta Motor\") y los carga en la tabla \"Cedesarrollo\".\"DIM_ESTUDIANTES\" utilizando una conexi\u00f3n ADO.NET. Esto garantiza que la informaci\u00f3n de los estudiantes se mantenga actualizada y refleje los cambios que provienen de las fuentes de datos integradas.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Actualizaci\u00f3n de Datos de Estudiantes:   Integrar y actualizar la informaci\u00f3n de la dimensi\u00f3n de estudiantes, asegurando que los registros contengan los datos m\u00e1s recientes provenientes de diversas fuentes.</p> </li> <li> <p>Consolidaci\u00f3n de Informaci\u00f3n:   Actualizar campos clave como el tipo de documento, n\u00famero de documento y los identificadores asociados (ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE) en la tabla de estudiantes, permitiendo an\u00e1lisis precisos en el Data Warehouse.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-tecnica","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Data Flow Task (Microsoft.Pipeline).</p> </li> <li> <p>Origen de Datos:   La informaci\u00f3n se recibe de la salida del componente \"Consulta Motor\", que extrae y transforma los datos desde el \u00e1rea de staging.</p> </li> <li> <p>Transformaciones y Mapeos:   Los datos provistos incluyen, entre otros, las siguientes columnas:</p> <ul> <li>TIPO_DOCUMENTO (cadena de caracteres, 40 caracteres).</li> <li>DOCUMENTO (cadena de caracteres, 255 caracteres).</li> <li>ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE (n\u00fameros enteros).</li> </ul> </li> <li> <p>Destino de Datos:   Los registros se cargan en la tabla \"Cedesarrollo\".\"DIM_ESTUDIANTES\" mediante un destino ADO.NET configurado para:</p> <ul> <li>Utilizar inserciones masivas (Bulk Insert) para optimizar el rendimiento.</li> <li>Par\u00e1metros configurados: <code>BatchSize</code> = 0 y <code>CommandTimeout</code> = 30 segundos.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#flujo-de-ejecucion","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Extracci\u00f3n y Transformaci\u00f3n:    La salida del componente \"Consulta Motor\" suministra los datos de estudiantes, los cuales incluyen la informaci\u00f3n necesaria para la actualizaci\u00f3n de la dimensi\u00f3n.</p> </li> <li> <p>Carga de Datos:    Los datos transformados se cargan en la tabla \"Cedesarrollo\".\"DIM_ESTUDIANTES\" actualizando o insertando nuevos registros seg\u00fan corresponda, asegurando que la dimensi\u00f3n refleje la informaci\u00f3n m\u00e1s reciente.</p> </li> </ol> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant ConsultaMotor as Componente \"Consulta Motor\"\n    participant ADO_Dest as Destino ADO.NET (\"Actualizar Registros\")\n    participant DB as Base de Datos\n\n    ConsultaMotor -&gt;&gt; ADO_Dest: Env\u00eda datos (TIPO_DOCUMENTO, DOCUMENTO, ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE)\n    ADO_Dest -&gt;&gt; DB: Actualiza la tabla \"Cedesarrollo\".\"DIM_ESTUDIANTES\"\n    DB --&gt;&gt; ADO_Dest: Confirmaci\u00f3n de actualizaci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_jornada","title":"Componente <code>DIM_JORNADA</code>","text":"<p>El contenedor <code>DIM_JORNADA</code> es un contenedor de secuencias que agrupa dos flujos de datos relacionados con la actualizaci\u00f3n de la dimensi\u00f3n de jornadas. Este contenedor integra dos procesos principales: uno denominado <code>DIM_JORNADA cede</code> y otro <code>DIM_JORNADA emp</code>. Cada uno se encarga de procesar, transformar y cargar datos de jornadas desde fuentes Excel hacia la tabla de destino, aplicando distintas validaciones y transformaciones espec\u00edficas para cada flujo.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#1-proceso-dim_jornada-cede","title":"1. Proceso: DIM_JORNADA cede","text":"<p>Objetivo: Procesar y transformar datos relacionados con jornadas para la dimensi\u00f3n \u201ccede\u201d. Se realiza la lectura de datos desde un archivo Excel, se aplican transformaciones como la conversi\u00f3n y derivaci\u00f3n de columnas, se filtran registros vac\u00edos, y se enriquecen los datos mediante un componente Lookup que compara con la tabla de destino para identificar registros nuevos.</p> <p>Componentes del Flujo:</p> <ul> <li> <p>Excel Source:   Extrae datos de la hoja <code>Sheet1$</code> utilizando un administrador de conexi\u00f3n OLE DB.</p> </li> <li> <p>Sort JORNADA:   Ordena los registros por el campo <code>JORNADA</code> y elimina duplicados, garantizando un flujo de datos limpio y ordenado.</p> </li> <li> <p>ELIMINAR VACIOS (Conditional Split):   Filtra filas que no sean nulas y cuyo largo sea mayor a 0 en la columna <code>JORNADA</code> utilizando la condici\u00f3n: <pre><code>!ISNULL(JORNADA) &amp;&amp; LEN(JORNADA) &gt; 0\n</code></pre></p> </li> <li> <p>Derived Column:   Transforma el campo <code>JORNADA</code> para ajustarlo a un formato de cadena de longitud m\u00e1xima 40 y asigna valores constantes para campos como <code>ID_UNIDAD</code> (valor fijo 2) y <code>ID_JORNADA</code> (inicialmente 0).</p> </li> <li> <p>Lookup:   Realiza una b\u00fasqueda en la tabla de destino <code>[Cedesarrollo].[DIM_JORNADA]</code> utilizando los campos <code>JORNADA</code> (convertida) e <code>ID_UNIDAD</code> para determinar si el registro ya existe.  </p> <ul> <li>No coincidencias: Los registros que no se encuentran se env\u00edan a la siguiente etapa para ser insertados.</li> </ul> </li> <li> <p>Guardar en DIM_JORNADA:   Inserta los registros procesados y validados en la tabla destino <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code>.  </p> <ul> <li>Propiedades clave: </li> <li>BatchSize = 0  </li> <li>CommandTimeout = 30 segundos  </li> <li>Inserci\u00f3n masiva activada (UseBulkInsertWhenPossible = true)</li> </ul> </li> </ul> <p>Diagrama de Secuencia (DIM_JORNADA cede):</p> <pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source\n    participant Sort as Sort JORNADA\n    participant EliminarVacios as ELIMINAR VACIOS\n    participant DerivedColumn as Derived Column\n    participant Lookup as Lookup\n    participant Guardar as Guardar en DIM_JORNADA\n\n    ExcelSource -&gt;&gt; Sort: Extrae datos de la hoja Sheet1$\n    Sort -&gt;&gt; EliminarVacios: Ordena y elimina duplicados\n    EliminarVacios -&gt;&gt; DerivedColumn: Filtra registros v\u00e1lidos\n    DerivedColumn -&gt;&gt; Lookup: Transforma y asigna ID_UNIDAD\n    Lookup -&gt;&gt; Guardar: Env\u00eda registros no coincidentes</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#2-proceso-dim_jornada-emp","title":"2. Proceso: DIM_JORNADA emp","text":"<p>Objetivo: Procesar y transformar datos relacionados con jornadas para la dimensi\u00f3n \u201cemp\u201d. Este flujo se orienta a la extracci\u00f3n de informaci\u00f3n de otra fuente Excel, con sus propias transformaciones y validaciones para asegurar que los datos sean consistentes antes de ser cargados en la misma tabla de destino <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code>.</p> <p>Componentes del Flujo:</p> <ul> <li> <p>Excel Source 1:   Lee los datos de la hoja <code>Sheet1$</code> desde un archivo Excel utilizando un administrador de conexi\u00f3n espec\u00edfico para esta fuente.</p> </li> <li> <p>Sort:   Ordena los registros por la columna <code>JORNADA</code> y elimina duplicados, prepar\u00e1ndolos para el procesamiento posterior.</p> </li> <li> <p>Conditional Split:   Filtra las filas verificando que el campo <code>JORNADA</code> no sea nulo y tenga contenido (condici\u00f3n: <code>!ISNULL(JORNADA) &amp;&amp; LEN(JORNADA) &gt; 0</code>).</p> </li> <li> <p>Derived Column:   Genera la columna <code>JORNADA_Convertida</code>, convirtiendo el valor del campo <code>JORNADA</code> a una cadena de longitud 40. Adem\u00e1s, asigna valores fijos a <code>ID_UNIDAD</code> (valor 3) y a <code>ID_JORNADA</code> (inicialmente 0).</p> </li> <li> <p>Lookup:   Compara los registros procesados con la tabla de destino <code>[Cedesarrollo].[DIM_JORNADA]</code> mediante un Lookup que utiliza los campos <code>JORNADA_Convertida</code> e <code>ID_UNIDAD</code> para identificar registros existentes.  </p> <ul> <li>Registros sin coincidencia: Se env\u00edan a la salida de \u201cNo Match\u201d para ser insertados.</li> </ul> </li> <li> <p>Destino de ADO.NET:   Inserta los datos transformados y filtrados en la tabla <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code>.  </p> <ul> <li>Propiedades clave: </li> <li>BatchSize = 0  </li> <li>CommandTimeout = 30 segundos  </li> <li>Bulk Insert activado</li> </ul> </li> </ul> <p>Diagrama de Secuencia (DIM_JORNADA emp):</p> <pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source 1\n    participant Sort as Sort\n    participant ConditionalSplit as Conditional Split\n    participant DerivedColumn as Derived Column\n    participant Lookup as Lookup\n    participant Destino as Destino de ADO.NET\n\n    ExcelSource -&gt;&gt; Sort: Extrae datos de Excel\n    Sort -&gt;&gt; ConditionalSplit: Ordena y filtra registros v\u00e1lidos\n    ConditionalSplit -&gt;&gt; DerivedColumn: Pasa registros v\u00e1lidos\n    DerivedColumn -&gt;&gt; Lookup: Aplica transformaciones y asigna ID_UNIDAD\n    Lookup -&gt;&gt; Destino: Inserta registros nuevos en DIM_JORNADA</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_periodo_academico-py","title":"Componente <code>dim_periodo_academico py</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tarea dim_periodo_academico py ejecuta un script de Python para procesar la dimensi\u00f3n <code>PERIODO_ACADEMICO</code>. Este script realiza operaciones espec\u00edficas relacionadas con la extracci\u00f3n, transformaci\u00f3n y carga (ETL) para actualizar la tabla de dimensiones en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#detalles-de-la-configuracion","title":"Detalles de la Configuraci\u00f3n","text":"<ol> <li> <p>Ejecutable</p> <ul> <li>Ruta del ejecutable:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Script ejecutado:      <pre><code>dim_periodo_academico.py\n</code></pre></li> </ul> </li> <li> <p>Directorio de trabajo</p> <ul> <li>Ruta:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul> </li> <li> <p>Argumentos</p> <ul> <li>Script llamado con el siguiente comando:     <pre><code>dim_periodo_academico.py\n</code></pre></li> </ul> </li> <li> <p>Propiedades Avanzadas</p> <ul> <li>Variables utilizadas:<ul> <li><code>Python_Executable</code>: Variable del proyecto que define la ruta del ejecutable de Python.</li> <li><code>Working_Directory</code>: Variable que especifica el directorio base para los scripts.</li> </ul> </li> <li>Propiedad de <code>Executable</code>:      <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>Propiedad de <code>WorkingDirectory</code>:      <pre><code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> </ul> </li> </ol> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSISPackage as Paquete SSIS\n    participant PythonScript as dim_periodo_academico.py\n\n    SSISPackage-&gt;&gt;PythonScript: Llama al ejecutable de Python\n    PythonScript-&gt;&gt;Database: Procesa datos de `PERIODO_ACADEMICO`\n    PythonScript-&gt;&gt;SSISPackage: Retorna el estado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_periodo_academico","title":"Componente <code>DIM_PERIODO_ACADEMICO</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos en SSIS realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) para la dimensi\u00f3n <code>DIM_PERIODO_ACADEMICO</code>. Utiliza datos de una fuente de Excel, realiza conversiones de tipo y valida los registros con una tabla de referencia antes de cargarlos en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae los datos desde una hoja de Excel llamada <code>Sheet1$</code>.</li> <li>Conexi\u00f3n: <code>Administrador de conexiones con Excel 8</code>.</li> <li>Columnas Extra\u00eddas:<ul> <li><code>PERIODO</code> (Texto, longitud 255)</li> <li><code>ID_UNIDAD</code> (Real)</li> <li><code>FECHA_INICIO</code> (Fecha)</li> <li><code>FECHA_FIN</code> (Fecha)</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos de entrada en tipos y formatos espec\u00edficos.</li> <li>Columnas Convertidas:</li> <li><code>_PERIODO</code> (Texto, longitud 40)</li> <li><code>_ID_UNIDAD</code> (Entero)</li> <li><code>_FECHA_INICIO</code> (Fecha)</li> <li><code>_FECHA_FIN</code> (Fecha)</li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Compara los registros con la tabla <code>DIM_PERIODO_ACADEMICO</code> en la base de datos para identificar coincidencias.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code>.</li> <li>Consulta de Validaci\u00f3n: <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\nWHERE [PERIODO_ACADEMICO] = ? \n    AND [ID_UNIDAD] = ?\n</code></pre></li> <li>Columnas Validadas: <code>PERIODO_ACADEMICO</code>, <code>ID_UNIDAD</code></li> <li>Salidas:<ul> <li><code>Match Output</code>: Registros coincidentes.</li> <li><code>No Match Output</code>: Registros sin coincidencias, enviados para carga.</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Inserta los registros no coincidentes en la tabla de destino.</li> <li>Tabla de Destino: <code>\"Cedesarrollo\".\"DIM_PERIODO_ACADEMICO\"</code>.</li> <li>Propiedades:</li> <li>Inserci\u00f3n Masiva: Activada.</li> <li>Batch Size: 0 (Utiliza el tama\u00f1o predeterminado del b\u00fafer de SSIS).</li> <li>Timeout de Comando: 30 segundos.</li> <li>Columnas Insertadas: <code>PERIODO_ACADEMICO</code>, <code>ID_UNIDAD</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code></li> </ul> </li> </ol> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant Excel as Fuente de Excel\n    participant DataConversion as Conversi\u00f3n de Datos\n    participant Lookup as Validaci\u00f3n de Datos\n    participant Destino as Base de Datos\n\n    Excel-&gt;&gt;DataConversion: Extraer datos\n    DataConversion-&gt;&gt;Lookup: Validar con tabla de referencia\n    Lookup-&gt;&gt;Destino: Insertar registros no coincidentes</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-tarea-cede_diseno_curricular","title":"Componente <code>Tarea cede_Dise\u00f1o_Curricular</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Tarea cede_Dise\u00f1o_Curricular</code> es un componente de ejecuci\u00f3n de procesos en SSIS que utiliza un script Python para procesar o descargar datos relacionados con el dise\u00f1o curricular de una instituci\u00f3n educativa. Este script es ejecutado en un entorno Python configurado previamente.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#detalles-del-componente","title":"Detalles del Componente","text":"<ul> <li>Tipo de Tarea: <code>Execute Process Task</code>.</li> <li>Descripci\u00f3n: Ejecuta un script Python (<code>download.py</code>) con un argumento espec\u00edfico (<code>--key cede_Dise\u00f1o_Curricular</code>) para realizar tareas como descargar o transformar datos asociados al dise\u00f1o curricular.</li> <li>Propiedades Clave:<ul> <li>Ejecutable: Ruta al ejecutable de Python configurado en la variable <code>Python_Executable</code> del proyecto.</li> <li>Directorio de Trabajo: Ruta configurada en la variable <code>Working_Directory</code> del proyecto.</li> <li>Argumentos: <code>download.py --key cede_Dise\u00f1o_Curricular</code>.</li> </ul> </li> </ul> <p>Propiedades T\u00e9cnicas</p> Propiedad Valor Executable <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code> Working Directory <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code> Arguments <code>download.py --key cede_Dise\u00f1o_Curricular</code> Tiempo de Ejecuci\u00f3n No especificado (timeout predeterminado del sistema). <p>Flujo de Trabajo</p> <ol> <li> <p>Inicio del Proceso: </p> <ul> <li>La tarea se inicia autom\u00e1ticamente al ejecutarse el paquete SSIS.</li> </ul> </li> <li> <p>Definici\u00f3n del Contexto:</p> <ul> <li>El entorno de ejecuci\u00f3n y los argumentos se configuran din\u00e1micamente utilizando expresiones vinculadas a las variables del proyecto:</li> <li><code>@[$Project::Python_Executable]</code> para el ejecutable.</li> <li><code>@[$Project::Working_Directory]</code> para el directorio de trabajo.</li> </ul> </li> <li> <p>Ejecuci\u00f3n del Script:</p> <ul> <li>El script Python (<code>download.py</code>) se ejecuta con el argumento <code>--key cede_Dise\u00f1o_Curricular</code>.</li> <li>El script puede realizar operaciones como descarga de datos, validaci\u00f3n, transformaci\u00f3n, etc.</li> </ul> </li> <li> <p>Finalizaci\u00f3n:</p> <ul> <li>El proceso concluye una vez que el script finaliza su ejecuci\u00f3n. Los resultados del script pueden ser monitoreados mediante los logs configurados en el paquete.</li> </ul> </li> </ol> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as Script Python\n    participant Sistema as Sistema Operativo\n\n    SSIS -&gt;&gt; Python: Ejecutar `download.py --key cede_Dise\u00f1o_Curricular`\n    Python -&gt;&gt; Sistema: Leer datos del directorio configurado\n    Sistema -&gt;&gt; Python: Proveer acceso a los archivos\n    Python -&gt;&gt; Python: Procesar o transformar datos\n    Python -&gt;&gt; SSIS: Retornar estado de finalizaci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_programa","title":"Componente <code>Data DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Data DIM_PROGRAMA</code> implementa un flujo de datos para extraer informaci\u00f3n de un archivo Excel, procesarla mediante operaciones de clasificaci\u00f3n, agregaci\u00f3n y b\u00fasquedas, y finalmente cargar los datos en la tabla <code>DIM_PROGRAMA</code> de la base de datos. Este proceso se utiliza para estructurar y consolidar datos relacionados con programas acad\u00e9micos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos: <code>Excel Source</code></p> <ul> <li>Prop\u00f3sito: Leer datos desde un archivo Excel ubicado en la ruta configurada en el administrador de conexiones <code>OleDbConnection</code>.</li> <li>Columnas Procesadas:<ul> <li><code>PROGRAMA</code></li> <li><code>COD_MODULO</code></li> <li><code>MODULO</code></li> <li><code>SEMESTRE</code>, entre otras.</li> </ul> </li> <li>Propiedades Principales:<ul> <li>Tabla de Origen: <code>Sheet1$</code></li> <li>Acceso: Modo directo (<code>AccessMode = 0</code>).</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Sort PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Ordenar los datos por la columna <code>PROGRAMA</code> y eliminar duplicados.</li> <li>Propiedades Principales:<ul> <li>Columna de Ordenaci\u00f3n: <code>PROGRAMA</code>.</li> <li>Eliminaci\u00f3n de Duplicados: Activada.</li> </ul> </li> <li>Salida:<ul> <li>Datos ordenados para el componente de b\u00fasqueda.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Lookup PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Realizar una b\u00fasqueda en la tabla <code>DIM_PROGRAMA</code> para identificar programas existentes.</li> <li>Propiedades Principales:<ul> <li>SQL: <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA] WHERE [PROGRAMA] = ?\n</code></pre></li> <li>Comportamiento de No Coincidencia: Las filas sin coincidencias se env\u00edan al componente de agregaci\u00f3n.</li> </ul> </li> <li>Salida:<ul> <li>Coincidencias: Filas que ya existen en la tabla <code>DIM_PROGRAMA</code>.</li> <li>No Coincidencias: Filas nuevas que requieren agregaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Aggregate 1</code></p> <ul> <li>Prop\u00f3sito: Consolidar datos agrupados por la columna <code>PROGRAMA</code>.</li> <li>Propiedades Principales:<ul> <li>Columna de Agrupaci\u00f3n: <code>PROGRAMA</code>.</li> <li>Escala de Claves: Baja (500,000 valores aproximados).</li> </ul> </li> <li>Salida:<ul> <li>Datos agrupados enviados al destino.</li> </ul> </li> </ul> </li> <li> <p>Destino: <code>Guardar DIM_PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Cargar los datos procesados en la tabla <code>DIM_PROGRAMA</code> de la base de datos.</li> <li>Propiedades Principales:<ul> <li>Tabla de Destino: <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code>.</li> <li>Inserci\u00f3n Masiva: Activada.</li> </ul> </li> <li>Columnas Procesadas:<ul> <li><code>PROGRAMA</code>.</li> </ul> </li> </ul> </li> </ol> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant Excel as Excel Source\n    participant Sort as Sort PROGRAMA\n    participant Lookup as Lookup PROGRAMA\n    participant Aggregate as Aggregate 1\n    participant Destino as Guardar DIM_PROGRAMA\n\n    Excel -&gt;&gt; Sort: Leer datos\n    Sort -&gt;&gt; Lookup: Ordenar datos\n    Lookup -&gt;&gt; Aggregate: Enviar no coincidencias\n    Aggregate -&gt;&gt; Destino: Enviar datos agregados\n    Destino -&gt;&gt; Destino: Cargar en `DIM_PROGRAMA`</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_plan_curricular","title":"Componente <code>Data DIM_PLAN_CURRICULAR</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente <code>Data DIM_PLAN_CURRICULAR</code> es un flujo de datos que extrae informaci\u00f3n desde una fuente Excel, realiza transformaciones derivadas y operaciones de b\u00fasqueda, y finalmente inserta los datos procesados en la tabla <code>DIM_PLAN_CURRICULAR</code> de la base de datos. Este flujo asegura la consolidaci\u00f3n y estructuraci\u00f3n de la informaci\u00f3n del plan curricular.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos: <code>PLAN_CURRICULAR</code></p> <ul> <li>Prop\u00f3sito: Leer datos desde un archivo Excel utilizando el administrador de conexiones <code>OleDbConnection</code>.</li> <li>Columnas Procesadas:<ul> <li><code>PROGRAMA</code>, <code>COD_MODULO</code>, <code>MODULO</code>, <code>SEMESTRE</code>, <code>INTENSIDAD_HORARIA</code>, entre otras.</li> </ul> </li> <li>Propiedades Principales:<ul> <li>Tabla de Origen: <code>Sheet1$</code></li> <li>Modo de Acceso: Directo (<code>AccessMode = 0</code>).</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Tranformar Columnas</code></p> <ul> <li>Prop\u00f3sito: Crear nuevas columnas derivadas a partir de columnas existentes.</li> <li>Columnas Derivadas:<ul> <li><code>_SEMESTRE</code>: Convertido de <code>SEMESTRE</code> a formato <code>DT_WSTR, 40</code>.</li> <li><code>_MODULO</code>: Convertido de <code>MODULO</code> a formato <code>DT_WSTR, 200</code>.</li> <li><code>_INTENSIDAD_HORARIA</code>, <code>_INTENSIDAD_HORARIA_SEMANAL</code>, <code>_NO_CREDITOS</code>: Convertidas a formato <code>DT_WSTR, 40</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Lookup ID_PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Verificar y asociar la clave primaria <code>ID_PROGRAMA</code> de la tabla <code>DIM_PROGRAMA</code> con las filas procesadas.</li> <li>Propiedades Principales:<ul> <li>SQL: <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA] WHERE [PROGRAMA] = ?\n</code></pre></li> <li>Comportamiento de No Coincidencia: Ignorar fallas (<code>IgnoreFailure</code>).</li> </ul> </li> <li>Salida:<ul> <li>Coincidencias: Filas existentes en <code>DIM_PROGRAMA</code>.</li> <li>No Coincidencias: Se procesan en el siguiente paso.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Lookup DIM_PLAN_CURRICULAR</code></p> <ul> <li>Prop\u00f3sito: Identificar filas ya existentes en la tabla <code>DIM_PLAN_CURRICULAR</code>.</li> <li>Propiedades Principales:<ul> <li>SQL: <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PLAN_CURRICULAR] WHERE [MODULO] = ?\n</code></pre></li> <li>Comportamiento de No Coincidencia: Filas nuevas se env\u00edan al destino.</li> </ul> </li> </ul> </li> <li> <p>Destino: <code>Guardar DIM_PLAN_CURRICULAR</code></p> <ul> <li>Prop\u00f3sito: Insertar los datos procesados en la tabla <code>DIM_PLAN_CURRICULAR</code> de la base de datos.</li> <li>Propiedades Principales:<ul> <li>Tabla de Destino: <code>\"Cedesarrollo\".\"DIM_PLAN_CURRICULAR\"</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible = true</code>).</li> </ul> </li> <li>Columnas Procesadas: <code>_MODULO</code>, <code>_INTENSIDAD_HORARIA</code>, <code>_INTENSIDAD_HORARIA_SEMANAL</code>, <code>_NO_CREDITOS</code>, <code>_SEMESTRE</code>, <code>ID_PROGRAMA</code>.</li> </ul> </li> </ol> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant Excel as PLAN_CURRICULAR\n    participant Transform as Tranformar Columnas\n    participant LookupID as Lookup ID_PROGRAMA\n    participant LookupPlan as Lookup DIM_PLAN_CURRICULAR\n    participant Destino as Guardar DIM_PLAN_CURRICULAR\n\n    Excel -&gt;&gt; Transform: Leer datos\n    Transform -&gt;&gt; LookupID: Generar columnas derivadas\n    LookupID -&gt;&gt; LookupPlan: Enviar registros coincidentes\n    LookupPlan -&gt;&gt; Destino: Enviar filas nuevas\n    Destino -&gt;&gt; Destino: Insertar en DIM_PLAN_CURRICULAR</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-tarea-ep-ept-05","title":"Componente <code>Tarea EP-EPT-05</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EPT-05 es un componente de ejecuci\u00f3n de procesos (Execute Process Task) que forma parte del contenedor DIM_PLAN_CURRICULAR emp. Su funci\u00f3n es ejecutar un script de Python para realizar operaciones complementarias al flujo principal de actualizaci\u00f3n de la dimensi\u00f3n de planes curriculares. Este script, <code>download.py</code>, se invoca con el par\u00e1metro <code>--key EPEPT05</code>, lo que indica que se ejecutan tareas espec\u00edficas relacionadas con el proceso \"EPEPT05\".</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#propiedades-principales","title":"Propiedades Principales","text":"<ul> <li> <p>Ejecutable:</p> <ul> <li>Se utiliza el int\u00e9rprete de Python definido din\u00e1micamente a trav\u00e9s de la variable de proyecto <code>@[$Project::Python_Executable]</code>.</li> <li>Ruta de ejemplo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> </ul> </li> <li> <p>Directorio de Trabajo:</p> <ul> <li>Configurado din\u00e1micamente mediante la expresi\u00f3n: <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code></li> <li>Esto asegura que el script se ejecute en el entorno adecuado.</li> </ul> </li> <li> <p>Argumentos del Script:</p> <ul> <li>Se ejecuta el comando: <code>download.py --key EPEPT05</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#funcionalidad-y-proposito","title":"Funcionalidad y Prop\u00f3sito","text":"<ul> <li> <p>Objetivo:   Este componente se encarga de ejecutar el script Python que realiza tareas complementarias (por ejemplo, descarga de datos o validaciones previas) necesarias para la actualizaci\u00f3n de la dimensi\u00f3n de planes curriculares.</p> </li> <li> <p>Integraci\u00f3n en el Proceso Global:   La ejecuci\u00f3n de esta tarea se realiza antes de iniciar el procesamiento principal de datos en el contenedor DIM_PLAN_CURRICULAR emp, garantizando que el entorno y la informaci\u00f3n requerida est\u00e9n preparados para las operaciones siguientes.</p> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as Tarea EP-EPT-05\n    participant OS as Sistema Operativo\n    participant PythonScript as Script download.py\n\n    SSIS -&gt;&gt; OS: Ejecuta el int\u00e9rprete de Python\n    OS -&gt;&gt; PythonScript: Llama a `download.py --key EPEPT05`\n    PythonScript --&gt;&gt; OS: Retorna resultado del proceso (\u00e9xito o error)\n    OS --&gt;&gt; SSIS: Devuelve el estado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_programa_1","title":"Componente Data DIM_PROGRAMA","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_PROGRAMA es un Data Flow Task que se encarga de extraer, transformar y cargar datos provenientes de un archivo Excel, para finalmente insertarlos en la tabla de destino <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code> de la base de datos. Este flujo de datos consolida informaci\u00f3n sobre programas acad\u00e9micos, garantizando la integridad y calidad de los datos antes de su almacenamiento.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#funcionalidad-y-proceso","title":"Funcionalidad y Proceso","text":"<p>El proceso se divide en varias etapas, las cuales se describen a continuaci\u00f3n:</p> <ol> <li> <p>Extracci\u00f3n de Datos (Excel Source)</p> <ul> <li>Fuente: Se utiliza un origen de datos Excel para leer informaci\u00f3n de la hoja <code>Sheet1$</code>.</li> <li>Columnas Procesadas: Entre las columnas se encuentra la columna <code>PROGRAMA</code>, que es el dato clave a trabajar.</li> <li>Conexi\u00f3n: Se emplea un administrador de conexi\u00f3n OLE DB (definido en el Connection Manager <code>Excel_Connection_Dim_Programa_DE</code>).</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos</p> <ul> <li>Aggregate 1:     Se utiliza una transformaci\u00f3n de tipo Aggregate para agrupar los registros por la columna <code>PROGRAMA</code>.  <ul> <li>Funci\u00f3n: Re\u00fane las filas para obtener un conjunto \u00fanico de valores de <code>PROGRAMA</code>.  </li> <li>Par\u00e1metros: </li> <li>KeyScale: Se especifica como 0 (valor bajo, es decir, para aproximadamente 500,000 claves).</li> </ul> </li> <li>Sort PROGRAMA:     Antes del agrupamiento o para garantizar un orden correcto, se aplica una transformaci\u00f3n Sort que ordena los datos en base a la columna <code>PROGRAMA</code> (eliminando duplicados).</li> <li>Lookup ID_PROGRAMA:     Se realiza un Lookup para obtener la clave primaria <code>ID_PROGRAMA</code> de la tabla <code>[Cedesarrollo].[DIM_PROGRAMA]</code>.  <ul> <li>SQL del Lookup: <pre><code>select * from [Cedesarrollo].[DIM_PROGRAMA] where [PROGRAMA] = ?\n</code></pre></li> <li>Comportamiento:   Si se encuentra una coincidencia, se recupera el <code>ID_PROGRAMA</code> correspondiente; de lo contrario, se considerar\u00e1 que la fila es nueva.</li> </ul> </li> <li>Lookup PROGRAMA:     Otra transformaci\u00f3n Lookup se utiliza para validar la existencia del valor de <code>PROGRAMA</code> en la dimensi\u00f3n, usando la misma columna como par\u00e1metro de b\u00fasqueda.<ul> <li>SQL del Lookup: <pre><code>select * from (select * from [Cedesarrollo].[DIM_PROGRAMA]) [refTable]\nwhere [refTable].[PROGRAMA] = ?\n</code></pre></li> <li>NoMatchBehavior:   Se configura para enviar a la salida \u201cno match\u201d aquellas filas que no tienen coincidencia, permitiendo la posterior inserci\u00f3n de nuevos registros.</li> </ul> </li> </ul> </li> <li> <p>Componente de Script</p> <ul> <li>Componente de Script Personalizado:     Se incluye un Script Component (implementado en C#) que recibe la columna <code>PROGRAMA</code> y aplica una transformaci\u00f3n para capitalizar el valor (por ejemplo, convertirlo a \"Title Case\").  <ul> <li>Funci\u00f3n: </li> <li>Lee el valor original de <code>PROGRAMA</code>.</li> <li>Utiliza la cultura \u201ces-ES\u201d para convertir el texto a formato Title Case.</li> <li>Almacena el resultado en una columna de salida denominada <code>PROGRAMACAPITALIZADO</code>.</li> </ul> </li> <li>Prop\u00f3sito:     Este paso permite unificar el formato de los nombres de programa antes de su inserci\u00f3n en la base de datos.</li> </ul> </li> <li> <p>Carga de Datos (Destino: ADO.NET Destination)</p> <ul> <li>Destino:     La transformaci\u00f3n final consiste en el componente ADO.NET Destination que inserta los datos transformados en la tabla <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code>.</li> <li>Propiedades Clave: <ul> <li>BatchSize: 0 (se utiliza el tama\u00f1o predeterminado del b\u00fafer de SSIS).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: Activado, para mejorar el rendimiento de la inserci\u00f3n masiva.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-flujo-de-datos","title":"Diagrama de Flujo de Datos","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#flowchart-td-aexcel-source-bsort-programa-ordena-y-elimina-duplicados-b-caggregate-1-agrupa-por-programa-c-dlookup-id_programa-obtiene-id-si-existe-d-elookup-programa-valida-existencia-en-dim_programa-e-fcomponente-de-script-capitaliza-programa-f-gguardar-dim_programa-inserta-en-la-tabla-de-destino","title":"<pre><code>flowchart TD\n    A[Excel Source] --&gt; B[Sort PROGRAMA Ordena y elimina duplicados]\n    B --&gt; C[Aggregate 1 Agrupa por PROGRAMA]\n    C --&gt; D[Lookup ID_PROGRAMA Obtiene ID si existe]\n    D --&gt; E[Lookup PROGRAMA Valida existencia en DIM_PROGRAMA]\n    E --&gt; F[Componente de Script Capitaliza PROGRAMA]\n    F --&gt; G[Guardar DIM_PROGRAMA Inserta en la tabla de destino]</code></pre>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_plan_curricular_1","title":"Componente: Data DIM_PLAN_CURRICULAR","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_PLAN_CURRICULAR es un Data Flow Task que procesa la informaci\u00f3n de planes curriculares proveniente de un archivo Excel. Su objetivo es transformar y validar los datos antes de insertarlos en la tabla de destino en la base de datos, asegurando la calidad e integridad de la informaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#proceso-etl","title":"Proceso ETL","text":"<p>El flujo de datos se compone de los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n de Datos (Excel Source)</p> <ul> <li>Origen: Se extraen datos desde la hoja <code>Sheet1$</code> de un archivo Excel.</li> <li>Columnas Clave: <ul> <li><code>REGISTRO</code></li> <li><code>PROGRAMA</code></li> <li><code>COD_MODULO</code></li> <li><code>MODULO</code></li> <li><code>ABREVIACI\u00d3N</code></li> <li><code>SEMESTRE</code></li> <li><code>INTENSIDAD_HORARIA</code></li> <li><code>INTENSIDAD_HORARIA_SEMANAL</code></li> <li><code>NO_CREDITOS</code></li> </ul> </li> <li>Conexi\u00f3n: Utiliza un administrador de conexi\u00f3n OLE DB definido en <code>Excel_Connection_Dim_Programa_DE</code>.</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos \u2013 Tranformar Columnas (Derived Column)</p> <ul> <li>Funci\u00f3n:     Se crean columnas derivadas para formatear y convertir los valores extra\u00eddos:<ul> <li><code>_SEMESTRE</code>: Convierte el valor de <code>SEMESTRE</code> a una cadena de 40 caracteres.</li> <li><code>_INTENSIDAD_HORARIA</code>: Convierte el valor de <code>INTENSIDAD_HORARIA</code> a una cadena de 40 caracteres.</li> <li><code>_INTENSIDAD_HORARIA_SEMANAL</code>: Convierte el valor de <code>INTENSIDAD_HORARIA_SEMANAL</code> a una cadena de 40 caracteres.</li> <li><code>_NO_CREDITOS</code>: Convierte el valor de <code>NO_CREDITOS</code> a una cadena de 40 caracteres.</li> <li><code>_MODULO</code>: Convierte el valor de <code>MODULO</code> a una cadena de 200 caracteres.</li> </ul> </li> <li>Objetivo: Normalizar y preparar los datos para la validaci\u00f3n y la carga.</li> </ul> </li> <li> <p>Ordenaci\u00f3n \u2013 Sort PROGRAMA (Sort)</p> <ul> <li>Funci\u00f3n:     Ordena los datos en funci\u00f3n de la columna <code>PROGRAMA</code>, eliminando duplicados para facilitar el procesamiento posterior.</li> <li>Propiedades Destacadas:<ul> <li>EliminateDuplicates: Activado.</li> <li>MaximumThreads: -1 (utiliza el m\u00e1ximo disponible).</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n y Enriquecimiento \u2013 Lookup Transformations</p> <ul> <li> <p>Lookup DIM_PLAN_CURRICULAR:</p> <ul> <li>Objetivo:   Verificar si el valor de la columna derivada <code>_MODULO</code> ya existe en la tabla de destino.</li> <li>Consulta: <pre><code>select * from (select * from [Cedesarrollo].[DIM_PLAN_CURRICULAR]) [refTable]\nwhere [refTable].[MODULO] = ?\n</code></pre></li> <li>Comportamiento en No Coincidencia:   Los registros sin coincidencia se env\u00edan a la salida \u201cLookup No Match Output\u201d, lo que indica que son nuevos y deben insertarse.</li> </ul> </li> <li> <p>Lookup ID_PROGRAMA:</p> <ul> <li>Objetivo:   Obtener el <code>ID_PROGRAMA</code> correspondiente desde la tabla <code>[Cedesarrollo].[DIM_PROGRAMA]</code> utilizando el valor de <code>PROGRAMA</code> extra\u00eddo del archivo Excel.</li> <li>Consulta: <pre><code>select * from [Cedesarrollo].[DIM_PROGRAMA] where [PROGRAMA] = ?\n</code></pre></li> <li>Uso:   La salida de este Lookup se utiliza en la siguiente transformaci\u00f3n para separar registros existentes de aquellos nuevos.</li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n de Datos \u2013 Conditional Split</p> <ul> <li>Funci\u00f3n:     Eval\u00faa la existencia del valor <code>ID_PROGRAMA</code> (resultado del Lookup ID_PROGRAMA).  </li> <li>Condici\u00f3n: <ul> <li>Case 1: Registros donde <code>ID_PROGRAMA</code> no es <code>NULL</code> (lo que indica que ya existe un registro relacionado).</li> <li>Default: Registros donde <code>ID_PROGRAMA</code> es <code>NULL</code> (nuevos registros que deben ser insertados).</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos \u2013 Guardar DIM_PLAN_CURRICULAR (ADO.NET Destination)</p> <ul> <li>Funci\u00f3n:     Inserta los registros nuevos (por ejemplo, los provenientes del \u201cCase 1\u201d del Conditional Split) en la tabla <code>\"Cedesarrollo\".\"DIM_PLAN_CURRICULAR\"</code>.</li> <li>Propiedades Clave:<ul> <li>BatchSize: 0 (utiliza el tama\u00f1o del buffer interno).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: True, para optimizar la inserci\u00f3n masiva.</li> </ul> </li> </ul> </li> </ol> <p>Diagrama de Flujo de Datos</p> <pre><code>flowchart TD\n    Start[Inicio: Excel Source PLAN_CURRICULAR]\n    Transform[Transformar Columnas: Crear _SEMESTRE, _INTENSIDAD_HORARIA, _INTENSIDAD_HORARIA_SEMANAL, _NO_CREDITOS, _MODULO]\n    Sort[Ordenar PROGRAMA: Sort PROGRAMA]\n    LookupPlan[Verificar Existencia: Lookup DIM_PLAN_CURRICULAR]\n    LookupID[Obtener ID: Lookup ID_PROGRAMA]\n    Split[Evaluar Registro: Conditional Split]\n    Save[Guardar Nuevos Registros en DIM_PLAN_CURRICULAR]\n    Existing[Gestionar Registros Existentes]\n    End[Fin]\n\n    Start --&gt; Transform\n    Transform --&gt; Sort\n    Sort --&gt; LookupPlan\n    LookupPlan --&gt; LookupID\n    LookupID --&gt; Split\n    Split -- \"Si ID_PROGRAMA no es nulo\" --&gt; Save\n    Split -- \"Si ID_PROGRAMA es nulo\" --&gt; Existing\n    Save --&gt; End\n    Existing --&gt; End</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/","title":"06. CEDESARROLLO_FACT","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#cedesarrollo_fact","title":"CEDESARROLLO_FACT","text":"<p>El paquete SSIS \"06-CEDESARROLLO_FACT\" es un sistema robusto dise\u00f1ado para realizar procesos ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) relacionados con datos operativos educativos y administrativos. Este paquete se enfoca en integrar informaci\u00f3n sobre matr\u00edculas, jornadas, programas, per\u00edodos acad\u00e9micos y evaluaciones, consolidando datos desde m\u00faltiples fuentes en el Data Warehouse <code>DWH_COMFENALCO</code>. El objetivo principal es asegurar la disponibilidad de datos precisos y consistentes para an\u00e1lisis estrat\u00e9gico y generaci\u00f3n de reportes.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El paquete tiene como prop\u00f3sito principal gestionar y transformar datos cr\u00edticos de varias fuentes. A trav\u00e9s de un flujo de trabajo modular y escalable, asegura la integraci\u00f3n de los datos, prepar\u00e1ndolos para an\u00e1lisis detallados y toma de decisiones estrat\u00e9gicas.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>DIM_ESTUDIANTES</code>: Informaci\u00f3n b\u00e1sica de estudiantes.</li> <li><code>DIM_JORNADA</code>: Detalles de las jornadas acad\u00e9micas.</li> <li><code>DIM_PROGRAMA</code>: Datos de programas educativos.</li> <li><code>FACT_NOTAS</code>: Registros de notas finales de los estudiantes.</li> <li>Archivos Excel y CSV:</li> <li>Planes curriculares.</li> <li>Programas educativos y datos de matr\u00edculas.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexi\u00f3n ADO.NET para acceso eficiente a bases de datos.</li> <li>Conexi\u00f3n OLE DB para lectura de archivos Excel y CSV.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>C\u00e1lculo de campos adicionales como <code>ID_PROGRAMA</code> y <code>NOTA_PROMEDIO</code>.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Comparaci\u00f3n de datos con tablas maestras como <code>DIM_PERIODO_ACADEMICO</code> y <code>DIM_JORNADA</code> para garantizar consistencia.</li> </ul> </li> <li>Clasificaci\u00f3n (<code>Conditional Split</code>):<ul> <li>Filtrado de datos bas\u00e1ndose en condiciones como registros v\u00e1lidos e inv\u00e1lidos.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad entre columnas de entrada y destino.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas utilizadas:<ul> <li><code>DIM_PERIODO_ACADEMICO</code>: Detalles de los per\u00edodos acad\u00e9micos.</li> <li><code>DIM_JORNADA</code>: Informaci\u00f3n sobre jornadas.</li> <li><code>DIM_PROGRAMA</code>: Datos de programas educativos.</li> <li><code>FACT_NOTAS</code>: Registros consolidados de evaluaciones.</li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones Masivas (<code>Bulk Insert</code>): Activada para maximizar el rendimiento en la carga de datos.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python:<ul> <li>Automatizan tareas como descargas desde rutas predefinidas y validaci\u00f3n de datos en tiempo real.</li> </ul> </li> <li>Integraci\u00f3n:<ul> <li>Uso de variables din\u00e1micas para ajustar rutas de trabajo y par\u00e1metros espec\u00edficos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_ESTUDIANTES:</p> <ul> <li><code>ID_ESTUDIANTE</code>: Identificador \u00fanico.</li> <li><code>NOMBRE</code>: Nombre del estudiante.</li> <li><code>DOCUMENTO</code>: Documento de identidad.</li> </ul> </li> <li> <p>DIM_JORNADA:</p> <ul> <li><code>ID_JORNADA</code>: Identificador de la jornada.</li> <li><code>JORNADA</code>: Descripci\u00f3n de la jornada.</li> </ul> </li> <li> <p>DIM_PROGRAMA:</p> <ul> <li><code>ID_PROGRAMA</code>: Identificador \u00fanico.</li> <li><code>NOMBRE_PROGRAMA</code>: Nombre del programa acad\u00e9mico.</li> </ul> </li> <li> <p>FACT_NOTAS:</p> <ul> <li><code>ID_NOTA</code>: Identificador \u00fanico de la nota.</li> <li><code>ID_ESTUDIANTE</code>: Relaci\u00f3n con el estudiante.</li> <li><code>ID_JORNADA</code>: Relaci\u00f3n con la jornada.</li> <li><code>NOTA_FINAL</code>: Evaluaci\u00f3n final.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos (Data Flow Diagram - DFD)</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extrae datos de DIM_ESTUDIANTES, DIM_JORNADA y FACT_NOTAS\n    SSIS -&gt;&gt; Python: Ejecuta scripts para validaci\u00f3n y descargas\n    SSIS -&gt;&gt; DWH: Carga datos procesados en tablas destino</code></pre> <ol> <li>Diagrama de Transformaciones y Validaciones</li> </ol> <pre><code>graph TD\n    %% Entradas\n    A1[DIM_ESTUDIANTES] --&gt; T1[Derived Column: Transformaci\u00f3n de campos]\n    A2[DIM_JORNADA] --&gt; T2[Lookup: Validaci\u00f3n de jornadas]\n    A3[FACT_NOTAS] --&gt; T3[Conditional Split: Filtrado de registros]\n\n    %% Transformaciones\n    T1 --&gt; L1[Lookup ID_ESTUDIANTE]\n    T2 --&gt; L2[Lookup ID_JORNADA]\n    T3 --&gt; C1[Guardar datos transformados]</code></pre> <ol> <li>Diagrama ER para Tablas de Dimensiones</li> </ol> <pre><code>erDiagram\n    DIM_ESTUDIANTES {\n        int ID_ESTUDIANTE\n        string NOMBRE\n        string DOCUMENTO\n    }\n    DIM_JORNADA {\n        int ID_JORNADA\n        string JORNADA\n    }\n    DIM_PROGRAMA {\n        int ID_PROGRAMA\n        string NOMBRE_PROGRAMA\n    }\n    FACT_NOTAS {\n        int ID_NOTA\n        int ID_ESTUDIANTE\n        int ID_JORNADA\n        float NOTA_FINAL\n    }\n    DIM_ESTUDIANTES ||--|| DIM_JORNADA : \"Relaci\u00f3n Estudiante-Jornada\"\n    DIM_JORNADA ||--|| FACT_NOTAS : \"Jornada-Notas\"\n    DIM_PROGRAMA ||--|| FACT_NOTAS : \"Programa-Notas\"</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_desertores","title":"FACT_DESERTORES","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-cede_cancelados_desertores","title":"Componente <code>Tarea cede_Cancelados_Desertores</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tarea cede_Cancelados_Desertores es un componente de tipo Execute Process Task en SSIS que se utiliza para ejecutar un proceso externo mediante un script de Python. Este script se encarga de descargar y procesar los datos relacionados con cancelaciones y desertores, informaci\u00f3n que posteriormente se integrar\u00e1 en el flujo de datos del paquete FACT_DESERTORES para an\u00e1lisis y reportes.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Execute Process Task  </li> <li>Ejecutable: Utiliza la variable de proyecto <code>@[$Project::Python_Executable]</code>, que apunta al ejecutable de Python configurado.  </li> <li>Argumentos: <code>download.py --key cede_Cancelados_Desertores</code> </li> <li>Directorio de Trabajo:   Se establece mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con el path <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code> </li> <li>Ruta F\u00edsica Ejemplo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code> </li> <li>Propiedades Adicionales:<ul> <li>Filtro de registro: <code>FilterKind=0</code> </li> <li>ThreadHint: <code>0</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<p>El siguiente diagrama de secuencia ilustra el proceso que se ejecuta en esta tarea:</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta download.py --key cede_Cancelados_Desertores\n    Python -&gt;&gt; Python: Descarga y procesa datos de cancelados y desertores\n    Python -&gt;&gt; SSIS: Retorna resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-emp_cancelados_desertores","title":"Componente <code>Tarea emp_Cancelados_Desertores</code>","text":"<p>La tarea <code>emp_Cancelados_Desertores</code> es un Execute Process Task dentro del paquete SSIS orientado a alimentar la tabla de hechos <code>FACT_DESERTORES</code> con la informaci\u00f3n de estudiantes cancelados o desertores. A continuaci\u00f3n se detalla su prop\u00f3sito, configuraci\u00f3n y l\u00f3gica de ejecuci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#1-tipo-de-tarea","title":"1. Tipo de Tarea","text":"<ul> <li>Tipo: Execute Process Task</li> <li>Descripci\u00f3n: Ejecuta un proceso externo (en este caso un script de Python) para descargar o generar los datos de estudiantes cancelados/desertores que luego se cargar\u00e1n en el Data Warehouse.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#2-proposito","title":"2. Prop\u00f3sito","text":"<ul> <li>Objetivo principal: Invocar el script <code>download.py</code> para obtener la informaci\u00f3n de \u201cemp_Estudiantes_inasistencias\u201d (estudiantes con inasistencias prolongadas que se consideran cancelados o desertores) desde la fuente de datos o API correspondiente.</li> <li>Resultado esperado: Generar o actualizar un archivo intermedio (o volcar directamente en staging) con los datos de cancelaciones y deserciones, listos para ser procesados por etapas posteriores del paquete ETL.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#3-configuracion-y-propiedades","title":"3. Configuraci\u00f3n y Propiedades","text":"Propiedad Valor / Expresi\u00f3n Descripci\u00f3n Executable <code>@[$Project::Python_Executable]</code> Ruta din\u00e1mica al int\u00e9rprete de Python configurada en un par\u00e1metro de proyecto (<code>Python_Executable</code>), por ejemplo: <code>C:\\\u2026\\env\\Scripts\\python.exe</code>. WorkingDirectory <code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Directorio de trabajo donde se encuentra el script y sus dependencias. Se construye a partir del par\u00e1metro de proyecto <code>Working_Directory</code>. Arguments <code>download.py --key emp_Estudiantes_inasistencias</code> Argumentos que se pasan al int\u00e9rprete de Python: - <code>download.py</code> \u2794 nombre del script que implementa la l\u00f3gica de descarga. - <code>--key emp_Estudiantes_inasistencias</code> \u2794 par\u00e1metro que indica al script qu\u00e9 conjunto de datos debe descargar (en este caso, estudiantes con inasistencias). DTSID / refId <code>{e9cadb0f-846d-4227-a988-77af6421306b}</code> / <code>Package\\FACT_DESERTORES\\Tarea emp_Cancelados_Desertores</code> Identificadores internos de SSIS para la tarea. Description \u201cTarea Ejecutar proceso\u201d Texto descriptivo breve; puede ampliarse para indicar que se trata de la descarga de datos de desertores. ThreadHint <code>0</code> Configuraci\u00f3n de concurrencia; deja valor por defecto."},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#4-flujo-de-ejecucion","title":"4. Flujo de Ejecuci\u00f3n","text":"<ol> <li>Resoluci\u00f3n de Par\u00e1metros:    Al iniciar la tarea, SSIS eval\u00faa las expresiones y obtiene las rutas reales para el int\u00e9rprete de Python y el directorio de trabajo desde los par\u00e1metros de proyecto.</li> <li> <p>Invocaci\u00f3n del Proceso:</p> <ul> <li>Se lanza el ejecutable de Python con los argumentos definidos.</li> <li>El script <code>download.py</code> realiza la conexi\u00f3n a la fuente (API o base de datos), descarga el conjunto de datos identificado por la clave <code>emp_Estudiantes_inasistencias</code> y genera el archivo de salida (por ejemplo, un CSV o JSON en el directorio de trabajo).</li> </ul> </li> <li> <p>Control de Errores: Si el proceso retorna un c\u00f3digo distinto de cero, SSIS marcar\u00e1 la tarea como fallida y detendr\u00e1 el flujo (a menos que est\u00e9 configurado para ignorar errores).</p> </li> <li>Salida y Continuaci\u00f3n: Una vez completada exitosamente, la tarea deja disponibles los datos descargados para las siguientes tareas (por ejemplo, un Data Flow Task que lea el archivo generado y lo cargue en staging).</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#5-buenas-practicas-y-recomendaciones","title":"5. Buenas Pr\u00e1cticas y Recomendaciones","text":"<ul> <li>Variables de Proyecto Din\u00e1micas:   Mantener las rutas al int\u00e9rprete de Python y al directorio de scripts parametrizadas permite mover el paquete entre distintos entornos (desarrollo, pruebas, producci\u00f3n) sin cambios manuales.</li> <li>Manejo de Logs:   Asegurar que el script <code>download.py</code> genere logs (archivo o stdout) con detalles de la operaci\u00f3n para facilitar diagn\u00f3sticos en caso de errores.</li> <li>Validaciones Previas:   Antes de invocar el proceso, verificar que el directorio de trabajo exista y tenga los permisos adecuados.</li> <li>Timeout y Retries:   Considerar configurar un tiempo de espera (Timeout) y reintentos (Retry) en caso de fallos temporales de red o del API.</li> </ul> <p>Este Execute Process Task es esencial para orquestar la descarga autom\u00e1tica de datos de desertores, garantizando que la tabla <code>FACT_DESERTORES</code> se alimente con informaci\u00f3n actualizada antes de proceder a la transformaci\u00f3n y carga en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-dim_estudiantes-py","title":"Componente <code>dim_Estudiantes py</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente dim_Estudiantes py es una tarea de tipo Execute Process Task en SSIS, dise\u00f1ada para ejecutar un script de Python que procesa la dimensi\u00f3n de estudiantes. Este proceso se utiliza para extraer, transformar y preparar los datos de la dimensi\u00f3n de estudiantes, integr\u00e1ndolos en el sistema ETL de FACT_DESERTORES.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_1","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Execute Process Task  </li> <li>Ejecutable: Utiliza la variable de proyecto <code>@[$Project::Python_Executable]</code>, que apunta al ejecutable de Python configurado.  </li> <li>Argumentos: <code>dim_Estudiantes.py</code> </li> <li>Directorio de Trabajo:   Se define mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con el path <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code> </li> <li>Ruta F\u00edsica Ejemplo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<p>El siguiente diagrama de secuencia muestra el proceso que se ejecuta en esta tarea:</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta dim_Estudiantes.py\n    Python -&gt;&gt; Python: Procesa la dimensi\u00f3n de estudiantes\n    Python -&gt;&gt; SSIS: Retorna resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-truncar-tabla-temporal","title":"Componente <code>Truncar tabla Temporal</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente Truncar tabla Temporal es una tarea de tipo Execute SQL Task que se utiliza para limpiar la tabla temporal utilizada en el proceso ETL de FACT_DESERTORES. Concretamente, se encarga de truncar la tabla <code>[STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code>, eliminando todos sus registros antes de cargar nuevos datos. Esto garantiza que el \u00e1rea de staging se encuentre limpia y preparada para el proceso de integraci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_2","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Execute SQL Task  </li> <li>Conexi\u00f3n: Utiliza la conexi\u00f3n identificada por <code>{5972EC76-2533-4771-BB68-A92E1CDD645D}</code> para conectarse al servidor SQL donde reside la tabla.  </li> <li>Sentencia SQL: <pre><code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO]\n</code></pre></li> <li>Descripci\u00f3n: Ejecuta la sentencia SQL para truncar la tabla temporal, eliminando todos los registros existentes y dejando la tabla lista para la carga de nuevos datos.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<p>El siguiente diagrama muestra el proceso que se ejecuta en esta tarea:</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n\n    SSIS -&gt;&gt; SQL: Ejecuta TRUNCATE TABLE STAGE_AREA.Transversal.TMP_DESERTORES_CEDESARROLLO\n    SQL --&gt;&gt; SSIS: Confirma truncamiento</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-tabla-temporal","title":"Componente <code>Actualizar Tabla Temporal</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar Tabla Temporal es un Data Flow Task que se encarga de actualizar la tabla temporal utilizada para almacenar informaci\u00f3n sobre desertores en el proceso ETL. Este flujo extrae datos desde una fuente Excel, aplicando las transformaciones necesarias y finalmente cargando la informaci\u00f3n en la tabla <code>[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code>. La tarea es fundamental para garantizar que los datos temporales est\u00e9n actualizados y listos para su posterior procesamiento.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source: cede_desertores</p> <ul> <li>Descripci\u00f3n: Extrae datos de un archivo Excel (hoja <code>Sheet1$</code>) que contiene informaci\u00f3n relevante de desertores.</li> <li>Columnas Extra\u00eddas:<ul> <li>PROGRAMA</li> <li>NOMBRE_ESTUDIANTE</li> <li>FECHA</li> <li>TIPO</li> <li>CAUSA</li> <li>OBSERVACIONES</li> <li>SEDE</li> <li>JORNADA</li> </ul> </li> <li>Conexi\u00f3n: Utiliza el Connection Manager configurado para Excel (por ejemplo, <code>Excel_Connection_Fact_Desertores_CE</code>).</li> </ul> </li> <li> <p>Destino ADO.NET: TMP_DESERTORES_CEDESARROLLO</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla temporal <code>[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code> del \u00e1rea de staging.</li> <li>Propiedades:<ul> <li>Tabla Destino: <code>\"Transversal\".\"TMP_DESERTORES_CEDESARROLLO\"</code></li> <li>Batch Size: <code>0</code> (usa el tama\u00f1o predeterminado del buffer)</li> <li>Command Timeout: <code>30</code> segundos</li> <li>Uso de Bulk Insert: Activado para mejorar el rendimiento.</li> </ul> </li> <li>Conexi\u00f3n: Utiliza el Connection Manager asignado a la base de datos de staging (por ejemplo, <code>STAGE_AREA</code>).</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#flujo-del-proceso","title":"Flujo del Proceso","text":"<ol> <li>Extracci\u00f3n: El componente Excel Source extrae la informaci\u00f3n de la hoja <code>Sheet1$</code> del archivo configurado.</li> <li>(Opcional) Procesamiento/Transformaci\u00f3n: Si bien en este caso no se indican transformaciones adicionales, en muchos escenarios se pueden incluir pasos intermedios para validar o transformar los datos antes de la carga.</li> <li>Carga: Los datos extra\u00eddos se env\u00edan directamente al destino ADO.NET, donde se insertan en la tabla temporal.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-flujo","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el proceso de actualizaci\u00f3n de la tabla temporal:</p> <pre><code>graph TD\n    A[Excel Source: cede_desertores] --&gt; B[Procesamiento de Datos]\n    B --&gt; C[Destino ADO.NET: TMP_DESERTORES_CEDESARROLLO]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-truncar-tabla-temporal-educacion-continua","title":"Componente <code>Truncar tabla Temporal Educacion Continua</code>","text":"<p>Esta tarea es un Execute SQL Task que prepara el \u00e1rea de staging eliminando todo el contenido previo de la tabla temporal utilizada para procesar datos de desertores de Educaci\u00f3n Continua.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#1-tipo-de-tarea_1","title":"1. Tipo de Tarea","text":"<ul> <li>Tipo: Execute SQL Task</li> <li>Descripci\u00f3n: Ejecuta un comando T\u2011SQL directamente contra la base de datos de staging.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#2-proposito_1","title":"2. Prop\u00f3sito","text":"<ul> <li>Objetivo principal: Asegurar que la tabla temporal   <code>[STAGE_AREA].[Transversal].[TMP_DESERTORES_DESARROLLO]</code>   est\u00e9 vac\u00eda antes de cargar los nuevos registros de desertores de Educaci\u00f3n Continua.</li> <li>Motivaci\u00f3n: Evitar duplicados y garantizar que cada ejecuci\u00f3n del paquete trabaje con datos frescos.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#3-configuracion-y-propiedades_1","title":"3. Configuraci\u00f3n y Propiedades","text":"Propiedad Valor Descripci\u00f3n Connection <code>{5972EC76-2533-4771-BB68-A92E1CDD645D}</code> Identificador del Connection Manager apuntando a la base de datos de staging (<code>STAGE_AREA</code>). SqlStatementSource <code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_DESERTORES_DESARROLLO]</code> Comando que borra de forma r\u00e1pida y eficiente todas las filas de la tabla temporal. refId / ObjectName <code>Package\\FACT_DESERTORES\\Truncar tabla Temporal Educacion Continua</code> / <code>\"Truncar tabla Temporal Educacion Continua\"</code> Ruta y nombre internos en el paquete SSIS. Description \u201cTarea Ejecutar SQL\u201d Texto gen\u00e9rico; puede ampliarse para especificar el truncado de la tabla de desarrollo de desertores. ThreadHint <code>0</code> Valor por defecto de concurrencia."},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#4-flujo-de-ejecucion_1","title":"4. Flujo de Ejecuci\u00f3n","text":"<ol> <li>Inicio de la Tarea: SSIS abre la conexi\u00f3n de staging definida.</li> <li>Ejecuci\u00f3n de TRUNCATE: Se env\u00eda el comando <code>TRUNCATE TABLE</code>, que elimina todas las filas sin registrar cada fila individualmente en el registro de transacciones (a diferencia de <code>DELETE</code>), lo que ofrece mayor velocidad y libera el espacio de la tabla.</li> <li>Confirmaci\u00f3n: Si el comando finaliza correctamente, la tarea se marca como exitosa y el flujo contin\u00faa hacia la carga de nuevos datos.</li> <li>Errores: Cualquier fallo (por ejemplo, falta de permisos o bloqueo de la tabla) producir\u00e1 una excepci\u00f3n que detendr\u00e1 el paquete o propagar\u00e1 el error seg\u00fan la configuraci\u00f3n de manejo de errores.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#5-buenas-practicas-y-recomendaciones_1","title":"5. Buenas Pr\u00e1cticas y Recomendaciones","text":"<ul> <li>Permisos Adecuados: Verificar que el usuario de conexi\u00f3n tenga permiso <code>ALTER</code> o <code>CONTROL</code> sobre la tabla para ejecutar <code>TRUNCATE</code>.</li> <li>Bloqueos y Concurrencia: Asegurarse de que no haya transacciones activas que impidan el truncado (por ejemplo, lecturas con bloqueo).</li> <li>Revisi\u00f3n de Dependencias: Confirmar que ning\u00fan proceso posterior necesite retener datos de la tabla antes de truncar.</li> <li>Auditor\u00eda de Ejecuci\u00f3n: Registrar en el log de SSIS la ejecuci\u00f3n de esta tarea para facilitar diagn\u00f3sticos y trazabilidad.</li> </ul> <p>Con esta tarea, el paquete garantiza un entorno limpio en staging, evitando la acumulaci\u00f3n de datos antiguos y favoreciendo la coherencia en el c\u00e1lculo de la tabla de hechos <code>FACT_DESERTORES</code>.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-tabla-temporal-educacion-continua","title":"Componente <code>Actualizar Tabla Temporal Educaci\u00f3n Continua</code>","text":"<p>Esta tarea es un Data Flow Task que importa desde un archivo Excel los registros de desertores de Educaci\u00f3n Continua y los carga en la tabla temporal de staging para su posterior procesamiento.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#1-tipo-de-tarea_2","title":"1. Tipo de Tarea","text":"<ul> <li>Tipo: Data Flow Task</li> <li>Nombre interno: <code>Actualizar Tabla Temporal Educaci\u00f3n Continua</code></li> <li>Descripci\u00f3n: Extrae datos de desertores desde un Excel y los vuelca en la tabla temporal <code>[Transversal].[TMP_DESERTORES_DESARROLLO]</code> del \u00e1rea de staging.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#2-proposito_2","title":"2. Prop\u00f3sito","text":"<ul> <li>Objetivo principal: Sincronizar la tabla temporal de desertores con la informaci\u00f3n m\u00e1s reciente proporcionada en un archivo Excel (<code>Sheet1$</code>), de modo que el proceso de carga de hechos (<code>FACT_DESERTORES</code>) trabaje siempre con datos actualizados.</li> <li>Motivaci\u00f3n: Centralizar en staging el detalle de cada desertor (programa, estudiante, porcentaje de inasistencia, fecha, etc.) para facilitar validaciones y transformaciones posteriores.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#3-componentes-del-flujo-de-datos","title":"3. Componentes del Flujo de Datos","text":"Componente Tipo Conexi\u00f3n / Objeto Descripci\u00f3n Desarrollo_Desertores Excel Source <code>Excel_Connection_Fact_Desertores_DE</code> \u2192 <code>Sheet1$</code> Lee desde la hoja Sheet1\\$ del Excel las columnas: \u2013 PROGRAMA\u2013 NOMBRE_ESTUDIANTE\u2013 GRUPO\u2013 M\u00d3DULO\u2013 SEMESTRE\u2013 CR\u00c9DITOS\u2013 PORCENTAJE_INASISTENCIA\u2013 SEDE\u2013 JORNADA\u2013 TIPO_DOCUMENTO\u2013 DOCUMENTO_ESTUDIANTE\u2013 FECHA Destino de ADO NET ADO.NET Destination <code>STAGE_AREA</code> \u2192 <code>\"Transversal\".\"TMP_DESERTORES_DESARROLLO\"</code> Inserta en bloque todos los registros le\u00eddos desde el Excel usando <code>SqlBulkCopy</code> para maximizar el rendimiento. <p>Y un path conecta la salida del Excel Source (<code>Excel Source Output</code>) con la entrada del destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#4-configuracion-y-propiedades-clave","title":"4. Configuraci\u00f3n y Propiedades Clave","text":"<ul> <li> <p>Excel Source \u2013 Desarrollo_Desertores</p> <ul> <li>AccessMode: OpenRowset (0)</li> <li>OpenRowset: <code>Sheet1$</code></li> <li>CommandTimeout: 0 (sin l\u00edmite)</li> </ul> </li> <li> <p>ADO.NET Destination \u2013 Destino de ADO NET</p> <ul> <li>TableOrViewName: <code>\"Transversal\".\"TMP_DESERTORES_DESARROLLO\"</code></li> <li>BatchSize: 0 (usa el tama\u00f1o de b\u00fafer del componente)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: True</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#5-flujo-de-ejecucion","title":"5. Flujo de Ejecuci\u00f3n","text":"<ol> <li>Inicia la lectura del archivo Excel definido en el Connection Manager.</li> <li>Extrae todas las columnas relevantes de <code>Sheet1$</code>.</li> <li>Enruta los datos directamente al componente de destino ADO.NET.</li> <li>Inserta en bloque los registros en la tabla temporal de staging.</li> <li>Finaliza exitosamente, dejando la tabla lista para el siguiente paso del paquete.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#6-buenas-practicas-y-recomendaciones","title":"6. Buenas Pr\u00e1cticas y Recomendaciones","text":"<ul> <li>Validaci\u00f3n de Excel: Asegurar que la estructura y los nombres de columnas de la hoja no cambien (o usar variables para parametrizar la hoja).</li> <li>Permisos: El usuario de la conexi\u00f3n <code>STAGE_AREA</code> debe tener permisos <code>INSERT</code> y <code>ALTER</code> sobre la tabla temporal.</li> <li>Manejo de Errores: Revisar los flujos de error (Error Outputs) para capturar filas con problemas de conversi\u00f3n y enviarlas a un log o staging de errores.</li> <li>Rendimiento: Si el Excel es muy grande, considerar convertirlo previamente a CSV o usar una extensi\u00f3n de source m\u00e1s eficiente.</li> </ul> <p>Con esto, la tabla <code>TMP_DESERTORES_DESARROLLO</code> queda actualizada con la informaci\u00f3n de desertores de Educaci\u00f3n Continua para su consolidaci\u00f3n en el modelo de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-dim_programa","title":"Componente <code>Actualizar DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar DIM_PROGRAMA es un Data Flow Task que forma parte del proceso ETL del paquete FACT_DESERTORES. Su funci\u00f3n es identificar los programas que a\u00fan no han sido registrados en la tabla de dimensi\u00f3n DIM_PROGRAMA y posteriormente insertar dichos registros en la base de datos. Para ello, se consume informaci\u00f3n de la tabla temporal (almacenada en el \u00e1rea de staging) y se realiza un proceso de comparaci\u00f3n (lookup) con la tabla de destino para detectar los registros faltantes. Finalmente, los programas identificados se insertan en la tabla <code>[Cedesarrollo].[DIM_PROGRAMA]</code>.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-de-componentes-y-flujo","title":"Detalle de Componentes y Flujo","text":"<ol> <li> <p>Identificar programas</p> <ul> <li>Tipo de Componente: Data Reader Source (adaptado mediante un Managed Component Host)</li> <li>Funci\u00f3n: Ejecuta una instrucci\u00f3n SQL para extraer la lista de programas distintos desde la tabla temporal <code>[STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code> que a\u00fan no se han registrado en la tabla de dimensi\u00f3n.  </li> <li>SQL Utilizado:     <pre><code>SELECT DISTINCT d.[PROGRAMA]\nFROM [STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO] d\nLEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PROGRAMA] p ON d.[PROGRAMA] = p.[PROGRAMA]\nWHERE p.ID_PROGRAMA IS NULL\n</code></pre></li> <li>Objetivo: Extraer los registros de programas nuevos que deben ser insertados.</li> </ul> </li> <li> <p>Guardar DIM_PROGRAMA</p> <ul> <li>Tipo de Componente: ADO.NET Destination</li> <li>Funci\u00f3n: Inserta en la tabla <code>[Cedesarrollo].[DIM_PROGRAMA]</code> los registros identificados en el paso anterior.</li> <li>Propiedades Clave:<ul> <li>Tabla Destino: <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code></li> <li>Batch Size: 0 (usa el tama\u00f1o predeterminado del buffer)</li> <li>Command Timeout: 30 segundos</li> <li>Bulk Insert: Activado (para optimizar el rendimiento)</li> </ul> </li> <li>Conexi\u00f3n: Utiliza el Connection Manager asignado a la base de datos destino (por ejemplo, <code>DWH_COMFENALCO_Destino</code>).</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#flujo-del-proceso_1","title":"Flujo del Proceso","text":"<ol> <li> <p>Extracci\u00f3n de Datos:    El componente Identificar programas se conecta a la base de datos y ejecuta la consulta SQL para obtener la lista de programas presentes en la tabla temporal que no tienen un registro en DIM_PROGRAMA.</p> </li> <li> <p>Carga de Datos:    Los datos extra\u00eddos se env\u00edan al componente Guardar DIM_PROGRAMA, el cual inserta los registros nuevos en la tabla de destino.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-flujo-del-proceso","title":"Diagrama de Flujo del Proceso","text":"<pre><code>graph TD\n    A[Identificar programas: Extraer lista de programas nuevos]\n    B[Guardar DIM_PROGRAMA: Insertar registros en DIM_PROGRAMA]\n    A --&gt; B</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-fact_desercion","title":"Componente <code>Actualizar FACT_DESERCION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar FACT_DESERCION es un Data Flow Task que forma parte del proceso ETL del paquete FACT_DESERTORES. Su objetivo es extraer la informaci\u00f3n de desertores a trav\u00e9s de una consulta SQL compleja, validar y transformar los datos obtenidos y, finalmente, insertar en la tabla de hechos FACT_DESERCION de la base de datos. La consulta utiliza varias CTE y uniones (JOIN) para consolidar informaci\u00f3n de distintos or\u00edgenes (como la tabla temporal de desertores, dimensiones de jornada, periodo acad\u00e9mico y estudiantes) y detectar aquellos registros que a\u00fan no existen en FACT_DESERCION.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-de-componentes-y-flujo-del-proceso","title":"Detalle de Componentes y Flujo del Proceso","text":"<ol> <li> <p>Consulta (Data Reader Source)</p> <ul> <li>Tipo de Componente: Managed Component Host (Data Reader Source)</li> <li>Funci\u00f3n: Ejecuta una consulta SQL que utiliza CTE para:<ul> <li>Extraer datos de desertores desde la tabla temporal <code>[STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code>.</li> <li>Estandarizar nombres y calcular identificadores, como <code>ID_FECHA</code> y <code>PERIODO_ACADEMICO</code>.</li> <li>Unir los datos con dimensiones como DIM_JORNADA, DIM_PERIODO_ACADEMICO y la dimensi\u00f3n de estudiantes (a trav\u00e9s de un LEFT JOIN sobre el nombre estandarizado).</li> <li>Seleccionar \u00fanicamente los registros que a\u00fan no tienen un valor asignado en la columna <code>ID_DESERCION</code> de FACT_DESERCION.</li> </ul> </li> <li>SQL Utilizado:     La consulta SQL (con CTE) extrae columnas como <code>NOMBRE_ESTUDIANTE</code>, <code>SEDE</code>, <code>ID_FECHA</code>, <code>FECHA</code>, <code>TIPO</code>, <code>CAUSA</code>, <code>OBSERVACIONES</code>, junto con identificadores provenientes de las uniones con DIM_JORNADA, DIM_PERIODO_ACADEMICO y la dimensi\u00f3n de estudiantes.</li> </ul> </li> <li> <p>Salida de Origen</p> <ul> <li>La salida de la consulta (Data Reader) contiene los registros que cumplen la condici\u00f3n de no estar presentes en FACT_DESERCION (es decir, aquellos con <code>ID_DESERCION</code> nulo).</li> </ul> </li> <li> <p>Destino \u2013 Guardar en FACT_DESERCION</p> <ul> <li>Tipo de Componente: ADO.NET Destination</li> <li>Funci\u00f3n: Inserta los registros resultantes de la consulta en la tabla de hechos <code>[Cedesarrollo].[FACT_DESERCION]</code>.</li> <li>Propiedades Clave:<ul> <li>Tabla Destino: <code>\"Cedesarrollo\".\"FACT_DESERCION\"</code></li> <li>Batch Size: 0 (se usa el tama\u00f1o predeterminado del buffer)</li> <li>Command Timeout: 30 segundos</li> <li>Bulk Insert: Activado para optimizar el rendimiento</li> </ul> </li> <li>Conexi\u00f3n: Utiliza el Connection Manager configurado para el destino de datos (por ejemplo, <code>DWH_COMFENALCO_Destino</code>).</li> </ul> </li> <li> <p>Flujo de Datos</p> </li> <li>Los datos fluyen desde la ejecuci\u00f3n de la consulta (que consolida la informaci\u00f3n de desertores) hasta el componente de destino, el cual inserta \u00fanicamente aquellos registros nuevos que no tienen un <code>ID_DESERCION</code> asignado.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama de proceso muestra de forma esquem\u00e1tica el flujo de datos dentro de este Data Flow Task:</p> <pre><code>graph TD\n    A[Consulta: Extraer y consolidar datos de desertores]\n    B[Salida de Origen: Registros sin ID_DESERCION]\n    C[Destino ADO.NET: Guardar en FACT_DESERCION]\n\n    A --&gt; B\n    B --&gt; C</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#actualizar-fact_desercion-continua","title":"<code>Actualizar FACT_DESERCION Continua</code>","text":"<p>Esta tarea es un Data Flow Task que toma los registros de desertores en staging, determina cu\u00e1les a\u00fan no est\u00e1n en la tabla de hechos y los carga en <code>Cedesarrollo.FACT_DESERCION</code>.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#tipo-de-tarea","title":"Tipo de Tarea","text":"<ul> <li>Tipo: Data Flow Task</li> <li>Nombre interno: <code>Actualizar FACT_DESERCION Continua</code></li> <li>Descripci\u00f3n: Extrae desertores nuevos de la tabla temporal y los vuelca en la tabla de hechos de deserci\u00f3n continua.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#proposito","title":"Prop\u00f3sito","text":"<ul> <li>Objetivo principal: Insertar \u00fanicamente los registros de deserci\u00f3n que a\u00fan no existen en <code>FACT_DESERCION</code>, evitando duplicados y garantizando la actualizaci\u00f3n incremental de la tabla de hechos.</li> <li>Fuente de datos: <code>[STAGE_AREA].[Transversal].[TMP_DESERTORES_DESARROLLO]</code></li> <li>Destino: <code>[Cedesarrollo].[FACT_DESERCION]</code></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"Componente Tipo Conexi\u00f3n / Objeto Funci\u00f3n Consulta ADO.NET Source <code>STAGE_AREA</code> \u2192 staging TMP_DESERTORES_DESARROLLO Ejecuta un SQL que: <ol> <li>Define CTE Desertores (normaliza nombre, genera ID_FECHA y PERIODO_ACAD\u00c9MICO, fija TIPO='Desertor', CAUSA='Inasistencia', ID_UNIDAD=3).</li> <li>Hace SELECT DISTINCT de esa CTE, uni\u00e9ndola con dimensiones (estudiantes, jornada, periodo, programa).</li> <li>Filtra s\u00f3lo los que no aparecen a\u00fan en FACT_DESERCION (<code>WHERE ID_DESERCION IS NULL</code>). |    | Destino de ADO NET | ADO.NET Destination | <code>DWH_COMFENALCO_Destino</code> \u2192 <code>\"Cedesarrollo\".\"FACT_DESERCION\"</code> | Inserta en bloque los registros resultantes utilizando SqlBulkCopy, para maximizar rendimiento.                                                                                                                       |</li> </ol> <p>El \u00fanico path conecta la salida de la fuente (<code>Salida de origen de ADO NET</code>) con la entrada del destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#configuracion-y-propiedades-clave","title":"Configuraci\u00f3n y Propiedades Clave","text":"<ul> <li> <p>Consulta (Source)</p> </li> <li> <p>AccessMode: 2 (SQL Command)</p> </li> <li> <p>SqlCommand:</p> <pre><code>WITH Desertores AS (\n  SELECT  \n    PROGRAMA,\n    CAST(TRIM(UPPER(NOMBRE_ESTUDIANTE)) AS NVARCHAR(200)) AS NOMBRE_ESTUDIANTE,\n    FECHA,\n    CONVERT(INT, CONVERT(VARCHAR, FECHA, 112)) AS ID_FECHA,\n    CAST(YEAR(FECHA) AS NVARCHAR(4)) + '-' +\n      CASE WHEN MONTH(FECHA)&lt;=6 THEN '1' ELSE '2' END AS PERIODO_ACADEMICO,\n    'Desertor' AS TIPO,\n    'Inasistencia' AS CAUSA,\n    SEDE, JORNADA, TIPO_DOCUMENTO,\n    CAST(FORMAT(DOCUMENTO_ESTUDIANTE,'0') AS NVARCHAR(20)) AS DOCUMENTO,\n    3 AS ID_UNIDAD\n  FROM STAGE_AREA.Transversal.TMP_DESERTORES_DESARROLLO\n)\nSELECT DISTINCT d.*, \n  COALESCE(e.ID_ESTUDIANTE,-1) AS ID_ESTUDIANTE,\n  ISNULL(pa.ID_PERIODO,-1) AS ID_PERIODO,\n  j.ID_JORNADA,\n  ISNULL(p.ID_PROGRAMA,-1) AS ID_PROGRAMA\nFROM Desertores d\nLEFT JOIN DIM_ESTUDIANTES e ON \u2026 \nINNER JOIN DIM_JORNADA j ON \u2026\nLEFT JOIN DIM_PERIODO_ACADEMICO pa ON \u2026\nLEFT JOIN DIM_PROGRAMA p ON \u2026\nLEFT JOIN FACT_DESERCION fd ON \u2026 \nWHERE fd.ID_DESERCION IS NULL\n</code></pre> <ul> <li>CommandTimeout: 30\u202fs</li> <li>AllowImplicitStringConversion: True</li> </ul> </li> <li> <p>Destino de ADO NET (Destination)</p> <ul> <li>TableOrViewName: <code>\"Cedesarrollo\".\"FACT_DESERCION\"</code></li> <li>BatchSize: 0 (usa el buffer interno)</li> <li>CommandTimeout: 30\u202fs</li> <li>UseBulkInsertWhenPossible: True</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-id_periodo","title":"Componente <code>Actualizar ID_PERIODO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar ID_PERIODO es una tarea de ejecuci\u00f3n SQL (Execute SQL Task) que se encarga de actualizar el campo ID_PERIODO en la tabla de hechos FACT_DESERCION del esquema Cedesarrollo. Para lograr esto, el proceso sigue estos pasos:</p> <ol> <li> <p>Calcular el PERIODO_ACADEMICO:    Se utiliza una expresi\u00f3n basada en la columna FECHA para generar un valor en el formato <code>YYYY-S</code>, donde:</p> <ul> <li><code>S = '1'</code> para los meses de enero a junio (primer semestre).</li> <li><code>S = '2'</code> para los meses de julio a diciembre (segundo semestre).</li> </ul> </li> <li> <p>Construir una tabla temporal (CTE):    Se crea la CTE PeriodoTemp que extrae el ID_DESERCION, FECHA y el PERIODO_ACADEMICO calculado a partir de la tabla FACT_DESERCION.</p> </li> <li> <p>Actualizar FACT_DESERCION:    Se realiza una actualizaci\u00f3n en la tabla FACT_DESERCION mediante un <code>INNER JOIN</code> entre la CTE PeriodoTemp y la dimensi\u00f3n DIM_PERIODO_ACADEMICO, usando como condici\u00f3n de uni\u00f3n el valor calculado de PERIODO_ACADEMICO y filtrando adem\u00e1s por ID_UNIDAD igual a 2. De esta manera, se asigna el ID_PERIODO correcto a cada registro de FACT_DESERCION.</p> </li> <li> <p>Verificaci\u00f3n:    Finalmente, se ejecuta una consulta SELECT para validar que la actualizaci\u00f3n se realiz\u00f3 correctamente, mostrando los campos ID_DESERCION, ID_PERIODO y FECHA.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_1","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama muestra de forma esquem\u00e1tica los pasos del proceso:</p> <pre><code>graph TD\n    A[Inicio: FACT_DESERCION]\n    B[Crear CTE PeriodoTemp]\n    C[Calcular PERIODO_ACADEMICO a partir de FECHA]\n    D[Unir con DIM_PERIODO_ACADEMICO filtrar por ID_UNIDAD = 2]\n    E[Actualizar ID_PERIODO en FACT_DESERCION]\n    F[Verificar resultados con SELECT]\n\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_estado_matriculas","title":"FACT_ESTADO_MATRICULAS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ejecutar-sql","title":"Componente <code>Tarea Ejecutar SQL</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>Esta tarea se encarga de gestionar la existencia y el contenido de la tabla temporal TMP_MATRICULAS_CEDESARROLLO dentro del \u00e1rea de staging (STAGE_AREA.Transversal). El proceso eval\u00faa si la tabla ya existe; en caso afirmativo, la vac\u00eda mediante la instrucci\u00f3n <code>TRUNCATE TABLE</code>, y si no existe, la crea con la estructura definida.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso","title":"Detalles del Proceso","text":"<ol> <li> <p>Verificaci\u00f3n de la existencia de la tabla:    Utilizando la funci\u00f3n <code>OBJECT_ID</code>, se determina si la tabla TMP_MATRICULAS_CEDESARROLLO ya existe en el esquema STAGE_AREA.Transversal.</p> </li> <li> <p>Si la tabla existe:    Se ejecuta la instrucci\u00f3n <code>TRUNCATE TABLE</code> para eliminar todos los registros existentes y dejarla lista para la carga de nuevos datos.</p> </li> <li> <p>Si la tabla no existe:    Se crea la tabla TMP_MATRICULAS_CEDESARROLLO en el esquema Transversal con la siguiente estructura:</p> <ul> <li>Columnas para almacenar informaci\u00f3n relacionada con la matr\u00edcula, como JORNADA, NOMBRE_ESTUDIANTE, TIPO_DOCUMENTO, DOCUMENTO_ESTUDIANTE, FECHA_MATRICULA, TELEFONO, CELULAR, CORREO, SEMESTRE, ESTADO, SEDE, PROGRAMA, ID_UNIDAD.</li> <li>Columnas derivadas para almacenar valores transformados: _SEMESTRE, _CORREO, _CELULAR, _TELEFONO, _NOMBRE_ESTUDIANTE, _SEDE.</li> <li>Columnas adicionales para validaci\u00f3n y relaciones: DOCUMENTOS_COMPLETOS, ID_JORNADA, ID_PROGRAMA, FECHA_INICIO_PERIODO.</li> </ul> </li> <li> <p>Finalizaci\u00f3n:    El script concluye asegur\u00e1ndose de que, seg\u00fan el escenario, la tabla temporal se encuentre disponible y en un estado limpio para ser utilizada en posteriores procesos de ETL.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_2","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama de proceso ilustra de forma esquem\u00e1tica las operaciones realizadas por esta tarea:</p> <pre><code>graph TD\n    A[Inicio: Verificar existencia de TMP_MATRICULAS_CEDESARROLLO] --&gt; B{\u00bfTabla existe?}\n    B -- S\u00ed --&gt; C[Truncar tabla: TRUNCATE TABLE]\n    B -- No --&gt; D[Crear tabla con estructura definida]\n    D --&gt; E[Fin: Tabla creada]\n    C --&gt; E[Fin: Tabla vaciada]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-truncar-tabla-temporal-listas","title":"Componente <code>Truncar tabla temporal Listas</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Esta tarea es una operaci\u00f3n de ejecuci\u00f3n SQL que se encarga de vaciar la tabla temporal TMP_LISTADO_MATRICULAS_Q10 ubicada en el esquema STAGE_AREA.Transversal. Su funci\u00f3n principal es limpiar la tabla antes de iniciar procesos posteriores de carga y transformaci\u00f3n de datos, garantizando que no existan registros antiguos que puedan interferir con la nueva carga.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_1","title":"Detalles del Proceso","text":"<ol> <li> <p>Objetivo:    Eliminar todos los registros existentes en la tabla TMP_LISTADO_MATRICULAS_Q10 para asegurar que la tabla est\u00e9 en estado limpio antes de utilizarla en el flujo ETL.</p> </li> <li> <p>Acciones Realizadas:  </p> <ul> <li>Se ejecuta la instrucci\u00f3n <code>TRUNCATE TABLE</code> sobre la tabla [STAGE_AREA].[Transversal].[TMP_LISTADO_MATRICULAS_Q10].</li> <li>Esta acci\u00f3n elimina r\u00e1pidamente todos los datos de la tabla sin afectar su estructura, permitiendo una recarga eficiente de la informaci\u00f3n.</li> </ul> </li> <li> <p>Beneficios:  </p> <ul> <li>Integridad de Datos: Evita la acumulaci\u00f3n de datos obsoletos o duplicados en la etapa de staging.</li> <li>Rendimiento: El uso de <code>TRUNCATE TABLE</code> es m\u00e1s eficiente que un <code>DELETE</code> sin cl\u00e1usula <code>WHERE</code> para tablas grandes, ya que se resetea la estructura de almacenamiento.</li> <li>Preparaci\u00f3n para ETL: Garantiza que la tabla temporal est\u00e9 lista para recibir nuevos datos, lo cual es fundamental en procesos de integraci\u00f3n y transformaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_3","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama ilustra el proceso ejecutado por esta tarea:</p> <pre><code>graph TD\n    A[Inicio: Verificar existencia de TMP_LISTADO_MATRICULAS_Q10] --&gt; B[Ejecutar TRUNCATE TABLE]\n    B --&gt; C[Tabla temporal vaciada]\n    C --&gt; D[Fin del proceso]</code></pre> <p>Documentando tarea de flujo de datos</p> <p>La tarea \"Matriculas Desarrollo Empresarial\" tiene los siguientes elementos clave:</p> <ul> <li> <p>Encabezado: Tipo de tarea, nombre y descripci\u00f3n, detallando su prop\u00f3sito como carga de estado de matr\u00edcula en la tabla de ensayo \"TMP_LISTADO_MATRICULAS_Q10\".</p> </li> <li> <p>Componentes:</p> </li> <li> <p>DerivedColumn: A\u00f1ade el valor constante \"ID_UNIDAD\" = 3.</p> </li> <li>Fuente Excel: Lee el archivo \"Listado emp\" para obtener campos como JORNADA, NOMBRE_ESTUDIANTE, FECHA_MATRICULA, entre otros.</li> <li> <p>Destino ADO.NET: Inserta datos en la tabla de destino mediante copia masiva.</p> </li> <li> <p>Ruta de datos: Fuente Excel \u2192 DerivedColumn \u2192 Destino ADO.NET.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-matriculas-desarrollo-empresarial","title":"Componente <code>Matriculas Desarrollo Empresarial</code>","text":"<p>Este es un Data Flow Task que toma un listado de matr\u00edculas extra\u00eddo desde un archivo Excel, le a\u00f1ade la unidad organizacional fija y lo vuelca en una tabla temporal de staging para su posterior procesamiento.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#1-tipo-de-tarea_3","title":"1. Tipo de Tarea","text":"<ul> <li>Tipo: Data Flow Task</li> <li>Nombre interno: <code>Matriculas Desarrollo Empresarial</code></li> <li>Descripci\u00f3n: Lee matr\u00edculas desde Excel, a\u00f1ade <code>ID_UNIDAD=3</code> y carga en staging.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#2-proposito_3","title":"2. Prop\u00f3sito","text":"<ul> <li>Objetivo principal: Poblar la tabla staging   <code>Transversal.TMP_LISTADO_MATRICULAS_Q10</code> con el detalle de matr\u00edculas y su estado, asignando la unidad \u201cDesarrollo Empresarial\u201d (<code>ID_UNIDAD=3</code>).</li> <li>Origen de datos: Excel (Sheet1\\$) v\u00eda <code>Excel_Connection_Fact_Estado_Matriculas_DE</code></li> <li>Destino: Tabla staging <code>STAGE_AREA.Transversal.TMP_LISTADO_MATRICULAS_Q10</code></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#3-componentes-del-flujo-de-datos_1","title":"3. Componentes del Flujo de Datos","text":"Componente Tipo Conexi\u00f3n / Objeto Funci\u00f3n Listado emp Excel Source <code>Project.ConnectionManagers[Excel_Connection_Fact_Estado_Matriculas_DE]</code> \u2192 Sheet1\\$ Lee columnas: JORNADA, NOMBRE_ESTUDIANTE, TIPO_DOCUMENTO, DOCUMENTO_ESTUDIANTE, FECHA_MATRICULA, TELEFONO, CELULAR, CORREO, SEMESTRE, ESTADO, SEDE, PROGRAMA. emp Derived ID_UNIDAD Derived Column Input = salida de \u201cListado emp\u201d Crea o sobrescribe columna ID_UNIDAD con el valor constante <code>3</code>. TMP_MATRICULAS_Q10 ADO.NET Destination <code>Project.ConnectionManagers[STAGE_AREA]</code> \u2192 <code>\"Transversal\".\"TMP_LISTADO_MATRICULAS_Q10\"</code> Inserta en bloque (SqlBulkCopy) todos los campos, incluyendo el nuevo <code>ID_UNIDAD</code>."},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#4-rutas-de-datos","title":"4. Rutas de Datos","text":"<ol> <li>Excel Source Output \u2192 Derived Column Input</li> <li>Derived Column Output \u2192 ADO.NET Destination Input</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#5-configuracion-y-propiedades-clave","title":"5. Configuraci\u00f3n y Propiedades Clave","text":"<ul> <li> <p>Listado emp (Excel Source)</p> <ul> <li>AccessMode: 0 (OpenRowset)</li> <li>OpenRowset: <code>Sheet1$</code></li> <li>CommandTimeout: 0 (sin l\u00edmite)</li> </ul> </li> <li> <p>emp Derived ID_UNIDAD</p> <ul> <li>Expression (ID_UNIDAD): <code>3</code></li> <li>FriendlyExpression: <code>3</code></li> </ul> </li> <li> <p>TMP_MATRICULAS_Q10 (ADO.NET Destination)</p> <ul> <li>TableOrViewName: <code>\"Transversal\".\"TMP_LISTADO_MATRICULAS_Q10\"</code></li> <li>BatchSize: <code>0</code> (usa tama\u00f1o de buffer interno)</li> <li>CommandTimeout: <code>30</code>\u202fs</li> <li>UseBulkInsertWhenPossible: <code>True</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#6-buenas-practicas-y-recomendaciones_1","title":"6. Buenas Pr\u00e1cticas y Recomendaciones","text":"<ul> <li>Validaci\u00f3n de datos: Capturar en el flujo de error cualquier fila con formato inv\u00e1lido (fechas, conversiones).</li> <li>\u00cdndices staging: Asegurar \u00edndices en las columnas de filtrado y joins posteriores (por ejemplo, <code>DOCUMENTO_ESTUDIANTE</code>, <code>ID_UNIDAD</code>).</li> <li>Monitorizaci\u00f3n: Registrar el n\u00famero de filas le\u00eddas vs. insertadas para detectar discrepancias.</li> <li>Mantenimiento: Si cambia la unidad l\u00f3gica, actualizar \u00fanicamente la expresi\u00f3n derivada en \u201cemp Derived ID_UNIDAD\u201d.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-matriculas-cedesarrollo","title":"Componente <code>Matriculas Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>El componente Matriculas Cedesarrollo es un Data Flow Task encargado de procesar informaci\u00f3n de matr\u00edculas correspondientes al \u00e1rea de Cedesarrollo. Este flujo extrae datos desde un archivo Excel (utilizando el componente \"Listado cede\"), aplica transformaciones para estandarizar la informaci\u00f3n (por ejemplo, derivando un valor fijo para el identificador de unidad, que en este caso es 2) y carga el resultado en una tabla de staging denominada TMP_LISTADO_MATRICULAS_Q10 ubicada en el esquema Transversal.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_2","title":"Detalles del Proceso","text":"<ol> <li> <p>Extracci\u00f3n de Datos \u2013 Listado cede </p> <ul> <li>Fuente: Se utiliza un componente Excel Source denominado \"Listado cede\" para extraer los datos de la hoja de Excel.  </li> <li>Columnas Extra\u00eddas: Entre las columnas extra\u00eddas se encuentran:  <ul> <li>JORNADA </li> <li>NOMBRE_ESTUDIANTE </li> <li>TIPO_DOCUMENTO </li> <li>DOCUMENTO_ESTUDIANTE </li> <li>FECHA_MATRICULA </li> <li>TELEFONO </li> <li>CELULAR </li> <li>CORREO </li> <li>SEMESTRE </li> <li>ESTADO </li> <li>SEDE </li> <li>PROGRAMA</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos \u2013 Derivaci\u00f3n del ID_UNIDAD </p> <ul> <li>Componente: \"cede Derived ID_UNIDAD\"  </li> <li>Funci\u00f3n: Utiliza una transformaci\u00f3n Derived Column para agregar una nueva columna llamada ID_UNIDAD con un valor constante de 2.  </li> <li>Prop\u00f3sito: Este valor permite clasificar los registros como pertenecientes al \u00e1rea de Cedesarrollo, facilitando la integraci\u00f3n y posterior an\u00e1lisis.</li> </ul> </li> <li> <p>Carga de Datos \u2013 TMP_LISTADO_MATRICULAS_Q10 </p> <ul> <li>Destino: El componente \"TMP_MATRICULAS_Q10\" carga la informaci\u00f3n transformada en la tabla de staging [Transversal].[TMP_LISTADO_MATRICULAS_Q10].  </li> <li>Propiedades Clave: <ul> <li>Se utiliza la inserci\u00f3n masiva (Bulk Insert) para optimizar el rendimiento.  </li> <li>Configurado para trabajar con un tama\u00f1o de lote que se adapta al b\u00fafer interno de SSIS.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_4","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama muestra el flujo general de datos en este componente:</p> <pre><code>graph TD\n    A[Excel Source: Listado cede] --&gt; B[Derived Column: cede Derived ID_UNIDAD]\n    B --&gt; C[Destino: TMP_LISTADO_MATRICULAS_Q10]\n    C --&gt; D[Datos cargados en staging]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-dim_programa_1","title":"Componente <code>Actualizar DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar DIM_PROGRAMA es un Data Flow Task que forma parte del flujo ETL del paquete FACT_DESERTORES. Su prop\u00f3sito es extraer informaci\u00f3n de programas acad\u00e9micos de una fuente (por ejemplo, un archivo Excel que contiene el listado de estudiantes o programas) y cargar los registros que a\u00fan no existen en la tabla de dimensi\u00f3n DIM_PROGRAMA del esquema Cedesarrollo.</p> <p>Este componente se encarga de identificar los programas nuevos (aquellos que no est\u00e1n registrados en DIM_PROGRAMA) y, posteriormente, los inserta en la tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_3","title":"Detalles del Proceso","text":"<ol> <li> <p>Identificar Registros Nuevos </p> <ul> <li>El componente \"Identificar programas\" ejecuta una consulta SQL contra la tabla temporal (por ejemplo, una tabla en el \u00e1rea de staging) para extraer los programas que a\u00fan no han sido registrados en DIM_PROGRAMA.</li> <li>Se utiliza una instrucci\u00f3n que compara los datos extra\u00eddos con la informaci\u00f3n ya existente en DIM_PROGRAMA (mediante un LEFT JOIN y filtrando los registros donde el campo ID_PROGRAMA es NULL).</li> </ul> </li> <li> <p>Cargar Datos en DIM_PROGRAMA </p> <ul> <li>Una vez identificados los registros nuevos, el componente \"Guardar DIM_PROGRAMA\" inserta dichos registros en la tabla [Cedesarrollo].[DIM_PROGRAMA].</li> <li>Se utiliza la inserci\u00f3n masiva (Bulk Insert) para optimizar el rendimiento.</li> </ul> </li> <li> <p>Conexi\u00f3n y Configuraci\u00f3n </p> <ul> <li>El componente utiliza un administrador de conexiones configurado para el destino (DWH_COMFENALCO_Destino).</li> <li>Se definen propiedades como el tama\u00f1o del lote (BatchSize), tiempo de espera (CommandTimeout) y el uso de la interfaz SqlBulkCopy para mejorar el rendimiento.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_5","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama ilustra el flujo de datos para actualizar la tabla DIM_PROGRAMA:</p> <pre><code>graph TD\n    A[Identificar programas nuevos] --&gt; B[Generar conjunto de registros nuevos]\n    B --&gt; C[Guardar DIM_PROGRAMA]\n    C --&gt; D[Tabla DIM_PROGRAMA actualizada]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tmp_matriculas_cedesarrollo","title":"Componente <code>TMP_MATRICULAS_CEDESARROLLO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>El componente TMP_MATRICULAS_CEDESARROLLO es un Data Flow Task encargado de cargar y unificar datos de matr\u00edculas de Cedesarrollo en la tabla de staging [Transversal].[TMP_LISTADO_MATRICULAS_Q10]. Este flujo de datos toma la informaci\u00f3n procesada y consolidada (por medio de la transformaci\u00f3n \"Unificacion Listas Q10\") y la env\u00eda al destino, donde se almacena para procesos posteriores de integraci\u00f3n y an\u00e1lisis.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_4","title":"Detalles del Proceso","text":"<ol> <li> <p>Unificaci\u00f3n de Listas (Unificacion Listas Q10)</p> <ul> <li>Funci\u00f3n:     Extrae y unifica datos provenientes de una fuente consolidada (por ejemplo, registros de matr\u00edculas extra\u00eddos del Excel \"Listado cede\"). Esta transformaci\u00f3n estandariza la informaci\u00f3n, elimina duplicados y genera un conjunto de datos unificado.</li> <li>Columnas Clave: <ul> <li>NOMBRE_ESTUDIANTE  </li> <li>TIPO_DOCUMENTO  </li> <li>DOCUMENTO_ESTUDIANTE  </li> <li>FECHA_MATRICULA  </li> <li>TELEFONO  </li> <li>CELULAR  </li> <li>CORREO  </li> <li>SEMESTRE  </li> <li>ESTADO  </li> <li>SEDE  </li> <li>PROGRAMA  </li> <li>ID_UNIDAD  </li> <li>DOCUMENTOS_COMPLETOS  </li> <li>JORNADA</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos \u2013 Tabla Temporal</p> <ul> <li>Funci\u00f3n:     El componente \"Tabla Temporal\" utiliza el destino ADO.NET para insertar los datos unificados en la tabla [Transversal].[TMP_LISTADO_MATRICULAS_Q10].</li> <li>Propiedades Destacadas: <ul> <li>Inserci\u00f3n masiva habilitada para optimizar el rendimiento.  </li> <li>Par\u00e1metros de BatchSize y CommandTimeout configurados para un procesamiento eficiente.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_6","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama ilustra el flujo de datos en el componente:</p> <pre><code>graph TD\n    A[Unificacion Listas Q10 Fuente ADO.NET] --&gt; B[Tabla Temporal Destino]\n    B --&gt; C[Datos cargados en TMP_LISTADO_MATRICULAS_Q10]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-fact_estado_matriculas","title":"Componente <code>FACT_ESTADO_MATRICULAS</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>El componente Poblar Tabla FACT_ESTADO_MATRICULAS es un Data Flow Task que se encarga de extraer, transformar y cargar (ETL) datos para la tabla de hechos FACT_ESTADO_MATRICULAS. La informaci\u00f3n consolidada proviene de una consulta SQL que unifica y filtra registros de matr\u00edculas, asegur\u00e1ndose de insertar \u00fanicamente aquellos registros nuevos (aquellos que a\u00fan no se encuentren en la tabla destino). Este proceso permite actualizar la informaci\u00f3n del estado de matr\u00edcula en el entorno de Cedesarrollo, vinculando datos de estudiantes, programas, jornadas, periodos y fechas.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_5","title":"Detalles del Proceso","text":"<ol> <li> <p>Consulta de Origen (FACT_ESTADO_MATRICULAS Consulta):</p> <ul> <li>Funci\u00f3n:     Se ejecuta una consulta SQL que utiliza expresiones con cl\u00e1usulas WITH para crear subconjuntos de datos (por ejemplo, la CTE Matriculas) y generar valores calculados, como el identificador de fecha (ID_FECHA) y el periodo acad\u00e9mico derivado.</li> <li>Uniones y Filtros: <ul> <li>Se relaciona la fuente de datos con la tabla de estudiantes y, opcionalmente, con la tabla de periodos acad\u00e9micos.</li> <li>Se utiliza la funci\u00f3n ROW_NUMBER para eliminar duplicados y seleccionar s\u00f3lo el primer registro por estudiante, jornada, programa, periodo y semestre.</li> </ul> </li> <li>Resultado:     Se retorna un conjunto de datos que incluye campos clave como ID_PERIODO, ID_PROGRAMA, SEDE, ID_JORNADA, NOMBRE_ESTUDIANTE, ID_ESTUDIANTE, ID_FECHA, FECHA_MATRICULA, TELEFONO, CELULAR, CORREO, DOCUMENTOS_COMPLETOS, SEMESTRE, FECHA_INICIO_PERIODO y un campo de control (ID_MATRICULA) que, si es nulo, indica que el registro no existe en FACT_ESTADO_MATRICULAS.</li> </ul> </li> <li> <p>Salida de la Consulta:</p> <ul> <li>Los datos resultantes de la consulta se env\u00edan a la salida \"Salida de origen de ADO NET\" para su posterior procesamiento y carga.</li> </ul> </li> <li> <p>Carga en la Tabla Destino:</p> <ul> <li>Destino ADO.NET:     El componente utiliza el destino ADO.NET configurado para insertar los registros en la tabla [Cedesarrollo].[FACT_ESTADO_MATRICULAS].</li> <li>Propiedades Clave: <ul> <li>Se configura para realizar inserciones en bloque (Bulk Insert) con un BatchSize de 0 y un CommandTimeout de 30 segundos.</li> <li>Se utilizan las columnas extra\u00eddas por la consulta para alimentar la tabla destino, garantizando que se inserten s\u00f3lo aquellos registros que a\u00fan no se encuentren en la tabla (seg\u00fan la condici\u00f3n WHERE de la consulta).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_7","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama ilustra de forma esquem\u00e1tica el flujo de datos dentro de este componente:</p> <pre><code>graph TD\n    A[Consulta FACT_ESTADO_MATRICULAS]\n    B[Salida de origen de ADO NET]\n    C[Destino ADO.NET: FACT_ESTADO_MATRICULAS]\n\n    A --&gt; B\n    B --&gt; C</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_graduados","title":"FACT_GRADUADOS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_programa","title":"Componente <code>Data DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_PROGRAMA est\u00e1 dise\u00f1ado para extraer, transformar y cargar (ETL) la informaci\u00f3n de los programas educativos provenientes de un archivo Excel. El proceso incluye la eliminaci\u00f3n de duplicados, la agregaci\u00f3n de datos y la verificaci\u00f3n de la existencia del programa a trav\u00e9s de una transformaci\u00f3n de b\u00fasqueda (Lookup). Finalmente, los registros \u00fanicos se insertan en la tabla [Cedesarrollo].[DIM_PROGRAMA].</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-proceso","title":"Detalle del Proceso","text":"<ol> <li> <p>Excel Source (Listado cede):</p> <ul> <li>Funci\u00f3n:     Extrae los datos de un archivo Excel, espec\u00edficamente de la hoja Sheet1, que contiene informaci\u00f3n relacionada con los programas (entre otros campos como JORNADA, NOMBRE_ESTUDIANTE, TIPO_DOCUMENTO, DOCUMENTO, etc.).</li> <li>Salida:     Genera un conjunto de registros que se utilizan como base para el procesamiento.</li> </ul> </li> <li> <p>Derived Column (cede Derived ID_UNIDAD):</p> <ul> <li>Funci\u00f3n:     Agrega o modifica columnas en el flujo de datos. En este caso, se crea una nueva columna ID_UNIDAD con un valor constante igual a 2, asignando la unidad correspondiente para el entorno de Cedesarrollo.</li> <li>Salida:     Los registros ahora incluyen el campo ID_UNIDAD.</li> </ul> </li> <li> <p>Sort PROGRAMA:</p> <ul> <li>Funci\u00f3n:     Ordena los registros por la columna PROGRAMA en orden ascendente. Se configura para eliminar duplicados, asegurando que cada programa se procese una sola vez.</li> <li>Salida:     Registros \u00fanicos y ordenados por PROGRAMA.</li> </ul> </li> <li> <p>Lookup PROGRAMA:</p> <ul> <li>Funci\u00f3n:     Realiza una b\u00fasqueda en la tabla [Cedesarrollo].[DIM_PROGRAMA] para identificar aquellos registros que ya existen en la dimensi\u00f3n.  <ul> <li>La consulta de Lookup se basa en la columna PROGRAMA.</li> <li>La propiedad NoMatchBehavior est\u00e1 configurada para enviar los registros sin coincidencias a la salida de \u201cno match\u201d, lo que permite identificar los nuevos programas.</li> </ul> </li> <li>Salida:     Se generan dos salidas:<ul> <li>Lookup Match Output: Registros que ya existen en la dimensi\u00f3n.</li> <li>Lookup No Match Output: Registros nuevos que deben ser insertados.</li> </ul> </li> </ul> </li> <li> <p>Aggregate 1:</p> <ul> <li>Funci\u00f3n:     Agrega (agrupa) los registros nuevos provenientes de la salida \u201cno match\u201d del Lookup.  <ul> <li>Se agrupa por la columna PROGRAMA.</li> <li>Se utiliza una funci\u00f3n de agregaci\u00f3n (en este caso, la propia columna) para garantizar que se obtenga un registro \u00fanico para cada programa.</li> </ul> </li> <li>Salida:     Un conjunto consolidado de programas nuevos.</li> </ul> </li> <li> <p>Destino ADO.NET \u2013 Guardar DIM_PROGRAMA:</p> <ul> <li>Funci\u00f3n:     Inserta los registros \u00fanicos resultantes en la tabla [Cedesarrollo].[DIM_PROGRAMA].</li> <li>Configuraci\u00f3n: <ul> <li>Se utiliza el proveedor ADO.NET configurado para el destino DWH_COMFENALCO_Destino.</li> <li>Se habilita el uso de inserci\u00f3n masiva (Bulk Insert) para mejorar el rendimiento.</li> </ul> </li> <li>Resultado:     La dimensi\u00f3n DIM_PROGRAMA queda actualizada con los nuevos programas.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-flujo-de-datos","title":"Diagrama de Flujo de Datos","text":"<pre><code>flowchart TD\n    A[Excel Source: Listado cede] --&gt; B[Derived Column: cede Derived ID_UNIDAD Asigna ID_UNIDAD = 2]\n    B --&gt; C[Sort PROGRAMA Ordena y elimina duplicados]\n    C --&gt; D[Lookup PROGRAMA Verifica existencia en DIM_PROGRAMA]\n    D -- \"No Match\" --&gt; E[Aggregate 1 Agrupa por PROGRAMA]\n    E --&gt; F[Destino ADO.NET: Guardar DIM_PROGRAMA]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_jornada","title":"Componente <code>Data DIM_JORNADA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_JORNADA extrae informaci\u00f3n relacionada con las jornadas acad\u00e9micas desde un archivo Excel, la transforma y la prepara para integrarse a la dimensi\u00f3n [Cedesarrollo].[DIM_JORNADA]. Este componente utiliza diversas transformaciones para garantizar que los datos sean consistentes, se eliminen duplicados y se enriquezcan con informaci\u00f3n de referencia.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-proceso_1","title":"Detalle del Proceso","text":"<ol> <li> <p>Excel Source 1:</p> <ul> <li>Funci\u00f3n:     Lee los datos desde un archivo Excel (hoja Sheet1) que contiene informaci\u00f3n sobre jornadas, as\u00ed como otros campos relevantes como ID_MATRICULA, TIPO_DOCUMENTO, DOCUMENTO, GRUPO, SEDE, PROGRAMA, PERIODO_ACADEMICO, SEMESTRE, FECHA_GRADUADO, ACTA_GRADUADO, FOLIO_GRADUADO, ZONA, \u00daLTIMA FECHA DE ACTUALIZACI\u00d3N y ID_UNIDAD.</li> <li>Salida:     Proporciona el conjunto de registros que servir\u00e1 como base para las transformaciones posteriores.</li> </ul> </li> <li> <p>Sort JORNADA:</p> <ul> <li>Funci\u00f3n:     Ordena los datos en funci\u00f3n de la columna JORNADA (y de ID_UNIDAD como segundo criterio), eliminando registros duplicados.  </li> <li>Salida:     Un conjunto ordenado y sin duplicados, que garantiza que cada jornada se procese de manera \u00fanica.</li> </ul> </li> <li> <p>Transformar Columnas (Derived Column):</p> <ul> <li>Funci\u00f3n:     Crea nuevas columnas derivadas, en este caso:</li> <li>_JORNADA: Se transforma y se ajusta el valor de la columna JORNADA para asegurar consistencia (por ejemplo, se puede estandarizar el formato o recortar espacios).</li> <li>_ID_UNIDAD: Convierte el valor de ID_UNIDAD al tipo de dato correcto (en este ejemplo se transforma a entero).</li> <li>Salida:     Los registros salen enriquecidos con las columnas _JORNADA y _ID_UNIDAD, prepar\u00e1ndolos para el siguiente paso.</li> </ul> </li> <li> <p>Aggregate:</p> <ul> <li>Funci\u00f3n:     Agrupa los registros bas\u00e1ndose en las columnas _JORNADA y _ID_UNIDAD. Esta agregaci\u00f3n garantiza que para cada combinaci\u00f3n \u00fanica de jornada y unidad se obtenga un solo registro.</li> <li>Salida:     Registros consolidados y agrupados, listos para ser verificados y comparados con la tabla de referencia.</li> </ul> </li> <li> <p>Filtrar Registros (Conditional Split):</p> <ul> <li>Funci\u00f3n:     Utiliza una condici\u00f3n (por ejemplo, verificando que la columna _JORNADA no sea nula ni est\u00e9 vac\u00eda) para dirigir solo los registros v\u00e1lidos al flujo de carga.</li> <li>Salida:     Se env\u00edan los registros v\u00e1lidos a la siguiente transformaci\u00f3n y los registros con errores o datos faltantes a la salida de error.</li> </ul> </li> <li> <p>Lookup DIM_JORNADA:</p> <ul> <li>Funci\u00f3n:     Realiza una b\u00fasqueda en la tabla [Cedesarrollo].[DIM_JORNADA] utilizando las columnas JORNADA e ID_UNIDAD para determinar si el registro ya existe.  <ul> <li>Par\u00e1metros:   Se utilizan los valores transformados (_JORNADA y _ID_UNIDAD) para hacer la comparaci\u00f3n.</li> </ul> </li> <li>Salida: <ul> <li>Lookup Match Output: Registros que ya existen en la dimensi\u00f3n.</li> <li>Lookup No Match Output: Registros nuevos que no tienen coincidencia en la tabla de referencia y, por tanto, deben ser insertados.</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_JORNADA (Destino ADO.NET):</p> <ul> <li>Funci\u00f3n:     Inserta los registros nuevos (provenientes de la salida \u201cno match\u201d del Lookup) en la tabla [Cedesarrollo].[DIM_JORNADA].  </li> <li>Configuraci\u00f3n: <ul> <li>Se utiliza un Connection Manager ADO.NET configurado para el destino DWH_COMFENALCO_Destino.</li> <li>La tarea est\u00e1 optimizada para inserciones masivas (Bulk Insert) para mejorar el rendimiento.</li> </ul> </li> <li>Resultado:     La dimensi\u00f3n DIM_JORNADA se actualiza con la informaci\u00f3n de nuevas jornadas, garantizando la integridad y consistencia de los datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-flujo-de-datos","title":"Diagrama del Flujo de Datos","text":"<pre><code>flowchart TD\n    A[Excel Source 1: Lee datos de jornada y otros campos]\n    B[Sort JORNADA: Ordena y elimina duplicados]\n    C[Transformar Columnas: Crea _JORNADA y _ID_UNIDAD]\n    D[Aggregate: Agrupa registros por _JORNADA y _ID_UNIDAD]\n    E[Filtrar Registros: Verifica que _JORNADA no sea nulo]\n    F[Lookup DIM_JORNADA: Busca coincidencias en la dimensi\u00f3n]\n    G[Guardar DIM_JORNADA: Inserta registros nuevos en Cedesarrollo.DIM_JORNADA]\n\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n    F -- \"No Match\" --&gt; G</code></pre> <p>Actualizando documentaci\u00f3n</p> <p>El usuario quiere actualizar la documentaci\u00f3n del pipeline de datos, bas\u00e1ndose en un c\u00f3digo que proporcionaron. El flujo comienza con \"Excel Source\" y sigue con \"Filtrar Documento Vac\u00edos\" (Conditional Split), luego \"Derived Column\" (ajustando la fecha de \u00faltima actualizaci\u00f3n: \u00daLTIMA FECHA). Despu\u00e9s, el flujo incluye varios \"Lookups\" (ID_ESTUDIANTE, ID_JORNADA, ID_PERIODO, ID_PROGRAMA), seguido de \"Transforma Columnas\". Adem\u00e1s, \"Lookup ACTA GRADO\" toma datos del primer \"Derived Column\". Necesito reflejar este flujo con precisi\u00f3n en la documentaci\u00f3n.</p> <p>Aclarando el flujo del pipeline</p> <p>El flujo parece seguir varios pasos y tiene dos componentes llamados \"Transformar Columnas\", aunque tienen funciones diferentes. La primera instancia ajusta la \"\u00daLTIMA FECHA\" y usa un \"Derived Column\". Luego, se encuentra otro \"Derived Column\" llamado \"Transformar Columnas\", que realiza conversiones de tipo y agrega un prefijo de guion bajo a los campos. Este \u00faltimo pasa su salida al \"Multicast\", mientras que el componente \"Lookup ACTA GRADO\" usa la salida de la primera transformaci\u00f3n de fecha.</p> <p>Pensado durante 10 segundos</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-fact_graduados","title":"Componente <code>Data FACT_GRADUADOS</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#objetivo","title":"Objetivo","text":"<p>Procesar los registros de graduados extra\u00eddos de un archivo Excel, limpiarlos y enriquecerlos (ajuste de fechas, filtrado, type\u2010casts, lookup de dimensiones y normalizaci\u00f3n de IDs), y finalmente cargarlos en la tabla <code>[Cedesarrollo].[FACT_GRADUADOS]</code> para su an\u00e1lisis y reporte.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#flujo-del-proceso_2","title":"Flujo del Proceso","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Funci\u00f3n:     Lee todos los campos de la hoja Sheet1 del Excel.</li> <li>Columnas clave extra\u00eddas: <code>ID_MATRICULA</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>GRUPO</code>, <code>SEDE</code>, <code>JORNADA</code>,     <code>PROGRAMA</code>, <code>PERIODO_ACADEMICO</code>, <code>SEMESTRE</code>, <code>FECHA_GRADUADO</code>,     <code>ACTA_GRADUADO</code>, <code>FOLIO_GRADUADO</code>, <code>ZONA</code>, <code>\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N</code>, <code>ID_UNIDAD</code>.</li> </ul> </li> <li> <p>Conditional Split \u2013 Filtrar DOCUMENTO vac\u00edos</p> <ul> <li>Funci\u00f3n:     Desecha las filas donde el campo <code>DOCUMENTO</code> est\u00e9 nulo o s\u00f3lo contenga espacios.</li> <li> <p>Expresi\u00f3n:</p> <pre><code>!ISNULL(_DOCUMENTO) &amp;&amp; LEN(TRIM(_DOCUMENTO)) &gt; 0\n</code></pre> </li> </ul> </li> <li> <p>Derived Column \u2013 Ajuste de \u201c\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N\u201d</p> <ul> <li>Funci\u00f3n:     Garantiza siempre una fecha v\u00e1lida: si es nula, usa <code>GETDATE()</code>, si no, mantiene el valor.</li> <li> <p>Expresi\u00f3n:</p> <pre><code>ISNULL([\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N]) \n  ? GETDATE() \n  : [\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N]\n</code></pre> </li> </ul> </li> <li> <p>Derived Column \u2013 Formateo y prefijos de campos</p> <ul> <li>Funci\u00f3n:     Crea versiones tipadas y con prefijo <code>_</code> de los campos extra\u00eddos, para homogeneizar antes de los lookups.</li> <li> <p>Ejemplo de expresiones:</p> <pre><code>(DT_WSTR,40)[TIPO_DOCUMENTO]    AS _TIPO_DOCUMENTO  \n(DT_WSTR,20)[DOCUMENTO]         AS _DOCUMENTO  \n(DT_WSTR,20)[GRUPO]             AS _GRUPO  \n(DT_WSTR,255)[SEDE]             AS _SEDE  \n\u2026  \n(DT_I4)[ID_UNIDAD]              AS _ID_UNIDAD  \n</code></pre> </li> </ul> </li> <li> <p>Lookup Transformations</p> <ul> <li>Lookup ID_ESTUDIANTE     \u2013 Busca en <code>[Cedesarrollo].[DIM_ESTUDIANTES]</code> por <code>_DOCUMENTO</code> \u2192 obtiene <code>ID_ESTUDIANTE</code>.</li> <li>Lookup ID_JORNADA     \u2013 Usa <code>_JORNADA</code>\u202f+\u202f<code>_ID_UNIDAD</code> en <code>[Cedesarrollo].[DIM_JORNADA]</code> \u2192 obtiene <code>ID_JORNADA</code>.</li> <li>Lookup ID_PERIODO     \u2013 Usa <code>PERIODO_ACADEMICO</code>\u202f+\u202f<code>_ID_UNIDAD</code> en <code>[Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code> \u2192 obtiene <code>ID_PERIODO</code>.</li> <li>Lookup ID_PROGRAMA     \u2013 Busca <code>_PROGRAMA</code> en <code>[Cedesarrollo].[DIM_PROGRAMA]</code> \u2192 obtiene <code>ID_PROGRAMA</code>.</li> </ul> </li> <li> <p>Derived Column \u2013 Normalizaci\u00f3n de IDs</p> <ul> <li>Funci\u00f3n:     Sustituye cualquier <code>NULL</code> en los IDs cr\u00edticos (<code>ID_ESTUDIANTE</code>, <code>ID_PERIODO</code>) por\u202f<code>-1</code> para evitar llaves faltantes.</li> <li> <p>Expresiones:</p> <pre><code>ISNULL(ID_ESTUDIANTE) ? -1 : ID_ESTUDIANTE  \nISNULL(ID_PERIODO)    ? -1 : ID_PERIODO\n</code></pre> </li> </ul> </li> <li> <p>Lookup ACTA GRADO</p> <ul> <li>Funci\u00f3n:     Verifica en <code>[Cedesarrollo].[FACT_GRADUADOS]</code> si ya existe un graduado con     <code>ACTA_GRADUADO</code>, <code>ID_ESTUDIANTE</code>, <code>ID_PROGRAMA</code> para evitar duplicados o actualizar registros.</li> </ul> </li> <li> <p>Multicast FACT_GRADUADOS</p> <ul> <li>Funci\u00f3n:     Duplica el flujo enriquecido para enviarlo al destino sin alterar los datos.</li> </ul> </li> <li> <p>Destino \u2013 Guardar FACT_GRADUADOS</p> <ul> <li>Funci\u00f3n:     Inserta en masa (bulk insert) el conjunto final en la tabla     <code>[Cedesarrollo].[FACT_GRADUADOS]</code> v\u00eda ADO.NET (Connection Manager <code>DWH_COMFENALCO_Destino</code>).</li> <li>Optimizaci\u00f3n:     Uso de <code>SqlBulkCopy</code> cuando sea posible y <code>BatchSize=0</code> para rendimiento \u00f3ptimo.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_inscripcion_matriculas","title":"FACT_INSCRIPCION_MATRICULAS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_programa-1","title":"Componente <code>Data DIM_PROGRAMA 1</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_PROGRAMA 1 se encarga de procesar informaci\u00f3n de programas acad\u00e9micos, realizando operaciones de extracci\u00f3n desde una fuente de Excel, transformaci\u00f3n de datos y carga en una tabla de destino. Incluye tareas de ordenamiento, b\u00fasqueda y agregaci\u00f3n de registros.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li>Hoja: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>TIPO_DOCUMENTO, REFERENCIA, INSCRITO, FECHA, DOCUMENTO_ESTUDIANTE, PROGRAMA, NOMBRE, SEDE, JORNADA</code></li> </ul> </li> </ul> </li> <li> <p>Sort PROGRAMA</p> <ul> <li>Descripci\u00f3n: Ordena los datos en funci\u00f3n de la columna PROGRAMA.</li> <li>Propiedades:<ul> <li>Elimina duplicados: <code>true</code></li> <li>Orden por columna: PROGRAMA en orden ascendente.</li> </ul> </li> </ul> </li> <li> <p>Lookup PROGRAMA</p> <ul> <li>Descripci\u00f3n: Realiza un cruce de informaci\u00f3n con la tabla DIM_PROGRAMA para enriquecer los datos.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA]</code></li> <li>Comportamiento ante no coincidencias: Envia registros sin coincidencia a un flujo separado.</li> </ul> </li> </ul> </li> <li> <p>Aggregate 1</p> <ul> <li>Descripci\u00f3n: Realiza operaciones de agregaci\u00f3n sobre la columna PROGRAMA.</li> <li>Propiedades:<ul> <li>Factor de extensi\u00f3n de memoria: <code>25%</code></li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_PROGRAMA</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino DIM_PROGRAMA.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Table\n\n    SSIS -&gt;&gt; Excel: Extraer datos\n    Excel -&gt;&gt; SSIS: Datos procesados\n    SSIS -&gt;&gt; SQL: Lookup con DIM_PROGRAMA\n    SQL -&gt;&gt; SSIS: Resultados del cruce\n    SSIS -&gt;&gt; SQL: Carga de datos en DIM_PROGRAMA</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-fact_inscripcion_matriculas","title":"Componente <code>Data FACT_INSCRIPCION_MATRICULAS</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data FACT_INSCRIPCION_MATRICULAS maneja la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con la inscripci\u00f3n de matr\u00edculas. Incluye tareas de b\u00fasqueda, transformaci\u00f3n y derivaci\u00f3n de columnas, con la carga final en una tabla de hechos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>TIPO_DOCUMENTO,REFERENCIA,INSCRITO,FECHA,DOCUMENTO_ESTUDIANTE,PROGRAMA,NOMBRE,SEDE,JORNADA</code></li> </ul> </li> </ul> </li> <li> <p>Lookup ID_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Busca y asocia el identificador del estudiante desde la tabla DIM_ESTUDIANTES.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code></li> <li>Columna de uni\u00f3n: DOCUMENTO</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PROGRAMA</p> <ul> <li>Descripci\u00f3n: Busca y asocia el identificador del programa desde la tabla DIM_PROGRAMA.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA]</code></li> <li>Columna de uni\u00f3n: PROGRAMA</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_JORNADA</p> <ul> <li>Descripci\u00f3n: Busca y asocia el identificador de la jornada desde la tabla DIM_JORNADA.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]</code></li> <li>Columna de uni\u00f3n: JORNADA</li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas</p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas con transformaciones personalizadas.</li> <li>Columnas derivadas:<ul> <li><code>_INSCRITO</code>: <code>(DT_WSTR,40)INSCRITO</code></li> <li><code>_FECHA</code>: <code>(DT_DATE)FECHA</code></li> <li><code>_ID_PERIODO</code>: <code>-1</code></li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_INSCRIPCION_MATRICULAS</p> <ul> <li>Descripci\u00f3n: Busca coincidencias en la tabla FACT_INSCRIPCION_MATRICULAS.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]</code></li> <li>Columnas de uni\u00f3n: ID_ESTUDIANTE, ID_PROGRAMA, ID_JORNADA</li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_INSCRIPCION_MATRICULAS</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla de destino.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_INSCRIPCION_MATRICULAS\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Table\n\n    SSIS -&gt;&gt; Excel: Extraer datos\n    Excel -&gt;&gt; SSIS: Datos procesados\n    SSIS -&gt;&gt; SQL: Lookup con DIM_ESTUDIANTES\n    SQL -&gt;&gt; SSIS: Resultado Lookup ID_ESTUDIANTE\n    SSIS -&gt;&gt; SQL: Lookup con DIM_PROGRAMA\n    SQL -&gt;&gt; SSIS: Resultado Lookup ID_PROGRAMA\n    SSIS -&gt;&gt; SQL: Lookup con DIM_JORNADA\n    SQL -&gt;&gt; SSIS: Resultado Lookup ID_JORNADA\n    SSIS -&gt;&gt; SQL: Carga datos en FACT_INSCRIPCION_MATRICULAS</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_notas","title":"FACT_NOTAS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-cede_historico_notas","title":"Componente <code>Tarea cede_Historico_Notas</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>La tarea cede_Historico_Notas ejecuta un proceso externo para descargar datos hist\u00f3ricos de notas utilizando un script de Python.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-proceso","title":"Componentes del Proceso","text":"<ol> <li>Tarea cede_Historico_Notas<ul> <li>Descripci\u00f3n: Ejecuta un script de Python para descargar datos hist\u00f3ricos de notas.</li> <li>Propiedades:<ul> <li>Ruta del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos: <code>download.py --key cede_Historico_Notas</code></li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key cede_Historico_Notas`\n    Python -&gt;&gt; Python: Descarga datos de notas hist\u00f3ricas\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-dim_estudiantes-py_1","title":"Componente <code>dim_Estudiantes py</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>La tarea dim_Estudiantes py ejecuta un proceso externo para procesar la dimensi\u00f3n de estudiantes utilizando un script de Python.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-proceso_1","title":"Componentes del Proceso","text":"<ol> <li>dim_Estudiantes py<ul> <li>Descripci\u00f3n: Ejecuta un script de Python para procesar la tabla de dimensi\u00f3n de estudiantes.</li> <li>Propiedades:<ul> <li><code>Ruta del ejecutable</code>: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li><code>Argumentos</code>: <code>dim_Estudiantes.py</code></li> <li><code>Directorio de trabajo</code>: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `dim_Estudiantes.py`\n    Python -&gt;&gt; Python: Procesa la dimensi\u00f3n de estudiantes\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_jornada_1","title":"Componente <code>Data DIM_JORNADA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_JORNADA realiza el flujo de datos necesario para procesar y cargar la tabla de dimensi\u00f3n DIM_JORNADA. Incluye la extracci\u00f3n desde un archivo de Excel, transformaciones de datos y la carga en una base de datos de destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>JORNADA, SEDE, PERIODO_ACADEMICO, CURSO, NOMBRE_ESTUDIANTE, PRIMER_CORTE, SEGUNDO_CORTE, TERCER_CORTE, NOTA_FINAL, INASISTENCIAS_ACUMULADAS, MODULO, FECHA_INICIO, PROGRAMA_ACADEMICO, NOMBRE_DOCENTE, FECHA_FIN</code></li> </ul> </li> </ul> </li> <li> <p>Transformar ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Deriva una nueva columna con un identificador de unidad fijo.</li> <li>Columnas derivadas:<ul> <li>ID_UNIDAD: <code>2</code></li> </ul> </li> </ul> </li> <li> <p>Sort ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Ordena los datos por JORNADA y ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Eliminaci\u00f3n de duplicados: <code>true</code></li> </ul> </li> </ul> </li> <li> <p>Ajustar Ancho Columnas</p> <ul> <li>Descripci\u00f3n: Ajusta el ancho de las columnas procesadas.</li> <li>Columnas derivadas:<ul> <li>_JORNADA: <code>(DT_WSTR,40)JORNADA</code></li> <li>_ID_UNIDAD: <code>(DT_I4)ID_UNIDAD</code></li> </ul> </li> </ul> </li> <li> <p>Filtrar Registros Nulos</p> <ul> <li>Descripci\u00f3n: Filtra registros con valores nulos o vac\u00edos en la columna _JORNADA.</li> <li>Condici\u00f3n: <code>!ISNULL(_JORNADA) &amp;&amp; LEN(TRIM(_JORNADA)) &gt; 0</code></li> </ul> </li> <li> <p>Lookup DIM_JORNADA</p> <ul> <li>Descripci\u00f3n: Busca y asocia los registros en la tabla DIM_JORNADA con base en las columnas _JORNADA y _ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]</code></li> <li>Columnas de uni\u00f3n: JORNADA, ID_UNIDAD</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_JORNADA</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla DIM_JORNADA.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant DB as Database\n\n    SSIS -&gt;&gt; Excel: Extrae datos de `Sheet1$`\n    Excel -&gt;&gt; SSIS: Devuelve datos extra\u00eddos\n    SSIS -&gt;&gt; SSIS: Realiza transformaciones y ajustes\n    SSIS -&gt;&gt; DB: Guarda datos en `DIM_JORNADA`</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_periodo_academico","title":"Componente <code>Data DIM_PERIODO_ACADEMICO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_PERIODO_ACADEMICO realiza un flujo de datos para procesar y cargar la tabla de dimensi\u00f3n DIM_PERIODO_ACADEMICO. Este flujo incluye la extracci\u00f3n desde un archivo de Excel, transformaciones de datos y la carga en una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>PERIODO_ACADEMICO, SEDE, JORNADA, CURSO, NOMBRE_ESTUDIANTE, PRIMER_CORTE, SEGUNDO_CORTE, TERCER_CORTE, NOTA_FINAL, INASISTENCIAS_ACUMULADAS, MODULO, FECHA_INICIO, PROGRAMA_ACADEMICO, NOMBRE_DOCENTE, FECHA_FIN</code></li> </ul> </li> </ul> </li> <li> <p>Crear ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Deriva una nueva columna con un identificador de unidad fijo.</li> <li>Columnas derivadas:<ul> <li>ID_UNIDAD: <code>3</code></li> </ul> </li> </ul> </li> <li> <p>Sort PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Ordena los datos por PERIODO_ACADEMICO y ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Eliminaci\u00f3n de duplicados: <code>true</code></li> </ul> </li> </ul> </li> <li> <p>Ajustar Ancho Columnas</p> <ul> <li>Descripci\u00f3n: Ajusta el ancho de las columnas procesadas.</li> <li>Columnas derivadas:<ul> <li>_PERIODO_ACADEMICO: <code>(DT_WSTR,40)PERIODO_ACADEMICO</code></li> <li>_ID_UNIDAD: <code>(DT_I4)ID_UNIDAD</code></li> </ul> </li> </ul> </li> <li> <p>Filtrar Registros Vac\u00edos</p> <ul> <li>Descripci\u00f3n: Filtra registros con valores vac\u00edos o nulos en la columna _PERIODO_ACADEMICO.</li> <li>Condici\u00f3n: <code>!ISNULL(_PERIODO_ACADEMICO) &amp;&amp; LEN(TRIM(_PERIODO_ACADEMICO)) &gt; 0</code></li> </ul> </li> <li> <p>Lookup DIM_PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Busca y asocia registros en la tabla DIM_PERIODO_ACADEMICO con base en las columnas _PERIODO_ACADEMICO y _ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code></li> <li>Columnas de uni\u00f3n: PERIODO_ACADEMICO, ID_UNIDAD</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla DIM_PERIODO_ACADEMICO.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_PERIODO_ACADEMICO\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencias","title":"Diagrama de Secuencias","text":"<pre><code>graph TD\n    A(Excel Source) --&gt; B(Crear ID_UNIDAD: Deriva ID_UNIDAD=3)\n    B --&gt; C(Sort PERIODO_ACADEMICO: Ordena por PERIODO_ACADEMICO, ID_UNIDAD)\n    C --&gt; D(Ajustar Ancho Columnas: Deriva _PERIODO_ACADEMICO y _ID_UNIDAD)\n    D --&gt; E(Filtrar Registros Vac\u00edos: Elimina registros vac\u00edos)\n    E --&gt; F(Lookup DIM_PERIODO_ACADEMICO: Busca en DIM_PERIODO_ACADEMICO)\n    F --&gt; G(Guardar DIM_PERIODO_ACADEMICO: Carga a la tabla destino)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-flow-task","title":"Componente <code>Data Flow Task</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>El componente Data Flow Task tiene como prop\u00f3sito principal realizar la integraci\u00f3n, transformaci\u00f3n y carga de datos desde diversas fuentes hacia un destino final, aplicando transformaciones y validaciones requeridas para asegurar la calidad de los datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-de-los-componentes-del-flujo-de-datos","title":"Detalle de los Componentes del Flujo de Datos","text":"<ol> <li> <p>Combinar las tablas</p> <ul> <li>Descripci\u00f3n: Realiza una operaci\u00f3n de combinaci\u00f3n tipo JOIN entre dos conjuntos de datos. Se utiliza para consolidar datos en base a un campo clave.</li> <li>Propiedades:<ul> <li>Tipo de combinaci\u00f3n: <code>INNER JOIN</code>.</li> <li>N\u00famero de columnas clave: <code>1</code>.</li> <li>Manejo de nulos: Se trata como valores iguales.</li> <li>Buffers m\u00e1ximos por entrada: <code>5</code>.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada izquierda: Datos ordenados por <code>_NOMBRE_ESRTUDIANTE</code>.</li> <li>Entrada derecha: Datos ordenados por <code>NOMBRE_ESTUDIANTE</code>.</li> <li>Salida: Datos combinados con columnas provenientes de ambas entradas.</li> </ul> </li> </ul> </li> <li> <p>DIM_ESTUDIANTES PROCESADO</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla DIM_ESTUDIANTES para agregar informaci\u00f3n adicional a los registros actuales.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code>.</li> <li>Manejo de filas sin coincidencia: Se redirigen a una salida de error.</li> </ul> </li> <li>Conexiones:<ul> <li>Fuente de datos: OLE DB Connection Manager a DWH_COMFENALCO_Destino_OLEDB.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: <code>_DOCUMENTO</code>.</li> <li>Salida: <code>ID_ESTUDIANTE</code> mapeado desde la tabla de referencia.</li> </ul> </li> </ul> </li> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde una hoja de Excel para procesarlos en el flujo de datos.</li> <li>Propiedades:<ul> <li>Tabla/hoja: <code>Sheet1$</code>.</li> <li>Modo de acceso: Directo.</li> </ul> </li> <li>Conexiones:<ul> <li>Administrador de conexiones: OLE DB Connection Manager configurado para Excel.</li> </ul> </li> <li>Salidas:<ul> <li>Salida principal: Datos le\u00eddos con columnas como <code>PERIODO_ACADEMICO</code>, <code>JORNADA</code>, y <code>NOMBRE_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_NOTAS</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla FACT_NOTAS del destino de base de datos.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Cedesarrollo\".\"FACT_NOTAS\"</code>.</li> <li>Tama\u00f1o del lote: <code>0</code> (autom\u00e1tico).</li> <li>Uso de inserci\u00f3n masiva: Habilitado.</li> </ul> </li> <li>Conexiones:<ul> <li>Fuente: OLE DB Connection Manager configurado a DWH_COMFENALCO_Destino.</li> </ul> </li> <li>Entradas:<ul> <li>Datos combinados y enriquecidos con columnas como <code>PRIMER_CORTE</code>, <code>SEGUNDO_CORTE</code>, y <code>NOTA_FINAL</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_NOTAS</p> <ul> <li>Descripci\u00f3n: Valida si las notas ya existen en la tabla destino mediante un proceso de b\u00fasqueda.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_NOTAS] WHERE CURSO = ?</code>.</li> <li>Manejo de filas sin coincidencia: Redirige a una salida espec\u00edfica.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: Claves combinadas como <code>CURSO</code>, <code>ID_JORNADA</code>, y <code>ID_ESTUDIANTE</code>.</li> <li>Salida: Coincidencias y no coincidencias gestionadas separadamente.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_JORNADA</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_JORNADA</code> basado en el campo <code>JORNADA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Fuente: OLE DB Connection Manager.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: <code>JORNADA</code>.</li> <li>Salida: <code>ID_JORNADA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Recupera el <code>ID_PERIODO</code> usando el campo <code>PERIODO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code>.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: <code>PERIODO_ACADEMICO</code>.</li> <li>Salida: <code>ID_PERIODO</code>.</li> </ul> </li> </ul> </li> <li> <p>Sort NOMBRE_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Ordena los datos por el campo <code>_NOMBRE_ESRTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Elimina duplicados: No.</li> <li>Orden: Ascendente por <code>_NOMBRE_ESRTUDIANTE</code>.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: Datos procesados.</li> <li>Salida: Datos ordenados.</li> </ul> </li> </ul> </li> <li> <p>Sort _NOMBRE_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Similar al componente anterior, ordena los datos por el campo <code>_NOMBRE_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Elimina duplicados: No.</li> <li>Orden: Ascendente por <code>_NOMBRE_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n Columnas</p> <ul> <li>Descripci\u00f3n: Aplica transformaciones para generar columnas derivadas.</li> <li>Propiedades:<ul> <li>Agrega columnas como <code>_CURSO</code> y <code>_NOMBRE_DOCENTE</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    Excel[Excel Source 1] --&gt; Transformacion[Transformaci\u00f3n Columnas]\n    Transformacion --&gt; DIM_ESTUDIANTES[Lookup DIM_ESTUDIANTES]\n    DIM_ESTUDIANTES --&gt; CombinarTablas[Combinar las tablas]\n    CombinarTablas --&gt; Sort1[Sort NOMBRE_ESTUDIANTE]\n    Sort1 --&gt; LookupPERIODO[Lookup ID_PERIODO]\n    Sort1 --&gt; LookupJORNADA[Lookup ID_JORNADA]\n    LookupPERIODO --&gt; Guardar[Guardar FACT_NOTAS]\n    LookupJORNADA --&gt; Guardar\n    Sort1 --&gt; Guardar\n    _NOMBRE_ESTUDIANTE[Sort _NOMBRE_ESTUDIANTE] --&gt; Guardar</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_facturacion","title":"FACT_FACTURACION","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-cede_ingresos","title":"Componente <code>Tarea cede_Ingresos</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>El componente Tarea cede_Ingresos es un proceso ejecutado externamente que utiliza un script Python para descargar y procesar datos de ingresos relacionados con el proyecto COMFENALCO_EDUCACION. Este componente permite la integraci\u00f3n de datos externos al flujo de trabajo de SSIS, automatizando la adquisici\u00f3n de informaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-componente","title":"Detalle del Componente","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python externo para procesar datos de ingresos. Este script interact\u00faa con un servicio o base de datos externa, descargando y preparando la informaci\u00f3n para el an\u00e1lisis posterior.</li> <li>Propiedades:<ul> <li>Script ejecutado: <code>download.py</code>.</li> <li>Par\u00e1metro pasado: <code>--key cede_Ingresos</code>.</li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Utiliza las variables del proyecto:<ul> <li>Python_Executable: Ruta del ejecutable de Python.</li> <li>Working_Directory: Ruta del directorio base del proyecto.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea cede_Ingresos\n    participant Python as Script Python\n\n    SSIS -&gt;&gt; Python: Ejecutar `download.py --key cede_Ingresos`\n    Python -&gt;&gt; Python: Descargar y procesar datos de ingresos\n    Python -&gt;&gt; SSIS: Retornar datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-06-archivos-manuales","title":"Componente <code>Tarea EP-EPT-06 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EPT-06 (archivos manuales) es una tarea de ejecuci\u00f3n de proceso dise\u00f1ada para procesar datos de manera manual a trav\u00e9s de un script Python. Este componente forma parte del flujo de trabajo de FACT_FACTURACION, permitiendo la obtenci\u00f3n de informaci\u00f3n espec\u00edfica asociada con el identificador EPEPT06.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-componente_1","title":"Detalle del Componente","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python para procesar archivos manuales relacionados con el proyecto. Esta tarea es esencial para integrar datos que requieren intervenci\u00f3n manual antes de su inclusi\u00f3n en el flujo automatizado.</li> <li>Propiedades:<ul> <li>Script ejecutado: <code>download.py</code>.</li> <li>Par\u00e1metro pasado: <code>--key EPEPT06</code>.</li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Utiliza las variables del proyecto:<ul> <li>Python_Executable: Ruta del ejecutable de Python.</li> <li>Working_Directory: Ruta del directorio base del proyecto.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea EP-EPT-06\n    participant Python as Script Python\n\n    SSIS -&gt;&gt; Python: Ejecutar `download.py --key EPEPT06`\n    Python -&gt;&gt; Python: Procesar archivos manuales asociados\n    Python -&gt;&gt; SSIS: Retornar resultados procesados</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-fact_facturacion","title":"Componente <code>Tarea fact_facturacion</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_24","title":"Descripci\u00f3n General","text":"<p>El componente Tarea fact_facturacion es una tarea de ejecuci\u00f3n de proceso utilizada para automatizar el procesamiento de datos de facturaci\u00f3n mediante un script Python. Este componente forma parte del flujo de trabajo de FACT_FACTURACION, desempe\u00f1ando un rol crucial en la generaci\u00f3n de reportes y el manejo de datos relacionados con la facturaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-componente_2","title":"Detalle del Componente","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python encargado del procesamiento de la informaci\u00f3n de facturaci\u00f3n.</li> <li>Propiedades:<ul> <li>Script ejecutado: <code>fact_facturacion.py</code>.</li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Utiliza las variables del proyecto:<ul> <li>Python_Executable: Ruta del ejecutable de Python.</li> <li>Working_Directory: Ruta del directorio base del proyecto.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_11","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea fact_facturacion\n    participant Python as Script Python\n\n    SSIS -&gt;&gt; Python: Ejecutar `fact_facturacion.py`\n    Python -&gt;&gt; Python: Procesar datos de facturaci\u00f3n\n    Python -&gt;&gt; SSIS: Retornar resultados procesados</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-fact_facturacion","title":"Componente <code>Data FACT_FACTURACION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_25","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data FACT_FACTURACION se encarga de extraer, transformar y cargar informaci\u00f3n relacionada con la facturaci\u00f3n. Este componente integra datos provenientes de un archivo Excel (EP-EPT-06) y realiza las siguientes operaciones:</p> <ol> <li>Data Conversion: Convierte el tipo de datos de la columna FUENTE_RECURSOS del flujo de entrada (proveniente del Excel) a un formato de cadena de longitud 40.  </li> <li>Derived Column Transformation: Crea columnas derivadas mediante expresiones. Entre las columnas generadas se encuentran:  <ul> <li>_DOCUMENTO_PAGO: Convierte el valor de DOCUMENTO_PAGO a una cadena de 20 caracteres.  </li> <li>ID_FECHA: Calcula un identificador num\u00e9rico basado en la fecha contable, combinando a\u00f1o, mes y d\u00eda.  </li> <li>_CONCEPTO: Genera una versi\u00f3n en cadena (longitud 255) del campo CONCEPTO.  </li> <li>_ID_CONCEPTO: Convierte el campo ID_CONCEPTO a entero.  </li> <li>_TIPO_DOCUMENTO: Convierte TIPO_DOCUMENTO_PAGO a una cadena de 40 caracteres.  </li> <li>_NO_RECIBO: Convierte NO_RECIBO a una cadena de 40 caracteres.  </li> <li>_ANIO_CONTABLE: Deriva el a\u00f1o de FECHA_CONTABLE en formato cadena (40 caracteres).  </li> </ul> </li> <li>Lookup Transformations:  <ul> <li>Se ejecuta un primer Lookup que, mediante la combinaci\u00f3n de los campos NO_RECIBO y la versi\u00f3n derivada de DOCUMENTO_PAGO, consulta la tabla FACT_FACTURACION para determinar si existen registros previos (para evitar duplicados).  </li> <li>Se utilizan dos Lookups consecutivos: el primero consulta la tabla destino mediante una expresi\u00f3n SQL sin par\u00e1metros y el segundo utiliza par\u00e1metros para comparar NO_RECIBO y DOCUMENTO_PAGO.</li> </ul> </li> <li>Destino ADO.NET: Finalmente, el flujo carga los datos transformados y validados en la tabla de destino FACT_FACTURACION. Entre las columnas de destino se encuentran:  <ul> <li>FECHA_CONTABLE, VALOR_FACTURADO, VALOR_PAGADO, ID_FECHA, TIPO_DOCUMENTO_PAGO, DOCUMENTO_PAGO, CAJERO, ID_CONCEPTO, CONCEPTO, NO_RECIBO, ID_TARIFA, ID_CATEGORIA y FUENTE_RECURSOS.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-proceso","title":"Diagrama de Proceso","text":"<p>El siguiente diagrama de proceso describe de forma resumida el flujo de datos de Data FACT_FACTURACION:</p> <pre><code>flowchart TD\n    A[EP-EPT-06: Fuente Excel] --&gt; B[Data Conversion: Convertir FUENTE_RECURSOS]\n    B --&gt; C[Derived Column: Crear columnas derivadas]\n    C --&gt; D[Lookup 1: Consulta FACT_FACTURACION por NO_RECIBO y DOCUMENTO_PAGO]\n    D --&gt; E[Lookup 1 1: Consulta adicional para obtener ID_CATEGORIA]\n    E --&gt; F[Destino ADO.NET: Insertar datos en FACT_FACTURACION]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-de-componentes","title":"Detalle de Componentes","text":"<ol> <li> <p>Data Conversion </p> <ul> <li>Entrada: Columna FUENTE_RECURSOS (tipo cadena, 255 caracteres) proveniente del Excel.  </li> <li>Salida: Columna convertida denominada Copy of FUENTE_RECURSOS con tipo cadena y longitud 40.</li> </ul> </li> <li> <p>Derived Column Transformation </p> <ul> <li>Operaciones:<ul> <li>_DOCUMENTO_PAGO: Convierte DOCUMENTO_PAGO a DT_WSTR(20).</li> <li>ID_FECHA: Calcula (YEAR(FECHA_CONTABLE) * 10000 + MONTH(FECHA_CONTABLE) * 100 + DAY(FECHA_CONTABLE)).</li> <li>_CONCEPTO, _ID_CONCEPTO, _TIPO_DOCUMENTO, _NO_RECIBO y _ANIO_CONTABLE: Se generan mediante expresiones que formatean y convierten los valores extra\u00eddos.</li> </ul> </li> </ul> </li> <li> <p>Lookup 1 y Lookup 1 1 </p> <ul> <li>Lookup 1: Realiza una consulta que une registros de la salida del Derived Column con la tabla FACT_FACTURACION.  </li> <li>Lookup 1 1: Complementa la b\u00fasqueda utilizando par\u00e1metros basados en CONCEPTO, ANIO_CONTABLE y el resultado del primer Lookup para obtener el ID_TARIFA y validar la categor\u00eda.</li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Acci\u00f3n: Inserta el conjunto final de datos en la tabla FACT_FACTURACION utilizando una inserci\u00f3n masiva para optimizar el rendimiento.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>EP-EPT-06 (Excel Source)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code>.</li> <li>Columnas extra\u00eddas:     <code>NO_RECIBO</code>, <code>FECHA_CONTABLE</code>, <code>PAGADO_POR</code>, <code>TIPO_DOCUMENTO_PAGO</code>, <code>DOCUMENTO_PAGO</code>, <code>CAJERO</code>, <code>ID_CONCEPTO</code>, <code>CONCEPTO</code>, <code>VALOR_FACTURADO</code>, <code>NOMBRE</code>, <code>VALOR_1</code>, <code>VALOR_PAGADO</code>.</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Crea columnas derivadas mediante expresiones para transformar datos existentes.</li> <li>Columnas derivadas:<ul> <li>_DOCUMENTO_PAGO: <code>(DT_WSTR,20)DOCUMENTO_PAGO</code>.</li> <li>ID_FECHA: <code>(DT_I4)(YEAR(FECHA_CONTABLE) * 10000 + MONTH(FECHA_CONTABLE) * 100 + DAY(FECHA_CONTABLE))</code>.</li> <li>_CONCEPTO: <code>(DT_WSTR,255)CONCEPTO</code>.</li> <li>_ID_CONCEPTO: <code>(DT_I4)ID_CONCEPTO</code>.</li> <li>_TIPO_DOCUMENTO: <code>(DT_WSTR,40)TIPO_DOCUMENTO_PAGO</code>.</li> <li>_NO_RECIBO: <code>(DT_WSTR,40)NO_RECIBO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Busca y asocia datos desde la tabla FACT_FACTURACION.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_FACTURACION]</code>.</li> <li>Condiciones de uni\u00f3n:<ul> <li><code>NO_RECIBO</code> con <code>NO_RECIBO</code>.</li> <li><code>_DOCUMENTO_PAGO</code> con <code>DOCUMENTO_PAGO</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla de destino en la base de datos.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_FACTURACION\"</code>.</li> <li>Inserci\u00f3n masiva habilitada: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_12","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(EP-EPT-06: Fuente Excel) --&gt; B(Derived Column: Transformaciones)\n    B --&gt; C(Lookup: Buscar en FACT_FACTURACION)\n    C --&gt; D(Destino de ADO NET: Cargar datos en FACT_FACTURACION)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_horario","title":"FACT_HORARIO","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-04-achivos-manuales","title":"Componente <code>Tarea EP-EPT-04 (achivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_26","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-04 (achivos manuales) es un proceso externo que se ejecuta mediante un script de Python. Su funci\u00f3n es descargar de forma manual los archivos necesarios para el procesamiento de datos de horarios acad\u00e9micos. Esta tarea forma parte del flujo de integraci\u00f3n de FACT_HORARIO y permite que los datos descargados est\u00e9n disponibles en el entorno de trabajo para etapas posteriores del proceso ETL.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-la-tarea","title":"Propiedades de la Tarea","text":"<ul> <li>Tipo de Tarea: Ejecutar proceso externo.</li> <li> <p>Ejecutable:   La ruta se configura mediante la variable del proyecto: <code>@[$Project::Python_Executable]</code>   En este caso, la ruta real es: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Argumentos: <code>download.py --key EPEPT04</code></p> </li> <li> <p>Directorio de Trabajo:   Se configura mediante la variable: <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code></p> </li> <li> <p>Configuraciones Adicionales:</p> <ul> <li>La tarea utiliza un filtro de registro (LoggingOptions) configurado con <code>FilterKind=0</code>.</li> <li>El valor de <code>ThreadHint</code> se establece en <code>0</code> para indicar que no se sugiere un n\u00famero espec\u00edfico de hilos.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-proceso_1","title":"Diagrama de Proceso","text":"<p>El siguiente diagrama de proceso describe la ejecuci\u00f3n de la tarea:</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta download.py --key EPEPT04\n    Python -&gt;&gt; Python: Descarga archivos manuales para FACT_HORARIO\n    Python -&gt;&gt; SSIS: Retorna resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_horario","title":"Componente <code>Procesar FACT_HORARIO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_27","title":"Descripci\u00f3n General","text":"<p>Este paquete SSIS tiene como objetivo procesar los datos relacionados con horarios acad\u00e9micos. Incluye m\u00faltiples transformaciones para extraer, transformar y cargar datos (ETL) desde archivos de Excel hacia una base de datos compatible con ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source </p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel.  </li> <li>Propiedades:  <ul> <li>Nombre de hoja: <code>'EP-EPT-04$'</code> </li> <li>Timeout del comando: <code>0</code> (sin l\u00edmite).  </li> <li>AccessMode: <code>0</code> (modo directo).  </li> </ul> </li> <li>Conexiones: OleDbConnection.  </li> <li>Columnas de salida:  <ul> <li><code>MODULO</code>, <code>PERIODO ACADEMICO</code>, <code>PROGRAMA</code>, <code>JORNADA</code>, <code>SEMESTRE</code>, etc.  </li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PROGRAMA </p> <ul> <li>Descripci\u00f3n: Asocia datos del m\u00f3dulo con su respectivo programa.  </li> <li>Propiedades:  <ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PLAN_CURRICULAR] WHERE MODULO = ?</code> </li> <li>Tipo de cach\u00e9: <code>Completa</code>.  </li> </ul> </li> <li>Conexi\u00f3n: OleDbConnection.  </li> <li>Columnas de entrada: <code>MODULO</code>.  </li> <li>Columnas de salida: <code>ID_PROGRAMA</code>, <code>ID_MODULO</code>.  </li> </ul> </li> <li> <p>Join Tablas </p> <ul> <li>Descripci\u00f3n: Une dos flujos de datos ordenados.  </li> <li>Propiedades:  <ul> <li>Tipo de uni\u00f3n: <code>INNER</code>.  </li> <li>Columnas clave: <code>SEMESTRE</code>, <code>GRUPO</code>.  </li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas </p> <ul> <li>Descripci\u00f3n: Aplica transformaciones derivadas a las columnas.  </li> <li>Columnas de salida:  <ul> <li><code>NOMBRE_DOCENTE</code>: <code>(DT_WSTR,200)_DOCENTE</code>.  </li> <li><code>HORA_FIN</code>: <code>(DT_WSTR,40)FIN</code>.  </li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_HORARIO </p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_HORARIO</code>.  </li> <li>Propiedades:  <ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_HORARIO\"</code>.  </li> <li>Tama\u00f1o de lotes: <code>0</code>.  </li> </ul> </li> <li>Columnas de entrada: <code>GRUPO</code>, <code>ID_MODULO</code>, <code>ID_PERIODO</code>, <code>NOMBRE_DOCENTE</code>, etc.  </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_13","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Excel Source\n    participant Lookup as Lookup ID_PROGRAMA\n    participant Join as Join Tablas\n    participant Transform as Transformar Columnas\n    participant Save as Guardar FACT_HORARIO\n\n    Excel -&gt;&gt; Lookup: Env\u00eda datos (MODULO)\n    Lookup -&gt;&gt; Join: Devuelve ID_PROGRAMA\n    Join -&gt;&gt; Transform: Realiza uni\u00f3n\n    Transform -&gt;&gt; Save: Transformaciones derivadas\n    Save -&gt;&gt; DB: Inserta datos en FACT_HORARIO</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_ausentismo_docente","title":"FACT_AUSENTISMO_DOCENTE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-edf-02-achivos-manuales","title":"Componente Tarea EP-EDF-02 (achivos manuales)","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_28","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EDF-02 (achivos manuales) ejecuta un proceso externo mediante un script de Python. Este script est\u00e1 dise\u00f1ado para descargar y preparar datos manuales asociados al archivo identificado como EP-EDF-02.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-componente","title":"Detalles del Componente","text":"<p>Propiedades</p> <ul> <li>Tipo de Tarea: Ejecutar proceso externo.</li> <li>Ruta del Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> <li>Argumentos:<ul> <li><code>download.py --key EPEDF02</code>.</li> </ul> </li> <li>Directorio de Trabajo:<ul> <li><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> </ul> </li> </ul> <p>Variables Utilizadas</p> <ul> <li>@[$Project::Python_Executable]: Ruta al ejecutable de Python.</li> <li>@[$Project::Working_Directory]: Ruta base del directorio de trabajo.</li> </ul> <p>Descripci\u00f3n del Script</p> <ul> <li>Script: <code>download.py</code>.</li> <li>Argumento Principal: <code>--key EPEDF02</code>, utilizado para identificar el archivo espec\u00edfico a procesar.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_14","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEDF02`\n    Python -&gt;&gt; Python: Descarga datos correspondientes a EPEDF02\n    Python -&gt;&gt; SSIS: Finaliza ejecuci\u00f3n del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_ausentismo_docente","title":"Componente <code>Procesar FACT_AUSENTISMO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_29","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_AUSENTISMO_DOCENTE gestiona el flujo de datos para la extracci\u00f3n, transformaci\u00f3n y carga de informaci\u00f3n sobre ausentismo docente. Inicia con la lectura de un archivo Excel, realiza transformaciones en columnas, utiliza b\u00fasquedas en tablas relacionadas y finalmente carga los datos transformados en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel EP-EDF-02 (Excel Source)</p> <ul> <li>Descripci\u00f3n: Extrae datos de un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code>.</li> <li>Columnas extra\u00eddas:     <code>PERIODO_ACADEMICO</code>, <code>FECHA</code>, <code>NOMBRE_DOCENTE</code>, <code>CARGO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>, <code>AUSENCIA_HORAS</code>, <code>AUSENCIA_DIAS</code>, <code>TIPO_AUSENCIA</code>, <code>PERMISO</code>, <code>MOTIVO_AUSENCIA</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformacion de Columnas</p> <ul> <li>Descripci\u00f3n: Realiza transformaciones para crear nuevas columnas derivadas.</li> <li>Columnas derivadas:<ul> <li>_PERIODO: <code>(DT_WSTR,40)PERIODO_ACADEMICO</code>.</li> <li>ID_FECHA: <code>[REPLACE]([REPLACE]([REPLACE](FECHA,\"-\",\"\"),\"/\",\"\"),\".\",\"\")</code>.</li> <li>_MOTIVO_AUSENCIA: <code>(DT_WSTR,40)MOTIVO_AUSENCIA</code>.</li> <li>_FECHA: <code>(DT_DATE)FECHA</code>.</li> <li>_DOCENTE: <code>(DT_WSTR,200)NOMBRE_DOCENTE</code>.</li> <li>_CARGO: <code>(DT_WSTR,40)CARGO</code>.</li> <li>_INICIO: <code>(DT_DATE)FECHA_INICIO</code>.</li> <li>_FIN: <code>(DT_DATE)FECHA_FIN</code>.</li> <li>_HORAS: <code>(DT_WSTR,40)AUSENCIA_HORAS</code>.</li> <li>_DIAS: <code>(DT_WSTR,40)AUSENCIA_DIAS</code>.</li> <li>_TIPO: <code>(DT_WSTR,40)TIPO_AUSENCIA</code>.</li> <li>_PERMISO: <code>(DT_WSTR,40)PERMISO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Busca el ID del periodo acad\u00e9mico en la tabla DIM_PERIODO_ACADEMICO.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code>.</li> <li>Condiciones de uni\u00f3n:<ul> <li><code>_PERIODO</code> con <code>PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Columna _ID_FECHA</p> <ul> <li>Descripci\u00f3n: Convierte el valor de ID_FECHA a tipo entero.</li> <li>Propiedades:<ul> <li>Expresi\u00f3n: <code>(DT_I4)ID_FECHA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_AUSENTISMO_DOCENTE</p> <ul> <li>Descripci\u00f3n: Busca datos en la tabla de destino para determinar registros existentes.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]</code>.</li> <li>Condiciones de uni\u00f3n:<ul> <li><code>_DOCENTE</code> con <code>NOMBRE_DOCENTE</code>.</li> <li><code>ID_PERIODO</code> con <code>ID_PERIODO</code>.</li> <li><code>_ID_FECHA</code> con <code>ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_AUSENTISMO_DOCENTE</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla destino.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_AUSENTISMO_DOCENTE\"</code>.</li> <li>Inserci\u00f3n masiva habilitada: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_15","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(EP-EDF-02: Fuente Excel) --&gt; B(Transformacion de Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Columna _ID_FECHA)\n    D --&gt; E(Lookup FACT_AUSENTISMO_DOCENTE)\n    E --&gt; F(Guardar FACT_AUSENTISMO_DOCENTE)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_permiso_estudiante","title":"FACT_PERMISO_ESTUDIANTE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-edf-04-achivos-manuales","title":"Componente <code>Tarea EP-EDF-04 (achivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_30","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EDF-04 (achivos manuales) ejecuta un proceso externo mediante un script de Python. Este script est\u00e1 dise\u00f1ado para descargar y procesar datos manuales relacionados con el archivo identificado como EP-EDF-04.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-componente_1","title":"Detalles del Componente","text":"<p>Propiedades</p> <ul> <li>Tipo de Tarea: Ejecutar proceso externo.</li> <li>Ruta del Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> <li>Argumentos:<ul> <li><code>download.py --key EPEDF04</code>.</li> </ul> </li> <li>Directorio de Trabajo:<ul> <li><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> </ul> </li> </ul> <p>Variables Utilizadas</p> <ul> <li>@[$Project::Python_Executable]: Ruta al ejecutable de Python.</li> <li>@[$Project::Working_Directory]: Ruta base del directorio de trabajo.</li> </ul> <p>Descripci\u00f3n del Script</p> <ul> <li>Script: <code>download.py</code>.</li> <li>Argumento Principal: <code>--key EPEDF04</code>, utilizado para identificar el archivo espec\u00edfico a procesar.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_16","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEDF04`\n    Python -&gt;&gt; Python: Descarga datos correspondientes a EPEDF04\n    Python -&gt;&gt; SSIS: Reporta resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_permiso_estudiante","title":"Componente <code>Procesar FACT_PERMISO_ESTUDIANTE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_31","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_PERMISO_ESTUDIANTE extrae datos de un archivo Excel (<code>EP-EDF-04</code>), transforma y enriquece los datos utilizando varias transformaciones, y finalmente los carga en una tabla destino en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_9","title":"Componentes del Flujo de Datos","text":"<p>1. Excel Source (EP-EDF-04)</p> <ul> <li>Descripci\u00f3n: Carga datos desde el archivo Excel asociado a la hoja <code>Sheet1$</code>.</li> <li>Propiedades:<ul> <li>Timeout de Comando: <code>0</code> (sin l\u00edmite).</li> <li>Modo de Acceso: <code>OpenRowset</code>.</li> </ul> </li> <li>Columnas Procesadas:   <code>PERIODO ACADEMICO</code>, <code>DOC_ESTUDIANTE</code>, <code>MODULO</code>, <code>FECHA</code>, <code>HORA</code>, <code>MOTIVO_AUSENCIA</code>, <code>SOPORTE_AUSENCIA</code>.</li> </ul> <p>2. Transformar Columnas</p> <ul> <li>Descripci\u00f3n: Aplica transformaciones para crear nuevas columnas y enriquecer los datos.</li> <li>Columnas Derivadas:<ul> <li><code>_PERIODO</code>: Transformaci\u00f3n de <code>PERIODO ACADEMICO</code>.</li> <li><code>DOCUMENTO</code>: Transformaci\u00f3n de <code>DOC_ESTUDIANTE</code>.</li> <li><code>_MODULO</code>: Transformaci\u00f3n de <code>MODULO</code>.</li> <li><code>ID_FECHA</code>: Deriva un identificador de fecha.</li> <li><code>_FECHA</code>: Conversi\u00f3n a formato de fecha.</li> <li><code>_HORA</code>, <code>_MOTIVO_AUSENCIA</code>, <code>_SOPORTE_AUSENCIA</code>.</li> </ul> </li> </ul> <p>3. Lookup ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Enlaza informaci\u00f3n de la tabla <code>DIM_PERIODO_ACADEMICO</code> para identificar el ID del periodo acad\u00e9mico.</li> <li>Consulta SQL:   <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\nWHERE [PERIODO_ACADEMICO] = ?\n</code></pre></li> <li>Salida:     <code>ID_PERIODO</code>.</li> </ul> <p>4. Lookup ID_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Consulta la tabla <code>DIM_ESTUDIANTES</code> para obtener el ID del estudiante basado en su documento.</li> <li>Consulta SQL:   <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_ESTUDIANTES]\nWHERE [DOCUMENTO] = ?\n</code></pre></li> <li>Salida:   <code>ID_ESTUDIANTE</code>.</li> </ul> <p>5. Lookup FACT_PERMISO_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Verifica si existe un permiso para el estudiante en la tabla <code>FACT_PERMISO_ESTUDIANTE</code> utilizando m\u00faltiples claves.</li> <li>Consulta SQL:   <pre><code>SELECT * \nFROM [Cedesarrollo].[FACT_PERMISO_ESTUDIANTE]\nWHERE [ID_FECHA] = ? \n  AND [ID_PERIODO] = ? \n  AND [ID_ESTUDIANTE] = ?\n</code></pre></li> </ul> <p>6. Destino ADO.NET (Guardar FACT_PERMISO_ESTUDIANTE)</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>FACT_PERMISO_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Tabla Destino: <code>\"Cedesarrollo\".\"FACT_PERMISO_ESTUDIANTE\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (ajustado al tama\u00f1o del buffer).</li> <li>Timeout de Comando: <code>30</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_17","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant DB as SQL Server Database\n\n    SSIS -&gt;&gt; Excel: Carga datos de EP-EDF-04\n    Excel -&gt;&gt; SSIS: Env\u00eda datos al flujo\n    SSIS -&gt;&gt; DB: Consulta ID_PERIODO desde DIM_PERIODO_ACADEMICO\n    SSIS -&gt;&gt; DB: Consulta ID_ESTUDIANTE desde DIM_ESTUDIANTES\n    SSIS -&gt;&gt; DB: Verifica datos en FACT_PERMISO_ESTUDIANTE\n    SSIS -&gt;&gt; DB: Inserta datos en FACT_PERMISO_ESTUDIANTE</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#dim_preguntas_cotizacion","title":"DIM_PREGUNTAS_COTIZACION","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-12-archivos-manuales","title":"Componente <code>Tarea EP-EPT-12 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_32","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EPT-12 (archivos manuales) utiliza el componente Execute Process Task para ejecutar un script Python que descarga datos asociados con la clave <code>EPEPT12</code>.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-configuracion","title":"Propiedades de Configuraci\u00f3n","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python ubicado en el entorno de trabajo para descargar datos.</li> <li>Archivo Ejecutable: <code>python.exe</code> del entorno virtual en:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos:   <pre><code>download.py --key EPEPT12\n</code></pre></li> <li>Directorio de Trabajo:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_18","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT12`\n    Python -&gt;&gt; Python: Descarga datos asociados a la clave\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-valor-nulo-por-defecto","title":"Componente <code>Valor nulo por defecto</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_33","title":"Descripci\u00f3n General","text":"<p>El componente Valor nulo por defecto es una tarea de ejecuci\u00f3n SQL en SSIS que se utiliza para garantizar que exista un registro por defecto en la tabla de dimensi\u00f3n DIM_PREGUNTAS_COTIZACION. En concreto, verifica si ya existe un registro con ID_PREGUNTAS igual a -1. Si no existe, inserta un registro con los siguientes valores: - ID_PREGUNTAS: -1 - PREGUNTA: \"PREGUNTA_NO_IDENTIFICADA\" - OBSERVACIONES: \"SIN_OBSERVACIONES\"</p> <p>Este registro se utiliza para representar valores nulos o no identificados en el proceso de carga de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_3","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Ejecutar SQL (Execute SQL Task)</li> <li>Conexi\u00f3n: Se utiliza el administrador de conexiones con ID <code>{C2A27DDB-56C2-4889-8A4B-7AA7124DFFD7}</code> para conectarse al servidor de destino.</li> <li>Script SQL:   <pre><code>-- Verificar si ya existe el registro con ID_PREGUNTA -1\nIF NOT EXISTS (SELECT 1 FROM [DWH_COMFENALCO].[Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] WHERE ID_PREGUNTAS = -1)\nBEGIN\n    -- Insertar -1 para preguntas de cotizaciones\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] ON;\n    INSERT INTO [DWH_COMFENALCO].[Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] (ID_PREGUNTAS, PREGUNTA, OBSERVACIONES)\n    VALUES (-1, 'PREGUNTA_NO_IDENTIFICADA', 'SIN_OBSERVACIONES');\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] OFF;\nEND;\n</code></pre></li> <li>Tiempo de Espera y Otras Opciones: Se utilizan las configuraciones predeterminadas para la tarea SQL.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-proceso_2","title":"Diagrama de Proceso","text":"<p>El siguiente diagrama ilustra el proceso que ejecuta este componente:</p> <pre><code>sequenceDiagram\n    SSIS Package -&gt;&gt; SQL Server: Ejecuta la tarea SQL\n    SQL Server --&gt;&gt; SQL Server: Verifica existencia de registro con ID_PREGUNTAS = -1\n    alt Registro no existe\n        SQL Server -&gt;&gt; SQL Server: Inserta registro por defecto\n    else Registro ya existe\n        SQL Server -&gt;&gt; SQL Server: No realiza acci\u00f3n\n    end\n    SQL Server --&gt;&gt; SSIS Package: Retorna resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_evaluacion_formacion","title":"Componente <code>Procesar FACT_EVALUACION_FORMACION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_34","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_EVALUACION_FORMACION tiene como prop\u00f3sito extraer, transformar y cargar datos relacionados con las preguntas de cotizaci\u00f3n en la tabla destino DIM_PREGUNTAS_COTIZACION. Utiliza un archivo Excel como fuente y realiza transformaciones y validaciones antes de insertar los datos en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_10","title":"Componentes del Flujo de Datos","text":"<p>1. Componente EP-EPT-12 (Fuente Excel)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel en la hoja <code>Sheet1$</code>.</li> <li>Propiedades:<ul> <li>Conexi\u00f3n: Administrador de conexiones con Excel.</li> <li>Columnas de salida:<ul> <li><code>PREGUNTA</code>: Texto relacionado con las preguntas de cotizaci\u00f3n.</li> <li><code>OBSERVACIONES</code>: Comentarios u observaciones adicionales.</li> </ul> </li> </ul> </li> </ul> <p>2. Transformaci\u00f3n de Columnas</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas de las existentes o las formatea seg\u00fan sea necesario.</li> <li>Columnas de salida:<ul> <li><code>_PREGUNTA</code>: Conversi\u00f3n de <code>PREGUNTA</code> al formato <code>DT_WSTR</code> con una longitud de 200.</li> <li><code>_OBSERVACIONES</code>: Conversi\u00f3n de <code>OBSERVACIONES</code> al formato <code>DT_WSTR</code> con una longitud de 200.</li> </ul> </li> </ul> <p>3. Lookup</p> <ul> <li>Descripci\u00f3n: Verifica si las preguntas ya existen en la tabla destino para evitar duplicados.</li> <li>Fuente de referencia: Tabla DIM_PREGUNTAS_COTIZACION.</li> <li>Propiedades:<ul> <li>SQL de b\u00fasqueda:      <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PREGUNTAS_COTIZACION]\n</code></pre></li> <li>Comportamiento en caso de no coincidencias: Enviar filas al siguiente paso.</li> </ul> </li> </ul> <p>4. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta datos nuevos en la tabla DIM_PREGUNTAS_COTIZACION.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_PREGUNTAS_COTIZACION\"</code>.</li> <li>Conexi\u00f3n: Administrador de conexiones con ADO.NET.</li> <li>Columnas cargadas:<ul> <li><code>PREGUNTA</code>.</li> <li><code>OBSERVACIONES</code>.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_19","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Fuente Excel\n    participant SSIS as Flujo de Datos\n    participant DB as Base de Datos\n\n    Excel -&gt;&gt; SSIS: Extrae datos (PREGUNTA, OBSERVACIONES)\n    SSIS -&gt;&gt; SSIS: Aplica transformaciones (_PREGUNTA, _OBSERVACIONES)\n    SSIS -&gt;&gt; DB: Verifica duplicados (Lookup)\n    SSIS -&gt;&gt; DB: Inserta datos nuevos</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_plan_cobertura","title":"FACT_PLAN_COBERTURA","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-07-archivos-manuales","title":"Componente <code>Tarea EP-EPT-07 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_35","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EPT-07 (archivos manuales) ejecuta un proceso externo mediante un script de Python. Su prop\u00f3sito es descargar los datos relacionados con el plan de cobertura, proces\u00e1ndolos desde un archivo externo y prepar\u00e1ndolos para su integraci\u00f3n en el flujo de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo","title":"Componentes del Flujo","text":"<p>1. Ejecutar Proceso (EP-EPT-07)</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python ubicado en el directorio de trabajo para descargar los datos correspondientes.</li> <li>Propiedades:</li> <li>Archivo ejecutable:     <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos del script:     <pre><code>download.py --key EPEPT07\n</code></pre></li> <li>Directorio de trabajo:     <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> <li>Propiedades din\u00e1micas:<ul> <li><code>Executable</code>: @[$Project::Python_Executable]</li> <li><code>WorkingDirectory</code>: @[$Project::Working_Directory] + \"\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\"</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_20","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT07`\n    Python -&gt;&gt; Python: Descarga datos de Plan de Cobertura\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_plan_cobertura","title":"Componente <code>Procesar FACT_PLAN_COBERTURA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_36","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_PLAN_COBERTURA permite extraer, transformar y cargar (ETL) datos relacionados con el plan de cobertura. Utiliza varias transformaciones y b\u00fasquedas para preparar los datos antes de almacenarlos en el destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_11","title":"Componentes del Flujo de Datos","text":"<p>1. Fuente de Excel (EP-EPT-07)</p> <ul> <li>Descripci\u00f3n: Extrae datos de una hoja de c\u00e1lculo de Excel.</li> <li>Propiedades:<ul> <li>Nombre del objeto de base de datos: <code>Sheet1$</code></li> <li>Conexi\u00f3n: Administrador de conexiones con Excel 17</li> <li>Columnas de salida: <code>,UNIDAD,MODALIDAD,CATEGOR\u00cdA,USOS_PROYECTADOS,USUARIOS_PROYECTADOS,PERIODO_ACADEMICO,PROGRAMA</code></li> </ul> </li> </ul> <p>2. Columna Derivada</p> <ul> <li>Descripci\u00f3n: Genera una nueva columna <code>_PERIODO</code> basada en la columna <code>PERIODO ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Expresi\u00f3n derivada: <code>(DT_WSTR,40)[PERIODO ACADEMICO]</code></li> <li>Columna de salida: <code>_PERIODO</code></li> </ul> </li> </ul> <p>3. B\u00fasqueda de ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_PERIODO_ACADEMICO</code> para obtener el ID del per\u00edodo acad\u00e9mico asociado.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\nWHERE [PERIODO_ACADEMICO] = ?\n</code></pre></li> <li>Columnas relacionadas:<ul> <li>Entrada: <code>_PERIODO</code></li> <li>Salida: <code>ID_PERIODO</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_21","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Fuente de Excel\n    participant SQL as SQL Lookup\n\n    SSIS -&gt;&gt; Excel: Extrae datos desde \"Sheet1$\"\n    Excel -&gt;&gt; SSIS: Env\u00eda datos transformados\n    SSIS -&gt;&gt; SQL: Realiza b\u00fasqueda en \"DIM_PERIODO_ACADEMICO\"\n    SQL -&gt;&gt; SSIS: Retorna ID_PERIODO</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_desempenho_docente_de","title":"FACT_DESEMPENHO_DOCENTE_DE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-08-archivos-manuales","title":"Componente <code>Tarea EP-EPT-08 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_37","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-08 es un componente de tipo <code>Execute Process Task</code> que ejecuta un script de Python para descargar datos necesarios en el flujo de trabajo del paquete SSIS. El script se ejecuta utilizando un entorno virtual Python previamente configurado.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_4","title":"Propiedades del Componente","text":"<ul> <li>Ruta del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos: <code>download.py --key EPEPT08</code></li> <li>Directorio de trabajo:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_22","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT08`\n    Python -&gt;&gt; Python: Descarga datos\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_desempenho_docente_de","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE_DE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_38","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_DESEMPENHO_DOCENTE_DE es responsable de la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de los datos de evaluaci\u00f3n de desempe\u00f1o docente en la base de datos destino <code>Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE</code>. Incluye transformaciones para derivar columnas, realizar b\u00fasquedas en tablas relacionadas y cargar los datos procesados en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_12","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source (EP-EPT-08) </p> <ul> <li>Descripci\u00f3n: Extrae datos de una hoja de c\u00e1lculo Excel denominada <code>Sheet1$</code>.</li> <li>Propiedades:  <ul> <li>Nombre de la tabla u objeto: <code>Sheet1$</code>.  </li> <li>Conexi\u00f3n: Administrador de conexiones Excel 18.  </li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas </p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas como <code>_PERIODO_ACADEMICO</code>, <code>_ID_FECHA</code>, y <code>_ID_UNIDAD</code> a partir de las columnas de entrada.  </li> <li>Propiedades de las columnas derivadas:  <ul> <li><code>_PERIODO_ACADEMICO</code>: Convierte <code>PERIODO_ACADEMICO</code> a <code>DT_WSTR</code> (40).  </li> <li><code>_ID_FECHA</code>: Calcula un identificador num\u00e9rico basado en <code>FECHA</code>.  </li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO </p> <ul> <li>Descripci\u00f3n: Busca el identificador de per\u00edodo acad\u00e9mico en la tabla <code>DIM_PERIODO_ACADEMICO</code>.  </li> <li>Propiedades:  <ul> <li>Consulta SQL: <code>SELECT * FROM DIM_PERIODO_ACADEMICO</code>.  </li> </ul> </li> </ul> </li> <li> <p>Lookup 1 </p> <ul> <li>Descripci\u00f3n: Compara los datos actuales con los registros en <code>FACT_DESEMPENHO_DOCENTE_DE</code> para verificar duplicados.  </li> <li>Propiedades:  <ul> <li>Condici\u00f3n de b\u00fasqueda: Coincide con <code>NOMBRE_DOCENTE</code>, <code>PROGRAMA</code>, <code>ID_FECHA</code>, entre otros campos.  </li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET </p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en <code>FACT_DESEMPENHO_DOCENTE_DE</code>.  </li> <li>Propiedades:  <ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_DESEMPENHO_DOCENTE_DE\"</code>.  </li> <li>Inserci\u00f3n masiva habilitada.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_23","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Excel Source\n    participant Transform as Transformar Columnas\n    participant LookupPeriodo as Lookup ID_PERIODO\n    participant LookupFact as Lookup FACT_DESEMPENHO_DOCENTE_DE\n    participant ADO as Destino de ADO NET\n\n    Excel -&gt;&gt; Transform: Enviar datos\n    Transform -&gt;&gt; LookupPeriodo: Buscar ID_PERIODO\n    LookupPeriodo -&gt;&gt; LookupFact: Validar duplicados\n    LookupFact -&gt;&gt; ADO: Insertar nuevos registros</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_desempenho_docente_ce","title":"FACT_DESEMPENHO_DOCENTE_CE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_desempenho_docente_ce","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE_CE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_39","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EDF-09 (archivos manuales) ejecuta un proceso externo para descargar datos de evaluaci\u00f3n del desempe\u00f1o docente utilizando un script en Python. Este componente forma parte de la soluci\u00f3n ETL dise\u00f1ada para integrar datos en el sistema.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_5","title":"Propiedades del Componente","text":"<ol> <li>Descripci\u00f3n: Ejecuta un script de Python que descarga datos necesarios para el proceso ETL.</li> <li>Script Python: <code>download.py</code></li> <li>Argumentos: <code>--key EPEDF09</code></li> <li>Ejecutable:    Ruta del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Directorio de Trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_24","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEDF09`\n    Python -&gt;&gt; Python: Descarga datos para FACT_DESEMPENHO_DOCENTE_CE\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_desempenho_docente_ce_1","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE_CE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_40","title":"Descripci\u00f3n General","text":"<p>Este componente Procesar FACT_DESEMPENHO_DOCENTE_CE realiza la integraci\u00f3n y transformaci\u00f3n de datos para evaluar el desempe\u00f1o docente centralizado. Se utiliza una combinaci\u00f3n de fuentes de datos Excel, transformaciones derivadas, b\u00fasquedas (lookups) y carga de datos a un destino compatible con ADO.NET en una base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_13","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente Excel (EP-EDF-09):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel que contiene la informaci\u00f3n inicial de desempe\u00f1o docente.</li> <li>Propiedades:<ul> <li>Tabla o rango: <code>Sheet1$</code></li> <li>Columnas principales: <code>ID_UNIDAD</code>, <code>PERIODO_ACADEMICO</code>, <code>NOMBRE_DOCENTE</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Columnas:</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas o ajusta valores en las existentes.</li> <li>Propiedades:<ul> <li>Ejemplo: Convierte <code>PERIODO_ACADEMICO</code> a una columna derivada <code>_PERIODO_ACADEMICO</code>.</li> <li>Ajusta <code>ID_UNIDAD</code> de <code>wstr</code> a <code>i4</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO:</p> <ul> <li>Descripci\u00f3n: Busca informaci\u00f3n del periodo acad\u00e9mico desde la tabla <code>DIM_PERIODO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Modo de b\u00fasqueda: Exact Match.</li> <li>Columna unida: <code>PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup Principal:</p> <ul> <li>Descripci\u00f3n: Relaciona datos adicionales desde <code>FACT_DESEMPENHO_DOCENTE_CE</code>.</li> <li>Propiedades:<ul> <li>Criterios: <code>ID_UNIDAD</code>, <code>NOMBRE_DOCENTE</code>, <code>ID_PERIODO</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_DESEMPENHO_DOCENTE_CE</code>.</li> <li>Propiedades:<ul> <li>Nombre de tabla: <code>\"Cedesarrollo\".\"FACT_DESEMPENHO_DOCENTE_CE\"</code></li> <li>Tama\u00f1o de lote: <code>0</code> (predeterminado).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_25","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Fuente Excel) --&gt; B(Transformar Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Lookup Principal)\n    D --&gt; E(Destino ADO.NET)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_asistencia_act_bienestar","title":"FACT_ASISTENCIA_ACT_BIENESTAR","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-11-archivos-manuales","title":"Componente <code>Tarea EP-EPT-11 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_41","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-11 (archivos manuales) ejecuta un script en Python que descarga los datos necesarios para alimentar el flujo de datos del paquete. Este proceso es fundamental para asegurar que los archivos requeridos est\u00e9n disponibles en el entorno de trabajo antes de procesar la informaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-la-tarea_1","title":"Propiedades de la Tarea","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python para descargar archivos manuales asociados al flujo de datos.</li> <li>Propiedades Configuradas:<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>download.py --key EPEPT11</code></li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#funcionamiento","title":"Funcionamiento","text":"<ol> <li>El script se ejecuta usando el int\u00e9rprete de Python configurado en el entorno virtual localizado en el directorio <code>env</code>.</li> <li>Descarga el archivo identificado por la clave <code>EPEPT11</code> mediante el comando <code>download.py</code>.</li> <li>Al completarse, los datos quedan disponibles en el directorio de trabajo especificado.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_26","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT11`\n    Python -&gt;&gt; Python: Descarga datos para archivos manuales\n    Python -&gt;&gt; SSIS: Reporta \u00e9xito o error</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_asistencia_act_bienestar","title":"Componente <code>Procesar FACT_ASISTENCIA_ACT_BIENESTAR</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_42","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_ASISTENCIA_ACT_BIENESTAR integra, transforma y carga informaci\u00f3n relacionada con la asistencia a actividades de bienestar. Este proceso incluye extracciones desde Excel, transformaciones de columnas, b\u00fasquedas en tablas auxiliares y la carga final de los datos en la tabla destino de SQL Server.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_14","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente Excel (EP-EPT-11):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel con informaci\u00f3n inicial de asistencia.</li> <li>Propiedades:<ul> <li>Tabla o rango: <code>Sheet1$</code></li> <li>Columnas principales: <code>PERIODO_ACADEMICO</code>, <code>DOCUMENTO</code>, <code>FECHA</code>, <code>ACTIVIDAD</code>, <code>ASISTIO</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Columnas:</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas y realiza conversiones de formato.</li> <li>Propiedades:<ul> <li>Convierte <code>FECHA</code> a formato <code>date</code> y deriva <code>ID_FECHA</code>.</li> <li>Ajusta los tipos de datos para <code>DOCUMENTO</code> y <code>TIPO_DOCUMENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO:</p> <ul> <li>Descripci\u00f3n: Busca el ID del periodo acad\u00e9mico en la tabla <code>DIM_PERIODO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Columna de uni\u00f3n: <code>PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_ESTUDIANTE:</p> <ul> <li>Descripci\u00f3n: Encuentra el ID del estudiante utilizando el documento de identificaci\u00f3n desde la tabla <code>DIM_ESTUDIANTES</code>.</li> <li>Propiedades:<ul> <li>Columna de uni\u00f3n: <code>DOCUMENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_ASISTENCIA_ACT_BIENESTAR:</p> <ul> <li>Descripci\u00f3n: Verifica duplicados en la tabla destino antes de la carga.</li> <li>Propiedades:<ul> <li>Criterios: <code>ID_FECHA</code>, <code>ID_PERIODO</code>, <code>ID_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_ASISTENCIA_ACT_BIENESTAR</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_ASISTENCIA_ACT_BIENESTAR\"</code>.</li> <li>Tama\u00f1o de lote: <code>0</code> (predeterminado).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_27","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Fuente Excel) --&gt; B(Transformar Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Lookup ID_ESTUDIANTE)\n    D --&gt; E(Lookup FACT_ASISTENCIA_ACT_BIENESTAR)\n    E --&gt; F(Destino ADO.NET)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_evaluacion_plan_curricular","title":"FACT_EVALUACION_PLAN_CURRICULAR","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-09-archivos-manuales","title":"Componente <code>Tarea EP-EPT-09 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_43","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-09 (archivos manuales) es una tarea de proceso que ejecuta un script en Python para descargar los archivos necesarios relacionados con la evaluaci\u00f3n del plan curricular. Este paso es crucial para garantizar que los datos requeridos est\u00e9n disponibles antes de procesar la informaci\u00f3n en el flujo de datos del paquete.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-la-tarea_2","title":"Propiedades de la Tarea","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python para descargar archivos relacionados con el plan curricular.</li> <li>Propiedades Configuradas:<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>download.py --key EPEPT09</code></li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#funcionamiento_1","title":"Funcionamiento","text":"<ol> <li>El script <code>download.py</code> se ejecuta a trav\u00e9s del int\u00e9rprete de Python especificado en el entorno virtual.</li> <li>Usa el argumento <code>--key EPEPT09</code> para identificar los datos a descargar.</li> <li>Los archivos descargados se almacenan en el directorio de trabajo configurado, asegurando la disponibilidad para las siguientes etapas del flujo.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_28","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT09`\n    Python -&gt;&gt; Python: Descarga datos relacionados con EPEPT09\n    Python -&gt;&gt; SSIS: Reporta \u00e9xito o error</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_evaluacion_plan_curricular","title":"Componente <code>Procesar FACT_EVALUACION_PLAN_CURRICULAR</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_44","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_EVALUACION_PLAN_CURRICULAR es una tarea de flujo de datos en un paquete SSIS que se encarga de extraer datos desde un archivo Excel, transformar las columnas necesarias y cargar la informaci\u00f3n procesada en una tabla en la base de datos. Este proceso incluye pasos de b\u00fasqueda y transformaci\u00f3n para asegurar la consistencia de los datos y su adecuaci\u00f3n para an\u00e1lisis posteriores.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_15","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source (EP-EPT-09) </p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (hoja <code>Sheet1$</code>) relacionado con la evaluaci\u00f3n del plan curricular.</li> <li>Propiedades:<ul> <li>Archivo de Origen: Conexi\u00f3n OLE DB configurada para Excel.</li> <li>Columnas Extra\u00eddas:</li> <li><code>ID_UNIDAD</code></li> <li><code>UNIDAD</code></li> <li><code>PERIODO_ACADEMICO</code></li> <li><code>CALIFICACION</code></li> <li><code>OBSERVACIONES</code></li> </ul> </li> <li>Conexi\u00f3n: Administrador de conexiones de Excel 21.</li> </ul> </li> <li> <p>Derived Column (Transformar Columnas) </p> <ul> <li>Descripci\u00f3n: Aplica transformaciones a las columnas de entrada, generando nuevas columnas derivadas.</li> <li>Columnas Derivadas:<ul> <li><code>_PERIODO_ACADEMICO</code>: Transformaci\u00f3n de <code>PERIODO_ACADEMICO</code> para formato interno.</li> <li><code>_ID_UNIDAD</code>: Conversi\u00f3n de <code>ID_UNIDAD</code> a entero.</li> <li><code>_UNIDAD</code>, <code>_CALIFICACION</code>, <code>_OBSERVACIONES</code>: Procesadas para asegurar consistencia.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO </p> <ul> <li>Descripci\u00f3n: Busca informaci\u00f3n adicional en la tabla <code>[Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code> relacionada con el per\u00edodo acad\u00e9mico.</li> <li>Propiedades:<ul> <li>SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code>.</li> <li>Columna de uni\u00f3n: <code>_PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_EVALUACION_PLAN_CURRICULAR </p> <ul> <li>Descripci\u00f3n: Valida si los datos ya existen en la tabla <code>[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]</code> para evitar duplicados.</li> <li>Propiedades:<ul> <li>SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR] WHERE [ID_UNIDAD] = ? AND [ID_PERIODO] = ?</code>.</li> </ul> </li> </ul> </li> <li> <p>ADO.NET Destination (Guardar FACT_EVALUACION_PLAN_CURRICULAR) </p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados y validados en la tabla <code>[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Cedesarrollo\".\"FACT_EVALUACION_PLAN_CURRICULAR\"</code>.</li> <li>Batch Size: 0 (usa tama\u00f1o predeterminado).</li> <li>Modo de inserci\u00f3n: Bulk Insert para mejor rendimiento.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_29","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(EP-EPT-09: Extraer Excel) --&gt; B(Transformar Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Lookup FACT_EVALUACION_PLAN_CURRICULAR)\n    D --&gt; E(Guardar FACT_EVALUACION_PLAN_CURRICULAR)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_evaluacion_formacion","title":"FACT_EVALUACION_FORMACION","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-10-archivos-manuales","title":"Componente <code>Tarea EP-EPT-10 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_45","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EPT-10 (archivos manuales) ejecuta un proceso externo utilizando un script de Python para descargar datos relacionados con la evaluaci\u00f3n de formaci\u00f3n. La tarea es parte de un paquete SSIS y est\u00e1 configurada para garantizar que los datos se procesen correctamente antes de ser utilizados en el flujo de datos del paquete.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_16","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Execute Process Task (EP-EPT-10) </p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python ubicado en el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Propiedades:<ul> <li>Executable: Ruta del ejecutable de Python configurado mediante una variable de proyecto (<code>@[$Project::Python_Executable]</code>).</li> <li>Argumentos: <code>download.py --key EPEPT10</code>.</li> <li>Directorio de Trabajo: <code>\\\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> </ul> </li> <li>Prop\u00f3sito:<ul> <li>Descargar datos necesarios para el proceso de evaluaci\u00f3n de formaci\u00f3n.</li> <li>Asegurar que los archivos est\u00e1n actualizados antes de continuar con las siguientes tareas en el flujo de datos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_30","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Inicia Tarea EP-EPT-10) --&gt; B(Ejecuta Python Script)\n    B --&gt; C(Descarga datos)\n    C --&gt; D(Contin\u00faa flujo SSIS)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_evaluacion_formacion_1","title":"Componente <code>Procesar FACT_EVALUACION_FORMACION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_46","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_EVALUACION_FORMACION es una tarea de flujo de datos en un paquete SSIS. Su objetivo principal es extraer datos desde un archivo Excel, transformarlos y realizar un Lookup en la base de datos antes de cargar los datos en la tabla destino <code>Cedesarrollo.FACT_EVALUACION_FORMACION</code>. </p> <p>Este proceso incluye tareas de transformaci\u00f3n de columnas, validaci\u00f3n de datos y manejo de errores para garantizar la calidad y coherencia de la informaci\u00f3n cargada.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_17","title":"Componentes del Flujo de Datos","text":"<p>1. Excel Source (EP-EPT-10)     - Descripci\u00f3n: Extrae datos de un archivo Excel ubicado en un directorio espec\u00edfico.     - Propiedades:         - Hoja de trabajo: <code>Sheet1$</code>.         - Conexi\u00f3n: Administrador de conexiones configurado para Excel (<code>Administrador de conexiones con Excel 22</code>).  </p> <p>2. Derived Column Transformation     - Descripci\u00f3n: Realiza transformaciones en los datos extra\u00eddos, generando nuevas columnas derivadas o modificando las existentes.     - Propiedades principales:         - Transformaci\u00f3n de datos como <code>TIPO_DOCUMENTO_ENCUESTADO</code>, <code>DOCUMENTO_ENCUESTADO</code>, y columnas de evaluaci\u00f3n (<code>ASPECTO_1</code> a <code>ASPECTO_9</code>).  </p> <p>3. Lookup Transformation     - Descripci\u00f3n: Realiza una b\u00fasqueda de datos en la tabla <code>FACT_EVALUACION_FORMACION</code> para validar y complementar la informaci\u00f3n procesada.     - Propiedades principales:         - SQL de referencia: <pre><code>SELECT * \nFROM Cedesarrollo.FACT_EVALUACION_FORMACION\nWHERE DOCUMENTO_ENCUESTADO = ? \n    AND ID_TARIFA = ?\n</code></pre>         - Manejo de filas sin coincidencia: Env\u00eda las filas al destino final para carga.  </p> <p>4. Destino ADO.NET     - Descripci\u00f3n: Carga los datos procesados en la tabla <code>Cedesarrollo.FACT_EVALUACION_FORMACION</code>.     - Propiedades principales:         - Nombre de la tabla: <code>\"Cedesarrollo\".\"FACT_EVALUACION_FORMACION\"</code>.         - Inserci\u00f3n masiva: Activada para optimizar el rendimiento.  </p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_31","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant Derived as Derived Columns\n    participant Lookup as Lookup Table\n    participant ADO as ADO.NET Destination\n\n    SSIS -&gt;&gt; Excel: Extrae datos de archivo\n    Excel -&gt;&gt; Derived: Transforma columnas\n    Derived -&gt;&gt; Lookup: Busca datos existentes\n    Lookup -&gt;&gt; ADO: Env\u00eda filas sin coincidencia\n    ADO -&gt;&gt; SSIS: Finaliza carga de datos</code></pre> <pre><code>graph TD\n    A(Inicio) --&gt; B(Excel Source: EP-EPT-10)\n    B --&gt; C(Transformar Columnas)\n    C --&gt; D(Lookup Transformation)\n    D --&gt; E(Destino ADO.NET)\n    E --&gt; F(Finalizaci\u00f3n)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_cotizaciones","title":"FACT_COTIZACIONES","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-tarea-am-dre-05-archivos-manuales","title":"Componente <code>Procesar Tarea AM-DRE-05 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_47","title":"Descripci\u00f3n General","text":"<p>Esta tarea ejecuta un script Python para descargar datos necesarios para el proceso de integraci\u00f3n de <code>FACT_COTIZACIONES</code>. El script se ejecuta desde un entorno virtual configurado en el proyecto y utiliza una clave espec\u00edfica <code>AMDRE05</code> para identificar los datos que se deben procesar.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo_1","title":"Componentes del Flujo","text":"<p>1. Tarea de Ejecuci\u00f3n de Proceso: AM-DRE-05     - Descripci\u00f3n: Ejecuta el script Python <code>download.py</code> para obtener los datos relevantes.     - Propiedades:         - Ejecutable: <code>python.exe</code> ubicado en el entorno virtual configurado.         - Directorio de Trabajo: <code>\\\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.         - Argumentos del Script: <code>download.py --key AMDRE05</code>.  </p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-ejecucion","title":"Diagrama de Ejecuci\u00f3n","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key AMDRE05`\n    Python -&gt;&gt; Python: Descarga datos de cotizaciones\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-fact_cotizacion","title":"Componente <code>Tarea fact_cotizacion</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_48","title":"Descripci\u00f3n General","text":"<p>La tarea fact_cotizacion es un componente de tipo Execute Process Task en SSIS que se encarga de ejecutar un proceso externo mediante un script de Python. En este caso, se ejecuta el script <code>fact_cotizacion.py</code>, el cual se utiliza para procesar y consolidar informaci\u00f3n relacionada con las cotizaciones. La tarea se configura utilizando variables de proyecto para definir la ruta del ejecutable de Python y el directorio de trabajo.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_6","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Execute Process Task  </li> <li>Ejecutable:   Se utiliza la variable de proyecto <code>@[$Project::Python_Executable]</code>, que apunta a la ruta del ejecutable de Python.  </li> <li>Argumentos: <code>fact_cotizacion.py</code></li> <li>Directorio de Trabajo:   Se configura con la variable de proyecto <code>@[$Project::Working_Directory]</code> concatenada con el path <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> <li>Ruta F\u00edsica (ejemplo): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Propiedades Adicionales:  <ul> <li>Filtro de registro: <code>FilterKind=0</code> </li> <li>ThreadHint: <code>0</code> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_32","title":"Diagrama de Secuencia","text":"<p>El siguiente diagrama de secuencia ilustra el proceso que se ejecuta en esta tarea:</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta fact_cotizacion.py\n    Python -&gt;&gt; Python: Procesa y consolida datos de cotizaciones\n    Python -&gt;&gt; SSIS: Retorna resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_cotizaciones","title":"Componente <code>Procesar FACT_COTIZACIONES</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_49","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_COTIZACIONES representa una tarea de flujo de datos en SSIS dise\u00f1ada para extraer, transformar y cargar informaci\u00f3n de cotizaciones desde un archivo Excel hacia una base de datos. Este proceso incluye transformaciones derivadas, operaciones de b\u00fasqueda, combinaciones de datos y ordenamientos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-de-los-componentes-del-flujo-de-datos","title":"Detalles de los Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos: Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae los datos de un archivo Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0 (tiempo de espera infinito).</li> <li><code>OpenRowset</code>: Sheet1$.</li> <li><code>AccessMode</code>: 0 (modo de acceso por defecto).</li> </ul> </li> <li>Conexi\u00f3n:<ul> <li><code>ConnectionManager</code>: Administrador de conexiones con Excel 23.</li> </ul> </li> <li>Salidas:<ul> <li>Columnas: FECHA_REGISTRO, NOMBRE, DOCUMENTO, TIPO_DOCUMENTO, ESTADO_COTIZACION, PREGUNTA, RESPUESTA.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Derived Column (Transformar Columnas)</p> <ul> <li>Descripci\u00f3n: Crea columnas derivadas mediante expresiones.</li> <li>Propiedades:<ul> <li>Ejemplo: Generaci\u00f3n de <code>_ID_FECHA</code> reemplazando caracteres en <code>FECHA_REGISTRO</code>.</li> </ul> </li> <li>Columnas Derivadas:<ul> <li><code>_ID_FECHA</code>, <code>_DOCUMENTO</code>, <code>_TIPO_DOCUMENTO</code>, <code>_NOMBRE</code>, <code>_EST_COTIZACION</code>, <code>_PREGUNTA</code>, <code>_RESPUESTA</code>, <code>_FECHA_REGISTRO</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Lookup (ID_ESTUDIANTE)</p> <ul> <li>Descripci\u00f3n: Busca datos en la tabla <code>DIM_ESTUDIANTES</code>.</li> <li>Propiedades:<ul> <li>SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code>.</li> <li>Comportamiento: Ignorar fallos de coincidencia.</li> </ul> </li> <li>Entradas:<ul> <li><code>_DOCUMENTO</code>.</li> </ul> </li> <li>Salidas:<ul> <li>Coincidencias: <code>ID_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Sort</p> <ul> <li>Descripci\u00f3n: Ordena los datos de entrada en orden ascendente por columnas espec\u00edficas.</li> <li>Propiedades:<ul> <li><code>MaximumThreads</code>: -1 (uso autom\u00e1tico de hilos).</li> </ul> </li> <li>Columnas Ordenadas:<ul> <li><code>PREGUNTA</code>, <code>_PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Merge Join</p> <ul> <li>Descripci\u00f3n: Combina dos flujos de datos ordenados mediante un Join INNER.</li> <li>Propiedades:<ul> <li><code>JoinType</code>: INNER JOIN.</li> </ul> </li> <li>Entradas:<ul> <li>Izquierda: Datos ordenados por <code>PREGUNTA</code>.</li> <li>Derecha: Datos ordenados por <code>_PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos: ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos combinados en la tabla <code>FACT_COTIZACIONES</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Cedesarrollo\".\"FACT_COTIZACIONES\"</code>.</li> <li><code>BatchSize</code>: 0.</li> </ul> </li> <li>Entradas:<ul> <li>Columnas transformadas y combinadas.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_33","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Database\n\n    SSIS -&gt;&gt; Excel: Extrae datos de Sheet1$\n    SSIS -&gt;&gt; SSIS: Realiza transformaci\u00f3n derivada\n    SSIS -&gt;&gt; SQL: Realiza Lookup ID_ESTUDIANTE\n    SSIS -&gt;&gt; SSIS: Ordena datos\n    SSIS -&gt;&gt; SSIS: Combina flujos (Merge Join)\n    SSIS -&gt;&gt; SQL: Carga datos en FACT_COTIZACIONES</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/","title":"07. PROTECCION_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#proteccion_dimensiones","title":"PROTECCION_DIMENSIONES","text":"<p>El paquete SSIS \"07-PROTECCION_DIMENSIONES\" est\u00e1 dise\u00f1ado para gestionar flujos ETL que procesan datos cr\u00edticos relacionados con dimensiones de protecci\u00f3n, como preguntas y respuestas educativas, caracter\u00edsticas de campos y establecimientos educativos. Este paquete asegura un flujo de trabajo eficiente, consolidando datos desde m\u00faltiples fuentes y garantizando su integridad en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es transformar y cargar datos clave para dimensiones educativas y de protecci\u00f3n social. Esto incluye validar informaci\u00f3n de campos, programas y encuestas, asegurando que los datos consolidados sean precisos, consistentes y preparados para an\u00e1lisis estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes utilizadas:<ul> <li>Archivos Excel: Informaci\u00f3n sobre preguntas, respuestas, programas y caracter\u00edsticas de campos.</li> <li>Bases de Datos: Validaci\u00f3n de registros en tablas maestras como <code>DIM_PROGRAMA</code>, <code>DIM_PREGUNTAS_EE_JEC</code> y <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>.</li> </ul> </li> <li>Conexiones configuradas:<ul> <li>Administradores OLE DB y ADO.NET.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad de tipos entre columnas de entrada y destino.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Garantiza consistencia mediante b\u00fasquedas en tablas maestras.</li> </ul> </li> <li>Clasificaci\u00f3n (<code>Conditional Split</code>):<ul> <li>Filtra registros v\u00e1lidos y redirige no v\u00e1lidos.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas destino:<ul> <li><code>DIM_CAMPOS_CARACT</code></li> <li><code>DIM_PROGRAMA</code></li> <li><code>DIM_PREGUNTAS_EE_JEC</code></li> <li><code>DIM_RESPUESTAS_EE_JEC</code></li> <li><code>DIM_ESTABLECIMIENTO_EDUCATIVO</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para optimizar la carga.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Integraci\u00f3n de scripts Python para automatizar descargas desde SharePoint y procesar datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_CAMPOS_CARACT:</p> <ul> <li><code>ID_CARACTERISTICA</code>: Identificador \u00fanico.</li> <li><code>PREGUNTA</code>: Texto de la pregunta.</li> <li><code>OBSERVACIONES</code>: Informaci\u00f3n adicional.</li> </ul> </li> <li> <p>DIM_PROGRAMA:</p> <ul> <li><code>ID_PROGRAMA</code>: Identificador del programa.</li> <li><code>NOMBRE_PROGRAMA</code>: Descripci\u00f3n del programa.</li> </ul> </li> <li> <p>DIM_PREGUNTAS_EE_JEC:</p> <ul> <li><code>ID_PREGUNTA</code>: Identificador \u00fanico.</li> <li><code>PREGUNTA</code>: Texto de la pregunta.</li> <li><code>ID_PROGRAMA</code>: Relaci\u00f3n con el programa.</li> </ul> </li> <li> <p>DIM_RESPUESTAS_EE_JEC:</p> <ul> <li><code>ID_RESPUESTA</code>: Identificador \u00fanico.</li> <li><code>RESPUESTA</code>: Texto de la respuesta.</li> <li><code>ID_PREGUNTA</code>: Relaci\u00f3n con la pregunta.</li> </ul> </li> <li> <p>DIM_ESTABLECIMIENTO_EDUCATIVO:</p> <ul> <li><code>ID_ESTABLECIMIENTO</code>: Identificador \u00fanico.</li> <li><code>NOMBRE_ESTABLECIMIENTO</code>: Nombre del establecimiento.</li> <li><code>REPRESENTANTE_LEGAL</code>: Persona responsable.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos (Data Flow Diagram - DFD)</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Fuente de Excel\n    participant DB as Base de Datos\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; Excel: Extraer datos de campos, programas y preguntas\n    SSIS -&gt;&gt; DB: Validar registros en tablas maestras\n    SSIS -&gt;&gt; Python: Ejecutar scripts para extracci\u00f3n desde SharePoint\n    SSIS -&gt;&gt; DWH: Cargar datos procesados en tablas destino</code></pre> <ol> <li>Diagrama de Transformaciones y Validaciones</li> </ol> <pre><code>graph TD\n    A1[Datos de Campos y Programas] --&gt; T1[Conversi\u00f3n de Datos]\n    A2[Preguntas y Respuestas] --&gt; T2[Lookup: Validar Preguntas]\n    T1 --&gt; T3[Clasificaci\u00f3n por Condicional Split]\n    T2 --&gt; L1[Lookup: Validar Respuestas]\n    T3 --&gt; C1[Cargar datos validados]</code></pre> <ol> <li>Diagrama ER para Tablas de Dimensiones</li> </ol> <pre><code>erDiagram\n    DIM_CAMPOS_CARACT {\n        int ID_CARACTERISTICA\n        string PREGUNTA\n        string OBSERVACIONES\n    }\n    DIM_PROGRAMA {\n        int ID_PROGRAMA\n        string NOMBRE_PROGRAMA\n    }\n    DIM_PREGUNTAS_EE_JEC {\n        int ID_PREGUNTA\n        string PREGUNTA\n        int ID_PROGRAMA\n    }\n    DIM_RESPUESTAS_EE_JEC {\n        int ID_RESPUESTA\n        string RESPUESTA\n        int ID_PREGUNTA\n    }\n    DIM_ESTABLECIMIENTO_EDUCATIVO {\n        int ID_ESTABLECIMIENTO\n        string NOMBRE_ESTABLECIMIENTO\n        string REPRESENTANTE_LEGAL\n    }\n    DIM_PROGRAMA ||--|| DIM_PREGUNTAS_EE_JEC : \"Asociado a programas\"\n    DIM_PREGUNTAS_EE_JEC ||--|| DIM_RESPUESTAS_EE_JEC : \"Relaci\u00f3n Pregunta-Respuesta\"\n    DIM_ESTABLECIMIENTO_EDUCATIVO ||--|| DIM_PROGRAMA : \"Conexi\u00f3n con programas\"</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-ejecucion-etls","title":"Componente <code>Ejecuci\u00f3n ETLs</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Este componente ejecuta un proceso Python encargado de la conexi\u00f3n y extracci\u00f3n de datos desde SharePoint para la carpeta espec\u00edfica <code>Protecci\u00f3n</code>, ubicada dentro de la estructura de archivos del proyecto. Es parte del flujo de automatizaci\u00f3n de ETL en un paquete de SSIS.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ul> <li> <p>Descripci\u00f3n: Este componente utiliza una tarea de tipo <code>Execute Process Task</code> en SSIS para invocar un script Python que se encuentra dentro del entorno virtual configurado para el proyecto.</p> </li> <li> <p>Propiedades:</p> <ul> <li> <p>Executable:      <pre><code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"\n</code></pre>     Especifica la ruta al ejecutable de Python dentro del entorno virtual del proyecto.</p> </li> <li> <p>WorkingDirectory:     <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\03.Proteccion\"\n</code></pre>     Define el directorio de trabajo donde se encuentra el script Python.</p> </li> <li> <p>Arguments:      <pre><code>SharePoint_Connection_Proteccion.py\n</code></pre>     Indica el script que ser\u00e1 ejecutado para conectar y procesar los datos de SharePoint.</p> </li> <li> <p>TimeOut:     <pre><code>@[$Project::Tiempo_Espera_Segundos]\n</code></pre>     Configura el tiempo m\u00e1ximo de espera en segundos para que el proceso se complete, definido en 600 segundos (10 minutos).</p> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo-del-proceso","title":"Diagrama de Flujo del Proceso","text":"<p>El siguiente diagrama ilustra el flujo de ejecuci\u00f3n para el componente Ejecuci\u00f3n ETLs:</p> <pre><code>graph TD\n    A[Inicio del proceso] --&gt; B[Obtener ruta del ejecutable Python]\n    B --&gt; C[Definir directorio de trabajo]\n    C --&gt; D[Ejecutar script SharePoint_Connection_Proteccion.py]\n    D --&gt; E[Esperar a la finalizaci\u00f3n del proceso Timeout: 600 seg]\n    E --&gt; F[\u00bfProceso completado exitosamente?]\n    F --&gt; G[Registrar \u00e9xito en logs]:::success\n    F --&gt; H[Registrar error y abortar]:::error\n    G --&gt; I[Fin del proceso]\n    H --&gt; I</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_campos_caract","title":"Componente <code>Data DIM_CAMPOS_CARACT</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_CAMPOS_CARACT forma parte de un flujo ETL desarrollado en SSIS para cargar y transformar datos relacionados con las caracter\u00edsticas de campos en la tabla <code>DIM_CAMPOS_CARACT</code> dentro del esquema <code>Protecci\u00f3n</code>. Este proceso incluye la lectura de datos desde un archivo Excel, conversi\u00f3n de datos, validaci\u00f3n mediante un componente de tipo Lookup, y finalmente, la carga en la base de datos de destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Conecta y extrae datos desde una hoja llamada <code>Sheet1$</code> en un archivo Excel, con columnas <code>PREGUNTA</code> y <code>OBSERVACIONES</code>.</li> <li>Propiedades:<ul> <li>AccessMode: 0 (por tabla u objeto).</li> <li>Hoja seleccionada: <code>Sheet1$</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Convierte los datos extra\u00eddos a un formato compatible con los siguientes componentes del flujo.</li> <li>Columnas Convertidas:<ul> <li><code>PREGUNTA</code> \u2192 <code>Copy of PREGUNTA</code>.</li> <li><code>OBSERVACIONES</code> \u2192 <code>Copy of OBSERVACIONES</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida y enriquece los datos mediante la b\u00fasqueda de correspondencias en la tabla destino <code>DIM_CAMPOS_CARACT</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_CAMPOS_CARACT]\nWHERE [PREGUNTA] = ?\n</code></pre></li> <li>Columnas Salida:<ul> <li><code>PREGUNTA_</code>.</li> <li><code>OBSERVACIONES_</code>.</li> <li><code>ID_PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados y validados en la tabla <code>DIM_CAMPOS_CARACT</code> dentro del esquema <code>Protecci\u00f3n</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (tama\u00f1o predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva si es posible).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el flujo completo de datos del componente Data DIM_CAMPOS_CARACT:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Conversi\u00f3n de datos]\n    C --&gt; D[Validaci\u00f3n mediante Lookup]\n    D --&gt; E{\u00bfCoincidencia encontrada?}\n    E -- S\u00ed --&gt; F[Cargar datos en ADO NET Destination]\n    E -- No --&gt; G[Registrar datos no coincidentes]\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_preguntas_ee_jec","title":"Componente <code>Data DIM_PREGUNTAS_EE_JEC</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>Este componente gestiona un flujo de datos ETL que extrae preguntas relacionadas con ejecuci\u00f3n de eventos educativos desde un archivo Excel y las procesa para ser almacenadas en la tabla <code>DIM_PREGUNTAS_EE_JEC</code> del esquema <code>Protecci\u00f3n</code>. Incluye validaciones, transformaciones, y manejo de datos no coincidentes.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae los datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PROGRAMA</code></li> <li><code>PREGUNTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde una hoja).</li> <li>Conexi\u00f3n: Administrador de conexiones <code>Excel_Connection_Dim_Preguntas_JEC</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Programas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida los programas en los datos de entrada con los registros existentes en <code>DIM_PROGRAMA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PROGRAMA]\nWHERE [PROGRAMA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia encontrada: Asocia el <code>ID_PROGRAMA</code>.</li> <li>Sin coincidencia: Redirige a la etapa de conversi\u00f3n de datos.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas extra\u00eddas (<code>PREGUNTA</code>) a un formato compatible con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>PREGUNTA</code> \u2192 <code>Copy of PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup):</p> <ul> <li>Descripci\u00f3n: Verifica si las preguntas existen en la tabla destino <code>DIM_PREGUNTAS_EE_JEC</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_JEC]\nWHERE [PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>DIM_PREGUNTAS_EE_JEC</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_1","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el flujo completo del componente Data DIM_PREGUNTAS_EE_JEC:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n de Programas Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Preguntas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_respuesta_ee_jec","title":"Componente <code>Data DIM_RESPUESTA_EE_JEC</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos procesa respuestas asociadas a preguntas de encuestas educativas (<code>DIM_RESPUESTA_EE_JEC</code>). Las respuestas se extraen de un archivo Excel, se validan con las tablas existentes y se cargan en la base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PREGUNTA</code></li> <li><code>RESPUESTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde la hoja).</li> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_Respuestas_JEC</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida que las preguntas existan en <code>DIM_PREGUNTAS_EE_JEC</code> y asigna el <code>ID_PREGUNTA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_JEC]\nWHERE [PREGUNTA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia encontrada: Asocia el <code>ID_PREGUNTA</code>.</li> <li>Sin coincidencia: Redirige al flujo de transformaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas de texto para compatibilidad con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>RESPUESTA</code> \u2192 <code>Copy of RESPUESTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Respuestas (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida que las respuestas no est\u00e9n duplicadas en <code>DIM_RESPUESTAS_EE_JEC</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_RESPUESTAS_EE_JEC]\nWHERE [RESPUESTA] = ? AND [ID_PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga las respuestas validadas y procesadas en <code>DIM_RESPUESTAS_EE_JEC</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_2","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama muestra el proceso completo del flujo de datos:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n de Preguntas Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Respuestas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_preguntas_aipi","title":"Componente <code>Data DIM_PREGUNTAS_AIPI</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos carga preguntas relacionadas con el programa AIPI en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code>. El proceso incluye validaci\u00f3n, transformaci\u00f3n de datos y carga en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PROGRAMA</code></li> <li><code>PREGUNTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde la hoja).</li> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_Preguntas_AIPI</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n del Programa (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida que el programa asociado a la pregunta exista en la tabla <code>DIM_PROGRAMA</code> y asigna el <code>ID_PROGRAMA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PROGRAMA]\nWHERE [PROGRAMA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia encontrada: Asocia el <code>ID_PROGRAMA</code>.</li> <li>Sin coincidencia: Redirige al flujo de transformaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas para compatibilidad con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>PREGUNTA</code> \u2192 <code>Copy of PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida que las preguntas no est\u00e9n duplicadas en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_AIPI]\nWHERE [PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga las preguntas validadas y procesadas en <code>DIM_PREGUNTAS_EE_AIPI</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_3","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el proceso:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n del Programa Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Preguntas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_respuesta_aipi","title":"Componente <code>Data DIM_RESPUESTA_AIPI</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos realiza la carga de respuestas relacionadas con el programa AIPI en la tabla <code>DIM_RESPUESTAS_EE_AIPI</code>. El proceso incluye validaci\u00f3n, conversi\u00f3n de datos y carga en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PREGUNTA</code></li> <li><code>RESPUESTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde la hoja).</li> <li>Conexi\u00f3n: <code>Excel_Connection_Respuesta_AIPI</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida que la pregunta asociada a la respuesta exista en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code> y asigna el <code>ID_PREGUNTA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_AIPI]\nWHERE [PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas para compatibilidad con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>RESPUESTA</code> \u2192 <code>Copy of RESPUESTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Respuestas (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida que las respuestas no est\u00e9n duplicadas en la tabla <code>DIM_RESPUESTAS_EE_AIPI</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_RESPUESTAS_EE_AIPI]\nWHERE [RESPUESTA] = ? AND [ID_PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga las respuestas validadas y procesadas en <code>DIM_RESPUESTAS_EE_AIPI</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_4","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el proceso:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n de Preguntas Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Respuestas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-cargar_dim_sedes","title":"Componente <code>Cargar_DIM_SEDES</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente Cargar_DIM_SEDES es una tarea de tipo Execute SQL Task en SSIS. Su funci\u00f3n principal es limpiar (truncar) la tabla de staging que contiene informaci\u00f3n de poblaci\u00f3n de protecci\u00f3n antes de realizar nuevas cargas de datos. Esto asegura que la tabla est\u00e9 vac\u00eda y preparada para la inserci\u00f3n de datos actualizados.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#detalles-tecnicos","title":"Detalles T\u00e9cnicos","text":"<ul> <li>Tipo de Tarea: Execute SQL Task</li> <li>Nombre del Componente: <code>Cargar_DIM_SEDES</code></li> <li>Descripci\u00f3n: Ejecuta una sentencia SQL para truncar la tabla <code>[STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION]</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#propiedades-principales","title":"Propiedades Principales","text":"<ul> <li>Connection: Utiliza la conexi\u00f3n referenciada por el ID <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code>.</li> <li> <p>SQL Statement:   <pre><code>truncate table [STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION]\n</code></pre>   Esta sentencia limpia completamente la tabla para permitir la inserci\u00f3n de nuevos datos sin residuos de cargas anteriores.</p> </li> <li> <p>Task Contact: <code>Execute SQL Task; Microsoft Corporation; SQL Server 2022; \u00a9 2022 Microsoft Corporation; All Rights Reserved; http://www.microsoft.com/sql/support/default.asp;1</code></p> </li> <li> <p>ThreadHint: 0 (Sin sugerencia de hilos).</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo-del-proceso_1","title":"Diagrama de Flujo del Proceso","text":"<p>El siguiente diagrama ilustra el flujo de ejecuci\u00f3n para el componente Cargar_DIM_SEDES:</p> <pre><code>graph TD\n    A[Inicio del Proceso] --&gt; B[Conectar a la base de datos]\n    B --&gt; C[Ejecutar sentencia SQL]\n    C --&gt; D[Truncar la tabla DIM_POBLACION_PROTECCION]\n    D --&gt; E[Registrar resultado de la operaci\u00f3n]\n    E --&gt; F[Fin del Proceso]</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_poblacion-to_stage_area","title":"Componente <code>Data DIM_POBLACION TO_STAGE_AREA</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_POBLACION TO_STAGE_AREA es un flujo de datos (Data Flow Task) dentro de un paquete SSIS que se encarga de extraer informaci\u00f3n de poblaci\u00f3n desde un archivo Excel, convertir el formato de algunas columnas y posteriormente cargar los datos transformados en una tabla de staging ubicada en el esquema Transversal. En este caso, la tabla destino es <code>[STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION]</code>. Este proceso forma parte de la preparaci\u00f3n de los datos antes de su integraci\u00f3n final en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source 1) </p> <ul> <li>Descripci\u00f3n: Conecta y extrae datos desde un archivo Excel.  </li> <li>Propiedades:<ul> <li>Hoja seleccionada: <code>Sheet1$</code></li> <li>Se extraen las columnas: <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion 1) </p> <ul> <li>Descripci\u00f3n: Transforma los datos extra\u00eddos para ajustarse a los requerimientos del destino.  </li> <li>Columnas Convertidas:<ul> <li>La columna <code>DOCUMENTO</code> se convierte a un nuevo campo denominado <code>Copy of DOCUMENTO</code> con un tama\u00f1o de 40 caracteres.</li> <li>La columna <code>TIPO_DOCUMENTO</code> se convierte a <code>Copy of TIPO_DOCUMENTO</code> con un tama\u00f1o de 20 caracteres.</li> </ul> </li> <li>Propiedades adicionales:<ul> <li>Se activa la opci\u00f3n de conversi\u00f3n sin uso de FastParse (FastParse = false) para asegurar la correcta transformaci\u00f3n de los datos.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination: Destino de ADO NET 1) </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de staging <code>[STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION]</code>.  </li> <li>Propiedades:<ul> <li>TableOrViewName: <code>\"Transversal\".\"DIM_POBLACION_PROTECCION\"</code></li> <li>BatchSize: 0 (usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> para mejorar el rendimiento mediante inserciones masivas.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo-del-proceso_2","title":"Diagrama de Flujo del Proceso","text":"<p>El siguiente diagrama ilustra el flujo completo de datos para el componente Data DIM_POBLACION TO_STAGE_AREA:</p> <pre><code>graph TD\n    A[Inicio del Proceso] --&gt; B[Extracci\u00f3n de datos desde Excel Source]\n    B --&gt; C[Conversi\u00f3n de datos Data Conversion]\n    C --&gt; D[Carga en destino ADO NET]\n    D --&gt; E[Fin del Proceso]</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_poblacion","title":"Componente <code>Data DIM_POBLACION</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Este componente procesa y carga informaci\u00f3n sobre la poblaci\u00f3n en la tabla <code>DIM_POBLACION</code> del esquema <code>Proteccion</code>. El flujo de datos extrae registros desde un archivo Excel, realiza conversiones de datos y luego inserta la informaci\u00f3n en el destino mediante un ADO NET Destination. Adem\u00e1s, se incorpora un componente que obtiene datos desde la fuente mediante una consulta SQL que utiliza una expresi\u00f3n CTE (Common Table Expression) para transformar y validar los datos de poblaci\u00f3n provenientes de la etapa (<code>STAGE_AREA</code>).</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source 1)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel, leyendo la hoja <code>Sheet1$</code> y capturando las columnas <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> <li>Propiedades:<ul> <li>OpenRowset: <code>Sheet1$</code></li> <li>AccessMode: 0 (lectura directa desde la hoja)</li> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_Poblacion</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion 1)</p> <ul> <li>Descripci\u00f3n: Convierte las columnas extra\u00eddas para ajustarlas a los requerimientos del destino.</li> <li>Columnas Convertidas:<ul> <li><code>DOCUMENTO</code> \u2192 <code>Copy of DOCUMENTO</code> (convertido a <code>wstr</code> con longitud 40)</li> <li><code>TIPO_DOCUMENTO</code> \u2192 <code>Copy of TIPO_DOCUMENTO</code> (convertido a <code>wstr</code> con longitud 20)</li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos SQL (poblacion)</p> <ul> <li>Descripci\u00f3n: Utiliza una consulta SQL que define la CTE <code>DIM_POBLACION_PROTECCION</code> para transformar y validar los registros provenientes de la etapa <code>STAGE_AREA</code>. Se aplican m\u00faltiples LEFT JOIN a tablas de referencia (DIM_EMPRESAS, DIM_AFILIADOS, DIM_BENEFICIARIOS y DIM_APORTANTE_NOAFILIADO) para obtener los identificadores correspondientes. Luego, se filtran los registros que a\u00fan no han sido cargados en la tabla destino <code>DIM_POBLACION</code> (de modo que los registros duplicados se descarten).</li> <li>SQL:     <pre><code>WITH DIM_POBLACION_PROTECCION as (\n    SELECT \n        pp.TIPO_DOCUMENTO, \n        pp.DOCUMENTO,\n        CASE WHEN e.ID_EMPRESA IS NULL THEN -1 ELSE e.ID_EMPRESA END AS ID_EMPRESA,\n        CASE WHEN a.ID_AFILIADO IS NULL THEN -1 ELSE a.ID_AFILIADO END AS ID_AFILIADO,\n        CASE WHEN b.ID_BENEFICIARIO IS NULL THEN -1 ELSE b.ID_BENEFICIARIO END AS ID_BENEFICIARIO,\n        CASE WHEN an.ID_APORTANTE IS NULL THEN -1 ELSE an.ID_APORTANTE END AS ID_APORTANTE\n    FROM [STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION] pp\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] e\n        ON pp.TIPO_DOCUMENTO = e.COD_TIPO_DOCUMENTO AND pp.DOCUMENTO = e.DOCUMENTO\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a\n        ON pp.TIPO_DOCUMENTO = a.COD_TIPO_DOCUMENTO AND pp.DOCUMENTO = a.NUMERO_DOCUMENTO\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b\n        ON pp.TIPO_DOCUMENTO = b.COD_TIPO_DOCUMENTO AND pp.DOCUMENTO = b.NUMERO_DOCUMENTO\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] an\n        ON pp.TIPO_DOCUMENTO = an.COD_TIPO_DOCUMENTO AND pp.DOCUMENTO = an.DOCUMENTO\n)\nSELECT pp.* \nFROM DIM_POBLACION_PROTECCION pp\nLEFT JOIN [DWH_COMFENALCO].[Proteccion].[DIM_POBLACION] ppp\n    ON pp.TIPO_DOCUMENTO = ppp.TIPO_DOCUMENTO\n    AND pp.DOCUMENTO = ppp.DOCUMENTO\n    AND pp.ID_EMPRESA = ppp.ID_EMPRESA\n    AND pp.ID_AFILIADO = ppp.ID_AFILIADO\n    AND pp.ID_BENEFICIARIO = ppp.ID_BENEFICIARIO\n    AND pp.ID_APORTANTE = ppp.ID_APORTANTE\nWHERE ppp.TIPO_DOCUMENTO IS NULL\n</code></pre></li> <li>Conexi\u00f3n: Utiliza el administrador de conexiones <code>DWH_COMFENALCO</code>.</li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination)</p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados y validados en la tabla <code>DIM_POBLACION</code> del esquema <code>Proteccion</code>.</li> <li>Propiedades:<ul> <li>TableOrViewName: <code>\"Proteccion\".\"DIM_POBLACION\"</code></li> <li>BatchSize: 0</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: <code>true</code></li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo-del-proceso_3","title":"Diagrama de Flujo del Proceso","text":"<pre><code>graph TD\n    A[Inicio] --&gt; B[Extracci\u00f3n de datos desde Excel Source 1]\n    B --&gt; C[Conversi\u00f3n de Datos Data Conversion 1]\n    C --&gt; D[Obtenci\u00f3n de datos mediante SQL poblacion]\n    D --&gt; E[Carga en ADO NET Destination Proteccion.DIM_POBLACION]\n    E --&gt; F[Fin]</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-establecimiento_educativo","title":"Componente <code>Data ESTABLECIMIENTO_EDUCATIVO</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>Este componente procesa informaci\u00f3n relacionada con establecimientos educativos y la carga en la tabla <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>. El flujo asegura que los datos sean validados y transformados antes de insertarse en el destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae los datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>NOMBRE_ESTABLECIMIENTO</code></li> <li><code>REPRESENTANTE_LEGAL</code></li> <li><code>DIRECCION</code></li> <li><code>MUNICIPIO</code></li> </ul> </li> <li>Propiedades:<ul> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_EE</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Datos (Lookup):</p> <ul> <li>Descripci\u00f3n: Busca si los registros ya existen en la tabla <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code> para evitar duplicados.</li> <li>Condiciones de B\u00fasqueda:<ul> <li><code>NOMBRE_ESTABLECIMIENTO</code></li> <li><code>REPRESENTANTE_LEGAL</code></li> <li><code>DIRECCION</code></li> <li><code>MUNICIPIO</code>.</li> </ul> </li> <li>Salida:<ul> <li>Filas coincidentes se eliminan del flujo.</li> <li>Filas no coincidentes contin\u00faan hacia el destino.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos (ADO.NET Destination):</p> <ul> <li>Descripci\u00f3n: Inserta los datos validados y \u00fanicos en la tabla <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>.</li> <li>Columnas de Entrada:<ul> <li><code>NOMBRE_ESTABLECIMIENTO</code></li> <li><code>REPRESENTANTE_LEGAL</code></li> <li><code>DIRECCION</code></li> <li><code>MUNICIPIO</code>.</li> </ul> </li> <li>Propiedades:<ul> <li>BatchSize: 0 (por defecto).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_5","title":"Diagrama de Flujo","text":"<pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n con Lookup]\n    C --&gt;|No Coincide| D[Carga en ADO.NET Destination]\n    C --&gt;|Coincide| E[Descartar Registros]\n    D --&gt; F[Fin]\n    E --&gt; F</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/","title":"08. PROTECCION_FACT","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#proteccion_fact","title":"PROTECCION_FACT","text":"<p>El paquete SSIS \"08-PROTECCION_FACT\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar informaci\u00f3n cr\u00edtica relacionada con operaciones de protecci\u00f3n social, como la caracterizaci\u00f3n de beneficiarios, diagn\u00f3sticos, entregas de materiales y visitas de seguimiento. Este paquete consolida datos de m\u00faltiples fuentes en el Data Warehouse <code>DWH_COMFENALCO</code>, asegurando su calidad, consistencia y disponibilidad para an\u00e1lisis y reportes estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es integrar datos operativos de protecci\u00f3n, garantizando la integridad y estructuraci\u00f3n de la informaci\u00f3n para apoyar an\u00e1lisis avanzados y toma de decisiones en el \u00e1mbito social y educativo.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos </p> <ul> <li>Fuentes Principales: <ul> <li>Archivos Planos:   Se procesan datos desde archivos planos que alimentan las siguientes tablas de hechos: <code>FACT_CARACTERIZACION</code>, <code>FACT_DIAGNOSTICOS_EE_JEC</code>, <code>FACT_ENTREGA_MATERIAL</code>, <code>FACT_VISITAS</code> y <code>FACT_DESERCION</code>.</li> <li>Bases de Datos Relacionales:   Se extrae informaci\u00f3n desde dimensiones y tablas de referencia como <code>DIM_TIEMPO</code>, <code>DIM_POBLACION</code>, <code>DIM_PROGRAMA</code>, <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>, entre otras.</li> </ul> </li> <li>Herramientas y Conexiones:     Se emplean conexiones OLE DB y ADO.NET para la integraci\u00f3n de datos.</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos </p> <ul> <li>Validaciones (<code>Lookup</code>):   Se realizan b\u00fasquedas en tablas maestras para enriquecer los datos de entrada, por ejemplo, en <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code> o <code>DIM_PREGUNTAS_EE_JEC</code>.</li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):   Se garantiza la compatibilidad de los datos al convertir tipos y longitudes seg\u00fan lo requiera el destino.</li> <li>Columnas Derivadas (<code>Derived Column</code>):   Se generan claves \u00fanicas y se asignan valores predefinidos para facilitar la integraci\u00f3n.</li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse </p> <ul> <li>Tablas Procesadas: <ul> <li><code>FACT_CARACTERIZACION</code></li> <li><code>FACT_DIAGNOSTICOS_EE_JEC</code></li> <li><code>FACT_ENTREGA_MATERIAL</code></li> <li><code>FACT_VISITAS</code></li> <li><code>FACT_DESERCION</code></li> </ul> </li> <li>Configuraci\u00f3n de Carga:   Se habilitan las inserciones masivas para optimizar el rendimiento y se aseguran la integridad referencial y la consistencia en la carga de datos.</li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts </p> <ul> <li>Uso de scripts SQL din\u00e1micos para la restauraci\u00f3n de claves for\u00e1neas en esquemas como Transversal, Cedesarrollo, Proteccion y Colegio, garantizando la integridad referencial en el Data Warehouse.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>FACT_CARACTERIZACION: </p> <ul> <li>Columnas clave: <code>ID_POBLACION</code>, <code>ID_PROGRAMA</code>, <code>ID_FECHA</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>FACT_DIAGNOSTICOS_EE_JEC: </p> <ul> <li>Columnas clave: <code>ID_FECHA</code>, <code>ID_PREGUNTA</code>, <code>ID_RESPUESTA</code>, <code>ID_REGISTRO</code>.</li> </ul> </li> <li> <p>FACT_ENTREGA_MATERIAL: </p> <ul> <li>Columnas clave: <code>ID_FECHA_ENTREGA</code>, <code>ID_MATERIAL</code>, <code>ID_PERSONAL</code>, <code>CANTIDAD_MATERIAL</code>.</li> </ul> </li> <li> <p>FACT_VISITAS: </p> <ul> <li>Columnas clave: <code>ID_FECHA</code>, <code>ID_PROGRAMA</code>, <code>MUNICIPIO</code>, <code>FECHA_PLANEADA</code>, <code>FECHA_EJECUTADA</code>.</li> </ul> </li> <li> <p>FACT_DESERCION: </p> <ul> <li>Columnas clave: <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>, <code>ID_POBLACION</code>, <code>ID_FECHA_REGISTRO</code>, <code>PROGRAMA</code>, <code>CAUSA</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Planos\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de dimensiones clave\n    SSIS -&gt;&gt; Excel: Leer datos desde archivos planos\n    SSIS -&gt;&gt; Python: Restaurar claves for\u00e1neas\n    SSIS -&gt;&gt; DWH: Cargar datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-truncar-caracterizacion-stage_area","title":"Componente <code>Truncar Caracterizacion STAGE_AREA</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Este componente es una tarea de tipo Execute SQL Task en SSIS dise\u00f1ada para truncar la tabla <code>[STAGE_AREA].[Transversal].[FACT_CARACTERIZACION_PROTECCION]</code>. El prop\u00f3sito principal es limpiar la tabla en el \u00e1rea de staging antes de cargar nuevos datos, asegurando que no existan registros previos que puedan interferir con el proceso ETL.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#propiedades-del-componente","title":"Propiedades del Componente","text":"<ul> <li> <p>Conexi\u00f3n:   Utiliza la conexi\u00f3n identificada por <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code>.</p> </li> <li> <p>SQL Statement:   Ejecuta la siguiente instrucci\u00f3n SQL:   <pre><code>truncate table [STAGE_AREA].[Transversal].[FACT_CARACTERIZACION_PROTECCION]\n</code></pre></p> </li> <li> <p>Descripci\u00f3n:   \"Tarea Ejecutar SQL\" que se encarga de vaciar la tabla de staging para la caracterizaci\u00f3n de protecci\u00f3n.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Task\n    participant SQL as SQL Server\n\n    SSIS -&gt;&gt; SQL: Ejecuta \"truncate table STAGE_AREA.Transversal.FACT_CARACTERIZACION_PROTECCION\"\n    SQL -&gt;&gt; SQL: Vac\u00eda la tabla</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_caracterizacion-stage_area","title":"Componente <code>Data FACT_CARACTERIZACION STAGE_AREA</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>Este componente forma parte de un flujo ETL en SSIS que procesa la informaci\u00f3n relacionada con la caracterizaci\u00f3n para el entorno de staging. Su objetivo es extraer datos desde un archivo plano, aplicar las transformaciones y conversiones necesarias, y finalmente cargar los datos resultantes en la tabla de destino Transversal.FACT_CARACTERIZACION_PROTECCION dentro del entorno de STAGE_AREA. Esto permite preparar los datos para su posterior integraci\u00f3n y validaci\u00f3n en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source </p> <ul> <li>Descripci\u00f3n:     Extrae datos desde un archivo plano (por ejemplo, CSV) que contiene columnas como DOCUMENTO, PROGRAMA, PREGUNTA, RESPUESTA, OBSERVACIONES, FECHA y TIPO_DOCUMENTO.</li> <li>Propiedades: <ul> <li>RetainNulls: false (no se retienen los valores nulos de origen).</li> <li>No se utiliza una columna para el nombre del archivo.</li> </ul> </li> <li>Salida:     Los datos extra\u00eddos se env\u00edan al siguiente componente para su transformaci\u00f3n.</li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Descripci\u00f3n:     Inserta los datos transformados en la tabla de destino. Se utiliza para cargar la informaci\u00f3n final en la tabla Transversal.FACT_CARACTERIZACION_PROTECCION.</li> <li>Propiedades Clave: <ul> <li>TableOrViewName:   \"Transversal\".\"FACT_CARACTERIZACION_PROTECCION\"</li> <li>BatchSize:   0 (se usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS).</li> <li>CommandTimeout:   30 segundos.</li> <li>UseBulkInsertWhenPossible:   true (habilita la inserci\u00f3n masiva para optimizar el rendimiento).</li> </ul> </li> <li>Conexi\u00f3n:     Se utiliza un administrador de conexiones configurado con el identificador DWH del \u00e1rea de staging.</li> <li>Mapeo de Columnas:     Se asignan columnas provenientes del Flat File Source a las columnas correspondientes del destino. Entre ellas se incluyen DOCUMENTO, PROGRAMA, PREGUNTA, RESPUESTA, OBSERVACIONES, TIPO_DOCUMENTO y FECHA.</li> </ul> </li> <li> <p>Rutas del Flujo de Datos </p> <ul> <li>Se establece una ruta directa desde la salida del Flat File Source hacia la entrada del Destino ADO.NET, lo que indica que todos los datos extra\u00eddos se pasan sin separaci\u00f3n intermedia a la carga final en la tabla de staging.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_caracterizacion","title":"Componente <code>Data FACT_CARACTERIZACION</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>Este componente forma parte de un flujo ETL en SSIS que extrae, transforma y carga datos de caracterizaci\u00f3n. La fuente de datos se define mediante una instrucci\u00f3n SQL que utiliza una CTE para preparar la informaci\u00f3n proveniente de la tabla de staging. Se unen datos de diversas dimensiones (poblaci\u00f3n, programa y campos de caracterizaci\u00f3n) para calcular un identificador de fecha basado en la fecha original. Posteriormente, se filtran los registros para incluir solo aquellos que a\u00fan no se encuentran en la tabla de destino. Finalmente, los datos se cargan en la tabla Proteccion.FACT_CARACTERIZACION en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (caract)</p> <ul> <li>Descripci\u00f3n:     Extrae datos utilizando una instrucci\u00f3n SQL que define una CTE llamada FACT_CARACTERIZACION_PROTECCION. La consulta recupera columnas como FECHA, ID_POBLACION, ID_PROGRAMA, ID_PREGUNTA, RESPUESTA y OBSERVACIONES. Adem\u00e1s, se calcula el identificador de fecha (ID_FECHA) a partir de la fecha, utilizando una concatenaci\u00f3n de a\u00f1o, mes y d\u00eda.</li> <li>Detalle de la Consulta SQL:     La consulta extrae registros de la tabla en el \u00e1rea de staging y realiza LEFT JOIN con las dimensiones DIM_POBLACION, DIM_PROGRAMA y DIM_CAMPOS_CARACT para relacionar la informaci\u00f3n. Finalmente, se seleccionan \u00fanicamente los registros que no tienen coincidencia en la tabla de destino FACT_CARACTERIZACION.</li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n:     Convierte el campo FECHA (extra\u00eddo en formato de cadena) a tipo dbTimeStamp. El resultado se almacena en la columna \"Copy of FECHA\" para garantizar la compatibilidad con el destino.</li> <li>Propiedades Relevantes: <ul> <li>Conversi\u00f3n de FECHA a formato de fecha y hora (dbTimeStamp).</li> <li>Se maneja la disposici\u00f3n de error configurada para abortar el componente en caso de error.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n:     Inserta los datos transformados y convertidos en la tabla de destino Proteccion.FACT_CARACTERIZACION.</li> <li>Propiedades Clave: <ul> <li>TableOrViewName: \"Transversal\".\"FACT_CARACTERIZACION_PROTECCION\" (para staging) o \"Proteccion\".\"FACT_CARACTERIZACION\" (para la carga final, seg\u00fan contexto de integraci\u00f3n).</li> <li>BatchSize: 0 (se utiliza el tama\u00f1o predeterminado del b\u00fafer interno de SSIS).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: true (habilita la inserci\u00f3n masiva para optimizar el rendimiento).</li> </ul> </li> <li>Mapeo de Columnas:     Se mapean columnas clave como ID_FECHA, ID_POBLACION, ID_PROGRAMA, ID_PREGUNTA, RESPUESTA y OBSERVACIONES desde la salida de la transformaci\u00f3n hasta el destino final.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-flujo-del-proceso","title":"Diagrama de Flujo del Proceso","text":"<p>El flujo de procesamiento se puede resumir de la siguiente manera:</p> <pre><code>graph TD\n    A[SQL Data Source] --&gt; B[Data Conversion]\n    B --&gt; C[ADO NET Destination]</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_diagnosticos_ee_jec","title":"Componente <code>Data FACT_DIAGNOSTICOS_EE_JEC</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>Este componente es un flujo de datos (Data Flow Task) de SSIS dise\u00f1ado para procesar y cargar datos relacionados con diagn\u00f3sticos en el entorno educativo (EE) para el m\u00f3dulo JEC. El proceso extrae informaci\u00f3n de un archivo plano, realiza conversiones de datos, aplica varias transformaciones de b\u00fasqueda (Lookup) para enriquecer los datos con claves de dimensiones y hechos, y finalmente carga los registros resultantes en la tabla destino Proteccion.FACT_DIAGNOSTICOS_EE_JEC en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source 1</p> <ul> <li>Descripci\u00f3n:     Extrae datos desde un archivo plano (CSV) utilizando la conexi\u00f3n definida por <code>Csv_Connection_Fact_Diagnosticos_EE_JEC</code>.</li> <li>Columnas de salida:     Incluye campos como:<ul> <li><code>FECHA</code></li> <li><code>PROGRAMA</code></li> <li><code>PREGUNTA</code></li> <li><code>RESPUESTA</code></li> <li><code>ID_REGISTRO</code></li> <li><code>FECHA_HORA_INICIO</code></li> <li><code>FECHA_HORA_FIN</code></li> <li><code>CORREO_FUNCIONARIO</code></li> <li><code>NOMBRE_FUNCIONARIO</code></li> <li><code>TOTAL_PUNTOS</code></li> <li><code>RECTOR</code></li> <li><code>FECHA_ULT_MODIF</code></li> </ul> </li> <li>Errores:     Las filas con errores son redirigidas a la salida de error con informaci\u00f3n adicional en las columnas <code>ErrorCode</code> y <code>ErrorColumn</code>.</li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n:     Convierte los datos extra\u00eddos a los tipos y formatos requeridos para su procesamiento posterior. Por ejemplo, convierte las cadenas que representan fechas en valores del tipo dbTimeStamp y realiza conversiones de texto a tipos num\u00e9ricos cuando es necesario.</li> <li>Columnas Convertidas: <ul> <li><code>ID_REGISTRO</code> se convierte a tipo numeric.</li> <li><code>FECHA_HORA_INICIO</code> y <code>FECHA_HORA_FIN</code> se convierten a tipo dbTimeStamp.</li> <li>Otros campos de texto (como <code>CORREO_FUNCIONARIO</code>, <code>NOMBRE_FUNCIONARIO</code>, <code>TOTAL_PUNTOS</code>, <code>RECTOR</code>, <code>FECHA</code>, <code>RESPUESTA</code>, <code>PREGUNTA</code> y <code>PROGRAMA</code>) se mantienen en formato cadena (wstr) con longitudes definidas.</li> </ul> </li> </ul> </li> <li> <p>Lookup Transformations</p> <ul> <li>Lookup (DIM_TIEMPO):<ul> <li>Descripci\u00f3n:   Realiza una b\u00fasqueda en la dimensi\u00f3n del tiempo para obtener el identificador de fecha (<code>ID_FECHA</code>) usando el valor convertido de la columna Copy of FECHA.</li> <li>SQL de Referencia: <code>SELECT * FROM [Dwh].[DIM_TIEMPO] WHERE FECHA = ?</code></li> </ul> </li> <li>Lookup 1 (DIM_PREGUNTAS_EE_JEC):<ul> <li>Descripci\u00f3n:   Cruza la columna convertida Copy of PREGUNTA con la tabla <code>DIM_PREGUNTAS_EE_JEC</code> para asociar cada registro con su correspondiente <code>ID_PREGUNTA</code>.</li> <li>SQL de Referencia: <code>SELECT * FROM [Proteccion].[DIM_PREGUNTAS_EE_JEC] WHERE PREGUNTA = ?</code></li> </ul> </li> <li>Lookup 2 (DIM_RESPUESTAS_EE_JEC):<ul> <li>Descripci\u00f3n:   Usa las columnas Copy of RESPUESTA y el <code>ID_PREGUNTA</code> obtenido previamente para buscar el <code>ID_RESPUESTA</code> en la tabla <code>DIM_RESPUESTAS_EE_JEC</code>.</li> <li>SQL de Referencia: <code>SELECT * FROM [Proteccion].[DIM_RESPUESTAS_EE_JEC] WHERE RESPUESTA = ? AND ID_PREGUNTA = ?</code></li> </ul> </li> <li>Lookup 3 (FACT_DIAGNOSTICOS_EE_JEC):<ul> <li>Descripci\u00f3n:   Verifica la existencia de registros duplicados en la tabla destino mediante una combinaci\u00f3n de varias columnas (FECHA_HORA_INICIO, FECHA_HORA_FIN, CORREO_FUNCIONARIO, NOMBRE_FUNCIONARIO, TOTAL_PUNTOS, RECTOR, RESPUESTA, ID_PREGUNTA y ID_RESPUESTA). Los registros sin coincidencia se permiten continuar para su inserci\u00f3n.</li> <li>SQL de Referencia:   La consulta compara todas las columnas clave para identificar duplicados.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n:     Inserta los datos transformados y validados en la tabla Proteccion.FACT_DIAGNOSTICOS_EE_JEC.</li> <li>Propiedades Clave: <ul> <li>TableOrViewName: <code>\"Proteccion\".\"FACT_DIAGNOSTICOS_EE_JEC\"</code></li> <li>BatchSize: 0 (usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true (habilita la inserci\u00f3n masiva para optimizar el rendimiento)</li> </ul> </li> <li>Columnas Cargadas:     Se cargan campos como:<ul> <li><code>ID_FECHA</code> (obtenido de Lookup DIM_TIEMPO)</li> <li><code>ID_PREGUNTA</code> (obtenido de Lookup 1)</li> <li><code>ID_RESPUESTA</code> (obtenido de Lookup 2)</li> <li>Adem\u00e1s, se incluyen columnas provenientes de la Data Conversion: Copy of ID_REGISTRO, Copy of FECHA_HORA_INICIO, Copy of FECHA_HORA_FIN, Copy of CORREO_FUNCIONARIO, Copy of NOMBRE_FUNCIONARIO, Copy of TOTAL_PUNTOS, Copy of RECTOR</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-flujo-del-proceso_1","title":"Diagrama de Flujo del Proceso","text":"<p>El proceso se puede resumir de la siguiente manera:</p> <pre><code>graph TD\n    A[Flat File Source] --&gt; B[Data Conversion]\n    B --&gt; C[Lookup: DIM_TIEMPO]\n    C --&gt; D[Lookup 1: DIM_PREGUNTAS_EE_JEC]\n    D --&gt; E[Lookup 2: DIM_RESPUESTAS_EE_JEC]\n    E --&gt; F[Lookup 3: Verificaci\u00f3n de duplicados en FACT_DIAGNOSTICOS_EE_JEC]\n    F --&gt; G[ADO.NET Destination]</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_diagnosticos_ee_aipi","title":"Componente <code>Data FACT_DIAGNOSTICOS_EE_AIPI</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente Data FACT_DIAGNOSTICOS_EE_AIPI es un flujo de datos (Data Flow Task) de SSIS dise\u00f1ado para extraer, transformar y cargar informaci\u00f3n de diagn\u00f3sticos para el m\u00f3dulo EE AIPI. Este proceso parte de un archivo plano que contiene informaci\u00f3n relevante, la cual es convertida a los formatos necesarios, enriquecida mediante varias transformaciones de b\u00fasqueda (Lookup) y, finalmente, insertada en la tabla destino Proteccion.FACT_DIAGNOSTICOS_EE_AIPI en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source</p> <ul> <li>Descripci\u00f3n:     Extrae datos desde un archivo plano delimitado utilizando la conexi\u00f3n configurada (<code>Csv_Connection_Fact_Diagnosticos_EE_AIPI</code>). Las columnas incluidas son:  <ul> <li>ESTABLECIMIENTO EDUCATIVO</li> <li>NOMBRE_SEDE</li> <li>MUNICIPIO</li> <li>ENTIDAD_ADMINISTRADORA</li> <li>DIRECCION</li> <li>FECHA</li> <li>PROGRAMA</li> <li>PREGUNTA</li> <li>RESPUESTA</li> <li>ID_REGISTRO</li> <li>FECHA_HORA_INICIO</li> <li>FECHA_HORA_FIN</li> <li>CORREO_FUNCIONARIO</li> <li>NOMBRE_FUNCIONARIO</li> <li>TOTAL_PUNTOS</li> <li>RECTOR</li> <li>FECHA_ULT_MODIF</li> </ul> </li> <li>Manejo de Errores:     Las filas que presenten errores durante la extracci\u00f3n se redirigen a una salida de error, registrando informaci\u00f3n adicional (por ejemplo, <code>ErrorCode</code> y <code>ErrorColumn</code>).</li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n:     Convierte las columnas extra\u00eddas a los tipos de datos requeridos para el procesamiento posterior. Se crean columnas de copia para asegurar la integridad y compatibilidad de la informaci\u00f3n. Por ejemplo:</li> <li>Columnas Convertidas: <ul> <li>Copy of ESTABLECIMIENTO EDUCATIVO (cadena extendida, wstr, longitud 255)</li> <li>Copy of NOMBRE_SEDE (wstr, longitud 200)</li> <li>Copy of MUNICIPIO (wstr, longitud 255)</li> <li>Copy of ENTIDAD_ADMINISTRADORA (wstr, longitud 255)</li> <li>Copy of DIRECCION (wstr, longitud 300)</li> <li>Copy of FECHA (convertido a dbTimeStamp)</li> <li>Copy of PREGUNTA (wstr, longitud 255)</li> <li>Copy of RESPUESTA (wstr, longitud 255)</li> <li>Otros campos necesarios para el enriquecimiento.</li> </ul> </li> </ul> </li> <li> <p>Transformaciones Lookup</p> <ul> <li>Lookup 1: DIM_ESTABLECIMIENTO_EDUCATIVO<ul> <li>Descripci\u00f3n:   Cruza la columna Copy of ESTABLECIMIENTO EDUCATIVO con la dimensi\u00f3n de establecimientos educativos para obtener el <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>.</li> <li>SQL de Referencia: <code>select * from [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] where NOMBRE_ESTABLECIMIENTO = ?</code></li> </ul> </li> <li>Lookup 2: DIM_PREGUNTAS_EE_AIPI<ul> <li>Descripci\u00f3n:   Utiliza la columna Copy of PREGUNTA para buscar el <code>ID_PREGUNTA</code> en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code>.</li> <li>SQL de Referencia: <code>select * from [Proteccion].[DIM_PREGUNTAS_EE_AIPI] where PREGUNTA = ?</code></li> </ul> </li> <li>Lookup 3: DIM_RESPUESTAS_EE_AIPI<ul> <li>Descripci\u00f3n:   Cruza la columna Copy of RESPUESTA junto con el <code>ID_PREGUNTA</code> obtenido previamente para asociar el registro con el <code>ID_RESPUESTA</code> en la tabla <code>DIM_RESPUESTAS_EE_AIPI</code>.</li> <li>SQL de Referencia: <code>select * from [Proteccion].[DIM_RESPUESTAS_EE_AIPI] where RESPUESTA = ? and ID_PREGUNTA = ?</code></li> </ul> </li> <li>Lookup 4: Validaci\u00f3n de Duplicados<ul> <li>Descripci\u00f3n:   Verifica la existencia de registros duplicados en la tabla destino. Esta transformaci\u00f3n utiliza m\u00faltiples columnas (por ejemplo, Copy of NOMBRE_SEDE, Copy of MUNICIPIO, Copy of ENTIDAD_ADMINISTRADORA, Copy of DIRECCION, Copy of FECHA, Copy of RESPUESTA, <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>, <code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>) para identificar si el registro ya existe en Proteccion.FACT_DIAGNOSTICOS_EE_AIPI.</li> <li>SQL de Referencia:   La consulta se estructura para comparar todas las columnas clave y enviar a la salida de \"No Match\" aquellos registros que no tengan duplicados.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n:     Inserta los datos finales, ya convertidos y enriquecidos, en la tabla Proteccion.FACT_DIAGNOSTICOS_EE_AIPI.</li> <li>Propiedades Clave:<ul> <li>TableOrViewName: <code>\"Proteccion\".\"FACT_DIAGNOSTICOS_EE_AIPI\"</code></li> <li>BatchSize: 0 (usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true</li> </ul> </li> <li>Columnas Cargadas:     Se incluyen columnas provenientes de la Data Conversion y los Lookups, tales como:<ul> <li><code>ID_FECHA</code> (obtenido de Lookup DIM_TIEMPO, si se aplicara)</li> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code></li> <li><code>ID_PREGUNTA</code></li> <li><code>ID_RESPUESTA</code></li> <li>Copy of ID_REGISTRO</li> <li>Copy of FECHA_HORA_INICIO</li> <li>Copy of FECHA_HORA_FIN</li> <li>Copy of CORREO_FUNCIONARIO</li> <li>Copy of NOMBRE_FUNCIONARIO</li> <li>Copy of TOTAL_PUNTOS</li> <li>Copy of RECTOR</li> <li>Entre otros campos relevantes.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-flujo-del-proceso_2","title":"Diagrama de Flujo del Proceso","text":"<p>El proceso general se representa de la siguiente forma:</p> <pre><code>graph TD\n    A[Flat File Source] --&gt; B[Data Conversion]\n    B --&gt; C[Lookup 1: DIM_ESTABLECIMIENTO_EDUCATIVO]\n    C --&gt; D[Lookup 2: DIM_PREGUNTAS_EE_AIPI]\n    D --&gt; E[Lookup 3: DIM_RESPUESTAS_EE_AIPI]\n    E --&gt; F[Lookup 4: Validaci\u00f3n de Duplicados]\n    F --&gt; G[Destino ADO.NET]</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_venta","title":"Componente <code>Data FACT_VENTA</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente Data FACT_VENTA es un Data Flow Task de SSIS que se encarga de extraer, transformar y cargar informaci\u00f3n de ventas en el entorno de protecci\u00f3n. La informaci\u00f3n se obtiene desde un archivo plano (CSV) y se procesa mediante varias transformaciones antes de insertarla en la tabla de destino Proteccion.FACT_VENTA. Este proceso integra la conversi\u00f3n de tipos de datos, el enriquecimiento mediante b\u00fasquedas en tablas de referencia (Lookup) y el uso de transformaciones derivadas para generar nuevos valores, como la asignaci\u00f3n de identificadores y la estandarizaci\u00f3n de campos.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source</p> <ul> <li>Funci\u00f3n:     Extrae los datos desde un archivo plano delimitado. Entre las columnas que se leen se encuentran:<ul> <li>FECHA</li> <li>CODIGO</li> <li>DOCUMENTO</li> <li>NOMBRE_USUARIO</li> <li>CATEGORIA_VENTA</li> <li>SERVICIO</li> <li>TIPO_DOCUMENTO</li> <li>VALOR_PAGADO_SIN_IMP</li> <li>COSTO</li> <li>SUBSIDIO</li> <li>PROGRAMA</li> </ul> </li> <li>Manejo de Errores:     Los registros que presenten problemas durante la extracci\u00f3n se env\u00edan a una salida de error, la cual captura c\u00f3digos y columnas de error para su posterior an\u00e1lisis.</li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Funci\u00f3n:     Convierte las columnas extra\u00eddas a los tipos de datos requeridos para el procesamiento. Por ejemplo, convierte la columna FECHA a un valor de tipo dbTimeStamp y ajusta las longitudes de campos de texto, como DOCUMENTO, NOMBRE_USUARIO, CATEGORIA_VENTA, SERVICIO y TIPO_DOCUMENTO.</li> <li>Resultado:     Se generan columnas \u201cCopy of \u2026\u201d que garantizan que los datos cumplen con el formato esperado en las transformaciones posteriores.</li> </ul> </li> <li> <p>Derived Column (Transformaci\u00f3n Derivada)</p> <ul> <li>Funci\u00f3n:     Crea nuevas columnas o modifica las existentes aplicando expresiones. En este caso, se utiliza para calcular y asignar valores derivados, como la conversi\u00f3n de la categor\u00eda de venta a un c\u00f3digo num\u00e9rico o la extracci\u00f3n del a\u00f1o a partir de la fecha.</li> <li>Ejemplo de Expresi\u00f3n:     Se eval\u00faa la columna de categor\u00eda y, seg\u00fan su valor, se asigna un c\u00f3digo espec\u00edfico (por ejemplo, \u201cA\u201d \u2192 1, \u201cB\u201d \u2192 2, etc.).</li> </ul> </li> <li> <p>Lookup \u2013 Dimensi\u00f3n Tiempo</p> <ul> <li>Funci\u00f3n:     Busca informaci\u00f3n en la dimensi\u00f3n de tiempo (almacenada en la base de datos DWH) utilizando el campo FECHA convertido. De esta forma se obtiene el identificador de fecha (ID_FECHA) que se usar\u00e1 en el registro de ventas.</li> <li>Consulta de Referencia:     Una instrucci\u00f3n SQL que extrae todos los registros de la dimensi\u00f3n de tiempo y filtra aquellos cuyo campo FECHA coincide con el valor procesado.</li> </ul> </li> <li> <p>Lookup \u2013 Dimensi\u00f3n Poblaci\u00f3n</p> <ul> <li>Funci\u00f3n:     Utiliza los campos DOCUMENTO y TIPO_DOCUMENTO (ya convertidos) para buscar y obtener el identificador de poblaci\u00f3n (ID_POBLACION) desde la tabla DIM_POBLACION del esquema Proteccion.</li> <li>Consulta de Referencia:     La instrucci\u00f3n SQL compara DOCUMENTO y TIPO_DOCUMENTO para encontrar la fila correspondiente.</li> </ul> </li> <li> <p>Lookup \u2013 Tarifas de Servicios</p> <ul> <li>Funci\u00f3n:     Consulta la tabla de tarifas de servicios (DIM_TARIFAS_SERVICIOS) del esquema Transversal para recuperar el identificador de tarifa (ID_TARIFA) aplicable al servicio registrado. Esta transformaci\u00f3n utiliza campos como SERVICIO, la categor\u00eda derivada y el a\u00f1o de la fecha.</li> <li>Consulta de Referencia:     Se utiliza una instrucci\u00f3n SQL parametrizada para filtrar la tarifa que corresponda a los datos de entrada.</li> </ul> </li> <li> <p>Lookup \u2013 Verificaci\u00f3n de Duplicados</p> <ul> <li>Funci\u00f3n:     Realiza una b\u00fasqueda en la tabla FACT_VENTA para detectar registros ya existentes. Esta verificaci\u00f3n se realiza comparando campos clave (por ejemplo, FECHA, DOCUMENTO, CATEGORIA_VENTA, SERVICIO, TIPO_DOCUMENTO, ID_POBLACION e ID_TARIFA). Los registros que no tengan coincidencias (es decir, que sean nuevos) se env\u00edan a la salida de \u201cNo Match\u201d, mientras que los duplicados se descartan.</li> <li>Importancia:     Garantiza la integridad de la carga evitando la inserci\u00f3n de registros repetidos.</li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Funci\u00f3n:     Inserta los registros procesados y verificados en la tabla Proteccion.FACT_VENTA.</li> <li>Propiedades Principales:<ul> <li>TableOrViewName: <code>\"Proteccion\".\"FACT_VENTA\"</code></li> <li>BatchSize: 0 (se utiliza el tama\u00f1o de b\u00fafer predeterminado de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true (para mejorar el rendimiento mediante inserciones masivas)</li> </ul> </li> <li>Columnas Cargadas:     Se incluyen campos provenientes de las etapas previas, como el identificador de fecha (ID_FECHA), identificador de poblaci\u00f3n (ID_POBLACION), identificador de tarifa (ID_TARIFA), adem\u00e1s de los campos originales o derivados de la fuente.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#flujo-del-proceso","title":"Flujo del Proceso","text":"<p>El flujo de datos se organiza en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    La fuente (Flat File Source) lee los datos del archivo CSV.</p> </li> <li> <p>Conversi\u00f3n:    La transformaci\u00f3n de Data Conversion ajusta el formato y tipo de datos, generando columnas \u201cCopy of \u2026\u201d.</p> </li> <li> <p>Enriquecimiento y Transformaci\u00f3n: </p> <ul> <li>La transformaci\u00f3n derivada (Derived Column) calcula nuevos valores basados en los datos convertidos.</li> <li>Las transformaciones Lookup consultan las dimensiones de tiempo, poblaci\u00f3n y tarifas, y tambi\u00e9n verifican la existencia de registros duplicados.</li> </ul> </li> <li> <p>Carga:    Finalmente, el componente ADO.NET Destination inserta los datos finales en la tabla Proteccion.FACT_VENTA.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_entrega_material","title":"Componente <code>Data FACT_ENTREGA_MATERIAL</code>","text":"<p>Parte del paquete SSIS que ejecuta un Data Flow Task para el proceso ETL de entrega de material en el entorno de protecci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente Data FACT_ENTREGA_MATERIAL se encarga de extraer datos desde un archivo plano (CSV), transformarlos y finalmente cargarlos en la tabla de destino Proteccion.FACT_ENTREGA_MATERIAL. El proceso incluye la conversi\u00f3n de formatos de datos, enriquecimiento mediante b\u00fasquedas en tablas de referencia (Lookup) y la validaci\u00f3n de la informaci\u00f3n antes de insertarla en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#detalle-de-componentes","title":"Detalle de Componentes","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#1-flat-file-source-1","title":"1. Flat File Source 1","text":"<ul> <li>Funci\u00f3n:   Extrae los datos de un archivo CSV.  </li> <li>Columnas extra\u00eddas: <ul> <li>FECHA_ENTREGA  </li> <li>ID_PERSONAL  </li> <li>ID_MATERIAL  </li> <li>NOMBRE_MATERIAL  </li> <li>TIPO_MATERIAL  </li> <li>CANTIDAD_MATERIAL  </li> <li>VALOR_MATERIAL  </li> <li>TIPO_DOCUMENTO  </li> <li>DOCUMENTO  </li> <li>PROGRAMA  </li> </ul> </li> <li>Manejo de errores:   Las filas con problemas durante la lectura se redirigen a una salida de error, la cual captura informaci\u00f3n sobre el error para su an\u00e1lisis.</li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#2-data-conversion","title":"2. Data Conversion","text":"<ul> <li>Funci\u00f3n:   Convierte los datos de las columnas extra\u00eddas al formato requerido por el proceso.  </li> <li>Columnas convertidas: <ul> <li>Se generan nuevas columnas (prefijadas con \"Copy of \u2026\") para:</li> <li>FECHA_ENTREGA: Convertida a tipo dbTimeStamp </li> <li>TIPO_DOCUMENTO, DOCUMENTO, NOMBRE_MATERIAL, TIPO_MATERIAL, PROGRAMA: Convertidas a cadenas de longitud adecuada  </li> </ul> </li> <li>Importancia:   Garantiza que los datos cumplan con los requisitos de formato y tipo para las siguientes transformaciones y la carga final.</li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#3-lookup","title":"3. Lookup","text":"<p>Se utilizan varias transformaciones Lookup para enriquecer la informaci\u00f3n y relacionarla con datos de referencia:</p> <ul> <li> <p>Lookup (sin n\u00famero): </p> <ul> <li>Funci\u00f3n:   Consulta la dimensi\u00f3n de tiempo (DIM_TIEMPO) para obtener el identificador de fecha (ID_FECHA) basado en la columna FECHA convertida.  </li> <li>Consulta:   Se utiliza una instrucci\u00f3n SQL parametrizada que filtra la dimensi\u00f3n de tiempo seg\u00fan el valor de FECHA.</li> </ul> </li> <li> <p>Lookup 1: </p> <ul> <li>Funci\u00f3n:   Recupera el identificador de programa (ID_PROGRAMA) a partir del valor de PROGRAMA.  </li> <li>Consulta:   La transformaci\u00f3n ejecuta una consulta en la tabla DIM_PROGRAMA del esquema Proteccion, filtrando por el campo PROGRAMA.</li> </ul> </li> <li> <p>Lookup 2: </p> <ul> <li>Funci\u00f3n:   Busca el identificador de poblaci\u00f3n (ID_POBLACION) utilizando los valores TIPO_DOCUMENTO y DOCUMENTO.  </li> <li>Consulta:   Se consulta la tabla DIM_POBLACION de Proteccion, comparando ambos campos para obtener el valor correspondiente.</li> </ul> </li> <li> <p>Lookup 3: </p> <ul> <li>Funci\u00f3n:   Valida y enriquece la informaci\u00f3n final consultando la tabla FACT_ENTREGA_MATERIAL.  </li> <li>Consulta:   Se utiliza una consulta parametrizada que verifica la existencia de un registro en FACT_ENTREGA_MATERIAL usando como filtros FECHA_ENTREGA, NOMBRE_MATERIAL, TIPO_MATERIAL, ID_FECHA, ID_PROGRAMA e ID_POBLACION.  </li> <li>Comportamiento:   Se ha configurado el Lookup para enviar a la salida \u201cNo Match\u201d las filas que no tienen coincidencia, permitiendo la inserci\u00f3n \u00fanicamente de nuevos registros.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#4-destino-adonet-proteccionfact_entrega_material","title":"4. Destino ADO.NET (Proteccion.FACT_ENTREGA_MATERIAL)","text":"<ul> <li>Funci\u00f3n:   Carga los datos finales transformados en la tabla de destino Proteccion.FACT_ENTREGA_MATERIAL.  </li> <li>Propiedades importantes: </li> <li>TableOrViewName: <code>\"Proteccion\".\"FACT_ENTREGA_MATERIAL\"</code> </li> <li>BatchSize: 0 (usa el tama\u00f1o de b\u00fafer predeterminado de SSIS)  </li> <li>CommandTimeout: 30 segundos  </li> <li>UseBulkInsertWhenPossible: true (para inserciones masivas que optimizan el rendimiento)</li> <li>Columnas cargadas:   Se insertan campos provenientes del proceso, entre ellos:  </li> <li>ID_PERSONAL, ID_MATERIAL  </li> <li>Los valores convertidos y enriquecidos, como FECHA_ENTREGA, ID_FECHA, ID_PROGRAMA, ID_POBLACION  </li> <li>Otras columnas con datos relativos al material entregado, como CANTIDAD_MATERIAL y VALOR_MATERIAL</li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#flujo-del-proceso_1","title":"Flujo del Proceso","text":"<p>El proceso ETL en Data FACT_ENTREGA_MATERIAL se estructura en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    El Flat File Source extrae los registros desde el archivo CSV.</p> </li> <li> <p>Conversi\u00f3n:    La transformaci\u00f3n Data Conversion genera versiones convertidas de los campos (por ejemplo, FECHA_ENTREGA a dbTimeStamp) para asegurar la compatibilidad con las transformaciones siguientes.</p> </li> <li> <p>Enriquecimiento y Validaci\u00f3n: </p> </li> <li>Las transformaciones Lookup consultan diferentes tablas de referencia para enriquecer y validar la informaci\u00f3n, verificando datos de tiempo, programa y poblaci\u00f3n.  </li> <li> <p>Se utiliza un Lookup adicional para descartar registros duplicados mediante la verificaci\u00f3n en la tabla de entrega de material.</p> </li> <li> <p>Carga:    Los registros transformados y validados se insertan en la tabla de destino utilizando el componente ADO.NET, con inserciones masivas para un rendimiento \u00f3ptimo.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_visitas","title":"Componente <code>Data FACT_VISITAS</code>","text":"<p>Este Data Flow Task se encarga de procesar informaci\u00f3n relacionada con visitas, realizando la extracci\u00f3n desde un archivo plano, la transformaci\u00f3n (incluida la conversi\u00f3n de datos y el enriquecimiento mediante m\u00faltiples b\u00fasquedas) y la carga en la tabla de destino en el esquema Proteccion.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#resumen-del-proceso","title":"Resumen del Proceso","text":"<p>Objetivo Principal: El flujo procesa registros de visitas, asegurando que los datos se transformen y enriquezcan adecuadamente antes de ser insertados en la tabla de destino Proteccion.FACT_VISITAS en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-clave","title":"Componentes Clave","text":"<ol> <li> <p>Flat File Source </p> <ul> <li>Funci\u00f3n: Extrae datos de un archivo plano (por ejemplo, CSV) con columnas como MUNICIPIO, FECHA_PLANEADA, ID_PERSONAL, PERSONAL, ACTIVIDAD, LUGAR, FECHA_EJECUTADA y PROGRAMA.</li> <li>Errores: Se redirigen a una salida de error en caso de problemas de conversi\u00f3n o lectura.</li> </ul> </li> <li> <p>Data Conversion </p> <ul> <li>Funci\u00f3n: Convierte las columnas extra\u00eddas al formato requerido.  </li> <li>Transformaciones: <ul> <li>Convierte la columna MUNICIPIO a un tipo de dato wstr con una longitud de 40 caracteres.  </li> <li>Convierte FECHA_PLANEADA y FECHA_EJECUTADA a dbTimeStamp, asegurando la correcta interpretaci\u00f3n de las fechas.</li> </ul> </li> <li>Objetivo: Garantizar la compatibilidad de tipos para las siguientes transformaciones y la carga.</li> </ul> </li> <li> <p>Lookup (sin n\u00famero y numerados) </p> <ul> <li>Lookup (general): <ul> <li>Consulta: Realiza una b\u00fasqueda en la dimensi\u00f3n de tiempo (DIM_TIEMPO) del Data Warehouse ([Dwh].[DIM_TIEMPO]), utilizando la fecha (FECHA) como par\u00e1metro para obtener el identificador de fecha (ID_FECHA).</li> </ul> </li> <li>Lookup 1: <ul> <li>Funci\u00f3n: Enriquecer la informaci\u00f3n con el identificador de programa (ID_PROGRAMA) consultando la tabla DIM_PROGRAMA en el esquema Proteccion, bas\u00e1ndose en el valor del campo PROGRAMA.</li> </ul> </li> <li>Lookup 2: <ul> <li>Funci\u00f3n: A trav\u00e9s de la verificaci\u00f3n de la poblaci\u00f3n, se obtiene o valida el identificador de poblaci\u00f3n (ID_POBLACION) mediante la comparaci\u00f3n de columnas (por ejemplo, TIPO_DOCUMENTO y DOCUMENTO) en la tabla DIM_POBLACION.</li> </ul> </li> <li>Manejo de filas sin coincidencia: <ul> <li>Los registros sin coincidencia en el Lookup se env\u00edan a una salida espec\u00edfica (Lookup No Match Output) para ser procesados (por ejemplo, para ser insertados como nuevos registros).</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Funci\u00f3n: Carga los datos finales en la tabla Proteccion.FACT_VISITAS.</li> <li>Propiedades Importantes: <ul> <li>Se utiliza la conexi\u00f3n ADO.NET con configuraci\u00f3n de inserci\u00f3n masiva (UseBulkInsertWhenPossible=true).</li> <li>Se definen propiedades como BatchSize (0, para usar el b\u00fafer interno de SSIS) y CommandTimeout (30 segundos).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#flujo-de-datos","title":"Flujo de Datos","text":"<ol> <li> <p>Extracci\u00f3n:    Los datos se leen desde el archivo plano a trav\u00e9s del componente Flat File Source.</p> </li> <li> <p>Conversi\u00f3n y Preparaci\u00f3n:    La transformaci\u00f3n Data Conversion genera columnas \"Copy of \u2026\" para las variables clave (por ejemplo, FECHA, DOCUMENTO, etc.), asegurando que los formatos sean los adecuados para los procesos posteriores.</p> </li> <li> <p>Enriquecimiento Mediante Lookups: </p> </li> <li>El primer Lookup asocia la fecha con el identificador correspondiente (ID_FECHA).  </li> <li>Lookups adicionales (Lookup 1 y Lookup 2) recuperan y validan el ID_PROGRAMA y el ID_POBLACION, respectivamente.</li> <li> <p>En caso de que alg\u00fan registro ya exista (por ejemplo, para evitar duplicados), el proceso puede redirigirlo a una salida de \u201cno match\u201d o \u201cerror\u201d seg\u00fan la configuraci\u00f3n.</p> </li> <li> <p>Carga:    Finalmente, el componente Destino de ADO NET inserta los datos transformados y enriquecidos en la tabla de destino Proteccion.FACT_VISITAS.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_desercion","title":"Componente <code>Data FACT_DESERCION</code>","text":"<p>Este flujo se encarga de procesar informaci\u00f3n relacionada con la deserci\u00f3n (abandono escolar) y consolidarla en la tabla Proteccion.FACT_DESERCION en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>Prop\u00f3sito: Extraer, transformar y cargar datos de deserci\u00f3n educativa. Los registros se leen desde un archivo plano (por ejemplo, CSV) y se transforman para asegurar la consistencia de la informaci\u00f3n antes de insertarlos en la tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-clave_1","title":"Componentes Clave","text":"<ol> <li> <p>Flat File Source </p> <ul> <li>Funci\u00f3n:     Lee datos de un archivo de texto. Las columnas extra\u00eddas incluyen, entre otras, <code>FECHA_REGISTRO</code>, <code>PROGRAMA</code>, <code>NOMBRE_EE</code>, <code>DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>ANIO_ACADEMICO</code> y <code>CAUSA</code>.</li> <li>Manejo de errores:     Los errores de conversi\u00f3n se redirigen a una salida de error, permitiendo el control y la depuraci\u00f3n de registros con datos inv\u00e1lidos.</li> </ul> </li> <li> <p>Data Conversion </p> <ul> <li>Funci\u00f3n:     Convierte los datos extra\u00eddos a los tipos requeridos para el procesamiento posterior.  </li> <li>Transformaciones espec\u00edficas: <ul> <li>Convierte <code>FECHA_REGISTRO</code> a formato dbTimeStamp.</li> <li>Crea columnas \"Copy of ...\" para <code>PROGRAMA</code>, <code>NOMBRE_EE</code>, <code>DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>ANIO_ACADEMICO</code> y <code>CAUSA</code> en los formatos requeridos.</li> </ul> </li> <li>Objetivo:     Garantizar la correcta transformaci\u00f3n de los datos y la compatibilidad con los siguientes procesos.</li> </ul> </li> <li> <p>Lookup Transformations </p> <ul> <li>Lookup General:     Utiliza la dimensi\u00f3n de tiempo ([Dwh].[DIM_TIEMPO]) para asociar la fecha de registro a su identificador (ID_FECHA). La consulta utiliza la fecha como par\u00e1metro para filtrar el registro correspondiente.</li> <li>Lookup 1:     Busca en la dimensi\u00f3n de programas ([Proteccion].[DIM_PROGRAMA]) para obtener el identificador de programa (ID_PROGRAMA) a partir del campo PROGRAMA.</li> <li>Lookup 2:     Se conecta a la dimensi\u00f3n de establecimientos educativos para asociar el registro con el identificador de establecimiento (ID_ESTABLECIMIENTO_EDUCATIVO).  </li> <li>Lookup 3:     Consulta la dimensi\u00f3n de poblaci\u00f3n ([Proteccion].[DIM_POBLACION]) utilizando el DOCUMENTO y TIPO_DOCUMENTO, lo que permite determinar o validar el identificador de poblaci\u00f3n (ID_POBLACION).</li> <li>Configuraci\u00f3n de manejo de filas sin coincidencia:     Los registros que no encuentran correspondencia en alguna de las b\u00fasquedas se canalizan a una salida de \"no match\", permitiendo su revisi\u00f3n o la inserci\u00f3n de nuevos registros en otras etapas.</li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Funci\u00f3n:     Inserta los datos transformados y enriquecidos en la tabla Proteccion.FACT_DESERCION.</li> <li>Propiedades importantes: <ul> <li>Se utiliza la interfaz ADO.NET con opciones de inserci\u00f3n masiva para optimizar el rendimiento (UseBulkInsertWhenPossible=true).</li> <li>Los par\u00e1metros como BatchSize y CommandTimeout se configuran para asegurar la estabilidad durante la carga.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#flujo-de-datos_1","title":"Flujo de Datos","text":"<ol> <li> <p>Extracci\u00f3n:    Los datos se leen desde el archivo plano mediante el componente Flat File Source.</p> </li> <li> <p>Transformaci\u00f3n: </p> </li> <li>El componente Data Conversion genera versiones convertidas de cada columna (por ejemplo, \"Copy of FECHA_REGISTRO\") para asegurar el formato correcto.</li> <li> <p>Las transformaciones Lookup enriquecen los datos obteniendo identificadores clave (ID_FECHA, ID_PROGRAMA, ID_ESTABLECIMIENTO_EDUCATIVO, ID_POBLACION) a partir de las dimensiones correspondientes.</p> </li> <li> <p>Carga:    Finalmente, el componente Destino de ADO NET inserta los datos procesados en la tabla Proteccion.FACT_DESERCION del Data Warehouse.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_plan_cobertura","title":"Componente <code>Data FACT_PLAN_COBERTURA</code>","text":"<p>Se encarga de extraer, transformar y cargar los datos del plan de cobertura en la tabla Proteccion.FACT_PLAN_COBERTURA.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Objetivo: Integrar y transformar datos relacionados con el plan de cobertura, obtenidos de un archivo Excel, para consolidarlos en la tabla de destino. Los datos incluyen informaci\u00f3n sobre la cobertura proyectada, la l\u00ednea de intervenci\u00f3n, el a\u00f1o y el municipio.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-clave_2","title":"Componentes Clave","text":"<ol> <li> <p>Excel Source </p> <ul> <li>Funci\u00f3n:     Extrae los registros del archivo Excel. Entre las columnas extra\u00eddas se encuentran:<ul> <li>COBERTURA PROYECTADA</li> <li>LINEA DE INTERVENCION</li> <li>ANIO</li> <li>MUNICIPIO</li> <li>Adem\u00e1s, se incluyen otras columnas de soporte (por ejemplo, INSTTITUCIONES EDUCATIVAS) para la realizaci\u00f3n de b\u00fasquedas posteriores.</li> </ul> </li> <li>Detalles:     Utiliza la hoja \"Sheet1$\" y extrae las columnas con los datos originales.</li> </ul> </li> <li> <p>Data Conversion </p> <ul> <li>Funci\u00f3n:     Convierte las columnas extra\u00eddas a los formatos adecuados para las transformaciones y la carga en el destino.  </li> <li>Transformaciones realizadas: <ul> <li>Crea columnas \"Copy of ...\" para cada uno de los campos relevantes:</li> <li>Copy of COBERTURA PROYECTADA</li> <li>Copy of LINEA DE INTERVENCION</li> <li>Copy of ANIO</li> <li>Copy of MUNICIPIO</li> </ul> </li> <li>Objetivo:     Asegurar que los datos tengan el tipo y la longitud correcta para las siguientes etapas del proceso.</li> </ul> </li> <li> <p>Lookup Transformations    Se utilizan varios Lookups para enriquecer y validar la informaci\u00f3n:</p> <ul> <li>Lookup:     Consulta la dimensi\u00f3n de tiempo ([Dwh].[DIM_TIEMPO]) para obtener el identificador de fecha (ID_FECHA) a partir de la fecha extra\u00edda.</li> <li>Lookup 1:     Se conecta a la dimensi\u00f3n de programas ([Proteccion].[DIM_PROGRAMA]) para obtener el identificador de programa (ID_PROGRAMA) a partir del campo PROGRAMA.</li> <li>Lookup 2:     Valida y/o obtiene datos de establecimientos educativos o de otros dominios para complementar el registro (por ejemplo, utilizando los campos MUNICIPIO, LINEA DE INTERVENCION, COBERTURA PROYECTADA y ANIO para verificar la existencia de un registro similar en el destino).</li> <li>Configuraci\u00f3n:     Cada transformaci\u00f3n de Lookup utiliza par\u00e1metros basados en las columnas convertidas para unir los datos y, en caso de no encontrar coincidencia, canaliza los registros a una salida \"no match\" para su revisi\u00f3n.</li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Funci\u00f3n:     Inserta los datos transformados y enriquecidos en la tabla Proteccion.FACT_PLAN_COBERTURA.</li> <li>Configuraci\u00f3n:     Se utiliza la interfaz ADO.NET con opciones de inserci\u00f3n masiva (UseBulkInsertWhenPossible activado) para optimizar el rendimiento. Adem\u00e1s, se configuran par\u00e1metros como BatchSize y CommandTimeout para asegurar una carga eficiente y confiable.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-tarea-ep-prs-04","title":"Componente <code>Tarea EP-PRS-04</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-PRS-04 es una Execute Process Task en SSIS dise\u00f1ada para ejecutar un script Python desde el entorno local. Su principal objetivo es ejecutar el archivo <code>download.py</code> con un par\u00e1metro clave espec\u00edfico (<code>--key EP-PRS-04</code>) dentro del entorno de trabajo configurado para la automatizaci\u00f3n del proceso.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#propiedades-del-componente_1","title":"Propiedades del Componente","text":"<ul> <li> <p>Comandos y Variables:</p> <ul> <li>Executable: Utiliza la variable <code>@[$Project::Python_Executable]</code>, que apunta al ejecutable de Python configurado para la ejecuci\u00f3n del script.</li> <li>Working Directory: El directorio de trabajo est\u00e1 configurado con la variable <code>@[$Project::Working_Directory]</code>, concatenando la ruta a los scripts espec\u00edficos dentro de la estructura del proyecto.</li> <li>Arguments: Se pasa el argumento <code>download.py --key EP-PRS-04</code>, que indica la ejecuci\u00f3n del script con la clave definida.</li> </ul> </li> <li> <p>Descripci\u00f3n:</p> <ul> <li>La tarea ejecuta el proceso externo <code>python.exe</code> para correr el script <code>download.py</code> en el entorno de trabajo proporcionado.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#detalles-del-componente","title":"Detalles del Componente","text":"<ul> <li> <p>Executable:</p> <ul> <li><code>@[$Project::Python_Executable]</code> - Esta expresi\u00f3n hace referencia a la ruta del ejecutable de Python configurado en el proyecto, que podr\u00eda variar dependiendo del entorno de despliegue.</li> </ul> </li> <li> <p>WorkingDirectory:</p> <ul> <li><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> - Define el directorio en el que se ejecutar\u00e1 el script Python. Este directorio debe contener el script <code>download.py</code> y el entorno de ejecuci\u00f3n.</li> </ul> </li> <li> <p>Arguments:</p> <ul> <li><code>\"download.py --key EP-PRS-04\"</code> - Especifica el nombre del archivo Python a ejecutar junto con el argumento <code>--key</code>, el cual est\u00e1 vinculado a un par\u00e1metro que define el comportamiento o los datos de entrada del script.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-truncar-cobertura-adulto-y-discapacidad","title":"Componente <code>Truncar Cobertura Adulto y Discapacidad</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>La tarea Truncar Cobertura Adulto y Discapacidad STAGE_AREA es un Execute SQL Task en SSIS dise\u00f1ado para truncar la tabla [STAGE_AREA].[Transversal].[STG_PLAN_COBERTURA_ADULTO_DISCAPACIDAD]. Su prop\u00f3sito principal es limpiar los datos existentes en esta tabla dentro del \u00e1rea de staging antes de realizar un proceso de carga de nuevos datos. Este paso garantiza que los registros anteriores no interfieran con la actualizaci\u00f3n o inserci\u00f3n de nuevos datos.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#propiedades-del-componente_2","title":"Propiedades del Componente","text":"<ul> <li> <p>Conexi\u00f3n:</p> <ul> <li>La tarea utiliza la conexi\u00f3n identificada por <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code>. Esta conexi\u00f3n est\u00e1 configurada para acceder a la base de datos de staging.</li> </ul> </li> <li> <p>Comando SQL:</p> <ul> <li>SQL Statement: La instrucci\u00f3n SQL que se ejecuta es:</li> </ul> <pre><code>truncate table [STAGE_AREA].[Transversal].[STG_PLAN_COBERTURA_ADULTO_DISCAPACIDAD]\n</code></pre> </li> <li> <p>Descripci\u00f3n:</p> <ul> <li>Esta tarea ejecuta un comando SQL para vaciar la tabla STG_PLAN_COBERTURA_ADULTO_DISCAPACIDAD en el \u00e1rea de staging, eliminando todos los registros existentes.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#detalles-del-componente_1","title":"Detalles del Componente","text":"<ul> <li> <p>SQL Statement Source:</p> <ul> <li>La instrucci\u00f3n SQL que se ejecuta es el comando truncate para la tabla STG_PLAN_COBERTURA_ADULTO_DISCAPACIDAD. Este comando elimina todos los registros de la tabla de manera eficiente, sin generar un log completo de las eliminaciones, lo que mejora el rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_plan_cobertura_adulto_discapacidad","title":"Componente <code>Data FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>La tarea Data FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD es un Data Flow Task de SSIS que se encarga de extraer datos desde la tabla de staging STG_PLAN_COBERTURA_ADULTO_DISCAPACIDAD en el esquema Transversal, transformarlos y luego cargarlos en la tabla de hechos FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD dentro del esquema Proteccion en el Data Warehouse. El objetivo principal es consolidar los datos de cobertura para adultos y personas con discapacidad.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen de ADO.NET</p> <ul> <li>Descripci\u00f3n:   Este componente extrae datos de la tabla de staging STG_PLAN_COBERTURA_ADULTO_DISCAPACIDAD. Se ejecuta una consulta SQL que recupera los datos necesarios y filtra aquellos que ya existen en la tabla de hechos FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD.</li> <li>Consulta SQL:</li> </ul> <p><pre><code>SELECT spd.[ANIO], spd.[COD_INFRAESTRUCTURA_CCF], spd.[SERVICIO], \n        spd.[CATEGORIA_CCF], spd.[NUM_PERSONAS_COBERTURA_SERVICIOS], \n        spd.[MES_PROYECTADO], 4 AS ID_UNIDAD, \n        CASE WHEN spd.[SERVICIO] = 26 THEN 2 ELSE 1 END AS ID_PROGRAMA,\n        CAST(spd.ANIO AS INT) * 10000 + CAST(spd.MES_PROYECTADO AS INT) * 100 + 1 AS ID_FECHA\nFROM [STAGE_AREA].[Transversal].[STG_PLAN_COBERTURA_ADULTO_DISCAPACIDAD] spd\nLEFT JOIN [DWH_COMFENALCO].[Proteccion].[FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD] fp \n    ON spd.[ANIO] = fp.[ANIO] \n    AND spd.[MES_PROYECTADO] = fp.MES_PROYECTADO\n    AND spd.COD_INFRAESTRUCTURA_CCF = fp.COD_INFRAESTRUCTURA_CCF\n    AND spd.[SERVICIO] = fp.[SERVICIO] \n    AND spd.CATEGORIA_CCF = fp.[CATEGORIA_CCF]\nWHERE fp.ID_REGISTRO IS NULL\n</code></pre> * Propiedades Clave:</p> <ul> <li>CommandTimeout: 30 segundos</li> <li>AllowImplicitStringConversion: true (permitir la conversi\u00f3n impl\u00edcita a cadenas)</li> <li>AccessMode: 2 (modo de recuperaci\u00f3n de informaci\u00f3n)</li> </ul> </li> <li> <p>Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n:   Este componente carga los datos transformados en la tabla de hechos FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD. Utiliza el componente ADO.NET para realizar la carga eficiente de datos, habilitando la opci\u00f3n de inserciones masivas para optimizar el rendimiento.</li> <li> <p>Propiedades Clave:</p> </li> <li> <p>TableOrViewName: <code>\"Proteccion\".\"FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD\"</code></p> </li> <li>BatchSize: 0 (tama\u00f1o de lote predeterminado, usa el tama\u00f1o del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true (habilita inserciones masivas)</li> </ul> </li> <li> <p>Conexi\u00f3n:</p> <ul> <li>IDbConnection: Se utiliza una conexi\u00f3n administrada a la base de datos DWH_COMFENALCO para la carga de datos en la tabla de hechos.</li> </ul> </li> <li> <p>Flujo de Datos:</p> <ul> <li>Los datos extra\u00eddos desde la consulta SQL se transforman y cargan en la tabla FACT_PLAN_COBERTURA_ADULTO_DISCAPACITADA. Las columnas clave de la tabla de origen (como ANIO, COD_INFRAESTRUCTURA_CCF, SERVICIO, CATEGORIA_CCF, NUM_PERSONAS_COBERTURA_SERVICIOS, MES_PROYECTADO, ID_UNIDAD, ID_PROGRAMA, ID_FECHA) son mapeadas y transferidas al destino.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-detallada-de-los-componentes-del-flujo","title":"Descripci\u00f3n Detallada de los Componentes del Flujo","text":"<ol> <li> <p>Origen de ADO.NET:</p> <ul> <li>Extracci\u00f3n de Datos: El componente Origen de ADO.NET usa la consulta SQL especificada para obtener los datos de la tabla de staging STG_PLAN_COBERTURA_ADULTO_DISCAPACITADA. Se filtran aquellos registros que ya est\u00e1n presentes en la tabla de hechos FACT_PLAN_COBERTURA_ADULTO_DISCAPACITADA para evitar duplicados.</li> <li> <p>Destino de ADO.NET:</p> </li> <li> <p>Carga de Datos: Los datos extra\u00eddos y transformados se cargan en la tabla FACT_PLAN_COBERTURA_ADULTO_DISCAPACITADA. El proceso de carga se optimiza mediante la inserci\u00f3n masiva de datos.</p> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-restaurar-llaves-foraneas","title":"Componente <code>Restaurar llaves foraneas</code>","text":"<p>Esta tarea de ejecuci\u00f3n SQL en SSIS, dise\u00f1ada para restaurar las restricciones de claves for\u00e1neas en distintos esquemas de la base de datos. A continuaci\u00f3n se describe el proceso:</p> <p>Objetivo: Restaurar las restricciones de claves for\u00e1neas que fueron previamente removidas o almacenadas de forma persistente, utilizando scripts SQL generados din\u00e1micamente para cada esquema (Transversal, Cedesarrollo, Proteccion y Colegio).</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#detalles-del-proceso","title":"Detalles del Proceso","text":"<ol> <li> <p>Generaci\u00f3n Din\u00e1mica de SQL:    Para cada esquema, se construye una instrucci\u00f3n SQL din\u00e1mica que:</p> <ul> <li>Utiliza un bucle (a trav\u00e9s de una agregaci\u00f3n en la consulta) para recorrer la tabla persistente correspondiente (por ejemplo, <code>dbo.ForeignKeys_Transversal</code>).</li> <li>Para cada restricci\u00f3n, se arma un comando <code>ALTER TABLE</code> que intenta agregar la clave for\u00e1nea usando <code>BEGIN TRY...END TRY</code> y <code>BEGIN CATCH...END CATCH</code> para capturar y notificar cualquier error (por ejemplo, si la constraint no puede agregarse).</li> </ul> </li> <li> <p>Ejecuci\u00f3n de las Instrucciones:    Una vez generadas las cadenas SQL para cada esquema, se ejecutan mediante la instrucci\u00f3n <code>EXEC sp_executesql</code> para restaurar las restricciones.</p> </li> <li> <p>Limpieza (Opcional):    Las l\u00edneas comentadas indican que, de ser necesario, se puede eliminar la tabla persistente con las definiciones de las llaves for\u00e1neas (<code>DROP TABLE dbo.ForeignKeys_&lt;Esquema&gt;</code>).</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#esquemas-procesados","title":"Esquemas Procesados","text":"<ul> <li>Transversal: Se restauran las restricciones definidas en la tabla <code>dbo.ForeignKeys_Transversal</code>.</li> <li>Cedesarrollo: Se restauran las restricciones definidas en la tabla <code>dbo.ForeignKeys_Cedesarrollo</code>, determinando din\u00e1micamente el esquema de referencia (Transversal, Dwh o Cedesarrollo) seg\u00fan la tabla de referencia.</li> <li>Proteccion: Se restauran las restricciones definidas en la tabla <code>dbo.ForeignKeys_Proteccion</code>, utilizando una l\u00f3gica similar para determinar el esquema de referencia.</li> <li>Colegio: Se restauran las restricciones definidas en la tabla <code>dbo.ForeignKeys_Colegio</code>, asignando el esquema adecuado (Transversal, Dwh o Colegio).</li> </ul>"},{"location":"02.Paquetes_SSIS/09-ETLS_CUBO/","title":"09. ETLS_CUBO","text":""},{"location":"02.Paquetes_SSIS/09-ETLS_CUBO/#etls-cubo","title":"ETLS CUBO","text":"<p>El paquete SSIS \"ETLS CUBO\" est\u00e1 dise\u00f1ado para gestionar procesos ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) enfocados en datos transversales y financieros. Este paquete asegura la correcta preparaci\u00f3n de tablas, la consolidaci\u00f3n de datos y la integraci\u00f3n eficiente en el Data Warehouse <code>DWH_COMFENALCO</code>, proporcionando una base s\u00f3lida para an\u00e1lisis y generaci\u00f3n de reportes.</p> <p>ETL PAQUETE 09</p>"},{"location":"03.Cubo/00.Introduccion/","title":"Introducci\u00f3n","text":""},{"location":"03.Cubo/00.Introduccion/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El cubo desarrollado en SSIS (SQL Server Integration Services) es una soluci\u00f3n anal\u00edtica dise\u00f1ada para procesar, consolidar y estructurar datos de m\u00faltiples fuentes dentro de un modelo sem\u00e1ntico. Este modelo permite realizar an\u00e1lisis multidimensionales, facilitando la toma de decisiones estrat\u00e9gicas y operativas mediante m\u00e9tricas clave, segmentaciones, y relaciones entre diversas dimensiones y hechos.</p> <p>El cubo integra datos desde un Data Warehouse centralizado, asegurando consistencia y eficiencia en la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de informaci\u00f3n. Este enfoque proporciona una vista consolidada y anal\u00edtica de los datos organizacionales.</p>"},{"location":"03.Cubo/00.Introduccion/#objetivos-del-cubo","title":"Objetivos del Cubo","text":"<p>1. Consolidaci\u00f3n de Datos:</p> <ul> <li>Unificar informaci\u00f3n procedente de diferentes tablas y dimensiones.</li> <li>Proveer datos consistentes para el an\u00e1lisis organizacional.</li> </ul> <p>2. An\u00e1lisis Multidimensional:</p> <ul> <li>Facilitar la creaci\u00f3n de reportes din\u00e1micos y visualizaciones anal\u00edticas.</li> <li>Permitir el desglose de informaci\u00f3n por jerarqu\u00edas, periodos y categor\u00edas.</li> </ul> <p>3. Optimizaci\u00f3n de Decisiones:</p> <ul> <li>Proveer m\u00e9tricas clave como ingresos, aportes, cobertura, y desempe\u00f1o.</li> <li>Ayudar en la identificaci\u00f3n de tendencias y oportunidades de mejora.</li> </ul>"},{"location":"03.Cubo/00.Introduccion/#principales-componentes-del-cubo","title":"Principales Componentes del Cubo","text":"<p>1. Dimensiones:</p> <ul> <li>Representan las jerarqu\u00edas y atributos que permiten segmentar y analizar los datos.</li> <li>Ejemplo: DIM_UNIDAD, DIM_TIEMPO_MENSUAL, y DIM_CATEGORIA.</li> </ul> <p>2. Hechos:</p> <ul> <li>Contienen los datos medibles y m\u00e9tricas clave para el an\u00e1lisis.</li> <li>Ejemplo: FACT_ACTIVIDADES, FACT_PERSONAL, y FACT_FINANCIERA.</li> </ul> <p>3. Relaciones:</p> <ul> <li>Definen c\u00f3mo las dimensiones y los hechos interact\u00faan entre s\u00ed.</li> <li>Aseguran consistencia y precisi\u00f3n en el modelo.</li> </ul> <p>4. Medidas:</p> <ul> <li>Proveen c\u00e1lculos predefinidos como sumas, promedios y conteos.</li> <li>Ejemplo: # Empresas Afiliadas Caja, Valor Aportes Totales.</li> </ul>"},{"location":"03.Cubo/00.Introduccion/#beneficios-del-cubo","title":"Beneficios del Cubo","text":"<p>1. Agilidad Anal\u00edtica:</p> <ul> <li>Generaci\u00f3n r\u00e1pida de informes para diversas \u00e1reas de la organizaci\u00f3n.</li> <li>Reducci\u00f3n de tiempos en la obtenci\u00f3n y an\u00e1lisis de datos.</li> </ul> <p>2. Consistencia y Calidad de Datos:</p> <ul> <li>Integraci\u00f3n de datos con controles de calidad y validaciones.</li> <li>Centralizaci\u00f3n de la informaci\u00f3n para evitar duplicidades o inconsistencias.</li> </ul> <p>3. Escalabilidad:</p> <ul> <li>Capacidad de adaptarse a nuevas necesidades de negocio a\u00f1adiendo dimensiones, hechos o medidas.</li> </ul> <p>4. Decisiones Basadas en Datos:</p> <ul> <li>Facilitaci\u00f3n de insights clave para la toma de decisiones fundamentadas.</li> </ul>"},{"location":"03.Cubo/00.Introduccion/#vista-del-modelo","title":"Vista del modelo","text":""},{"location":"03.Cubo/00.Introduccion/#diagrama-de-relaciones-y-tablas","title":"Diagrama de Relaciones y Tablas","text":"<pre><code>graph TD\n    FACT_ACTIVIDADES[Transversal FACT_ACTIVIDADES]\n    FACT_PERSONAL[Transversal FACT_PERSONAL]\n    FACT_FINANCIERA[Transversal FACT_FINANCIERA]\n    FACT_EVALUACION_DOCENTE[Transversal FACT_EVALUACION_DOCENTE]\n    DIM_UNIDAD[Transversal DIM_UNIDAD]\n    DIM_CATEGORIA[Transversal DIM_CATEGORIA]\n    DIM_TIEMPO[Transversal DIM_TIEMPO_MENSUAL]\n\n    FACT_ACTIVIDADES --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_ACTIVIDADES --&gt; DIM_CATEGORIA[ID_CATEGORIA]\n    FACT_ACTIVIDADES --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_FINANCIERA --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_TIEMPO[ID_FECHA]</code></pre>"},{"location":"03.Cubo/01.Origen/","title":"01. ORIGEN Y MEDIDAS","text":""},{"location":"03.Cubo/01.Origen/#origen-de-datos-del-cubo","title":"Origen de Datos del Cubo","text":""},{"location":"03.Cubo/01.Origen/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El origen de datos es un componente estructurado que conecta el cubo de SSIS con el Data Warehouse principal. Esta conexi\u00f3n permite la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos necesarios para las operaciones anal\u00edticas.</p>"},{"location":"03.Cubo/01.Origen/#detalles-de-configuracion","title":"Detalles de Configuraci\u00f3n","text":"<p>1. Tipo de Origen: </p> <ul> <li>Estructurado (<code>structured</code>).</li> </ul> <p>2. Nombre del Origen:</p> <ul> <li><code>SQL/10 5 21 29\\\\bi;DWH_COMFENALCO</code>.</li> </ul> <p>3. Detalles de Conexi\u00f3n:</p> <ul> <li>Protocolo: <code>tds</code> (Tabular Data Stream, utilizado para bases de datos SQL Server).</li> <li>Direcci\u00f3n:<ul> <li>Servidor: <code>10.5.21.29\\bi</code>.</li> <li>Base de Datos: <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ul> <p>4. Autenticaci\u00f3n:</p> <ul> <li>Tipo: <code>UsernamePassword</code>.</li> <li>Usuario: <code>prov_quality2</code>.</li> <li>Conexi\u00f3n encriptada: <code>false</code>.</li> </ul> <p>5. Credenciales:</p> <ul> <li>Ruta: <code>10.5.21.29\\\\bi;DWH_COMFENALCO</code>.</li> <li>Cifrado: No aplica (<code>EncryptConnection: false</code>).</li> </ul>"},{"location":"03.Cubo/01.Origen/#proposito","title":"Prop\u00f3sito","text":"<p>El origen de datos garantiza la conectividad y el acceso a las tablas y medidas necesarias para el funcionamiento del cubo. Este origen permite a los paquetes de SSIS consumir datos directamente desde el DWH para su an\u00e1lisis y explotaci\u00f3n.</p>"},{"location":"03.Cubo/01.Origen/#medidas","title":"Medidas","text":""},{"location":"03.Cubo/01.Origen/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tabla Medidas contiene columnas calculadas y una serie de medidas configuradas para realizar an\u00e1lisis y c\u00e1lculos dentro del cubo. Estas medidas se utilizan para analizar datos clave y generar m\u00e9tricas significativas para la toma de decisiones.</p>"},{"location":"03.Cubo/01.Origen/#estructura","title":"Estructura","text":"<p>Cada medida calculada se describe brevemente, indicando su objetivo, la l\u00f3gica DAX utilizada y (donde aplica) el formato de salida.</p>"},{"location":"03.Cubo/01.Origen/#unidades","title":"# Unidades","text":"<ul> <li> <p>Objetivo:   Contar el n\u00famero de unidades distintas en la tabla <code>Transversal DIM_UNIDAD</code>, excluyendo aquellas con ID igual a 5.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    DISTINCTCOUNT('Transversal DIM_UNIDAD'[ID_UNIDAD]), \n    'Transversal DIM_UNIDAD'[ID_UNIDAD] &lt;&gt; 5\n)\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#empresas-afiliadas-caja","title":"# Empresas Afiliadas Caja","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de empresas afiliadas a la caja de compensaci\u00f3n, considerando filtros de unidad seg\u00fan corresponda.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR EmpresasCalculo = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n    )\n\nVAR EmpresasCalculoSinFiltros = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD'), \n        REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 3,4}, \n    EmpresasCalculoSinFiltros,\n    EmpresasCalculo\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)   \n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#afiliados-caja","title":"# Afiliados Caja","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de personas afiliadas a la caja de compensaci\u00f3n, diferenciando seg\u00fan filtros aplicados por unidad o sin filtros para ciertas unidades espec\u00edficas.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR AfiliadosCalculo = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n    )\n\nVAR AfiliadosCalculoSinFiltros = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD'), \n        REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 3,4}, \n    AfiliadosCalculoSinFiltros,\n    AfiliadosCalculo\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)   \n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#beneficiarios-caja","title":"# Beneficiarios Caja","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de beneficiarios afiliados a la caja de compensaci\u00f3n, ajustando el c\u00e1lculo seg\u00fan la unidad seleccionada o removiendo filtros cuando aplique.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR BeneficiariosCalculo = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n    )\n\nVAR BeneficiariosCalculoSinFiltros = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD'), \n        REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 3,4}, \n    BeneficiariosCalculoSinFiltros,\n    BeneficiariosCalculo\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)   \n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#aportes-totales","title":"# Aportes Totales","text":"<ul> <li> <p>Objetivo:   Calcular la suma total de los aportes registrados en la actividad \"APORTES\", ajustando el c\u00e1lculo seg\u00fan la unidad seleccionada, con o sin filtros.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR AportesCalculo = \n    CALCULATE(\n        SUM('Transversal FACT_ACTIVIDADES'[NUMERO_APORTES]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"APORTES\"\n    )\n\nVAR AportesCalculoSinFiltros = \n    CALCULATE(\n        SUM('Transversal FACT_ACTIVIDADES'[NUMERO_APORTES]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"APORTES\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD])  IN {1, 2,3, 4}, \n    AportesCalculoSinFiltros,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) = 5, \n    AportesCalculo,\n    AportesCalculo\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#valor-aportes-totales","title":"Valor Aportes Totales","text":"<ul> <li> <p>Objetivo:   Calcular el valor monetario total de los aportes realizados en la actividad \"APORTES\", ajustando el resultado seg\u00fan la unidad seleccionada.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR AportesCalculo = \n    CALCULATE(\n        SUM('Transversal FACT_ACTIVIDADES'[TOTAL_APORTES]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"APORTES\"\n    )\n\nVAR AportesCalculoSinFiltros = \n    CALCULATE(\n        SUM('Transversal FACT_ACTIVIDADES'[TOTAL_APORTES]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"APORTES\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD])  IN {1, 2,3, 4}, \n    AportesCalculoSinFiltros,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) = 5, \n    AportesCalculo,\n    AportesCalculo\n)\n\nreturn IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#empresas_atendidas","title":"#Empresas_Atendidas","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de empresas atendidas exclusivamente para la unidad con ID igual a 3, devolviendo cero para otras unidades.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR EmpresasAtendidas =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER_EMPRESA]), \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 3, \n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2,4}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, EmpresasAtendidas,\n    EmpresasAtendidas\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)  \n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#afiliados_atendidos","title":"#Afiliados_Atendidos","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de afiliados atendidos, excluyendo registros con unidad igual a 5 o sin valor, y devolviendo cero para ciertas unidades espec\u00edficas.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR AfiliadosAtendidos =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n    )\n\nVAR dev = \nSWITCH(\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 3}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2}, AfiliadosAtendidos,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4}, AfiliadosAtendidos,\n    AfiliadosAtendidos\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)  \n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#beneficiarios_atendidos","title":"#Beneficiarios_Atendidos","text":"<ul> <li> <p>Objetivo:   Calcular el total de beneficiarios atendidos, considerando tanto beneficiarios formales como poblaci\u00f3n no afiliada, y aplicando l\u00f3gicas distintas seg\u00fan la unidad seleccionada.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR BeneficiariosAtendidos =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n    )\n\nVAR BeneficiariosAtendidosColegio =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR PoblacionNoAfiliada =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n    )\n\nVAR PoblacionNoAfiliadaColegio =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1}, BeneficiariosAtendidosColegio + PoblacionNoAfiliadaColegio,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2}, BeneficiariosAtendidos + PoblacionNoAfiliada,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4}, BeneficiariosAtendidos + PoblacionNoAfiliada,\n    BeneficiariosAtendidos\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cumplimiento_cobertura","title":"Cumplimiento_Cobertura","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de cumplimiento de la cobertura, dividiendo la cobertura ejecutada sobre la cobertura proyectada. Si la cobertura proyectada es cero, retorna BLANK() para evitar divisi\u00f3n inv\u00e1lida.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>IF([Cobertura proyectada] = 0 , BLANK() , \n  [Cobertura ejecutada] / [Cobertura proyectada]\n)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cantidad_usos","title":"Cantidad_Usos","text":"<ul> <li> <p>Objetivo:   Contar la cantidad total de registros de actividades realizadas, excluyendo aquellas asociadas a la unidad 5 o sin unidad definida.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    COUNT('Transversal FACT_ACTIVIDADES'[ACTIVIDAD]),\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n)\nreturn IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cantidad_aportes_totales","title":"Cantidad_Aportes_Totales","text":"<ul> <li> <p>Objetivo:   Referenciar directamente el valor calculado en la medida <code># Aportes Totales</code>.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>[# Aportes Totales]\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#valor_aportes_totales","title":"Valor_Aportes_Totales","text":"<ul> <li> <p>Objetivo:   Referenciar directamente el valor monetario calculado en la medida <code>Valor Aportes Totales</code>.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>[Valor Aportes Totales]\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cantidad-de-aportes-empresas-atendidas-educacion","title":"Cantidad de aportes empresas atendidas Educacion","text":"<ul> <li> <p>Objetivo:   Calcular la cantidad total de aportes realizados por empresas atendidas en el contexto educativo, aplicando filtros espec\u00edficos de tipo de poblaci\u00f3n educativa seg\u00fan la unidad seleccionada.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1},\n        CALCULATE([# Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_FORMAL] = \"SI\"),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2},\n        CALCULATE([# Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_TECNICA] = \"SI\"),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3},\n        CALCULATE([# Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_CONTINUA] = \"SI\"),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4},\n        CALCULATE([# Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_PROTECCION] = \"SI\"),\n    CALCULATE([# Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION] = \"SI\")\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#valor-de-aportes-empresas-atendidas-educacion","title":"Valor de aportes empresas atendidas Educacion","text":"<ul> <li> <p>Objetivo:   Calcular el valor total de aportes realizados por empresas atendidas en el contexto educativo, aplicando filtros espec\u00edficos seg\u00fan el tipo de poblaci\u00f3n educativa y la unidad seleccionada.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1},\n        CALCULATE([Valor Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_FORMAL] = \"SI\"),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2},\n        CALCULATE([Valor Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_TECNICA] = \"SI\"),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3},\n        CALCULATE([Valor Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_CONTINUA] = \"SI\"),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4},\n        CALCULATE([Valor Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_PROTECCION] = \"SI\"),\n    CALCULATE([Valor Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION] = \"SI\")\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev) \n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cantidad-de-subsidio-a-la-demand","title":"Cantidad de subsidio a la demand","text":"<ul> <li> <p>Objetivo:   Calcular la cantidad total de subsidios entregados a la demanda, diferenciando entre subsidios directos y subsidios aplicados a facturaci\u00f3n de matr\u00edculas, dependiendo de la unidad seleccionada.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var subsidio = CALCULATE(\n    COUNT('Transversal FACT_ACTIVIDADES'[SUBSIDIO]),\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n    'Transversal FACT_ACTIVIDADES'[SUBSIDIO] &gt; 0\n)\n\nvar SubsidioColegio = CALCULATE(\n    COUNT('Transversal FACT_ACTIVIDADES'[VALOR_FACTURADO]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"FACTURACION_MATRICULAS\",\n    'Transversal FACT_ACTIVIDADES'[ID_CONCEPTO] = 3,\n    'Transversal FACT_ACTIVIDADES'[ESTADO_PAGO] = \"PAGADO\"\n)\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1}, SubsidioColegio,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2, 4}, subsidio,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, 0,\n    subsidio + SubsidioColegio\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#valor-de-subsidio-a-la-demanda","title":"Valor de subsidio  a la demanda","text":"<ul> <li> <p>Objetivo:   Calcular el valor total de subsidios entregados a la demanda, diferenciando entre subsidios directos y aquellos aplicados a la facturaci\u00f3n de matr\u00edculas, seg\u00fan la unidad seleccionada.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var subsidio = CALCULATE(\n    SUM('Transversal FACT_ACTIVIDADES'[SUBSIDIO]),\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n)\n\nvar SubsidioColegio = CALCULATE(\n    -SUM('Transversal FACT_ACTIVIDADES'[VALOR_FACTURADO]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"FACTURACION_MATRICULAS\",\n    'Transversal FACT_ACTIVIDADES'[ID_CONCEPTO] = 3,\n    'Transversal FACT_ACTIVIDADES'[ESTADO_PAGO] = \"PAGADO\"\n)\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1}, SubsidioColegio,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2, 4}, subsidio,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, 0,\n    subsidio + SubsidioColegio\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#poblacion-atendida-por-educacion","title":"% Poblaci\u00f3n Atendida por Educaci\u00f3n","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de la poblaci\u00f3n afiliada (afiliados y beneficiarios) que ha sido atendida mediante actividades educativas.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var Poblacion = [# Afiliados Caja] + [# Beneficiarios Caja]\nvar PoblacionAtendida = [#Afiliados_Atendidos] + [#Beneficiarios_Atendidos] \nvar dev = DIVIDE(PoblacionAtendida, Poblacion, 0)  \nRETURN IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cobertura-ejecutada","title":"Cobertura ejecutada","text":"<ul> <li> <p>Objetivo:   Calcular la cobertura total ejecutada como la suma de empresas, afiliados y beneficiarios atendidos.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>[#Empresas_Atendidas] + [#Afiliados_Atendidos] + [#Beneficiarios_Atendidos]\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cantidad-de-graduados","title":"Cantidad de Graduados","text":"<ul> <li> <p>Objetivo:   Calcular la cantidad total de graduados por unidad, considerando beneficiarios afiliados y no afiliados, y aplicando filtros temporales por semestre seg\u00fan corresponda a la unidad educativa.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR colegio_retiros = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"GRADUADOS\",\n    'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n    DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA])\n)\n\nVAR colegio_retirosNoAfiliada = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"GRADUADOS\",\n    'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n    'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n    'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n    DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA])\n)\n\nVAR InicioSemestre =\n    IF (\n        MONTH(MINX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])) &lt;= 6,\n        DATE(YEAR(MINX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])), 1, 1),\n        DATE(YEAR(MINX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])), 7, 1)\n    )\n\nVAR FinSemestre =\n    IF (\n        MONTH(MAXX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])) &lt;= 6,\n        DATE(YEAR(MAXX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])), 6, 30),\n        DATE(YEAR(MAXX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])), 12, 31)\n    )\n\nVAR RetirosCedesarrollo = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_GRADUADO]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"GRADUADOS\",\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 2,\n    DATESBETWEEN('Transversal DIM_TIEMPO_MENSUAL'[FECHA], InicioSemestre, FinSemestre),\n    REMOVEFILTERS('Transversal FACT_ACTIVIDADES'[ID_UNIDAD])\n)\n\nVAR RetirosDE = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_GRADUADO]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"GRADUADOS\",\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 3,\n    REMOVEFILTERS('Transversal FACT_ACTIVIDADES'[ID_UNIDAD])\n)\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1}, colegio_retiros + colegio_retirosNoAfiliada,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2}, RetirosCedesarrollo,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, RetirosDE,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4}, 0,\n    colegio_retiros + colegio_retirosNoAfiliada + RetirosCedesarrollo + RetirosDE\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-promocion","title":"Porcentaje de promoci\u00f3n","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de promoci\u00f3n de estudiantes matriculados, considerando tanto poblaci\u00f3n afiliada como no afiliada, con l\u00f3gica diferenciada seg\u00fan la unidad educativa.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Matriculas =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR PromocionColegio =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] IN { \"PROMOCION\" },\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n    )\n\nVAR MatriculasPoblacionNoAfiliada =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR MatriculasNoAfiliadaColegio =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR PromocionCedesarrollo =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] IN { \"PROMOCION\" },\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1}, DIVIDE(PromocionColegio, Matriculas + MatriculasNoAfiliadaColegio, 0),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2}, DIVIDE(PromocionCedesarrollo, Matriculas + MatriculasPoblacionNoAfiliada, 0),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4}, 0,\n    (DIVIDE(PromocionColegio, Matriculas + MatriculasNoAfiliadaColegio, 0) + DIVIDE(PromocionCedesarrollo, Matriculas + MatriculasPoblacionNoAfiliada, 0)) * 0.5\n)\n\nRETURN IF( ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-desercion","title":"Porcentaje de desercion","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de deserci\u00f3n escolar diferenciando por unidad: Colegio, Cedesarrollo u otras, combinando el total de retiros con el total de matr\u00edculas (afiliadas y no afiliadas).</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Matriculas =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR RetirosColegio =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] IN { \"RETIROS\" },\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n    )\n\nVAR MatriculasPoblacionNoAfiliada =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR MatriculasNoAfiliadaColegio =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR RetirosCedesarrollo =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] IN { \"RETIROS\" },\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1}, DIVIDE(RetirosColegio, Matriculas + MatriculasNoAfiliadaColegio, 0),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2}, DIVIDE(RetirosCedesarrollo, Matriculas + MatriculasPoblacionNoAfiliada, 0),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4}, 0,\n    (DIVIDE(RetirosColegio, Matriculas + MatriculasNoAfiliadaColegio, 0) + DIVIDE(RetirosCedesarrollo, Matriculas + MatriculasPoblacionNoAfiliada, 0)) * 0.5\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-empresas-que-repiten-la-compra-de-los-servicios-de-fomento-empresarial","title":"Porcentaje de empresas que repiten la compra de los servicios de fomento empresarial","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de empresas que han comprado m\u00e1s de una vez servicios relacionados con fomento empresarial en la unidad 3, basado en los registros de facturaci\u00f3n.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var Num_Servicios_Vendidos = \nCALCULATE(\n    COUNTROWS('Transversal FACT_ACTIVIDADES'),\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 3,\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"FACTURACION\",\n    CONTAINSSTRING(UPPER('Transversal FACT_ACTIVIDADES'[DESCRIPCION]), \"FOMENTO\")\n)\n\nvar Empresas_Repetidas = \nSUMX(\n    SUMMARIZE(\n        'Transversal FACT_ACTIVIDADES',\n        'Transversal FACT_ACTIVIDADES'[ID_POBLACION],\n        \"Num_Servicios_Vendidos\", \n        CALCULATE(\n            COUNTROWS('Transversal FACT_ACTIVIDADES'),\n            'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 3,\n            'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"FACTURACION\",\n            'Transversal FACT_ACTIVIDADES'[ID_POBLACION] &lt;&gt; -1,\n            CONTAINSSTRING(UPPER('Transversal FACT_ACTIVIDADES'[DESCRIPCION]), \"FOMENTO\")\n        )\n    ),\n    IF([Num_Servicios_Vendidos] &gt; 1, 1, 0)\n)\n\nVAR Emp_Total =     \nCALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]), \n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 3,\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"FACTURACION\",\n    CONTAINSSTRING(UPPER('Transversal FACT_ACTIVIDADES'[DESCRIPCION]), \"FOMENTO\")\n)\n\nvar dev = DIVIDE( Empresas_Repetidas, [#Empresas que compran servicios de fomento empresarial], 0)    \n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-usuarios-que-repiten-la-compra-de-servicios-de-proteccion-social","title":"Porcentaje de usuarios que repiten la compra de servicios de protecci\u00f3n social","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de usuarios que han adquirido m\u00e1s de una vez servicios de protecci\u00f3n social, bas\u00e1ndose en la cantidad de tarifas registradas por usuario.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Usuarios_repiten = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    FILTER(\n        SUMMARIZE(\n            'Transversal FACT_ACTIVIDADES', \n            'Transversal FACT_ACTIVIDADES'[PARTNER],\n            'Transversal FACT_ACTIVIDADES'[ID_TARIFA],\n            \"Num_Servicios\", COUNT('Transversal FACT_ACTIVIDADES'[ID_TARIFA])\n        ),\n        [Num_Servicios] &gt; 1\n    )\n)\n\nVAR Usuarios_Totales =  \nCALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER])\n)\n\nvar dev = divide(Usuarios_repiten, Usuarios_Totales, 0)\n\nreturn dev \n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#espacios-fisicos-salones","title":"# Espacios f\u00edsicos (Salones)","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de salones f\u00edsicos activos disponibles, seg\u00fan el estado registrado como \"ACTIVO\" en la tabla de capacidad f\u00edsica.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_CAPACIDAD_FISICA'[ID_SALON]),\n    'Transversal FACT_CAPACIDAD_FISICA'[ESTADO] = \"ACTIVO\"\n)\n\nRETURN IF( ISBLANK(dev) , BLANK(), dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#servicios-ofertados","title":"# Servicios ofertados","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de servicios ofertados distintos con objeto tarifa v\u00e1lido, filtrando por unidad organizacional seg\u00fan su c\u00f3digo de infraestructura correspondiente.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR SelectedUnidad = SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD], BLANK())\n\nRETURN\nCALCULATE(\n    DISTINCTCOUNT('Transversal FACT_SERVICIOS_OFERTADOS'[CON_OBJETO_TARIFA]),\n    'Transversal FACT_SERVICIOS_OFERTADOS'[COD_SERVICIO] &lt;&gt; 0,\n    IF(\n        ISBLANK(SelectedUnidad),\n        TRUE(),\n        SWITCH(\n            TRUE(),\n            SelectedUnidad = 1, 'Transversal FACT_SERVICIOS_OFERTADOS'[COD_INFRAESTRUCTURA_CCF] = \"CCF008-12-00001\",\n            SelectedUnidad = 2, 'Transversal FACT_SERVICIOS_OFERTADOS'[COD_INFRAESTRUCTURA_CCF] = \"CCF008-13-00001\",\n            SelectedUnidad = 3, 'Transversal FACT_SERVICIOS_OFERTADOS'[COD_INFRAESTRUCTURA_CCF] = \"CCF008-15-00001\",\n            SelectedUnidad = 4, 'Transversal FACT_SERVICIOS_OFERTADOS'[COD_INFRAESTRUCTURA_CCF] = \"CCF008-26-00001\",\n            SelectedUnidad = 5, 'Transversal FACT_SERVICIOS_OFERTADOS'[COD_INFRAESTRUCTURA_CCF] = \"-1\",\n            TRUE(), 0\n        )\n    )\n)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#servicios-vendidos","title":"# Servicios vendidos","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de servicios vendidos, identificados por objeto tarifa, excluyendo aquellos asociados a la unidad con ID igual a 5.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>--CALCULATE( DISTINCTCOUNT( 'Transversal DIM_TARIFAS_SERVICIOS'[CON_OBJETO_TARIFA] ) , 'Transversal DIM_TARIFAS_SERVICIOS'[COD_SERVICIO] &lt;&gt; 0 )\nVAR t1 =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal DIM_TARIFAS_SERVICIOS'[CON_OBJETO_TARIFA]),\n        'Transversal DIM_TARIFAS_SERVICIOS'[COD_SERVICIO] &lt;&gt; 0\n    )\nVAR dev =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal DIM_TARIFAS_SERVICIOS'[CON_OBJETO_TARIFA]),\n        FILTER(\n            RELATEDTABLE('Transversal FACT_ACTIVIDADES'),\n            'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5\n        )\n    )\nRETURN\n    IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#estudiantes-activos","title":"# Estudiantes activos","text":"<ul> <li> <p>Objetivo:   Calcular el total de estudiantes activos restando del total de matr\u00edculas los retiros y los graduados.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Matriculas = [Cantidad de matriculas]\nVAR Retiros = [# Retiros]\nvar Graduados = [Cantidad de Graduados]\n\nvar dev = Matriculas - Retiros - Graduados\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#estudiantes-por-salon","title":"# Estudiantes por salon","text":"<ul> <li> <p>Objetivo:   Calcular el promedio de estudiantes activos por cada sal\u00f3n f\u00edsico disponible, evitando divisiones por cero.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>IF([# Espacios f\u00edsicos (Salones)] = 0, 0, [# Estudiantes activos]/[# Espacios f\u00edsicos (Salones)])\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#docentes-y-profesionales","title":"# Docentes y profesionales","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de docentes y profesionales registrados con un identificador v\u00e1lido en la tabla de personal.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_PERSONAL'[ID_PERSONAL]),\n    'Transversal FACT_PERSONAL'[ID_PERSONAL] &lt;&gt; -1\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#pqrs","title":"# PQRS","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de registros \u00fanicos de PQRS (Peticiones, Quejas, Reclamos y Sugerencias) asociados a la actividad \u201cPQR\u201d.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>IF(\n    ISBLANK(\n        CALCULATE(\n            DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_PQR]), \n            'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"PQR\"\n        )\n    ),\n    0,\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_PQR]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"PQR\"\n    )\n)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#numero-de-usos-por-pqrs","title":"Numero de usos por PQRS","text":"<ul> <li> <p>Objetivo:   Calcular el promedio de usos o interacciones asociados por cada registro de PQRS, evitando divisiones por cero.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = IF(\n    [# PQRS] = 0, \n    0,\n    [Cantidad_Usos]/[# PQRS]\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-promotores","title":"Porcentaje de Promotores","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de usuarios que calificaron con 7 o m\u00e1s en la actividad \"NSU\", consider\u00e1ndolos como promotores.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Total = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"NSU\"\n)\n\nVAR Promotores = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    FILTER(\n        'Transversal FACT_ACTIVIDADES',\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"NSU\" &amp;&amp;\n        IFERROR(VALUE('Transversal FACT_ACTIVIDADES'[CALIFICACION]), BLANK()) &gt;= 7\n    )\n)\n\nvar dev = DIVIDE(Promotores, Total, 0)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-detractores","title":"Porcentaje de detractores","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de usuarios que calificaron con menos de 7 en la actividad \"NSU\", consider\u00e1ndolos como detractores.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Total = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"NSU\"\n)\n\nVAR Detractores = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    FILTER(\n        'Transversal FACT_ACTIVIDADES',\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"NSU\" &amp;&amp;\n        IFERROR(VALUE('Transversal FACT_ACTIVIDADES'[CALIFICACION]), BLANK()) &lt; 7\n    )\n)\n\nvar dev = DIVIDE(Detractores, Total, 0)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#calificaciones-de-docentes","title":"Calificaciones de docentes","text":"<ul> <li> <p>Objetivo:   Calcular el promedio de las calificaciones definitivas asignadas a los docentes seg\u00fan los registros en la tabla de evaluaci\u00f3n docente.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = AVERAGEX(\n    'Transversal FACT_EVALUACION_DOCENTE',\n    IFERROR(VALUE('Transversal FACT_EVALUACION_DOCENTE'[CALIFICACION_DEFINITIVA]), BLANK())\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#de-estudiantes-con-resultado-superior-al-50-de-valor-total-de-la-prueba","title":"% de estudiantes con resultado superior al 50% de valor total de la Prueba","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de estudiantes cuyo resultado en la prueba SABER 11 supera el 50% del valor total (m\u00e1s de 250 puntos), con base en registros individuales.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR total_Estudiantes =\n    CALCULATE(\n        SUM('Transversal FACT_UNIDADES'[NUM_ESTUDIANTES]),\n        'Transversal FACT_UNIDADES'[ORIGEN] = \"FACT_SABER11_INDIVIDUAL\"\n    )\n\nVAR estudiantes_mayora_250 =\n    CALCULATE(\n        SUM('Transversal FACT_UNIDADES'[NUM_MAYOR_250]),\n        'Transversal FACT_UNIDADES'[ORIGEN] = \"FACT_SABER11_INDIVIDUAL\"\n    )\n\nvar dev = DIVIDE(estudiantes_mayora_250, total_Estudiantes, 0)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#resultado-de-la-categoria-de-las-pruebas-saber-11-para-la-cec","title":"Resultado de la Categor\u00eda de las pruebas Saber 11 para la CEC","text":"<ul> <li> <p>Objetivo:   Obtener la \u00faltima categor\u00eda registrada de los resultados de la prueba Saber 11 para la CEC, seg\u00fan la columna <code>CATEGORIA_SABER11</code>.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    LASTNONBLANK(\n        'Transversal FACT_UNIDADES'[CATEGORIA_SABER11],\n        1\n    )\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-efectividad-en-las-cotizaciones-fomento-empresarial-i7404","title":"Porcentaje de efectividad en las cotizaciones Fomento empresarial-I7404","text":"<ul> <li> <p>Objetivo:   Representar el valor de la medida existente [% efectividad en las cotizaciones Fomento empresarial], manteniendo su resultado y formato, posiblemente adaptada para un indicador o c\u00f3digo espec\u00edfico (I7404).</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>[% efectividad en las cotizaciones Fomento empresarial]\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#ingresos-ejecutados-ingresos-presupuestados","title":"Ingresos ejecutados / Ingresos presupuestados","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de ejecuci\u00f3n de ingresos, dividiendo los ingresos ejecutados entre los ingresos presupuestados, y devolviendo 0 si el valor es nulo.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = DIVIDE([Ingresos Ejecutados]/[Ingresos Presupuestados], 0)\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#empresas-que-compran-servicios-de-fomento-empresarial","title":"#Empresas que compran servicios de fomento empresarial","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de empresas (poblaciones) que han adquirido servicios relacionados con fomento empresarial mediante facturaci\u00f3n en la unidad 3.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Emp_Total = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]), \n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 3,\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"FACTURACION\",\n    CONTAINSSTRING(UPPER('Transversal FACT_ACTIVIDADES'[DESCRIPCION]), \"FOMENTO\")\n)\n\nreturn IF(ISBLANK(Emp_Total), 0, Emp_Total)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#afiliados-atendidos-por-proteccion-social","title":"#Afiliados atendidos por Proteccion Social","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de afiliados \u00fanicos con atenci\u00f3n registrada en la unidad 4 (Protecci\u00f3n Social), excluyendo registros inv\u00e1lidos.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[ID_AFILIADO]),\n    'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 4\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cobertura-para-empleados-de-la-caja-de-compensacion-en-programas-de-educacion","title":"Cobertura para Empleados de la Caja de Compensacion en programas de educacion","text":"<ul> <li> <p>Objetivo:   Calcular la cobertura ejecutada en programas educativos exclusivamente para empleados de la Caja de Compensaci\u00f3n identificados con el c\u00f3digo de empresa \"0060007786\".</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    [Cobertura ejecutada],\n    'Transversal FACT_ACTIVIDADES'[PARTNER_EMPRESA] = \"0060007786\"\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-afiliados-atendidos-respecto-al-total-atendido-proteccion-social","title":"Porcentaje de afiliados atendidos respecto al total atendido (Protecci\u00f3n Social)","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de afiliados atendidos por Protecci\u00f3n Social respecto al total de personas atendidas en dicha unidad.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>DIVIDE([#Afiliados atendidos por Proteccion Social], [#Afiliados_Atendidos], 0)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-poblacion-fosfec-respecto-al-total-atendido-desarrollo-empresarial","title":"Porcentaje de poblaci\u00f3n FOSFEC respecto al total atendido (Desarrollo Empresarial)","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de la poblaci\u00f3n FOSFEC atendida dentro del total cubierto por Desarrollo Empresarial, aplicando l\u00f3gica condicional para mostrar el resultado solo cuando la unidad corresponde a la 3.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var PorcentajeFOSFEC = \n    CALCULATE(\n        DIVIDE(\n            [Cantidad de poblaci\u00f3n FOSFEC atendida por Desarrollo Empresarial],\n            [Cobertura ejecutada],\n            0\n        ),\n        'Transversal DIM_UNIDAD'[ID_UNIDAD] = 3,\n        REMOVEFILTERS('Transversal DIM_UNIDAD'[ID_UNIDAD])\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 4}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, PorcentajeFOSFEC,\n    PorcentajeFOSFEC\n)\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cobertura-proyectada","title":"Cobertura proyectada","text":"<ul> <li> <p>Objetivo:   Calcular la cobertura proyectada mensual y anual para diferentes unidades y programas, diferenciando el tratamiento para programas de protecci\u00f3n social (adulto mayor, discapacidad, AIPI, JEC) y otras unidades.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR MesesSeleccionados =\n    VALUES('Transversal DIM_TIEMPO_MENSUAL'[ID_FECHA])  \n\nvar CoberturaProyectada = \n    AVERAGEX(\n        MesesSeleccionados,\n        CALCULATE(\n            SUM('Transversal FACT_UNIDADES'[POBLACION_PROYECTADA]),\n            'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"COBERTURA PROYECTADA\",\n            'Transversal DIM_UNIDAD'[ID_UNIDAD] &lt;&gt; 4\n        )\n    )\n\nVAR EsPorMes = \n    ISFILTERED('Transversal DIM_TIEMPO_MENSUAL'[ID_MES]) \n\nvar CoberturaProyectadaAdultoDiscapacidad =\n    IF(\n        EsPorMes,\n        AVERAGEX(\n            MesesSeleccionados,\n            CALCULATE(\n                SUM('Transversal FACT_UNIDADES'[POBLACION_PROYECTADA]),\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"COBERTURA PROYECTADA\",\n                'Transversal DIM_UNIDAD'[ID_UNIDAD] = 4,\n                'Proteccion DIM_PROGRAMA'[ID_PROGRAMA] IN {1, 2},\n                REMOVEFILTERS('Transversal DIM_UNIDAD'[UNIDAD])\n            )\n        ),\n        CALCULATE(\n            SUM('Transversal FACT_UNIDADES'[POBLACION_PROYECTADA]),\n            'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"COBERTURA PROYECTADA\",\n            'Transversal DIM_UNIDAD'[ID_UNIDAD] = 4,\n            'Proteccion DIM_PROGRAMA'[ID_PROGRAMA] IN {1, 2},\n            REMOVEFILTERS('Transversal DIM_UNIDAD'[UNIDAD])\n        )\n    )\n\nvar CoberturaAIPI_JEC = \n    AVERAGEX(\n        MesesSeleccionados,\n        CALCULATE(\n            SUM('Transversal FACT_UNIDADES'[POBLACION_PROYECTADA]),\n            'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"COBERTURA PROYECTADA\",\n            'Transversal DIM_UNIDAD'[ID_UNIDAD] = 4,\n            'Proteccion DIM_PROGRAMA'[ID_PROGRAMA] &lt;&gt; 1,\n            'Proteccion DIM_PROGRAMA'[ID_PROGRAMA] &lt;&gt; 2\n        )\n    )\n\nvar CoberturaProyectadaProteccion = \n    SWITCH (\n        TRUE(),\n        SELECTEDVALUE('Proteccion DIM_PROGRAMA'[ID_PROGRAMA]) IN {1,2}, CoberturaProyectadaAdultoDiscapacidad,\n        SELECTEDVALUE('Proteccion DIM_PROGRAMA'[ID_PROGRAMA]) IN {3,4}, CoberturaAIPI_JEC,\n        CoberturaProyectada + CoberturaAIPI_JEC\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1,2,3}, CoberturaProyectada,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4}, CoberturaProyectadaProteccion,\n    CoberturaProyectada + CoberturaProyectadaProteccion\n)\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#movilidad-academica","title":"Movilidad academica","text":"<ul> <li> <p>Objetivo:   Representar el valor de la medida <code>[# Estudiantes activos]</code> como indicador de movilidad acad\u00e9mica, posiblemente con un enfoque anal\u00edtico o visual distinto.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>[# Estudiantes activos]\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#nivel-se-satisfaccion-a-partir-de-la-nsu-promedio","title":"Nivel se satisfacci\u00f3n a partir de la NSU promedio","text":"<ul> <li> <p>Objetivo:   Calcular el nivel de satisfacci\u00f3n promedio de los usuarios a partir de las calificaciones registradas en la actividad \"NSU\".</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    AVERAGEX(\n        FILTER(\n            'Transversal FACT_ACTIVIDADES',\n            'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"NSU\"\n        ),\n        IFERROR(VALUE('Transversal FACT_ACTIVIDADES'[CALIFICACION]), BLANK())\n    )\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#promotores-promedio-del-proceso-a-partir-de-la-nsu","title":"Promotores promedio del proceso  a partir de la NSU","text":"<pre><code>* **Objetivo:**\n  Calcular el porcentaje de usuarios que calificaron con 9 o m\u00e1s en la actividad \"NSU\", consider\u00e1ndolos como promotores del proceso evaluado.\n\n* **Expresi\u00f3n DAX:**\n\n  ```DAX\n  VAR Total = CALCULATE(\n      DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n      'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"NSU\"\n  )\n\n  VAR Promotores = CALCULATE(\n      DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n      FILTER(\n          'Transversal FACT_ACTIVIDADES',\n          'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"NSU\" &amp;&amp;  \n          IFERROR(VALUE('Transversal FACT_ACTIVIDADES'[CALIFICACION]), 0) &gt;= 9\n      )\n  )\n\n  var dev = DIVIDE(Promotores, Total, 0)\n\n  return dev\n  ```\n\n* **Formato:** Num\u00e9rico.\n</code></pre>"},{"location":"03.Cubo/01.Origen/#cantidad-de-matriculas","title":"Cantidad de matriculas","text":"<ul> <li> <p>Objetivo:   Calcular el total de matr\u00edculas registradas, diferenciando por unidad si corresponde a Colegio, otras unidades educativas, o Protecci\u00f3n Social, e incluyendo poblaci\u00f3n no afiliada cuando aplica.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Matriculas =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_MATRICULA]),\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR MatriculasColegio =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR MatriculasPoblacionNoAfiliada =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_MATRICULA]),\n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR MatriculasNoAfiliadaColegio =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n        'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\"\n    )\n\nVAR dev = SWITCH(\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1}, MatriculasColegio + MatriculasNoAfiliadaColegio,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2, 3}, Matriculas,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4}, 0,\n    MatriculasColegio + MatriculasNoAfiliadaColegio + Matriculas\n)\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#valor-del-subsidio-a-la-demanda-a-partir-de-las-transacciones-realizadas-por-los-afiliados","title":"Valor del subsidio a la demanda a partir de las transacciones realizadas por los afiliados","text":"<ul> <li> <p>Objetivo:   Representar el valor total del subsidio a la demanda basado en las transacciones realizadas por afiliados, reutilizando la medida existente <code>[Valor de subsidio  a la demanda]</code>.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>[Valor de subsidio  a la demanda]\n</code></pre> <ul> <li>Formato: Moneda.</li> </ul>"},{"location":"03.Cubo/01.Origen/#numero-de-transacciones-de-afiliados-con-categoria-a-y-b","title":"Numero de transacciones de afiliados con categoria A y B","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de transacciones realizadas por afiliados clasificados en las categor\u00edas A y B seg\u00fan la columna <code>CATEGORIA_VENTA</code>.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    COUNTROWS('Transversal FACT_ACTIVIDADES'),\n    'Transversal FACT_ACTIVIDADES'[CATEGORIA_VENTA] IN { \"A\", \"B\" }\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#resultado-del-ejercicio-resultado-presupuestado","title":"Resultado del ejercicio / Resultado presupuestado","text":"<ul> <li> <p>Objetivo:   Calcular la relaci\u00f3n entre el resultado contable real (ingresos menos costos ejecutados) y el resultado presupuestado (ingresos menos costos planificados), indicando el grado de cumplimiento.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var ResultadoContable = [Ingresos Ejecutados] - [Costos Ejecutados]\nvar ResultadoPresupuesto = [Ingresos Presupuestados] - [Costos Presupuestados]\nvar dev = DIVIDE(ResultadoContable, ResultadoPresupuesto, 0)\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#valor-de-los-ingresos-percibidos-por-la-prestacion-de-servicios-ingresos-ejecutados","title":"Valor de los ingresos percibidos por la prestaci\u00f3n de servicios (Ingresos ejecutados)","text":"<ul> <li> <p>Objetivo:   Calcular el total de ingresos efectivamente percibidos por la prestaci\u00f3n de servicios, registrados bajo la actividad \"EJECUCION_CONTABLE\" en la tabla financiera.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    SUM('Transversal FACT_FINANCIERA'[INGRESOS]),\n    'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"EJECUCION_CONTABLE\"\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Moneda.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-estudiantes-de-la-jec-que-desertan-de-la-institucion-educativa","title":"Porcentaje de estudiantes de la JEC que desertan de la Instituci\u00f3n Educativa","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de estudiantes pertenecientes a la Jornada Escolar Completa (JEC) que han desertado de la instituci\u00f3n educativa, comparando los casos de deserci\u00f3n con la caracterizaci\u00f3n total.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Est_Desertan = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"DESERCION\",\n    'Transversal FACT_ACTIVIDADES'[DESCRIPCION] = \"JEC\"\n)\n\nVAR Est_Total = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"CARACTERIZACION\",\n    'Transversal FACT_ACTIVIDADES'[DESCRIPCION] = \"JEC\"\n)\n\nvar dev = DIVIDE(Est_Desertan, Est_Total, 0)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#porcentaje-de-estudiantes-de-aipi-que-desertan-de-la-institucion-educativa","title":"Porcentaje de estudiantes de AIPI que desertan de la Instituci\u00f3n Educativa","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de estudiantes del programa AIPI que han desertado de la instituci\u00f3n educativa, comparando los casos de deserci\u00f3n con la cantidad total caracterizada.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Est_Desertan = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"DESERCION\",\n    'Transversal FACT_ACTIVIDADES'[DESCRIPCION] = \"AIPI\"\n)\n\nVAR Est_Total = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"CARACTERIZACION\",\n    'Transversal FACT_ACTIVIDADES'[DESCRIPCION] = \"AIPI\"\n)\n\nvar dev = DIVIDE(Est_Desertan, Est_Total, 0)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#desercion-temprana-de-fosfec","title":"Desercion temprana de FOSFEC","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de deserci\u00f3n de la poblaci\u00f3n vinculada al programa FOSFEC, comparando los casos de retiro frente al total de matriculados con dicha condici\u00f3n, aplicando la l\u00f3gica solo en la unidad 3.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR FOSFEC = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\",\n    'Cedesarrollo DIM_PROGRAMA'[FOSFEC] = \"SI\"\n)\n\nVAR DesercionFOSFEC = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"RETIROS\",\n    'Cedesarrollo DIM_PROGRAMA'[FOSFEC] = \"SI\"\n)\n\nVAR dev = SWITCH(\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 4}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, DIVIDE(DesercionFOSFEC, FOSFEC, 0),\n    DIVIDE(DesercionFOSFEC, FOSFEC, 0)\n)\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#horas-contratadas","title":"# horas contratadas","text":"<ul> <li> <p>Objetivo:   Calcular el total de horas mensuales contratadas para personal bajo el concepto de \"CONTRATACION\", devolviendo BLANK si no hay registros.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>IF(\n    ISBLANK(\n        CALCULATE(\n            SUM('Transversal FACT_PERSONAL'[HORAS_CONTRATADAS_MENSUAL]),\n            'Transversal FACT_PERSONAL'[CONCEPTO] = \"CONTRATACION\"\n        )\n    ),\n    BLANK(),\n    CALCULATE(\n        SUM('Transversal FACT_PERSONAL'[HORAS_CONTRATADAS_MENSUAL]),\n        'Transversal FACT_PERSONAL'[CONCEPTO] = \"CONTRATACION\"\n    )\n)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#reductores-de-capacidad-contratada","title":"Reductores de capacidad contratada","text":"<ul> <li> <p>Objetivo:   Calcular la suma total de horas mensuales que representan una reducci\u00f3n en la capacidad contratada debido a conceptos como \"AUSENTISMO\" o \"REEMPLAZO\".</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    SUM('Transversal FACT_PERSONAL'[HORAS_CONTRATADAS_MENSUAL]),\n    'Transversal FACT_PERSONAL'[CONCEPTO] = \"AUSENTISMO\" || \n    'Transversal FACT_PERSONAL'[CONCEPTO] = \"REEMPLAZO\"\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#real-de-tiempo-administrativo","title":"% real de tiempo administrativo","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje real de tiempo administrativo disponible, ajustando el 30\u202f% del tiempo contratado seg\u00fan las horas empleadas en cubrir ausencias.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = DIVIDE(\n    (0.3 * [# horas contratadas] - [# Horas empleadas en cubrir ausencias]),\n    [# horas contratadas],\n    0\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#horas-empleadas-en-cubrir-ausencias","title":"# Horas empleadas en cubrir ausencias","text":"<ul> <li> <p>Objetivo:   Calcular la cantidad total de horas mensuales contratadas bajo el concepto de \"REEMPLAZO\", representando el tiempo destinado a cubrir ausencias del personal.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>CALCULATE(\n    SUM('Transversal FACT_PERSONAL'[HORAS_CONTRATADAS_MENSUAL]),\n    'Transversal FACT_PERSONAL'[CONCEPTO] = \"REEMPLAZO\"\n)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#utilizacion-de-las-bibliotecas-virtuales","title":"% Utilizaci\u00f3n de las bibliotecas virtuales","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de estudiantes matriculados en la unidad educativa (ID_UNIDAD = 1) que hacen uso de la biblioteca virtual, midiendo el alcance del servicio digital.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR personas_biblioteca = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"BIBLIOTECA_VIRTUAL\"\n)\n\nVAR personas_total = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\",\n    'Transversal DIM_UNIDAD'[ID_UNIDAD] = 1\n)\n\nvar dev = DIVIDE(personas_biblioteca, personas_total, 0)\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#inversiones-en-la-infraestructura-fisica","title":"Inversiones en la infraestructura f\u00edsica","text":"<ul> <li> <p>Objetivo:   Calcular el total de inversiones ejecutadas en infraestructura f\u00edsica, identificadas mediante cuentas contables que inician con \u201c1516\u201d y registradas como ejecuci\u00f3n contable.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = SUMX(\n    FILTER(\n        'Transversal FACT_FINANCIERA',\n        'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"EJECUCION_CONTABLE\" &amp;&amp;\n        LEFT('Transversal FACT_FINANCIERA'[CUENTA], 4) = \"1516\"\n    ),\n    'Transversal FACT_FINANCIERA'[IMPORTE]\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#inversion-en-infraestructura-tecnologica","title":"Inversion en infraestructura tecnologica","text":"<ul> <li> <p>Objetivo:   Calcular el valor total de inversiones ejecutadas en infraestructura tecnol\u00f3gica, filtrando aquellas transacciones con cuentas contables que inician con \"1528\" y asociadas a la actividad \"EJECUCION_CONTABLE\".</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = SUMX(\n    FILTER(\n        'Transversal FACT_FINANCIERA',\n        'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"EJECUCION_CONTABLE\" &amp;&amp;\n        LEFT('Transversal FACT_FINANCIERA'[CUENTA], 4) = \"1528\"\n    ),\n    'Transversal FACT_FINANCIERA'[IMPORTE]\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#rotacion-de-la-planta-total","title":"% Rotaci\u00f3n de la planta Total","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de rotaci\u00f3n del personal contratado, midiendo la proporci\u00f3n de retiros frente a ingresos en la planta total.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Ingresos = CALCULATE(\n    COUNT('Transversal FACT_PERSONAL'[ID_PERSONAL]),\n    'Transversal FACT_PERSONAL'[CONCEPTO] = \"CONTRATACION\"\n)\n\nVAR Retiros = CALCULATE(\n    COUNT('Transversal FACT_PERSONAL'[ID_PERSONAL]),\n    'Transversal FACT_PERSONAL'[CONCEPTO] = \"FIN_CONTRATACION\"\n)\n\nvar dev = DIVIDE((Ingresos - Retiros), Ingresos, 0)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#de-estudiantes-matriculados-con-documentos-completos-del-total-de-matriculados","title":"% de Estudiantes matriculados con documentos completos del total de matriculados","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de estudiantes matriculados que tienen todos sus documentos completos, respecto al total de estudiantes con estado de documentaci\u00f3n identificado.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR EstudiantesDocumentos = CALCULATE(\n    SUM('Transversal FACT_UNIDADES'[NUM_ESTUDIANTES]),\n    'Transversal FACT_UNIDADES'[DOCUMENTOS_COMPLETOS] = \"SI\"\n)\n\nVAR Estudiantes = CALCULATE(\n    SUM('Transversal FACT_UNIDADES'[NUM_ESTUDIANTES]),\n    'Transversal FACT_UNIDADES'[DOCUMENTOS_COMPLETOS] = \"SI\" ||\n    'Transversal FACT_UNIDADES'[DOCUMENTOS_COMPLETOS] = \"NO\"\n)\n\nvar dev = DIVIDE(EstudiantesDocumentos, Estudiantes, 0)\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#de-afiliados-beneficiados-desde-ps-respecto-a-la-poblacion-impactada-de-ps","title":"% de afiliados beneficiados desde PS respecto a la poblaci\u00f3n impactada de PS","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de afiliados que han sido atendidos por el \u00e1rea de Protecci\u00f3n Social (PS) respecto al total de afiliados registrados en la Caja.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = DIVIDE(\n    [#Afiliados atendidos por Proteccion Social],\n    [# Afiliados Caja],\n    0\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#empresas-atendidas","title":"% Empresas Atendidas","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de empresas atendidas frente al total de empresas potenciales identificadas, reflejando el alcance de la gesti\u00f3n empresarial.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = DIVIDE(\n    [#Empresas_Atendidas],\n    [# Empresas Potenciales],\n    0\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#afiliados-por-educacion","title":"% afiliados por educaci\u00f3n","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de afiliados atendidos en programas educativos respecto al total de afiliados potenciales.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = DIVIDE(\n    [#Afiliados_Atendidos],\n    [# Afiliados Potenciales],\n    0\n)\n\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#beneficiarios-atendidos","title":"% Beneficiarios Atendidos","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de beneficiarios atendidos en relaci\u00f3n con el total de beneficiarios potenciales registrados, considerando la existencia de beneficiarios en caja.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = DIVIDE(\n    [#Beneficiarios_Atendidos],\n    [# Beneficiarios Potenciales],\n    0\n)\n\nreturn IF([# Beneficiarios Caja] = 0, 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#numero-de-iniciativas","title":"N\u00famero de iniciativas","text":"<ul> <li> <p>Objetivo:   Calcular la suma de los resultados asociados a la actividad \"INICIATIVAS\" dentro de la tabla <code>Transversal FACT_UNIDADES</code>.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    SUMX(\n        FILTER(\n            'Transversal FACT_UNIDADES',\n            'Transversal FACT_UNIDADES'[ACTIVIDAD] = \"INICIATIVAS\"\n        ),\n        VALUE('Transversal FACT_UNIDADES'[RESULTADO])\n    )\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#evaluaciones-por-debajo-del-promedio","title":"% evaluaciones por debajo del promedio","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de evaluaciones docentes cuya calificaci\u00f3n definitiva est\u00e1 por debajo del promedio de calificaciones de docentes.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Promedio = [Calificaciones de docentes]\nvar dev = CALCULATE(\n    COUNTROWS('Transversal FACT_EVALUACION_DOCENTE'), \n    VALUE('Transversal FACT_EVALUACION_DOCENTE'[CALIFICACION_DEFINITIVA]) &lt; Promedio\n) / COUNTROWS('Transversal FACT_EVALUACION_DOCENTE')\n\nreturn IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#incremento-del-de-rentabilidad-del-servicio-sin-fomento-al-empleo","title":"Incremento del % de rentabilidad del servicio sin fomento al empleo","text":"<ul> <li> <p>Objetivo:   Representa un valor constante para el incremento del porcentaje de rentabilidad del servicio sin incluir el fomento al empleo.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>0.8\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#nivel-de-ejecucion-del-fondo-jec","title":"Nivel de ejecuci\u00f3n del fondo JEC","text":"<ul> <li> <p>Objetivo:   Calcular el nivel de ejecuci\u00f3n del fondo JEC, comparando el resultado del ejercicio con el resultado presupuestado para cuentas espec\u00edficas y \u00e1reas relacionadas con la jornada escolar complementaria.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = \nCALCULATE(\n    [Resultado del ejercicio / Resultado presupuestado],\n    'Transversal FACT_FINANCIERA'[ID_CEBE] IN {11911, 11912, 11913, 11914, 11915, 11916}\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#nivel-de-ejecucion-del-fondo-aipi","title":"Nivel de ejecuci\u00f3n del fondo AIPI","text":"<ul> <li> <p>Objetivo:   Calcular el nivel de ejecuci\u00f3n del fondo AIPI, comparando el resultado del ejercicio con el resultado presupuestado para cuentas y \u00e1reas relacionadas con la atenci\u00f3n integral a la ni\u00f1ez.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    [Resultado del ejercicio / Resultado presupuestado],\n    'Transversal FACT_FINANCIERA'[ID_CEBE] IN {1196, 1197, 11991, 11992}\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#atencion-usuarios-de-los-programas-de-proteccion-social","title":"Atencion usuarios de los programas de proteccion social","text":"<ul> <li> <p>Objetivo:   Reflejar el n\u00famero de afiliados atendidos por los programas de protecci\u00f3n social.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>[#Afiliados atendidos por Proteccion Social]\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#evaluacion-de-la-pertinencia-del-diseno-curricular-por-el-sector-productivo","title":"Evaluaci\u00f3n de la Pertinencia del Dise\u00f1o Curricular por el Sector Productivo","text":"<ul> <li> <p>Objetivo:   Calcular la evaluaci\u00f3n promedio de la pertinencia del dise\u00f1o curricular por el sector productivo, basada en las calificaciones de la actividad \"EVALUACION DISENO CURRICULAR\".</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    AVERAGEX(\n        FILTER(\n            'Transversal FACT_UNIDADES',\n            'Transversal FACT_UNIDADES'[ACTIVIDAD] = \"EVALUACION DISENO CURRICULAR\"\n        ),\n        VALUE('Transversal FACT_UNIDADES'[CALIFICACION])\n    )\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#efectividad-en-las-cotizaciones-fomento-empresarial","title":"% efectividad en las cotizaciones Fomento empresarial","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de efectividad en las cotizaciones de fomento empresarial, dividiendo las cotizaciones ganadas entre el total de cotizaciones.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Cotizaciones = CALCULATE(\n    COUNT('Transversal FACT_ACTIVIDADES'[DESCRIPCION]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"COTIZACIONES\"\n)\n\nVAR CotizacionesGanadas = CALCULATE(\n    COUNT('Transversal FACT_ACTIVIDADES'[DESCRIPCION]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"COTIZACIONES\",\n    'Transversal FACT_ACTIVIDADES'[ESTADO] IN {\"GANADO\",\"CIERRE\"}\n)\n\nvar dev = divide(CotizacionesGanadas, Cotizaciones, 0)\n\nreturn IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#productividad-del-portafolio-de-desarrollo-empresarial","title":"Productividad del portafolio de desarrollo empresarial","text":"<ul> <li> <p>Objetivo:   Calcular la productividad del portafolio de desarrollo empresarial, midiendo la relaci\u00f3n entre los servicios vendidos y los servicios ofertados, espec\u00edficamente para la unidad 3.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = \n    divide(\n        CALCULATE([# Servicios vendidos],'Transversal DIM_UNIDAD'[ID_UNIDAD] = 3),\n        CALCULATE([# Servicios ofertados], 'Transversal DIM_UNIDAD'[ID_UNIDAD] = 3),\n        0\n    )\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#cantidad-de-poblacion-fosfec-atendida-por-desarrollo-empresarial","title":"Cantidad de poblaci\u00f3n FOSFEC atendida por Desarrollo Empresarial","text":"<ul> <li> <p>Objetivo:   Contar la cantidad de poblaci\u00f3n FOSFEC atendida por el \u00e1rea de desarrollo empresarial, bas\u00e1ndose en las actividades de matr\u00edcula y la condici\u00f3n de FOSFEC.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var FOSFEC =  \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_POBLACION]),\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\",\n        'Cedesarrollo DIM_PROGRAMA'[FOSFEC] = \"SI\"\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2,4}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, FOSFEC,\n    FOSFEC\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#numero-de-aportes-de-empresas-atendidas-por-educacion","title":"N\u00famero de aportes de empresas atendidas por Educaci\u00f3n","text":"<ul> <li> <p>Objetivo:   Reflejar el n\u00famero total de aportes de empresas atendidas por el \u00e1rea de Educaci\u00f3n.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>[# Aportes Totales]\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#atencion-poblacion-vulnerable","title":"Atenci\u00f3n poblaci\u00f3n vulnerable","text":"<ul> <li> <p>Objetivo:   Calcular la cobertura ejecutada para la poblaci\u00f3n vulnerable, excluyendo ciertos factores de vulnerabilidad espec\u00edficos (por ejemplo, aquellos con ID de vulnerabilidad igual a -1, 13, o valores en blanco).</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    [Cobertura ejecutada], \n    'Transversal DIM_FACTOR_DE_VULNERABILIDAD'[ID_FACTOR_VULNERABILIDAD] &lt;&gt; -1,\n    'Transversal DIM_FACTOR_DE_VULNERABILIDAD'[ID_FACTOR_VULNERABILIDAD] &lt;&gt; 13,\n    'Transversal DIM_FACTOR_DE_VULNERABILIDAD'[ID_FACTOR_VULNERABILIDAD] &lt;&gt; BLANK()\n)\n\nRETURN IF( ISBLANK(dev) , 0 , dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#accidentalidad-de-la-poblacion-estudiantil","title":"% accidentalidad de la poblaci\u00f3n estudiantil","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de estudiantes que han recibido atenci\u00f3n en enfermer\u00eda, comparado con el total de estudiantes matriculados en el colegio.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR EstudiantesEnfermeria = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ENFERMERIA\"\n)\n\nVAR EstudiantesColegio = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\",\n    'Transversal DIM_CAPACIDAD_FISICA'[ID_UNIDAD] = 1\n)\n\nvar dev = DIVIDE(EstudiantesEnfermeria, EstudiantesColegio, 0)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#estudiantes-matriculados-con-documentos-completos-del-total-de-matriculados","title":"% Estudiantes matriculados con documentos completos del total de matriculados","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de estudiantes matriculados que tienen todos los documentos completos, en relaci\u00f3n con el total de matriculados.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>[% de Estudiantes matriculados con documentos completos del total de matriculados]\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#detractores-promedio-del-proceso-a-partir-de-la-nsu","title":"Detractores promedio del proceso a partir de la NSU","text":"<pre><code>* **Objetivo:**\n  Calcular el porcentaje de detractores en el proceso, considerando las calificaciones por debajo de 7 en la actividad \"NSU\" en relaci\u00f3n con el total de participantes.\n\n* **Expresi\u00f3n DAX:**\n\n  ```DAX\n  VAR Total = CALCULATE(\n      DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n      'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"NSU\"\n  )\n\n  VAR Detractores = CALCULATE(\n      DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n      FILTER(\n          'Transversal FACT_ACTIVIDADES',\n          'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"NSU\" &amp;&amp;\n          IFERROR(VALUE('Transversal FACT_ACTIVIDADES'[CALIFICACION]), BLANK()) &lt; 7\n      )\n  )\n\n  var dev = Divide(Detractores, Total, 0)\n\n  return dev\n  ```\n\n* **Formato:** Num\u00e9rico.\n</code></pre>"},{"location":"03.Cubo/01.Origen/#afiliados-atendidos","title":"%Afiliados Atendidos","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de afiliados atendidos en relaci\u00f3n con el total de afiliados potenciales.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = divide( [#Afiliados_Atendidos], [# Afiliados Potenciales], 0)\n\nreturn IF( ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#resultado-nps","title":"Resultado NPS","text":"<ul> <li> <p>Objetivo:   Calcular el promedio de las calificaciones no en blanco para la actividad, representando el resultado del Net Promoter Score (NPS).</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = AVERAGEX(\n    FILTER(\n        'Transversal FACT_ACTIVIDADES',\n        'Transversal FACT_ACTIVIDADES'[CALIFICACION] &lt;&gt; BLANK()\n    ),\n    IFERROR(\n        VALUE('Transversal FACT_ACTIVIDADES'[CALIFICACION]),\n        0\n    )\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#variacion-desercion-respecto-vigencia-anterior","title":"Variaci\u00f3n deserci\u00f3n respecto vigencia anterior","text":"<ul> <li> <p>Objetivo:   Calcular la variaci\u00f3n porcentual en la deserci\u00f3n de estudiantes respecto al a\u00f1o anterior, considerando la diferencia entre los retiros actuales y los del a\u00f1o anterior.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR Retiros_Ano_Actual = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"RETIROS\"\n)\n\nVAR Fecha_Actual_Min = MIN('Transversal FACT_ACTIVIDADES'[ID_FECHA])\nVAR Fecha_Actual_Max = MAX('Transversal FACT_ACTIVIDADES'[ID_FECHA])\n\nVAR Fecha_Anterior_Min = DATE(\n    YEAR(DATE(\n        DIVIDE(Fecha_Actual_Min, 10000),\n        MOD(DIVIDE(Fecha_Actual_Min, 100), 100),\n        MOD(Fecha_Actual_Min, 100)\n    )) - 1,\n    MONTH(DATE(\n        DIVIDE(Fecha_Actual_Min, 10000),\n        MOD(DIVIDE(Fecha_Actual_Min, 100), 100),\n        MOD(Fecha_Actual_Min, 100)\n    )),\n    DAY(DATE(\n        DIVIDE(Fecha_Actual_Min, 10000),\n        MOD(DIVIDE(Fecha_Actual_Min, 100), 100),\n        MOD(Fecha_Actual_Min, 100)\n    ))\n)\n\nVAR Fecha_Anterior_Max = DATE(\n    YEAR(DATE(\n        DIVIDE(Fecha_Actual_Max, 10000),\n        MOD(DIVIDE(Fecha_Actual_Max, 100), 100),\n        MOD(Fecha_Actual_Max, 100)\n    )) - 1,\n    MONTH(DATE(\n        DIVIDE(Fecha_Actual_Max, 10000),\n        MOD(DIVIDE(Fecha_Actual_Max, 100), 100),\n        MOD(Fecha_Actual_Max, 100)\n    )),\n    DAY(DATE(\n        DIVIDE(Fecha_Actual_Max, 10000),\n        MOD(DIVIDE(Fecha_Actual_Max, 100), 100),\n        MOD(Fecha_Actual_Max, 100)\n    ))\n)\n\nVAR ID_Fecha_Anterior_Min = YEAR(Fecha_Anterior_Min) * 10000 + MONTH(Fecha_Anterior_Min) * 100 + DAY(Fecha_Anterior_Min)\nVAR ID_Fecha_Anterior_Max = YEAR(Fecha_Anterior_Max) * 10000 + MONTH(Fecha_Anterior_Max) * 100 + DAY(Fecha_Anterior_Max)\n\nVAR Retiros_Ano_Anterior = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"RETIROS\",\n    'Transversal FACT_ACTIVIDADES'[ID_FECHA] &gt;= ID_Fecha_Anterior_Min,\n    'Transversal FACT_ACTIVIDADES'[ID_FECHA] &lt;= ID_Fecha_Anterior_Max\n)\n\nvar dev = IF(\n    NOT ISBLANK(Retiros_Ano_Anterior),\n    (Retiros_Ano_Actual - Retiros_Ano_Anterior) / Retiros_Ano_Anterior,\n    BLANK()\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#aportes-educacionaportes-totales","title":"% Aportes Educaci\u00f3n/Aportes Totales","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de aportes realizados por las empresas atendidas por Educaci\u00f3n en relaci\u00f3n con el total de aportes.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>DIVIDE([Valor de aportes empresas atendidas Educacion], [Valor Aportes Totales], 0)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#ingresos-ejecutados","title":"Ingresos Ejecutados","text":"<pre><code>* **Objetivo:**\n  Calcular el total de ingresos ejecutados en la actividad \"EJECUCION\\_CONTABLE\" dentro de la tabla `Transversal FACT_FINANCIERA`.\n\n* **Expresi\u00f3n DAX:**\n\n  ```DAX\n  var Ingresos = \n      CALCULATE(\n          SUM('Transversal FACT_FINANCIERA'[INGRESOS]),\n          'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"EJECUCION_CONTABLE\"\n      )\n\n  return IF(ISBLANK(Ingresos), 0, Ingresos)\n  ```\n\n* **Formato:** Num\u00e9rico.\n</code></pre>"},{"location":"03.Cubo/01.Origen/#ingresos-presupuestados","title":"Ingresos Presupuestados","text":"<ul> <li> <p>Objetivo:   Calcular el total de ingresos presupuestados en la actividad \"PRESUPUESTO_CONTABLE\" dentro de la tabla <code>Transversal FACT_FINANCIERA</code>.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var Ingresos = \n    CALCULATE(\n        SUM('Transversal FACT_FINANCIERA'[INGRESOS]),\n        'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"PRESUPUESTO_CONTABLE\"\n    )\n\nreturn IF(ISBLANK(Ingresos), 0, Ingresos)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#costos-ejecutados","title":"Costos Ejecutados","text":"<ul> <li> <p>Objetivo:   Calcular el total de costos ejecutados en la actividad \"EJECUCION_CONTABLE\", sumando los valores de gastos y costos dentro de la tabla <code>Transversal FACT_FINANCIERA</code>.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var Costos = \n    CALCULATE(\n        SUM('Transversal FACT_FINANCIERA'[GASTOS]) + SUM('Transversal FACT_FINANCIERA'[COSTOS]),\n        'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"EJECUCION_CONTABLE\"\n    )\n\nreturn IF(ISBLANK(Costos), 0, Costos)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#costos-presupuestados","title":"Costos Presupuestados","text":"<ul> <li> <p>Objetivo:   Calcular el total de costos presupuestados en la actividad \"PRESUPUESTO_CONTABLE\", sumando los valores de gastos y costos dentro de la tabla <code>Transversal FACT_FINANCIERA</code>.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var Costos = \n    CALCULATE(\n        SUM('Transversal FACT_FINANCIERA'[GASTOS]) + SUM('Transversal FACT_FINANCIERA'[COSTOS]),\n        'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"PRESUPUESTO_CONTABLE\"\n    )\n\nreturn IF(ISBLANK(Costos), 0, Costos)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#empresas-potenciales","title":"# Empresas Potenciales","text":"<ul> <li> <p>Objetivo:   Calcular el n\u00famero de empresas potenciales, excluyendo aquellas con ID de empresa igual a -1, y aplicando filtros espec\u00edficos por unidad organizacional.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR EmpresasCalculo = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n    )\n\nVAR EmpresasCalculoSinFiltros = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nvar dev = SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2,4}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, EmpresasCalculoSinFiltros,\n    EmpresasCalculo\n)\n\nRETURN IF( ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#afiliados-potenciales","title":"# Afiliados Potenciales","text":"<ul> <li> <p>Objetivo:   Calcular la cantidad de afiliados potenciales, aplicando filtros por tipo de poblaci\u00f3n y categor\u00eda, con especial \u00e9nfasis en los afiliados con ciertas caracter\u00edsticas demogr\u00e1ficas como edad y discapacidad.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR AfiliadosCalculo = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n    )\n\nVAR AfiliadosCalculoSinFiltros = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nVAR AfiliadosPotencialTecnica =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        'Transversal FACT_ACTIVIDADES'[Mayor_igual_18_Anios] = \"SI\",\n        'Transversal FACT_ACTIVIDADES'[Menor_60_Anios] = \"SI\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nVAR dev = SWITCH(\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 3}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2}, AfiliadosPotencialTecnica,\n    AfiliadosCalculo\n)\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#beneficiarios-potenciales","title":"# Beneficiarios Potenciales","text":"<ul> <li> <p>Objetivo:   Calcular el n\u00famero de beneficiarios potenciales, segmentando por diversas categor\u00edas demogr\u00e1ficas y aplicando filtros por unidad organizacional y programa de protecci\u00f3n.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR BeneficiariosCalculo = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n    )\n\nVAR BeneficiariosCalculoSinFiltros = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nVAR BeneficiariosPotencialFormal =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        'Transversal FACT_ACTIVIDADES'[EDAD] &gt;= 5,\n        'Transversal FACT_ACTIVIDADES'[EDAD] &lt; 18,\n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nVAR BeneficiariosPotencialTecnica =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        'Transversal FACT_ACTIVIDADES'[EDAD] &gt;= 18,\n        'Transversal FACT_ACTIVIDADES'[EDAD] &lt; 60,\n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nVAR BeneficiariosPotencialProteccion =\n    SWITCH(\n        TRUE(),\n        SELECTEDVALUE('Proteccion DIM_PROGRAMA'[ID_PROGRAMA]) IN {1},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[Mayor_igual_60_Anios] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'),\n                REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        SELECTEDVALUE('Proteccion DIM_PROGRAMA'[ID_PROGRAMA]) IN {2},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                VALUE('Transversal FACT_ACTIVIDADES'[DISCAPACIDAD]) = 1,\n                REMOVEFILTERS('Transversal DIM_UNIDAD'),\n                REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        SELECTEDVALUE('Proteccion DIM_PROGRAMA'[ID_PROGRAMA]) IN {3},\n            0,\n        SELECTEDVALUE('Proteccion DIM_PROGRAMA'[ID_PROGRAMA]) IN {4},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[Menor_6_Anios] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'),\n                REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        CALCULATE(\n            DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n            'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n            'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n            'Transversal FACT_ACTIVIDADES'[Potencial_Proteccion] = \"SI\",\n            REMOVEFILTERS('Transversal DIM_UNIDAD'),\n            REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n        )\n    )\n\nvar dev = SWITCH(\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1}, BeneficiariosPotencialFormal,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2}, BeneficiariosPotencialTecnica,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4}, BeneficiariosPotencialProteccion,\n    BeneficiariosCalculo\n)\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#empresas-impactadas","title":"# Empresas Impactadas","text":"<ul> <li> <p>Objetivo:   Calcular el n\u00famero de empresas impactadas en diferentes niveles educativos, incluyendo educaci\u00f3n formal, t\u00e9cnica, continua y protecci\u00f3n social.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR EmpresasImpactadas =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION] = \"SI\"\n    )\n\nVAR dev = \n    SWITCH(\n        TRUE(),\n        SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_FORMAL] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'), REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_TECNICA] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'), REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_CONTINUA] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'), REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_PROTECCION] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'), REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        EmpresasImpactadas\n    )\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#afiliados-impactados","title":"# Afiliados Impactados","text":"<ul> <li> <p>Objetivo:   Calcular el n\u00famero de afiliados impactados por la educaci\u00f3n en diferentes niveles, como educaci\u00f3n formal, t\u00e9cnica, continua y protecci\u00f3n social.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR AfiliadosImpactados =\n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n        'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n        'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION] = \"SI\"\n    )\n\nVAR dev = \n    SWITCH(\n        TRUE(),\n        SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_FORMAL] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'), REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_TECNICA] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'), REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_CONTINUA] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'), REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4},\n            CALCULATE(\n                DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n                'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n                'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n                'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_PROTECCION] = \"SI\",\n                REMOVEFILTERS('Transversal DIM_UNIDAD'), REMOVEFILTERS('Proteccion DIM_PROGRAMA')\n            ),\n        AfiliadosImpactados\n    )\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#beneficiarios-impactados","title":"# Beneficiarios Impactados","text":"<ul> <li> <p>Objetivo:   Calcular el n\u00famero de beneficiarios impactados por diferentes niveles de educaci\u00f3n seg\u00fan la unidad seleccionada, considerando formal, t\u00e9cnica, continua y protecci\u00f3n.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR SelectedUnidad = SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD], BLANK())\n\nRETURN\nCALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n    FILTER(\n        'Transversal FACT_ACTIVIDADES',\n        SWITCH(\n            TRUE(),\n            ISBLANK(SelectedUnidad), 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION] = \"SI\", -- Condici\u00f3n general si no se selecciona unidad\n            SelectedUnidad = 1, 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_FORMAL] = \"SI\",\n            SelectedUnidad = 2, 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_TECNICA] = \"SI\",\n            SelectedUnidad = 3, 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_CONTINUA] = \"SI\",\n            SelectedUnidad = 4, 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION_PROTECCION] = \"SI\",\n            SelectedUnidad = 5, 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION] = \"SI\",\n            FALSE -- Para manejar cualquier otro caso no especificado\n        )\n    )\n)\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#ingresos-ejecutados-fondo-jec","title":"# Ingresos ejecutados fondo JEC","text":"<ul> <li> <p>Objetivo:   Calcular los ingresos ejecutados espec\u00edficamente para el fondo de la Jornada Escolar Complementaria (JEC), restringido a las cuentas y CEBE correspondientes.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = \nCALCULATE(\n    [Ingresos Ejecutados],\n    --VALUE( 'Transversal FACT_FINANCIERA'[ID_CUENTA]) IN {941, 953},'Transversal FACT_FINANCIERA'[AREA] =\"JORNADA ESCOLAR COMPLEMENTARIA\",\n    'Transversal FACT_FINANCIERA'[ID_CEBE] IN {11911, 11912, 11913, 11914, 11915, 11916}\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#costos-ejecutados-fondo-jec","title":"# Costos ejecutados fondo JEC","text":"<ul> <li> <p>Objetivo:   Calcular los costos ejecutados espec\u00edficamente para el fondo de la Jornada Escolar Complementaria (JEC), restringido a las cuentas y CEBE correspondientes.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = \nCALCULATE(\n    [Costos Ejecutados],\n    --VALUE( 'Transversal FACT_FINANCIERA'[ID_CUENTA]) IN {941, 953},'Transversal FACT_FINANCIERA'[AREA] =\"JORNADA ESCOLAR COMPLEMENTARIA\",\n    'Transversal FACT_FINANCIERA'[ID_CEBE] IN {11911, 11912, 11913, 11914, 11915, 11916}\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#ingresos-ejecutados-fondo-aipi","title":"# Ingresos Ejecutados fondo AIPI","text":"<ul> <li> <p>Objetivo:   Calcular los ingresos ejecutados espec\u00edficamente para el fondo de Atenci\u00f3n Integral a la Ni\u00f1ez (AIPI), restringido a las cuentas y CEBE correspondientes.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    [Ingresos Ejecutados],\n    --VALUE( 'Transversal FACT_FINANCIERA'[ID_CUENTA]) IN {941, 953},'Transversal FACT_FINANCIERA'[AREA] =\"ATENCION INTEGRAL A LA NINEZ\",\n    'Transversal FACT_FINANCIERA'[ID_CEBE] IN {1196, 1197, 11991, 11992}\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#costos-ejecutados-fondo-aipi","title":"# Costos Ejecutados fondo AIPI","text":"<ul> <li> <p>Objetivo:   Calcular los costos ejecutados espec\u00edficamente para el fondo de Atenci\u00f3n Integral a la Ni\u00f1ez (AIPI), restringido a las cuentas y CEBE correspondientes.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var dev = CALCULATE(\n    [Costos Ejecutados],\n    --VALUE( 'Transversal FACT_FINANCIERA'[ID_CUENTA]) IN {941, 953},'Transversal FACT_FINANCIERA'[AREA] =\"ATENCION INTEGRAL A LA NINEZ\",\n    'Transversal FACT_FINANCIERA'[ID_CEBE] IN {1196, 1197, 11991, 11992}\n)\n\nreturn dev\n</code></pre> <ul> <li>Formato: Num\u00e9rico.</li> </ul>"},{"location":"03.Cubo/01.Origen/#variacion-porcentual-saber-11-respecto-al-ano-anterior","title":"# Variaci\u00f3n Porcentual Saber 11 respecto al a\u00f1o anterior","text":"<ul> <li> <p>Objetivo:   Calcular la variaci\u00f3n porcentual del resultado del examen Saber 11 en comparaci\u00f3n con el a\u00f1o anterior.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR ResultadoActual = \n    SUMX(\n        'Transversal FACT_UNIDADES',\n        IF(\n            ISNUMBER('Transversal FACT_UNIDADES'[RESULTADO]),\n            'Transversal FACT_UNIDADES'[RESULTADO],\n            0\n        )\n    )\n\nVAR ResultadoAnterior = \n    CALCULATE(\n        SUMX(\n            'Transversal FACT_UNIDADES',\n            IF(\n                ISNUMBER('Transversal FACT_UNIDADES'[RESULTADO]),\n                'Transversal FACT_UNIDADES'[RESULTADO],\n                0\n            )\n        ),\n        PREVIOUSYEAR('Transversal DIM_TIEMPO_MENSUAL'[FECHA])\n    )\n\nRETURN \n    IF(\n        ResultadoAnterior = 0,\n        BLANK(),\n        DIVIDE(ResultadoActual - ResultadoAnterior, ResultadoAnterior, BLANK())\n    )\n</code></pre> <ul> <li>Formato: Porcentaje.</li> </ul>"},{"location":"03.Cubo/01.Origen/#de-beneficiarios-de-empresa-atendida-por-educacion","title":"% de Beneficiarios de Empresa atendida por Educaci\u00f3n","text":"<ul> <li> <p>Objetivo:   Calcular el porcentaje de beneficiarios de empresas que han sido atendidos por el \u00e1rea de Educaci\u00f3n.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var Poblacion = [# Beneficiarios Caja]\nvar PoblacionAtendida = [#Beneficiarios_Atendidos]\nvar dev = DIVIDE(PoblacionAtendida, Poblacion, 0)\nRETURN IF( ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Porcentaje.</li> </ul>"},{"location":"03.Cubo/01.Origen/#subsidioaportes","title":"Subsidio/Aportes","text":"<ul> <li> <p>Objetivo:   Calcular la proporci\u00f3n entre el subsidio otorgado y los aportes totales.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>var subsidio = [Valor de subsidio a la demanda]\nvar aportes = [Valor Aportes Totales]\nvar dev = divide(subsidio, aportes, 0)\nreturn IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: Porcentaje.</li> </ul>"},{"location":"03.Cubo/01.Origen/#retiros","title":"# Retiros","text":"<ul> <li> <p>Objetivo:   Calcular el n\u00famero total de retiros registrados, teniendo en cuenta las diferentes unidades y periodos.</p> </li> <li> <p>Expresi\u00f3n DAX:</p> </li> </ul> <pre><code>VAR colegio_retiros = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"RETIROS\",\n    'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5, \n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n    DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA])\n)\n\nVAR colegio_retirosNoAfiliada = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"RETIROS\",\n    'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] = -1,\n    'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] = -1,\n    'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] = -1,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n    DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA])\n)\n\nVAR InicioSemestre = IF(\n    MONTH(MINX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])) &lt;= 6,\n    DATE(YEAR(MINX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])), 1, 1), -- Primer semestre\n    DATE(YEAR(MINX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])), 7, 1) -- Segundo semestre\n)\n\nVAR FinSemestre = IF(\n    MONTH(MAXX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])) &lt;= 6,\n    DATE(YEAR(MAXX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])), 6, 30), -- Fin del primer semestre\n    DATE(YEAR(MAXX(DATESYTD('Transversal DIM_TIEMPO_MENSUAL'[FECHA]), 'Transversal DIM_TIEMPO_MENSUAL'[FECHA])), 12, 31) -- Fin del segundo semestre\n)\n\nVAR RetirosCedesarrollo = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_DESERCION]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"RETIROS\",\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 2,\n    DATESBETWEEN('Transversal DIM_TIEMPO_MENSUAL'[FECHA], InicioSemestre, FinSemestre),\n    REMOVEFILTERS('Transversal FACT_ACTIVIDADES'[ID_UNIDAD])\n)\n\nVAR RetirosDE = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_DESERCION]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"RETIROS\",\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 3,\n    REMOVEFILTERS('Transversal FACT_ACTIVIDADES'[ID_UNIDAD])\n)\n\nVAR dev = SWITCH(\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1}, colegio_retiros + colegio_retirosNoAfiliada,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {2}, RetirosCedesarrollo,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {3}, RetirosDE,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {4}, 0,\n    colegio_retiros + colegio_retirosNoAfiliada + RetirosCedesarrollo + RetirosDE\n)\n\nRETURN IF(ISBLANK(dev), 0, dev)\n</code></pre> <ul> <li>Formato: N\u00famero.</li> </ul>"},{"location":"03.Cubo/01.Origen/#proposito_1","title":"Prop\u00f3sito","text":"<ol> <li> <p>Proveer c\u00e1lculos espec\u00edficos como conteos, sumas, promedios y agregaciones sobre datos transversales, incluyendo afiliados, beneficiarios, empresas, aportes y actividades realizadas.</p> </li> <li> <p>Facilitar m\u00e9tricas clave como n\u00famero de unidades, afiliados atendidos, beneficiarios impactados, aportes totales, ingresos ejecutados, costos presupuestados y variaciones porcentuales.</p> </li> <li> <p>Apoyar an\u00e1lisis avanzados mediante la eliminaci\u00f3n de restricciones de filtros y la aplicaci\u00f3n de l\u00f3gicas condicionales seg\u00fan unidades, programas y actividades espec\u00edficas.</p> </li> <li> <p>Generar informaci\u00f3n valiosa para la toma de decisiones estrat\u00e9gicas y operativas, incluyendo indicadores de desempe\u00f1o, cobertura, efectividad, deserci\u00f3n, rotaci\u00f3n y satisfacci\u00f3n.</p> </li> <li> <p>Proveer soporte para la evaluaci\u00f3n de programas educativos, protecci\u00f3n social, desarrollo empresarial y otros servicios ofrecidos por la organizaci\u00f3n.</p> </li> </ol>"},{"location":"03.Cubo/02.Tablas%20copy/","title":"02.Tablas copy","text":""},{"location":"03.Cubo/02.Tablas%20copy/#tablas","title":"Tablas","text":""},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-dim_unidad","title":"Tabla: Transversal DIM_UNIDAD","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_UNIDAD es una dimensi\u00f3n que define las unidades organizacionales o funcionales del sistema. Esta tabla es fundamental para categorizar y segmentar datos relacionados con las actividades y procesos empresariales.</p> <p></p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla","title":"Estructura de la Tabla","text":"<p>1. Nombre de la Tabla: <code>Transversal DIM_UNIDAD</code>.</p> <p>2. Columnas:</p> <ul> <li>ID_UNIDAD:<ul> <li>Tipo de Datos: <code>int64</code>.</li> <li>Descripci\u00f3n: Identificador \u00fanico de cada unidad.</li> <li>Columna Fuente: <code>ID_UNIDAD</code>.</li> </ul> </li> <li>UNIDAD:<ul> <li>Tipo de Datos: <code>string</code>.</li> <li>Descripci\u00f3n: Nombre descriptivo de la unidad.</li> <li>Columna Fuente: <code>UNIDAD</code>.</li> </ul> </li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#particiones","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos de la tabla).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_UNIDAD = Source{[Schema=\"Transversal\", Item=\"DIM_UNIDAD\"]}[Data]\nin\n    Transversal_DIM_UNIDAD\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_UNIDAD se utiliza para:</p> <ul> <li>Proveer una referencia jer\u00e1rquica o categ\u00f3rica para an\u00e1lisis y segmentaciones.</li> <li>Establecer relaciones con otras tablas, como hechos o medidas, en el modelo sem\u00e1ntico del cubo.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#relacion-con-el-cubo","title":"Relaci\u00f3n con el Cubo","text":"<p>Esta tabla se integra con otras dimensiones y hechos para calcular medidas como: - N\u00famero de actividades por unidad. - Rendimiento de procesos espec\u00edficos.</p> <p>Entendido, aqu\u00ed est\u00e1 la documentaci\u00f3n ajustada con la numeraci\u00f3n en negritas dentro del formato Markdown:</p>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-dim_tiempo_mensual","title":"Tabla: Transversal DIM_TIEMPO_MENSUAL","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_TIEMPO_MENSUAL es una dimensi\u00f3n de tiempo que permite segmentar los datos en diferentes niveles temporales, como d\u00edas, semanas, meses, bimestres, trimestres, cuatrimestres, semestres y a\u00f1os. Proporciona una estructura detallada para an\u00e1lisis cronol\u00f3gicos.</p> <p></p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_1","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA FECHA dateTime FECHA DESC_FECHA string DESC_FECHA ID_SEMANA int64 ID_SEMANA DESC_SEMANA string DESC_SEMANA ID_NO_MES int64 ID_NO_MES DESC_NO_MES string DESC_NO_MES ID_MES int64 ID_MES DESC_MES string DESC_MES DESC_MES_CORTA string DESC_MES_CORTA ID_BIMESTRE int64 ID_BIMESTRE DESC_BIMESTRE string DESC_BIMESTRE ID_TRIMESTRE int64 ID_TRIMESTRE DESC_TRIMESTRE string DESC_TRIMESTRE ID_CUATRIMESTRE int64 ID_CUATRIMESTRE DESC_CUATRIMESTRE string DESC_CUATRIMESTRE ID_SEMESTRE int64 ID_SEMESTRE DESC_SEMESTRE string DESC_SEMESTRE ID_ANIO int64 ID_ANIO ID_ANIO_ANT int64 ID_ANIO_ANT NUM_DIA_SEMANA int64 NUM_DIA_SEMANA FESTIVO int64 FESTIVO FECHA_CORTA dateTime FECHA_CORTA"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_1","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:       <pre><code>let\n      Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n      Transversal_DIM_TIEMPO_MENSUAL = Source{[Schema=\"Transversal\",Item=\"DIM_TIEMPO_MENSUAL\"]}[Data]\nin\n      Transversal_DIM_TIEMPO_MENSUAL\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_1","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_TIEMPO_MENSUAL se utiliza para:</p> <ul> <li>Segmentar datos en intervalos de tiempo espec\u00edficos.</li> <li>Proporcionar jerarqu\u00edas temporales para an\u00e1lisis (d\u00eda, semana, mes, bimestre, trimestre, cuatrimestre, semestre y a\u00f1o).</li> <li>Relacionar datos temporales con otras dimensiones y hechos para an\u00e1lisis detallados.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-dim_categoria","title":"Tabla: Transversal DIM_CATEGORIA","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_CATEGORIA define las categor\u00edas utilizadas en el modelo para clasificar datos. Esta dimensi\u00f3n permite agrupar y segmentar informaci\u00f3n relacionada con diferentes \u00e1reas del sistema.</p> <p></p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_2","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente COD_CATEGORIA string COD_CATEGORIA DESCRIPCION string DESCRIPCION"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_2","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_CATEGORIA = Source{[Schema=\"Transversal\",Item=\"DIM_CATEGORIA\"]}[Data]\nin\n    Transversal_DIM_CATEGORIA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_2","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_CATEGORIA se utiliza para:</p> <ul> <li>Clasificar informaci\u00f3n en grupos o categor\u00edas predefinidas.</li> <li>Relacionar datos categorizados con otras dimensiones y hechos para an\u00e1lisis m\u00e1s detallados.</li> <li>Facilitar la segmentaci\u00f3n de datos en reportes y consultas.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-fact_actividades","title":"Tabla: Transversal FACT_ACTIVIDADES","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_ACTIVIDADES registra informaci\u00f3n detallada sobre las actividades realizadas por afiliados y empresas, incluyendo datos demogr\u00e1ficos, econ\u00f3micos, y sobre aportes. Esta tabla es clave para el an\u00e1lisis de hechos y m\u00e9tricas relacionadas con las actividades.</p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_3","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente PARTNER string PARTNER ID_EMPRESA int64 ID_EMPRESA ID_AFILIADO int64 ID_AFILIADO ID_TIPO_AFILIADO int64 ID_TIPO_AFILIADO TIPO_AFILIADO string TIPO_AFILIADO ID_CATEGORIA int64 ID_CATEGORIA FECHA_AFILIACION dateTime FECHA_AFILIACION FECHA_RETIRO dateTime FECHA_RETIRO ID_GENERO int64 ID_GENERO ID_ESTADO_CIVIL int64 ID_ESTADO_CIVIL ID_PERTENENCIA_ETNICA int64 ID_PERTENENCIA_ETNICA ID_FACTOR_VULNERABILIDAD int64 ID_FACTOR_VULNERABILIDAD ESTRATO int64 ESTRATO ID_CIUDAD int64 ID_CIUDAD SALARIO_BASICO double SALARIO_BASICO FECHA_MENSUAL dateTime FECHA_MENSUAL ID_FECHA int64 ID_FECHA ID_UNIDAD int64 ID_UNIDAD ESTADOREGISTRO string ESTADOREGISTRO PARTNER_AFILIADO string PARTNER_AFILIADO PARTNER_EMPRESA string PARTNER_EMPRESA TIPO_POBLACION string TIPO_POBLACION ACTIVIDAD string ACTIVIDAD TOTAL_APORTES double TOTAL_APORTES NUMERO_APORTES int64 NUMERO_APORTES"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_3","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_ACTIVIDADES = Source{[Schema=\"Transversal\",Item=\"FACT_ACTIVIDADES\"]}[Data]\nin\n    Transversal_FACT_ACTIVIDADES\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_3","title":"Prop\u00f3sito","text":"<p>La tabla FACT_ACTIVIDADES se utiliza para:</p> <ul> <li>Analizar informaci\u00f3n demogr\u00e1fica, econ\u00f3mica y de aportes de afiliados y empresas.</li> <li>Calcular m\u00e9tricas relacionadas con actividades y aportes.</li> <li>Proveer datos detallados para informes y an\u00e1lisis multidimensionales.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-fact_personal","title":"Tabla: Transversal FACT_PERSONAL","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_PERSONAL almacena informaci\u00f3n relacionada con el personal, sus asignaciones y las horas contratadas. Es \u00fatil para el an\u00e1lisis de recursos humanos y la planificaci\u00f3n operativa.</p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_4","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA ID_PERSONAL int64 ID_PERSONAL NOMBRE string NOMBRE CONCEPTO string CONCEPTO DESCRIPCION string DESCRIPCION FECHA_FIN dateTime FECHA_FIN HORAS_CONTRATADAS_MENSUAL int64 HORAS_CONTRATADAS_MENSUAL ID_UNIDAD int64 ID_UNIDAD"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_4","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_PERSONAL = Source{[Schema=\"Transversal\",Item=\"FACT_PERSONAL\"]}[Data]\nin\n    Transversal_FACT_PERSONAL\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_4","title":"Prop\u00f3sito","text":"<p>La tabla FACT_PERSONAL se utiliza para:</p> <ul> <li>Analizar las asignaciones y contratos del personal.</li> <li>Monitorear las horas contratadas mensualmente.</li> <li>Relacionar los datos del personal con otras dimensiones para informes y planificaci\u00f3n estrat\u00e9gica.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-fact_financiera","title":"Tabla: Transversal FACT_FINANCIERA","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_FINANCIERA contiene informaci\u00f3n detallada sobre los datos financieros de la organizaci\u00f3n, incluyendo cuentas, ingresos, gastos, y resultados. Es una fuente fundamental para el an\u00e1lisis financiero y la generaci\u00f3n de informes.</p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_5","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA ID_ANIO int64 ID_ANIO ID_MES int64 ID_MES ID_CEBE string ID_CEBE CEBE string CEBE DESCRIPCION_CEBE string DESCRIPCION_CEBE DEPARTAMENTO string DEPARTAMENTO AREA string AREA SUBAREA string SUBAREA SEGMENTO string SEGMENTO DESCRIPCION_SEGMENTO string DESCRIPCION_SEGMENTO CODIGO_SSF int64 CODIGO_SSF NOMBRE_SSF string NOMBRE_SSF ID_CUENTA string ID_CUENTA CUENTA string CUENTA CUENTA_HOMOLOGA string CUENTA_HOMOLOGA DESCRIPCION string DESCRIPCION TIPO_CUENTA string TIPO_CUENTA TIPO_OPERACION string TIPO_OPERACION GRUPO_CUENTA string GRUPO_CUENTA SUBGRUPO_CUENTA string SUBGRUPO_CUENTA GRUPO_OPERACION string GRUPO_OPERACION CUENTA_SSF string CUENTA_SSF DESCRIPCION_SSF string DESCRIPCION_SSF CUENTA_DESCRIPCION string CUENTA_DESCRIPCION CUENTA_DESCRIPCION_SSF string CUENTA_DESCRIPCION_SSF SIGNO_INGRESOS int64 SIGNO_INGRESOS CLASIFICACION int64 CLASIFICACION SEGMENT string SEGMENT IMPORTE int64 IMPORTE INGRESOS int64 INGRESOS INGRESOS_OPERACIONALES int64 INGRESOS_OPERACIONALES GASTOS int64 GASTOS GASTOS_OPERACIONALES int64 GASTOS_OPERACIONALES GASTOS_OPERACIONALES_ADMIN int64 GASTOS_OPERACIONALES_ADMIN RESULTADO_EJERCICIO int64 RESULTADO_EJERCICIO COSTOS int64 COSTOS ACTIVO int64 ACTIVO PASIVO int64 PASIVO PATRIMONIO int64 PATRIMONIO GASTOS_CON_DISTRIBUCION int64 GASTOS_CON_DISTRIBUCION GASTOS_SIN_DISTRIBUCION int64 GASTOS_SIN_DISTRIBUCION"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_5","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_FINANCIERA = Source{[Schema=\"Transversal\",Item=\"FACT_FINANCIERA\"]}[Data]\nin\n    Transversal_FACT_FINANCIERA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_5","title":"Prop\u00f3sito","text":"<p>La tabla FACT_FINANCIERA se utiliza para:</p> <ul> <li>Analizar el comportamiento financiero de la organizaci\u00f3n.</li> <li>Evaluar ingresos, gastos, costos, y resultados financieros.</li> <li>Relacionar los datos financieros con otras dimensiones para an\u00e1lisis multidimensionales y generaci\u00f3n de informes detallados.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-fact_evaluacion_docente","title":"Tabla: Transversal FACT_EVALUACION_DOCENTE","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_EVALUACION_DOCENTE almacena informaci\u00f3n relacionada con las evaluaciones acad\u00e9micas de los docentes, incluyendo calificaciones definitivas, per\u00edodos acad\u00e9micos y datos personales. Es clave para el an\u00e1lisis del desempe\u00f1o docente.</p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_6","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente PERIODO_ACADEMICO string PERIODO_ACADEMICO ID_UNIDAD int64 ID_UNIDAD ID_PERSONAL int64 ID_PERSONAL NOMBRE_DOCENTE string NOMBRE_DOCENTE CALIFICACION_DEFINITIVA string CALIFICACION_DEFINITIVA ID_FECHA int64 ID_FECHA"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_6","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_EVALUACION_DOCENTE = Source{[Schema=\"Transversal\",Item=\"FACT_EVALUACION_DOCENTE\"]}[Data]\nin\n    Transversal_FACT_EVALUACION_DOCENTE\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_6","title":"Prop\u00f3sito","text":"<p>La tabla FACT_EVALUACION_DOCENTE se utiliza para:</p> <ul> <li>Analizar el desempe\u00f1o acad\u00e9mico de los docentes.</li> <li>Generar informes de calificaciones definitivas por per\u00edodo acad\u00e9mico.</li> <li>Relacionar datos de evaluaci\u00f3n docente con otras dimensiones como unidades y fechas.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-calculatedtableindicadores","title":"Tabla: CalculatedTableIndicadores","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>La tabla CalculatedTableIndicadores es una tabla calculada que contiene indicadores clave para el an\u00e1lisis y evaluaci\u00f3n del rendimiento en diversas \u00e1reas, como cobertura, movilidad acad\u00e9mica, promoci\u00f3n, deserci\u00f3n, matr\u00edculas, graduados, y satisfacci\u00f3n.</p> <p></p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_7","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente indicador string (calculada) [indicador]"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_7","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>CalculatedTable 1</code>.</p> <p>2. Fuente:</p> <ul> <li>Tipo: <code>calculated</code>.</li> <li>Expresi\u00f3n:      <pre><code>DATATABLE (\n    \"indicador\", STRING, \n    { \n        {\"Cumplimiento Cobertura\"},\n        {\"Cobertura Proyectada\"},\n        {\"Movilidad Academica\"},\n        {\"Porcentaje de Promoci\u00f3n\"},\n        {\"Porcentaje de Deserci\u00f3n\"},\n        {\"Cantidad de Matr\u00edculas\"},\n        {\"Cantidad de Graduados\"},\n        {\"Cantidad de PQRs\"},\n        {\"Nivel de satisfacci\u00f3n a partir de la NSU promedio\"},\n        {\"Promotores promedio del Proceso a partir de la NSU\"},\n        {\"Detractores promedio del Proceso a partir de la NSU\"}\n    }\n)\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_7","title":"Prop\u00f3sito","text":"<p>La tabla CalculatedTableIndicadores se utiliza para:</p> <ul> <li>Listar y categorizar indicadores clave para el an\u00e1lisis.</li> <li>Servir como base para reportes y consultas espec\u00edficas relacionadas con la evaluaci\u00f3n del desempe\u00f1o.</li> <li>Proveer una visi\u00f3n consolidada de los indicadores m\u00e1s relevantes para la organizaci\u00f3n.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#relaciones-del-modelo","title":"Relaciones del Modelo","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Las relaciones definen c\u00f3mo las tablas del modelo interact\u00faan entre s\u00ed, asegurando la coherencia y la integridad de los datos en los an\u00e1lisis. A continuaci\u00f3n se detallan las relaciones establecidas entre las tablas del modelo.</p> Nombre Tabla Origen Columna Origen Tabla Destino Columna Destino e8e7ee5e-2bb5-447c-8a42-40fa4ccf9143 Transversal FACT_ACTIVIDADES ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 1a8196d0-09e6-4d0c-9f29-4a8d0ff4ee13 Transversal FACT_ACTIVIDADES ID_CATEGORIA Transversal DIM_CATEGORIA COD_CATEGORIA e4a99626-9ef6-4da8-89db-664ec2a6d8c8 Transversal FACT_ACTIVIDADES ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 395ef55c-3800-4448-bc48-46690276bd39 Transversal FACT_PERSONAL ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA cdfe13d4-3917-431a-b0c9-b496df147a20 Transversal FACT_PERSONAL ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD a8efdf32-e907-42ab-a950-937906c7b167 Transversal FACT_EVALUACION_DOCENTE ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 632bc53c-67b6-4634-82f9-8adbfc71e691 Transversal FACT_EVALUACION_DOCENTE ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 7246e8e1-e2c3-4a17-89eb-c077680b0f6b Transversal FACT_FINANCIERA ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA"},{"location":"03.Cubo/02.Tablas%20copy/#diagrama-de-relaciones-y-tablas","title":"Diagrama de Relaciones y Tablas","text":"<p>A continuaci\u00f3n, se presenta el diagrama de relaciones del modelo utilizando formato Mermaid para visualizar las conexiones entre tablas y sus relaciones:</p> <pre><code>graph TD\n    FACT_ACTIVIDADES[Transversal FACT_ACTIVIDADES]\n    FACT_PERSONAL[Transversal FACT_PERSONAL]\n    FACT_FINANCIERA[Transversal FACT_FINANCIERA]\n    FACT_EVALUACION_DOCENTE[Transversal FACT_EVALUACION_DOCENTE]\n    DIM_UNIDAD[Transversal DIM_UNIDAD]\n    DIM_CATEGORIA[Transversal DIM_CATEGORIA]\n    DIM_TIEMPO[Transversal DIM_TIEMPO_MENSUAL]\n\n    FACT_ACTIVIDADES --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_ACTIVIDADES --&gt; DIM_CATEGORIA[ID_CATEGORIA]\n    FACT_ACTIVIDADES --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_FINANCIERA --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_TIEMPO[ID_FECHA]</code></pre>"},{"location":"03.Cubo/02.Tablas%20copy/#explicacion-del-diagrama","title":"Explicaci\u00f3n del Diagrama","text":"<ol> <li> <p>Tablas de Hechos:</p> <ul> <li>FACT_ACTIVIDADES: Conecta con DIM_UNIDAD, DIM_CATEGORIA, y DIM_TIEMPO_MENSUAL.</li> <li>FACT_PERSONAL: Relacionada con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> <li>FACT_FINANCIERA: Conecta con DIM_TIEMPO_MENSUAL.</li> <li>FACT_EVALUACION_DOCENTE: Conecta con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> </ul> </li> <li> <p>Tablas de Dimensiones:</p> <ul> <li>DIM_UNIDAD: Relaciona hechos mediante el campo <code>ID_UNIDAD</code>.</li> <li>DIM_CATEGORIA: Relaciona hechos mediante el campo <code>ID_CATEGORIA</code>.</li> <li>DIM_TIEMPO_MENSUAL: Relaciona hechos mediante el campo <code>ID_FECHA</code>.</li> </ul> </li> </ol>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito-de-las-relaciones","title":"Prop\u00f3sito de las Relaciones","text":"<ul> <li> <p>Conexi\u00f3n entre hechos y dimensiones: Permitir que las tablas de hechos como FACT_ACTIVIDADES, FACT_PERSONAL, FACT_FINANCIERA y FACT_EVALUACION_DOCENTE se relacionen directamente con sus dimensiones correspondientes.</p> </li> <li> <p>Integridad de Datos: Garantizar que los datos en el modelo est\u00e9n relacionados de manera l\u00f3gica y consistente.</p> </li> <li> <p>Facilitar el An\u00e1lisis Multidimensional: Habilitar an\u00e1lisis por jerarqu\u00edas y categor\u00edas, como tiempo, unidad, y categor\u00eda.</p> </li> </ul>"},{"location":"03.Cubo/02.Tablas/","title":"02. TABLAS","text":""},{"location":"03.Cubo/02.Tablas/#tablas","title":"Tablas","text":""},{"location":"03.Cubo/02.Tablas/#tabla-transversal-dim_unidad","title":"Tabla: Transversal DIM_UNIDAD","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_UNIDAD es una dimensi\u00f3n clave del modelo sem\u00e1ntico que define las unidades organizacionales o funcionales del sistema. Esta tabla permite clasificar y segmentar la informaci\u00f3n de los procesos y actividades, sirviendo como eje de referencia para relacionar datos en otras tablas del cubo (por ejemplo, para an\u00e1lisis de actividades o m\u00e9tricas espec\u00edficas por unidad).</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla","title":"Estructura de la Tabla","text":"<p>La tabla est\u00e1 compuesta por las siguientes columnas:</p> Columna Tipo de Datos Columna Fuente / Tipo Descripci\u00f3n ID_UNIDAD int64 ID_UNIDAD Identificador \u00fanico de cada unidad organizacional. UNIDAD string UNIDAD Nombre descriptivo de la unidad (por ejemplo, \"Ventas\", \"Operaciones\", etc.). UNIDAD_ESTANDAR string (Calculada) Calculada Nombre de la unidad con formato estandarizado (capitalizaci\u00f3n de palabras). <p>Nota: La columna <code>UNIDAD_ESTANDAR</code> es una columna calculada mediante una expresi\u00f3n DAX para estandarizar la capitalizaci\u00f3n del nombre de la unidad.</p>"},{"location":"03.Cubo/02.Tablas/#particiones","title":"Particiones","text":"<ul> <li>Nombre de la Partici\u00f3n: Partition</li> <li>Vista de Datos: full (carga completa de los datos de la tabla).</li> <li>Fuente:   La tabla se obtiene a trav\u00e9s de una consulta en M con la siguiente expresi\u00f3n:</li> </ul> <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_UNIDAD = Source{[Schema=\"Transversal\",Item=\"DIM_UNIDAD\"]}[Data]\nin\n    Transversal_DIM_UNIDAD\n</code></pre>"},{"location":"03.Cubo/02.Tablas/#proposito","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n Transversal DIM_UNIDAD se utiliza para:</p> <ul> <li>Identificaci\u00f3n y Clasificaci\u00f3n: Proveer una llave para identificar cada unidad operativa o funcional en el modelo.</li> <li>Segmentaci\u00f3n Anal\u00edtica: Permitir el filtrado y segmentaci\u00f3n de datos en an\u00e1lisis y reportes, facilitando comparaciones y relaciones entre distintas unidades.</li> <li>Integraci\u00f3n del Modelo: Servir como referencia en las relaciones entre las tablas de hechos y otras dimensiones, asegurando consistencia en el an\u00e1lisis de la informaci\u00f3n empresarial.</li> <li>Estandarizaci\u00f3n: Ofrecer una versi\u00f3n estandarizada del nombre de la unidad (<code>UNIDAD_ESTANDAR</code>) para visualizaciones y reportes consistentes.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-dim_tiempo_mensual","title":"Tabla: Transversal DIM_TIEMPO_MENSUAL","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_TIEMPO_MENSUAL es una dimensi\u00f3n temporal dise\u00f1ada para segmentar la informaci\u00f3n en diferentes niveles cronol\u00f3gicos. Esta tabla consolida datos de fechas y sus descripciones, permitiendo analizar la informaci\u00f3n en intervalos espec\u00edficos como d\u00edas, semanas, meses, bimestres, trimestres, cuatrimestres, semestres y a\u00f1os. Su estructura detallada facilita la integraci\u00f3n de datos temporales con los hechos del cubo, permitiendo an\u00e1lisis hist\u00f3ricos y tendencias a lo largo del tiempo.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_1","title":"Estructura de la Tabla","text":"<p>La tabla est\u00e1 compuesta por las siguientes columnas:</p> Columna Tipo de Datos Fuente Descripci\u00f3n ID_FECHA int64 ID_FECHA Identificador \u00fanico de la fecha. FECHA dateTime FECHA Representa la fecha completa. DESC_FECHA string DESC_FECHA Descripci\u00f3n textual de la fecha (por ejemplo, \"Lunes, 01 de Enero de 2024\"). ID_SEMANA int64 ID_SEMANA N\u00famero identificador de la semana del a\u00f1o. DESC_SEMANA string DESC_SEMANA Descripci\u00f3n o nombre de la semana. ID_NO_MES int64 ID_NO_MES N\u00famero del mes en formato num\u00e9rico (por ejemplo, 1 para enero). DESC_NO_MES string DESC_NO_MES Descripci\u00f3n num\u00e9rica del mes. ID_MES int64 ID_MES Identificador del mes. DESC_MES string DESC_MES Nombre completo del mes (por ejemplo, \"Enero\"). DESC_MES_CORTA string DESC_MES_CORTA Versi\u00f3n abreviada del nombre del mes (por ejemplo, \"Ene\"). ID_BIMESTRE int64 ID_BIMESTRE Identificador del bimestre. DESC_BIMESTRE string DESC_BIMESTRE Descripci\u00f3n del bimestre. ID_TRIMESTRE int64 ID_TRIMESTRE Identificador del trimestre. DESC_TRIMESTRE string DESC_TRIMESTRE Descripci\u00f3n del trimestre. ID_CUATRIMESTRE int64 ID_CUATRIMESTRE Identificador del cuatrimestre. DESC_CUATRIMESTRE string DESC_CUATRIMESTRE Descripci\u00f3n del cuatrimestre. ID_SEMESTRE int64 ID_SEMESTRE Identificador del semestre. DESC_SEMESTRE string DESC_SEMESTRE Descripci\u00f3n del semestre. ID_ANIO int64 ID_ANIO A\u00f1o correspondiente a la fecha. ID_ANIO_ANT int64 ID_ANIO_ANT A\u00f1o anterior al actual, utilizado para comparaciones temporales. NUM_DIA_SEMANA int64 NUM_DIA_SEMANA N\u00famero del d\u00eda de la semana (por ejemplo, 1 para lunes). FESTIVO int64 FESTIVO Indicador de festivo (1 si la fecha es festiva, 0 en caso contrario). FECHA_CORTA dateTime FECHA_CORTA Representaci\u00f3n abreviada o simplificada de la fecha, \u00fatil para visualizaciones y c\u00e1lculos r\u00e1pidos. <p>Nota: La columna <code>FECHA_CORTA</code> utiliza un formato personalizado: \"MMMM 'de' yyyy\".</p>"},{"location":"03.Cubo/02.Tablas/#particiones_1","title":"Particiones","text":"<p>La tabla cuenta con una partici\u00f3n configurada de la siguiente forma:</p> <ul> <li>Nombre de la Partici\u00f3n: <code>Partition</code></li> <li>Vista de Datos: <code>full</code> (se carga la totalidad de los datos de la tabla).</li> <li>Fuente:   Se obtiene mediante la siguiente expresi\u00f3n en M:</li> </ul> <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_TIEMPO_MENSUAL = Source{[Schema=\"Transversal\",Item=\"DIM_TIEMPO_MENSUAL\"]}[Data]\nin\n    Transversal_DIM_TIEMPO_MENSUAL\n</code></pre>"},{"location":"03.Cubo/02.Tablas/#proposito_1","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n Transversal DIM_TIEMPO_MENSUAL se utiliza para:</p> <ul> <li>Segmentaci\u00f3n Temporal: Dividir los datos en intervalos espec\u00edficos (d\u00eda, semana, mes, bimestre, trimestre, cuatrimestre, semestre y a\u00f1o) para facilitar el an\u00e1lisis cronol\u00f3gico.</li> <li>Jerarqu\u00edas Temporales: Permitir an\u00e1lisis jer\u00e1rquicos que vinculan datos detallados (como d\u00edas y semanas) con niveles m\u00e1s agregados (meses, trimestres, a\u00f1os), lo cual es fundamental para la elaboraci\u00f3n de informes y dashboards.</li> <li>Integraci\u00f3n de Datos: Servir como llave para relacionar informaci\u00f3n de hechos (por ejemplo, en las tablas de actividades, personal o financiera) con el tiempo, asegurando la consistencia y calidad en los an\u00e1lisis.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-dim_categoria","title":"Tabla: Transversal DIM_CATEGORIA","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_CATEGORIA define las categor\u00edas utilizadas en el modelo para clasificar datos. Esta dimensi\u00f3n permite agrupar y segmentar informaci\u00f3n relacionada con diferentes \u00e1reas del sistema.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_2","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente COD_CATEGORIA string COD_CATEGORIA DESCRIPCION string DESCRIPCION"},{"location":"03.Cubo/02.Tablas/#particiones_2","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:     <pre><code>let\n  Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n  Transversal_DIM_CATEGORIA = Source{[Schema=\"Transversal\",Item=\"DIM_CATEGORIA\"]}[Data]\nin\n  Transversal_DIM_CATEGORIA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_2","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_CATEGORIA se utiliza para:</p> <ul> <li>Clasificar informaci\u00f3n en grupos o categor\u00edas predefinidas.</li> <li>Relacionar datos categorizados con otras dimensiones y hechos para an\u00e1lisis m\u00e1s detallados.</li> <li>Facilitar la segmentaci\u00f3n de datos en reportes y consultas.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_actividades","title":"Tabla: Transversal FACT_ACTIVIDADES","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_ACTIVIDADES es el hecho central del modelo sem\u00e1ntico y consolida informaci\u00f3n de diversas actividades realizadas en el entorno empresarial. Esta tabla integra datos provenientes de m\u00faltiples procesos ETL \u2013 tales como afiliaci\u00f3n, pagos, PQR, evaluaciones, entre otros \u2013 y contiene informaci\u00f3n demogr\u00e1fica, econ\u00f3mica y operativa. Es fundamental para el an\u00e1lisis multidimensional y el c\u00e1lculo de m\u00e9tricas clave en el cubo.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_3","title":"Estructura de la Tabla","text":"<p>La tabla est\u00e1 compuesta por las siguientes columnas:</p> Columna Tipo de Datos Fuente/Expresi\u00f3n Descripci\u00f3n (Resumen) PARTNER string PARTNER Identificador principal del socio o entidad registrada. ID_EMPRESA int64 ID_EMPRESA Identificador de la empresa asociada. ID_AFILIADO int64 ID_AFILIADO Identificador del afiliado. ID_TIPO_AFILIADO int64 ID_TIPO_AFILIADO Identificador del tipo de afiliado. TIPO_AFILIADO string TIPO_AFILIADO Descripci\u00f3n textual del tipo de afiliado. ID_CATEGORIA int64 ID_CATEGORIA Identificador de la categor\u00eda a la que pertenece el registro. FECHA_AFILIACION dateTime FECHA_AFILIACION Fecha en que se realiz\u00f3 la afiliaci\u00f3n o inicio de la actividad. FECHA_RETIRO dateTime FECHA_RETIRO Fecha de retiro o fin de la actividad, si aplica. ID_GENERO int64 ID_GENERO Identificador del g\u00e9nero, para an\u00e1lisis demogr\u00e1fico. ID_ESTADO_CIVIL int64 ID_ESTADO_CIVIL Estado civil del registro. ID_PERTENENCIA_ETNICA int64 ID_PERTENENCIA_ETNICA Identificador de la pertenencia \u00e9tnica. ID_FACTOR_VULNERABILIDAD int64 ID_FACTOR_VULNERABILIDAD Factor de vulnerabilidad asociado, si aplica. ESTRATO int64 ESTRATO Nivel socioecon\u00f3mico del registro. ID_CIUDAD int64 ID_CIUDAD Identificador de la ciudad. SALARIO_BASICO double SALARIO_BASICO Valor del salario b\u00e1sico asociado. FECHA_MENSUAL dateTime FECHA_MENSUAL Fecha de referencia mensual para la actividad. ID_FECHA int64 ID_FECHA Clave que relaciona el registro con la dimensi\u00f3n temporal. ID_UNIDAD int64 ID_UNIDAD Identificador de la unidad operativa asociada. ESTADOREGISTRO string ESTADOREGISTRO Estado del registro (por ejemplo, \"CURRENT\"). PARTNER_AFILIADO string PARTNER_AFILIADO Identificador adicional para el afiliado, cuando aplica. PARTNER_EMPRESA string PARTNER_EMPRESA Identificador de la empresa en el caso de registros empresariales. TIPO_POBLACION string TIPO_POBLACION Define el tipo de poblaci\u00f3n involucrada (ej. \"AFILIADO\", \"EMPRESA\", \"BENEFICIARIO\", etc.). ACTIVIDAD string ACTIVIDAD Tipo de actividad registrada (por ejemplo, \"AFILIACION\", \"PQR\", \"PAGOS\", etc.). TOTAL_APORTES double TOTAL_APORTES Valor total de aportes realizados. NUMERO_APORTES int64 NUMERO_APORTES N\u00famero total de aportes registrados. ADEUDA double ADEUDA Monto adeudado, cuando aplica. ANIO_ACADEMICO int64 ANIO_ACADEMICO A\u00f1o acad\u00e9mico relacionado con el registro. CANTIDAD_MATERIAL int64 CANTIDAD_MATERIAL Cantidad de material involucrado en la actividad (si aplica). CALIFICACION string CALIFICACION Calificaci\u00f3n o puntaje asignado en evaluaciones o procesos similares. CAUSA string CAUSA Motivo o causa asociada al registro, \u00fatil en procesos de reclamos o PQR. CATEGORIA_VENTA string CATEGORIA_VENTA Categor\u00eda de venta asociada, cuando corresponde. COSTO double COSTO Costo asociado a la actividad o registro. CURSO string CURSO Curso o programa acad\u00e9mico, en caso de actividades educativas. DESCRIPCION string DESCRIPCION Descripci\u00f3n detallada del registro o actividad. ESTADO string ESTADO Estado actual del registro, por ejemplo, \"PAGADO\" o \"SIN PAGO\". ESTADO_PAGO string ESTADO_PAGO Estado del pago asociado al registro. FECHA_ADMISION dateTime FECHA_ADMISION Fecha de admisi\u00f3n o inicio de procesos educativos. ID_CONCEPTO int64 ID_CONCEPTO Identificador del concepto asociado (por ejemplo, tipo de pago). ID_CURSO int64 ID_CURSO Identificador del curso relacionado, cuando aplica. ID_ESTADO_GESTION int64 ID_ESTADO_GESTION Estado de gesti\u00f3n del proceso registrado. ID_GRADO int64 ID_GRADO Identificador del grado acad\u00e9mico, cuando corresponde. ID_MATERIAL int64 ID_MATERIAL Identificador del material, si est\u00e1 involucrado en la actividad. ID_POBLACION int64 ID_POBLACION Identificador de la poblaci\u00f3n (por ejemplo, de estudiantes). ID_PROGRAMA int64 ID_PROGRAMA Identificador del programa acad\u00e9mico o de servicios. ID_PREGUNTA int64 ID_PREGUNTA Identificador de la pregunta en procesos de evaluaci\u00f3n o PQR. NO_PRESTAMOS int64 NO_PRESTAMOS N\u00famero de pr\u00e9stamos o servicios prestados, cuando aplica. RESPUESTA string RESPUESTA Respuesta asociada a evaluaciones o PQR. SERVICIO_TRANSPORTE string SERVICIO_TRANSPORTE Indica si se provee servicio de transporte en el contexto del registro. SUBSIDIO double SUBSIDIO Valor del subsidio aplicado, cuando corresponde. VALOR_FACTURADO double VALOR_FACTURADO Monto facturado en la transacci\u00f3n o actividad. VALOR_MATERIAL double VALOR_MATERIAL Valor del material involucrado, en caso de actividades relacionadas. VALOR_PAGADO double VALOR_PAGADO Monto pagado en la transacci\u00f3n o actividad. VALOR_PAGADO_SIN_IMP double VALOR_PAGADO_SIN_IMP Valor pagado sin incluir impuestos, cuando aplica. POBLACION_EDUCACION string POBLACION_EDUCACION Indicador de si el registro pertenece al \u00e1mbito educativo. ID_PQR string ID_PQR Identificador de la PQR (Preguntas, Quejas y Reclamos) asociada al registro. ESTADO_PQR string ESTADO_PQR Estado de la PQR. ID_BENEFICIARIO int64 ID_BENEFICIARIO Identificador del beneficiario en procesos de afiliaci\u00f3n o PQR. CAUSA_PQR string CAUSA_PQR Causa asociada a la PQR. TIPO_PQRS string TIPO_PQRS Tipo de PQR (por ejemplo, Pregunta, Queja, Reclamo). ID_TARIFA int64 ID_TARIFA Identificador de la tarifa o servicio relacionado. DESCRIPCION_ calculated (string) \u2013 Valor calculado: <code>COALESCE('Transversal FACT_ACTIVIDADES'[DESCRIPCION], \"INDEFINIDO\")</code>. TIPO_OPERACION_ calculated (string) \u2013 Valor calculado: <code>COALESCE('Transversal FACT_ACTIVIDADES'[TIPO_POBLACION], \"INDEFINIDO\")</code>. PARTNER_EMPRESA_ calculated (string) \u2013 Valor calculado: <code>COALESCE('Transversal FACT_ACTIVIDADES'[PARTNER_EMPRESA], \"INDEFINIDO\")</code>. ID_GENERO_ calculated (int64) \u2013 Valor calculado: <code>COALESCE('Transversal FACT_ACTIVIDADES'[ID_GENERO], -1)</code>."},{"location":"03.Cubo/02.Tablas/#particiones_3","title":"Particiones","text":"<ul> <li>Nombre de la Partici\u00f3n: Partition  </li> <li>Vista de Datos: full (carga completa de los datos).  </li> <li>Fuente:   La tabla se obtiene mediante la siguiente expresi\u00f3n en M:</li> </ul> <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_ACTIVIDADES = Source{[Schema=\"Transversal\", Item=\"FACT_ACTIVIDADES\"]}[Data]\nin\n    Transversal_FACT_ACTIVIDADES\n</code></pre>"},{"location":"03.Cubo/02.Tablas/#proposito_3","title":"Prop\u00f3sito","text":"<p>La tabla Transversal FACT_ACTIVIDADES se utiliza para:</p> <ul> <li>Consolidar Datos de Actividades: Integrar informaci\u00f3n proveniente de diversos procesos ETL (afiliaci\u00f3n, PQR, pagos, evaluaciones, etc.) en un \u00fanico hecho.</li> <li>An\u00e1lisis Multidimensional: Servir como base para el c\u00e1lculo de m\u00e9tricas clave, permitiendo segmentar y analizar la informaci\u00f3n por diferentes dimensiones (unidad, tiempo, categor\u00eda, etc.).</li> <li>Soporte a Reportes y Dashboards: Proveer datos detallados para la generaci\u00f3n de informes estrat\u00e9gicos y operativos, facilitando la identificaci\u00f3n de tendencias y oportunidades de mejora.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_personal","title":"Tabla: Transversal FACT_PERSONAL","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_PERSONAL almacena informaci\u00f3n relacionada con el personal, sus asignaciones y las horas contratadas. Es \u00fatil para el an\u00e1lisis de recursos humanos y la planificaci\u00f3n operativa.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_4","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente Descripci\u00f3n ID_FECHA int64 ID_FECHA Identificador \u00fanico de la fecha. ID_PERSONAL int64 ID_PERSONAL Identificador \u00fanico del personal. NOMBRE string NOMBRE Nombre del personal. CONCEPTO string CONCEPTO Concepto asociado al registro. DESCRIPCION string DESCRIPCION Descripci\u00f3n del registro. FECHA_FIN dateTime FECHA_FIN Fecha de finalizaci\u00f3n del contrato o asignaci\u00f3n. HORAS_CONTRATADAS_MENSUAL int64 HORAS_CONTRATADAS_MENSUAL N\u00famero de horas contratadas mensualmente. ID_UNIDAD int64 ID_UNIDAD Identificador de la unidad operativa asociada. DESCRIPCION_ string Calculada Descripci\u00f3n adicional calculada: <code>\"Indefinido\"</code> si <code>DESCRIPCION</code> est\u00e1 en blanco. <p>Nota: La columna <code>DESCRIPCION_</code> es calculada mediante la expresi\u00f3n: <code>IF(ISBLANK('Transversal FACT_PERSONAL'[DESCRIPCION]), \"Indefinido\", 'Transversal FACT_PERSONAL'[DESCRIPCION])</code>.</p>"},{"location":"03.Cubo/02.Tablas/#particiones_4","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:     <pre><code>let\n  Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n  Transversal_FACT_PERSONAL = Source{[Schema=\"Transversal\",Item=\"FACT_PERSONAL\"]}[Data]\nin\n  Transversal_FACT_PERSONAL\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_4","title":"Prop\u00f3sito","text":"<p>La tabla FACT_PERSONAL se utiliza para:</p> <ul> <li>Analizar las asignaciones y contratos del personal.</li> <li>Monitorear las horas contratadas mensualmente.</li> <li>Relacionar los datos del personal con otras dimensiones para informes y planificaci\u00f3n estrat\u00e9gica.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_financiera","title":"Tabla: Transversal FACT_FINANCIERA","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_FINANCIERA contiene informaci\u00f3n detallada sobre los datos financieros de la organizaci\u00f3n, incluyendo cuentas, ingresos, gastos y resultados. Es una fuente fundamental para el an\u00e1lisis financiero y la generaci\u00f3n de informes.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_5","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA ID_ANIO int64 ID_ANIO ID_MES int64 ID_MES ID_CEBE int64 ID_CEBE CEBE string CEBE DESCRIPCION_CEBE string DESCRIPCION_CEBE DEPARTAMENTO string DEPARTAMENTO AREA string AREA SUBAREA string SUBAREA SEGMENTO int64 SEGMENTO DESCRIPCION_SEGMENTO string DESCRIPCION_SEGMENTO CODIGO_SSF int64 CODIGO_SSF NOMBRE_SSF string NOMBRE_SSF ID_CUENTA int64 ID_CUENTA CUENTA string CUENTA CUENTA_HOMOLOGA string CUENTA_HOMOLOGA DESCRIPCION string DESCRIPCION TIPO_CUENTA string TIPO_CUENTA TIPO_OPERACION string TIPO_OPERACION GRUPO_CUENTA string GRUPO_CUENTA SUBGRUPO_CUENTA string SUBGRUPO_CUENTA GRUPO_OPERACION string GRUPO_OPERACION CUENTA_SSF int64 CUENTA_SSF DESCRIPCION_SSF string DESCRIPCION_SSF CUENTA_DESCRIPCION string CUENTA_DESCRIPCION CUENTA_DESCRIPCION_SSF string CUENTA_DESCRIPCION_SSF SIGNO_INGRESOS int64 SIGNO_INGRESOS CLASIFICACION int64 CLASIFICACION SEGMENT int64 SEGMENT IMPORTE double IMPORTE INGRESOS double INGRESOS INGRESOS_OPERACIONALES double INGRESOS_OPERACIONALES GASTOS double GASTOS GASTOS_OPERACIONALES double GASTOS_OPERACIONALES GASTOS_OPERACIONALES_ADMIN double GASTOS_OPERACIONALES_ADMIN RESULTADO_EJERCICIO double RESULTADO_EJERCICIO COSTOS double COSTOS ACTIVO double ACTIVO PASIVO double PASIVO PATRIMONIO double PATRIMONIO GASTOS_CON_DISTRIBUCION double GASTOS_CON_DISTRIBUCION GASTOS_SIN_DISTRIBUCION double GASTOS_SIN_DISTRIBUCION ACTIVIDAD string ACTIVIDAD ID_UNIDAD int64 ID_UNIDAD TIPO_OPERACION_ string Calculada TIPO string TIPO FUENTE_PRINCIPAL string FUENTE_PRINCIPAL <p>Nota: La columna <code>TIPO_OPERACION_</code> es calculada mediante la expresi\u00f3n: <code>IF(ISBLANK('Transversal FACT_FINANCIERA'[TIPO_OPERACION]), \"INDEFINIDA\", 'Transversal FACT_FINANCIERA'[TIPO_OPERACION])</code>.</p>"},{"location":"03.Cubo/02.Tablas/#particiones_5","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:     <pre><code>let\n  Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n  Transversal_FACT_FINANCIERA = Source{[Schema=\"Transversal\",Item=\"FACT_FINANCIERA\"]}[Data]\nin\n  Transversal_FACT_FINANCIERA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_5","title":"Prop\u00f3sito","text":"<p>La tabla FACT_FINANCIERA se utiliza para:</p> <ul> <li>Analizar el comportamiento financiero de la organizaci\u00f3n.</li> <li>Evaluar ingresos, gastos, costos y resultados financieros.</li> <li>Relacionar los datos financieros con otras dimensiones para an\u00e1lisis multidimensionales y generaci\u00f3n de informes detallados.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_evaluacion_docente","title":"Tabla: Transversal FACT_EVALUACION_DOCENTE","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_EVALUACION_DOCENTE almacena informaci\u00f3n relacionada con las evaluaciones acad\u00e9micas de los docentes, incluyendo calificaciones definitivas, per\u00edodos acad\u00e9micos y datos personales. Es clave para el an\u00e1lisis del desempe\u00f1o docente.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_6","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente PERIODO_ACADEMICO string PERIODO_ACADEMICO ID_UNIDAD int64 ID_UNIDAD ID_PERSONAL int64 ID_PERSONAL NOMBRE_DOCENTE string NOMBRE_DOCENTE CALIFICACION_DEFINITIVA string CALIFICACION_DEFINITIVA ID_FECHA int64 ID_FECHA"},{"location":"03.Cubo/02.Tablas/#particiones_6","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:     <pre><code>let\n  Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n  Transversal_FACT_EVALUACION_DOCENTE = Source{[Schema=\"Transversal\",Item=\"FACT_EVALUACION_DOCENTE\"]}[Data]\nin\n  Transversal_FACT_EVALUACION_DOCENTE\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_6","title":"Prop\u00f3sito","text":"<p>La tabla FACT_EVALUACION_DOCENTE se utiliza para:</p> <ul> <li>Analizar el desempe\u00f1o acad\u00e9mico de los docentes.</li> <li>Generar informes de calificaciones definitivas por per\u00edodo acad\u00e9mico.</li> <li>Relacionar datos de evaluaci\u00f3n docente con otras dimensiones como unidades y fechas.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-calculatedtableindicadores","title":"Tabla: CalculatedTableIndicadores","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>La tabla CalculatedTableIndicadores es una tabla calculada que contiene indicadores clave para el an\u00e1lisis y evaluaci\u00f3n del rendimiento en diversas \u00e1reas, como cobertura, movilidad acad\u00e9mica, promoci\u00f3n, deserci\u00f3n, matr\u00edculas, graduados y satisfacci\u00f3n.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_7","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente indicador string (calculada) [indicador]"},{"location":"03.Cubo/02.Tablas/#particiones_7","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>CalculatedTable 1</code>.</p> <p>2. Fuente:</p> <ul> <li>Tipo: <code>calculated</code>.</li> <li>Expresi\u00f3n:     <pre><code>DATATABLE (\n  \"indicador\", STRING, \n  { \n     {\"Cumplimiento Cobertura\"},\n     {\"Cobertura Proyectada\"},\n     {\"Movilidad Academica\"},\n     {\"Porcentaje de Promoci\u00f3n\"},\n     {\"Porcentaje de Deserci\u00f3n\"},\n     {\"Cantidad de Matr\u00edculas\"},\n     {\"Cantidad de Graduados o Certificados\"},\n     {\"Cantidad de PQRs\"},\n     {\"Nivel de satisfacci\u00f3n a partir de la NSU promedio\"},\n     {\"Promotores promedio del Proceso a partir de la NSU\"},\n     {\"Detractores promedio del Proceso a partir de la NSU\"}\n  }\n)\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_7","title":"Prop\u00f3sito","text":"<p>La tabla CalculatedTableIndicadores se utiliza para:</p> <ul> <li>Listar y categorizar indicadores clave para el an\u00e1lisis.</li> <li>Servir como base para reportes y consultas espec\u00edficas relacionadas con la evaluaci\u00f3n del desempe\u00f1o.</li> <li>Proveer una visi\u00f3n consolidada de los indicadores m\u00e1s relevantes para la organizaci\u00f3n.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#relaciones-del-modelo","title":"Relaciones del Modelo","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Las relaciones definen c\u00f3mo las tablas del modelo interact\u00faan entre s\u00ed, asegurando la coherencia y la integridad de los datos en los an\u00e1lisis. A continuaci\u00f3n se detallan las relaciones establecidas entre las tablas del modelo, actualizadas con la informaci\u00f3n del JSON.</p> Nombre Tabla Origen Columna Origen Tabla Destino Columna Destino 395ef55c-3800-4448-bc48-46690276bd39 Transversal FACT_PERSONAL ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA cdfe13d4-3917-431a-b0c9-b496df147a20 Transversal FACT_PERSONAL ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD a8efdf32-e907-42ab-a950-937906c7b167 Transversal FACT_EVALUACION_DOCENTE ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 632bc53c-67b6-4634-82f9-8adbfc71e691 Transversal FACT_EVALUACION_DOCENTE ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 7246e8e1-e2c3-4a17-89eb-c077680b0f6b Transversal FACT_FINANCIERA ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA e01f4c3c-2a45-4889-b297-c92f354929bb Transversal FACT_FINANCIERA ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 94f190ae-0dd3-4abf-a7be-458e0497c97a Transversal FACT_MINERIA ID_PROGRAMA Cedesarrollo DIM_PROGRAMA ID_PROGRAMA 58b77052-20e0-4dfb-acd0-4cb3e9afa6f2 Transversal FACT_MINERIA ID_CURSO Colegio DIM_CURSO ID_CURSO 2785a61f-9fb7-4db3-b5dd-b6ca7bdf9f63 Transversal FACT_MINERIA ID_CATEGORIA Transversal DIM_CATEGORIA COD_CATEGORIA 4b6d8d02-ffc2-4697-b15d-f8c98f573a17 Transversal FACT_MINERIA ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD a90709fa-9526-4bf2-9735-6e5b10fe69ad Transversal FACT_MINERIA ID_FECHA_MENSUAL Transversal DIM_TIEMPO_MENSUAL ID_FECHA c5ffc465-7368-414a-b72f-f457d3f81db9 Transversal FACT_UNIDADES ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD a351c33b-3f01-4bbf-b295-88ee5c86be67 Transversal FACT_UNIDADES ID_FECHA_MENSUAL Transversal DIM_TIEMPO_MENSUAL ID_FECHA 5a5c2b47-ec17-4247-828f-02289a229d06 Transversal FACT_ACTIVIDADES ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 1469e10f-7f24-448b-90b5-5efb1e0546e7 Transversal FACT_ACTIVIDADES ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 7db82b4d-6aa3-4be9-9281-0442a2f8b24c Transversal FACT_ACTIVIDADES ID_CATEGORIA Transversal DIM_CATEGORIA COD_CATEGORIA"},{"location":"03.Cubo/02.Tablas/#diagrama-de-relaciones-y-tablas","title":"Diagrama de Relaciones y Tablas","text":"<p>A continuaci\u00f3n, se presenta el diagrama de relaciones del modelo utilizando formato Mermaid para visualizar las conexiones entre tablas y sus relaciones, actualizado para incluir las relaciones adicionales del JSON:</p> <pre><code>graph TD\n  FACT_ACTIVIDADES[Transversal FACT_ACTIVIDADES]\n  FACT_PERSONAL[Transversal FACT_PERSONAL]\n  FACT_FINANCIERA[Transversal FACT_FINANCIERA]\n  FACT_EVALUACION_DOCENTE[Transversal FACT_EVALUACION_DOCENTE]\n  FACT_MINERIA[Transversal FACT_MINERIA]\n  FACT_UNIDADES[Transversal FACT_UNIDADES]\n  DIM_UNIDAD[Transversal DIM_UNIDAD]\n  DIM_CATEGORIA[Transversal DIM_CATEGORIA]\n  DIM_TIEMPO[Transversal DIM_TIEMPO_MENSUAL]\n  DIM_PROGRAMA[Proteccion DIM_PROGRAMA]\n  DIM_CURSO[Colegio DIM_CURSO]\n\n  FACT_ACTIVIDADES --&gt; DIM_UNIDAD[ID_UNIDAD]\n  FACT_ACTIVIDADES --&gt; DIM_CATEGORIA[ID_CATEGORIA]\n  FACT_ACTIVIDADES --&gt; DIM_TIEMPO[ID_FECHA]\n  FACT_PERSONAL --&gt; DIM_TIEMPO[ID_FECHA]\n  FACT_PERSONAL --&gt; DIM_UNIDAD[ID_UNIDAD]\n  FACT_FINANCIERA --&gt; DIM_TIEMPO[ID_FECHA]\n  FACT_FINANCIERA --&gt; DIM_UNIDAD[ID_UNIDAD]\n  FACT_EVALUACION_DOCENTE --&gt; DIM_UNIDAD[ID_UNIDAD]\n  FACT_EVALUACION_DOCENTE --&gt; DIM_TIEMPO[ID_FECHA]\n  FACT_MINERIA --&gt; DIM_PROGRAMA[ID_PROGRAMA]\n  FACT_MINERIA --&gt; DIM_CURSO[ID_CURSO]\n  FACT_MINERIA --&gt; DIM_CATEGORIA[ID_CATEGORIA]\n  FACT_MINERIA --&gt; DIM_UNIDAD[ID_UNIDAD]\n  FACT_MINERIA --&gt; DIM_TIEMPO[ID_FECHA]\n  FACT_UNIDADES --&gt; DIM_UNIDAD[ID_UNIDAD]\n  FACT_UNIDADES --&gt; DIM_TIEMPO[ID_FECHA]</code></pre>"},{"location":"03.Cubo/02.Tablas/#explicacion-del-diagrama","title":"Explicaci\u00f3n del Diagrama","text":"<ol> <li> <p>Tablas de Hechos:</p> <ul> <li>FACT_ACTIVIDADES: Conecta con DIM_UNIDAD, DIM_CATEGORIA y DIM_TIEMPO_MENSUAL.</li> <li>FACT_PERSONAL: Relacionada con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> <li>FACT_FINANCIERA: Conecta con DIM_TIEMPO_MENSUAL y DIM_UNIDAD.</li> <li>FACT_EVALUACION_DOCENTE: Conecta con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> <li>FACT_MINERIA: Relacionada con DIM_PROGRAMA, DIM_CURSO, DIM_CATEGORIA, DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> <li>FACT_UNIDADES: Conecta con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> </ul> </li> <li> <p>Tablas de Dimensiones:</p> <ul> <li>DIM_UNIDAD: Relaciona hechos mediante el campo <code>ID_UNIDAD</code>.</li> <li>DIM_CATEGORIA: Relaciona hechos mediante el campo <code>ID_CATEGORIA</code>.</li> <li>DIM_TIEMPO_MENSUAL: Relaciona hechos mediante el campo <code>ID_FECHA</code>.</li> <li>DIM_PROGRAMA y DIM_CURSO: Relacionan hechos espec\u00edficos de miner\u00eda y actividades.</li> </ul> </li> </ol>"},{"location":"03.Cubo/02.Tablas/#proposito-de-las-relaciones","title":"Prop\u00f3sito de las Relaciones","text":"<ul> <li>Conexi\u00f3n entre hechos y dimensiones: Permitir que las tablas de hechos se relacionen directamente con sus dimensiones correspondientes.</li> <li>Integridad de Datos: Garantizar que los datos en el modelo est\u00e9n relacionados de manera l\u00f3gica y consistente.</li> <li>Facilitar el An\u00e1lisis Multidimensional: Habilitar an\u00e1lisis por jerarqu\u00edas y categor\u00edas, como tiempo, unidad y categor\u00eda.</li> </ul>"},{"location":"03.Cubo/03.ETL/","title":"03. ETL","text":"<p>El paquete SSIS <code>09-ETLS_CUBO</code> est\u00e1 dise\u00f1ado para extraer, transformar y cargar (ETL) datos de diversas \u00e1reas operativas de Comfenalco en el Data Warehouse <code>DWH_COMFENALCO</code>. Su objetivo principal es consolidar informaci\u00f3n detallada sobre afiliaciones, interacciones (PQRS, NPS) y actividades espec\u00edficas de diferentes unidades de negocio (Protecci\u00f3n, Cedesarrollo, Colegio) en tablas centrales como <code>FACT_ACTIVIDADES</code> y <code>STG_FACT_AFILIACIONES</code>, facilitando as\u00ed el an\u00e1lisis integral y la generaci\u00f3n de inteligencia de negocio.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>Integrar datos operativos dispersos para construir una visi\u00f3n unificada y mensualizada de las actividades y afiliaciones. Esto permite realizar an\u00e1lisis transversales, seguimiento de indicadores clave, caracterizaci\u00f3n de poblaciones y soporte a decisiones estrat\u00e9gicas en las distintas \u00e1reas de servicio de la organizaci\u00f3n.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-del-paquete-ssis-09-etls_cubo","title":"Descripci\u00f3n del Paquete SSIS \"09-ETLS_CUBO\"","text":"<p>El paquete sigue un flujo estructurado para garantizar la calidad y consistencia de los datos cargados en el Data Warehouse:</p>"},{"location":"03.Cubo/03.ETL/#1-preparacion-del-entorno-analitico","title":"1. Preparaci\u00f3n del Entorno Anal\u00edtico","text":"<ul> <li>Truncar Tablas de Destino y Staging:   Se ejecutan tareas SQL (<code>Truncar Tablas Cubo</code>) para limpiar tablas clave antes de la carga, incluyendo:</li> <li><code>FACT_UNIDADES</code>, <code>FACT_ACTIVIDADES</code>, <code>FACT_EVALUACION_DOCENTE</code>, <code>FACT_FINANCIERA</code>, <code>FACT_PERSONAL</code>, <code>FACT_MINERIA</code></li> <li><code>DIM_TIEMPO_MENSUAL</code></li> <li><code>STG_FACT_AFILIACIONES</code>   Esto asegura que no haya datos residuales de ejecuciones anteriores y optimiza la carga.</li> <li>Cargar Dimensi\u00f3n de Tiempo Mensual:   Se puebla la tabla <code>DIM_TIEMPO_MENSUAL</code> (<code>DIM_TIEMPO_MENSUAL</code>) extrayendo y transformando datos de la dimensi\u00f3n de tiempo general (<code>DIM_TIEMPO</code>), asegurando una granularidad mensual consistente para los an\u00e1lisis.</li> </ul>"},{"location":"03.Cubo/03.ETL/#2-construccion-del-staging-de-afiliaciones-stg_fact_afiliaciones","title":"2. Construcci\u00f3n del Staging de Afiliaciones (<code>STG_FACT_AFILIACIONES</code>)","text":"<p>Esta tabla temporal es crucial para enriquecer posteriormente la tabla <code>FACT_ACTIVIDADES</code>. Se carga en etapas:</p> <ul> <li>Afiliaci\u00f3n Mensual Empresas:   Se extraen datos de <code>DIM_EMPRESAS</code>, se ajustan las fechas de afiliaci\u00f3n/retiro a los l\u00edmites de <code>DIM_TIEMPO_MENSUAL</code> y se cargan las empresas vigentes en <code>STG_FACT_AFILIACIONES</code>.</li> <li>Afiliaci\u00f3n Mensual Afiliados:   Dentro de un bucle (<code>Contenedor de bucles For</code>), se procesan los afiliados (<code>DIM_AFILIADOS</code>) en lotes de 100,000 (controlado por <code>User::MaxIterationAfil</code>). Para cada afiliado vigente, se genera un registro por cada mes de actividad en los \u00faltimos 3 a\u00f1os, calculando edad y asociando la empresa aportante, carg\u00e1ndose en <code>STG_FACT_AFILIACIONES</code>.</li> <li>Afiliaci\u00f3n Mensual Beneficiarios:   Similar al proceso de afiliados, se procesan los beneficiarios (<code>DIM_BENEFICIARIOS</code>) en lotes de 100,000 (controlado por <code>User::MaxIterationBene</code> dentro de <code>Contenedor de bucles For 1</code>). Se genera un registro mensual por beneficiario vigente, se calcula la edad, se intenta asignar categor\u00eda del afiliado asociado (o por defecto 'D') y se carga en <code>STG_FACT_AFILIACIONES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#3-consolidacion-en-la-tabla-de-hechos-principal-fact_actividades","title":"3. Consolidaci\u00f3n en la Tabla de Hechos Principal (<code>FACT_ACTIVIDADES</code>)","text":"<p>Diversos flujos de datos cargan informaci\u00f3n espec\u00edfica de diferentes \u00e1reas, enriqueci\u00e9ndola con datos de <code>STG_FACT_AFILIACIONES</code> y otras dimensiones:</p> <ul> <li>PQRS (<code>FACT_ACTIVIDADES_PQRS</code>):   Unifica PQRS de afiliados, beneficiarios, empresas y no aportantes desde <code>FACT_PQRS</code>. Calcula edad, asigna categor\u00eda (o valor por defecto) y normaliza la fecha a nivel mensual antes de cargar en <code>FACT_ACTIVIDADES</code>.</li> <li>NPS (<code>FACT_ACTIVIDADES_NPS</code>):   Carga datos de encuestas NPS (<code>FACT_ENCUESTAS</code>), enriqueci\u00e9ndolos con informaci\u00f3n demogr\u00e1fica y de afiliaci\u00f3n obtenida cruzando con dimensiones y <code>STG_FACT_AFILIACIONES</code>.</li> <li>Protecci\u00f3n (<code>FACT_ACTIVIDADES_PROTECCION</code>):   Consolida actividades del \u00e1rea de Protecci\u00f3n (Ventas, Caracterizaci\u00f3n, Deserci\u00f3n, Entrega de Material) desde tablas del esquema <code>Proteccion</code>. Unifica, enriquece con datos poblacionales y afiliatorios (<code>STG_FACT_AFILIACIONES</code>), y carga en <code>FACT_ACTIVIDADES</code>.</li> <li>Cedesarrollo (<code>FACT_ACTIVIDADES_CEDESARROLLO</code>, <code>Matricula Mensual Educacion Tecnica</code>, <code>Facturacion Tecnica y Continua</code>):   Integra m\u00faltiples hechos de Cedesarrollo (Graduados, Inasistencias, Matr\u00edculas, Cotizaciones, Facturaci\u00f3n, etc.) desde tablas del esquema <code>Cedesarrollo</code>. Normaliza a nivel mensual, enriquece con datos demogr\u00e1ficos (<code>STG_FACT_AFILIACIONES</code>) y carga en <code>FACT_ACTIVIDADES</code>. Incluye flujos espec\u00edficos para matr\u00edcula t\u00e9cnica y facturaci\u00f3n.</li> <li>Colegio (<code>FACT_ACTIVIDADES_COLEGIO</code>):   Consolida una amplia gama de actividades escolares (Matr\u00edcula, Facturaci\u00f3n, Transporte, Biblioteca, Enfermer\u00eda, Psicorientaci\u00f3n, Retiros) desde diversas fuentes del dominio Colegio. Enriquece con datos de afiliaci\u00f3n y poblacionales antes de cargar en <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#diagramas","title":"Diagramas","text":""},{"location":"03.Cubo/03.ETL/#1-diagrama-de-flujo-general","title":"1. Diagrama de Flujo General","text":"<pre><code>graph TD\n  subgraph Preparaci\u00f3n\n    A[Truncar Tablas Cubo] --&gt; B[Cargar DIM_TIEMPO_MENSUAL]\n  end\n\n  subgraph Staging Afiliaciones\n    C[Afiliaci\u00f3n Empresas] --&gt; F[STG_FACT_AFILIACIONES]\n    D[Afiliaci\u00f3n Afiliados Bucle] --&gt; F\n    E[Afiliaci\u00f3n Beneficiarios Bucle] --&gt; F\n  end\n\n  subgraph Carga FACT_ACTIVIDADES\n    G[Carga PQRS] --&gt; Z[FACT_ACTIVIDADES]\n    H[Carga NPS] --&gt; Z\n    I[Carga Protecci\u00f3n] --&gt; Z\n    J[Carga Cedesarrollo] --&gt; Z\n    K[Carga Colegio] --&gt; Z\n  end\n\n  B --&gt; C\n  B --&gt; D\n  B --&gt; E\n  F --&gt; G\n  F --&gt; H\n  F --&gt; I\n  F --&gt; J\n  F --&gt; K\n\n  %% Dependencias adicionales (simplificado)\n  B --&gt; G\n  B --&gt; H\n  B --&gt; I\n  B --&gt; J\n</code></pre>"},{"location":"03.Cubo/03.ETL/#2-modelo-de-datos-simplificado-foco-en-fact_actividades","title":"2. Modelo de Datos Simplificado (Foco en FACT_ACTIVIDADES)","text":"<pre><code>erDiagram\n  FACT_ACTIVIDADES {\n    int ID_Actividad PK\n    int ID_FECHA FK\n    string PARTNER\n    int ID_AFILIADO FK\n    int ID_BENEFICIARIO FK\n    int ID_EMPRESA FK\n    int ID_UNIDAD FK\n    string ACTIVIDAD\n    int ID_CATEGORIA\n    int EDAD\n    int ID_GENERO FK\n    decimal VALOR_PAGADO\n    int CALIFICACION_NPS\n    string FUENTE_PRINCIPAL\n    string TIPO_POBLACION\n    string ESTADOREGISTRO\n    string PARTNER_AFILIADO\n    string PARTNER_EMPRESA\n    int DISCAPACIDAD\n    int ID_CURSO FK\n    int ID_PROGRAMA FK\n    int ID_TARIFA FK\n    string ESTADO_PQR\n    string CAUSA_PQR\n    string SERVICIO_TRANSPORTE\n    int ID_GRADO\n    int ANIO_ACADEMICO\n    %% Otros campos espec\u00edficos de cada actividad\n  }\n\n  DIM_TIEMPO_MENSUAL {\n    int ID_FECHA PK\n    date FECHA\n    string DESC_MES\n    int ID_ANIO\n    %% Otros atributos temporales\n  }\n\n  STG_FACT_AFILIACIONES {\n    string PARTNER\n    int ID_FECHA\n    int ID_AFILIADO\n    int ID_BENEFICIARIO\n    int ID_EMPRESA\n    int ID_CATEGORIA\n    int EDAD\n    int ID_GENERO\n    date FECHA_NACIMIENTO\n    int DISCAPACIDAD\n    string PARTNER_AFILIADO\n    string PARTNER_EMPRESA\n    string TIPO_POBLACION\n    string ACTIVIDAD\n    %% Otros campos de afiliaci\u00f3n\n  }\n\n  DIM_AFILIADOS {\n    int ID_AFILIADO PK\n    string PARTNER\n    int ID_CATEGORIA\n    int ID_GENERO\n    %% Otros atributos\n  }\n\n  DIM_BENEFICIARIOS {\n    int ID_BENEFICIARIO PK\n    string PARTNER\n    int ID_AFILIADO FK\n    %% Otros atributos\n  }\n\n  DIM_EMPRESAS {\n    int ID_EMPRESA PK\n    string PARTNER\n    %% Otros atributos\n  }\n\n  DIM_UNIDAD {\n    int ID_UNIDAD PK\n    string NOMBRE_UNIDAD\n  }\n\n  FACT_ACTIVIDADES ||--o{ DIM_TIEMPO_MENSUAL : \"tiene fecha\"\n  FACT_ACTIVIDADES ||--o{ DIM_AFILIADOS : \"relacionado con\"\n  FACT_ACTIVIDADES ||--o{ DIM_BENEFICIARIOS : \"relacionado con\"\n  FACT_ACTIVIDADES ||--o{ DIM_EMPRESAS : \"relacionado con\"\n  FACT_ACTIVIDADES ||--o{ DIM_UNIDAD : \"pertenece a\"\n  FACT_ACTIVIDADES ||--o{ STG_FACT_AFILIACIONES : \"enriquecido por\" \n\n</code></pre>"},{"location":"03.Cubo/03.ETL/#componentes","title":"Componentes","text":""},{"location":"03.Cubo/03.ETL/#truncar-tablas-cubo","title":"Truncar Tablas Cubo","text":"<p>El componente <code>Truncar Tablas Cubo</code> forma parte del paquete SSIS <code>09-ETLS_CUBO</code> y est\u00e1 dise\u00f1ado para truncar tablas espec\u00edficas dentro del Data Warehouse <code>DWH_COMFENALCO</code> y otras \u00e1reas asociadas. Este proceso de truncado se realiza para limpiar las tablas de hechos y staging antes de realizar la carga de nuevos datos, garantizando que las tablas est\u00e9n listas para recibir la informaci\u00f3n m\u00e1s actualizada.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Truncar Tablas Cubo</code> es una tarea de ejecuci\u00f3n de SQL que elimina todos los datos de las tablas de hechos y staging. Este proceso es cr\u00edtico para mantener la integridad de los datos, eliminando informaci\u00f3n obsoleta o err\u00f3nea antes de realizar cargas de nuevos registros.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete","title":"Ubicaci\u00f3n en el Paquete","text":"<ul> <li>Paquete: <code>09-ETLS_CUBO</code></li> <li>Tarea: <code>Truncar Tablas Cubo</code></li> <li>Componente: <code>Microsoft.ExecuteSQLTask</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito","title":"Prop\u00f3sito","text":"<p>El prop\u00f3sito de este componente es truncar las siguientes tablas para eliminar los registros previos antes de proceder con la inserci\u00f3n de datos nuevos:</p> <ul> <li> <p>Tablas a truncar:</p> <ul> <li><code>FACT_UNIDADES</code></li> <li><code>FACT_ACTIVIDADES</code></li> <li><code>FACT_EVALUACION_DOCENTE</code></li> <li><code>FACT_FINANCIERA</code></li> <li><code>FACT_PERSONAL</code></li> <li><code>FACT_MINERIA</code></li> <li><code>DIM_TIEMPO_MENSUAL</code></li> <li><code>STG_FACT_AFILIACIONES</code></li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Componente SSIS: <code>Microsoft.ExecuteSQLTask</code></li> <li>Conexi\u00f3n: La tarea est\u00e1 configurada para utilizar la conexi\u00f3n <code>{29BC876E-1EAF-4F6F-8F38-39B8E881EEB6}</code>, que corresponde al <code>DWH_COMFENALCO</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio","title":"L\u00f3gica de Negocio","text":"<p>El SQL ejecutado dentro de este componente realiza un <code>TRUNCATE TABLE</code> en las tablas especificadas, eliminando todos los datos sin realizar un registro en el log de transacciones. Esto mejora la eficiencia en la limpieza de datos cuando se necesita realizar un proceso de carga completa en el cubo.</p>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Este componente se ejecuta t\u00edpicamente antes de cargar los datos en el cubo o en las tablas de hechos. Tras el truncado, otros componentes de carga como el que inserta las nuevas filas en las tablas de hechos o staging se encargan de rellenar las tablas con la informaci\u00f3n m\u00e1s reciente.</p>"},{"location":"03.Cubo/03.ETL/#script-sql","title":"Script SQL","text":"<p>El script SQL ejecutado por este componente es el siguiente:</p> <pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_UNIDADES];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_PERSONAL];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_MINERIA];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL];\nTRUNCATE TABLE [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES];\n</code></pre>"},{"location":"03.Cubo/03.ETL/#dim_tiempo_mensual","title":"DIM_TIEMPO_MENSUAL","text":"<p>El componente <code>DIM_TIEMPO_MENSUAL</code> forma parte del paquete SSIS <code>09-ETLS_CUBO</code> y est\u00e1 dise\u00f1ado para cargar los datos de la dimensi\u00f3n temporal a nivel mensual en la tabla <code>DIM_TIEMPO_MENSUAL</code> del Data Warehouse <code>DWH_COMFENALCO</code>. Su principal funci\u00f3n es extraer datos desde la tabla de tiempo de la base de datos de origen y cargar esos datos en el destino correspondiente para su posterior an\u00e1lisis en el cubo OLAP.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente <code>DIM_TIEMPO_MENSUAL</code> es una tarea de flujo de datos (Data Flow Task) que realiza la extracci\u00f3n y transformaci\u00f3n de los datos de tiempo. Utiliza la instrucci\u00f3n SQL para extraer las fechas y los valores asociados (mes, trimestre, semestre, etc.), transformarlos seg\u00fan sea necesario, y luego cargarlos en la tabla <code>DIM_TIEMPO_MENSUAL</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_1","title":"Ubicaci\u00f3n en el Paquete","text":"<ul> <li>Paquete: <code>09-ETLS_CUBO</code></li> <li>Tarea: <code>DIM_TIEMPO_MENSUAL</code></li> <li>Componente: <code>Microsoft.Pipeline</code> (Data Flow Task)</li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_1","title":"Prop\u00f3sito","text":"<p>El prop\u00f3sito del componente <code>DIM_TIEMPO_MENSUAL</code> es extraer datos de la tabla <code>DIM_TIEMPO</code> del <code>DWH_COMFENALCO</code>, transformar la informaci\u00f3n y cargarla en la tabla de destino <code>DIM_TIEMPO_MENSUAL</code>. Los datos que se extraen incluyen informaci\u00f3n relacionada con las fechas, tales como el mes, trimestre, semestre y a\u00f1o.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_1","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen de Datos:   Los datos se extraen de la tabla <code>[DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]</code>, utilizando una consulta SQL para obtener las fechas y sus descripciones.</p> </li> <li> <p>Destino de Carga:   Los datos extra\u00eddos se cargan en la tabla <code>[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]</code>.</p> </li> <li> <p>Conexi\u00f3n:   Utiliza la conexi\u00f3n <code>{29BC876E-1EAF-4F6F-8F38-39B8E881EEB6}:external</code> para conectar con la base de datos <code>DWH_COMFENALCO</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_1","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Transformaci\u00f3n:   Los datos son extra\u00eddos con una consulta SQL que obtiene las fechas del primer d\u00eda de cada mes y otros atributos relacionados como el ID de semana, mes, trimestre, semestre, a\u00f1o, etc.</p> </li> <li> <p>Carga de Datos:   Los datos transformados se cargan en la tabla de destino utilizando ADO.NET Destination, lo que permite una carga eficiente de datos a trav\u00e9s de la conexi\u00f3n OLE DB.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_1","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Este componente se ejecuta despu\u00e9s de que los datos han sido transformados en otras tareas y se asegura de que los datos de la dimensi\u00f3n de tiempo est\u00e9n disponibles en la tabla <code>DIM_TIEMPO_MENSUAL</code> para ser utilizados en los cubos OLAP y otros an\u00e1lisis.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-de-extraccion","title":"Script SQL de Extracci\u00f3n","text":"<p>La instrucci\u00f3n SQL utilizada para extraer los datos es la siguiente (incluida en el componente Origen de ADO NET):</p> <pre><code>WITH FechasPrimerDiaMes AS (\n    SELECT \n        [ID_FECHA],\n        [FECHA],\n        [DESC_FECHA],\n        [ID_SEMANA],\n        [DESC_SEMANA],\n        [ID_NO_MES],\n        [DESC_NO_MES],\n        [ID_MES],\n        [DESC_MES],\n        [DESC_MES_CORTA],\n        [ID_BIMESTRE],\n        [DESC_BIMESTRE],\n        [ID_TRIMESTRE],\n        [DESC_TRIMESTRE],\n        [ID_CUATRIMESTRE],\n        [DESC_CUATRIMESTRE],\n        [ID_SEMESTRE],\n        [DESC_SEMESTRE],\n        [ID_ANIO],\n        [ID_ANIO_ANT],\n        [NUM_DIA_SEMANA],\n        [FESTIVO],\n        [FECHA_CORTA]\n    FROM \n        [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]\n    WHERE \n        DATEPART(DAY, FECHA) = 1\n        AND ID_ANIO BETWEEN DATEPART(YEAR, GETDATE()) - 3 AND DATEPART(YEAR, GETDATE())\n)\nSELECT \n    [ID_FECHA],\n    [FECHA],\n    [DESC_FECHA],\n    [ID_SEMANA],\n    [DESC_SEMANA],\n    [ID_NO_MES],\n    [DESC_NO_MES],\n    [ID_MES],\n    [DESC_MES],\n    [DESC_MES_CORTA],\n    [ID_BIMESTRE],\n    [DESC_BIMESTRE],\n    [ID_TRIMESTRE],\n    [DESC_TRIMESTRE],\n    [ID_CUATRIMESTRE],\n    [DESC_CUATRIMESTRE],\n    [ID_SEMESTRE],\n    [DESC_SEMESTRE],\n    [ID_ANIO],\n    [ID_ANIO_ANT],\n    [NUM_DIA_SEMANA],\n    [FESTIVO],\n    [FECHA_CORTA],\n    '[DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]' as [FUENTE_PRINCIPAL]\nFROM \n    FechasPrimerDiaMes\nWHERE [FECHA] &lt;= '2024-05-01'\nORDER BY [FECHA];\n</code></pre>"},{"location":"03.Cubo/03.ETL/#afiliacion-mensual-empresas","title":"Afiliaci\u00f3n mensual Empresas","text":"<p>El componente <code>Afiliaci\u00f3n mensual Empresas</code> forma parte del paquete SSIS <code>FACT_ACTIVIDADES</code> y est\u00e1 dise\u00f1ado para procesar y cargar informaci\u00f3n de afiliaci\u00f3n mensual de empresas en el Data Warehouse <code>DWH_COMFENALCO</code>. Esta tarea se encarga de extraer los datos de las empresas y su afiliaci\u00f3n desde las tablas de origen, realizar las transformaciones necesarias, y luego cargar estos datos en la tabla de destino correspondiente en la base de datos.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente <code>Afiliaci\u00f3n mensual Empresas</code> es una tarea de flujo de datos (Data Flow Task) que maneja el proceso de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con las afiliaciones mensuales de empresas. Los datos extra\u00eddos incluyen informaci\u00f3n detallada de las empresas y su afiliaci\u00f3n, como el estado, fecha de afiliaci\u00f3n, fecha de retiro, y otros atributos relevantes.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_2","title":"Ubicaci\u00f3n en el Paquete","text":"<ul> <li>Paquete: <code>FACT_ACTIVIDADES</code></li> <li>Tarea: <code>Afiliaci\u00f3n mensual Empresas</code></li> <li>Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_2","title":"Prop\u00f3sito","text":"<p>El prop\u00f3sito de este componente es procesar la informaci\u00f3n de afiliaci\u00f3n mensual de empresas, extraerla de las fuentes correspondientes, transformarla seg\u00fan las reglas de negocio definidas y cargarla en la tabla de destino <code>STG_FACT_AFILIACIONES</code> en la base de datos <code>DWH_COMFENALCO</code>.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_2","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Componente SSIS: <code>Microsoft.Pipeline</code></li> <li>Conexi\u00f3n: Utiliza la conexi\u00f3n <code>STAGE_AREA</code>, gestionada a trav\u00e9s del administrador de conexiones de SSIS.</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_2","title":"L\u00f3gica de Negocio","text":"<p>Este componente realiza las siguientes operaciones principales:</p> <ol> <li>Extracci\u00f3n de Datos: Se extraen los datos de la tabla <code>DIM_EMPRESAS</code> en el esquema <code>Aportes</code> de <code>DWH_COMFENALCO</code>.</li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Las fechas de afiliaci\u00f3n y retiro se ajustan a las fechas m\u00ednimas y m\u00e1ximas en la tabla <code>DIM_TIEMPO_MENSUAL</code>.</li> <li>Se asegura de que solo se consideren las empresas cuyo estado sea <code>VIGEN</code> y cuyo estado de registro sea <code>CURRENT</code>.</li> </ul> </li> <li> <p>Carga de Datos: Los datos transformados se cargan en la tabla <code>STG_FACT_AFILIACIONES</code> en el esquema <code>Transversal</code>.</p> </li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_2","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Este componente depende de la tabla <code>DIM_EMPRESAS</code> en el esquema <code>Aportes</code> y de la tabla <code>DIM_TIEMPO_MENSUAL</code> en el esquema <code>Transversal</code> para obtener la informaci\u00f3n de fechas. Adem\u00e1s, los datos procesados se cargan en la tabla de destino <code>STG_FACT_AFILIACIONES</code>.</p>"},{"location":"03.Cubo/03.ETL/#script-sql_1","title":"Script SQL","text":"<p>El componente ejecuta una consulta SQL compleja para extraer, transformar y cargar los datos. El script SQL utilizado es el siguiente:</p> <pre><code>WITH MinFecha AS (\n    SELECT MIN(FECHA) AS MinFecha\n    FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n),\nMaxFecha AS (\n    SELECT MAX(FECHA) AS MaxFecha\n    FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n),\n-- CTE para seleccionar los registros de la empresa\nEmpresas AS (\n    SELECT\n        [ID_EMPRESA],\n        [PARTNER],\n        CAST([FECHA_AFILIACION] AS DATE) AS [FECHA_AFILIACION],\n        [FECHA_FUNDACION],\n        CAST([FECHA_RETIRO] AS DATE) AS [FECHA_RETIRO],\n        [ESTADO],\n        [ESTADOREGISTRO],\n        [COD_CIUDAD]\n    FROM \n        [DWH_COMFENALCO].[Aportes].[DIM_EMPRESAS]\n    WHERE [ESTADO] = 'VIGEN' and [ESTADOREGISTRO] = 'CURRENT' \n),\nEmpresasOptimizado as (\n    SELECT \n        [ID_EMPRESA],\n        [PARTNER],\n        [FECHA_FUNDACION],\n        CASE \n            WHEN [FECHA_AFILIACION] &lt;= (SELECT MinFecha FROM MinFecha) THEN COALESCE(CAST((SELECT MinFecha FROM MinFecha) AS DATE), CAST(GETDATE() AS DATE))\n            ELSE [FECHA_AFILIACION]\n        END AS [FECHA_AFILIACION],\n        CASE \n            WHEN [FECHA_RETIRO] &gt;= (SELECT MaxFecha FROM MaxFecha) THEN COALESCE(CAST((SELECT MaxFecha FROM MaxFecha) AS DATE), CAST(GETDATE() AS DATE))\n            ELSE [FECHA_RETIRO]\n        END AS [FECHA_RETIRO],\n        [ESTADOREGISTRO],\n        [ESTADO],\n        [COD_CIUDAD]\n    FROM Empresas\n),\n-- Seleccionar los registros por mes y hacer el join con DIM_TIEMPO_MENSUAL\nEmpresasPorMes AS (\n    SELECT \n        e.[ID_EMPRESA],\n        e.[PARTNER],\n        e.[FECHA_AFILIACION],\n        e.[FECHA_FUNDACION],\n        e.[FECHA_RETIRO],\n        e.[ESTADOREGISTRO],\n        e.[ESTADO],\n        e.[COD_CIUDAD],\n        ds.FECHA_CORTA AS FECHA_MENSUAL,\n        ds.ID_FECHA,\n        5 AS ID_UNIDAD\n    FROM \n        EmpresasOptimizado e\n    INNER JOIN \n        [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] ds ON ds.FECHA_CORTA BETWEEN e.[FECHA_AFILIACION] AND COALESCE(e.[FECHA_RETIRO], GETDATE())\n)\nSELECT \n    em.[PARTNER],\n    em.[ID_EMPRESA],\n    -1 AS ID_AFILIADO,\n    -1 AS ID_TIPO_AFILIADO,\n    NULL AS TIPO_AFILIADO,\n    5 AS ID_CATEGORIA, \n    em.[FECHA_AFILIACION],\n    em.[FECHA_RETIRO],\n    -1 AS ID_GENERO,\n    -1 AS ID_ESTADO_CIVIL,\n    -1 AS ID_PERTENENCIA_ETNICA,\n    -1 AS ID_FACTOR_VULNERABILIDAD,\n    NULL AS ESTRATO,\n    em.[COD_CIUDAD] AS ID_CIUDAD,\n    NULL AS SALARIO_BASICO,\n    em.[FECHA_MENSUAL],\n    em.[ID_FECHA],\n    em.[ID_UNIDAD],\n    em.[ESTADOREGISTRO],\n    -1 AS PARTNER_AFILIADO,\n    em.[PARTNER] AS PARTNER_EMPRESA,\n    'EMPRESA' as TIPO_POBLACION,\n    'AFILIACION' AS ACTIVIDAD,\n    '[DWH_COMFENALCO].[Aportes].[DIM_EMPRESAS]' as [FUENTE_PRINCIPAL]\nFROM \n    EmpresasPorMes em\nORDER BY \n    em.[ID_EMPRESA], em.[FECHA_MENSUAL];\n</code></pre>"},{"location":"03.Cubo/03.ETL/#almacenar-max-afiliados","title":"Almacenar MAX afiliados","text":"<p>El componente <code>Almacenar MAX afiliados</code> es una tarea en el paquete SSIS <code>FACT_ACTIVIDADES</code> que se encarga de almacenar el n\u00famero m\u00e1ximo de iteraciones para procesar los afiliados, basado en el total de registros que cumplen con ciertos criterios. Esta tarea calcula cu\u00e1ntos lotes de 100,000 registros se necesitar\u00e1n para procesar todos los afiliados activos en el sistema.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Almacenar MAX afiliados</code> ejecuta una consulta SQL para contar el n\u00famero de registros activos de afiliados en la tabla <code>DIM_AFILIADOS</code>, considerando \u00fanicamente aquellos registros cuyo estado es <code>CURRENT</code> y que tienen una fecha v\u00e1lida de afiliaci\u00f3n. El resultado de la consulta se utiliza para calcular el n\u00famero de iteraciones necesarias para procesar a todos los afiliados en lotes de 100,000.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_3","title":"Ubicaci\u00f3n en el Paquete","text":"<ul> <li>Paquete: <code>FACT_ACTIVIDADES</code></li> <li>Tarea: <code>Almacenar MAX afiliados</code></li> <li>Componente: <code>Microsoft.ExecuteSQLTask</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_3","title":"Prop\u00f3sito","text":"<p>El prop\u00f3sito de este componente es calcular y almacenar el n\u00famero m\u00e1ximo de iteraciones necesarias para procesar los afiliados en lotes de 100,000 registros. Este valor se almacena en una variable de SSIS, <code>User::MaxIterationAfil</code>, para ser utilizado posteriormente en el flujo de trabajo.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_3","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Componente SSIS: <code>Microsoft.ExecuteSQLTask</code></li> <li>Conexi\u00f3n: Utiliza la conexi\u00f3n <code>DWH_COMFENALCO</code> gestionada a trav\u00e9s del administrador de conexiones de SSIS.</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_3","title":"L\u00f3gica de Negocio","text":"<p>Este componente ejecuta una consulta SQL que:</p> <ol> <li>Cuenta los registros de afiliados en la tabla <code>DIM_AFILIADOS</code> donde el estado es <code>CURRENT</code> y la fecha de afiliaci\u00f3n es v\u00e1lida.</li> <li>Valida la fecha de retiro para asegurar que sea v\u00e1lida o nula.</li> <li>Calcula el n\u00famero de lotes: Se divide el total de registros entre 100,000 y se le suma 1, lo que representa el n\u00famero m\u00e1ximo de iteraciones necesarias para procesar todos los registros.</li> </ol> <p>El resultado de esta operaci\u00f3n se almacena en la variable <code>User::MaxIterationAfil</code>, que posteriormente se utiliza en el proceso para realizar las iteraciones necesarias.</p>"},{"location":"03.Cubo/03.ETL/#script-sql_2","title":"Script SQL","text":"<p>La consulta SQL utilizada es la siguiente:</p> <pre><code>select FLOOR(COUNT(*) / 100000.0) + 1 as num\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS]\nWHERE [ESTADOREGISTRO] = 'CURRENT' \n  AND ISDATE([FECHA_AFILIACION]) = 1 \n  AND (ISDATE([FECHA_RETIRO]) = 1 OR [FECHA_RETIRO] IS NULL)\n</code></pre> <ul> <li><code>COUNT(*)</code>: Cuenta el total de registros en la tabla <code>DIM_AFILIADOS</code> donde se cumplen las condiciones de afiliaci\u00f3n activa y fechas v\u00e1lidas.</li> <li><code>FLOOR(COUNT(*) / 100000.0) + 1</code>: Calcula el n\u00famero de lotes de 100,000 registros. La funci\u00f3n <code>FLOOR</code> asegura que el c\u00e1lculo redondee hacia abajo el n\u00famero de lotes, y se le suma 1 para garantizar que al menos un lote se procese.</li> </ul> <p>El valor calculado se almacena en la variable <code>User::MaxIterationAfil</code> para su uso posterior en el flujo de datos.</p>"},{"location":"03.Cubo/03.ETL/#fact_actividadescontenedor-de-bucles-forafiliacion-mensual-afiliados","title":"FACT_ACTIVIDADES\\Contenedor de bucles For\\Afiliacion mensual Afiliados","text":"<p>El componente <code>FACT_ACTIVIDADES\\Contenedor de bucles For\\Afiliacion mensual Afiliados</code> es una tarea de flujo de datos dentro del paquete SSIS <code>09\u2011ETLS_CUBO</code>.\u202fSu funci\u00f3n es generar y cargar, de forma incremental y particionada, la afiliaci\u00f3n mensual de los afiliados\u202fen la tabla de staging <code>[DWH_COMFENALCO].[Transversal].[STG_FACT_AFILIACIONES]</code>, sirviendo de base para la tabla de hechos <code>FACT_ACTIVIDADES</code> del cubo OLAP.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_4","title":"Descripci\u00f3n\u202fGeneral","text":"<ul> <li>Tipo de tarea: Data\u202fFlow\u202fTask (Microsoft.Pipeline)</li> <li>Objetivo: Materializar, mes a mes, la situaci\u00f3n de cada afiliado activo en los \u00faltimos\u202f3\u202fa\u00f1os, enriquecida con metadatos (edad, empresa aportante, unidad, etc.).</li> <li>Destino f\u00edsico: Tabla de staging <code>Transversal.STG_FACT_AFILIACIONES</code> (motor\u202fADO\u202f.NET).</li> </ul>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_4","title":"Ubicaci\u00f3n\u202fen\u202fel\u202fPaquete","text":"<pre><code>09-ETLS_CUBO\n\u2514\u2500 FACT_ACTIVIDADES\n   \u2514\u2500 Contenedor de bucles For\n      \u2514\u2500 Afiliacion mensual Afiliados   \u2190 (este componente)\n</code></pre>"},{"location":"03.Cubo/03.ETL/#proposito_4","title":"Prop\u00f3sito","text":"<ol> <li>Persistir un snapshot mensual de los afiliados para an\u00e1lisis de cohortes y m\u00e9tricas hist\u00f3ricas.</li> <li>Reducir carga de memoria procesando los afiliados en lotes de\u202f100\u202f000 registros (controlado por la variable <code>@VarTime</code>).</li> <li>Centralizar reglas de negocio de afiliaci\u00f3n (vigencia, edad, estrato, poblaci\u00f3n, etc.) antes de la carga definitiva a la tabla de hechos.</li> </ol>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_4","title":"Detalles\u202fde\u202fImplementaci\u00f3n","text":"Elemento Configuraci\u00f3n clave Origen OLE\u202fDB\u202fSource (conexi\u00f3n <code>DWH_COMFENALCO_Destino_OLEDB</code>) Modo de acceso <code>SQL\u202fCommand</code> parametrizado (<code>@VarTime</code> \u2194 variable de Foreach) Destino ADO\u202fNET\u202fDestination \u2192 <code>\"Transversal\".\"STG_FACT_AFILIACIONES\"</code> BatchSize <code>0</code> (lote = tama\u00f1o de b\u00fafer interno) BulkInsert <code>True</code> (usa <code>SqlBulkCopy</code> cuando el proveedor lo permite) Timeout <code>600\u202fs</code> en origen y destino Gesti\u00f3n de errores Salida de error dedicada para registro de filas rechazadas"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_4","title":"L\u00f3gica\u202fde\u202fNegocio","text":"<ol> <li> <p>Generaci\u00f3n de calendario mensual</p> <ul> <li>Se toma la fecha m\u00e1xima de <code>DIM_TIEMPO</code> y se retrocede 3\u202fa\u00f1os.</li> <li>Se cruza con <code>Transversal.DIM_TIEMPO_MENSUAL</code> para garantizar coherencia de la dimensi\u00f3n tiempo.</li> </ul> </li> <li> <p>Selecci\u00f3n de afiliados vigentes</p> <ul> <li>De <code>Aportes.DIM_AFILIADOS</code> se filtran registros <code>ESTADOREGISTRO = 'CURRENT'</code>.</li> <li>Se valida que <code>FECHA_AFILIACION</code> sea fecha v\u00e1lida y que <code>FECHA_RETIRO</code> sea nula o fecha v\u00e1lida.</li> </ul> </li> <li> <p>Particionamiento controlado</p> <ul> <li>El contenedor For\u00a0Loop alimenta la variable <code>@VarTime</code> (1\u2026N).</li> <li>Cada iteraci\u00f3n procesa hasta 100\u202f000 afiliados (<code>ROW_NUMBER()</code>\u00a0\u2192 <code>BETWEEN\u2026</code>).</li> </ul> </li> <li> <p>Expansi\u00f3n temporal</p> <ul> <li>Se repite cada afiliado por todos los meses comprendidos entre su afiliaci\u00f3n y su retiro (o el mes corriente).</li> </ul> </li> <li> <p>C\u00e1lculo de atributos</p> <ul> <li>Edad: <code>DATEDIFF(YEAR, FECHA_NACIMIENTO, FECHA_MENSUAL)</code>.</li> <li>Unidad: constante <code>5</code>.</li> <li>Empresa aportante: primer\u202f<code>PARTNER</code> encontrado en <code>Aportes.DIM_EMPRESAS</code>.</li> <li>Tipo poblaci\u00f3n / Actividad / Fuente: valores literales \u2018AFILIADO\u2019, \u2018AFILIACION\u2019 y ruta\u202fde\u202forigen.</li> </ul> </li> <li> <p>Filtrado de duplicados</p> <ul> <li>Se conserva la fila con salario m\u00e1s alto por afiliado y mes (<code>ROW_NUMBER()\u202fOVER(PARTITION\u202fBY\u202fPARTNER,\u202fID_FECHA ORDER\u202fBY\u202fSALARIO_BASICO\u202fDESC) =\u202f1</code>).</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#script-sql-completo","title":"Script\u202fSQL (completo)","text":"<pre><code>DECLARE @VarTime INT = ?;\n\n-- 1) Fechas mensuales (\u00faltimos 3 a\u00f1os)\nWITH MaxFecha AS (\n    SELECT MAX(FECHA) AS MaxFecha\n    FROM [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]\n),\nNumberSeries AS (\n    SELECT ROW_NUMBER() OVER (ORDER BY (SELECT NULL)) - 1 AS Number\n    FROM [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]\n),\nDateSeries AS (\n    SELECT DATEADD(MONTH, Number, DATEFROMPARTS(YEAR(MaxFecha) - 3, 1, 1)) AS MonthDate,\n           CONVERT(INT, FORMAT(\n               DATEADD(MONTH, Number, DATEFROMPARTS(YEAR(MaxFecha) - 3, 1, 1)),\n               'yyyyMMdd')) AS ID_FECHA\n    FROM NumberSeries\n    CROSS JOIN MaxFecha\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dtm\n           ON dtm.ID_FECHA = CONVERT(INT, FORMAT(\n                DATEADD(MONTH, Number, DATEFROMPARTS(YEAR(MaxFecha) - 3, 1, 1)),\n                'yyyyMMdd'))\n    WHERE Number BETWEEN 0\n          AND DATEDIFF(MONTH, DATEFROMPARTS(YEAR(MaxFecha) - 3, 1, 1), MaxFecha)\n),\n\n-- 2) Empresa aportante principal\nUniquePartners AS (\n    SELECT PARTNER, DOCUMENTO,\n           ROW_NUMBER() OVER (PARTITION BY DOCUMENTO ORDER BY PARTNER) AS RowNum\n    FROM [DWH_COMFENALCO].[Aportes].[DIM_EMPRESAS]\n),\nFilteredPartners AS (\n    SELECT PARTNER AS PARTNER_EMPRESA, DOCUMENTO\n    FROM UniquePartners\n    WHERE RowNum = 1\n),\n\n-- 3) Afiliados activos + paginaci\u00f3n\nAfiliadosConRowNum AS (\n    SELECT  ID_AFILIADO, PARTNER, ID_TIPO_AFILIADO, TIPO_AFILIADO,\n            ID_CATEGORIA, CAST(FECHA_NACIMIENTO AS DATE) AS FECHA_NACIMIENTO,\n            CAST(FECHA_AFILIACION AS DATE) AS FECHA_AFILIACION,\n            CAST(FECHA_RETIRO AS DATE)     AS FECHA_RETIRO,\n            ID_GENERO, ID_ESTADO_CIVIL, ID_PERTENENCIA_ETNICA,\n            ID_FACTOR_VULNERABILIDAD, ESTRATO, ID_CIUDAD,\n            SALARIO_BASICO, APORTANTE, ESTADOREGISTRO,\n            ROW_NUMBER() OVER (ORDER BY ID_AFILIADO) AS RowNum\n    FROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS]\n    WHERE ESTADOREGISTRO = 'CURRENT'\n      AND ISDATE(FECHA_AFILIACION) = 1\n      AND (ISDATE(FECHA_RETIRO) = 1 OR FECHA_RETIRO IS NULL)\n),\nAfiliados AS (\n    SELECT *\n    FROM AfiliadosConRowNum\n    WHERE RowNum BETWEEN ((@VarTime - 1) * 100000) + 1\n                     AND     @VarTime      * 100000\n),\n\n-- 4) Repetir afiliado por cada mes de vigencia\nAfiliadosPorMes AS (\n    SELECT  a.*, ds.MonthDate AS FECHA_MENSUAL, ds.ID_FECHA,\n            5 AS ID_UNIDAD,\n            ROW_NUMBER() OVER\n               (PARTITION BY a.PARTNER, ds.ID_FECHA\n                ORDER BY a.SALARIO_BASICO DESC) AS RN\n    FROM Afiliados a\n    JOIN DateSeries ds\n      ON ds.MonthDate BETWEEN a.FECHA_AFILIACION\n                          AND COALESCE(a.FECHA_RETIRO, GETDATE())\n)\n\n-- 5) Resultado final\nSELECT  am.PARTNER,\n        -1 AS ID_EMPRESA,\n        am.ID_AFILIADO, am.ID_TIPO_AFILIADO, am.TIPO_AFILIADO,\n        am.ID_CATEGORIA, am.FECHA_NACIMIENTO,\n        DATEDIFF(YEAR, am.FECHA_NACIMIENTO, am.FECHA_MENSUAL) AS EDAD,\n        am.FECHA_AFILIACION, am.FECHA_RETIRO,\n        am.ID_GENERO, am.ID_ESTADO_CIVIL, am.ID_PERTENENCIA_ETNICA,\n        am.ID_FACTOR_VULNERABILIDAD, am.ESTRATO, am.ID_CIUDAD,\n        am.SALARIO_BASICO, am.FECHA_MENSUAL, am.ID_FECHA, am.ID_UNIDAD,\n        am.ESTADOREGISTRO,\n        am.PARTNER           AS PARTNER_AFILIADO,\n        fp.PARTNER_EMPRESA,\n        'AFILIADO'   AS TIPO_POBLACION,\n        'AFILIACION' AS ACTIVIDAD,\n        '[DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS]' AS FUENTE_PRINCIPAL\nFROM AfiliadosPorMes am\nJOIN FilteredPartners fp\n  ON am.APORTANTE = fp.DOCUMENTO\nWHERE am.RN = 1\nORDER BY am.PARTNER, am.FECHA_MENSUAL;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_3","title":"Relaci\u00f3n\u202fcon\u202fOtros\u202fComponentes","text":"Dependencia Tipo Uso <code>Transversal.DIM_TIEMPO_MENSUAL</code> Dimensi\u00f3n de tiempo Asegura que los ID_FECHA generados existan en el DW <code>Dwh.DIM_TIEMPO</code> Dimensi\u00f3n de tiempo Obtenci\u00f3n de la fecha m\u00e1xima para acotar el rango de 3\u202fa\u00f1os <code>Aportes.DIM_AFILIADOS</code> Dimensi\u00f3n de dominio Fuente principal de los afiliados <code>Aportes.DIM_EMPRESAS</code> Dimensi\u00f3n de empresas Derivar <code>PARTNER_EMPRESA</code> (aportante) <code>STG_FACT_AFILIACIONES</code> Tabla\u202fstaging destino Recibe los registros para posteriores transformaciones hacia <code>FACT_ACTIVIDADES</code> <p>Observaci\u00f3n: La tarea se encuentra dentro de un Contenedor\u202fFor\u202fLoop que recorre el rango de valores de <code>@VarTime</code>, permitiendo que grandes vol\u00famenes de afiliados se carguen en paralelo o en iteraciones controladas, evitando sobrecargar la memoria durante la ejecuci\u00f3n del paquete.</p>"},{"location":"03.Cubo/03.ETL/#fact_actividadesalmacenar-max-beneficiarios","title":"FACT_ACTIVIDADES\\Almacenar\u202fMAX\u202fbeneficiarios","text":"<p>El componente <code>FACT_ACTIVIDADES\\Almacenar\u202fMAX\u202fbeneficiarios</code> es una tarea\u202fEjecutar\u202fSQL dentro del paquete SSIS <code>09\u2011ETLS_CUBO</code>.\u202fSu misi\u00f3n es calcular cu\u00e1ntas iteraciones deber\u00e1 ejecutar posteriormente el contenedor\u202fFor Loop que procesa la carga masiva de beneficiarios, evitando desbordes de memoria y asegurando un particionamiento homog\u00e9neo de 100\u202f000 registros por lote.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_5","title":"Descripci\u00f3n\u202fGeneral","text":"Atributo Valor Tipo de tarea <code>ExecuteSQLTask</code> Conexi\u00f3n <code>{29BC876E-1EAF-4F6F-8F38-39B8E881EEB6}</code> (base de datos <code>DWH_COMFENALCO</code>) ResultSet <code>Single Row</code> Variable de salida <code>User::MaxIterationBene</code> (INT)"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_5","title":"Ubicaci\u00f3n\u202fen\u202fel\u202fPaquete","text":"<pre><code>09-ETLS_CUBO\n\u2514\u2500 FACT_ACTIVIDADES\n   \u2514\u2500 Almacenar MAX beneficiarios   \u2190 (este componente)\n</code></pre>"},{"location":"03.Cubo/03.ETL/#proposito_5","title":"Prop\u00f3sito","text":"<ol> <li>Contar beneficiarios vigentes registrados en <code>Aportes.DIM_BENEFICIARIOS</code> cuyo <code>TIPO_APORTANTE = 'X'</code>.</li> <li>Calcular el n\u00famero de lotes necesarios para procesarlos de a 100\u202f000 filas.</li> <li>Almacenar el resultado en la variable <code>User::MaxIterationBene</code>, utilizada como l\u00edmite superior del For\u202fLoop que alimenta el flujo de datos Afiliaci\u00f3n mensual Beneficiarios (y componentes afines).</li> </ol>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_5","title":"Detalles\u202fde\u202fImplementaci\u00f3n","text":"Elemento Configuraci\u00f3n SQLStatementSource Sentencia <code>SELECT</code> (ver m\u00e1s abajo) Result Binding Resultado ordinal 0 \u2192 <code>User::MaxIterationBene</code> ResultType <code>SingleRow</code> (una sola fila con un campo <code>num</code>) ThreadHint <code>0</code> (sin afinidad de subproceso) Reintentos / Timeout Hereda configuraci\u00f3n global del paquete"},{"location":"03.Cubo/03.ETL/#script-sql_3","title":"Script\u202fSQL","text":"<pre><code>SELECT  FLOOR(COUNT(*) / 100000.0) + 1 AS num\nFROM    [DWH_COMFENALCO].[Aportes].[DIM_BENEFICIARIOS]\nWHERE   [ESTADOREGISTRO] = 'CURRENT'\n  AND   [TIPO_APORTANTE] = 'X';\n</code></pre> <ul> <li> <p>L\u00f3gica:</p> <ul> <li>Cuenta los beneficiarios vigentes (<code>ESTADOREGISTRO = 'CURRENT'</code>) y con aportante de tipo \u2018X\u2019.</li> <li>Divide el total entre 100\u202f000 y redondea hacia abajo (<code>FLOOR</code>).</li> <li>Suma 1 para cubrir el residuo del \u00faltimo lote.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_4","title":"Relaci\u00f3n\u202fcon\u202fOtros\u202fComponentes","text":"Componente Tipo Interacci\u00f3n <code>Contenedor de bucles For\\Afiliaci\u00f3n mensual Beneficiarios</code> For\u202fLoop Usa <code>User::MaxIterationBene</code> como valor m\u00e1ximo (<code>EvalExpression</code>) para iterar los lotes. <code>Transversal.STG_FACT_BENEFICIARIOS</code> (u otro staging) Destino de flujos Recibe los datos procesados en cada iteraci\u00f3n. <p>Observaci\u00f3n: Este c\u00e1lculo se ejecuta antes de iniciar la carga masiva de beneficiarios.\u202fDe este modo el paquete conoce de antemano cu\u00e1ntas vueltas dar\u00e1 el bucle y puede distribuir los recursos (memoria, tiempo de ejecuci\u00f3n) de forma predecible.</p>"},{"location":"03.Cubo/03.ETL/#fact_actividadescontenedor-de-bucles-for-1afiliacion-mensual-beneficiarios","title":"FACT_ACTIVIDADES\\Contenedor\u00a0de\u00a0bucles\u00a0For\u202f1\\Afiliaci\u00f3n\u202fmensual\u202fBeneficiarios","text":"<p>El componente Afiliaci\u00f3n\u202fmensual\u202fBeneficiarios es un Data\u202fFlow\u202fTask que vive dentro del contenedor For\u202fLoop\u202f1 del paquete SSIS <code>09\u2011ETLS_CUBO</code>.\u202fSu funci\u00f3n es extraer, transformar y cargar \u2014en lotes de 100\u202f000 filas\u2014 la afiliaci\u00f3n mensual de beneficiarios vigentes, generando un registro por cada combinaci\u00f3n beneficiario\u2011mes en la tabla <code>Transversal.STG_FACT_AFILIACIONES</code>.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_6","title":"Descripci\u00f3n\u202fGeneral","text":"Atributo Valor Tipo de componente <code>Data\u202fFlow\u202fTask</code> Fuente <code>OLE DB Source</code> \u2014 consulta SQL parametrizada (ver L\u00f3gica de negocio) Destino <code>ADO\u202fNET\u202fDestination</code> \u2192 <code>Transversal.STG_FACT_AFILIACIONES</code> Conexiones - OLE\u202fDB: <code>{57F24C4D\u2011\u2026582B}</code> \u2192 DWH_COMFENALCO \u2011 ADO\u202fNET: <code>{5972EC76\u2011\u2026645D}</code> \u2192 STAGE_AREA Lote insert <code>UseBulkInsertWhenPossible = true</code> \u2022 <code>BatchSize = 0</code> (auto) Par\u00e1metro de entrada <code>@VarTime</code> (INT) \u2190 variable del For\u202fLoop (<code>User::IterTimeBene</code>) Filas por iteraci\u00f3n 100\u202f000 (ROW_NUMBER\u00a0con filtrado por rango)"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_6","title":"Ubicaci\u00f3n\u202fen\u202fel\u202fPaquete","text":"<pre><code>09-ETLS_CUBO\n\u2514\u2500 FACT_ACTIVIDADES\n   \u2514\u2500 Contenedor de bucles For 1\n      \u2514\u2500 Afiliaci\u00f3n mensual Beneficiarios   \u2190 (este flujo de datos)\n</code></pre>"},{"location":"03.Cubo/03.ETL/#proposito_6","title":"Prop\u00f3sito","text":"<ol> <li>Paginaci\u00f3n de beneficiarios vigentes    Procesa 100\u202f000 registros por vuelta, seg\u00fan el \u00edndice <code>RowNumm</code> y el par\u00e1metro <code>@VarTime</code> que suministra el For\u202fLoop.</li> <li>Generaci\u00f3n de series mensuales    Replica cada beneficiario para cada mes comprendido entre su fecha de afiliaci\u00f3n y de retiro (cortadas a los l\u00edmites globales de la tabla\u202fde tiempo).</li> <li> <p>Normalizaci\u00f3n y enriquecimiento</p> <ul> <li>Ajuste de fechas err\u00f3neas ('1900\u201101\u201101' \u2192 9999\u201112\u201131).</li> <li>C\u00e1lculo de edad al corte del mes.</li> <li>Asignaci\u00f3n de categor\u00eda (<code>ID_CATEGORIA</code>) a partir de actividades del staging de afiliados (si existe, si no, valor por defecto <code>4</code>\u00a0\u2013\u00a0categor\u00eda\u00a0D).</li> </ul> </li> <li> <p>Carga incremental    Inserta el resultado en <code>STG_FACT_AFILIACIONES</code> para ser consolidado m\u00e1s adelante por la rutina de fact table.</p> </li> </ol>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_6","title":"Detalles\u202fde\u202fImplementaci\u00f3n","text":"Elemento Configuraci\u00f3n / Observaci\u00f3n OLE\u202fDB\u202fSource \u2013 SQL Consulta con varios CTE para: \u2022\u202fPaginar (<code>BeneficiariosConRowNum</code>) \u2022\u202fCorregir fechas y filtrar (<code>BeneficiariosOptimizado</code>) \u2022\u202fExpandir a meses (<code>BeneficiariosPorMes</code>) \u2022\u202fAsociar categor\u00eda v\u00eda left\u00a0join al staging de afiliados (<code>CTE_Ranking</code>) ParameterMapping <code>\"Par\u00e1metro0:Input\",{16F02750\u2011\u2026 EB7F}</code> \u2190 variable del contenedor Destino ADO\u202fNET Tabla: <code>Transversal.STG_FACT_AFILIACIONES</code>; <code>UseBulkInsertWhenPossible = true</code> Manejo de errores Salida \u201cError Output\u201d configurada; filas err\u00f3neas se redirigen (actualmente sin conexi\u00f3n de manejo espec\u00edfica, solo logging). ThreadHint / Buffering Configuraci\u00f3n heredada; <code>BatchSize = 0</code> conf\u00eda en el tama\u00f1o interno del buffer SSIS."},{"location":"03.Cubo/03.ETL/#logica-de-negocio-resumen-de-la-sql","title":"L\u00f3gica\u202fde\u202fNegocio\u00a0(resumen de la SQL)","text":"<ol> <li> <p>Ventana de fechas</p> <ul> <li><code>MinFecha</code>, <code>MaxFecha</code> se toman de <code>Transversal.DIM_TIEMPO_MENSUAL</code>.</li> </ul> </li> <li> <p>Selecci\u00f3n de beneficiarios vigentes</p> <pre><code>WHERE ESTADOREGISTRO = 'CURRENT'\n  AND TIPO_APORTANTE  = 'X'\n</code></pre> </li> <li> <p>Paginaci\u00f3n por <code>ROW_NUMBER()</code> \u2192 rango = <code>(@VarTime\u20111)*100\u202f000\u00a0+\u00a01</code> \u2026 <code>@VarTime*100\u202f000</code>.</p> </li> <li> <p>Depuraci\u00f3n / Normalizaci\u00f3n</p> <ul> <li>Relleno de fechas nulas o valores 1900\u201101\u201101 / 9999\u201112\u201131.</li> <li>Eliminaci\u00f3n de duplicados por <code>PARTNER</code> conservando el ingreso m\u00e1s antiguo.</li> </ul> </li> <li> <p>Explosi\u00f3n mensual    Join con <code>DIM_TIEMPO_MENSUAL</code> \u21d2 un registro por mes.</p> </li> <li> <p>Enriquecimiento de categor\u00eda <code>LEFT JOIN</code> con staging de afiliados; si no existe, se asigna <code>4</code>.</p> </li> <li> <p>Selecci\u00f3n final    Se elige <code>RowNum = 1</code> (primer registro por beneficiario\u2011mes) y se proyectan 40+ columnas normalizadas, incluyendo:</p> <ul> <li><code>TIPO_POBLACION = 'BENEFICIARIO'</code></li> <li><code>ACTIVIDAD      = 'AFILIACION'</code></li> <li><code>FUENTE_PRINCIPAL = [DIM_BENEFICIARIOS]</code></li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_5","title":"Relaci\u00f3n\u202fcon\u202fOtros\u202fComponentes","text":"Componente Tipo Relaci\u00f3n For\u202fLoop\u00a01 Contenedor Suministra <code>@VarTime</code> y controla el n\u00famero de iteraciones (<code>User::MaxIterationBene</code>) calculado en la tarea Almacenar\u202fMAX\u202fbeneficiarios. Almacenar\u202fMAX\u202fbeneficiarios Execute\u202fSQL\u202fTask Define cu\u00e1ntas vueltas da el For\u202fLoop (\u2192\u202flotes de 100\u202fk). STG_FACT_AFILIACIONES Tabla staging Recibe tanto afiliados como beneficiarios; etapa previa a la fact table definitiva. Flujo Afiliaci\u00f3n\u202fmensual\u202fAfiliados Data\u202fFlow Corre en paralelo (diferente contenedor) y escribe en la misma tabla, con <code>TIPO_POBLACION = 'AFILIADO'</code>. <p>Buenas pr\u00e1cticas implementadas</p> <ul> <li>Paginaci\u00f3n para evitar consumo excesivo de memoria.</li> <li>Uso de <code>BulkInsert</code> para acelerar la escritura.</li> <li>Normalizaci\u00f3n agresiva de fechas y categor\u00edas para minimizar reprocesos posteriores.\u00a0</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_actividades-fact_actividades_pqrs","title":"FACT_ACTIVIDADES\\\u202fFACT_ACTIVIDADES_PQRS","text":"<p>Flujo de datos que consolida todas las PQRS (Peticiones, Quejas, Reclamos y Sugerencias) provenientes de afiliados, beneficiarios, empresas y no\u2011aportantes, y las carga en la fact table <code>Transversal.FACT_ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#resumen-rapido","title":"Resumen r\u00e1pido","text":"Atributo Valor Tipo de tarea <code>Data\u202fFlow\u202fTask</code> Origen <code>ADO\u202fNET Source</code> (consulta UNION\u202fALL de 4 conjuntos) Destino <code>ADO\u202fNET\u202fDestination</code> \u2192 <code>Transversal.FACT_ACTIVIDADES</code> Conexi\u00f3n <code>{29BC876E\u2011\u2026EEB6}</code> \u2192\u00a0DWH_COMFENALCO BulkInsert <code>UseBulkInsertWhenPossible = true</code> Timeout 30\u202fseg. (origen y destino) Registros estimados \u2248\u202f1\u202f\u00d7\u202f<code>FACT_PQRS</code> (sin paginaci\u00f3n; carga completa)"},{"location":"03.Cubo/03.ETL/#flujo-de-alta-nivel","title":"Flujo de alta\u202fnivel","text":"<pre><code>FACT_ACTIVIDADES\n\u2514\u2500 FACT_ACTIVIDADES_PQRS\n   \u251c\u2500 Origen ADO NET  \u2500\u2500\u25ba (Resultados UNION de 4 SELECT)\n   \u2514\u2500 Destino ADO NET \u2500\u2500\u25ba FACT_ACTIVIDADES\n</code></pre>"},{"location":"03.Cubo/03.ETL/#contenido-del-origen","title":"Contenido del origen","text":"<p>La instrucci\u00f3n SQL crea el alias <code>con</code> uniendo cuatro SELECT:</p> <ol> <li> <p>Afiliados</p> <ul> <li>JOIN <code>FACT_PQRS</code> \u2194 <code>DIM_AFILIADOS</code></li> <li>Calcula edad con <code>DATEDIFF</code> sobre <code>DIM_TIEMPO_MENSUAL</code>.</li> <li>Copia <code>ID_CATEGORIA</code> que ya existe en el afiliado.</li> </ul> </li> <li> <p>Beneficiarios</p> <ul> <li>JOIN <code>FACT_PQRS</code> \u2194 <code>DIM_BENEFICIARIOS</code> (+\u00a0<code>DIM_AFILIADOS</code> para la categor\u00eda).</li> <li>Si el afiliado no aporta categor\u00eda se usa <code>4</code> (D).</li> </ul> </li> <li> <p>Empresas</p> <ul> <li>JOIN <code>FACT_PQRS</code> \u2194 <code>DIM_EMPRESAS</code>.</li> <li>Fija <code>ID_CATEGORIA = 5</code> (E).</li> <li>Edad =\u00a0\u20111; datos demogr\u00e1ficos gen\u00e9ricos (\u20111).</li> </ul> </li> <li> <p>No aportantes</p> <ul> <li>Filtra registros donde <code>ID_AFILIADO + ID_EMPRESA + ID_BENEFICIARIO = -3</code>.</li> <li>Marca partner \u20180000000000\u2019, categor\u00eda <code>4</code>, demograf\u00eda gen\u00e9rica.</li> </ul> </li> </ol> <p>Los cuatro bloques a\u00f1aden campos comunes faltantes con valores por defecto (<code>-1</code>, <code>NULL</code> o literales) y establecen:</p> <ul> <li>ACTIVIDAD = 'PQR'</li> <li>POBLACION_EDUCACION y sub\u2011banderas \u00abFORMAL / T\u00c9CNICA / CONTINUA / PROTECCI\u00d3N\u00bb basadas en <code>ID_UNIDAD</code>.</li> <li>FUENTE_PRINCIPAL = '[DWH_COMFENALCO].[Transversal].[FACT_PQRS]'</li> <li>ID_FECHA se normaliza al primer d\u00eda del mes (<code>yyyymm01</code>) para compatibilizar con la dimensi\u00f3n tiempo mensual.</li> </ul>"},{"location":"03.Cubo/03.ETL/#mapeo-principal-de-columnas","title":"Mapeo principal de columnas","text":"Salida del origen Destino\u00a0<code>FACT_ACTIVIDADES</code> Nota <code>ID_PQR</code> <code>ID_PQR</code> Identificador \u00fanico de la PQR <code>ID_UNIDAD</code> <code>ID_UNIDAD</code> 1\u202f=\u202fEducaci\u00f3n\u00a0Formal, 2\u202f=\u202fT\u00e9cnica\u2026 <code>ID_FECHA</code> <code>ID_FECHA</code> Fecha mensual normalizada <code>ESTADO_PQR</code> <code>ESTADO_PQR</code> Abierta, Cerrada, etc. \u2026 \u2026 40+ columnas mapeadas autom\u00e1ticamente (ver XML) <p>Campos no aplicables a cierto tipo de solicitante se rellenan con:</p> <ul> <li><code>\u20111</code> para claves for\u00e1neas ausentes</li> <li><code>NULL</code> para fechas y textos indeterminados</li> <li>Valores literales de control (<code>2</code>\u00a0para discapacidad predeterminada, \u2018SI/NO\u2019 en banderas de educaci\u00f3n).</li> </ul>"},{"location":"03.Cubo/03.ETL/#manejo-de-errores","title":"Manejo de errores","text":"<ul> <li>Salida de error configurada tanto en origen como en destino.</li> <li>Filas que fallen se redirigen al <code>Error Output</code> (actualmente sin downstream\u00a0handler \u2014 solo logging).</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-el-resto-del-paquete","title":"Relaci\u00f3n con el resto del paquete","text":"Componente Rol Interacci\u00f3n <code>FACT_ACTIVIDADES_PQRS</code> Carga PQRS Complementa las cargas de Afiliados y Beneficiarios dentro de <code>FACT_ACTIVIDADES</code>; todos escriben sobre la misma table con distintas ACTIVIDAD (<code>AFILIACION</code>, <code>PQR</code>, etc.). <code>Transversal.FACT_PQRS</code> Fuente operacional Contiene los movimientos brutos de PQRS \u2014 punto de partida del flujo. <code>Transversal.DIM_TIEMPO_MENSUAL</code> Dimensi\u00f3n tiempo Provee la fecha de corte mensual (<code>ID_FECHA</code>, <code>FECHA</code>). <code>DIM_AFILIADOS</code>, <code>DIM_BENEFICIARIOS</code>, <code>DIM_EMPRESAS</code> Dimensiones de contexto Enriquecen con datos demogr\u00e1ficos y de categor\u00eda."},{"location":"03.Cubo/03.ETL/#buenas-practicas-destacadas","title":"Buenas pr\u00e1cticas destacadas","text":"<ul> <li>Normalizaci\u00f3n de fechas a fin de mes para garantizar consistencia temporal.</li> <li>Discriminaci\u00f3n por tipo de solicitante mediante <code>UNION\u202fALL</code> (evita l\u00f3gica condicional pesada).</li> <li>Carga masiva (<code>BulkInsert</code>) directamente a la fact table, minimizando staging intermedio.</li> <li>Bandera de poblaci\u00f3n educativa derivada de la unidad para facilitar reporting de formaci\u00f3n.</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_actividades_nps","title":"FACT_ACTIVIDADES_NPS","text":"<p>El componente <code>FACT_ACTIVIDADES_NPS</code> forma parte del paquete SSIS <code>FACT_ACTIVIDADES</code> y est\u00e1 dise\u00f1ado para cargar la informaci\u00f3n de Net Promoter Score (NPS) en la tabla de hechos <code>FACT_ACTIVIDADES</code> del Data Warehouse <code>DWH_COMFENALCO</code>. Su funci\u00f3n principal es extraer, transformar y cargar los datos relacionados con las encuestas NPS y las actividades asociadas para su posterior an\u00e1lisis.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p><code>FACT_ACTIVIDADES_NPS</code> es una Data Flow Task que combina un origen ADO\u00a0.NET y un destino ADO\u00a0.NET.</p> <ul> <li>El origen (componente <code>fact nps</code>) emplea una consulta Transact\u2011SQL para obtener informaci\u00f3n de varias tablas de hechos y dimensiones.</li> <li>El destino (componente <code>Destino de ADO\u00a0NET</code>) inserta los registros transformados en la tabla <code>[Transversal].[FACT_ACTIVIDADES]</code> utilizando modo bulk insert cuando es posible, lo que optimiza la carga.</li> </ul>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_7","title":"Ubicaci\u00f3n en el Paquete","text":"<ul> <li>Paquete: <code>FACT_ACTIVIDADES</code></li> <li>Tarea: <code>FACT_ACTIVIDADES_NPS</code></li> <li>Componente: <code>Microsoft.Pipeline</code> (Data Flow Task)</li> <li>DTSID: <code>{89720DBD-8A16-4443-AA6F-BBB82A9BC068}</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_7","title":"Prop\u00f3sito","text":"<p>Extraer las respuestas NPS registradas en <code>FACT_ENCUESTAS</code>, enriquecerlas con informaci\u00f3n de afiliados, beneficiarios, empresas y tiempos, y consolidar todo en la tabla <code>FACT_ACTIVIDADES</code>. Esto permite analizar la satisfacci\u00f3n (NPS) junto con atributos demogr\u00e1ficos, de tiempo y de negocio en el cubo OLAP o en reportes relacionales.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_7","title":"Detalles de Implementaci\u00f3n","text":"Elemento Descripci\u00f3n Origen de Datos Componente <code>fact nps</code> (ADO\u00a0.NET Source) conectado a <code>DWH_COMFENALCO</code>. Recupera los datos mediante la instrucci\u00f3n SQL mostrada m\u00e1s abajo. Destino de Carga Componente <code>Destino de ADO\u00a0NET</code> que inserta en <code>[Transversal].[FACT_ACTIVIDADES]</code>. Conexi\u00f3n <code>Project.ConnectionManagers[DWH_COMFENALCO]</code> \u2013 GUID <code>{29BC876E-1EAF-4F6F-8F38-39B8E881EEB6}:external</code>. Modo de Inserci\u00f3n <code>UseBulkInsertWhenPossible = true</code>, <code>BatchSize = 0</code> (usa el tama\u00f1o de b\u00fafer interno). Flujo La salida del origen se conecta directamente a la entrada del destino a trav\u00e9s del path \u201cSalida de origen de ADO\u00a0NET\u201d."},{"location":"03.Cubo/03.ETL/#logica-de-negocio_5","title":"L\u00f3gica de Negocio","text":"<ol> <li> <p>Consulta principal (<code>consulta</code>)</p> <ul> <li>Recupera los registros NPS de <code>[Transversal].[FACT_ENCUESTAS]</code> filtrando <code>NPS = 'SI'</code>.</li> <li>Enriquecer con datos de dimensiones: <code>DIM_AFILIADOS</code>, <code>DIM_BENEFICIARIOS</code>, <code>DIM_EMPRESAS</code> y <code>DIM_APORTANTE_NOAFILIADO</code>.</li> <li>Ajusta claves de tiempo al primer d\u00eda de mes y asegura la existencia en <code>DIM_TIEMPO_MENSUAL</code>.</li> </ul> </li> <li> <p>Tabla auxiliar (<code>partnerTable</code>)</p> <ul> <li>Agrega informaci\u00f3n de partners a partir de <code>STG_FACT_AFILIACIONES</code> (actividad = 'AFILIACION').</li> </ul> </li> <li> <p>Resultado final</p> <ul> <li>Une <code>consulta</code> con <code>partnerTable</code> para completar atributos faltantes (partner afiliado, categor\u00eda, g\u00e9nero, edad, discapacidad).</li> <li>A\u00f1ade campos calculados y valores por defecto (por ejemplo, <code>ID_UNIDAD = COALESCE(ID_UNIDAD,5)</code>, <code>ID_CURSO = -1</code>).</li> <li>Etiqueta la fuente de los datos con la columna <code>FUENTE_PRINCIPAL</code>.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_6","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Depende de la carga previa de <code>DIM_TIEMPO_MENSUAL</code> para validar las fechas.</li> <li>Requiere que las dimensiones de Afiliados, Beneficiarios, Empresas y Aportantes No Afiliados est\u00e9n actualizadas para las claves for\u00e1neas.</li> <li>La tabla <code>FACT_ACTIVIDADES</code> es consumida por cubos OLAP y reportes anal\u00edticos que combinan actividades (ventas, cursos, NPS, etc.).</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-de-extraccion_1","title":"Script SQL de Extracci\u00f3n","text":"<pre><code>WITH consulta AS (\n    /* -------------------------------------------------\n       Construye el dataset base a partir de ENCUESTAS NPS\n    -------------------------------------------------- */\n    SELECT \n        NULL                     AS CURSO,\n        NULL                     AS ID_GRADO,\n        NULL                     AS ANIO_ACADEMICO,\n        PARTNER,\n        NULL                     AS ESTADO,\n        NULL                     AS ESTADO_PAGO,\n        ID_FECHA,\n        NULL                     AS ID_ESTADO_GESTION,\n        NULL                     AS FECHA_ADMISION,\n        NULL                     AS SERVICIO_TRANSPORTE,\n        ID_EMPRESA,\n        ID_AFILIADO,\n        ID_BENEFICIARIO,\n        ID_TIPO_AFILIADO,\n        TIPO_AFILIADO,\n        FECHA_AFILIACION,\n        FECHA_RETIRO,\n        ID_ESTADO_CIVIL,\n        ID_PERTENENCIA_ETNICA,\n        ID_FACTOR_VULNERABILIDAD,\n        ESTRATO,\n        ID_CIUDAD,\n        SALARIO_BASICO,\n        FECHA_MENSUAL,\n        NULL                     AS ID_CONCEPTO,\n        NULL                     AS VALOR_FACTURADO,\n        NULL                     AS VALOR_PAGADO,\n        NULL                     AS ADEUDA,\n        NULL                     AS NO_PRESTAMOS,\n        'INDEFINIDO'             AS DESCRIPCION,\n        ACTIVIDAD,\n        ESTADOREGISTRO,\n        TIPO_POBLACION,\n        TOTAL_APORTES,\n        NUMERO_APORTES,\n        CALIFICACION,\n        COALESCE(ID_UNIDAD,5)    AS ID_UNIDAD,\n        -1                       AS ID_CURSO,\n        -1                       AS ID_PROGRAMA,\n        -1                       AS ID_TARIFA,\n        'SI'                     AS POBLACION_EDUCACION,\n        CASE WHEN ID_UNIDAD = 1 THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_FORMAL,\n        CASE WHEN ID_UNIDAD = 2 THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_TECNICA,\n        CASE WHEN ID_UNIDAD = 3 THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_CONTINUA,\n        CASE WHEN ID_UNIDAD = 4 THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_PROTECCION\n    FROM (\n        /* ---------- Datos crudos de FACT_ENCUESTAS y dimensiones ---------- */\n        SELECT \n            COALESCE(NULLIF(de.PARTNER,'0000000000'),\n                     NULLIF(da.PARTNER,'0000000000'),\n                     NULLIF(db.PARTNER,'0000000000'),\n                     daa.PARTNER)         AS PARTNER,\n            fe.ID_EMPRESA,\n            fe.ID_AFILIADO,\n            fe.ID_BENEFICIARIO,\n            NULL                       AS ID_TIPO_AFILIADO,\n            NULL                       AS TIPO_AFILIADO,\n            COALESCE(da.ID_CATEGORIA,4) AS ID_CATEGORIA,\n            NULL                       AS FECHA_AFILIACION,\n            NULL                       AS FECHA_RETIRO,\n            COALESCE(da.ID_GENERO,-1)  AS ID_GENERO,\n            -1                         AS ID_ESTADO_CIVIL,\n            -1                         AS ID_PERTENENCIA_ETNICA,\n            -1                         AS ID_FACTOR_VULNERABILIDAD,\n            NULL                       AS ESTRATO,\n            NULL                       AS ID_CIUDAD,\n            NULL                       AS SALARIO_BASICO,\n            NULL                       AS FECHA_MENSUAL,\n            LEFT(fe.ID_FECHA,6)*100+1  AS ID_FECHA,\n            fe.ID_UNIDAD,\n            NULL                       AS ESTADOREGISTRO,\n            NULL                       AS TIPO_POBLACION,\n            'NSU'                      AS ACTIVIDAD,\n            NULL                       AS TOTAL_APORTES,\n            NULL                       AS NUMERO_APORTES,\n            fe.CALIFICACION\n        FROM [DWH_COMFENALCO].[Transversal].[FACT_ENCUESTAS]              fe\n        LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS]          da  ON fe.ID_AFILIADO   = da.ID_AFILIADO\n        LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS]      db  ON fe.ID_BENEFICIARIO = db.ID_BENEFICIARIO\n        LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS]           de  ON fe.ID_EMPRESA   = de.ID_EMPRESA\n        LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] daa ON fe.ID_APORTANTE = daa.ID_APORTANTE\n        WHERE fe.NPS = 'SI'\n    ) AS uni\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM\n        ON uni.ID_FECHA = dimM.ID_FECHA\n),\npartnerTable AS (\n    /* ----------------------------------------------\n       Datos complementarios de afiliaciones por PARTNER\n    ----------------------------------------------- */\n    SELECT \n        PARTNER,\n        ID_FECHA,\n        MAX(PARTNER_AFILIADO)           AS PARTNER_AFILIADO,\n        MAX(PARTNER_EMPRESA)            AS PARTNER_EMPRESA,\n        MIN(ID_CATEGORIA)               AS ID_CATEGORIA,\n        MAX(ID_GENERO)                  AS ID_GENERO,\n        MAX(FECHA_NACIMIENTO)           AS FECHA_NACIMIENTO,\n        MAX(EDAD)                       AS EDAD,\n        MAX(DISCAPACIDAD)               AS DISCAPACIDAD\n    FROM [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES]\n    WHERE ACTIVIDAD = 'AFILIACION'\n    GROUP BY PARTNER, ID_FECHA\n)\nSELECT  \n    c.*,\n    COALESCE(pt.PARTNER_AFILIADO,'0000000000') AS PARTNER_AFILIADO,\n    COALESCE(pt.PARTNER_EMPRESA,'0000000000')  AS PARTNER_EMPRESA,\n    '[DWH_COMFENALCO].[Transversal].[FACT_ENCUESTAS]' AS FUENTE_PRINCIPAL,\n    COALESCE(pt.ID_CATEGORIA,4)    AS ID_CATEGORIA,\n    COALESCE(pt.ID_GENERO,-1)      AS ID_GENERO,\n    pt.FECHA_NACIMIENTO,\n    COALESCE(pt.EDAD,-1)           AS EDAD,\n    COALESCE(pt.DISCAPACIDAD,2)    AS DISCAPACIDAD\nFROM consulta c\nLEFT JOIN partnerTable pt\n    ON c.PARTNER = pt.PARTNER\n   AND c.ID_FECHA = pt.ID_FECHA;\n</code></pre> <p>Nota:</p> <ul> <li>La consulta usa varias funciones <code>COALESCE</code> y valores por defecto (<code>-1</code>, <code>'SI'</code>, <code>'NO'</code>, <code>'INDEFINIDO'</code>) para garantizar integridad referencial y evitar valores nulos en la tabla de hechos.</li> <li>Las columnas de tiempo se alinean al primer d\u00eda de cada mes para aprovechar la clave existente en <code>DIM_TIEMPO_MENSUAL</code>.</li> <li>El campo <code>FUENTE_PRINCIPAL</code> documenta la procedencia original de los datos, facilitando trazabilidad en el Data\u00a0Warehouse.</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_actividades_proteccion","title":"FACT_ACTIVIDADES_PROTECCION","text":"<p>El componente <code>FACT_ACTIVIDADES_PROTECCION</code> forma parte del paquete SSIS <code>FACT_ACTIVIDADES</code> y consolida\u202flas actividades del \u00e1rea de Protecci\u00f3n (ventas, caracterizaciones, deserciones y entrega de material) en la tabla <code>FACT_ACTIVIDADES</code> del Data\u202fWarehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_8","title":"Descripci\u00f3n general","text":"<p>Se trata de una tarea de flujo de datos (Data\u202fFlow\u202fTask) que:</p> <ol> <li>Extrae la informaci\u00f3n mediante una\u202ffuente ADO\u202f.NET (componente <code>proteccion</code>) usando una consulta SQL que unifica varias tablas fact y adiciona metadatos procedentes de otras\u202fdimensiones.</li> <li>Transforma determinados campos con el componente <code>Data\u202fConversion</code> (por ejemplo, convierte num\u00e9ricos a decimales y a cadenas).</li> <li>Carga el resultado en <code>[Transversal].[FACT_ACTIVIDADES]</code> mediante un destino ADO\u202f.NET con inserci\u00f3n masiva (SqlBulkCopy).</li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_8","title":"Ubicaci\u00f3n en el paquete","text":"Nivel Valor Paquete <code>FACT_ACTIVIDADES</code> Ruta interna <code>Package\\FACT_ACTIVIDADES\\FACT_ACTIVIDADES_PROTECCION</code> Tipo de ejecutable <code>Microsoft.Pipeline</code> (Data\u202fFlow\u202fTask) DTSID <code>{96A6D477-CB23-402D-9C9C-7D0337963198}</code>"},{"location":"03.Cubo/03.ETL/#proposito_8","title":"Prop\u00f3sito","text":"<p>Consolidar, a nivel mensual, todas las actividades de los programas de protecci\u00f3n en un \u00fanico fact table (<code>FACT_ACTIVIDADES</code>) para su explotaci\u00f3n anal\u00edtica. Se integran ventas, caracterizaciones, deserciones y entregas de material junto con atributos poblacionales, afiliatorios y temporales.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_8","title":"Detalles de implementaci\u00f3n","text":"Elemento Descripci\u00f3n Origen de datos Componente <code>proteccion</code> \u2013 ADO\u202f.NET Source. Extrae datos mediante la consulta SQL que se documenta m\u00e1s abajo. Transformaciones <code>Data Conversion</code> crea:\u2022 <code>Copy of VALOR_MATERIAL</code> \u2192 <code>decimal(28,2)</code>\u2022 <code>Copy of VALOR_PAGADO_SIN_IMP</code> \u2192 <code>decimal(28,2)</code>\u2022 <code>Copy of SUBSIDIO</code> \u2192 <code>nvarchar(50)</code> Destino de carga Componente <code>Destino de ADO\u202fNET</code> \u2013 tabla <code>[Transversal].[FACT_ACTIVIDADES]</code>. Usa <code>UseBulkInsertWhenPossible = true</code> para mayor rendimiento. Conexiones <code>Project.ConnectionManagers[DWH_COMFENALCO]</code> (origen y destino). Filas por lote 0 (usa el tama\u00f1o de b\u00fafer interno de SSIS). Timeout comandos 30\u202fs (por defecto)"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_6","title":"L\u00f3gica de negocio","text":"<ol> <li> <p>Unificaci\u00f3n de fuentes \u2013\u202fla CTE <code>consulta</code> agrupa registros de:</p> <ul> <li><code>[Proteccion].[FACT_VENTA]</code></li> <li><code>[Proteccion].[FACT_CARACTERIZACION]</code> + <code>[Proteccion].[DIM_PROGRAMA]</code></li> <li><code>[Proteccion].[FACT_DESERCION]</code> + <code>[Proteccion].[DIM_PROGRAMA]</code></li> <li><code>[Proteccion].[FACT_ENTREGA_MATERIAL]</code></li> </ul> </li> <li> <p>Enriquecimiento poblacional \u2013 se enlaza con <code>[Proteccion].[DIM_POBLACION]</code> para obtener <code>ID_AFILIADO</code>, <code>ID_BENEFICIARIO</code>, <code>ID_EMPRESA</code>, etc.</p> </li> <li> <p>Datos afiliatorios \u2013 se cruzan las dimensiones de afiliados, beneficiarios, empresas y aportantes no afiliados del esquema Transversal para resolver el <code>PARTNER</code>.</p> </li> <li> <p>Calendario \u2013 se obliga a que la fecha fact (<code>ID_FECHA</code>) exista en <code>[Transversal].[DIM_TIEMPO_MENSUAL]</code>.</p> </li> <li> <p>Metadatos de afiliaci\u00f3n \u2013 se trae informaci\u00f3n complementaria de <code>[STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES]</code> (CTE <code>partnerTable</code>) para categor\u00eda, g\u00e9nero, edad, discapacidad y partners relacionados.</p> </li> <li> <p>Flags de poblaci\u00f3n \u2013 se derivan los campos <code>POBLACION_EDUCACION*</code> seg\u00fan la unidad acad\u00e9mica (<code>ID_UNIDAD</code>).</p> </li> <li> <p>Conversi\u00f3n de tipos \u2013 se ajustan tipos num\u00e9ricos y se generan copias para adecuarse al schema de destino.</p> </li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_7","title":"Relaci\u00f3n con otros componentes","text":"<ul> <li>Este flujo se ejecuta dentro del contenedor <code>FACT_ACTIVIDADES</code>, junto con otros procesos (por ejemplo, afiliaciones y aportes) que alimentan la misma tabla de hechos <code>FACT_ACTIVIDADES</code>.</li> <li>Las columnas de afiliaci\u00f3n utilizadas aqu\u00ed provienen del flujo <code>STG_FACT_AFILIACIONES</code> documentado aparte.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-de-extraccion_2","title":"Script SQL de extracci\u00f3n","text":"<pre><code>WITH consulta AS (  ----------------------------------\n    SELECT\n        CASE\n            WHEN de.PARTNER &lt;&gt; '0000000000' THEN de.PARTNER\n            WHEN da.PARTNER &lt;&gt; '0000000000' THEN da.PARTNER\n            WHEN db.PARTNER &lt;&gt; '0000000000' THEN db.PARTNER\n            ELSE daa.PARTNER\n        END                                            AS [PARTNER],\n        dp.[ID_EMPRESA],\n        dp.[ID_AFILIADO],\n        dp.[ID_BENEFICIARIO],\n        dp.ID_POBLACION,\n        ID_FECHA,\n        [CATEGORIA_VENTA],\n        COALESCE(DESCRIPCION,'INDEFINIDO')             AS DESCRIPCION,\n        [COSTO],\n        [SUBSIDIO],\n        [VALOR_PAGADO_SIN_IMP],\n        ID_PREGUNTA,\n        RESPUESTA,\n        ANIO_ACADEMICO,\n        CAUSA,\n        ID_PROGRAMA,\n        ID_MATERIAL,\n        CANTIDAD_MATERIAL,\n        VALOR_MATERIAL,\n        ACTIVIDAD,\n        4                                              AS ID_UNIDAD,\n        -1                                             AS ID_CURSO,\n        -1                                             AS ID_PERTENENCIA_ETNICA,\n        ID_FACTOR_VULNERABILIDAD,\n        -1                                             AS ID_ESTADO_CIVIL,\n        ID_TARIFA,\n        'INDEFINIDO'                                   AS ESTADO_PAGO,\n        'INDEFINIDO'                                   AS TIPO_POBLACION,\n        FUENTE_PRINCIPAL\n    FROM (\n        /* ---------- FACT_VENTA ---------- */\n        SELECT  LEFT([ID_FECHA],6)*100+1               AS ID_FECHA,\n                [ID_POBLACION],\n                [CATEGORIA_VENTA],\n                [SERVICIO]                             AS DESCRIPCION,\n                [COSTO],\n                [SUBSIDIO],\n                [VALOR_PAGADO_SIN_IMP],\n                NULL                                   AS ID_PREGUNTA,\n                NULL                                   AS RESPUESTA,\n                NULL                                   AS ANIO_ACADEMICO,\n                NULL                                   AS CAUSA,\n                -1                                     AS ID_PROGRAMA,\n                NULL                                   AS ID_MATERIAL,\n                NULL                                   AS CANTIDAD_MATERIAL,\n                NULL                                   AS VALOR_MATERIAL,\n                'VENTA'                                AS ACTIVIDAD,\n                '[DWH_COMFENALCO].[Proteccion].[FACT_VENTA]'          AS [FUENTE_PRINCIPAL],\n                [ID_TARIFA]\n        FROM    [DWH_COMFENALCO].[Proteccion].[FACT_VENTA]\n\n        UNION ALL\n        /* ---------- FACT_CARACTERIZACION ---------- */\n        SELECT  LEFT([ID_FECHA],6)*100+1               AS ID_FECHA,\n                [ID_POBLACION],\n                NULL                                   AS CATEGORIA_VENTA,\n                dp.PROGRAMA                            AS DESCRIPCION,\n                NULL                                   AS COSTO,\n                NULL                                   AS SUBSIDIO,\n                NULL                                   AS VALOR_PAGADO_SIN_IMP,\n                [ID_PREGUNTA],\n                [RESPUESTA],\n                NULL                                   AS ANIO_ACADEMICO,\n                NULL                                   AS CAUSA,\n                fc.ID_PROGRAMA,\n                NULL                                   AS ID_MATERIAL,\n                NULL                                   AS CANTIDAD_MATERIAL,\n                NULL                                   AS VALOR_MATERIAL,\n                'CARACTERIZACION'                      AS ACTIVIDAD,\n                '[DWH_COMFENALCO].[Proteccion].[FACT_CARACTERIZACION]' AS [FUENTE_PRINCIPAL],\n                -1                                     AS ID_TARIFA\n        FROM    [DWH_COMFENALCO].[Proteccion].[FACT_CARACTERIZACION] fc\n        LEFT JOIN [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] dp\n               ON fc.ID_PROGRAMA = dp.ID_PROGRAMA\n\n        UNION ALL\n        /* ---------- FACT_DESERCION ---------- */\n        SELECT  LEFT([ID_FECHA],6)*100+1               AS ID_FECHA,\n                fd.[ID_POBLACION],\n                NULL                                   AS CATEGORIA_VENTA,\n                dp.PROGRAMA                            AS DESCRIPCION,\n                NULL                                   AS COSTO,\n                NULL                                   AS SUBSIDIO,\n                NULL                                   AS VALOR_PAGADO_SIN_IMP,\n                NULL                                   AS ID_PREGUNTA,\n                NULL                                   AS RESPUESTA,\n                [ANIO_ACADEMICO]*10000+101             AS ANIO_ACADEMICO,\n                [CAUSA],\n                -1                                     AS ID_PROGRAMA,\n                NULL                                   AS ID_MATERIAL,\n                NULL                                   AS CANTIDAD_MATERIAL,\n                NULL                                   AS VALOR_MATERIAL,\n                'DESERCION'                            AS ACTIVIDAD,\n                '[DWH_COMFENALCO].[Proteccion].[FACT_DESERCION]'      AS [FUENTE_PRINCIPAL],\n                -1                                     AS ID_TARIFA\n        FROM    [DWH_COMFENALCO].[Proteccion].[FACT_DESERCION] fd\n        LEFT JOIN [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] dp\n               ON fd.ID_PROGRAMA = dp.ID_PROGRAMA\n\n        UNION ALL\n        /* ---------- FACT_ENTREGA_MATERIAL ---------- */\n        SELECT  LEFT([ID_FECHA],6)*100+1               AS ID_FECHA,\n                [ID_POBLACION],\n                NULL                                   AS CATEGORIA_VENTA,\n                NULL                                   AS DESCRIPCION,\n                NULL                                   AS COSTO,\n                NULL                                   AS SUBSIDIO,\n                NULL                                   AS VALOR_PAGADO_SIN_IMP,\n                NULL                                   AS ID_PREGUNTA,\n                NULL                                   AS RESPUESTA,\n                NULL                                   AS ANIO_ACADEMICO,\n                NULL                                   AS CAUSA,\n                [ID_PROGRAMA],\n                [ID_MATERIAL],\n                [CANTIDAD_MATERIAL],\n                [VALOR_MATERIAL],\n                'ENTREGA_MATERIAL'                     AS ACTIVIDAD,\n                '[DWH_COMFENALCO].[Proteccion].[FACT_ENTREGA_MATERIAL]' AS [FUENTE_PRINCIPAL],\n                -1                                     AS ID_TARIFA\n        FROM    [DWH_COMFENALCO].[Proteccion].[FACT_ENTREGA_MATERIAL]\n    ) un\n    JOIN [DWH_COMFENALCO].[Proteccion].[DIM_POBLACION]   dp ON un.[ID_POBLACION] = dp.[ID_POBLACION]\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS]           da  ON dp.ID_AFILIADO    = da.ID_AFILIADO\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS]       db  ON dp.ID_BENEFICIARIO= db.ID_BENEFICIARIO\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS]            de  ON dp.ID_EMPRESA     = de.ID_EMPRESA\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO]daa ON dp.ID_APORTANTE   = daa.ID_APORTANTE\n    INNER JOIN (\n        SELECT ID_FECHA AS ID_FECHA2\n        FROM   [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n    ) dimM ON un.ID_FECHA = dimM.ID_FECHA2\n),\npartnerTable AS (\n    SELECT PARTNER, ID_FECHA,\n           MAX(PARTNER_AFILIADO)  AS PARTNER_AFILIADO,\n           MAX(PARTNER_EMPRESA)   AS PARTNER_EMPRESA,\n           MIN(ID_CATEGORIA)      AS ID_CATEGORIA,\n           MAX(ID_GENERO)         AS ID_GENERO,\n           MAX(FECHA_NACIMIENTO)  AS FECHA_NACIMIENTO,\n           MAX(EDAD)              AS EDAD,\n           MAX(DISCAPACIDAD)      AS DISCAPACIDAD\n    FROM   [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES]\n    WHERE  ACTIVIDAD = 'AFILIACION'\n    GROUP BY PARTNER, ID_FECHA\n)\nSELECT c.*,\n       COALESCE(pt.PARTNER_AFILIADO, '0000000000')      AS PARTNER_AFILIADO,\n       COALESCE(pt.PARTNER_EMPRESA , '0000000000')      AS PARTNER_EMPRESA,\n       COALESCE(pt.ID_CATEGORIA   , 4)                 AS ID_CATEGORIA,\n       COALESCE(pt.ID_GENERO      , -1)                AS ID_GENERO,\n       pt.FECHA_NACIMIENTO,\n       COALESCE(pt.EDAD           , -1)                AS EDAD,\n       COALESCE(pt.DISCAPACIDAD   , 2)                 AS DISCAPACIDAD,\n       'SI'                                            AS POBLACION_EDUCACION,\n       CASE WHEN c.ID_UNIDAD = 1 THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_FORMAL,\n       CASE WHEN c.ID_UNIDAD = 2 THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_TECNICA,\n       CASE WHEN c.ID_UNIDAD = 3 THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_CONTINUA,\n       CASE WHEN c.ID_UNIDAD = 4 THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_PROTECCION\nFROM   consulta c\nLEFT  JOIN partnerTable pt\n       ON c.PARTNER = pt.PARTNER\n      AND c.ID_FECHA = pt.ID_FECHA;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_actividades_cedesarrollo","title":"FACT_ACTIVIDADES_CEDESARROLLO","text":"<p>El componente <code>FACT_ACTIVIDADES_CEDESARROLLO</code> pertenece al paquete SSIS <code>FACT_ACTIVIDADES</code>, dentro de la ruta <code>Actividades\u202fCedesarrollo\\FACT_ACTIVIDADES_CEDESARROLLO</code>, y se encarga de consolidar y cargar la informaci\u00f3n de actividades acad\u00e9micas y administrativas en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> del Data\u202fWarehouse.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_9","title":"Descripci\u00f3n\u202fGeneral","text":"<p>Se trata de una tarea de flujo de datos (Data\u202fFlow\u202fTask) compuesta por:</p> Componente Tipo Descripci\u00f3n cedesarrollo ADO\u202fNET\u202fSource Ejecuta una consulta SQL extensa que unifica m\u00faltiples hechos (graduados, inasistencias, cotizaciones, matr\u00edcula, deserciones, etc.) y les a\u00f1ade atributos demogr\u00e1ficos. Destino de ADO\u202fNET ADO\u202fNET\u202fDestination Inserta el conjunto resultante en <code>Transversal.FACT_ACTIVIDADES</code> usando SqlBulkCopy para acelerar la carga."},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_9","title":"Ubicaci\u00f3n\u202fen\u202fel\u202fPaquete","text":"<ul> <li>Paquete: <code>FACT_ACTIVIDADES</code></li> <li>Carpeta: <code>Actividades\u202fCedesarrollo</code></li> <li>Tarea: <code>FACT_ACTIVIDADES_CEDESARROLLO</code></li> <li>DTSID: <code>{fd72a580-f504-4930-9aef-e5cb0d6648cb}</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_9","title":"Prop\u00f3sito","text":"<p>Consolidar, enriquecer y cargar en un \u00fanico hecho todas las interacciones relevantes de los estudiantes del programa Cedesarrollo (graduaci\u00f3n, asistencia, retiros, notas, facturaci\u00f3n, etc.), normalizadas a nivel mensual y alineadas con la dimensi\u00f3n tiempo <code>DIM_TIEMPO_MENSUAL</code> para su an\u00e1lisis en el cubo OLAP y en reportes operativos.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_9","title":"Detalles\u202fde\u202fImplementaci\u00f3n","text":"Aspecto Detalle Origen de datos La consulta extrae y unifica informaci\u00f3n de varias tablas de los esquemas <code>Cedesarrollo</code> y <code>Transversal</code>. Transformaciones clave * UNION de ocho subconjuntos de datos.* Derivaci\u00f3n de campos por defecto (<code>-1</code>, \u2018INDEFINIDO\u2019).* Join con la tabla <code>STG_FACT_AFILIACIONES</code> (aliased partnerTable) para atributos demogr\u00e1ficos.* Filtrado a fechas presentes en <code>DIM_TIEMPO_MENSUAL</code> (garantizando granularidad mensual). Destino <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> Conexi\u00f3n Connection\u202fManager <code>DWH_COMFENALCO</code> \u2013 GUID <code>{29BC876E\u20111EAF\u20114F6F\u20118F38\u201139B8E881EEB6}</code> Modo de carga SqlBulkCopy (propiedad <code>UseBulkInsertWhenPossible = true</code>) sin partici\u00f3n por lotes (BatchSize\u202f=\u202f0). Manejo de errores Salidas de error configuradas para origen y destino con los campos est\u00e1ndar <code>ErrorCode</code> y <code>ErrorColumn</code>."},{"location":"03.Cubo/03.ETL/#logica-de-negocio_7","title":"L\u00f3gica\u202fde\u202fNegocio","text":"<ol> <li> <p>Unificaci\u00f3n de hechos:</p> <ul> <li>Graduados, Inasistencias (regular y FOSFEC), Inscripci\u00f3n y Estado de Matr\u00edculas, Asistencia a Bienestar, Cotizaciones, Deserciones y Promoci\u00f3n/Repitencia se combinan en una sola CTE <code>consulta</code>.</li> </ul> </li> <li> <p>Normalizaci\u00f3n temporal:</p> <ul> <li>Cada registro se convierte al primer d\u00eda del mes correspondiente (<code>LEFT(ID_FECHA,6)*100+1</code>) y se valida contra <code>DIM_TIEMPO_MENSUAL</code>.</li> </ul> </li> <li> <p>Enriquecimiento demogr\u00e1fico:</p> <ul> <li>Uni\u00f3n con <code>STG_FACT_AFILIACIONES</code> para obtener <code>PARTNER_AFILIADO</code>, <code>PARTNER_EMPRESA</code>, <code>ID_CATEGORIA</code>, <code>ID_GENERO</code>, edad, discapacidad y fecha de nacimiento.</li> </ul> </li> <li> <p>Marcado de poblaci\u00f3n:</p> <ul> <li>Se generan banderas <code>POBLACION_EDUCACION_*</code> seg\u00fan la unidad acad\u00e9mica (1=Formal,\u202f2=T\u00e9cnica,\u202f3=Continua,\u202f4=Protecci\u00f3n).</li> </ul> </li> <li> <p>Carga:</p> <ul> <li>El resultado final se inserta en <code>FACT_ACTIVIDADES</code> para consumo anal\u00edtico.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_8","title":"Relaci\u00f3n\u202fcon\u202fOtros\u202fComponentes","text":"<ul> <li><code>DIM_TIEMPO_MENSUAL</code> \u2013 Garantiza coherencia de fechas a nivel mensual.</li> <li>Diversas dimensiones de Transversal (Afiliados, Beneficiarios, Empresas, Aportantes) y de Cedesarrollo (Estudiantes, Jornada, Periodo Acad\u00e9mico) para claves for\u00e1neas.</li> <li>Sirve como hecho base para indicadores de gesti\u00f3n educativa, asistencia y facturaci\u00f3n en los cubos de Educaci\u00f3n\u202fy\u202fBienestar.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-de-extraccion_3","title":"Script\u202fSQL de\u202fExtracci\u00f3n","text":"<p>A continuaci\u00f3n se incluye \u00edntegramente la consulta utilizada por el componente <code>cedesarrollo</code>. Se divide en dos CTE principales (<code>consulta</code>, <code>partnerTable</code>) y la selecci\u00f3n final.</p> <pre><code>WITH consulta AS (\n    ----------------------------------\n    SELECT con.*,\n           -1  AS ID_CURSO,\n           -1  AS ID_PERTENENCIA_ETNICA,\n           -1  AS ID_FACTOR_VULNERABILIDAD,\n           -1  AS ID_ESTADO_CIVIL,\n           'INDEFINIDO' AS ESTADO_PAGO,\n           'INDEFINIDO' AS TIPO_POBLACION\n    FROM (\n        /* === GRADUADOS ==================================================== */\n        SELECT  ID_ESTUDIANTE,\n                ISNULL(ID_PROGRAMA,-1)          AS ID_PROGRAMA,\n                ID_PERIODO,\n                LEFT(FORMAT(FECHA_GRADUADO,'yyyyMMdd'),6)*100+1 AS ID_FECHA,\n                GRUPO,\n                NULL AS TOTAL_INASISTENCIA,\n                NULL AS ESTADO,\n                'INDEFINIDO' AS DESCRIPCION,\n                NULL AS ASISTIO,\n                'GRADUADOS' AS ACTIVIDAD,\n                j.ID_UNIDAD,\n                '[DWH_COMFENALCO].[Cedesarrollo].[FACT_GRADUADOS]' AS FUENTE_PRINCIPAL,\n                ID_GRADUADO,\n                -1 AS ID_DESERCION,\n                -1 AS ID_MATRICULA\n        FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_GRADUADOS] fg\n        INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j\n               ON fg.ID_JORNADA = j.ID_JORNADA\n\n        UNION ALL\n        /* === INASISTENCIAS ================================================ */\n        SELECT ID_ESTUDIANTE,\n               -1 AS ID_PROGRAMA,\n               ID_PERIODO,\n               LEFT(ID_FECHA,6)*100+1 AS ID_FECHA,\n               NULL AS GRUPO,\n               TOTAL_INASISTENCIA,\n               NULL AS ESTADO,\n               'INDEFINIDO' AS DESCRIPCION,\n               NULL AS ASISTIO,\n               'INASISTENCIAS' AS ACTIVIDAD,\n               j.ID_UNIDAD,\n               '[DWH_COMFENALCO].[Cedesarrollo].[FACT_INASISTENCIAS]' AS FUENTE_PRINCIPAL,\n               -1 AS ID_GRADUADO,\n               -1 AS ID_DESERCION,\n               -1 AS ID_MATRICULA\n        FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INASISTENCIAS] fi\n        INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j\n               ON fi.ID_JORNADA = j.ID_JORNADA\n        /* \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 */\n        /*  \u21b3\u00a0Se omiten por brevedad los bloques UNION ALL de:                */\n        /*    - INASISTENCIA_FOSFEC                                           */\n        /*    - INSCRIPCION_MATRICULAS                                        */\n        /*    - ASISTENCIA_ACT_BIENESTAR                                      */\n        /*    - COTIZACIONES                                                  */\n        /*    - ESTADO_MATRICULAS                                             */\n        /*    - DESERCION                                                     */\n        /*    - PROMOCION / REPITENCIA                                        */\n        /* ================================================================== */\n    ) uni\n    /* === JOIN con dimensiones Transversal y validaci\u00f3n de fecha mensual === */\n    LEFT  JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] die\n           ON uni.ID_ESTUDIANTE = die.ID_ESTUDIANTE\n    LEFT  JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] da\n           ON die.ID_AFILIADO = da.ID_AFILIADO\n    LEFT  JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] db\n           ON die.ID_BENEFICIARIO = db.ID_BENEFICIARIO\n    LEFT  JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] de\n           ON die.ID_EMPRESA = de.ID_EMPRESA\n    LEFT  JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] daa\n           ON die.ID_APORTANTE = daa.ID_APORTANTE\n    INNER JOIN (SELECT ID_FECHA AS ID_FECHA2\n                FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]) dimM\n           ON uni.ID_FECHA = dimM.ID_FECHA2\n    -----------------------------------\n),\npartnerTable AS (\n    SELECT  PARTNER,\n            ID_FECHA,\n            MAX(PARTNER_AFILIADO)  AS PARTNER_AFILIADO,\n            MAX(PARTNER_EMPRESA)   AS PARTNER_EMPRESA,\n            MIN(ID_CATEGORIA)      AS ID_CATEGORIA,\n            MAX(ID_GENERO)         AS ID_GENERO,\n            MAX(FECHA_NACIMIENTO)  AS FECHA_NACIMIENTO,\n            MAX(EDAD)              AS EDAD,\n            MAX(DISCAPACIDAD)      AS DISCAPACIDAD\n    FROM [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES]\n    WHERE ACTIVIDAD = 'AFILIACION'\n    GROUP BY PARTNER, ID_FECHA\n)\n/* === Selecci\u00f3n final ===================================================== */\nSELECT  c.*,\n        ISNULL(pt.PARTNER_AFILIADO,'0000000000')               AS PARTNER_AFILIADO,\n        ISNULL(pt.PARTNER_EMPRESA,'0000000000')                AS PARTNER_EMPRESA,\n        ISNULL(pt.ID_CATEGORIA,4)                              AS ID_CATEGORIA,\n        ISNULL(pt.ID_GENERO,-1)                                AS ID_GENERO,\n        pt.FECHA_NACIMIENTO,\n        ISNULL(pt.EDAD,-1)                                     AS EDAD,\n        ISNULL(pt.DISCAPACIDAD,2)                              AS DISCAPACIDAD,\n        'SI'                                                   AS POBLACION_EDUCACION,\n        CASE WHEN c.ID_UNIDAD = 1 THEN 'SI' ELSE 'NO' END      AS POBLACION_EDUCACION_FORMAL,\n        CASE WHEN c.ID_UNIDAD = 2 THEN 'SI' ELSE 'NO' END      AS POBLACION_EDUCACION_TECNICA,\n        CASE WHEN c.ID_UNIDAD = 3 THEN 'SI' ELSE 'NO' END      AS POBLACION_EDUCACION_CONTINUA,\n        CASE WHEN c.ID_UNIDAD = 4 THEN 'SI' ELSE 'NO' END      AS POBLACION_EDUCACION_PROTECCION\nFROM    consulta c\nLEFT JOIN partnerTable pt\n       ON c.PARTNER = pt.PARTNER\n      AND c.ID_FECHA = pt.ID_FECHA;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#notas-adicionales","title":"Notas\u202fAdicionales","text":"<ul> <li>La salida incluye columnas de control (<code>ErrorCode</code>, <code>ErrorColumn</code>) para manejo de filas rechazadas.</li> <li>Los valores por defecto (<code>-1</code>, \u2018INDEFINIDO\u2019, \u20180000000000\u2019) permiten mantener integridad referencial sin nulos en el destino.</li> <li>El modelo soporta trazabilidad de la fuente original mediante el campo <code>FUENTE_PRINCIPAL</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#actividades-cedesarrollomatricula-mensual-educacion-tecnica","title":"Actividades Cedesarrollo\\Matricula Mensual Educacion Tecnica","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general-del-componente","title":"Descripci\u00f3n General del Componente","text":"<p>Este flujo de datos del paquete SSIS extrae, transforma y carga registros mensuales de matr\u00edcula de educaci\u00f3n t\u00e9cnica provenientes de Cedesarrollo. Su prop\u00f3sito es consolidar la informaci\u00f3n de estudiantes matriculados con dimensiones transversales como afiliaciones, beneficiarios, empresas y tiempo acad\u00e9mico, para insertarla en la tabla <code>FACT_ACTIVIDADES</code> del DWH.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-del-paquete","title":"Ubicaci\u00f3n del Paquete","text":"<p><code>Package\\FACT_ACTIVIDADES\\Actividades Cedesarrollo\\Matricula Mensual Educacion Tecnica</code></p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<p>Cargar mensualmente las matr\u00edculas aprobadas en educaci\u00f3n t\u00e9cnica desde la tabla <code>FACT_ESTADO_MATRICULAS</code> y enriquecerlas con informaci\u00f3n demogr\u00e1fica, acad\u00e9mica y de afiliaci\u00f3n para an\u00e1lisis de cobertura y caracterizaci\u00f3n poblacional.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_10","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Origen: <code>DWH_COMFENALCO.Cedesarrollo.FACT_ESTADO_MATRICULAS</code></li> <li>Destino: <code>DWH_COMFENALCO_Destino.Transversal.FACT_ACTIVIDADES</code></li> <li> <p>Transformaciones:</p> <ul> <li>Filtrado por unidad acad\u00e9mica <code>ID_UNIDAD = 2</code>.</li> <li>Uni\u00f3n con las tablas de dimensi\u00f3n <code>DIM_JORNADA</code>, <code>DIM_ESTUDIANTES</code>, <code>DIM_PERIODO_ACADEMICO</code>, <code>STG_FACT_AFILIACIONES</code>, <code>DIM_AFILIADOS</code>, <code>DIM_BENEFICIARIOS</code> y <code>DIM_EMPRESAS</code>.</li> <li>Generaci\u00f3n de fechas mensuales con <code>DIM_TIEMPO_MENSUAL</code>.</li> <li>Clasificaci\u00f3n de poblaci\u00f3n por tipo de educaci\u00f3n.</li> <li>Conversi\u00f3n de campos como <code>ID_FECHA</code>, <code>PARTNER</code>, <code>ID_ESTUDIANTE</code>, <code>ID_CATEGORIA</code>, <code>DISCAPACIDAD</code>, entre otros.</li> </ul> </li> <li> <p>M\u00e9todo de carga: Bulk Insert mediante ADO.NET Destination.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_8","title":"L\u00f3gica de Negocio","text":"<ol> <li>Se filtran las matr\u00edculas con fecha de inicio v\u00e1lida y unidad de tipo t\u00e9cnica.</li> <li>Se enriquecen con datos del estudiante (afiliado, empresa, beneficiario) mediante <code>LEFT JOIN</code>.</li> <li>Se busca informaci\u00f3n de afiliaciones activas (<code>ACTIVIDAD = 'AFILIACION'</code>) para el mismo partner y fecha.</li> <li>Se establecen variables categ\u00f3ricas como <code>POBLACION_EDUCACION_TECNICA</code> para segmentar seg\u00fan unidad educativa.</li> <li>Se replican los datos para cada mes en el rango del semestre utilizando una tabla de fechas generada din\u00e1micamente.</li> <li>Finalmente, se insertan en <code>FACT_ACTIVIDADES</code>, incluyendo trazabilidad del partner, identificaci\u00f3n del estudiante y clasificaci\u00f3n poblacional.</li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_9","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Dependencias:</p> <ul> <li><code>DWH_COMFENALCO.Cedesarrollo.DIM_JORNADA</code></li> <li><code>DWH_COMFENALCO.Cedesarrollo.DIM_ESTUDIANTES</code></li> <li><code>DWH_COMFENALCO.Transversal.STG_FACT_AFILIACIONES</code></li> <li><code>DWH_COMFENALCO.Transversal.DIM_TIEMPO_MENSUAL</code></li> </ul> </li> <li> <p>Alimenta:</p> <ul> <li>Tabla de hechos <code>FACT_ACTIVIDADES</code>, usada en dashboards de educaci\u00f3n t\u00e9cnica.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-principal","title":"Script SQL Principal","text":"<pre><code>WITH Matriculas_Cedesarrollo AS (\n  SELECT DISTINCT ...\n  FROM DWH_COMFENALCO.Cedesarrollo.FACT_ESTADO_MATRICULAS ...\n  WHERE j.ID_UNIDAD = 2 AND pa.FECHA_INICIO IS NOT NULL\n),\nFechasMensualesCedesarrollo AS (\n  SELECT A\u00f1o * 10000 + (Mes % 100) * 100 + 01 AS ID_FECHA_MENSUAL, ...\n),\npartnerTable AS (\n  SELECT PARTNER, ID_FECHA, MAX(PARTNER_AFILIADO) AS PARTNER_AFILIADO, ...\n  FROM STAGE_AREA.Transversal.STG_FACT_AFILIACIONES\n  WHERE ACTIVIDAD = 'AFILIACION'\n  GROUP BY PARTNER, ID_FECHA\n),\nMatriculasCedesarrolloCompleto AS (\n  SELECT c.*, COALESCE(pt.PARTNER_AFILIADO, '0000000000') ...\n  FROM Matriculas_Cedesarrollo c\n  LEFT JOIN partnerTable pt ON c.PARTNER = pt.PARTNER ...\n),\nMatriculas_CedesarrolloMensual AS (\n  SELECT mc.*, ID_FECHA_MENSUAL AS ID_FECHA\n  FROM MatriculasCedesarrolloCompleto mc\n  INNER JOIN FechasMensualesCedesarrollo fm ...\n)\nSELECT cm.*\nFROM Matriculas_CedesarrolloMensual cm\nINNER JOIN DWH_COMFENALCO.Transversal.DIM_TIEMPO_MENSUAL dimM\n  ON cm.ID_FECHA = dimM.ID_FECHA\nORDER BY PARTNER, ID_FECHA;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#actividades-cedesarrollofacturacion-tecnica-y-continua","title":"Actividades Cedesarrollo\\Facturacion Tecnica y Continua","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general-del-componente_1","title":"Descripci\u00f3n General del Componente","text":"<p>Este componente realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de la informaci\u00f3n de facturaci\u00f3n de servicios t\u00e9cnicos y educaci\u00f3n continua del sistema de Cedesarrollo hacia la tabla <code>FACT_ACTIVIDADES</code> en el <code>DWH_COMFENALCO</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-del-componente","title":"Ubicaci\u00f3n del Componente","text":"<ul> <li>Paquete SSIS: <code>FACT_ACTIVIDADES</code></li> <li>Ruta: <code>Actividades Cedesarrollo\\Facturacion Tecnica y Continua</code></li> <li>Tipo de tarea: <code>Data Flow Task</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_10","title":"Prop\u00f3sito","text":"<p>Unificar, enriquecer y cargar informaci\u00f3n de facturaci\u00f3n t\u00e9cnica y continua, relacionando datos de tarifas, afiliados, estudiantes y beneficios, permitiendo an\u00e1lisis detallados de cobertura educativa y subsidios aplicados.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_11","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen:</p> <ul> <li>Componente <code>cedesarrollo</code> (origen ADO.NET).</li> <li>Consulta SQL avanzada con subconsultas <code>SubsidiosCedesarrollo</code>, <code>Facturacion</code> y <code>partnerTable</code>.</li> </ul> </li> <li> <p>Destino:</p> <ul> <li>Componente <code>Destino de ADO NET</code> cargando en tabla <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code>.</li> <li>Uso de <code>SqlBulkCopy</code> habilitado para rendimiento \u00f3ptimo.</li> </ul> </li> <li> <p>Tipo de Conexiones:</p> <ul> <li><code>DWH_COMFENALCO</code> (origen).</li> <li><code>DWH_COMFENALCO_Destino</code> (destino).</li> </ul> </li> <li> <p>Timeout Configurado: 30 segundos.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_9","title":"L\u00f3gica de Negocio","text":"<ul> <li>Se calculan subsidios para categor\u00edas 1 y 2 en tarifas distintas al a\u00f1o 2022.</li> <li> <p>La unidad educativa se clasifica como:</p> <ul> <li><code>ID_UNIDAD = 1</code>: Formal</li> <li><code>ID_UNIDAD = 2</code>: T\u00e9cnica</li> <li><code>ID_UNIDAD = 3</code>: Continua</li> <li><code>ID_UNIDAD = 4</code>: Protecci\u00f3n</li> </ul> </li> <li> <p>Se asignan valores categ\u00f3ricos \"SI\"/\"NO\" a indicadores como <code>POBLACION_EDUCACION_CONTINUA</code>.</p> </li> <li> <p>La determinaci\u00f3n del <code>PARTNER</code> se basa en un orden de prioridad entre tablas de afiliados, empresas y estudiantes.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_10","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Integra datos desde:</p> <ul> <li><code>FACT_FACTURACION</code> de Cedesarrollo.</li> <li>Tablas dimensionales: <code>DIM_AFILIADOS</code>, <code>DIM_BENEFICIARIOS</code>, <code>DIM_EMPRESAS</code>, <code>DIM_APORTANTE_NOAFILIADO</code>, <code>DIM_ESTUDIANTES</code>.</li> <li>STG <code>STG_FACT_AFILIACIONES</code>.</li> </ul> </li> <li> <p>Se relaciona temporalmente con <code>DIM_TIEMPO_MENSUAL</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-principal_1","title":"Script SQL Principal","text":"<pre><code>WITH SubsidiosCedesarrollo AS (\nSELECT [ANIO_TARIFA]\n      ,COD_CATEGORIA AS ID_CATEGORIA\n      ,max([COS_UNITARIO_CONCEPTO]) as COSTO_UNITARIO\n      ,MAX([VAL_TARIFA]) VALOR_TARIFA\n      ,max([COS_UNITARIO_CONCEPTO]) - MAX([VAL_TARIFA])  AS SUBSIDIO\n  FROM [DWH_COMFENALCO].[Transversal].[DIM_TARIFAS_SERVICIOS]\n  WHERE COD_INFRAESTRUCTURA_CCF = 'CCF008-13-00001' AND COD_CATEGORIA IN (1,2) AND ANIO_TARIFA != 2022\n  GROUP BY [ANIO_TARIFA], COD_CATEGORIA\n  ),\nFacturacion as (\nSELECT \n    -1 as ID_PROGRAMA,\n    LEFT([ID_FECHA],6) * 100 + 1 as ID_FECHA,\n    [ESTADO_PAGO] as ESTADO,\n    COALESCE( [CONCEPTO] , 'INDEFINIDO')  as DESCRIPCION,\n    'FACTURACION' as ACTIVIDAD,\n    ISNULL(\n     CASE \n        WHEN de.PARTNER &lt;&gt; '0000000000' THEN de.PARTNER \n        ELSE CASE \n            WHEN da.PARTNER &lt;&gt; '0000000000' THEN da.PARTNER \n            ELSE CASE \n                WHEN db.PARTNER &lt;&gt; '0000000000' THEN db.PARTNER \n                ELSE daa.PARTNER \n                END \n            END \n        END,'0000000000') as [PARTNER],\n    CASE\n            WHEN LEN(NO_RECIBO) &lt; 6 THEN 2\n            ELSE 3\n        END AS ID_UNIDAD,\n        COALESCE(ID_TARIFA, -1) as ID_TARIFA,\n        ISNULL(SUBSIDIO,0) AS SUBSIDIO,\n        COALESCE(dest.ID_EMPRESA, -1) as ID_EMPRESA,\n    COALESCE(dest.ID_AFILIADO, -1) as ID_AFILIADO,\n     COALESCE(dest.ID_BENEFICIARIO, -1) as ID_BENEFICIARIO,\n     COALESCE(dest.ID_APORTANTE, -1) as ID_APORTANTE,\n     COALESCE(dest.ID_ESTUDIANTE, -1) as  ID_ESTUDIANTE,\n     '[DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION]' as [FUENTE_PRINCIPAL]\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n\n  LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] da\n  ON ff.[TIPO_DOCUMENTO_PAGO] = da.[COD_TIPO_DOCUMENTO]\n  AND ff.[DOCUMENTO_PAGO] = da.[NUMERO_DOCUMENTO]\n  LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] db\n   ON ff.[TIPO_DOCUMENTO_PAGO] = db.[COD_TIPO_DOCUMENTO]\n  AND ff.[DOCUMENTO_PAGO] = db.[NUMERO_DOCUMENTO]\n  LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] de\n   ON ff.[TIPO_DOCUMENTO_PAGO] = de.[COD_TIPO_DOCUMENTO]\n  AND ff.[DOCUMENTO_PAGO] = de.[DOCUMENTO]\n  LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] daa\n   ON ff.[TIPO_DOCUMENTO_PAGO] = daa.[COD_TIPO_DOCUMENTO]\n  AND ff.[DOCUMENTO_PAGO] = daa.[DOCUMENTO]\n  LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] dest \n  ON ff.[TIPO_DOCUMENTO_PAGO] = dest .[TIPO_DOCUMENTO]\n  AND ff.[DOCUMENTO_PAGO] = dest .[DOCUMENTO] \n   INNER JOIN (select ID_FECHA as ID_FECHA2  from  [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] ) dimM\n ON ff.ID_FECHA = dimM.ID_FECHA2)\n,\n  partnerTable  as (\nSELECT \n    PARTNER,\n    ID_FECHA,\n    MAX([PARTNER_AFILIADO]) AS PARTNER_AFILIADO,\n    MAX([PARTNER_EMPRESA]) AS PARTNER_EMPRESA,\n    MIN([ID_CATEGORIA]) AS ID_CATEGORIA,\n    MAX([ID_GENERO]) AS ID_GENERO,\n    MAX([FECHA_NACIMIENTO]) AS FECHA_NACIMIENTO,\n    MAX([EDAD]) AS EDAD,\n    MAX([DISCAPACIDAD]) AS DISCAPACIDAD\nFROM [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES]\nWHERE ACTIVIDAD = 'AFILIACION'\nGROUP BY PARTNER, ID_FECHA\n\n  )\n  select  \n        c.ID_PROGRAMA,\n        c.ID_FECHA,\n        c.ESTADO,\n        c.DESCRIPCION,\n        c.ACTIVIDAD,\n        c.[PARTNER],\n        c.ID_UNIDAD,\n        c.ID_TARIFA,\n        --c.SUBSIDIO,\n        CASE\n            WHEN c.SUBSIDIO = 0 AND pt.ID_CATEGORIA IN (1,2)\n                AND DESCRIPCION LIKE '%PROG%' AND DESCRIPCION NOT LIKE '%CREDITO%' THEN SC.SUBSIDIO\n            ELSE 0\n        END AS SUBSIDIO,\n        c.ID_EMPRESA,\n        c.ID_AFILIADO,\n        c.ID_BENEFICIARIO,\n        c.ID_APORTANTE,\n        c.ID_ESTUDIANTE,\n        c.[FUENTE_PRINCIPAL],\n        COALESCE(pt.[PARTNER_AFILIADO], '0000000000') as PARTNER_AFILIADO,\n        COALESCE(pt.[PARTNER_EMPRESA] , '0000000000') as PARTNER_EMPRESA,\n        COALESCE(pt.[ID_CATEGORIA] , 4) as ID_CATEGORIA,\n        COALESCE(pt.[ID_GENERO] , -1) as ID_GENERO,\n        pt.[FECHA_NACIMIENTO], \n        COALESCE(pt.[EDAD] , -1) as EDAD,\n        COALESCE(pt.DISCAPACIDAD, 2) AS DISCAPACIDAD\n        ,'SI' AS POBLACION_EDUCACION\n        ,CASE \n            WHEN c.ID_UNIDAD = 1 THEN 'SI'\n            ELSE 'NO'\n        END AS POBLACION_EDUCACION_FORMAL,\n        CASE \n            WHEN c.ID_UNIDAD = 2 THEN 'SI'\n            ELSE 'NO'\n        END AS POBLACION_EDUCACION_TECNICA,\n        CASE \n            WHEN c.ID_UNIDAD = 3 THEN 'SI'\n            ELSE 'NO'\n        END AS POBLACION_EDUCACION_CONTINUA,\n        CASE \n            WHEN c.ID_UNIDAD = 4 THEN 'SI'\n            ELSE 'NO'\n        END AS POBLACION_EDUCACION_PROTECCION \n  from  Facturacion c\n  LEFT JOIN  partnerTable pt\n  ON c.[PARTNER] = pt.[PARTNER]\n  AND c.ID_FECHA = pt.ID_FECHA\n  LEFT JOIN SubsidiosCedesarrollo sc ON LEFT(c.ID_FECHA,4) = sc.ANIO_TARIFA AND pt.ID_CATEGORIA = sc.ID_CATEGORIA\n</code></pre>"},{"location":"03.Cubo/03.ETL/#actividades-colegiofact_actividades_colegio","title":"Actividades Colegio\\FACT_ACTIVIDADES_COLEGIO","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general-del-componente_2","title":"Descripci\u00f3n General del Componente","text":"<p>Este flujo de datos realiza la consolidaci\u00f3n de m\u00faltiples fuentes relacionadas con actividades acad\u00e9micas y de apoyo en el entorno escolar, tales como matr\u00edculas, facturaci\u00f3n, transporte, biblioteca, enfermer\u00eda, retiros y psicorientaci\u00f3n. A trav\u00e9s de una l\u00f3gica unificada y enriquecimiento con dimensiones transversales, se genera una vista consolidada de actividades por a\u00f1o acad\u00e9mico, beneficiario y tipo de servicio, para cargarla en la tabla <code>FACT_ACTIVIDADES</code> del DWH.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-del-paquete_1","title":"Ubicaci\u00f3n del Paquete","text":"<p><code>Package\\FACT_ACTIVIDADES\\Actividades Colegio\\FACT_ACTIVIDADES_COLEGIO</code></p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_1","title":"Prop\u00f3sito del Componente","text":"<p>Integrar diferentes hechos escolares provenientes de m\u00faltiples fuentes del dominio educativo, enriqueciendo cada registro con afiliaciones, caracter\u00edsticas poblacionales y categorizaciones transversales. Esta integraci\u00f3n proporciona una vista consolidada de la experiencia educativa de los beneficiarios, facilitando an\u00e1lisis institucionales y caracterizaci\u00f3n poblacional.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_12","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen de datos:</p> <ul> <li><code>FACT_INSCRIPCION_MATRICULAS</code></li> <li><code>FACT_RESULTADOS</code></li> <li><code>FACT_TRANSPORTE</code></li> <li><code>FACT_FACTURACION_MATRICULAS</code></li> <li><code>FACT_BIBLIOTECA</code></li> <li><code>FACT_BIBLIOTECA_VIRTUAL</code></li> <li><code>FACT_ENFERMERIA</code></li> <li><code>FACT_RETIROS</code></li> <li><code>FACT_PSICORIENTACION</code></li> </ul> </li> <li> <p>Transformaciones aplicadas:</p> <ul> <li>Uni\u00f3n y estandarizaci\u00f3n de todos los hechos bajo una estructura com\u00fan.</li> <li>C\u00e1lculo de fecha acad\u00e9mica (<code>ANIO_ACADEMICO</code>) y normalizaci\u00f3n de <code>ID_FECHA</code>.</li> <li>Enriquecimiento con datos del beneficiario desde <code>DIM_BENEFICIARIOS</code>.</li> <li>Incorporaci\u00f3n de caracter\u00edsticas poblacionales desde <code>STG_FACT_AFILIACIONES</code>.</li> <li>Clasificaci\u00f3n de registros por unidad acad\u00e9mica (formal, t\u00e9cnica, continua, protecci\u00f3n).</li> </ul> </li> <li> <p>Carga final:</p> <ul> <li>Se aplica l\u00f3gica <code>CASE</code> para generar banderas de clasificaci\u00f3n (<code>POBLACION_EDUCACION_TECNICA</code>, <code>POBLACION_EDUCACION_FORMAL</code>, etc.).</li> <li>Uni\u00f3n con <code>DIM_TIEMPO_MENSUAL</code> asegura trazabilidad temporal estructurada.</li> <li>La informaci\u00f3n es enviada al destino final <code>FACT_ACTIVIDADES</code>.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_10","title":"L\u00f3gica de Negocio","text":"<ul> <li>Consolidar en un \u00fanico conjunto de datos las distintas actividades realizadas por los estudiantes durante el a\u00f1o acad\u00e9mico.</li> <li>Estandarizar columnas comunes como <code>PARTNER</code>, <code>ID_FECHA</code>, <code>ACTIVIDAD</code>, <code>VALOR_FACTURADO</code>, <code>ADEUDA</code>, <code>SERVICIO_TRANSPORTE</code>.</li> <li>Utilizar la dimensi\u00f3n de tiempo para garantizar granularidad mensual.</li> <li>Clasificar registros por unidad para uso en dashboards segmentados (formal, t\u00e9cnica, continua).</li> <li>Asegurar integridad referencial mediante <code>LEFT JOIN</code> con dimensiones de beneficiarios y afiliaciones.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_11","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Dependencias:</p> <ul> <li>Tablas fuente del dominio <code>Colegio</code> en el DWH.</li> <li>Dimensiones transversales: <code>DIM_BENEFICIARIOS</code>, <code>STG_FACT_AFILIACIONES</code>, <code>DIM_TIEMPO_MENSUAL</code>.</li> </ul> </li> <li> <p>Destino:</p> <ul> <li>Tabla consolidada <code>FACT_ACTIVIDADES</code> que representa el principal insumo para visualizaciones y an\u00e1lisis educativos.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-principal-fragmento-representativo","title":"Script SQL Principal (Fragmento Representativo)","text":"<pre><code>WITH consulta AS (\n  SELECT ... FROM FACT_INSCRIPCION_MATRICULAS\n  UNION\n  SELECT ... FROM FACT_RESULTADOS\n  UNION\n  SELECT ... FROM FACT_TRANSPORTE\n  UNION\n  SELECT ... FROM FACT_FACTURACION_MATRICULAS\n  UNION\n  SELECT ... FROM FACT_BIBLIOTECA\n  UNION\n  SELECT ... FROM FACT_BIBLIOTECA_VIRTUAL\n  UNION\n  SELECT ... FROM FACT_ENFERMERIA\n  UNION\n  SELECT ... FROM FACT_RETIROS\n  UNION\n  SELECT ... FROM FACT_PSICORIENTACION\n),\npartnerTable AS (\n  SELECT PARTNER, ID_FECHA, MAX(PARTNER_AFILIADO) AS PARTNER_AFILIADO, ...\n  FROM STG_FACT_AFILIACIONES\n  WHERE ACTIVIDAD = 'AFILIACION'\n  GROUP BY PARTNER, ID_FECHA\n)\nSELECT c.*, \n       COALESCE(pt.PARTNER_AFILIADO, '0000000000') AS PARTNER_AFILIADO,\n       COALESCE(pt.ID_CATEGORIA, 4) AS ID_CATEGORIA,\n       ...\n       CASE WHEN c.ID_UNIDAD = 1 THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_FORMAL,\n       ...\nFROM consulta c\nLEFT JOIN partnerTable pt ON c.PARTNER = pt.PARTNER AND c.ID_FECHA = pt.ID_FECHA;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#actividades-colegiomatricula-mensual-colegio","title":"Actividades Colegio\\Matricula Mensual Colegio","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>Este componente del paquete SSIS se encarga de consolidar la informaci\u00f3n mensual de matr\u00edculas aprobadas en colegios, combinando datos de matriculaci\u00f3n acad\u00e9mica con atributos de afiliaci\u00f3n del beneficiario. Los resultados se cargan en la tabla de hechos <code>FACT_ACTIVIDADES</code>, permitiendo su posterior an\u00e1lisis multidimensional en el Data Warehouse institucional.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-del-paquete_2","title":"Ubicaci\u00f3n del Paquete","text":"<p><code>Package\\FACT_ACTIVIDADES\\Actividades Colegio\\Matricula Mensual Colegio</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_11","title":"Prop\u00f3sito","text":"<p>Transformar registros de matr\u00edcula aprobada de educaci\u00f3n formal provenientes de la tabla <code>FACT_ESTADO_MATRICULAS</code>, enriquecerlos con atributos demogr\u00e1ficos y afiliativos, y normalizar fechas en formato mensual. El componente genera un set de datos depurado para seguimiento mensual de poblaci\u00f3n escolar beneficiaria.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_13","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Origen de datos: ADO.NET con query compleja basada en CTEs sobre <code>DWH_COMFENALCO.Colegio.FACT_ESTADO_MATRICULAS</code>.</li> <li> <p>Transformaciones:</p> <ul> <li>Conversi\u00f3n de fecha de pago en <code>ID_FECHA_MENSUAL</code>.</li> <li>Uniones con <code>DIM_BENEFICIARIOS</code> y <code>STG_FACT_AFILIACIONES</code>.</li> <li>Etiquetado de tipo de poblaci\u00f3n educativa por unidad.</li> </ul> </li> <li> <p>Destino: ADO.NET hacia <code>DWH_COMFENALCO.Transversal.FACT_ACTIVIDADES</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_11","title":"L\u00f3gica de Negocio","text":"<ul> <li>Filtra matr\u00edculas aprobadas (<code>CA20_ESTADO_MATRICULA = 'APROBADA'</code>).</li> <li>Excluye registros con fechas de pago no v\u00e1lidas (<code>CA20_FECHA_PAGO != '00000000'</code>).</li> <li>Crea una dimensi\u00f3n de fechas mensuales (enero a diciembre).</li> <li>Clasifica la actividad como <code>ESTADO_MATRICULAS</code>.</li> <li>Enlaza cada matr\u00edcula con datos afiliativos y demogr\u00e1ficos del beneficiario.</li> <li>Asegura consistencia temporal con la tabla <code>DIM_TIEMPO_MENSUAL</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_12","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Reutiliza estructuras comunes con otros componentes del paquete <code>FACT_ACTIVIDADES</code> como:</p> <ul> <li><code>Matricula Mensual Educacion Tecnica</code></li> <li><code>FACT_ESTADO_MATRICULAS</code> como fuente primaria</li> <li><code>STG_FACT_AFILIACIONES</code> y <code>DIM_BENEFICIARIOS</code> como enriquecimiento transversal</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-principal_2","title":"Script SQL Principal","text":"<pre><code>WITH EstadoMatriculasColegio AS (\n    SELECT  \n        1 AS ID_UNIDAD, [ID_GRADO], [CA20_ANO_ACADEMICO] AS ANIO_ACADEMICO,\n        [CA20_BP_ESTUDIANTE] AS PARTNER, COALESCE(db.ID_BENEFICIARIO, -1) AS ID_BENEFICIARIO,\n        [CA20_ESTADO_MATRICULA] AS ESTADO, [CA20_ESTADO_PAGO] AS ESTADO_PAGO,\n        CASE \n            WHEN [CA20_FECHA_PAGO] = 00000000 THEN [CA20_FECHA_PAGO]\n            WHEN CAST(LEFT([CA20_FECHA_PAGO], 4) AS INT) &lt; [CA20_ANO_ACADEMICO]\n                THEN [CA20_ANO_ACADEMICO] * 10000 + 101\n            ELSE LEFT([CA20_FECHA_PAGO], 6) * 100 + 1 \n        END AS ID_FECHA_MENSUAL,\n        [CA20_FECHA_PAGO], CA20_CURSO AS ID_CURSO, \n        'ESTADO_MATRICULAS' AS ACTIVIDAD,\n        '[DWH_COMFENALCO].[Colegio].[FACT_ESTADO_MATRICULAS]' AS FUENTE_PRINCIPAL\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_ESTADO_MATRICULAS] em\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] db\n        ON em.[CA20_BP_ESTUDIANTE] = db.[PARTNER]\n    WHERE [CA20_ESTADO_MATRICULA] = 'APROBADA' AND CA20_FECHA_PAGO != '00000000'\n),\n...\nSELECT cm.* FROM EstadoMatriculasColegioMensual cm\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM ON cm.ID_FECHA = dimM.ID_FECHA;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#almacenar-max-actividades","title":"Almacenar MAX ACTIVIDADES","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>Este componente es una tarea de ejecuci\u00f3n SQL (<code>Execute SQL Task</code>) cuyo prop\u00f3sito es calcular la cantidad total de iteraciones mensuales requeridas para procesar los datos de afiliaciones, determinando as\u00ed el mes m\u00e1s reciente disponible en el tiempo dimensional.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_10","title":"Ubicaci\u00f3n en el Paquete","text":"<p>Se encuentra dentro del paquete SSIS <code>FACT_ACTIVIDADES</code>, bajo la ruta l\u00f3gica <code>Package\\FACT_ACTIVIDADES\\Almacenar MAX ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#proposito_12","title":"Prop\u00f3sito","text":"<p>Obtener el n\u00famero de iteraciones necesarias para recorrer todos los meses disponibles en la tabla <code>STG_FACT_AFILIACIONES</code>, validando que los datos coincidan con el calendario definido en la tabla <code>DIM_TIEMPO_MENSUAL</code>. Este resultado se almacena en una variable de usuario para control del flujo posterior.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_14","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Tipo de tarea: <code>Execute SQL Task</code></li> <li>Conexi\u00f3n usada: <code>{29BC876E-1EAF-4F6F-8F38-39B8E881EEB6}</code> (probablemente conexi\u00f3n a <code>STAGE_AREA</code> o <code>DWH_COMFENALCO</code>)</li> <li>Variable de salida: <code>User::MaxIterationApor</code></li> <li>Tipo de resultado: Fila \u00fanica (Single Row)</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_12","title":"L\u00f3gica de Negocio","text":"<ol> <li>Se declaran dos variables locales <code>@MinID_FECHA</code> y <code>@MaxID_FECHA</code> que almacenan el primer y \u00faltimo mes v\u00e1lido de la tabla de afiliaciones (<code>STG_FACT_AFILIACIONES</code>), considerando solamente los registros que tengan correspondencia en la tabla de fechas <code>DIM_TIEMPO_MENSUAL</code>.</li> <li>Se calcula la diferencia en meses entre ambas fechas usando <code>DATEDIFF(MONTH, ...)</code>.</li> <li>A este valor se le suma 1 para incluir el mes actual en la iteraci\u00f3n (<code>@DiffMonths + 1</code>).</li> <li>El resultado (<code>@VarTime</code>) se almacena como salida de la consulta en la variable <code>User::MaxIterationApor</code>.</li> </ol>"},{"location":"03.Cubo/03.ETL/#script-sql-utilizado","title":"Script SQL Utilizado","text":"<pre><code>DECLARE @MinID_FECHA VARCHAR(8);\nDECLARE @MaxID_FECHA VARCHAR(8);\n\n-- Obtener el mes m\u00ednimo de ID_FECHA\nSELECT \n    @MinID_FECHA = MIN(LEFT(CONVERT(VARCHAR(8), a.[ID_FECHA], 112), 6) + '01')\nFROM \n    [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES] a\nINNER JOIN \n    [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t\n    ON LEFT(CONVERT(VARCHAR(8), a.[ID_FECHA], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112);\n\n-- Obtener el mes m\u00e1ximo de ID_FECHA\nSELECT \n    @MaxID_FECHA = MAX(LEFT(CONVERT(VARCHAR(8), a.[ID_FECHA], 112), 6) + '01')\nFROM \n    [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES] a\nINNER JOIN \n    [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t\n    ON LEFT(CONVERT(VARCHAR(8), a.[ID_FECHA], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112);\n\n-- Calcular la diferencia en meses entre el mes m\u00ednimo y el mes m\u00e1ximo\nDECLARE @DiffMonths INT;\n\nSELECT \n    @DiffMonths = DATEDIFF(MONTH, \n        CONVERT(DATE, LEFT(@MinID_FECHA, 6) + '01'), \n        CONVERT(DATE, LEFT(@MaxID_FECHA, 6) + '01'));\n\n-- El valor entero que debes poner en la variable @VarTime para obtener el \u00faltimo mes\nDECLARE @VarTime INT = @DiffMonths + 1;\n\n-- Resultado\nSELECT ISNULL(@VarTime, 1) AS VarTimeParaMaxMes;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#contenedor-de-bucles-para-actividadesactividad-afiliacion","title":"Contenedor de bucles para Actividades\\Actividad Afiliacion","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>Este componente es una tarea de flujo de datos que tiene como objetivo cargar informaci\u00f3n transformada relacionada con actividades afiliadas en la tabla <code>FACT_ACTIVIDADES</code>, la cual forma parte del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p><code>FACT_ACTIVIDADES &gt; Contenedor de bucles para Actividades &gt; Actividad Afiliacion</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_13","title":"Prop\u00f3sito","text":"<p>Almacenar en el Data Warehouse informaci\u00f3n detallada sobre afiliaciones y actividades realizadas por beneficiarios en distintos programas o servicios, permitiendo su an\u00e1lisis desde m\u00faltiples dimensiones como g\u00e9nero, curso, estrato, programa, tipo de afiliaci\u00f3n, entre otros.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_15","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Tipo de tarea: <code>Data Flow Task</code></li> <li>Destino: Tabla <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code> v\u00eda componente <code>ADO NET Destination</code></li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code></li> <li>Modo de inserci\u00f3n: Uso de <code>SqlBulkCopy</code> activado para mayor rendimiento</li> <li>Timeout del comando: 30 segundos</li> <li>Batch Size: 0 (usa el buffer predeterminado de SSIS)</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_13","title":"L\u00f3gica de Negocio","text":"<ol> <li>Se reciben los datos desde una fuente OLE DB (no incluida en este extracto).</li> <li>Se procesan columnas correspondientes a atributos de afiliaci\u00f3n, actividad, contexto educativo, condiciones socioecon\u00f3micas, demograf\u00eda, y gesti\u00f3n.</li> <li>Se realiza una carga directa de los datos transformados a <code>FACT_ACTIVIDADES</code> manteniendo alineaci\u00f3n con las columnas definidas en el metadata externo.</li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_13","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Este flujo se encuentra dentro de un contenedor iterativo que probablemente procese m\u00faltiples actividades por lote.</li> <li>Se alimenta de una fuente OLE DB definida en el mismo flujo de datos.</li> <li>Est\u00e1 acoplado al componente de carga del Data Warehouse de Comfenalco para el dominio de actividades.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql_4","title":"Script SQL","text":"<pre><code>DECLARE @MinMes VARCHAR(8); -- Cambiado a VARCHAR para manejar unicode\n\nSELECT \n    @MinMes = MIN(LEFT(CONVERT(VARCHAR(8), a.[ID_FECHA], 112), 6) + '01') -- Uso de VARCHAR aqu\u00ed\nFROM \n    [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES] a\nINNER JOIN \n    [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t\n    ON LEFT(CONVERT(VARCHAR(8), a.[ID_FECHA], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112); -- Conversi\u00f3n a VARCHAR\n\n-- Paso 2: Declarar la variable para determinar el mes\nDECLARE @VarTime INT = ?; -- Ajusta este valor seg\u00fan la iteraci\u00f3n que quieras filtrar\n\n-- Calcular el mes a filtrar basado en @VarTime\nDECLARE @MesFiltrado VARCHAR(8) = FORMAT(DATEADD(MONTH, @VarTime - 1, CONVERT(DATE, @MinMes)), 'yyyyMM') + '01'; -- Ajustado a VARCHAR\n\n-- Consultas posteriores\nWITH ActividadesPoblacionPartner AS (\n    SELECT \n        CONVERT(VARCHAR, ID_FECHA, 112) AS ID_FECHA,\n        CONVERT(VARCHAR, PARTNER) AS PARTNER,\n        CASE WHEN MAX(POBLACION_EDUCACION) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION,\n        CASE WHEN MAX(POBLACION_EDUCACION_FORMAL) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_FORMAL,\n        CASE WHEN MAX(POBLACION_EDUCACION_TECNICA) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_TECNICA,\n        CASE WHEN MAX(POBLACION_EDUCACION_CONTINUA) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_CONTINUA,\n        CASE WHEN MAX(POBLACION_EDUCACION_PROTECCION) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_PROTECCION\n    FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n    GROUP BY CONVERT(VARCHAR, ID_FECHA, 112), CONVERT(VARCHAR, PARTNER)\n),\nActividadesPoblacionAgrupadoAfiliado AS (\n    SELECT \n        CONVERT(VARCHAR, ID_FECHA, 112) AS ID_FECHA,\n        CONVERT(VARCHAR, PARTNER_AFILIADO) AS PARTNER,\n        CASE WHEN MAX(POBLACION_EDUCACION) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION,\n        CASE WHEN MAX(POBLACION_EDUCACION_FORMAL) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_FORMAL,\n        CASE WHEN MAX(POBLACION_EDUCACION_TECNICA) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_TECNICA,\n        CASE WHEN MAX(POBLACION_EDUCACION_CONTINUA) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_CONTINUA,\n        CASE WHEN MAX(POBLACION_EDUCACION_PROTECCION) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_PROTECCION\n    FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n    GROUP BY CONVERT(VARCHAR, ID_FECHA, 112), CONVERT(VARCHAR, PARTNER_AFILIADO)\n),\nActividadesPoblacionAgrupadoEmpresa AS (\n    SELECT \n        CONVERT(VARCHAR, ID_FECHA, 112) AS ID_FECHA,\n        CONVERT(VARCHAR, PARTNER_EMPRESA) AS PARTNER,\n        CASE WHEN MAX(POBLACION_EDUCACION) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION,\n        CASE WHEN MAX(POBLACION_EDUCACION_FORMAL) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_FORMAL,\n        CASE WHEN MAX(POBLACION_EDUCACION_TECNICA) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_TECNICA,\n        CASE WHEN MAX(POBLACION_EDUCACION_CONTINUA) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_CONTINUA,\n        CASE WHEN MAX(POBLACION_EDUCACION_PROTECCION) = 'SI' THEN 'SI' ELSE 'NO' END AS POBLACION_EDUCACION_PROTECCION\n    FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n    GROUP BY CONVERT(VARCHAR, ID_FECHA, 112), CONVERT(VARCHAR, PARTNER_EMPRESA)\n),\nConsolidadoActividades AS (\n    SELECT ID_FECHA, PARTNER, \n           POBLACION_EDUCACION, \n           POBLACION_EDUCACION_FORMAL, \n           POBLACION_EDUCACION_TECNICA, \n           POBLACION_EDUCACION_CONTINUA, \n           POBLACION_EDUCACION_PROTECCION\n    FROM ActividadesPoblacionPartner\n    UNION\n    SELECT ID_FECHA, PARTNER, \n           POBLACION_EDUCACION, \n           POBLACION_EDUCACION_FORMAL, \n           POBLACION_EDUCACION_TECNICA, \n           POBLACION_EDUCACION_CONTINUA, \n           POBLACION_EDUCACION_PROTECCION\n    FROM ActividadesPoblacionAgrupadoAfiliado\n    UNION\n    SELECT ID_FECHA, PARTNER, \n           POBLACION_EDUCACION, \n           POBLACION_EDUCACION_FORMAL, \n           POBLACION_EDUCACION_TECNICA, \n           POBLACION_EDUCACION_CONTINUA, \n           POBLACION_EDUCACION_PROTECCION\n    FROM ActividadesPoblacionAgrupadoEmpresa\n),\nActividadesPoblacion AS (\nSELECT ID_FECHA, PARTNER,\n       MAX(POBLACION_EDUCACION) AS POBLACION_EDUCACION,\n       MAX(POBLACION_EDUCACION_FORMAL) AS POBLACION_EDUCACION_FORMAL,\n       MAX(POBLACION_EDUCACION_TECNICA) AS POBLACION_EDUCACION_TECNICA,\n       MAX(POBLACION_EDUCACION_CONTINUA) AS POBLACION_EDUCACION_CONTINUA,\n       MAX(POBLACION_EDUCACION_PROTECCION) AS POBLACION_EDUCACION_PROTECCION\nFROM ConsolidadoActividades\nGROUP BY ID_FECHA, PARTNER),\nAfiliaciones AS (\n    SELECT \n        CONVERT(VARCHAR(255),[ACTIVIDAD]) AS [ACTIVIDAD]\n      ,[ADEUDA]\n      ,[ANIO_ACADEMICO]\n      ,[CANTIDAD_MATERIAL]\n      ,[CALIFICACION]\n      ,[CAUSA]\n      ,[CATEGORIA_VENTA]\n      ,[COSTO]\n      ,[CURSO]\n      ,[DESCRIPCION]\n      ,[ESTADO]\n      ,[ESTADOREGISTRO]\n      ,[ESTADO_PAGO]\n      ,[ESTRATO]\n      ,[DISCAPACIDAD]\n      ,[EDAD]\n      ,[FECHA_NACIMIENTO]\n      ,[FECHA_AFILIACION]\n      ,[FECHA_MENSUAL]\n      ,[FECHA_RETIRO]\n      ,[FECHA_ADMISION]\n      ,[ID_AFILIADO]\n      ,[ID_CATEGORIA]\n      ,[ID_CIUDAD]\n      ,[ID_CONCEPTO]\n      ,[ID_CURSO]\n      ,[ID_EMPRESA]\n      ,[ID_ESTADO_CIVIL]\n      ,[ID_ESTADO_GESTION]\n      ,[ID_FACTOR_VULNERABILIDAD]\n      ,[ID_FECHA]\n      ,[ID_GENERO]\n      ,[ID_GRADO]\n      ,[ID_MATERIAL]\n      ,[ID_PERTENENCIA_ETNICA]\n      ,[ID_POBLACION]\n      ,[ID_PROGRAMA]\n      ,[ID_PREGUNTA]\n      ,[ID_TIPO_AFILIADO]\n      ,[ID_UNIDAD]\n      ,[NO_PRESTAMOS]\n      ,[NUMERO_APORTES]\n      --,[PARTNER]\n      ,[PARTNER_AFILIADO]\n      ,[PARTNER_EMPRESA]\n      ,[RESPUESTA]\n      ,[SALARIO_BASICO]\n      ,[SERVICIO_TRANSPORTE]\n      ,[SUBSIDIO]\n      ,[TIPO_AFILIADO]\n      ,[TIPO_POBLACION]\n      ,[TOTAL_APORTES]\n      ,[VALOR_FACTURADO]\n      ,[VALOR_MATERIAL]\n      ,[VALOR_PAGADO]\n      ,[VALOR_PAGADO_SIN_IMP]\n      ,CONVERT(VARCHAR(255),[FUENTE_PRINCIPAL]) as FUENTE_PRINCIPAL\n      ,[ID_PQR]\n      ,[ESTADO_PQR]\n      ,[ID_BENEFICIARIO]\n      ,[CAUSA_PQR]\n      ,[TIPO_PQRS]\n      ,[ID_TARIFA]\n        -- Otras columnas necesarias\n        --,CONVERT(VARCHAR, ID_FECHA, 112) AS ID_FECHA, -- Conversi\u00f3n expl\u00edcita\n        ,CONVERT(VARCHAR(50), PARTNER) AS PARTNER        -- Conversi\u00f3n expl\u00edcita\n    FROM [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES]\n    WHERE CONVERT(VARCHAR, ID_FECHA, 112) = @MesFiltrado -- Conversi\u00f3n expl\u00edcita\n)\nSELECT \n    fa.*,\n    CONVERT(VARCHAR(50),COALESCE(ap.POBLACION_EDUCACION, 'NO')) AS POBLACION_EDUCACION,\n    COALESCE(ap.POBLACION_EDUCACION_FORMAL, 'NO') AS POBLACION_EDUCACION_FORMAL,\n    COALESCE(ap.POBLACION_EDUCACION_TECNICA, 'NO') AS POBLACION_EDUCACION_TECNICA,\n    COALESCE(ap.POBLACION_EDUCACION_CONTINUA, 'NO') AS POBLACION_EDUCACION_CONTINUA,\n    COALESCE(ap.POBLACION_EDUCACION_PROTECCION, 'NO') AS POBLACION_EDUCACION_PROTECCION\nFROM Afiliaciones fa\nLEFT JOIN ActividadesPoblacion ap\n    ON fa.ID_FECHA = ap.ID_FECHA \n   AND fa.PARTNER = ap.PARTNER; -- Comparaci\u00f3n compatible\n</code></pre>"},{"location":"03.Cubo/03.ETL/#almacenar-max-aportes","title":"Almacenar MAX Aportes","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>Este componente es una tarea de ejecuci\u00f3n SQL (<code>Execute SQL Task</code>) utilizada para calcular din\u00e1micamente el n\u00famero de periodos mensuales disponibles en la tabla de hechos de aportes. El resultado se almacena en una variable de usuario que controla iteraciones posteriores de procesamiento.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete_1","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p><code>FACT_ACTIVIDADES &gt; Almacenar MAX Aportes</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_14","title":"Prop\u00f3sito","text":"<p>Calcular la diferencia en meses entre la primera y la \u00faltima fecha contable registrada en la tabla <code>[Aportes].[FACT_APORTES_SHR_DET]</code>, considerando \u00fanicamente aquellas fechas que tienen correspondencia v\u00e1lida en la dimensi\u00f3n de tiempo mensual. El resultado se almacena en la variable <code>User::MaxIterationApor</code>, que ser\u00e1 utilizada para definir el n\u00famero de iteraciones o ciclos de procesamiento en componentes posteriores del paquete.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_16","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Tipo de tarea: <code>Execute SQL Task</code></li> <li>Conexi\u00f3n: <code>{29BC876E-1EAF-4F6F-8F38-39B8E881EEB6}</code> \u2192 Conexi\u00f3n al servidor <code>DWH_COMFENALCO</code></li> <li>Tipo de resultado: <code>ResultSetType_SingleRow</code></li> <li>Variable de destino: <code>User::MaxIterationApor</code></li> <li>Script ejecutado:</li> </ul> <pre><code>DECLARE @MinID_FECHA VARCHAR(8);\nDECLARE @MaxID_FECHA VARCHAR(8);\n\n-- Obtener el mes m\u00ednimo de FECHA_CONTABLE\nSELECT \n    @MinID_FECHA = MIN(LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01')\nFROM \n    [DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET] a\nINNER JOIN \n    [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t\n    ON LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112);\n\n-- Obtener el mes m\u00e1ximo de FECHA_CONTABLE\nSELECT \n    @MaxID_FECHA = MAX(LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01')\nFROM \n    [DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET] a\nINNER JOIN \n    [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t\n    ON LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112);\n\n-- Calcular diferencia en meses\nDECLARE @DiffMonths INT;\nSELECT \n    @DiffMonths = DATEDIFF(MONTH, \n        CONVERT(DATE, LEFT(@MinID_FECHA, 6) + '01'), \n        CONVERT(DATE, LEFT(@MaxID_FECHA, 6) + '01'));\n\n-- Resultado ajustado\nDECLARE @VarTime INT = @DiffMonths + 1;\nSELECT @VarTime AS VarTimeParaMaxMes;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_14","title":"L\u00f3gica de Negocio","text":"<p>El objetivo de esta tarea es preparar la variable <code>User::MaxIterationApor</code> con un valor din\u00e1mico que representa la cantidad de meses a procesar en iteraciones posteriores. Esta l\u00f3gica es \u00fatil en escenarios de ejecuci\u00f3n mensual o incremental, asegurando que se abarquen todos los periodos registrados en la fuente.</p>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_14","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Esta tarea es un paso previo necesario para contenedores de tipo bucle <code>For Loop</code> u otros componentes iterativos dentro del mismo paquete.</li> <li>Tiene relaci\u00f3n directa con la estructura temporal <code>DIM_TIEMPO_MENSUAL</code>, asegurando la validez del rango de fechas contables procesadas.</li> </ul>"},{"location":"03.Cubo/03.ETL/#contenedor-de-bucles-for-1-1aportes-totales","title":"Contenedor de bucles For 1 1\\Aportes Totales","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>Este componente SSIS es un Data Flow Task que consolida y transforma los aportes mensuales de los afiliados a partir de la tabla <code>FACT_APORTES_SHR_DET</code>. Posteriormente, los enriquece con informaci\u00f3n de afiliaci\u00f3n, categorizaci\u00f3n, poblaci\u00f3n educativa y otras dimensiones clave para cargarlos en la tabla <code>Transversal.FACT_ACTIVIDADES</code> del Data Warehouse.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-del-paquete_3","title":"Ubicaci\u00f3n del Paquete","text":"<p><code>FACT_ACTIVIDADES.dtsx \u2192 Contenedor de bucles For 1 1 \u2192 Aportes Totales</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_15","title":"Prop\u00f3sito","text":"<p>Transformar y centralizar la informaci\u00f3n mensual de aportes del dominio de educaci\u00f3n formal y t\u00e9cnica, asociando caracter\u00edsticas adicionales de los beneficiarios y su entorno educativo, con el fin de consolidar un conjunto de datos para an\u00e1lisis institucional y estrat\u00e9gico.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_17","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Origen de datos: <code>DWH_COMFENALCO.Aportes.FACT_APORTES_SHR_DET</code></li> <li>Tipo de componente origen: OLE DB Source con query parametrizada por variable <code>@VarTime</code></li> <li>Destino: <code>Transversal.FACT_ACTIVIDADES</code> v\u00eda componente ADO.NET Destination</li> <li>Modo de escritura: Bulk Insert habilitado</li> <li>Timeout configurado: 600 segundos</li> <li>Variable de entrada: <code>@VarTime</code> mapeada como par\u00e1metro de iteraci\u00f3n mensual</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_15","title":"L\u00f3gica de Negocio","text":"<ol> <li>Determina el mes m\u00e1s antiguo de aportes (<code>@MinMes</code>) en la tabla fuente.</li> <li>Calcula din\u00e1micamente el mes a filtrar (<code>@MesFiltrado</code>) seg\u00fan el valor iterado en el bucle For.</li> <li>Consolida los aportes por afiliado y empresa agrupados por mes.</li> <li>Enlaza los registros con afiliaciones y poblaci\u00f3n educativa activa en el mismo mes (<code>AfiliadosEducacionMes</code>).</li> <li> <p>Cruza los datos con dimensiones complementarias como:</p> <ul> <li>Tabla <code>STG_FACT_AFILIACIONES</code> para obtener <code>ID_CATEGORIA</code>, <code>ID_GENERO</code>, <code>FECHA_NACIMIENTO</code>, <code>EDAD</code>.</li> <li>Tabla <code>FACT_ACTIVIDADES</code> para campos como <code>POBLACION_EDUCACION_FORMAL</code>, <code>TEC</code>, <code>CONTINUA</code>, <code>PROTECCION</code>.</li> </ul> </li> <li> <p>Se asignan valores por defecto en atributos cuando no hay correspondencias (<code>-1</code> o constantes como <code>5</code> en <code>ID_UNIDAD</code>).</p> </li> <li> <p>Finalmente, se cargan los registros en la tabla de hechos <code>FACT_ACTIVIDADES</code>.</p> </li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_15","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Este flujo depende de las salidas previas del proceso de afiliaciones (<code>AFILIACION</code> como ACTIVIDAD).</li> <li>Su resultado alimenta la vista consolidada de actividades mensuales (<code>FACT_ACTIVIDADES_COLEGIO</code>).</li> <li>Las dimensiones <code>DIM_TIEMPO_MENSUAL</code>, <code>STG_FACT_AFILIACIONES</code>, y <code>FACT_ACTIVIDADES</code> son clave para enriquecer el dataset.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-utilizado_1","title":"Script SQL Utilizado","text":"<pre><code>DECLARE @MinMes VARCHAR(8);\n\n\nSELECT \n    @MinMes = MIN(LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01')\nFROM \n    [DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET] a\nINNER JOIN \n[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t\nON LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112)\n\n\n-- Paso 2: Declarar la variable para determinar el mes\nDECLARE @VarTime INT = ?; -- Ajusta este valor seg\u00fan la iteraci\u00f3n que quieras filtrar\n\n-- Calcular el mes a filtrar basado en @VarTime\nDECLARE @MesFiltrado INT = CONVERT(INT, FORMAT(DATEADD(MONTH, @VarTime - 1, CONVERT(DATE, @MinMes)), 'yyyyMM') + '01');\n\n--SELECT @MesFiltrado AS MinID_FECHA;\n\nWITH Aportes_Total AS (\nSELECT \n    ISNULL(a.[BP_EMPRESA],'0000000000') as 'PARTNER', \n    a.[ID_EMPRESA],\n    a.[ID_AFILIADO],\n    CONVERT(DATE, LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01') AS FECHA_MENSUAL,\n    LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' AS ID_FECHA,\n    SUM(CONVERT(DECIMAL(18, 2), a.[APORTE])) AS TOTAL_APORTES,\n    COUNT(a.[APORTE]) AS NUMERO_APORTES,\n    ISNULL(a.[BP_EMPRESA],'0000000000') AS BP_EMPRESA,\n    a.[BP_AFILIADO],\n    'APORTES' AS ACTIVIDAD\nFROM \n    [DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET] a\nINNER JOIN \n    [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t\n    ON LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112)\nWHERE LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' = @MesFiltrado\nGROUP BY \n    a.[ID_EMPRESA],\n    a.[ID_AFILIADO],\n    LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01',\n    a.[BP_EMPRESA],\n    a.[BP_AFILIADO]),\nPoblacion_Educacion_Mes AS (\nSELECT DISTINCT \n      [ID_FECHA]\n      ,[PARTNER]\n  FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n  WHERE ACTIVIDAD != 'AFILIACION'),\nAfiliadosMes AS (\nSELECT DISTINCT \n      [ID_FECHA]\n      ,[PARTNER]\n      ,[PARTNER_AFILIADO]\n  FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n  WHERE ACTIVIDAD = 'AFILIACION' AND PARTNER_AFILIADO IS NOT NULL\n),\nAfiliadosEducacionMes AS (\nSELECT \n    am.[ID_FECHA]\n    ,am.[PARTNER_AFILIADO]\n    FROM AfiliadosMes am\nINNER JOIN Poblacion_Educacion_Mes pem ON am.[ID_FECHA] =pem.[ID_FECHA] and am.PARTNER = pem.PARTNER\n),\nconsulta as( SELECT distinct ap.*  \n    --,am.PARTNER_AFILIADO\n    ,--CASE WHEN aem.PARTNER_AFILIADO IS NULL THEN 'NO' ELSE 'SI' END AS POBLACION_EDUCACION,\n    -1 as ID_CURSO,\n    -1 as ID_PROGRAMA,\n    -1 as ID_PERTENENCIA_ETNICA,\n    ---1 as ID_GENERO,\n    -1 as ID_FACTOR_VULNERABILIDAD,\n    -1 ID_ESTADO_CIVIL,\n    -1 as ID_TARIFA,\n    ---1 as ID_CATEGORIA,\n    5 as ID_UNIDAD\nFROM Aportes_Total ap\nLEFT JOIN AfiliadosEducacionMes aem ON ap.ID_FECHA = aem.ID_FECHA AND ap.BP_AFILIADO = aem.PARTNER_AFILIADO\n),\n  partnerTable  as (\nSELECT PARTNER,ID_FECHA,\n      MAX([PARTNER_AFILIADO]) as  PARTNER_AFILIADO\n      ,MAX([PARTNER_EMPRESA]) as PARTNER_EMPRESA,\n    MAX([ID_CATEGORIA]) AS ID_CATEGORIA,\n    MAX([ID_GENERO]) AS ID_GENERO\n\n  FROM [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES]\n  where ACTIVIDAD = 'AFILIACION'\n  group by [PARTNER], ID_FECHA\n\n  ),\n  CategoriaAfiliadoTable  as (\nSELECT ID_AFILIADO,ID_FECHA,\n    MAX([ID_CATEGORIA]) AS ID_CATEGORIA,\n    MAX([ID_GENERO]) AS ID_GENERO,\n    MAX([FECHA_NACIMIENTO]) AS FECHA_NACIMIENTO,\n    MAX([EDAD]) AS EDAD      \n  FROM [STAGE_AREA].[Transversal].[STG_FACT_AFILIACIONES]\n  where ACTIVIDAD = 'AFILIACION'\n  group by ID_AFILIADO, ID_FECHA\n\n  ),\n  ActividadesPoblacion AS (\n    SELECT \n        ID_FECHA, -- Conversi\u00f3n expl\u00edcita\n        --PARTNER,       -- Conversi\u00f3n expl\u00edcita\n        ID_AFILIADO,\n        MAX(POBLACION_EDUCACION) AS POBLACION_EDUCACION,\n        MAX(POBLACION_EDUCACION_FORMAL) AS POBLACION_EDUCACION_FORMAL,\n        MAX(POBLACION_EDUCACION_TECNICA) AS POBLACION_EDUCACION_TECNICA,\n        MAX(POBLACION_EDUCACION_CONTINUA) AS POBLACION_EDUCACION_CONTINUA,\n        MAX(POBLACION_EDUCACION_PROTECCION) AS POBLACION_EDUCACION_PROTECCION\n    FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n    WHERE ID_AFILIADO !=-1 AND ACTIVIDAD !='APORTES'\n    GROUP BY ID_AFILIADO, ID_FECHA)\n\n  select  c.*, \n  --COALESCE(pt.[PARTNER_AFILIADO], '0000000000') as PARTNER_AFILIADO,\n  --COALESCE(pt.[PARTNER_EMPRESA] , '0000000000') as PARTNER_EMPRESA,\n  COALESCE(c.[BP_AFILIADO], '0000000000') as PARTNER_AFILIADO,\n  COALESCE(c.[BP_EMPRESA] , '0000000000') as PARTNER_EMPRESA,\n  COALESCE(cata.[ID_CATEGORIA] , 4) as ID_CATEGORIA,\n  COALESCE(cata.[ID_GENERO] , -1) as ID_GENERO,\n  cata.[FECHA_NACIMIENTO], \n  COALESCE(cata.[EDAD] , -1) as EDAD,\n'[DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET]' AS [FUENTE_PRINCIPAL],\n    CONVERT(VARCHAR(50),COALESCE(act.POBLACION_EDUCACION, 'NO')) AS POBLACION_EDUCACION,\n    COALESCE(act.POBLACION_EDUCACION_FORMAL, 'NO') AS POBLACION_EDUCACION_FORMAL,\n    COALESCE(act.POBLACION_EDUCACION_TECNICA, 'NO') AS POBLACION_EDUCACION_TECNICA,\n    COALESCE(act.POBLACION_EDUCACION_CONTINUA, 'NO') AS POBLACION_EDUCACION_CONTINUA,\n    COALESCE(act.POBLACION_EDUCACION_PROTECCION, 'NO') AS POBLACION_EDUCACION_PROTECCION\n  from  consulta c\n  LEFT JOIN  partnerTable pt\n  ON c.[PARTNER] = pt.[PARTNER]\n  AND c.ID_FECHA = pt.ID_FECHA\n  LEFT JOIN  ActividadesPoblacion act\n  --ON c.[PARTNER] = act.[PARTNER]\n  ON c.[ID_AFILIADO] = act.[ID_AFILIADO]\n  AND c.ID_FECHA = act.ID_FECHA\n  LEFT JOIN CategoriaAfiliadoTable cata \n  ON c.[ID_AFILIADO] = cata.[ID_AFILIADO]\n  AND c.ID_FECHA = cata.ID_FECHA\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_personal_cubo","title":"FACT_PERSONAL_CUBO","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general-del-componente_3","title":"Descripci\u00f3n General del Componente","text":"<p>El flujo de datos <code>FACT_PERSONAL_CUBO</code> consolida eventos relacionados con el personal docente, tales como ausentismos, reemplazos, contrataciones y terminaciones, provenientes de m\u00faltiples fuentes. Integra estos datos y los transforma para su carga en la tabla de hechos <code>FACT_PERSONAL</code> del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-del-paquete_4","title":"Ubicaci\u00f3n del Paquete","text":"<p><code>Package\\FACT_PERSONAL_CUBO</code></p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_2","title":"Prop\u00f3sito del Componente","text":"<p>Unificar eventos mensuales del personal institucional para an\u00e1lisis de disponibilidad, contrataci\u00f3n y movimiento del recurso humano. Esta informaci\u00f3n permite alimentar cubos de an\u00e1lisis para planificaci\u00f3n y control de personal.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_18","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen:</p> <ul> <li><code>[DWH_COMFENALCO].[Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]</code></li> <li><code>[DWH_COMFENALCO].[Colegio].[FACT_AUSENTISMO_DOCENTE]</code></li> <li><code>[DWH_COMFENALCO].[Colegio].[FACT_REEMPLAZO_DOCENTE]</code></li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]</code></li> </ul> </li> <li> <p>Destino:</p> <ul> <li><code>\"Transversal\".\"FACT_PERSONAL\"</code></li> </ul> </li> <li> <p>Transformaciones:</p> <ul> <li>Agrupaci\u00f3n mensual de eventos mediante la f\u00f3rmula <code>LEFT(ID_FECHA,6)*100+1</code>.</li> <li>Uniformizaci\u00f3n de estructura con campos como <code>CONCEPTO</code>, <code>DESCRIPCION</code>, <code>HORAS_CONTRATADAS_MENSUAL</code>, <code>TIPO_AUSENCIA</code>, etc.</li> <li>Clasificaci\u00f3n de eventos: <code>AUSENTISMO</code>, <code>REEMPLAZO</code>, <code>CONTRATACION</code>, <code>FIN_CONTRATACION</code>.</li> <li>Trazabilidad con columna <code>FUENTE_PRINCIPAL</code> indicando la fuente original.</li> </ul> </li> <li> <p>M\u00e9todo de carga:   ADO.NET Destination con <code>UseBulkInsertWhenPossible = true</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_16","title":"L\u00f3gica de Negocio","text":"<ol> <li> <p>Se obtienen y unifican eventos de:</p> <ul> <li>Ausentismos docentes.</li> <li>Reemplazos temporales.</li> <li>Contrataciones activas.</li> <li>Terminaciones de contrato.</li> </ul> </li> <li> <p>Cada evento es asociado a un mes de an\u00e1lisis (<code>ID_FECHA</code> normalizado).</p> </li> <li> <p>Se enriquece con la unidad organizacional del personal mediante <code>LEFT JOIN</code> a <code>DIM_PERSONAL</code>.</p> </li> <li> <p>Se filtra para garantizar la existencia en <code>DIM_TIEMPO_MENSUAL</code>.</p> </li> <li> <p>Se insertan registros estandarizados con sus conceptos y trazabilidad en <code>FACT_PERSONAL</code>.</p> </li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_16","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Dependencias:</p> <ul> <li><code>DIM_TIEMPO_MENSUAL</code></li> <li><code>DIM_PERSONAL</code></li> </ul> </li> <li> <p>Destino Anal\u00edtico:</p> <ul> <li>Tabla de hechos <code>FACT_PERSONAL</code>, insumo para cubos de recursos humanos y reportes de gesti\u00f3n del talento docente.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-principal-resumen","title":"Script SQL Principal (Resumen)","text":"<pre><code>SELECT uni.ID_FECHA, uni.ID_PERSONAL,uni.NOMBRE,uni.CONCEPTO,uni.DESCRIPCION, uni.FECHA_FIN ,\nuni.HORAS_CONTRATADAS_MENSUAL, pers.ID_UNIDAD,AUSENCIA_HORAS,TIPO_AUSENCIA,uni.FUENTE_PRINCIPAL  FROM(\n\nSELECT LEFT([ID_FECHA], 6)*100 +1 as ID_FECHA\n      ,[ID_PERSONAL]\n      ,[NOMBRE_DOCENTE] as NOMBRE\n      ,'AUSENTISMO' as CONCEPTO\n      ,[MOTIVO_AUSENCIA] as DESCRIPCION\n      ,[FECHA_FIN]\n      ,NULL as HORAS_CONTRATADAS_MENSUAL\n      ,AUSENCIA_HORAS\n      ,TIPO_AUSENCIA,\n      '[DWH_COMFENALCO].[Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]' AS [FUENTE_PRINCIPAL]\n FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]\n\nUNION \n\nSELECT LEFT([ID_FECHA], 6)*100 +1 as ID_FECHA\n      ,[ID_PERSONAL_REEMPLAZA] as ID_PERSONAL\n      ,[DOCENTE_REEMPLAZA] as NOMBRE\n      ,'REEMPLAZO' as CONCEPTO\n      ,NULL as DESCRIPCION\n      ,NULL as FECHA_FIN\n      ,NULL as HORAS_CONTRATADAS_MENSUAL\n      ,NULL as AUSENCIA_HORAS\n      ,NULL as TIPO_AUSENCIA,\n      '[DWH_COMFENALCO].[Colegio].[FACT_REEMPLAZO_DOCENTE]' AS [FUENTE_PRINCIPAL]\nFROM [DWH_COMFENALCO].[Colegio].[FACT_REEMPLAZO_DOCENTE]\n\nUNION \n\nSELECT LEFT([ID_FECHA], 6)*100 +1 as ID_FECHA\n      ,[ID_PERSONAL]\n      ,[NOMBRE_DOCENTE] as NOMBRE\n      ,'AUSENTISMO' as CONCEPTO\n      ,[MOTIVO_AUSENCIA] as DESCRIPCION\n      ,[FECHA_FIN]\n      ,NULL as HORAS_CONTRATADAS_MENSUAL\n      ,AUSENCIA_HORAS\n      ,TIPO_AUSENCIA,\n      '[DWH_COMFENALCO].[Colegio].[FACT_AUSENTISMO_DOCENTE]' AS [FUENTE_PRINCIPAL]\nFROM [DWH_COMFENALCO].[Colegio].[FACT_AUSENTISMO_DOCENTE]\n\nUNION \n\nSELECT LEFT(CONVERT(INT, FORMAT([FECHA_INICIO_CONTRATACION], 'yyyyMMdd')), 6)*100 +1 AS ID_FECHA\n      ,[ID_PERSONAL]      \n      ,[NOMBRE]\n      ,'CONTRATACION' as CONCEPTO \n      ,NULL as DESCRIPCION\n      ,[FECHA_FIN_CONTRATACION] AS FECHA_FIN\n      ,[HORAS_CONTRATADAS_MENSUAL]\n      ,NULL as AUSENCIA_HORAS\n      ,NULL as TIPO_AUSENCIA,\n      '[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]' AS [FUENTE_PRINCIPAL]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\n\nUNION \n\n SELECT  LEFT(CONVERT(INT, FORMAT([FECHA_FIN_CONTRATACION], 'yyyyMMdd')), 6)*100 +1 AS ID_FECHA\n      ,[ID_PERSONAL]      \n      ,[NOMBRE]\n      ,'FIN_CONTRATACION' as CONCEPTO \n      ,[CAUSA_TERMINACION_CONTRATO] as DESCRIPCION\n      ,NULL as FECHA_FIN\n      ,NULL as HORAS_CONTRATADAS_MENSUAL\n      ,NULL as AUSENCIA_HORAS\n      ,NULL as TIPO_AUSENCIA,\n      '[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]' AS [FUENTE_PRINCIPAL]\n  FROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\n\n\n  ) as uni\n --   WHERE [ID_FECHA] IS NOT NULL\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM\n ON uni.ID_FECHA = dimM.ID_FECHA \n LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL] pers\n ON uni.ID_PERSONAL = pers.ID_PERSONAL\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_evaluacion_docente_cubo","title":"FACT_EVALUACION_DOCENTE_CUBO","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>Este componente del paquete SSIS carga evaluaciones docentes consolidadas desde diversas fuentes acad\u00e9micas hacia la tabla <code>Transversal.FACT_EVALUACION_DOCENTE</code> en el Data Warehouse <code>DWH_COMFENALCO</code>. Su objetivo es integrar calificaciones definitivas por periodo acad\u00e9mico, unidad y docente, permitiendo su an\u00e1lisis a nivel hist\u00f3rico y comparativo.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_11","title":"Ubicaci\u00f3n en el Paquete","text":"<ul> <li>Ruta SSIS: <code>Package\\FACT_EVALUACION_DOCENTE_CUBO</code></li> <li>Destino: <code>DWH_COMFENALCO.Transversal.FACT_EVALUACION_DOCENTE</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_16","title":"Prop\u00f3sito","text":"<p>Consolidar las calificaciones docentes de los sistemas acad\u00e9micos de Colegio y Cedesarrollo, incluyendo desempe\u00f1o y evaluaciones cuantitativas, para su an\u00e1lisis transversal por unidad, docente, fecha y periodo acad\u00e9mico.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_19","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Origen: Componente <code>FACT_EVALUACION</code> (ADO.NET Source)</li> <li>Destino: Componente <code>Destino de ADO NET</code> con tabla <code>Transversal.FACT_EVALUACION_DOCENTE</code></li> <li>Tipo de carga: Bulk Insert mediante <code>SqlBulkCopy</code></li> <li>Transformaci\u00f3n: Validaci\u00f3n y consolidaci\u00f3n de columnas comunes; ajuste de fechas (<code>ID_FECHA</code> generada a partir de <code>FECHA_FIN</code>)</li> <li>Integraci\u00f3n temporal: <code>DIM_TIEMPO_MENSUAL</code> para validaci\u00f3n y normalizaci\u00f3n de fechas.</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_17","title":"L\u00f3gica de Negocio","text":"<p>La l\u00f3gica combina m\u00faltiples or\u00edgenes de evaluaci\u00f3n docente:</p> <ol> <li>Evaluaci\u00f3n cuantitativa (<code>FACT_DESEMPENHO_DOCENTE</code>)</li> <li>Evaluaciones CE (<code>FACT_DESEMPENHO_DOCENTE_CE</code>)</li> <li>Evaluaciones DE (<code>FACT_DESEMPENHO_DOCENTE_DE</code>)</li> </ol> <p>Se prioriza la obtenci\u00f3n de <code>ID_FECHA</code> a partir de la \u00faltima fecha del periodo y se homogeniza la estructura para facilitar an\u00e1lisis OLAP.</p>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_17","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Utiliza dimensiones compartidas como <code>DIM_TIEMPO_MENSUAL</code> y <code>DIM_PERIODO_ACADEMICO</code>.</li> <li>Integra l\u00f3gica de negocio coherente con <code>FACT_PERSONAL_CUBO</code> para trazabilidad de personal docente.</li> <li>Complementa vistas como <code>VW_EVALUACION_DOCENTE</code> para an\u00e1lisis multidimensional.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-implementado","title":"Script SQL Implementado","text":"<pre><code>SELECT \n    PERIODO_ACADEMICO,\n    ID_UNIDAD,\n    ID_PERSONAL,\n    NOMBRE_DOCENTE,\n    CALIFICACION_DEFINITIVA,\n    uni.ID_FECHA, \n    uni.FUENTE_PRINCIPAL \nFROM (\n    SELECT \n        CONVERT(NVARCHAR, [ANIO_ACADEMICO]) AS PERIODO_ACADEMICO,\n        1 as ID_UNIDAD,\n        [ID_PERSONAL],\n        [NOMBRE_DOCENTE],\n        [TOTAL_GENERAL] as CALIFICACION_DEFINITIVA,\n        [ID_FECHA],\n        '[DWH_COMFENALCO].[Colegio].[FACT_DESEMPENHO_DOCENTE]' as FUENTE_PRINCIPAL\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_DESEMPENHO_DOCENTE]\n\n    UNION\n\n    SELECT \n        c2.[PERIODO_ACADEMICO],\n        c1.[ID_UNIDAD],\n        c1.[ID_PERSONAL],\n        c1.[NOMBRE_DOCENTE],\n        c1.[CALIFICACION_DEFINITIVA],\n        CONVERT(INT, FORMAT(MAX(c2.FECHA_FIN), 'yyyyMM') + '01') as ID_FECHA,\n        '[DWH_COMFENALCO].[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_CE]' as FUENTE_PRINCIPAL\n    FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_CE] as c1\n    LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] as c2\n        ON c1.ID_PERIODO = c2.ID_PERIODO\n    GROUP BY c1.ID_UNIDAD, c1.ID_PERSONAL, c1.NOMBRE_DOCENTE, c2.PERIODO_ACADEMICO, c1.CALIFICACION_DEFINITIVA\n\n    UNION\n\n    SELECT \n        c2.[PERIODO_ACADEMICO],\n        c1.[ID_UNIDAD],\n        c1.[ID_PERSONAL],\n        c1.[NOMBRE_DOCENTE],\n        c1.[CALIFICACION] as CALIFICACION_DEFINITIVA,\n        CONVERT(INT, FORMAT(MAX(c2.FECHA_FIN), 'yyyyMM') + '01') as ID_FECHA,\n        '[DWH_COMFENALCO].[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_DE]' as FUENTE_PRINCIPAL\n    FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_DE] as c1\n    INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] as c2\n        ON c1.ID_PERIODO = c2.ID_PERIODO\n    GROUP BY c1.ID_UNIDAD, c1.ID_PERSONAL, c1.NOMBRE_DOCENTE, c2.PERIODO_ACADEMICO, c1.CALIFICACION\n) uni\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM\n    ON uni.ID_FECHA = dimM.ID_FECHA;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#importancia-para-el-negocio","title":"Importancia para el Negocio","text":"<ul> <li>Evaluaci\u00f3n Docente Unificada: Permite una comparaci\u00f3n equitativa del desempe\u00f1o entre unidades y periodos.</li> <li>Indicadores Estrat\u00e9gicos: Aporta informaci\u00f3n clave para la gesti\u00f3n acad\u00e9mica y decisiones sobre desarrollo del personal docente.</li> <li>Auditor\u00eda y Trazabilidad: La columna <code>FUENTE_PRINCIPAL</code> permite rastrear la procedencia exacta de cada registro.</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_financiera_cubo","title":"FACT_FINANCIERA_CUBO","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_FINANCIERA_CUBO</code> dentro del paquete SSIS permite la transformaci\u00f3n, integraci\u00f3n y carga de informaci\u00f3n contable ejecutada y presupuestada. A trav\u00e9s de una consulta unificada, combina datos de ejecuci\u00f3n contable y presupuesto para permitir un an\u00e1lisis financiero completo, incluyendo resultados PYG y BALANCE por dimensiones organizativas y temporales.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_12","title":"Ubicaci\u00f3n en el Paquete","text":"<p><code>Package\\FACT_FINANCIERA_CUBO</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_17","title":"Prop\u00f3sito","text":"<p>Unificar, transformar y cargar informaci\u00f3n financiera desde las tablas <code>FACT_DETALLE_CONTABLE</code> y <code>FACT_PRESUPUESTO</code>, integrando datos presupuestales y ejecutados con el objetivo de habilitar an\u00e1lisis comparativos por unidad organizativa, cuenta contable y periodos mensuales en la tabla final <code>Transversal.FACT_FINANCIERA</code>.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_20","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen de Datos:</p> <ul> <li>Ejecuci\u00f3n Contable: <code>Financiera.FACT_DETALLE_CONTABLE</code></li> <li>Presupuesto Contable: <code>Financiera.FACT_PRESUPUESTO</code></li> </ul> </li> <li> <p>Uniones Clave:</p> <ul> <li><code>DIM_UNIDADES_ORGANIZATIVAS</code>, <code>DIM_CUENTA_CONTABLE</code>, <code>DIM_TIEMPO</code></li> </ul> </li> <li> <p>Destino:</p> <ul> <li>Tabla: <code>\"Transversal\".\"FACT_FINANCIERA\"</code> (via componente ADO.NET Destination)</li> </ul> </li> <li> <p>Carga:</p> <ul> <li>Operaci\u00f3n de tipo <code>Bulk Insert</code> habilitada para eficiencia.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_18","title":"L\u00f3gica de Negocio","text":"<ol> <li> <p>Consulta de Ejecuci\u00f3n: Se agrupan y suman valores contables como ingresos, gastos, costos, activos y pasivos a nivel de cuenta, unidad y fecha. El resultado incluye una columna calculada <code>TIPO</code> con valor <code>'PYG'</code> o <code>'BALANCE'</code> seg\u00fan el tipo de cuenta.</p> </li> <li> <p>Consulta de Presupuesto: Similar estructura y l\u00f3gica, diferenciando mediante el campo <code>ACTIVIDAD = 'PRESUPUESTO_CONTABLE'</code>.</p> </li> <li> <p>Uni\u00f3n: Se realiza un <code>UNION ALL</code> entre ambas consultas, permitiendo comparar ejecuci\u00f3n vs. presupuesto en un solo dataset.</p> </li> <li> <p>Enriquecimiento: Se integran claves de unidad (<code>ID_UNIDAD</code>) y tiempo (<code>DIM_TIEMPO_MENSUAL</code>) para an\u00e1lisis dimensional.</p> </li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_18","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Fuentes Vinculadas: <code>FACT_DETALLE_CONTABLE</code>, <code>FACT_PRESUPUESTO</code>, <code>DIM_TIEMPO</code>, <code>DIM_UNIDADES_ORGANIZATIVAS</code>, <code>DIM_CUENTA_CONTABLE</code></li> <li>Destino Final: <code>FACT_FINANCIERA</code> (ubicada en esquema <code>Transversal</code>)</li> <li>Dependencias: Requiere datos consistentes y cargados previamente en dimensiones de unidades y tiempo.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-completo_1","title":"Script SQL Completo","text":"<pre><code>WITH EjecucionContable AS\n(SELECT\n    Ej.[ID_MES]*100+1 as ID_FECHA,\n    Ej.ID_ANIO,Ej.ID_MES,Ej.ID_CEBE,Ej.CEBE,DESCRIPCION_CEBE,Ej.DEPARTAMENTO,Ej.AREA,Ej.SUBAREA,\n    Ej.SEGMENTO,Ej.DESCRIPCION_SEGMENTO,Ej.CODIGO_SSF,Ej.NOMBRE_SSF,Ej.ID_CUENTA,\n    Ej.CUENTA,Ej.CUENTA_HOMOLOGA,Ej.DESCRIPCION,Ej.TIPO_CUENTA,Ej.TIPO_OPERACION,\n    Ej.GRUPO_CUENTA,Ej.SUBGRUPO_CUENTA,Ej.GRUPO_OPERACION,Ej.CUENTA_SSF,\n    Ej.DESCRIPCION_SSF,Ej.CUENTA_DESCRIPCION,Ej.CUENTA_DESCRIPCION_SSF,\n    Ej.SIGNO_INGRESOS,Ej.CLASIFICACION,Ej.SEGMENT,\n    Ej.IMPORTE,\n    Ej.INGRESOS,\n    Ej.INGRESOS_OPERACIONALES,\n    Ej.GASTOS,\n    Ej.GASTOS_OPERACIONALES,\n    Ej.GASTOS_OPERACIONALES_ADMIN,\n    Ej.RESULTADO_EJERCICIO,\n    Ej.COSTOS,\n    Ej.ACTIVO,\n    Ej.PASIVO,\n    Ej.PATRIMONIO,\n    Ej.GASTOS_CON_DISTRIBUCION,\n    Ej.GASTOS_SIN_DISTRIBUCION,\n    Case When Ej.TIPO_CUENTA In ('INGRESOS','COSTOS','GASTOS') Then 'PYG' Else 'BALANCE' End As TIPO,\n    'EJECUCION_CONTABLE' as ACTIVIDAD,\n    'Consulta Detalle Contable Comfenalco' as FUENTE_PRINCIPAL\n\nFROM\n(\n\n    SELECT\n        Tp.[ID_ANIO],\n        Tp.[ID_MES],\n        Ft.[ID_CEBE],\n        Uo.[CEBE],\n        Upper(Uo.[CEBE_DESCRIPCION])As  [DESCRIPCION_CEBE], \n        Upper(Uo.[DEPARTAMENTO])As  [DEPARTAMENTO],\n        Upper(Uo.[AREA])        As  [AREA],\n        Upper(Uo.[SUBAREA])     As  [SUBAREA],\n        Uo.[SEGMENTO],\n        Uo.[DESCRIPCION_SEGMENTO],\n        Uo.[CODIGO_SSF],\n        Uo.[NOMBRE_SSF],\n        Ft.[ID_CUENTA],\n        Ct.[CUENTA],\n        Ct.[CUENTA_HOMOLOGA],\n        Upper(Ct.[DESCRIPCION])     As  [DESCRIPCION],\n        Upper(Ct.[TIPO_CUENTA])     As  [TIPO_CUENTA],\n        Upper(Ct.[TIPO_OPERACION])  As  [TIPO_OPERACION],\n        Upper(Ct.[GRUPO_CUENTA])    As  [GRUPO_CUENTA],\n        Upper(Ct.[SUBGRUPO_CUENTA]) As  [SUBGRUPO_CUENTA],\n        Upper(Ct.[GRUPO_OPERACION]) As  [GRUPO_OPERACION],\n        Ct.[CUENTA_SSF],\n        Upper(Ct.[DESCRIPCION_SSF])         As  [DESCRIPCION_SSF],\n        Upper(Ct.[CUENTA_DESCRIPCION])      As  [CUENTA_DESCRIPCION],\n        Upper(Ct.[CUENTA_DESCRIPCION_SSF])  As  [CUENTA_DESCRIPCION_SSF],\n        Ct.[SIGNO_INGRESOS],\n        Ct.[CLASIFICACION],\n        Ft.[SEGMENT],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[IMPORTE],0)))                  As  [IMPORTE],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[INGRESOS],0)))                 As  [INGRESOS],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[INGRESOS_OPERACIONALES],0)))   As  [INGRESOS_OPERACIONALES],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS],0)))                   As  [GASTOS],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_OPERACIONALES],0)))         As  [GASTOS_OPERACIONALES],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_OPERACIONALES_ADMIN],0)))   As  [GASTOS_OPERACIONALES_ADMIN],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[RESULTADO_EJERCICIO],0)))      As  [RESULTADO_EJERCICIO],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[COSTOS],0)))                   As  [COSTOS],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[ACTIVO],0)))                   As  [ACTIVO],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[PASIVO],0)))                   As  [PASIVO],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[PATRIMONIO],0)))               As  [PATRIMONIO],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_CON_DISTRIBUCION],0)))  As  [GASTOS_CON_DISTRIBUCION],  \n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_SIN_DISTRIBUCION],0)))  As  [GASTOS_SIN_DISTRIBUCION]\n\n      FROM [DWH_COMFENALCO].[Financiera].[FACT_DETALLE_CONTABLE] FT\n      INNER JOIN [DWH_COMFENALCO].[Financiera].[DIM_UNIDADES_ORGANIZATIVAS] Uo On  Ft.ID_CEBE = Uo.ID_CEBE\n      INNER JOIN [DWH_COMFENALCO].[Financiera].[DIM_CUENTA_CONTABLE] Ct On  Ft.ID_CUENTA = ct.ID_CUENTA\n      INNER JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] Tp On  Ft.ID_FECHA = tp.ID_FECHA\n      Where/*   TP.ID_ANIO = @A\u00f1o_Actual AND Try_convert(date,tp.FECHA,103) &lt;= @PeriodoMax\n        AND*/ --Ct.TIPO_CUENTA Not in  ('INGRESOS','COSTOS','GASTOS')\n        Ct.TIPO_CUENTA in  ('INGRESOS','COSTOS','GASTOS')\n        --AND   LEFT(Ct.CUENTA,4) in (1516,1528) \n\n      Group by \n\n        Tp.[ID_ANIO],Tp.[ID_MES],Ft.[ID_CEBE], Uo.[CEBE],Uo.[CEBE_DESCRIPCION],Uo.[DEPARTAMENTO],Uo.[AREA],Uo.[SUBAREA],Uo.[SEGMENTO],\n        Uo.[DESCRIPCION_SEGMENTO], Uo.[CODIGO_SSF],Uo.[NOMBRE_SSF],Ft.[ID_CUENTA],Ct.[CUENTA],\n        Ct.[CUENTA_HOMOLOGA],Ct.[DESCRIPCION],Ct.[TIPO_CUENTA],Ct.[TIPO_OPERACION],Ct.[GRUPO_CUENTA],\n        Ct.[SUBGRUPO_CUENTA],Ct.[GRUPO_OPERACION],Ct.[CUENTA_SSF],Ct.[DESCRIPCION_SSF],Ct.[CUENTA_DESCRIPCION],\n        Ct.[CUENTA_DESCRIPCION_SSF],Ct.[SIGNO_INGRESOS],Ct.[CLASIFICACION],Ft.[SEGMENT]\n )Ej\n     --Order by Ej.[ID_ANIO],Ej.[ID_MES],Ej.[ID_CEBE]\n),\nPresupuestoContable AS\n(\nSELECT\n    Ej.[ID_MES]*100+1 as ID_FECHA,\n    Ej.ID_ANIO,Ej.ID_MES,Ej.ID_CEBE,Ej.CEBE,Ej.DESCRIPCION_CEBE,Ej.DEPARTAMENTO,Ej.AREA,Ej.SUBAREA,\n    Ej.SEGMENTO,Ej.DESCRIPCION_SEGMENTO,Ej.CODIGO_SSF,Ej.NOMBRE_SSF,Ej.ID_CUENTA,\n    Ej.CUENTA,Ej.CUENTA_HOMOLOGA,Ej.DESCRIPCION,Ej.TIPO_CUENTA,Ej.TIPO_OPERACION,\n    Ej.GRUPO_CUENTA,Ej.SUBGRUPO_CUENTA,Ej.GRUPO_OPERACION,Ej.CUENTA_SSF,\n    Ej.DESCRIPCION_SSF,Ej.CUENTA_DESCRIPCION,Ej.CUENTA_DESCRIPCION_SSF,\n    Ej.SIGNO_INGRESOS,Ej.CLASIFICACION,Ej.SEGMENT,\n    Ej.IMPORTE,\n    Ej.INGRESOS,\n    Ej.INGRESOS_OPERACIONALES,\n    Ej.GASTOS,\n    Ej.GASTOS_OPERACIONALES,\n    Ej.GASTOS_OPERACIONALES_ADMIN,\n    Ej.RESULTADO_EJERCICIO,\n    Ej.COSTOS,\n    Ej.ACTIVO,\n    Ej.PASIVO,\n    Ej.PATRIMONIO,\n    Ej.GASTOS_CON_DISTRIBUCION,\n    Ej.GASTOS_SIN_DISTRIBUCION,\n    Case When Ej.TIPO_CUENTA In ('INGRESOS','COSTOS','GASTOS') Then 'PYG' Else 'BALANCE' End As TIPO\n    ,'PRESUPUESTO_CONTABLE' as ACTIVIDAD,\n     'Consulta Fact Presupuesto Comfenalco' as FUENTE_PRINCIPAL\nFROM\n(\n\n    SELECT\n        Tp.[ID_ANIO],\n        Tp.[ID_MES],\n        Ft.[ID_CEBE],\n        Uo.[CEBE],\n        Upper(Uo.[CEBE_DESCRIPCION]) As [DESCRIPCION_CEBE],\n        Upper(Uo.[DEPARTAMENTO])As  [DEPARTAMENTO],\n        Upper(Uo.[AREA])        As  [AREA],\n        Upper(Uo.[SUBAREA])     As  [SUBAREA],\n        Uo.[SEGMENTO],\n        Uo.[DESCRIPCION_SEGMENTO],\n        Uo.[CODIGO_SSF],\n        Uo.[NOMBRE_SSF],\n        Ft.[ID_CUENTA],\n        Ct.[CUENTA],\n        Ct.[CUENTA_HOMOLOGA],\n        Upper(Ct.[DESCRIPCION])     As  [DESCRIPCION],\n        Upper(Ct.[TIPO_CUENTA])     As  [TIPO_CUENTA],\n        Upper(Ct.[TIPO_OPERACION])  As  [TIPO_OPERACION],\n        Upper(Ct.[GRUPO_CUENTA])    As  [GRUPO_CUENTA],\n        Upper(Ct.[SUBGRUPO_CUENTA]) As  [SUBGRUPO_CUENTA],\n        Upper(Ct.[GRUPO_OPERACION]) As  [GRUPO_OPERACION],\n        Ct.[CUENTA_SSF],\n        Upper(Ct.[DESCRIPCION_SSF])         As  [DESCRIPCION_SSF],\n        Upper(Ct.[CUENTA_DESCRIPCION])      As  [CUENTA_DESCRIPCION],\n        Upper(Ct.[CUENTA_DESCRIPCION_SSF])  As  [CUENTA_DESCRIPCION_SSF],\n        Ct.[SIGNO_INGRESOS],\n        Ct.[CLASIFICACION],\n        Ft.[SEGMENT],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[VALOR],0)))                    As  [IMPORTE],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[INGRESOS],0)))                 As  [INGRESOS],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[INGRESOS_OPERACIONALES],0)))   As  [INGRESOS_OPERACIONALES],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS],0)))                   As  [GASTOS],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_OPERACIONALES],0)))         As  [GASTOS_OPERACIONALES],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_OPERACIONALES_ADMIN],0)))   As  [GASTOS_OPERACIONALES_ADMIN],\n        0 As    [RESULTADO_EJERCICIO],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[COSTOS],0)))                   As  [COSTOS],\n        0   As  [ACTIVO],\n        0   As  [PASIVO],\n        0   As  [PATRIMONIO],\n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_CON_DISTRIBUCION],0)))  As  [GASTOS_CON_DISTRIBUCION],  \n        Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_SIN_DISTRIBUCION],0)))  As  [GASTOS_SIN_DISTRIBUCION]\n\n      FROM [DWH_COMFENALCO].[Financiera].[FACT_PRESUPUESTO] FT\n      INNER JOIN [DWH_COMFENALCO].[Financiera].[DIM_UNIDADES_ORGANIZATIVAS] Uo On  Ft.ID_CEBE = Uo.ID_CEBE\n      INNER JOIN [DWH_COMFENALCO].[Financiera].[DIM_CUENTA_CONTABLE] Ct On  Ft.ID_CUENTA = ct.ID_CUENTA\n      INNER JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] Tp On  Ft.ID_FECHA = tp.ID_FECHA\n      Where /*tp.ID_ANIO = @A\u00f1o_Actual\n        And Try_convert(date,tp.FECHA,103) &lt;= @PeriodoMax\n        and */ --Ct.TIPO_CUENTA Not in  ('INGRESOS','COSTOS','GASTOS')\n        Ct.TIPO_CUENTA in  ('INGRESOS','COSTOS','GASTOS')\n        And ft.ID_TIPO_PRESUPUESTO = 4  /*Aprobado*/\n\n      Group by \n\n        Tp.[ID_ANIO],Tp.[ID_MES],Ft.[ID_CEBE], Uo.[CEBE],Uo.[CEBE_DESCRIPCION],Uo.[DEPARTAMENTO],Uo.[AREA],Uo.[SUBAREA],Uo.[SEGMENTO],\n        Uo.[DESCRIPCION_SEGMENTO], Uo.[CODIGO_SSF],Uo.[NOMBRE_SSF],Ft.[ID_CUENTA],Ct.[CUENTA],\n        Ct.[CUENTA_HOMOLOGA],Ct.[DESCRIPCION],Ct.[TIPO_CUENTA],Ct.[TIPO_OPERACION],Ct.[GRUPO_CUENTA],\n        Ct.[SUBGRUPO_CUENTA],Ct.[GRUPO_OPERACION],Ct.[CUENTA_SSF],Ct.[DESCRIPCION_SSF],Ct.[CUENTA_DESCRIPCION],\n        Ct.[CUENTA_DESCRIPCION_SSF],Ct.[SIGNO_INGRESOS],Ct.[CLASIFICACION],Ft.[SEGMENT]\n )Ej\n     --Order by Ej.[ID_ANIO],Ej.[ID_MES],Ej.[ID_CEBE]\n)\n\n select Ej.*, ID_UNIDAD from EjecucionContable Ej\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_UNIDADES_ORGANIZATIVAS] do ON Ej.ID_CEBE = do.ID_CEBE\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM ON Ej.ID_FECHA = dimM.ID_FECHA\n\n\nunion ALL\nSELECT Ej.*, ID_UNIDAD\n FROM PresupuestoContable Ej\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_UNIDADES_ORGANIZATIVAS] do ON Ej.ID_CEBE = do.ID_CEBE\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM ON Ej.ID_FECHA = dimM.ID_FECHA\n</code></pre>"},{"location":"03.Cubo/03.ETL/#procesar-fact_unidadescobertura-proyectada","title":"Procesar FACT_UNIDADES\\Cobertura Proyectada","text":""},{"location":"03.Cubo/03.ETL/#ruta-del-componente","title":"Ruta del Componente:","text":"<p><code>Package\\Procesar FACT_UNIDADES\\Cobertura Proyectada</code></p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>Este componente de flujo de datos consolida y transforma informaci\u00f3n de cobertura proyectada mensual desde m\u00faltiples dominios del sistema (Colegio, Cedesarrollo, Protecci\u00f3n Social y Adulto con Discapacidad), integrando fuentes dispersas en una \u00fanica tabla de hechos: <code>Transversal.FACT_UNIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete_2","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p>Se encuentra dentro del <code>Data Flow Task</code> llamado Cobertura Proyectada, parte del contenedor <code>Procesar FACT_UNIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_3","title":"Prop\u00f3sito del Componente","text":"<p>Su objetivo es centralizar la proyecci\u00f3n de cobertura mensual institucionalizada, combinando proyecciones educativas, programas sociales y planes de atenci\u00f3n, lo que facilita el an\u00e1lisis estrat\u00e9gico por unidad, grado, programa o tipo de cobertura.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_21","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen de Datos:   Fuente ADO.NET configurada con <code>AccessMode = 2</code>, ejecutando un script SQL con m\u00faltiples CTEs (<code>WITH</code>) y <code>UNION ALL</code>.</p> </li> <li> <p>Destino:   Componente ADO.NET de carga hacia la tabla <code>\"Transversal\".\"FACT_UNIDADES\"</code>, optimizado con inserciones masivas (<code>UseBulkInsertWhenPossible = true</code>).</p> </li> <li> <p>Relaci\u00f3n con otros componentes:</p> <ul> <li>Utiliza la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> como validador temporal.</li> <li> <p>Consolida datos de:</p> <ul> <li><code>[Colegio].[DIM_PRESUPUESTO]</code></li> <li><code>[Cedesarrollo].[FACT_PLAN_COBERTURA]</code></li> <li><code>[Proteccion].[FACT_PLAN_COBERTURA]</code></li> <li><code>[Proteccion].[FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD]</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_19","title":"L\u00f3gica de Negocio","text":"<ul> <li>Se generan tres calendarios mensuales (Colegio, Cedesarrollo y Protecci\u00f3n).</li> <li>Las coberturas proyectadas se asignan a <code>ID_UNIDAD</code>, <code>CATEGORIA</code>, <code>ID_PROGRAMA</code> y <code>ID_FECHA_MENSUAL</code>.</li> <li>Se hace mapeo categ\u00f3rico expl\u00edcito en Cedesarrollo (categor\u00edas A, B, C...).</li> <li>Se utiliza <code>UNION ALL</code> para combinar resultados homog\u00e9neos, todos marcados con <code>'COBERTURA PROYECTADA'</code> en el campo <code>ACTIVIDAD</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#sql-del-componente-completo","title":"SQL del Componente (completo)","text":"<pre><code>WITH CalendarioMensualColegio AS (\n    SELECT \n        A\u00f1oPresupuesto * 10000 + (Mes % 100) * 100 + 01 AS ID_FECHA_MENSUAL,\n        A\u00f1oPresupuesto,\n        Mes\n    FROM (\n        SELECT DISTINCT [ID_ANIO_PRESUPUESTO] AS A\u00f1oPresupuesto\n        FROM [DWH_COMFENALCO].[Colegio].[DIM_PRESUPUESTO]\n    ) AS A\u00f1os\n    CROSS JOIN (\n        SELECT 101 AS Mes UNION ALL SELECT 102 UNION ALL SELECT 103 UNION ALL\n        SELECT 104 UNION ALL SELECT 105 UNION ALL SELECT 106 UNION ALL\n        SELECT 107 UNION ALL SELECT 108 UNION ALL SELECT 109 UNION ALL\n        SELECT 110 UNION ALL SELECT 111 UNION ALL SELECT 112\n    ) AS Meses\n),\nCoberturaProyectadaColegio AS (\n    SELECT DP.[ID_CURSO], DP.[GRADO], CM.ID_FECHA_MENSUAL,\n           'DIM_PRESUPUESTO' AS ORIGEN,\n           '[DWH_COMFENALCO].[Colegio].[DIM_PRESUPUESTO]' AS FUENTE_PRINCIPAL,\n           MAX(DP.POBL_PROYECT) AS POBL_PROYECT\n    FROM [DWH_COMFENALCO].[Colegio].[DIM_PRESUPUESTO] DP\n    INNER JOIN CalendarioMensualColegio CM ON DP.[ID_ANIO_PRESUPUESTO] = CM.A\u00f1oPresupuesto\n    GROUP BY DP.[ID_CURSO], DP.[GRADO], CM.ID_FECHA_MENSUAL\n),\nCoberturaProyectadaColegioMensual AS (\n    SELECT [ID_CURSO], [GRADO], 1 AS ID_UNIDAD, 4 AS CATEGORIA,\n           NULL AS ID_PLAN_COBERTURA, NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n           NULL AS ID_PROGRAMA, ID_FECHA_MENSUAL,\n           SUM(CAST(POBL_PROYECT AS INT)) AS POBLACION_PROYECTADA,\n           ORIGEN, FUENTE_PRINCIPAL\n    FROM CoberturaProyectadaColegio\n    GROUP BY [ID_CURSO], [GRADO], ID_FECHA_MENSUAL, ORIGEN, FUENTE_PRINCIPAL\n),\nFechasMensualesCedesarrollo AS (\n    SELECT A\u00f1o * 10000 + (Mes % 100) * 100 + 01 AS ID_FECHA_MENSUAL,\n           A\u00f1o, Mes,\n           CASE \n             WHEN (Mes % 100) BETWEEN 1 AND 6 THEN A\u00f1o * 10000 + 101\n             WHEN (Mes % 100) BETWEEN 7 AND 12 THEN A\u00f1o * 10000 + 701\n           END AS ID_FECHA_INICIO_SEMESTRE\n    FROM (\n        SELECT DISTINCT YEAR(pa.[FECHA_INICIO]) AS A\u00f1o\n        FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_PLAN_COBERTURA] up\n        LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] pa ON up.ID_PERIODO = pa.ID_PERIODO\n    ) AS Anios\n    CROSS JOIN (\n        SELECT 101 AS Mes UNION ALL SELECT 102 UNION ALL SELECT 103 UNION ALL\n        SELECT 104 UNION ALL SELECT 105 UNION ALL SELECT 106 UNION ALL\n        SELECT 107 UNION ALL SELECT 108 UNION ALL SELECT 109 UNION ALL\n        SELECT 110 UNION ALL SELECT 111 UNION ALL SELECT 112\n    ) AS Meses\n),\nCoberturaCedesarrollo AS (\n    SELECT FORMAT([FECHA_INICIO], 'yyyyMMdd') AS ID_FECHA_INICIO_SEMESTRE,\n           up.[ID_UNIDAD],\n           CASE \n             WHEN CATEGORIA IN ('A', 'Categor\u00eda_A', 'Categor\u00eda_ A') THEN 1\n             WHEN CATEGORIA IN ('B', 'Categor\u00eda_B', 'Categor\u00eda_ B') THEN 2\n             WHEN CATEGORIA IN ('C', 'Categor\u00eda_C', 'Categor\u00eda_ C') THEN 3\n             WHEN CATEGORIA IN ('D', 'Categor\u00eda_D', 'Categor\u00eda_ D') THEN 4\n             WHEN CATEGORIA = 'Convenios' THEN 10\n             WHEN CATEGORIA = 'Empresa Afiliada' THEN 5\n             WHEN CATEGORIA IN ('Fondo de Ley_FOSFEC', 'FOSFEC') THEN 6\n             ELSE 4\n           END AS CATEGORIA,\n           [ID_PROGRAMA], [USUARIOS_PROYECTADOS],\n           'FACT_PLAN_COBERTURA' AS ORIGEN,\n           '[DWH_COMFENALCO].[Cedesarrollo].[FACT_PLAN_COBERTURA]' AS FUENTE_PRINCIPAL\n    FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_PLAN_COBERTURA] up\n    LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] pa ON up.ID_PERIODO = pa.ID_PERIODO\n),\nCoberturaCedesarrolloMensual AS (\n    SELECT -1 AS ID_CURSO, NULL AS GRADO, COALESCE(ID_UNIDAD, 5) AS ID_UNIDAD,\n           CATEGORIA, NULL AS ID_PLAN_COBERTURA, NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n           ID_PROGRAMA, ID_FECHA_MENSUAL,\n           SUM(CAST(USUARIOS_PROYECTADOS AS INT)) AS POBLACION_PROYECTADA,\n           ORIGEN, FUENTE_PRINCIPAL\n    FROM CoberturaCedesarrollo cc\n    INNER JOIN FechasMensualesCedesarrollo fm ON cc.ID_FECHA_INICIO_SEMESTRE = fm.ID_FECHA_INICIO_SEMESTRE\n    GROUP BY ID_UNIDAD, CATEGORIA, ID_FECHA_MENSUAL, ID_PROGRAMA, ORIGEN, FUENTE_PRINCIPAL\n),\nCalendarioMensualProteccion AS (\n    SELECT A\u00f1oPresupuesto * 10000 + (Mes % 100) * 100 + 01 AS ID_FECHA_MENSUAL,\n           A\u00f1oPresupuesto, Mes\n    FROM (\n        SELECT DISTINCT [ANIO] AS A\u00f1oPresupuesto\n        FROM [DWH_COMFENALCO].[Proteccion].[FACT_PLAN_COBERTURA]\n    ) AS A\u00f1os\n    CROSS JOIN (\n        SELECT 101 AS Mes UNION ALL SELECT 102 UNION ALL SELECT 103 UNION ALL\n        SELECT 104 UNION ALL SELECT 105 UNION ALL SELECT 106 UNION ALL\n        SELECT 107 UNION ALL SELECT 108 UNION ALL SELECT 109 UNION ALL\n        SELECT 110 UNION ALL SELECT 111 UNION ALL SELECT 112\n    ) AS Meses\n),\nCoberturaProyectadaProteccion AS (\n    SELECT [ID_PLAN_COBERTURA], CM.ID_FECHA_MENSUAL,\n           [ID_ESTABLECIMIENTO_EDUCATIVO], [ID_PROGRAMA], [COBERTURA_PROYECTADA] AS POBLACION_PROYECTADA,\n           'FACT_PLAN_COBERTURA' AS ORIGEN,\n           '[DWH_COMFENALCO].[Proteccion].[FACT_PLAN_COBERTURA]' AS FUENTE_PRINCIPAL\n    FROM [DWH_COMFENALCO].[Proteccion].[FACT_PLAN_COBERTURA] pc\n    INNER JOIN CalendarioMensualProteccion CM ON pc.ANIO = CM.A\u00f1oPresupuesto\n),\nCoberturaProyectadaProteccionMensual AS (\n    SELECT -1 AS ID_CURSO, NULL AS GRADO, 4 AS ID_UNIDAD, 4 AS CATEGORIA,\n           ID_PLAN_COBERTURA, ID_ESTABLECIMIENTO_EDUCATIVO, ID_PROGRAMA,\n           ID_FECHA_MENSUAL, POBLACION_PROYECTADA, ORIGEN, FUENTE_PRINCIPAL\n    FROM CoberturaProyectadaProteccion\n),\nCoberturaProyectadaAdultoDiscapacidad AS (\n    SELECT -1 AS ID_CURSO, NULL AS GRADO, ID_UNIDAD, CATEGORIA_CCF AS CATEGORIA,\n           ID_REGISTRO AS ID_PLAN_COBERTURA, NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n           ID_PROGRAMA, ID_FECHA AS ID_FECHA_MENSUAL, NUM_PERSONAS_COBERTURA_SERVICIOS AS POBLACION_PROYECTADA,\n           'FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD' AS ORIGEN,\n           '[DWH_COMFENALCO].[Proteccion].[FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD]' AS FUENTE_PRINCIPAL\n    FROM [DWH_COMFENALCO].[Proteccion].[FACT_PLAN_COBERTURA_ADULTO_DISCAPACIDAD]\n)\nSELECT c.*, 'COBERTURA PROYECTADA' AS ACTIVIDAD FROM CoberturaProyectadaColegioMensual c\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM ON c.ID_FECHA_MENSUAL = dimM.ID_FECHA\nUNION ALL\nSELECT ce.*, 'COBERTURA PROYECTADA' FROM CoberturaCedesarrolloMensual ce\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM ON ce.ID_FECHA_MENSUAL = dimM.ID_FECHA\nUNION ALL\nSELECT p.*, 'COBERTURA PROYECTADA' FROM CoberturaProyectadaProteccionMensual p\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM ON p.ID_FECHA_MENSUAL = dimM.ID_FECHA\nUNION ALL\nSELECT ad.*, 'COBERTURA PROYECTADA' FROM CoberturaProyectadaAdultoDiscapacidad ad\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM ON ad.ID_FECHA_MENSUAL = dimM.ID_FECHA\n</code></pre>"},{"location":"03.Cubo/03.ETL/#procesar-fact_unidadessaber-11-individual","title":"Procesar FACT_UNIDADES\\Saber 11 Individual","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>Este componente del flujo de datos genera un consolidado mensual de resultados individuales de las pruebas SABER 11 a partir de registros acad\u00e9micos por estudiante. La informaci\u00f3n es transformada en un formato unificado y cargada en la tabla <code>Transversal.FACT_UNIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete_3","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p><code>Package &gt; Procesar FACT_UNIDADES &gt; Saber 11 Individual</code></p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_4","title":"Prop\u00f3sito del Componente","text":"<p>Permitir el an\u00e1lisis mensualizado de desempe\u00f1o educativo a nivel de grado und\u00e9cimo (SABER 11), cruzando resultados tem\u00e1ticos de las pruebas con estructura acad\u00e9mica, unidad organizativa y tiempo. Este flujo estandariza la salida para integrarse a reportes consolidados de cobertura y resultados educativos.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_22","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen:   Fuente de datos <code>DWH_COMFENALCO.Colegio.FACT_SABER11_INDIVIDUAL</code>, accedido mediante un <code>DataReaderSourceAdapter</code>.</p> </li> <li> <p>Destino:   Tabla de destino <code>Transversal.FACT_UNIDADES</code>, cargada mediante <code>ADO.NET Destination</code>.</p> </li> <li> <p>Transformaciones Clave:</p> <ul> <li>C\u00e1lculo del <code>RESULTADO_FINAL</code> por estudiante basado en la suma ponderada de temas.</li> <li>Consolidaci\u00f3n por a\u00f1o acad\u00e9mico con n\u00famero de estudiantes y conteo de altos desempe\u00f1os.</li> <li>Generaci\u00f3n mensual del identificador <code>ID_FECHA_MENSUAL</code> mediante expansi\u00f3n de 12 meses.</li> <li>Filtrado por meses v\u00e1lidos del mismo a\u00f1o mediante <code>DIM_TIEMPO_MENSUAL</code>.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_20","title":"L\u00f3gica de Negocio","text":"<ol> <li>Se agrupan resultados individuales por tem\u00e1tica y estudiante, calculando una puntuaci\u00f3n final ajustada.</li> <li>Se consolida el resultado anual a nivel de unidad educativa.</li> <li>Se replican los datos por cada mes del a\u00f1o acad\u00e9mico mediante <code>CROSS JOIN</code> con un generador de offset de meses.</li> <li>El resultado mensual se filtra por existencia en la dimensi\u00f3n de tiempo para asegurar integridad temporal.</li> </ol>"},{"location":"03.Cubo/03.ETL/#script-sql-de-extraccion_4","title":"Script SQL de Extracci\u00f3n","text":"<pre><code>WITH TematicaResultadosSaber11 AS (\n    SELECT MAX(ID_FECHA) AS ID_FECHA,\n           ANIO_ACADEMICO,\n           ID_POBLACION_MATRICULA,\n           UPPER(TEMATICA) AS TEMATICA,\n           MAX(RESULTADO) AS RESULTADO_MAXIMO\n    FROM Colegio.FACT_SABER11_INDIVIDUAL\n    GROUP BY ANIO_ACADEMICO, ID_POBLACION_MATRICULA, UPPER(TEMATICA)\n),\nCalculoResultadoSaber11 AS (\n    SELECT ANIO_ACADEMICO,\n           MAX(ID_FECHA) AS ID_FECHA,\n           ID_POBLACION_MATRICULA,\n           SUM(CASE \n                   WHEN TEMATICA IN ('LECTURA CR\u00cdTICA', 'MATEM\u00c1TICAS', 'SOCIALES', 'CIENCIAS NATURALES') THEN RESULTADO_MAXIMO * 3\n                   WHEN TEMATICA = 'INGL\u00c9S' THEN RESULTADO_MAXIMO\n                   ELSE 0\n               END) AS SUMA_RESULTADOS\n    FROM TematicaResultadosSaber11\n    GROUP BY ANIO_ACADEMICO, ID_POBLACION_MATRICULA\n),\nSaber11Individual AS (\n    SELECT ANIO_ACADEMICO,\n           ID_FECHA,\n           ID_POBLACION_MATRICULA,\n           (SUMA_RESULTADOS / 13.0) * 5 AS RESULTADO_FINAL\n    FROM CalculoResultadoSaber11\n),\nSaber11IndividualConsolidado AS (\n    SELECT 14 AS ID_CURSO,\n           'UNDECIMO' AS GRADO,\n           1 AS ID_UNIDAD,\n           NULL AS CATEGORIA,\n           NULL AS ID_PLAN_COBERTURA,\n           NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n           NULL AS ID_PROGRAMA,\n           LEFT(MAX(ID_FECHA), 6) * 100 + 1 AS ID_FECHA_MENSUAL,\n           NULL AS POBLACION_PROYECTADA,\n           'FACT_SABER11_INDIVIDUAL' AS ORIGEN,\n           '[DWH_COMFENALCO].[Colegio].[FACT_SABER11_INDIVIDUAL]' AS FUENTE_PRINCIPAL,\n           'SABER 11' AS ACTIVIDAD,\n           NULL AS RESULTADO,\n           NULL AS CATEGORIA_SABER11,\n           NULL AS CAUSA,\n           NULL AS NUM_POBLACION,\n           NULL AS CALIFICACION,\n           NULL AS DOCUMENTOS_COMPLETOS,\n           COUNT(DISTINCT ID_POBLACION_MATRICULA) AS NUM_ESTUDIANTES,\n           COUNT(DISTINCT CASE WHEN CAST(RESULTADO_FINAL AS INT) &gt;= 250 THEN ID_POBLACION_MATRICULA ELSE NULL END) AS NUM_MAYOR_250,\n           NULL AS TEMATICA\n    FROM Saber11Individual\n    GROUP BY ANIO_ACADEMICO\n),\nFechasGeneradas AS (\n    SELECT 0 AS MesOffset UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL\n    SELECT 4 UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL\n    SELECT 8 UNION ALL SELECT 9 UNION ALL SELECT 10 UNION ALL SELECT 11\n),\nSaber11IndividualMensual AS (\n    SELECT ID_CURSO, GRADO, ID_UNIDAD, CATEGORIA, ID_PLAN_COBERTURA, ID_ESTABLECIMIENTO_EDUCATIVO,\n           ID_PROGRAMA,\n           (LEFT(SIC.ID_FECHA_MENSUAL, 4) * 10000) + \n           (MONTH(DATEADD(MONTH, FG.MesOffset, CONVERT(DATE, CAST(SIC.ID_FECHA_MENSUAL AS CHAR(8))))) * 100) + 1 AS ID_FECHA_MENSUAL,\n           POBLACION_PROYECTADA, ORIGEN, FUENTE_PRINCIPAL, ACTIVIDAD, RESULTADO, CATEGORIA_SABER11,\n           CAUSA, NUM_POBLACION, CALIFICACION, DOCUMENTOS_COMPLETOS, NUM_ESTUDIANTES,\n           NUM_MAYOR_250, TEMATICA\n    FROM Saber11IndividualConsolidado SIC\n    CROSS JOIN FechasGeneradas FG\n    WHERE YEAR(DATEADD(MONTH, FG.MesOffset, CONVERT(DATE, CAST(SIC.ID_FECHA_MENSUAL AS CHAR(8))))) = LEFT(SIC.ID_FECHA_MENSUAL, 4)\n)\nSELECT s11.*\nFROM Saber11IndividualMensual s11\nINNER JOIN Transversal.DIM_TIEMPO_MENSUAL dimM ON s11.ID_FECHA_MENSUAL = dimM.ID_FECHA;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_19","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Se integra con el modelo de datos mensualizados en <code>FACT_UNIDADES</code>.</li> <li>Su estructura es compatible con otros procesos educativos como matriculas, psicorientaci\u00f3n, biblioteca, etc.</li> <li>Utiliza la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> como eje de an\u00e1lisis.</li> </ul>"},{"location":"03.Cubo/03.ETL/#procesar-fact_unidadessaber-11-colegio","title":"Procesar FACT_UNIDADES\\Saber 11 Colegio","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>El componente Saber 11 Colegio dentro del paquete <code>Procesar FACT_UNIDADES</code> transforma datos de resultados acad\u00e9micos del examen SABER 11 para una instituci\u00f3n educativa espec\u00edfica (c\u00f3digo 313001003095), replicando sus valores a lo largo de los 12 meses del a\u00f1o y cargando dicha informaci\u00f3n en la tabla <code>Transversal.FACT_UNIDADES</code> del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_13","title":"Ubicaci\u00f3n en el Paquete","text":"<p><code>Package\\Procesar FACT_UNIDADES\\Saber 11 Colegio</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_18","title":"Prop\u00f3sito","text":"<p>Documentar y replicar mensualmente la informaci\u00f3n del examen SABER 11 de un colegio, permitiendo su an\u00e1lisis en un modelo de series de tiempo a nivel de unidad educativa y periodo mensual.</p>"},{"location":"03.Cubo/03.ETL/#implementacion-tecnica","title":"Implementaci\u00f3n T\u00e9cnica","text":"<ul> <li>Origen de Datos: Consulta SQL sobre la tabla <code>[DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS]</code> para un solo establecimiento (<code>COD_ESTABLECIMIENTO_EDUCATIVO = 313001003095</code>).</li> <li> <p>Transformaci\u00f3n:</p> <ul> <li>Los datos se replican usando una CTE <code>FechasGeneradas</code> que simula los 12 meses del a\u00f1o.</li> <li>Se recalcula <code>ID_FECHA_MENSUAL</code> para expandir un \u00fanico registro anual a registros mensuales usando <code>DATEADD</code> y <code>CROSS JOIN</code>.</li> <li>Se filtran los meses que coincidan con el a\u00f1o original del dato.</li> </ul> </li> <li> <p>Destino: Tabla <code>Transversal.FACT_UNIDADES</code> a trav\u00e9s de un componente ADO.NET Destination.</p> </li> <li>Control de Errores: Definidas salidas de error en caso de fallos de conversi\u00f3n o truncamiento.</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_21","title":"L\u00f3gica de Negocio","text":"<ul> <li>Cada resultado SABER 11 anual se convierte en 12 registros mensuales, uno por mes.</li> <li>Se conserva la trazabilidad con campos como <code>RESULTADO</code>, <code>CATEGORIA_SABER11</code> y <code>FUENTE_PRINCIPAL</code>.</li> <li>Se utiliza una combinaci\u00f3n fija de identificadores: <code>ID_CURSO = 14</code>, <code>GRADO = UNDECIMO</code>, <code>ID_UNIDAD = 1</code>.</li> <li>La dimensi\u00f3n de tiempo mensual es verificada cruzando <code>ID_FECHA_MENSUAL</code> con <code>DIM_TIEMPO_MENSUAL</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_20","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Depende del contenido de la tabla <code>[Colegio].[FACT_SABER11_COLEGIOS]</code>.</li> <li>Alimenta el cubo de cobertura educativa consolidada en <code>FACT_UNIDADES</code>.</li> <li>Se integra con otros flujos que procesan datos proyectados, reales y categorizados por actividad y programa.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-utilizado_2","title":"Script SQL Utilizado","text":"<pre><code>WITH Saber11Colegio as (\n  SELECT 14 as ID_CURSO,\n         'UNDECIMO' as GRADO,\n         1 AS ID_UNIDAD,\n         NULL AS CATEGORIA,\n         NULL AS ID_PLAN_COBERTURA,\n         [COD_ESTABLECIMIENTO_EDUCATIVO] AS ID_ESTABLECIMIENTO_EDUCATIVO,\n         NULL AS ID_PROGRAMA,\n         LEFT([ID_FECHA],6)*100+1 as ID_FECHA_MENSUAL,\n         NULL AS POBLACION_PROYECTADA,\n         'FACT_SABER11_COLEGIOS_CEC' AS ORIGEN,\n         '[DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS]' as FUENTE_PRINCIPAL,\n         'SABER 11' as ACTIVIDAD,\n         [RESULTADO],\n         [CATEGORIA_SABER11],\n         NULL as CAUSA,\n         NULL as NUM_POBLACION,\n         NULL as CALIFICACION,\n         NULL as DOCUMENTOS_COMPLETOS,\n         NULL as NUM_ESTUDIANTES,\n         NULL as NUM_MAYOR_250,\n         NULL as TEMATICA\n  FROM [DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS]\n  WHERE [COD_ESTABLECIMIENTO_EDUCATIVO] = 313001003095\n),\nFechasGeneradas AS (\n  SELECT 0 AS MesOffset UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL \n  SELECT 3 UNION ALL SELECT 4 UNION ALL SELECT 5 UNION ALL \n  SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL \n  SELECT 9 UNION ALL SELECT 10 UNION ALL SELECT 11\n),\nSaber11ColegioMensual as (\n  SELECT ID_CURSO,\n         GRADO,\n         ID_UNIDAD,\n         CATEGORIA,\n         ID_PLAN_COBERTURA,\n         ID_ESTABLECIMIENTO_EDUCATIVO,\n         ID_PROGRAMA,\n         (LEFT(SIC.ID_FECHA_MENSUAL, 4) * 10000) + \n         ((MONTH(DATEADD(MONTH, FG.MesOffset, CONVERT(DATE, CAST(SIC.ID_FECHA_MENSUAL AS CHAR(8))))) * 100)) + 1 AS ID_FECHA_MENSUAL,\n         POBLACION_PROYECTADA,\n         ORIGEN,\n         FUENTE_PRINCIPAL,\n         ACTIVIDAD,\n         RESULTADO,\n         CATEGORIA_SABER11,\n         CAUSA,\n         NUM_POBLACION,\n         CALIFICACION,\n         DOCUMENTOS_COMPLETOS,\n         NUM_ESTUDIANTES,\n         NUM_MAYOR_250,\n         TEMATICA\n  FROM Saber11Colegio SIC\n  CROSS JOIN FechasGeneradas FG\n  WHERE YEAR(DATEADD(MONTH, FG.MesOffset, CONVERT(DATE, CAST(SIC.ID_FECHA_MENSUAL AS CHAR(8))))) = LEFT(SIC.ID_FECHA_MENSUAL, 4)\n)\nSELECT s11.*\nFROM Saber11ColegioMensual s11\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM\n  ON s11.ID_FECHA_MENSUAL = dimM.ID_FECHA\n</code></pre>"},{"location":"03.Cubo/03.ETL/#procesar-fact_unidadesdesercion-aipi-y-jec","title":"Procesar FACT_UNIDADES\\Desercion AIPI y JEC","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>Este componente carga mensualmente informaci\u00f3n de deserci\u00f3n del programa de protecci\u00f3n social, espec\u00edficamente de los programas AIPI y Jornada Escolar Complementaria (JEC), desde la tabla <code>FACT_DESERCION</code>. El proceso consolida esta informaci\u00f3n y la transforma para integrarla en el modelo de unidades operativas del data warehouse.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete_4","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p><code>Procesar FACT_UNIDADES</code> \u2192 <code>Desercion AIPI y JEC</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_19","title":"Prop\u00f3sito","text":"<p>Integrar registros consolidados de deserci\u00f3n educativa por unidad, programa, causa y fecha, permitiendo monitorear causas de abandono y generar indicadores mensuales en la tabla <code>Transversal.FACT_UNIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_23","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen de Datos:   SQL Server \u2192 Tabla <code>[DWH_COMFENALCO].[Proteccion].[FACT_DESERCION]</code>   Consulta T-SQL con agregaci\u00f3n (<code>COUNT DISTINCT</code>) y transformaci\u00f3n de fechas a <code>ID_FECHA_MENSUAL</code>.</p> </li> <li> <p>Destino de Datos:   Tabla: <code>Transversal.FACT_UNIDADES</code>   Modo de carga: ADO.NET con <code>UseBulkInsertWhenPossible = true</code>.</p> </li> <li> <p>Componentes del Data Flow:</p> <ul> <li> <p>Origen: <code>unidades</code></p> <ul> <li>Tipo: <code>DataReader Source</code></li> <li>Usa CTE <code>DesercionProteccion</code> para estructurar los datos.</li> </ul> </li> <li> <p>Destino: <code>Destino de ADO NET</code></p> <ul> <li>Tabla objetivo: <code>Transversal.FACT_UNIDADES</code></li> <li>Inserta columnas: <code>ID_UNIDAD</code>, <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>, <code>ID_PROGRAMA</code>, <code>ID_FECHA_MENSUAL</code>, <code>ORIGEN</code>, <code>FUENTE_PRINCIPAL</code>, <code>ACTIVIDAD</code>, <code>CAUSA</code>, <code>NUM_POBLACION</code>.</li> </ul> </li> </ul> </li> <li> <p>Uni\u00f3n con Dimensi\u00f3n de Tiempo:   Se realiza un <code>INNER JOIN</code> con <code>Transversal.DIM_TIEMPO_MENSUAL</code> para asegurar la validez temporal del dato.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_22","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Filtro y Transformaci\u00f3n:   Convierte fechas <code>ID_FECHA</code> a formato <code>ID_FECHA_MENSUAL</code>. Se agrupan los registros por combinaci\u00f3n de establecimiento, programa y causa de deserci\u00f3n.</p> </li> <li> <p>Asignaci\u00f3n de Unidad:   Se asigna un identificador fijo (<code>ID_UNIDAD = 4</code>) para representar la unidad del dominio de protecci\u00f3n social.</p> </li> <li> <p>Normalizaci\u00f3n del Origen y Actividad:   Se define <code>ORIGEN = 'FACT_DESERCION'</code>, <code>FUENTE_PRINCIPAL = '[DWH_COMFENALCO].[Proteccion].[FACT_DESERCION]'</code> y <code>ACTIVIDAD = 'DESERCION'</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_21","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Este flujo es uno de varios que alimentan la tabla <code>FACT_UNIDADES</code>, cada uno especializado por dominio (ej. educaci\u00f3n, discapacidad, protecci\u00f3n). La unificaci\u00f3n final permite an\u00e1lisis comparativos por unidad, programa y periodo.</p>"},{"location":"03.Cubo/03.ETL/#script-sql-utilizado_3","title":"Script SQL Utilizado","text":"<pre><code>WITH DesercionProteccion AS (\n  SELECT \n     4 AS ID_UNIDAD,\n     ID_ESTABLECIMIENTO_EDUCATIVO,\n     ID_PROGRAMA,\n     ID_FECHA_MENSUAL,\n     ORIGEN,\n     FUENTE_PRINCIPAL,\n     ACTIVIDAD,\n     [CAUSA],\n     COUNT(DISTINCT([ID_POBLACION])) as NUM_POBLACION\n  FROM (\n    SELECT \n      CAST(ID_ESTABLECIMIENTO_EDUCATIVO AS nvarchar(40)) as ID_ESTABLECIMIENTO_EDUCATIVO,\n      ID_PROGRAMA,\n      LEFT([ID_FECHA],6)*100+1 as ID_FECHA_MENSUAL,\n      'FACT_DESERCION' AS ORIGEN,\n      '[DWH_COMFENALCO].[Proteccion].[FACT_DESERCION]' as FUENTE_PRINCIPAL,\n      'DESERCION' as ACTIVIDAD,\n      [CAUSA],\n      [ID_POBLACION]\n    FROM [DWH_COMFENALCO].[Proteccion].[FACT_DESERCION]\n  ) ll\n  GROUP BY  \n    ID_ESTABLECIMIENTO_EDUCATIVO,\n    ID_PROGRAMA,\n    ID_FECHA_MENSUAL,\n    ORIGEN,\n    FUENTE_PRINCIPAL,\n    ACTIVIDAD,\n    [CAUSA]\n)\nSELECT dp.*\nFROM DesercionProteccion dp\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM\n  ON dp.ID_FECHA_MENSUAL = dimM.ID_FECHA\n</code></pre>"},{"location":"03.Cubo/03.ETL/#procesar-fact_unidadesevaluacion-curricular-cedesarrollo","title":"Procesar FACT_UNIDADES\\Evaluacion Curricular Cedesarrollo","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>Este componente transforma y consolida informaci\u00f3n de evaluaci\u00f3n de dise\u00f1o curricular realizada por la unidad Cedesarrollo, convirtiendo registros semestrales en valores mensuales dentro del Data Warehouse. La informaci\u00f3n alimenta la tabla <code>FACT_UNIDADES</code> para an\u00e1lisis longitudinales de desempe\u00f1o acad\u00e9mico.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete_5","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p><code>Procesar FACT_UNIDADES</code> \u2192 <code>Evaluacion Curricular Cedesarrollo</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_20","title":"Prop\u00f3sito","text":"<p>Incorporar las calificaciones obtenidas en evaluaciones de dise\u00f1o curricular del programa Cedesarrollo, asociando dichas calificaciones a fechas mensuales mediante una correspondencia con periodos acad\u00e9micos definidos semestralmente.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_24","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen de Datos:   SQL Server \u2192 Tabla: <code>[DWH_COMFENALCO].[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]</code>   Consulta con <code>WITH</code> para estructurar las fechas de inicio de semestre y mapeo a calendario mensual (<code>DIM_TIEMPO_MENSUAL</code>).</p> </li> <li> <p>Destino de Datos:   Tabla: <code>Transversal.FACT_UNIDADES</code>   Tipo de carga: ADO.NET con <code>UseBulkInsertWhenPossible = true</code>.</p> </li> <li> <p>Columnas cargadas:</p> <ul> <li><code>ID_FECHA_MENSUAL</code></li> <li><code>ID_UNIDAD</code></li> <li><code>ORIGEN</code></li> <li><code>FUENTE_PRINCIPAL</code></li> <li><code>ACTIVIDAD</code></li> <li><code>CALIFICACION</code></li> </ul> </li> <li> <p>Asignaci\u00f3n de Unidad: <code>ID_UNIDAD</code> se obtiene con <code>COALESCE(fep.ID_UNIDAD, 5)</code> como valor predeterminado para Cedesarrollo.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_23","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Semestral a Mensual:   Se genera un rango completo de fechas mensuales (<code>FechasMensualesCedesarrollo</code>) y se mapean con el inicio de semestre de cada evaluaci\u00f3n (<code>ID_FECHA_INICIO_SEMESTRE</code>) para construir <code>ID_FECHA_MENSUAL</code>.</p> </li> <li> <p>Normalizaci\u00f3n de Valores:</p> <ul> <li><code>ORIGEN = 'FACT_EVALUACION_PLAN_CURRICULAR'</code></li> <li><code>FUENTE_PRINCIPAL = '[DWH_COMFENALCO].[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]'</code></li> <li><code>ACTIVIDAD = 'EVALUACION DISENO CURRICULAR'</code></li> </ul> </li> <li> <p>Condiciones Especiales:   Se realiza un <code>LEFT JOIN</code> con fechas de inicio semestral para asegurar que cada calificaci\u00f3n sea representada correctamente en la dimensi\u00f3n mensual.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_22","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Este flujo complementa otros del paquete <code>FACT_UNIDADES</code>, enfoc\u00e1ndose en la dimensi\u00f3n formativa de los programas. Es crucial para consolidar indicadores de calidad acad\u00e9mica y seguimiento al dise\u00f1o curricular en la unidad de Cedesarrollo.</p>"},{"location":"03.Cubo/03.ETL/#script-sql-utilizado_4","title":"Script SQL Utilizado","text":"<pre><code>WITH EvaluacionCurricular AS (\n  SELECT \n    COALESCE(fep.ID_UNIDAD, 5) AS ID_UNIDAD,\n    FORMAT([FECHA_INICIO], 'yyyyMMdd') AS ID_FECHA_INICIO_SEMESTRE,\n    'FACT_EVALUACION_PLAN_CURRICULAR' AS ORIGEN,\n    '[DWH_COMFENALCO].[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]' AS FUENTE_PRINCIPAL,\n    'EVALUACION DISENO CURRICULAR' AS ACTIVIDAD,\n    [CALIFICACION]\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR] fep\n  LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] pa\n    ON fep.ID_PERIODO = pa.ID_PERIODO\n),\nFechasMensualesCedesarrollo AS (\n  SELECT \n    A\u00f1o * 10000 + (Mes % 100) * 100 + 01 AS ID_FECHA_MENSUAL,\n    A\u00f1o,\n    Mes,\n    CASE \n      WHEN (Mes % 100) BETWEEN 1 AND 6 THEN A\u00f1o * 10000 + 101\n      WHEN (Mes % 100) BETWEEN 7 AND 12 THEN A\u00f1o * 10000 + 701\n    END AS ID_FECHA_INICIO_SEMESTRE\n  FROM (\n    SELECT DISTINCT YEAR(pa.FECHA_INICIO) AS A\u00f1o\n    FROM [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] pa\n  ) AS Anios\n  CROSS JOIN (\n    SELECT 101 AS Mes UNION ALL SELECT 102 UNION ALL SELECT 103 UNION ALL SELECT 104 UNION ALL \n    SELECT 105 UNION ALL SELECT 106 UNION ALL SELECT 107 UNION ALL SELECT 108 UNION ALL \n    SELECT 109 UNION ALL SELECT 110 UNION ALL SELECT 111 UNION ALL SELECT 112\n  ) AS Meses\n)\nSELECT fm.ID_FECHA_MENSUAL, e.*\nFROM EvaluacionCurricular e\nLEFT JOIN FechasMensualesCedesarrollo fm ON e.ID_FECHA_INICIO_SEMESTRE = fm.ID_FECHA_INICIO_SEMESTRE\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM ON fm.ID_FECHA_MENSUAL = dimM.ID_FECHA\n</code></pre>"},{"location":"03.Cubo/03.ETL/#procesar-fact_unidadesdocumentos-completos-cedesarrollo","title":"Procesar FACT_UNIDADES\\Documentos Completos Cedesarrollo","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>Este componente del flujo de datos transforma y consolida informaci\u00f3n mensual sobre el estado de documentaci\u00f3n completa de estudiantes del programa Cedesarrollo, calculando la cantidad de estudiantes y registrando dicha condici\u00f3n documental en la tabla <code>FACT_UNIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete_6","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p><code>Procesar FACT_UNIDADES</code> \u2192 <code>Documentos Completos Cedesarrollo</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_21","title":"Prop\u00f3sito","text":"<p>Determinar y cargar indicadores mensuales asociados al estado de documentos completos de los estudiantes registrados en matr\u00edculas de Cedesarrollo, permitiendo hacer seguimiento a la formalizaci\u00f3n acad\u00e9mica dentro del sistema educativo.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_25","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen de Datos:   Tabla fuente: <code>[DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS]</code>   Consulta agrupada por unidad, fecha mensual y estado documental (<code>DOCUMENTOS_COMPLETOS</code>).</p> </li> <li> <p>Destino de Datos:   Tabla destino: <code>Transversal.FACT_UNIDADES</code>   Cargado mediante componente ADO.NET con <code>UseBulkInsertWhenPossible = true</code>.</p> </li> <li> <p>Columnas cargadas:</p> <ul> <li><code>ID_UNIDAD</code></li> <li><code>ID_FECHA_MENSUAL</code></li> <li><code>ORIGEN</code></li> <li><code>FUENTE_PRINCIPAL</code></li> <li><code>ACTIVIDAD</code></li> <li><code>DOCUMENTOS_COMPLETOS</code></li> <li><code>NUM_ESTUDIANTES</code></li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_24","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Normalizaci\u00f3n temporal:   La fecha de corte mensual (<code>ID_FECHA_MENSUAL</code>) se calcula como <code>LEFT(ID_FECHA,6)*100 + 1</code>, asignando el primer d\u00eda del mes.</p> </li> <li> <p>Agrupaci\u00f3n:   Se agrupan registros por unidad, mes y valor de <code>DOCUMENTOS_COMPLETOS</code>, contando los estudiantes \u00fanicos por grupo.</p> </li> <li> <p>Estandarizaci\u00f3n de atributos:</p> <ul> <li><code>ORIGEN = 'FACT_ESTADO_MATRICULAS'</code></li> <li><code>FUENTE_PRINCIPAL = '[DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS]'</code></li> <li><code>ACTIVIDAD = 'MATRICULAS_ESTUDIANTES'</code></li> </ul> </li> <li> <p>Filtrado de fechas v\u00e1lidas:   Solo se cargan datos con <code>ID_FECHA_MENSUAL</code> presentes en la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_23","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Este componente alimenta la misma tabla de hechos (<code>FACT_UNIDADES</code>) que otros subprocesos del paquete, pero se enfoca en indicadores de formalizaci\u00f3n documental, cruciales para validar procesos de matr\u00edcula y cumplimiento de requisitos por parte de los estudiantes.</p>"},{"location":"03.Cubo/03.ETL/#script-sql-utilizado_5","title":"Script SQL Utilizado","text":"<pre><code>WITH DocumentosCompletos AS (\n  SELECT  \n    dp.ID_UNIDAD,\n    LEFT(ID_FECHA,6)*100+1 AS ID_FECHA_MENSUAL,\n    'FACT_ESTADO_MATRICULAS' AS ORIGEN,\n    '[DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS]' AS FUENTE_PRINCIPAL,\n    'MATRICULAS_ESTUDIANTES' AS ACTIVIDAD,\n    DOCUMENTOS_COMPLETOS,\n    COUNT(DISTINCT(ID_ESTUDIANTE)) AS NUM_ESTUDIANTES\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS] fc\n  INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] dp \n    ON fc.ID_PERIODO = dp.ID_PERIODO\n  GROUP BY dp.ID_UNIDAD, LEFT(ID_FECHA,6)*100+1, DOCUMENTOS_COMPLETOS\n)\nSELECT dc.*\nFROM DocumentosCompletos dc\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM \n  ON dc.ID_FECHA_MENSUAL = dimM.ID_FECHA\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_colegiotruncar-tabla","title":"FACT_MINERIA\\MINERIA_COLEGIO\\Truncar Tabla","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>Este componente es una tarea de tipo <code>Execute SQL Task</code> cuya funci\u00f3n principal es eliminar todos los registros existentes en la tabla de hechos <code>FACT_MINERIA</code> antes de realizar una nueva carga de datos. Esta operaci\u00f3n asegura que los datos cargados sean siempre actualizados y sin duplicaciones.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete_7","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p><code>FACT_MINERIA</code> \u2192 <code>MINERIA_COLEGIO</code> \u2192 <code>Truncar Tabla</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_22","title":"Prop\u00f3sito","text":"<p>Garantizar una limpieza total de la tabla <code>FACT_MINERIA</code> del esquema <code>Transversal</code> en el Data Warehouse <code>DWH_COMFENALCO</code>, eliminando cualquier residuo de ejecuciones anteriores y habilitando una carga limpia y confiable de los nuevos datos minados desde otras fuentes educativas.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_26","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Tipo de tarea: <code>Execute SQL Task</code></li> <li>Conexi\u00f3n utilizada: Administrador de conexi\u00f3n con ID <code>{29BC876E-1EAF-4F6F-8F38-39B8E881EEB6}</code> apuntando a <code>DWH_COMFENALCO</code></li> <li>Comando ejecutado:</li> </ul> <p><pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_MINERIA];\n</code></pre> * Efecto del comando:   Borra todos los registros de la tabla <code>FACT_MINERIA</code> de manera r\u00e1pida y sin registrar logs de transacci\u00f3n fila por fila, lo cual mejora el rendimiento en grandes vol\u00famenes de datos.</p>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_25","title":"L\u00f3gica de Negocio","text":"<p>Esta tarea no contiene l\u00f3gica condicional ni validaciones adicionales. Su ejecuci\u00f3n es determinista y obligatoria cada vez que se inicia el proceso de carga para asegurar la integridad y unicidad de los datos de miner\u00eda educativa.</p>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_24","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Es una tarea inicial que prepara la tabla <code>FACT_MINERIA</code> para ser poblada por flujos posteriores dentro del mismo subproceso <code>MINERIA_COLEGIO</code>. Su correcta ejecuci\u00f3n es cr\u00edtica para evitar duplicidades o inconsistencias en los an\u00e1lisis mineros posteriores.</p>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_colegioproceso-matricula-temporal","title":"FACT_MINERIA\\MINERIA_COLEGIO\\Proceso Matr\u00edcula (Temporal)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_24","title":"Descripci\u00f3n General","text":"<p>Este componente SSIS ejecuta una consulta compleja sobre la tabla <code>FACT_INSCRIPCION_MATRICULAS</code> del dominio educativo, integrando indicadores clave del proceso de matr\u00edcula escolar en una tabla temporal (<code>TMP_PROCESO_MATRICULA_COLEGIO</code>). Se incluyen indicadores por rol (codeudor, secretaria acad\u00e9mica, psicolog\u00eda, coordinaci\u00f3n acad\u00e9mica) y estados del proceso de admisi\u00f3n.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete_8","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p>Paquete: <code>FACT_MINERIA</code> Subcarpeta: <code>MINERIA_COLEGIO</code> Tarea: <code>Proceso Matr\u00edcula (Temporal)</code> Tipo: Tarea de flujo de datos (<code>Data Flow Task</code>)</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_5","title":"Prop\u00f3sito del Componente","text":"<p>Cargar una vista temporal consolidada de procesos de matr\u00edcula que permita medir la participaci\u00f3n y gesti\u00f3n de diferentes actores del proceso acad\u00e9mico (codeudor, psicolog\u00eda, coordinaci\u00f3n, secretaria acad\u00e9mica), as\u00ed como su estado (en proceso, admitido, desistido, etc.), para an\u00e1lisis posteriores en la miner\u00eda de datos educativa.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_27","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen de Datos:</p> <ul> <li>Tabla: <code>[DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS]</code></li> <li>Conectividad: ADO.NET a trav\u00e9s de <code>ConnectionManager</code> a <code>DWH_COMFENALCO</code>.</li> <li>L\u00f3gica: Se utilizan subconsultas con <code>OUTER APPLY</code>, <code>PIVOT</code>, <code>MAX</code>, <code>COUNT</code> e indicadores l\u00f3gicos (<code>CASE</code>) para transformar los estados del proceso de inscripci\u00f3n en indicadores anal\u00edticos.</li> </ul> </li> <li> <p>Destino de Datos:</p> <ul> <li>Tabla: <code>Transversal.TMP_PROCESO_MATRICULA_COLEGIO</code></li> <li>Conectividad: ADO.NET con <code>STAGE_AREA</code></li> <li>Se utiliza inserci\u00f3n masiva (<code>UseBulkInsertWhenPossible = true</code>) para mejorar rendimiento.</li> </ul> </li> <li> <p>Configuraci\u00f3n adicional:</p> <ul> <li>Timeout de comandos: 30 segundos.</li> <li>No se define un tama\u00f1o de lote espec\u00edfico (<code>BatchSize = 0</code>).</li> <li>Se manejan errores de conversi\u00f3n como <code>FailComponent</code>.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_26","title":"L\u00f3gica de Negocio","text":"<ol> <li>Extracci\u00f3n de las inscripciones acad\u00e9micas v\u00e1lidas (excluyendo ciertos estados).</li> <li>Transformaci\u00f3n mediante agregaciones (<code>MAX</code>, <code>COUNT</code>), indicadores booleanos y c\u00e1lculos de cumplimiento.</li> <li>Segmentaci\u00f3n por actores clave del proceso de matr\u00edcula.</li> <li>Carga en una tabla temporal para uso en etapas posteriores de an\u00e1lisis o carga en el DWH final.</li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_25","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Este proceso prepara los datos para una posterior integraci\u00f3n dentro de un modelo de miner\u00eda de procesos educativos o para alimentar el componente <code>FACT_MINERIA_ESTUDIANTE</code> como parte del an\u00e1lisis transversal del ciclo educativo.</p>"},{"location":"03.Cubo/03.ETL/#script-sql-del-origen-consulta-principal","title":"Script SQL del Origen (Consulta Principal)","text":"<pre><code>-----------------------------------------------------------------------------------------------------------\n-- FT FACT_INSCRIPCION_MATRICULAS   \n-----------------------------------------------------------------------------------------------------------\n\n\n    SELECT  FT.ID_FECHA,FT.ID_ANIO_ACADEMICO,FT.BP,FT.ID_CATEGORIA,FT.ID_CURSO,FT.ID_TIPO_ESTUDIANTE,\n\n            CASE WHEN FT2.[1] IS NULL THEN 0 ELSE 1 END AS IND_CODEUDOR,\n            CASE WHEN FT2.[1] =FT4.T_TOTAL_GESTION AND ISNULL(Ft3.IND_CUMPLIMIENTO,1)=0  THEN 0 ELSE 1 END AS P_CODEUDOR,\n            FT2.[1] AS T_CODEUDOR,\n\n            CASE WHEN FT2.[3] IS NULL THEN 0 ELSE 1 END AS IND_SECRETARIA_ACADEMICA,\n            CASE WHEN FT2.[3] =FT4.T_TOTAL_GESTION AND ISNULL(Ft3.IND_CUMPLIMIENTO,1)=0  THEN 0 ELSE 1 END AS P_SECRETARIA_ACADEMICA,\n            FT2.[3] AS T_SECRETARIA_ACADEMICA,\n\n            CASE WHEN FT2.[4] IS NULL THEN 0 ELSE 1 END AS IND_PSICOLOGIA,\n            CASE WHEN FT2.[4] =FT4.T_TOTAL_GESTION AND ISNULL(Ft3.IND_CUMPLIMIENTO,1)=0  THEN 0 ELSE 1 END AS P_PSICOLOGIA,\n            FT2.[4] AS T_PSICOLOGIA,\n\n\n            CASE WHEN FT2.[5] IS NULL THEN 0 ELSE 1 END AS IND_COORDINACION_ACADEMICA,\n            CASE WHEN FT2.[5] =FT4.T_TOTAL_GESTION AND ISNULL(Ft3.IND_CUMPLIMIENTO,1)=0  THEN 0 ELSE 1 END AS P_COORDINACION_ACADEMICA,\n            FT2.[5] AS T_COORDINACION_ACADEMICA,\n\n            1 AS INDICADOR,\n            FT4.T_TOTAL_GESTION,\n\n            ISNULL(Ft3.IND_CUMPLIMIENTO,1)  AS  IND_CUMPLIMIENTO,\n            ISNULL(FT5.IND_EN_PROCESO,0)    AS  IND_EN_PROCESO,\n            ISNULL(FT5.IND_ADMITIDO,0)      AS  IND_ADMITIDO,\n            ISNULL(FT5.IND_NO_ADMITIDO,0)   AS  IND_NO_ADMITIDO,\n            ISNULL(FT5.IND_DESISTIDO,0)     AS  IND_DESISTIDO\n\n    FROM\n    (\n\n        SELECT  T.ID_FECHA,\n                MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                MT.BP,\n                CA.ID_CATEGORIA,\n                CS.ID_CURSO,\n                ES.ID_TIPO_ESTUDIANTE\n\n\n        FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT \n        JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n        JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION]  EG  ON   EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO]  EP  ON   EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA  ON  EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n        JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS            ON  CS.ID_CURSO = MT.ID_CURSO\n        JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES  ON  ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED  ON  ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n        JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n\n        WHERE MT.ID_ESTADO_PROCESO !=11 AND MT.ID_TIPO_ESTUDIANTE != 2  \n        GROUP BY T.ID_FECHA,\n                MT.ANIO_ACADEMICO,\n                MT.BP,\n                CA.ID_CATEGORIA,\n                CS.ID_CURSO,\n                ES.ID_TIPO_ESTUDIANTE\n\n    )FT\n    OUTER APPLY\n    (\n        SELECT [1],[3],[4],[5],[11],[-1]\n        FROM\n        (\n\n            SELECT  T.ID_FECHA,\n                    MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                    MT.BP,\n                    CA.ID_CATEGORIA,\n                    CS.ID_CURSO,\n                    ES.ID_TIPO_ESTUDIANTE,\n                    EP.ID_ESTADO_PROCESO,\n                    SUM(MT.TIEMPO_GESTION_SEGUNDO_DIA_HABIL) AS TIEMPO_GESTION_SEGUNDO_DIA_HABIL\n\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT \n            JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n            JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION]  EG  ON   EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO]  EP  ON   EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA  ON  EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS            ON  CS.ID_CURSO = MT.ID_CURSO\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES  ON  ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED  ON  ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n\n\n            WHERE   MT.ID_ESTADO_PROCESO !=11\n                AND FT.ID_FECHA = MT.ID_FECHA\n                AND FT.ID_ANIO_ACADEMICO = MT.ANIO_ACADEMICO\n                AND FT.BP = MT.BP\n                AND FT.ID_CURSO = MT.ID_CURSO\n                AND FT.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n\n\n        GROUP BY T.ID_FECHA,\n                MT.ANIO_ACADEMICO,\n                MT.BP,\n                CA.ID_CATEGORIA,\n                CS.ID_CURSO,\n                ES.ID_TIPO_ESTUDIANTE,\n                EP.ID_ESTADO_PROCESO\n        )FT1\n        PIVOT (SUM(TIEMPO_GESTION_SEGUNDO_DIA_HABIL) FOR ID_ESTADO_PROCESO IN ([1],[3],[4],[5],[11],[-1])) as PVT   \n\n    )FT2\n\n    OUTER APPLY\n    (\n        SELECT IND_CUMPLIMIENTO\n        FROM\n        (\n\n            SELECT  T.ID_FECHA,\n                    MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                    MT.BP,\n                    CA.ID_CATEGORIA,\n                    CS.ID_CURSO,\n                    ES.ID_TIPO_ESTUDIANTE,\n                    0 AS IND_CUMPLIMIENTO \n\n\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT \n            JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n            JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION]  EG  ON   EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO]  EP  ON   EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA  ON  EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS            ON  CS.ID_CURSO = MT.ID_CURSO\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES  ON  ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED  ON  ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n\n\n            WHERE   MT.ID_ESTADO_PROCESO !=11\n                AND FT.ID_FECHA = MT.ID_FECHA\n                AND FT.ID_ANIO_ACADEMICO = MT.ANIO_ACADEMICO\n                AND FT.BP = MT.BP\n                AND FT.ID_CURSO = MT.ID_CURSO\n                AND FT.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                AND cast(mt.FECHA_GESTION AS date) = '1900-01-01'\n\n\n        GROUP BY T.ID_FECHA,\n                MT.ANIO_ACADEMICO,\n                MT.BP,\n                CA.ID_CATEGORIA,\n                CS.ID_CURSO,\n                ES.ID_TIPO_ESTUDIANTE\n\n        )FT1\n\n    )FT3\n\n    OUTER APPLY\n    (\n        SELECT T_TOTAL_GESTION\n        FROM\n        (\n\n            SELECT  T.ID_FECHA,\n                    MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                    MT.BP,\n                    CA.ID_CATEGORIA,\n                    CS.ID_CURSO,\n                    ES.ID_TIPO_ESTUDIANTE,\n                    MAX(TIEMPO_GESTION_SEGUNDO_DIA_HABIL) AS T_TOTAL_GESTION\n\n\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT \n            JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n            JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION]  EG  ON   EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO]  EP  ON   EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA  ON  EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS            ON  CS.ID_CURSO = MT.ID_CURSO\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES  ON  ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED  ON  ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n\n\n            WHERE   MT.ID_ESTADO_PROCESO !=11\n                AND FT.ID_FECHA = MT.ID_FECHA\n                AND FT.ID_ANIO_ACADEMICO = MT.ANIO_ACADEMICO\n                AND FT.BP = MT.BP\n                AND FT.ID_CURSO = MT.ID_CURSO\n                AND FT.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n\n\n        GROUP BY T.ID_FECHA,\n                MT.ANIO_ACADEMICO,\n                MT.BP,\n                CA.ID_CATEGORIA,\n                CS.ID_CURSO,\n                ES.ID_TIPO_ESTUDIANTE\n\n        )FT1\n\n    )FT4\n        OUTER APPLY\n    (\n        SELECT  ISNULL ([EN PROCESO],0)         AS  IND_EN_PROCESO,\n                ISNULL ([ADMITIDO],0)           AS  IND_ADMITIDO,\n                ISNULL ([NO ADMITIDO],0)        AS  IND_NO_ADMITIDO,\n                ISNULL ([PROCESO DESISTIDO],0)  AS  IND_DESISTIDO\n        FROM\n        (\n\n            SELECT  T.ID_FECHA,\n                    MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                    MT.BP,\n                    CA.ID_CATEGORIA,\n                    CS.ID_CURSO,\n                    ES.ID_TIPO_ESTUDIANTE,\n                    EA.DESC_ESTADO_ADMISION,\n                    COUNT(MT.BP) AS IND_ADMISION\n\n\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT \n            JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n            JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION]  EG  ON   EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO]  EP  ON   EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA  ON  EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS            ON  CS.ID_CURSO = MT.ID_CURSO\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES  ON  ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED  ON  ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n            JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n\n\n            WHERE   MT.ID_ESTADO_PROCESO !=11 AND EA.DESC_ESTADO_ADMISION IN ('EN PROCESO','ADMITIDO','NO ADMITIDO','PROCESO DESISTIDO')\n                AND FT.ID_FECHA = MT.ID_FECHA\n                AND FT.ID_ANIO_ACADEMICO = MT.ANIO_ACADEMICO\n                AND FT.BP = MT.BP\n                AND FT.ID_CURSO = MT.ID_CURSO\n                AND FT.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n\n\n        GROUP BY T.ID_FECHA,\n                MT.ANIO_ACADEMICO,\n                MT.BP,\n                CA.ID_CATEGORIA,\n                CS.ID_CURSO,\n                ES.ID_TIPO_ESTUDIANTE,\n                EA.DESC_ESTADO_ADMISION\n\n        )FT1\n        PIVOT (COUNT(FT1.BP) FOR FT1.DESC_ESTADO_ADMISION IN ([EN PROCESO],[ADMITIDO],[NO ADMITIDO],[PROCESO DESISTIDO])) as PVT    \n\n    )FT5\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_colegiogestion-matriculas","title":"FACT_MINERIA\\MINERIA_COLEGIO\\Gestion Matriculas","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_25","title":"Descripci\u00f3n General","text":"<p>El componente Gestion Matriculas del paquete SSIS tiene como funci\u00f3n la integraci\u00f3n de registros asociados al proceso de matr\u00edcula en colegios del dominio educativo, estructurando informaci\u00f3n operacional que describe el tipo de gesti\u00f3n realizada, su duraci\u00f3n y atributos acad\u00e9micos asociados, para su incorporaci\u00f3n en la tabla de hechos <code>FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-del-componente_1","title":"Ubicaci\u00f3n del Componente","text":"<p><code>FACT_MINERIA.dtsx &gt; MINERIA_COLEGIO &gt; Gestion Matriculas</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_23","title":"Prop\u00f3sito","text":"<p>Consolidar eventos del proceso de matr\u00edcula de estudiantes (como atenci\u00f3n por psicolog\u00eda, coordinaci\u00f3n acad\u00e9mica, secretar\u00eda, etc.), asignando el tipo de actividad, duraci\u00f3n y fecha para permitir an\u00e1lisis operativos y de eficiencia institucional.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_28","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Fuente de Datos: <code>[STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO]</code>   con enriquecimiento por <code>[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]</code>.</p> </li> <li> <p>Destino: <code>\"Transversal\".\"FACT_MINERIA\"</code></p> </li> <li> <p>Tipo de Componente:   Flujo de datos ADO.NET Source + ADO.NET Destination</p> </li> <li> <p>Carga:   Inserci\u00f3n directa con <code>SqlBulkCopy</code>, sin particionamiento (<code>BatchSize = 0</code>).</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_27","title":"L\u00f3gica de Negocio","text":"<ol> <li> <p>Extracci\u00f3n:    Se seleccionan m\u00faltiples subconjuntos de datos seg\u00fan los diferentes puntos de contacto del proceso de matr\u00edcula (codeudor, secretar\u00eda acad\u00e9mica, psicolog\u00eda, coordinaci\u00f3n acad\u00e9mica).</p> </li> <li> <p>Transformaci\u00f3n:</p> <ul> <li>Se crea la columna <code>ACTIVIDAD</code> para diferenciar el tipo de gesti\u00f3n.</li> <li><code>TIEMPO_SEGUNDOS</code> se calcula con base en columnas temporales espec\u00edficas (<code>T_CODEUDOR</code>, <code>T_PSICOLOGIA</code>, etc.).</li> <li>Se generan <code>FECHA_INICIAL</code> y <code>FECHA_FINAL</code> basados en <code>ID_FECHA</code> y los segundos de gesti\u00f3n.</li> </ul> </li> <li> <p>Carga:    La informaci\u00f3n se inserta en <code>FACT_MINERIA</code>, incluyendo datos de tiempo, curso, categor\u00eda, tipo de estudiante y tipo de actividad.</p> </li> </ol>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_26","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Este flujo alimenta la tabla <code>FACT_MINERIA</code>, la cual tambi\u00e9n es utilizada por otros componentes de miner\u00eda educativa. Se vincula con dimensiones temporales y acad\u00e9micas que permiten an\u00e1lisis transversales.</p>"},{"location":"03.Cubo/03.ETL/#script-sql-completo_2","title":"Script SQL Completo","text":"<pre><code>SELECT \n    BP\n    ,ID_FECHA_MENSUAL\n    ,ID_ANIO_ACADEMICO\n    --,CONVERT(INT, LEFT(CAST(ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL\n    ,1 AS ID_UNIDAD,\n    CAST(CONVERT(varchar, [ID_FECHA]) AS datetime) AS FECHA_INICIAL,\n    DATEADD(SECOND, TIEMPO_SEGUNDOS, CAST(CONVERT(varchar, [ID_FECHA]) AS datetime)) AS FECHA_FINAL,\n    ACTIVIDAD,\n    TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    ID_CATEGORIA,\n    ID_CURSO,\n    ID_TIPO_ESTUDIANTE,\n    'Consulta Proceso Matricula CEC Comfenalco' as FUENTE_PRINCIPAL\n    --P_CODEUDOR,\n    --P_PSICOLOGIA,\n    --P_SECRETARIA_ACADEMICA,\n    --P_COORDINACION_ACADEMICA,    \n    /*CASE \n        WHEN IND_EN_PROCESO + IND_ADMITIDO + IND_NO_ADMITIDO + IND_DESISTIDO = 0 THEN 1 \n        ELSE IND_EN_PROCESO \n    END AS IND_EN_PROCESO,*/\n    --IND_ADMITIDO,\n    --IND_NO_ADMITIDO,\n    --IND_DESISTIDO\nFROM (\n    SELECT \n        BP,\n        pm.ID_FECHA,\n        ID_ANIO_ACADEMICO,\n        CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        ID_CATEGORIA,\n        ID_CURSO,\n        ID_TIPO_ESTUDIANTE,\n        P_CODEUDOR,\n        P_PSICOLOGIA,\n        P_SECRETARIA_ACADEMICA,\n        P_COORDINACION_ACADEMICA,\n        'Gesti\u00f3n Codeudor' AS ACTIVIDAD, \n        ISNULL(T_CODEUDOR, 0) AS TIEMPO_SEGUNDOS,\n        IND_EN_PROCESO,\n        IND_ADMITIDO,\n        IND_NO_ADMITIDO,\n        IND_DESISTIDO\n    FROM [STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO] pm\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01')\n    WHERE P_CODEUDOR = 1\n\n    UNION ALL\n\n    SELECT \n        BP,\n        pm.ID_FECHA,\n        ID_ANIO_ACADEMICO,\n        CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        ID_CATEGORIA,\n        ID_CURSO,\n        ID_TIPO_ESTUDIANTE,\n        P_CODEUDOR,\n        P_PSICOLOGIA,\n        P_SECRETARIA_ACADEMICA,\n        P_COORDINACION_ACADEMICA,\n        'Gesti\u00f3n Secretaria Acad\u00e9mica' AS ACTIVIDAD, \n        ISNULL(T_SECRETARIA_ACADEMICA, 0) AS TIEMPO_SEGUNDOS,\n        IND_EN_PROCESO,\n        IND_ADMITIDO,\n        IND_NO_ADMITIDO,\n        IND_DESISTIDO\n    FROM [STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO] pm\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01')\n    WHERE P_SECRETARIA_ACADEMICA = 1\n\n    UNION ALL\n\n    SELECT \n        BP,\n        pm.ID_FECHA,\n        ID_ANIO_ACADEMICO,\n        CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        ID_CATEGORIA,\n        ID_CURSO,\n        ID_TIPO_ESTUDIANTE,\n        P_CODEUDOR,\n        P_PSICOLOGIA,\n        P_SECRETARIA_ACADEMICA,\n        P_COORDINACION_ACADEMICA,\n        'Gesti\u00f3n Psicolog\u00eda' AS ACTIVIDAD, \n        ISNULL(T_PSICOLOGIA, 0) AS TIEMPO_SEGUNDOS,\n        IND_EN_PROCESO,\n        IND_ADMITIDO,\n        IND_NO_ADMITIDO,\n        IND_DESISTIDO\n    FROM [STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO] pm\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01')\n    WHERE P_PSICOLOGIA = 1\n\n    UNION ALL\n\n    SELECT \n        BP,\n        pm.ID_FECHA,\n        ID_ANIO_ACADEMICO,\n        CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        ID_CATEGORIA,\n        ID_CURSO,\n        ID_TIPO_ESTUDIANTE,\n        P_CODEUDOR,\n        P_PSICOLOGIA,\n        P_SECRETARIA_ACADEMICA,\n        P_COORDINACION_ACADEMICA,\n        'Gesti\u00f3n Coordinaci\u00f3n Acad\u00e9mica' AS ACTIVIDAD, \n        ISNULL(T_COORDINACION_ACADEMICA, 0) AS TIEMPO_SEGUNDOS,\n        IND_EN_PROCESO,\n        IND_ADMITIDO,\n        IND_NO_ADMITIDO,\n        IND_DESISTIDO\n    FROM [STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO] pm\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01')\n    WHERE P_COORDINACION_ACADEMICA = 1\n\n    UNION ALL\n\n    SELECT \n        BP,\n        pm.ID_FECHA,\n        ID_ANIO_ACADEMICO,\n        CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        ID_CATEGORIA,\n        ID_CURSO,\n        ID_TIPO_ESTUDIANTE,\n        P_CODEUDOR,\n        P_PSICOLOGIA,\n        P_SECRETARIA_ACADEMICA,\n        P_COORDINACION_ACADEMICA,\n        'En Proceso' AS ACTIVIDAD, \n        T_TOTAL_GESTION AS TIEMPO_SEGUNDOS,\n        IND_EN_PROCESO,\n        IND_ADMITIDO,\n        IND_NO_ADMITIDO,\n        IND_DESISTIDO\n    FROM [STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO] pm\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01')\n    WHERE IND_EN_PROCESO = 1 OR IND_EN_PROCESO + IND_ADMITIDO + IND_NO_ADMITIDO + IND_DESISTIDO = 0\n\n    UNION ALL\n\n    SELECT \n        BP,\n        pm.ID_FECHA,\n        ID_ANIO_ACADEMICO,\n        CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        ID_CATEGORIA,\n        ID_CURSO,\n        ID_TIPO_ESTUDIANTE,\n        P_CODEUDOR,\n        P_PSICOLOGIA,\n        P_SECRETARIA_ACADEMICA,\n        P_COORDINACION_ACADEMICA,\n        'Estudiante Admitido' AS ACTIVIDAD, \n        T_TOTAL_GESTION AS TIEMPO_SEGUNDOS,\n        IND_EN_PROCESO,\n        IND_ADMITIDO,\n        IND_NO_ADMITIDO,\n        IND_DESISTIDO\n    FROM [STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO] pm\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01')\n    WHERE IND_ADMITIDO = 1\n\n    UNION ALL\n\n    SELECT \n        BP,\n        pm.ID_FECHA,\n        ID_ANIO_ACADEMICO,\n        CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        ID_CATEGORIA,\n        ID_CURSO,\n        ID_TIPO_ESTUDIANTE,\n        P_CODEUDOR,\n        P_PSICOLOGIA,\n        P_SECRETARIA_ACADEMICA,\n        P_COORDINACION_ACADEMICA,\n        'Estudiante No Admitido' AS ACTIVIDAD, \n        T_TOTAL_GESTION AS TIEMPO_SEGUNDOS,\n        IND_EN_PROCESO,\n        IND_ADMITIDO,\n        IND_NO_ADMITIDO,\n        IND_DESISTIDO\n    FROM [STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO] pm\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01')\n    WHERE IND_NO_ADMITIDO = 1\n\n    UNION ALL\n\n    SELECT \n        BP,\n        pm.ID_FECHA,\n        ID_ANIO_ACADEMICO,\n        CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        ID_CATEGORIA,\n        ID_CURSO,\n        ID_TIPO_ESTUDIANTE,\n        P_CODEUDOR,\n        P_PSICOLOGIA,\n        P_SECRETARIA_ACADEMICA,\n        P_COORDINACION_ACADEMICA,\n        'Estudiante Con Proceso Desistido' AS ACTIVIDAD, \n        T_TOTAL_GESTION AS TIEMPO_SEGUNDOS,\n        IND_EN_PROCESO,\n        IND_ADMITIDO,\n        IND_NO_ADMITIDO,\n        IND_DESISTIDO\n    FROM [STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO] pm\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01')\n    WHERE IND_DESISTIDO = 1\n\n) AS MATRICULAS_COLEGIO\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_colegiopagos-matriculas","title":"FACT_MINERIA\\MINERIA_COLEGIO\\Pagos Matriculas","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_26","title":"Descripci\u00f3n General","text":"<p>Este componente del paquete SSIS realiza la extracci\u00f3n, transformaci\u00f3n y carga de informaci\u00f3n relacionada con los pagos de matr\u00edculas escolares. Extrae los datos desde la facturaci\u00f3n e inscripciones acad\u00e9micas del dominio Colegio en el DWH, clasifica el estado de pago por tipo de matr\u00edcula (ordinaria o subsidiada), y los consolida en la tabla <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-del-paquete_5","title":"Ubicaci\u00f3n del Paquete","text":"<ul> <li>Carpeta: <code>FACT_MINERIA\\MINERIA_COLEGIO</code></li> <li>Nombre del componente: <code>Pagos Matriculas</code></li> <li>Tipo: Tarea de flujo de datos (Data Flow Task)</li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_24","title":"Prop\u00f3sito","text":"<p>Permite registrar mensualmente los pagos de matr\u00edcula (ordinarios y subsidiados), su estado (pagado, sin pagar o anulado) y la categorizaci\u00f3n acad\u00e9mica del beneficiario, todo en una estructura unificada para an\u00e1lisis transversales y de cobertura.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_29","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Fuente de Datos: <code>DWH_COMFENALCO.Colegio.FACT_FACTURACION_MATRICULAS</code> <code>DWH_COMFENALCO.Colegio.FACT_INSCRIPCION_MATRICULAS</code> <code>DWH_COMFENALCO.Colegio.DIM_CONCEPTO_FACT</code> <code>DWH_COMFENALCO.Transversal.DIM_TIEMPO_MENSUAL</code></p> </li> <li> <p>Destino de Carga:   Tabla: <code>Transversal.FACT_MINERIA</code>   Tipo: ADO.NET Destination</p> </li> <li> <p>Transformaciones Aplicadas:</p> <ul> <li>C\u00e1lculo del ID de fecha mensual y a\u00f1o acad\u00e9mico.</li> <li>Clasificaci\u00f3n del tipo de actividad (Pago Matr\u00edcula, Anulado, Subsidio, etc.).</li> <li>Uni\u00f3n con dimensiones categ\u00f3ricas (curso, categor\u00eda, tipo de estudiante).</li> <li>Validaci\u00f3n para no incluir conceptos no relevantes (<code>BIBLIOBANCO</code>).</li> <li>Asignaci\u00f3n por defecto para valores nulos.</li> </ul> </li> <li> <p>Configuraci\u00f3n T\u00e9cnica:</p> <ul> <li><code>UseBulkInsertWhenPossible = true</code></li> <li><code>CommandTimeout = 30</code></li> <li><code>BatchSize = 0</code> (usa el tama\u00f1o de buffer por defecto de SSIS)</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_28","title":"L\u00f3gica de Negocio","text":"<p>El componente determina la actividad de pago de matr\u00edcula en funci\u00f3n del concepto y estado del pago. Clasifica los registros como \"Pago Matr\u00edcula\", \"Sin Pago Matr\u00edcula\", o \"Anulado\", y aplica las mismas reglas para subsidios. Se asegura de mantener una \u00fanica inscripci\u00f3n por beneficiario y a\u00f1o, y agrega atributos categ\u00f3ricos relacionados con el beneficiario.</p>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_27","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Este componente complementa otros procesos del dominio <code>MINERIA_COLEGIO</code> como coberturas y actividades, alimentando la tabla <code>FACT_MINERIA</code> para an\u00e1lisis integrales que incluyan comportamiento financiero, asistencia y participaci\u00f3n acad\u00e9mica.</p>"},{"location":"03.Cubo/03.ETL/#script-sql-utilizado_6","title":"Script SQL Utilizado","text":"<pre><code>WITH Facturacion AS (\n    SELECT \n        i.BP,\n        CONVERT(INT, CAST(CASE \n            WHEN MONTH(i.FECHA_CONTABLE) &gt;= 10 THEN YEAR(i.FECHA_CONTABLE) + 1\n            ELSE YEAR(i.FECHA_CONTABLE)\n        END AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        CASE \n            WHEN MONTH(i.FECHA_CONTABLE) &gt;= 10 THEN YEAR(i.FECHA_CONTABLE) + 1\n            ELSE YEAR(i.FECHA_CONTABLE)\n        END AS ID_ANIO_ACADEMICO,\n        1 AS ID_UNIDAD,\n        CAST(CONVERT(varchar, i.FECHA_CONTABLE) AS datetime) AS FECHA_INICIAL,\n        CAST(CONVERT(varchar, i.FECHA_CONTABLE) AS datetime) AS FECHA_FINAL,\n        CASE\n            WHEN e.DESC_CONCEPTO = 'MATRICULA' AND i.ESTADO_PAGO = 'ANULADO' THEN 'Pago Matr\u00edcula Anulado'\n            WHEN e.DESC_CONCEPTO = 'MATRICULA' AND i.ESTADO_PAGO = 'PAGADO' THEN 'Pago Matr\u00edcula'\n            WHEN e.DESC_CONCEPTO = 'MATRICULA' AND i.ESTADO_PAGO = 'SIN PAGO' THEN 'Sin Pago Matr\u00edcula'\n            WHEN e.DESC_CONCEPTO = 'SUBSIDIO MATRICULA' AND i.ESTADO_PAGO = 'ANULADO' THEN 'Pago Matr\u00edcula Subsidio Anulado'\n            WHEN e.DESC_CONCEPTO = 'SUBSIDIO MATRICULA' AND i.ESTADO_PAGO = 'PAGADO' THEN 'Pago Matr\u00edcula Subsidio'\n            WHEN e.DESC_CONCEPTO = 'SUBSIDIO MATRICULA' AND i.ESTADO_PAGO = 'SIN PAGO' THEN 'Sin Pago Matr\u00edcula Subsidio'\n            ELSE 'Sin Identificar'\n        END AS ACTIVIDAD,\n        0 AS TIEMPO_SEGUNDOS,\n        i.VALOR_PAGADO\n    FROM DWH_COMFENALCO.Colegio.FACT_FACTURACION_MATRICULAS i\n    INNER JOIN DWH_COMFENALCO.Colegio.FACT_INSCRIPCION_MATRICULAS f ON i.ID = f.ID\n    INNER JOIN DWH_COMFENALCO.Colegio.DIM_CONCEPTO_FACT e ON i.ID_CONCEPTO = e.ID_CONCEPTO\n    WHERE e.DESC_CONCEPTO NOT IN ('BIBLIOBANCO')\n),\nUniqueRows AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA_FAMILIAR] AS ID_CATEGORIA,\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE],\n        ROW_NUMBER() OVER (PARTITION BY [BP], [ANIO_ACADEMICO] ORDER BY [ID] DESC) AS RowNum\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS]\n),\nInscripcion_Matriculas AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA],\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE]\n    FROM UniqueRows\n    WHERE RowNum = 1\n)\nSELECT f.*,\n       ISNULL(im.ID_CATEGORIA,4) AS ID_CATEGORIA,\n       ISNULL(im.ID_CURSO,-1) AS ID_CURSO,\n       ISNULL(im.ID_TIPO_ESTUDIANTE,-1) AS ID_TIPO_ESTUDIANTE,\n       'DWH_COMFENALCO.Colegio.FACT_FACTURACION_MATRICULAS' AS FUENTE_PRINCIPAL\nFROM Facturacion f\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = f.[ID_FECHA_MENSUAL]\nLEFT JOIN Inscripcion_Matriculas im ON im.[BP] = f.[BP] AND im.[ANIO_ACADEMICO] = f.[ID_ANIO_ACADEMICO]\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_colegiopqrs-colegio","title":"FACT_MINERIA\\MINERIA_COLEGIO\\PQRs Colegio","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_27","title":"Descripci\u00f3n General","text":"<p>Este componente integra solicitudes PQR (Peticiones, Quejas y Reclamos) relacionadas con estudiantes del Colegio, mediante el cruce de m\u00faltiples fuentes transversales y acad\u00e9micas del Data Warehouse <code>DWH_COMFENALCO</code>. El flujo transforma y enriquece la informaci\u00f3n con categor\u00edas, curso y tipo de estudiante, y finalmente la carga en la tabla <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_14","title":"Ubicaci\u00f3n en el Paquete","text":"<p><code>FACT_MINERIA\\MINERIA_COLEGIO\\PQRs Colegio</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_25","title":"Prop\u00f3sito","text":"<p>Consolidar en una \u00fanica fuente los eventos de tipo PQR de estudiantes de colegio, asociados a acudientes, categorizando por curso, tipo y a\u00f1o acad\u00e9mico, para su an\u00e1lisis como parte de las actividades de miner\u00eda de datos institucional.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_30","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li> <p>Origen de Datos: <code>DWH_COMFENALCO.Transversal.FACT_PQRS</code>   Enlazado a trav\u00e9s de relaciones con <code>DIM_TIEMPO_MENSUAL</code>, <code>DIM_AFILIADOS</code> y <code>DIM_ACUDIENTES</code>.</p> </li> <li> <p>Transformaciones Aplicadas:</p> <ul> <li>C\u00e1lculo de <code>ID_FECHA_MENSUAL</code> y <code>ID_ANIO_ACADEMICO</code>.</li> <li>Categorizaci\u00f3n de la actividad como <code>PQR</code> concatenada con causa.</li> <li>C\u00e1lculo de duraci\u00f3n en segundos (<code>TIEMPO_SEGUNDOS</code>).</li> <li>Enriquecimiento con <code>ID_CATEGORIA</code>, <code>ID_CURSO</code>, y <code>ID_TIPO_ESTUDIANTE</code> desde <code>FACT_INSCRIPCION_MATRICULAS</code>.</li> </ul> </li> <li> <p>Carga de Datos:   Destino: <code>Transversal.FACT_MINERIA</code> (por ADO.NET)   Modo: Inserci\u00f3n directa con opci\u00f3n de Bulk Insert habilitada.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_29","title":"L\u00f3gica de Negocio","text":"<ul> <li>Se consideran \u00fanicamente registros de PQR con <code>ID_UNIDAD = 1</code> (Colegio).</li> <li>La relaci\u00f3n con estudiantes se infiere desde el acudiente vinculado al afiliado del PQR.</li> <li>Para cada combinaci\u00f3n <code>BP</code> y a\u00f1o acad\u00e9mico, se selecciona la inscripci\u00f3n m\u00e1s reciente (<code>ROW_NUMBER()</code>).</li> <li>Las PQR se documentan como actividades del beneficiario en FACT_MINERIA, bajo el dominio del Colegio.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_28","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Consulta de Inscripciones: <code>FACT_INSCRIPCION_MATRICULAS</code></li> <li>Referencia de Lookup: <code>FACT_MINERIA</code></li> <li>Carga en destino com\u00fan: <code>FACT_MINERIA</code>, junto con otros procesos educativos.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-completo_3","title":"Script SQL (completo)","text":"<pre><code>WITH PQRS_ACUDIENTES AS (\n    SELECT \n        ac.[BP_ESTUDIANTE] as BP,\n        CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n        CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n        [ID_UNIDAD],\n        [FECHA_CREACION] AS FECHA_INICIAL,\n        [FECHA_RESOLUCION] AS FECHA_FINAL,\n        CONCAT('PQR ', LOWER([CAUSA])) AS ACTIVIDAD,\n        DATEDIFF(SECOND, [FECHA_CREACION], [FECHA_RESOLUCION]) AS TIEMPO_SEGUNDOS,\n        0 AS VALOR_PAGADO\n    FROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] f\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n        ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01')\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n        ON f.[ID_AFILIADO] = a.[ID_AFILIADO]\n    INNER JOIN [DWH_COMFENALCO].[Colegio].[DIM_ACUDIENTES] ac \n        ON ac.[BP_ACUDIENTE] = a.[PARTNER]\n    WHERE f.ID_AFILIADO != -1 AND ID_UNIDAD = 1\n),\nUniqueRows AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA_FAMILIAR] AS ID_CATEGORIA,\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE],\n        ROW_NUMBER() OVER (PARTITION BY [BP], [ANIO_ACADEMICO] ORDER BY [ID] DESC) AS RowNum\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS]\n),\nInscripcion_Matriculas AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA],\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE]\n    FROM UniqueRows\n    WHERE RowNum = 1\n)\nSELECT \n    pa.*,\n    ISNULL(im.ID_CATEGORIA, 4) AS ID_CATEGORIA,\n    ISNULL(im.ID_CURSO, -1) AS ID_CURSO,\n    ISNULL(im.ID_TIPO_ESTUDIANTE, -1) AS ID_TIPO_ESTUDIANTE,\n    '[DWH_COMFENALCO].[Transversal].[FACT_PQRS]' AS FUENTE_PRINCIPAL\nFROM PQRS_ACUDIENTES pa\nLEFT JOIN Inscripcion_Matriculas im \n    ON im.[BP] = pa.[BP] AND im.[ANIO_ACADEMICO] = pa.[ID_ANIO_ACADEMICO]\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_educacion_tecnica_y_continuainscripcion","title":"FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Inscripcion","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_28","title":"Descripci\u00f3n General","text":"<p>Este componente SSIS realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con inscripciones en programas de educaci\u00f3n t\u00e9cnica y continua. La fuente principal es la tabla <code>FACT_INSCRIPCION_MATRICULAS</code>, y el destino es la tabla consolidada <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete_9","title":"Ubicaci\u00f3n dentro del Paquete","text":"<p><code>FACT_MINERIA</code> &gt; <code>MINERIA_EDUCACION_TECNICA_Y_CONTINUA</code> &gt; <code>Inscripcion</code></p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_6","title":"Prop\u00f3sito del Componente","text":"<p>Unificar registros de inscripci\u00f3n provenientes de afiliados, beneficiarios, empresas y no aportantes, clasificando la actividad educativa y otras dimensiones relevantes para an\u00e1lisis longitudinales e integraciones con otros dominios del DWH.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_31","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Origen: <code>FACT_INSCRIPCION_MATRICULAS</code> (Cedesarrollo)</li> <li>Destino: <code>Transversal.FACT_MINERIA</code></li> <li>Tipo de extracci\u00f3n: ADO.NET Source</li> <li>Tipo de carga: ADO.NET Destination con <code>BulkInsert</code> habilitado</li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code></li> <li>L\u00f3gica de carga: Directa sin transformaci\u00f3n intermedia.</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_30","title":"L\u00f3gica de Negocio","text":"<p>La extracci\u00f3n se realiza mediante un query unificado (con <code>UNION ALL</code>) que agrupa la inscripci\u00f3n de:</p> <ol> <li>Afiliados</li> <li>Beneficiarios</li> <li>Empresas</li> <li>No aportantes</li> </ol> <p>Cada grupo se identifica por su relaci\u00f3n jer\u00e1rquica con estudiantes y se asignan valores categ\u00f3ricos fijos para facilitar su integraci\u00f3n anal\u00edtica:</p> <ul> <li><code>BP</code>: Identificador de partner seg\u00fan la fuente</li> <li><code>ID_CATEGORIA</code>: Se asignan valores predeterminados seg\u00fan el tipo de origen</li> <li><code>ID_CURSO</code> e <code>ID_TIPO_ESTUDIANTE</code>: se establecen en <code>-1</code> (no definidos)</li> <li><code>ACTIVIDAD</code>: Se clasifica como Estudiante Inscrito, Proceso Desistido, o Sin Identificar</li> <li><code>FUENTE_PRINCIPAL</code>: campo trazable para auditor\u00eda (<code>[DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]</code>)</li> </ul>"},{"location":"03.Cubo/03.ETL/#sql-completo","title":"SQL Completo","text":"<pre><code>-- Afiliados\nSELECT \n    a.[PARTNER] AS BP,\n    CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL,\n    YEAR(im.[FECHA]) AS ID_ANIO_ACADEMICO,\n    j.[ID_UNIDAD],\n    im.[FECHA] AS FECHA_INICIAL,\n    im.[FECHA] AS FECHA_FINAL,\n    CASE\n        WHEN im.[ESTADO] = 'INSCRITO' THEN 'Estudiante Inscrito'\n        WHEN im.[ESTADO] = 'NO INSCRITO' THEN 'Estudiante con Proceso Desistido'\n        ELSE 'Sin Identificar'\n    END AS ACTIVIDAD,\n    0 AS TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    a.[ID_CATEGORIA],\n    -1 AS ID_CURSO,\n    -1 AS ID_TIPO_ESTUDIANTE,\n    im.[ID_PROGRAMA],\n    '[DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]' AS FUENTE_PRINCIPAL\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] im\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e ON im.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a ON e.[ID_AFILIADO] = a.[ID_AFILIADO]\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j ON im.[ID_JORNADA] = j.[ID_JORNADA]\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)\nWHERE e.ID_AFILIADO != -1\n\nUNION ALL\n\n-- Beneficiarios\nSELECT \n    b.[PARTNER], CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT), YEAR(im.[FECHA]),\n    j.[ID_UNIDAD], im.[FECHA], im.[FECHA],\n    CASE\n        WHEN im.[ESTADO] = 'INSCRITO' THEN 'Estudiante Inscrito'\n        WHEN im.[ESTADO] = 'NO INSCRITO' THEN 'Estudiante con Proceso Desistido'\n        ELSE 'Sin Identificar'\n    END,\n    0, 0, ISNULL(a.[ID_CATEGORIA], 4), -1, -1, im.[ID_PROGRAMA],\n    '[DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]'\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] im\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e ON im.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b ON e.[ID_BENEFICIARIO] = b.[ID_BENEFICIARIO]\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j ON im.[ID_JORNADA] = j.[ID_JORNADA]\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)\nLEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a ON b.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE e.ID_BENEFICIARIO != -1\n\nUNION ALL\n\n-- Empresas\nSELECT \n    em.[PARTNER], CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT), YEAR(im.[FECHA]),\n    j.[ID_UNIDAD], im.[FECHA], im.[FECHA],\n    CASE\n        WHEN im.[ESTADO] = 'INSCRITO' THEN 'Estudiante Inscrito'\n        WHEN im.[ESTADO] = 'NO INSCRITO' THEN 'Estudiante con Proceso Desistido'\n        ELSE 'Sin Identificar'\n    END,\n    0, 0, 5, -1, -1, im.[ID_PROGRAMA],\n    '[DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]'\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] im\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e ON im.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] em ON e.[ID_EMPRESA] = em.[ID_EMPRESA]\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j ON im.[ID_JORNADA] = j.[ID_JORNADA]\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)\nWHERE e.ID_EMPRESA != -1\n\nUNION ALL\n\n-- No aportante\nSELECT \n    '0000000000', CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT), YEAR(im.[FECHA]),\n    j.[ID_UNIDAD], im.[FECHA], im.[FECHA],\n    CASE\n        WHEN im.[ESTADO] = 'INSCRITO' THEN 'Estudiante Inscrito'\n        WHEN im.[ESTADO] = 'NO INSCRITO' THEN 'Estudiante con Proceso Desistido'\n        ELSE 'Sin Identificar'\n    END,\n    0, 0,\n    CASE\n        WHEN e.[TIPO_DOCUMENTO] = 'NI' THEN 12\n        ELSE 4\n    END,\n    -1, -1, im.[ID_PROGRAMA],\n    '[DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]'\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] im\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e ON im.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j ON im.[ID_JORNADA] = j.[ID_JORNADA]\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)\nWHERE ID_AFILIADO + ID_EMPRESA + ID_BENEFICIARIO = -3\n</code></pre>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_29","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Este componente se conecta directamente al destino <code>Transversal.FACT_MINERIA</code>.</li> <li>Comparte l\u00f3gica y fuentes similares a otros componentes del paquete <code>MINERIA_EDUCACION_TECNICA_Y_CONTINUA</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_educacion_tecnica_y_continuaadmision","title":"FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Admision","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_29","title":"Descripci\u00f3n General","text":"<p>Este componente es un Data Flow Task del paquete <code>FACT_MINERIA</code>, orientado a la integraci\u00f3n de informaci\u00f3n de admisiones en programas de educaci\u00f3n t\u00e9cnica y continua. Extrae registros desde la tabla de hechos <code>FACT_ESTADO_MATRICULAS</code> y los clasifica en funci\u00f3n de su origen (afiliado, beneficiario, empresa o no aportante), generando una tabla consolidada de admisiones con metadatos educativos y organizacionales.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-del-componente_2","title":"Ubicaci\u00f3n del Componente","text":"<p><code>FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Admision</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_26","title":"Prop\u00f3sito","text":"<p>Integrar informaci\u00f3n de admisiones en programas de educaci\u00f3n t\u00e9cnica y continua desde m\u00faltiples fuentes (afiliados, beneficiarios, empresas, no aportantes), estructur\u00e1ndola con base en fechas acad\u00e9micas, categor\u00edas y programas, para ser cargada en la tabla <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_32","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Origen de Datos: Consulta SQL sobre <code>[DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS]</code> unida a m\u00faltiples dimensiones.</li> <li>Destino de Datos: Tabla <code>Transversal.FACT_MINERIA</code> mediante componente <code>Destino de ADO.NET</code>.</li> <li> <p>Transformaciones:</p> <ul> <li>Agrupaci\u00f3n de admisiones por tipo de actor (afiliado, beneficiario, empresa, no aportante).</li> <li>Mapeo de campos claves como fechas, unidades, programas, actividad y categor\u00eda.</li> <li>Asignaci\u00f3n de valores fijos a campos como <code>TIEMPO_SEGUNDOS</code>, <code>VALOR_PAGADO</code>, <code>ID_CURSO</code>, <code>ID_TIPO_ESTUDIANTE</code>.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_31","title":"L\u00f3gica de Negocio","text":"<ul> <li>Clasificaci\u00f3n de admisiones en funci\u00f3n de la relaci\u00f3n institucional del estudiante (afiliado, beneficiario, empresa o no aportante).</li> <li>Normalizaci\u00f3n de fechas de matr\u00edcula para obtener claves temporales (<code>ID_FECHA_MENSUAL</code>, <code>ID_ANIO_ACADEMICO</code>).</li> <li>Determinaci\u00f3n de la actividad seg\u00fan semestre de matr\u00edcula (<code>Estudiante Admitido Nuevo</code> vs <code>Antiguo</code>).</li> <li>En caso de no aportantes, asignaci\u00f3n de categor\u00eda basada en tipo de documento.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_30","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Fuente principal de datos: <code>FACT_ESTADO_MATRICULAS</code>.</li> <li>Apoya la construcci\u00f3n del modelo de miner\u00eda de datos educativos de Comfenalco.</li> <li>Se integra con otras transformaciones del paquete <code>FACT_MINERIA</code> para consolidaci\u00f3n transversal.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql-del-origen","title":"Script SQL del Origen","text":"<pre><code>-- Afiliados\nSELECT a.PARTNER AS BP,\n       CAST(FORMAT(fm.FECHA_MATRICULA, 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL,\n       YEAR(fm.FECHA_MATRICULA) AS ID_ANIO_ACADEMICO,\n       j.ID_UNIDAD,\n       fm.FECHA_MATRICULA AS FECHA_INICIAL,\n       fm.FECHA_MATRICULA AS FECHA_FINAL,\n       CASE WHEN fm.SEMESTRE IN ('\u00danico', '1') THEN 'Estudiante Admitido Nuevo' ELSE 'Estudiante Admitido Antiguo' END AS ACTIVIDAD,\n       0 AS TIEMPO_SEGUNDOS,\n       0 AS VALOR_PAGADO,\n       ISNULL(a.ID_CATEGORIA,4) AS ID_CATEGORIA,\n       -1 AS ID_CURSO,\n       -1 AS ID_TIPO_ESTUDIANTE,\n       fm.ID_PROGRAMA,\n       '[DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS]' AS FUENTE_PRINCIPAL\nFROM DWH_COMFENALCO.Cedesarrollo.FACT_ESTADO_MATRICULAS fm\nJOIN DWH_COMFENALCO.Cedesarrollo.DIM_ESTUDIANTES e ON fm.ID_ESTUDIANTE = e.ID_ESTUDIANTE\nJOIN DWH_COMFENALCO.Transversal.DIM_AFILIADOS a ON e.ID_AFILIADO = a.ID_AFILIADO\nJOIN DWH_COMFENALCO.Cedesarrollo.DIM_JORNADA j ON fm.ID_JORNADA = j.ID_JORNADA\nJOIN DWH_COMFENALCO.Transversal.DIM_TIEMPO_MENSUAL tm ON tm.ID_FECHA = CAST(FORMAT(fm.FECHA_MATRICULA, 'yyyyMM01') AS INT)\nWHERE e.ID_AFILIADO != -1\n\nUNION ALL\n\n-- Beneficiarios\nSELECT b.PARTNER AS BP, ...\n-- (contin\u00faa igual l\u00f3gica con JOIN a DIM_BENEFICIARIOS)\n\nUNION ALL\n\n-- Empresas\nSELECT em.PARTNER AS BP, ...\n-- (contin\u00faa con l\u00f3gica similar y categor\u00eda fija 5)\n\nUNION ALL\n\n-- No aportante\nSELECT '0000000000' AS BP,\n       ...\n       CASE WHEN e.TIPO_DOCUMENTO = 'NI' THEN 12 ELSE 4 END AS ID_CATEGORIA,\n       ...\nWHERE ID_AFILIADO + ID_EMPRESA + ID_BENEFICIARIO = -3\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_educacion_tecnica_y_continuapago","title":"FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Pago","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_30","title":"Descripci\u00f3n General","text":"<p>Este componente del flujo de datos del paquete <code>FACT_MINERIA</code> extrae, transforma y carga informaci\u00f3n relacionada con pagos realizados por diferentes tipos de beneficiarios en procesos de formaci\u00f3n t\u00e9cnica y continua. Se enfoca en la actividad \"Pago Matr\u00edcula\", obtenida desde la tabla <code>FACT_FACTURACION</code> del \u00e1rea de Cedesarrollo, y consolida dicha informaci\u00f3n en la tabla de hechos <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion","title":"Ubicaci\u00f3n","text":"<p><code>Package\\FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Pago</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_27","title":"Prop\u00f3sito","text":"<p>Consolidar pagos de matr\u00edcula provenientes de diversas categor\u00edas de participantes (afiliados, beneficiarios, empresas y no aportantes) en un solo flujo estandarizado, permitiendo su an\u00e1lisis en el contexto de miner\u00eda educativa.</p>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_33","title":"Detalles de Implementaci\u00f3n","text":"<ul> <li>Origen de datos: <code>DWH_COMFENALCO.Cedesarrollo.FACT_FACTURACION</code>, junto con dimensiones de estudiantes, afiliados, beneficiarios, empresas y tiempo mensual.</li> <li>Tipo de Origen: ADO.NET Source con consulta SQL personalizada.</li> <li>Destino: Tabla <code>Transversal.FACT_MINERIA</code> mediante componente ADO.NET Destination con inserciones masivas habilitadas (<code>UseBulkInsertWhenPossible = true</code>).</li> <li>Conexi\u00f3n: Usa el administrador de conexiones <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_32","title":"L\u00f3gica de Negocio","text":"<ul> <li>Se generan 4 bloques de datos seg\u00fan la categor\u00eda del participante: afiliado, beneficiario, empresa o no aportante.</li> <li>Se filtran conceptos irrelevantes (<code>CERTIFICADO</code>, <code>DERECHO GRADO</code>).</li> <li>Se estandarizan campos no disponibles con valores por defecto (<code>ID_CURSO</code>, <code>ID_PROGRAMA</code>, etc.).</li> <li>Se derivan columnas como <code>ID_FECHA_MENSUAL</code>, <code>ID_ANIO_ACADEMICO</code> y <code>ID_UNIDAD</code> a partir de la fecha contable.</li> <li>Se asigna la fuente como <code>'[DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION]'</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_31","title":"Relaci\u00f3n con Otros Componentes","text":"<p>Este componente forma parte del proceso de consolidaci\u00f3n educativa t\u00e9cnica y continua, y alimenta la tabla transversal <code>FACT_MINERIA</code>, usada por otros procesos anal\u00edticos del dominio educativo.</p>"},{"location":"03.Cubo/03.ETL/#script-sql_5","title":"Script SQL","text":"<pre><code>-- Afiliados\nSELECT distinct\n      a.[PARTNER] as BP\n      --,ff.[TIPO_DOCUMENTO_PAGO]\n      --,ff.[DOCUMENTO_PAGO]\n      ,CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(ff.[FECHA_CONTABLE]) AS ID_ANIO_ACADEMICO\n      ,CASE\n            WHEN LEN(NO_RECIBO) &lt; 6 THEN 2\n            ELSE 3\n        END AS ID_UNIDAD\n      ,ff.[FECHA_CONTABLE] AS FECHA_INICIAL\n      ,ff.[FECHA_CONTABLE] AS FECHA_FINAL\n      ,'Pago Matr\u00edcula' AS ACTIVIDAD\n      , 0 AS TIEMPO_SEGUNDOS\n      --,ff.[CONCEPTO]\n      ,ff.[VALOR_PAGADO]\n      ,ISNULL(a.[ID_CATEGORIA],4) AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,-1 AS ID_PROGRAMA\n      ,'[DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION]' as FUENTE_PRINCIPAL\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n  INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on ff.[TIPO_DOCUMENTO_PAGO] = e.[TIPO_DOCUMENTO] and ff.[DOCUMENTO_PAGO] = e.[DOCUMENTO]\n  INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a on e.[ID_AFILIADO] = a.[ID_AFILIADO]\n  INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT)\n  WHERE \n    [CONCEPTO] NOT LIKE '%CERTIFICADO%' AND [CONCEPTO] NOT LIKE '%DERECHO GRADO%'\n    AND e.ID_AFILIADO != -1\n\nUNION ALL\n-- Beneficiarios\nSELECT distinct\n      b.[PARTNER] as BP\n      --,ff.[TIPO_DOCUMENTO_PAGO]\n      --,ff.[DOCUMENTO_PAGO]\n      ,CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(ff.[FECHA_CONTABLE]) AS ID_ANIO_ACADEMICO\n      ,CASE\n            WHEN LEN(NO_RECIBO) &lt; 6 THEN 2\n            ELSE 3\n        END AS ID_UNIDAD\n      ,ff.[FECHA_CONTABLE] AS FECHA_INICIAL\n      ,ff.[FECHA_CONTABLE] AS FECHA_FINAL\n      ,'Pago Matr\u00edcula' AS ACTIVIDAD\n      , 0 AS TIEMPO_SEGUNDOS\n      --,ff.[CONCEPTO]\n      ,ff.[VALOR_PAGADO]\n      ,ISNULL(a.[ID_CATEGORIA],4) AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,-1 AS ID_PROGRAMA\n      ,'[DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION]' as FUENTE_PRINCIPAL\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n  INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on ff.[TIPO_DOCUMENTO_PAGO] = e.[TIPO_DOCUMENTO] and ff.[DOCUMENTO_PAGO] = e.[DOCUMENTO]\n  INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b on e.[ID_BENEFICIARIO] =  b.[ID_BENEFICIARIO]\n  INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT)\n  LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a on b.[ID_AFILIADO] = a.[ID_AFILIADO]\n  WHERE \n    [CONCEPTO] NOT LIKE '%CERTIFICADO%' AND [CONCEPTO] NOT LIKE '%DERECHO GRADO%'\n    AND e.ID_BENEFICIARIO != -1\n\nUNION ALL\n   -- Empresas\nSELECT distinct\n      em.[PARTNER] as BP\n      --,ff.[TIPO_DOCUMENTO_PAGO]\n      --,ff.[DOCUMENTO_PAGO]\n      ,CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(ff.[FECHA_CONTABLE]) AS ID_ANIO_ACADEMICO\n      ,CASE\n            WHEN LEN(NO_RECIBO) &lt; 6 THEN 2\n            ELSE 3\n        END AS ID_UNIDAD\n      ,ff.[FECHA_CONTABLE] AS FECHA_INICIAL\n      ,ff.[FECHA_CONTABLE] AS FECHA_FINAL\n      ,'Pago Matr\u00edcula' AS ACTIVIDAD\n      , 0 AS TIEMPO_SEGUNDOS\n      --,ff.[CONCEPTO]\n      ,ff.[VALOR_PAGADO]\n      ,5 AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,-1 AS ID_PROGRAMA\n      ,'[DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION]' as FUENTE_PRINCIPAL\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n  INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on ff.[TIPO_DOCUMENTO_PAGO] = e.[TIPO_DOCUMENTO] and ff.[DOCUMENTO_PAGO] = e.[DOCUMENTO]\n  INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] em on e.[ID_EMPRESA] =  em.[ID_EMPRESA]\n  INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT)\n  WHERE \n    [CONCEPTO] NOT LIKE '%CERTIFICADO%' AND [CONCEPTO] NOT LIKE '%DERECHO GRADO%'\n    AND e.ID_EMPRESA != -1\n\nUNION ALL\n\n-- No aportante\nSELECT distinct\n      '0000000000' as BP\n      --,ff.[TIPO_DOCUMENTO_PAGO]\n      --,ff.[DOCUMENTO_PAGO]\n      ,CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(ff.[FECHA_CONTABLE]) AS ID_ANIO_ACADEMICO\n      ,CASE\n            WHEN LEN(NO_RECIBO) &lt; 6 THEN 2\n            ELSE 3\n        END AS ID_UNIDAD\n      ,ff.[FECHA_CONTABLE] AS FECHA_INICIAL\n      ,ff.[FECHA_CONTABLE] AS FECHA_FINAL\n      ,'Pago Matr\u00edcula' AS ACTIVIDAD\n      , 0 AS TIEMPO_SEGUNDOS\n      --,ff.[CONCEPTO]\n      ,ff.[VALOR_PAGADO]\n      ,CASE\n            WHEN e.[TIPO_DOCUMENTO] = 'NI' THEN 12\n            ELSE 4\n        END AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,-1 AS ID_PROGRAMA\n      ,'[DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION]' as FUENTE_PRINCIPAL\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n  INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on ff.[TIPO_DOCUMENTO_PAGO] = e.[TIPO_DOCUMENTO] and ff.[DOCUMENTO_PAGO] = e.[DOCUMENTO]\n  --INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] em on e.[ID_EMPRESA] =  em.[ID_EMPRESA]\n  INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT)\n  WHERE \n    [CONCEPTO] NOT LIKE '%CERTIFICADO%' AND [CONCEPTO] NOT LIKE '%DERECHO GRADO%'\n    AND ID_AFILIADO + ID_EMPRESA+ ID_BENEFICIARIO  = -3\n</code></pre>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_educacion_tecnica_y_continuapqrs","title":"FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\PQRs","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_31","title":"Descripci\u00f3n General","text":"<p>Este componente realiza la extracci\u00f3n, transformaci\u00f3n y carga de datos asociados a las PQRs (Peticiones, Quejas y Reclamos) en el contexto de la educaci\u00f3n t\u00e9cnica y continua, consolidando los registros en la tabla <code>Transversal.FACT_MINERIA</code>. Utiliza informaci\u00f3n de beneficiarios y afiliados para clasificar y categorizar los eventos, integrando m\u00faltiples tablas del DWH.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_15","title":"Ubicaci\u00f3n en el Paquete","text":"<p><code>FACT_MINERIA \\ MINERIA_EDUCACION_TECNICA_Y_CONTINUA \\ PQRs</code></p>"},{"location":"03.Cubo/03.ETL/#proposito_28","title":"Prop\u00f3sito","text":"<p>Permitir el an\u00e1lisis mensual de actividades relacionadas con la gesti\u00f3n de PQRs, calculando tiempos de resoluci\u00f3n, categorizaciones y trazabilidad por unidad acad\u00e9mica, periodo y beneficiario o afiliado.</p>"},{"location":"03.Cubo/03.ETL/#implementacion-tecnica_1","title":"Implementaci\u00f3n T\u00e9cnica","text":"<ul> <li>Origen: ADO.NET Source con consulta SQL que hace <code>UNION</code> de registros seg\u00fan la relaci\u00f3n con <code>DIM_AFILIADOS</code> y <code>DIM_BENEFICIARIOS</code>.</li> <li> <p>Transformaciones:</p> <ul> <li><code>Lookup</code>: verifica existencia previa en <code>FACT_MINERIA</code> usando <code>BP</code>.</li> </ul> </li> <li> <p>Destino: ADO.NET Destination hacia la tabla <code>Transversal.FACT_MINERIA</code>.</p> </li> <li> <p>Conexiones:</p> <ul> <li><code>DWH_COMFENALCO</code> (ADO.NET)</li> <li><code>DWH_COMFENALCO_OLEDB</code> (OLEDB para Lookup)</li> </ul> </li> <li> <p>Columnas procesadas:</p> <ul> <li>BP, ID_FECHA_MENSUAL, ID_ANIO_ACADEMICO, ID_UNIDAD, FECHA_INICIAL, FECHA_FINAL, ACTIVIDAD, TIEMPO_SEGUNDOS, VALOR_PAGADO, ID_CATEGORIA, ID_CURSO, ID_TIPO_ESTUDIANTE, FUENTE_PRINCIPAL</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_33","title":"L\u00f3gica de Negocio","text":"<ul> <li>Registra eventos de PQR por afiliados y beneficiarios con ID_UNIDAD en (2,3).</li> <li>Calcula el tiempo de resoluci\u00f3n en segundos.</li> <li>Clasifica el tipo de actividad seg\u00fan la causa (<code>'PQR ' + lower(CAUSA)</code>).</li> <li>Asigna valores constantes a campos que no aplican (<code>ID_CURSO = -1</code>, <code>VALOR_PAGADO = 0</code>, etc.).</li> <li>Determina categor\u00eda por afiliado cuando est\u00e1 disponible, o usa valor por defecto.</li> <li>Aplica l\u00f3gica de actualizaci\u00f3n solo si el <code>BP</code> ya existe en <code>FACT_MINERIA</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_32","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Este flujo se alimenta de la tabla <code>FACT_PQRS</code> pero escribe en <code>FACT_MINERIA</code>, por lo que su salida debe integrarse con otros procesos que tambi\u00e9n alimentan dicha tabla desde otros dominios.</li> </ul>"},{"location":"03.Cubo/03.ETL/#script-sql_6","title":"Script SQL","text":"<pre><code>SELECT \n    a.[PARTNER] as BP,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n    [ID_UNIDAD],\n    [FECHA_CREACION] AS FECHA_INICIAL,\n    [FECHA_RESOLUCION] AS FECHA_FINAL,\n    CONCAT('PQR ', LOWER([CAUSA])) AS ACTIVIDAD,\n    DATEDIFF(SECOND, [FECHA_CREACION], [FECHA_RESOLUCION]) AS TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    [ID_CATEGORIA],\n    -1 AS ID_CURSO,\n    -1 AS ID_TIPO_ESTUDIANTE,\n    '[DWH_COMFENALCO].[Transversal].[FACT_PQRS]' AS FUENTE_PRINCIPAL\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] f\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n    ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01')\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n    ON f.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE f.ID_AFILIADO != -1 AND ID_UNIDAD in (2,3)\n\nUNION ALL\n\nSELECT \n    b.[PARTNER] as BP,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n    [ID_UNIDAD],\n    [FECHA_CREACION] AS FECHA_INICIAL,\n    [FECHA_RESOLUCION] AS FECHA_FINAL,\n    CONCAT('PQR ', LOWER([CAUSA])) AS ACTIVIDAD,\n    DATEDIFF(SECOND, [FECHA_CREACION], [FECHA_RESOLUCION]) AS TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    ISNULL(a.[ID_CATEGORIA],4) AS ID_CATEGORIA,\n    -1 AS ID_CURSO,\n    -1 AS ID_TIPO_ESTUDIANTE,\n    '[DWH_COMFENALCO].[Transversal].[FACT_PQRS]' AS FUENTE_PRINCIPAL\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] f\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n    ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01')\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b \n    ON f.[ID_BENEFICIARIO] =  b.[ID_BENEFICIARIO]\nLEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n    ON b.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE f.ID_BENEFICIARIO != -1 AND ID_UNIDAD in (2,3)\n</code></pre>"},{"location":"04.sharepoint/00.Introduccion/","title":"00.Introduccion","text":""},{"location":"04.sharepoint/00.Introduccion/#introduccion","title":"Introducci\u00f3n","text":""},{"location":"04.sharepoint/estructura_archivos_actualizacion/","title":"Estructura Archivos Actualizacion","text":""},{"location":"04.sharepoint/estructura_archivos_actualizacion/#sharepoint-detalle-actualizacion-archivos","title":"Sharepoint (Detalle actualizaci\u00f3n Archivos)","text":""},{"location":"04.sharepoint/estructura_archivos_actualizacion/#introduccion","title":"Introducci\u00f3n","text":"<p>La siguiente estructura detallada de los archivos organizados en SharePoint para la gesti\u00f3n de documentos relacionados con Comfenalco. Este esquema est\u00e1 dise\u00f1ado para facilitar el acceso, la actualizaci\u00f3n y el mantenimiento de los datos esenciales, asegurando que las responsabilidades y las frecuencias de actualizaci\u00f3n est\u00e9n claramente definidas.</p>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#proposito-del-documento","title":"Prop\u00f3sito del Documento","text":"<p>El prop\u00f3sito principal es servir como una gu\u00eda de referencia para:</p> <ol> <li>Ubicaci\u00f3n de Archivos: Identificar r\u00e1pidamente la ubicaci\u00f3n de cada archivo en SharePoint.</li> <li>Frecuencia de Actualizaci\u00f3n: Detallar la periodicidad con la que los archivos deben ser actualizados para mantener la informaci\u00f3n al d\u00eda.</li> <li>Responsables: Asignar claramente las responsabilidades para el mantenimiento de cada archivo.</li> <li>Observaciones Espec\u00edficas: Incluir notas relevantes, como la nomenclatura para los a\u00f1os o dependencias de terceros, para garantizar un correcto entendimiento de cada archivo.</li> </ol>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#estructura-del-documento","title":"Estructura del Documento","text":"<ol> <li>03.Archivos_Manuales:</li> <li> <p>Contiene subcarpetas que agrupan documentos seleccionados, estructuras propuestas y otros archivos categorizados en \u00e1reas como Transversal, Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica y Continua, y Protecci\u00f3n Social.</p> </li> <li> <p>Detalles por Archivo:</p> </li> <li>Cada archivo cuenta con la siguiente informaci\u00f3n:<ul> <li>Nombre del Archivo: Identificaci\u00f3n \u00fanica del documento.</li> <li>Ubicaci\u00f3n: Ruta exacta en SharePoint.</li> <li>Unidad: \u00c1rea responsable o relacionada con el contenido del archivo.</li> <li>Frecuencia de Actualizaci\u00f3n: Intervalo en el que debe ser revisado o actualizado.</li> <li>Responsable: Personas o equipos encargados del mantenimiento del documento.</li> <li>Observaciones: Detalles adicionales relevantes, como la estructura del nombre o el prop\u00f3sito del archivo.</li> </ul> </li> </ol>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#ejemplo-de-uso","title":"Ejemplo de Uso","text":"<ul> <li>Archivo: <code>AM-TRA-08.xlsx</code></li> <li>Ubicaci\u00f3n: <code>03.Archivos_Manuales/01.Archivos_Seleccionados/01.Transversal/01.Dim_Servicios</code></li> <li>Frecuencia de Actualizaci\u00f3n: Anual.</li> <li>Responsable: Planeaci\u00f3n y Presupuesto.</li> <li>Observaci\u00f3n: Archivos que incluyen un a\u00f1o en el nombre, por ejemplo, <code>AM-TRA-08_2024.xlsx</code>.</li> </ul>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#beneficios-del-documento","title":"Beneficios del Documento","text":"<ol> <li>Estandarizaci\u00f3n: Facilita el acceso y evita duplicaci\u00f3n o errores en la gesti\u00f3n documental.</li> <li>Claridad: Define roles y frecuencias, lo que asegura la actualizaci\u00f3n constante de los datos.</li> <li>Escalabilidad: Permite integrar nuevos archivos sin perder la organizaci\u00f3n.</li> </ol>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#actualizacion-de-archivos","title":"Actualizaci\u00f3n de archivos","text":"03.Archivos_Manuales 01.Archivos_Seleccionados 01.Transversal 01.Dim_Servicios <ul> <li>Archivo: AM-TRA-08.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/01.Archivos_Seleccionados/01.Transversal/01.Dim_Servicios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 02.Educacion_Formal 01.Dim_Libros <ul> <li>Archivo: AM-EDF-153.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/01.Archivos_Seleccionados/02.Educacion_Formal/01.Dim_Libros</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE BIBLIOTECA/AUXILIAR DE BIBLIOTECA Observaciones: Sin observaciones.</li> </ul> 02.Estructuras_Propuestas 01.Transversal 01.Dim_Servicios <ul> <li>Archivo: EP-TRA-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/01.Transversal/01.Dim_Servicios</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n; Planeaci\u00f3n y Presupuesto Observaciones: Sin observaciones.</li> </ul> 02.Dim_Capacidad_Fisica <ul> <li>Archivo: EP-TRA-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/01.Transversal/02.Dim_Capacidad_Fisica</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Sin observaciones.</li> </ul> 02.Educacion_Formal 01.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/01.DIM_PERSONAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 02.FACT_AUSENTISMO_DOCENTE <ul> <li>Archivo: EP-EDF-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/02.FACT_AUSENTISMO_DOCENTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORD. ACAD\u00c9MICAS Observaciones: Sin observaciones.</li> </ul> 03.FACT_BIBLIOTECA <ul> <li>Archivo: EP-EDF-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/03.FACT_BIBLIOTECA</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE BIBLIOTECA/AUXILIAR DE BIBLIOTECA Observaciones: Sin observaciones.</li> </ul> 04.FACT_BIBLIOTECA_VIRTUAL <ul> <li>Archivo: EP-EDF-06.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/04.FACT_BIBLIOTECA_VIRTUAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE BIBLIOTECA/AUXILIAR DE BIBLIOTECA Observaciones: Sin observaciones.</li> </ul> 05.FACT_DESEMPENHO_DOCENTE <ul> <li>Archivo: EP-EDF-09.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/05.FACT_DESEMPENHO_DOCENTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 06.FACT_ENFERMERIA <ul> <li>Archivo: EP-EDF-01.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/06.FACT_ENFERMERIA</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Enfermera Observaciones: Sin observaciones.</li> </ul> 07.FACT_LEGALIZACION <ul> <li>Archivo: EP-EDF-10.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/07.FACT_LEGALIZACION</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ANALISTA DE RECURSOS TECNOL\u00d3GICOS Observaciones: Sin observaciones.</li> </ul> 08.FACT_PERMISO_ESTUDIANTE <ul> <li>Archivo: EP-EDF-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/08.FACT_PERMISO_ESTUDIANTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 09.FACT_PSIORIENTACION <ul> <li>Archivo: EP-EDF-11.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/09.FACT_PSIORIENTACION</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADOR DE PSICOLOG\u00cdA Observaciones: Sin observaciones.</li> </ul> 10.FACT_REEMPLAZO_DOCENTE <ul> <li>Archivo: EP-EDF-03.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/10.FACT_REEMPLAZO_DOCENTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORD. ACAD\u00c9MICAS Observaciones: Sin observaciones.</li> </ul> 11.FACT_RESERVA_ESPACIOS <ul> <li>Archivo: EP-EDF-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/11.FACT_RESERVA_ESPACIOS</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: ANALISTA DE RECURSOS F\u00cdSICOS Y ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 12.FACT_SABER11_COLEGIOS <ul> <li>Archivo: EP-EDF-08.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/12.FACT_SABER11_COLEGIOS</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 13.FACT_SABER11_INDIVIDUAL <ul> <li>Archivo: EP-EDF-07.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/13.FACT_SABER11_INDIVIDUAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 14.FACT_SERVICIO_SOCIAL <ul> <li>Archivo: EP-EDF-13.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/14.FACT_SERVICIO_SOCIAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ASISTENTE ACAD\u00c9MICO BSMA Observaciones: Sin observaciones.</li> </ul> 03.Educacion_Tecnica 01.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/03.Educacion_Tecnica/01.DIM_PERSONAL</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 04.Educacion_Continua 01.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/04.Educacion_Continua/01.DIM_PERSONAL</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 05.Proteccion_Social 01.Caracterizacion AM-PRS-03 <ul> <li>Archivo: AM-PRS-03.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-03</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI y JEC. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> AM-PRS-10 <ul> <li>Archivo: AM-PRS-10.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-10</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para Adulto Mayor. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-102 <ul> <li>Archivo: AM-PRS-102.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-102</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Trimestral Responsable del Documento: Analista de protecci\u00f3n social Observaciones: Sin observaciones.</li> </ul> AM-PRS-11 <ul> <li>Archivo: AM-PRS-11.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-11</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para Discapacidad. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-12 <ul> <li>Archivo: AM-PRS-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-12</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para JEC. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-120 <ul> <li>Archivo: AM-PRS-120.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-120</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Analista de protecci\u00f3n social Observaciones: Sin observaciones.</li> </ul> AM-PRS-13 <ul> <li>Archivo: AM-PRS-13.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-13</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-145 <ul> <li>Archivo: AM-PRS-145.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-145</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI.</li> </ul> AM-PRS-145_CATEGORICAS <ul> <li>Archivo: AM-PRS-145_CATEGORICAS.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-145_CATEGORICAS</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: A demanda Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI.</li> </ul> AM-PRS-23 <ul> <li>Archivo: AM-PRS-23.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-23</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADORA DE PROGRAMA \u2013 AUXILIAR DE DEPARTAMENTO DE PROTECCI\u00d3N SOCIAL Observaciones: Sin observaciones.</li> </ul> AM-PRS-41 <ul> <li>Archivo: AM-PRS-41.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-41</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: AUXILIAR DE DEPARTAMENTO DE PROTECCI\u00d3N SOCIAL Observaciones: Sin observaciones.</li> </ul> AM-PRS-81 <ul> <li>Archivo: AM-PRS-81.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-81</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE PROGRAMA Observaciones: Para AIPI.</li> </ul> AM-PRS-91 <ul> <li>Archivo: AM-PRS-91.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-91</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADOR DE PROGRAMA Observaciones: Para JEC.</li> </ul> AM-PRS-91_CATEGORICAS <ul> <li>Archivo: AM-PRS-91_CATEGORICAS.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-91_CATEGORICAS</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADOR DE PROGRAMA Observaciones: Para JEC.</li> </ul> DIM_PROGRAMA <ul> <li>Archivo: ID_PROGRAMA.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/DIM_PROGRAMA</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: A demanda Responsable del Documento: Analista de protecci\u00f3n social Observaciones: Sin observaciones.</li> </ul> EP-PRS-02 <ul> <li>Archivo: EP-PSR-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PRS-02</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Sin observaciones.</li> </ul> EP-PRS-03 <ul> <li>Archivo: EP-PSR-03.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PRS-03</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Sin observaciones.</li> </ul> EP-PSR-01 <ul> <li>Archivo: EP-PSR-01.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PSR-01</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI.</li> </ul> EP-TRA-02 <ul> <li>Archivo: EP-TRA-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-TRA-02</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n Observaciones: Sin observaciones.</li> </ul> NSU/CEC <ul> <li>Archivo: CEC (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: CEC.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Cedesarrollo convenios <ul> <li>Archivo: campanas comfenalcoconvenios (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Convenios (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Convenios.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Consultorias <ul> <li>Archivo: campanas comfenalcoconsultorias (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Consultorias (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Consultorias.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Cursos y diplomados <ul> <li>Archivo: campanas comfenalcodiplomados (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Cursos y diplomados (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Cursos y diplomados.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Egresados <ul> <li>Archivo: comfenalcocedesarrolloegresados (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Egresado (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Egresado.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Estudiantes Activos <ul> <li>Archivo: base1.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base1Activos1.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base2.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base2Activos0.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base3.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base4.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base5.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Estudiantes Activos (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Estudiantes Activos.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Proteccion social <ul> <li>Archivo: campanas comfenalcoproteccion(2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoproteccion(3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoproteccion(4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoproteccion(5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Proteccion social (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Proteccion social.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> 02.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/02.DIM_PERSONAL</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 03.Otros_Archivos <ul> <li>Archivo: AM-DRE-05_08_12_2024.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: AUXILIAR ADMINISTRATIVO/ANALISTAS DE SERVICIO EMPRESARIAL/ANALISTA DE FOMENTO EMPRESARIAL Observaciones: Sin observaciones.</li> <li>Archivo: AM-DRE-16.xls Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: PERSONAL EXPERTO/ANALISTA DE FOMENTO EMPRESARIAL/ANALISTA DE SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: AM-EPT-47.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: COORDINADOR DE SERVICIOS TECNOL\u00d3GICOS Observaciones: Sin observaciones.</li> <li>Archivo: EP-EDF-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EDF-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EDF-09.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EDF-09_01_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: COORDINADOR DE SERVICIOS TECNOL\u00d3GICOS Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: PERSONAL EXPERTO/ANALISTA DE FOMENTO EMPRESARIAL/ANALISTA DE SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-06.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-06_10_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-06_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-07.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-07_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-08.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: ANALISTA SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-08_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: ANALISTA SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-09.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-10.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ANALISTA DE SERVICIOS EMPRESARIALES/ANALISTA DE FOMENTO EMPRESARIAL Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-10_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ANALISTA DE SERVICIOS EMPRESARIALES/ANALISTA DE FOMENTO EMPRESARIAL Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-11.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: A demanda Responsable del Documento: PERSONAL EXPERTO/ANALISTA DE FOMENTO EMPRESARIAL/ANALISTA DE SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> </ul> <p>```</p>"},{"location":"04.sharepoint/estructura_sharepoint/","title":"Estructura carpeta Sharepoint","text":""},{"location":"04.sharepoint/estructura_sharepoint/#sharepoint-configuracion-y-estructura","title":"Sharepoint (Configuraci\u00f3n y Estructura)","text":""},{"location":"04.sharepoint/estructura_sharepoint/#introduccion","title":"Introducci\u00f3n","text":"<p>La integraci\u00f3n de SharePoint con los procesos ETL (Extract, Transform, Load) garantiza una gesti\u00f3n centralizada, accesible y segura de los datos capturados mediante t\u00e9cnicas avanzadas de webscraping. Este enfoque permite organizar, almacenar y compartir informaci\u00f3n acad\u00e9mica y administrativa de manera eficiente, asegurando que los equipos involucrados puedan acceder a datos actualizados y estructurados.</p> <p>En el \u00e1mbito de la Educaci\u00f3n T\u00e9cnica y Continua, SharePoint se convierte en una herramienta clave para el manejo de los datos procesados, facilitando la colaboraci\u00f3n entre m\u00faltiples actores y plataformas. La implementaci\u00f3n de una estructura bien definida de carpetas y permisos asegura que los flujos de trabajo sean consistentes y escalables.</p>"},{"location":"04.sharepoint/estructura_sharepoint/#principales-caracteristicas-de-la-configuracion","title":"Principales Caracter\u00edsticas de la Configuraci\u00f3n","text":"<ol> <li>Creaci\u00f3n del Sitio del Proyecto:    El sitio COMFENALCO_EDUCACION act\u00faa como el repositorio principal de los datos extra\u00eddos, procesados y consolidados.</li> <li> <p>Estructuraci\u00f3n de Carpetas:  </p> <ul> <li>Las carpetas est\u00e1n organizadas en niveles jer\u00e1rquicos, categorizando los datos seg\u00fan su origen y prop\u00f3sito.</li> <li>Subcarpetas espec\u00edficas almacenan datos procesados y sin procesar, lo que permite un control preciso de las versiones y una f\u00e1cil recuperaci\u00f3n de informaci\u00f3n.</li> </ul> </li> <li> <p>Autenticaci\u00f3n Segura mediante Azure:  </p> <ul> <li>Registro de una aplicaci\u00f3n en Azure para la autenticaci\u00f3n de SharePoint.</li> <li>Uso de un cliente secreto y certificados para garantizar un acceso seguro a los datos.</li> </ul> </li> <li> <p>Gesti\u00f3n de Permisos:  </p> <ul> <li>Configuraci\u00f3n de permisos espec\u00edficos para aplicaciones como <code>Sites.FullControl.All</code> y <code>TermStore.Read.All</code>.</li> <li>Garant\u00eda de que solo usuarios autorizados puedan acceder y modificar la informaci\u00f3n almacenada.</li> </ul> </li> <li> <p>Automatizaci\u00f3n con Python:  </p> <ul> <li>El c\u00f3digo <code>SharePoint_Connection.py</code> permite interactuar directamente con las carpetas y archivos de SharePoint, automatizando procesos como la carga y extracci\u00f3n de datos.</li> </ul> </li> </ol>"},{"location":"04.sharepoint/estructura_sharepoint/#metodologia-para-configuracion-sharepoint-online-para-web-scrapping-y-ssis","title":"Metodolog\u00eda para Configuraci\u00f3n Sharepoint Online para Web Scrapping y SSIS","text":"<ol> <li>Crear en SharePoint el sitio del proyecto (<code>COMFENALCO_EDUCACION</code>)</li> <li> <p>En la parte de documentos crear las carpetas necesarias</p> <p></p> </li> <li> <p>En <code>Azure</code> ir a <code>Registro de Aplicaciones</code></p> </li> <li>Crear una nueva aplicaci\u00f3n.</li> <li>Asignarle un cliente secreto y copiar y guardar el <code>secret_client</code> que se genera. Solo se puede ver en este momento.</li> <li> <p>Subir un certificado. En la carpeta donde se vaya a crear la ETL de Web Scraping correr el siguiente comando y subir el archivo generado.     </p> <p>Observaciones</p> <ul> <li>Puede ser necesario instalar <code>OpenSSL</code> en Windows. Gu\u00eda para instalar <code>https://www.youtube.com/watch?v=coaGBdUcKiw</code></li> <li>Se puede tomar como referencia el siguiente video <code>https://www.youtube.com/watch?v=KWKiwpK-L5o</code></li> </ul> </li> <li> <p>Luego ir a <code>Permisos de API</code> y agregar un nuevo permiso. Buscar la aplicaci\u00f3n <code>SharePoint</code> y escoger permisos de aplicaci\u00f3n <code>Sites.FullControl.All</code>, <code>Real.All</code>, <code>TermStore.Read.all</code> </p> </li> <li>Conceder el permiso del paso anterior. Para este paso se requieren permisos de administrador en la consola de Azure. </li> <li>Con esto el c\u00f3digo de <code>SharePoint_Connection.py</code> debe funcionar. Tener cuidado de la carpeta a la cual se est\u00e1 dirigiendo en la variable <code>folder_url</code></li> </ol>"},{"location":"04.sharepoint/estructura_sharepoint/#estructura-de-la-carpeta","title":"Estructura de la Carpeta","text":""},{"location":"04.sharepoint/estructura_sharepoint/#comfenalco-educacion","title":"COMFENALCO EDUCACION","text":"Estructura de Carpetas Contraer todo Contiene los archivos resultado del WebScraping de diferentes plataformas relacionadas con la educaci\u00f3n y convenios de Comfenalco. 01.Q10 <ul> Carpeta principal con los datos extra\u00eddos del sistema Q10, organizados en categor\u00edas espec\u00edficas. 01.Educacion_Tecnica <ul> Subcarpeta con informaci\u00f3n t\u00e9cnica sobre docentes, matr\u00edculas, ingresos y notas hist\u00f3ricas. 01.Docentes <ul> Contiene archivos relacionados con los registros de los docentes procesados y sin procesar. <li>Docentes_08_12_2024.xlsx </li> <li>Docentes_09_12_2024.xlsx </li> <li>Docentes_20_11_2024.xlsx </li> <li>Docentes_21_11_2024.xlsx </li> <li>Docentes_23_11_2024.xlsx </li> <li>Docentes_23_12_2024.xlsx </li> <li>Docentes_27_12_2024.xlsx </li> </ul> 02.Disenio_Curricular <ul> Archivos relacionados con el plan de estudios (Pensum) de cada programa. <li>Dise\u00f1o_Curricular_08_12_2024.xlsx </li> <li>Dise\u00f1o_Curricular_17_12_2024.xlsx </li> <li>Dise\u00f1o_Curricular_20_11_2024.xlsx </li> <li>Dise\u00f1o_Curricular_21_11_2024.xlsx </li> <li>Dise\u00f1o_Curricular_27_12_2024.xlsx </li> </ul> 03.Listado_Matriculas <ul> Listado de matr\u00edculas con el listado de los estudiantes que fueron matriculados en un programa espec\u00edfico en el rango de fechas o periodo seleccionado. <li>Listado_Matriculas_01_01_2016_31_12_2016_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2016_31_12_2016_Act_24_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2017_31_12_2017_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2017_31_12_2017_Act_24_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2017_31_12_2017_Act_24_11_20241.xlsx </li> <li>Listado_Matriculas_01_01_2018_31_12_2018_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2018_31_12_2018_Act_24_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2019_31_12_2019_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2020_31_12_2020_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2021_31_12_2021_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2022_31_12_2022_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2023_31_12_2023_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_28_11_2024_Act_28_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_30_06_2024_Act_27_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_31_12_2024_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_31_12_2024_Act_27_12_2024.xlsx </li> </ul> 04.Ingresos <ul> Listado de archivos contiene el dinero recibido por concepto de pagos registrados en las diferentes modalidades de recaudo. <li>Ingresos_01_01_2017_31_12_2017_23_12_2024.xlsx </li> <li>Ingresos_01_01_2018_31_12_2018_23_12_2024.xlsx </li> <li>Ingresos_01_01_2019_31_12_2019_23_12_2024.xlsx </li> <li>Ingresos_01_01_2020_31_12_2020_23_12_2024.xlsx </li> <li>Ingresos_01_01_2020_31_12_2020_27_12_2024.xlsx </li> <li>Ingresos_01_01_2021_31_12_2021_23_12_2024.xlsx </li> <li>Ingresos_01_01_2022_31_12_2022_23_12_2024.xlsx </li> <li>Ingresos_01_01_2023_31_12_2023_23_12_2024.xlsx </li> <li>Ingresos_01_01_2024_31_12_2024_23_12_2024.xlsx </li> </ul> 05.Historico_Notas<ul> Historial detallado de los cursos que han sido archivados con sus respectivos estudiantes y notas. <li>- Historico_Notas_2023_2_0100c7e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_026fa7c8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_02cbe285_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0449a5e7_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_07dba647_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_092aac38_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0cddad19_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0dff50cb_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0e7858c3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_10375576_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_109d6949_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_121fad89_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_12dc19a4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_1735f955_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_185ac97e_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_1958d0f8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_1a220917_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2210ee55_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2226d5a5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2380e5e7_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_24b41186_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_273540de_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_29769f40_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2be84da8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2d29660f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2e068ad5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2ee8230e_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_306b3846_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_30cc8d74_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_32e309f0_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_33b9edfc_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_378b0fac_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_384c0f48_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4215b767_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_46b79fc3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4921f516_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4bad2c64_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4d3cc959_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4dc601e8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_541f1898_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_55a3bd93_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_55e6763f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_58f870e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_5f5f368b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_62908c57_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6500f569_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6540bc55_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_66b59284_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_68bb266b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6b58a8a9_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6ef0249a_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6f559dd2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_73887911_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7a4650f1_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7a962879_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7c26c9fe_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7e5281f2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7eaa6bf3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7ecf3546_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_81280bf5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_812e8d89_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_85fd6ce5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_885e0511_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_88851305_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_8a1dc0e8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_8ead704b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_8fd27aa1_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_91cb763c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_956755ea_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_9776db00_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_9a88ca6d_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_a8543b8f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_a895cfc3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ab2d75de_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ac6e1db1_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ad933526_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_af9aa73c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_b1d06454_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_b88458df_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_baec81f2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_bb6bce34_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_bbb5dd53_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_bec15051_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c155c17a_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c3b000d2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c576f83c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c6407892_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c9ac9d62_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_caa22d82_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_cae7be5c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_cbf22cd4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ccb297f0_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d413cda3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d573164b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d888e4af_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d9bd30a3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_dadd2624_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_db34b6b2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_dea03ce6_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_df10e46e_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_df7dbde9_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e1111635_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e6f87f14_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e7ec41ef_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e964d7d0_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ec138d23_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_eccbecbe_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_eea8e976_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f02f4642_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f0a906ec_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f104cb7f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f18569e3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f2835d58_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f75fcc99_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f8939331_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f9c45ab6_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f9d3b157_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_fa3190bf_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_fabd1fb4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_fcd657ef_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_046ce457_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_0e466b26_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_0f91b4b0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1130b71a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_12570c3e_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1a458bff_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1e01dc0c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1e36519c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1e949cc6_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1f4264e3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1f5150ed_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_248946e3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_28e1fc5a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_2c7b3b56_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_316ee9d7_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3255b38a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3283e4b3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_35394ea3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3588253c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3a428752_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3b426767_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3fa7f518_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_40fae1d1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_4ec16e1f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_50b5f8e0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_535a9c53_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_5d9b1d37_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_5ee76ea0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_62d748e5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_64183122_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_68eb8641_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_6e7f7ac5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_6f3268f9_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_6f48dd2f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_700898eb_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7044b236_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_741e9221_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_75f1b194_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_769e73ee_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_796685b9_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7b2d09b2_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7b8a67d1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7b8caefb_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7cf1c303_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7d9ff89c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7e2ece94_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7f88a9c1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7fd4026f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_82c2d334_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_86841d92_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_86fe6856_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_8870b866_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_898499c8_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_8a325911_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_8c233e77_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_9051cfba_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_91ca2296_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_95a35066_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_964ae673_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_978c7d05_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_98f3faec_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_9a46e7e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_9e635b41_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a2182500_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a4e412ce_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a80338d1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a8d30ce5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a9862f6d_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a9eb40a4_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_aa322057_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_ab514259_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_af9f6622_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b06dc7df_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b5c640c2_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b5f21992_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b8884db6_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b95c9d2a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_bb80a2a7_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_c5c6495d_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_c7133773_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_c7583eed_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_ca93eb94_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_cba65ff5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_cc57a34b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d1ce1966_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d34f5bf8_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d68444b2_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d812cccc_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d9aa91e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dc6f2109_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dccac103_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dcd84c6c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dcf2b57f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e3430d8b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e4ad961e_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e546f874_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e6a6da65_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e9175c3b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e91bf7dc_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_ef1d746b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f541b731_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f70675c0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f828cd1a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f9e953ce_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_fb4fd7a6_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_fbb74184_24_12_2024.xlsx </li> <li>- Historico_Notas_AA-Com. Org-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Compras-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Cont. Inv. Apli-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Gest. Doc-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Htas. Apoy. Tec-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Htas. Apoy. Tec-JN-G2-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-PROD.DOC-JM-S1-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-PROD.DOC-JN-S1-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-PROD.DOC-JN-S1-G2-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Sem. Tra. Emp-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_MV-Est. Can. Dist-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_MV-Estrat. Prec.-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_MV-Inv. Merc.-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-IMP.SG-SST-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-Sem. Tra. Emp-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-Sem. Tra. V.S-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-STAR-2-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_T\u00e9cnico Laboral en Auxiliar Administrativo_27_11_2024.xlsx </li> </ul> 06.Egresados_Graduados<ul> Nota: Contiene archivos de Excel con la informaci\u00f3n de los egresados y graduados.                          <li>- Graduados_2010 - 1_21_11_2024.xlsx </li> <li>- Graduados_2010 - 2_21_11_2024.xlsx </li> <li>- Graduados_2011 - 1_21_11_2024.xlsx </li> <li>- Graduados_2011 - 2_21_11_2024.xlsx </li> <li>- Graduados_2012 - 1_21_11_2024.xlsx </li> <li>- Graduados_2012 - 2_21_11_2024.xlsx </li> <li>- Graduados_2013 - 1_21_11_2024.xlsx </li> <li>- Graduados_2013 - 2_21_11_2024.xlsx </li> <li>- Graduados_2014 - 1_21_11_2024.xlsx </li> <li>- Graduados_2014 - 2_21_11_2024.xlsx </li> <li>- Graduados_2015 - 1_21_11_2024.xlsx </li> <li>- Graduados_2015 - 2_21_11_2024.xlsx </li> <li>- Graduados_2016 - 1_21_11_2024.xlsx </li> <li>- Graduados_2016 - 1_24_12_2024.xlsx </li> <li>- Graduados_2016 - 2_21_11_2024.xlsx </li> <li>- Graduados_2016 - 2_24_12_2024.xlsx </li> <li>- Graduados_2017 - 1_21_11_2024.xlsx </li> <li>- Graduados_2017 - 1_24_12_2024.xlsx </li> <li>- Graduados_2017 - 2_21_11_2024.xlsx </li> <li>- Graduados_2017 - 2_24_12_2024.xlsx </li> <li>- Graduados_2018-1_21_11_2024.xlsx </li> <li>- Graduados_2018-1_24_12_2024.xlsx </li> <li>- Graduados_2018-2_21_11_2024.xlsx </li> <li>- Graduados_2018-2_24_12_2024.xlsx </li> <li>- Graduados_2019-1 CONVENIO_21_11_2024.xlsx </li> <li>- Graduados_2019-1 CONVENIO_24_12_2024.xlsx </li> <li>- Graduados_2019-1_21_11_2024.xlsx </li> <li>- Graduados_2019-1_24_12_2024.xlsx </li> <li>- Graduados_2019-2_21_11_2024.xlsx </li> <li>- Graduados_2019-2_24_12_2024.xlsx </li> <li>- Graduados_2020-1_21_11_2024.xlsx </li> <li>- Graduados_2020-1_24_12_2024.xlsx </li> <li>- Graduados_2020-2_21_11_2024.xlsx </li> <li>- Graduados_2020-2_24_12_2024.xlsx </li> <li>- Graduados_2021-1_21_11_2024.xlsx </li> <li>- Graduados_2021-1_24_12_2024.xlsx </li> <li>- Graduados_2021-2_21_11_2024.xlsx </li> <li>- Graduados_2021-2_24_12_2024.xlsx </li> <li>- Graduados_2022-1_21_11_2024.xlsx </li> <li>- Graduados_2022-1_24_12_2024.xlsx </li> <li>- Graduados_2022-2_21_11_2024.xlsx </li> <li>- Graduados_2022-2_24_12_2024.xlsx </li> <li>- Graduados_2023-1_21_11_2024.xlsx </li> <li>- Graduados_2023-1_24_12_2024.xlsx </li> <li>- Graduados_2023-2_21_11_2024.xlsx </li> <li>- Graduados_2023-2_24_12_2024.xlsx </li> <li>- Graduados_2024-1_21_11_2024.xlsx </li> <li>- Graduados_2024-1_24_12_2024.xlsx </li> <li>- Graduados_2024-1_27_12_2024.xlsx </li> <li>- Graduados_2024-2_21_11_2024.xlsx </li> <li>- Graduados_2024-2_24_12_2024.xlsx </li> <li>- Graduados_2024-2_27_12_2024.xlsx </li> <li>- Graduados_23_12_2024.xlsx </li> <li>- Graduados_Agosto 2024_23_12_2024.xlsx </li> <li>- Graduados_Julio 2024_23_12_2024.xlsx </li> <li>- Graduados_Junio 2024_23_12_2024.xlsx </li> <li>- Graduados_Octubre 2024_23_12_2024.xlsx </li> <li>- Graduados_Septiembre 2024_23_12_2024.xlsx </li> </ul> 07.Cancelados_Desertores<ul> Nota: Contiene los registros de estudiantes que han cancelado su matr\u00edcula con su respectiva causa y descripci\u00f3n.                          <li>- Cancelados_desertores_01_02_2024_04_10_2024.xlsx </li> <li>- Cancelados_desertores_01_02_2024_22_03_2024.xlsx </li> <li>- Cancelados_desertores_03_02_2020_12_12_2020.xlsx </li> <li>- Cancelados_desertores_10_02_2022_21_10_2022.xlsx </li> <li>- Cancelados_desertores_11_02_2023_09_10_2023.xlsx </li> <li>- Cancelados_desertores_11_03_2019_03_12_2019.xlsx </li> <li>- Cancelados_desertores_28_02_2021_23_12_2021.xlsx </li> <li>- Cancelados_desertores_31_08_2018_04_10_2018.xlsx </li> </ul> Procesados<ul> Nota: Esta secci\u00f3n contiene los archivos procesados, organizados seg\u00fan la misma estructura jer\u00e1rquica de carpetas original. Los datos han sido preparados y optimizados para su integraci\u00f3n y consumo directo mediante SSIS, garantizando compatibilidad y eficiencia en los procesos ETL.                          01.Docentes<ul> <li>- procesado_cede_Docentes_08_12_2024_20_27.xlsx </li> <li>- procesado_cede_Docentes_23_12_2024_14_39.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_11_52.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_11_53.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_12_18.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_12_26.xlsx </li> 02.Disenio_Curricular<ul> <li>- procesado_cede_Dise\u00f1o_Curricular_08_12_2024_20_28.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_23_12_2024_14_41.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_27_12_2024_12_02.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_27_12_2024_12_03.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_27_12_2024_14_05.xlsx </li> 03.Listado_Matriculas<ul> <li>- procesado_cede_Listado_Matriculas_08_12_2024_20_21.xlsx </li> <li>- procesado_cede_Listado_Matriculas_08_12_2024_20_26.xlsx </li> <li>- procesado_cede_Listado_Matriculas_17_12_2024_09_34.xlsx </li> <li>- procesado_cede_Listado_Matriculas_23_12_2024_14_45.xlsx </li> <li>- procesado_cede_Listado_Matriculas_27_12_2024_12_09.xlsx </li> 04.Ingresos<ul> <li>- procesado_cede_Ingresos_08_12_2024_20_32.xlsx </li> <li>- procesado_cede_Ingresos_23_12_2024_14_56.xlsx </li> <li>- procesado_cede_Ingresos_27_12_2024_14_11.xlsx </li> 05.Historico_Notas<ul> <li>- procesado_cede_Historico_Notas_08_12_2024_20_36.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_08_44.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_08_50.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_09_04.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_09_20.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_09_23.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_18_15.xlsx </li> 06.Egresados_Graduados<ul> <li>- procesado_cede_Egresados_Graduados_08_12_2024_20_38.xlsx </li> <li>- procesado_cede_Egresados_Graduados_23_12_2024_21_28.xlsx </li> <li>- procesado_cede_Egresados_Graduados_24_12_2024_19_42.xlsx </li> 07.Cancelados_Desertores<ul> <li>- procesado_cede_Cancelados_Desertores_08_12_2024_20_41.xlsx </li> <li>- procesado_cede_Cancelados_Desertores_24_12_2024_20_14.xlsx </li> </ul> </ul> </ul> 02.Educacion_Continua Nota: Contiene registros de docentes relacionados con programas de educaci\u00f3n continua.                  <ul> 01.Docentes<ul> Nota: Listado de preinscritos en programas de educaci\u00f3n continua.                          <li>- Docentes_08_12_2024.xlsx </li> <li>- Docentes_20_11_2024.xlsx </li> <li>- Docentes_21_11_2024.xlsx </li> <li>- Docentes_25_12_2024.xlsx </li> <li>- Docentes_28_12_2024.xlsx </li> <li>- Docentes_30_11_2024.xlsx </li> </ul> 02.Preinscritos<ul> Nota: Archivos detallados de preinscritos en programas de educaci\u00f3n continua.                          <li>- Preinscritos_20_11_2024.xlsx </li> <li>- Preinscritos_21_11_2024.xlsx </li> <li>- Preinscritos_25_12_2024.xlsx </li> <li>- Preinscritos_27_12_2024.xlsx </li> <li>- Preinscritos_30_11_2024.xlsx </li> </ul> 03.Listado_Matriculas<ul> Nota: Listado de los estudiantes que fueron matriculados en un programa espec\u00edfico en el rango de fechas o periodo seleccionado.                          <li>- Listado_Matriculas_01_01_2018_31_12_2018_Act_30_11_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2019_30_06_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2019_31_03_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2020_31_03_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2021_31_03_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2022_31_03_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2023_31_03_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2024_31_03_2024_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2024_31_03_2024_Act_27_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2019_30_06_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2020_30_06_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2021_30_06_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2022_30_06_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2023_30_06_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2024_30_06_2024_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2024_30_06_2024_Act_27_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2018_31_12_2018_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2019_30_09_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2020_30_09_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2021_30_09_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2022_30_09_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2023_30_09_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2018_31_12_2018_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2019_31_12_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2020_31_12_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2021_31_12_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2022_31_12_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2023_31_12_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2024_31_12_2024_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2024_31_12_2024_Act_27_12_2024.xlsx </li> </ul> 04.Consolidado_inasistencias<ul> Nota: <li>- Consolidado_Inasistencias_1020.xlsx </li> <li>- Consolidado_Inasistencias_Consolidado_de_Inasistencias (1).xlsx </li> <li>- Consolidado_Inasistencias_Desarrollo Empresarial - Ma\u00f1ana_AUTOCONFIANZA_Noviembre 2024.xlsx </li> </ul> 05.Estudiantes_cancelados_por_inasistencias<ul> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Diciembre 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Diciembre 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Julio 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Septiembre 2023.xlsx </li> </ul> 06.Egresados_Graduados<ul> <li>- Graduados_Abril 2022_21_11_2024.xlsx </li> <li>- Graduados_Abril 2023_21_11_2024.xlsx </li> <li>- Graduados_Abril 2024_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2021_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2022_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2023_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2024_21_11_2024.xlsx </li> <li>- Graduados_Diciembre 2021_21_11_2024.xlsx </li> <li>- Graduados_Diciembre 2022_21_11_2024.xlsx </li> <li>- Graduados_Diciembre 2023_21_11_2024.xlsx </li> <li>- Graduados_Enero 2022_21_11_2024.xlsx </li> <li>- Graduados_Enero 2023_21_11_2024.xlsx </li> <li>- Graduados_Enero 2024_21_11_2024.xlsx </li> <li>- Graduados_Febrero 2022_21_11_2024.xlsx </li> <li>- Graduados_Febrero 2023_21_11_2024.xlsx </li> <li>- Graduados_Febrero 2024_21_11_2024.xlsx </li> <li>- Graduados_Julio 2022_21_11_2024.xlsx </li> <li>- Graduados_Julio 2023_21_11_2024.xlsx </li> <li>- Graduados_Julio 2024_21_11_2024.xlsx </li> <li>- Graduados_Junio 2022_21_11_2024.xlsx </li> <li>- Graduados_Junio 2023_21_11_2024.xlsx </li> <li>- Graduados_Junio 2024_21_11_2024.xlsx </li> <li>- Graduados_Marzo 2022_21_11_2024.xlsx </li> <li>- Graduados_Marzo 2023_21_11_2024.xlsx </li> <li>- Graduados_Marzo 2024_21_11_2024.xlsx </li> <li>- Graduados_Mayo 2022_21_11_2024.xlsx </li> <li>- Graduados_Mayo 2023_21_11_2024.xlsx </li> <li>- Graduados_Mayo 2024_21_11_2024.xlsx </li> <li>- Graduados_Noviembre 2022_21_11_2024.xlsx </li> <li>- Graduados_Noviembre 2023_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2019_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2021_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2022_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2023_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2024_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2021_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2022_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2023_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2024_21_11_2024.xlsx </li> </ul> Procesados Nota: Esta secci\u00f3n contiene los archivos procesados, organizados seg\u00fan la misma estructura jer\u00e1rquica de carpetas original. Los datos han sido preparados y optimizados para su integraci\u00f3n y consumo directo mediante SSIS, garantizando compatibilidad y eficiencia en los procesos ETL.                                                  0001.Docentes<ul> <li>- procesado_emp_Docentes_06_12_2024_19_05.xlsx </li> <li>- procesado_emp_Docentes_06_12_2024_19_06.xlsx </li> <li>- procesado_emp_Docentes_08_12_2024_20_45.xlsx </li> <li>- procesado_emp_Docentes_25_12_2024_06_53.xlsx </li> <li>- procesado_emp_Docentes_28_12_2024_06_58.xlsx </li> </ul> 02.Preinscritos<ul> <li>- procesado_emp_Preinscritos_06_12_2024_19_09.xlsx </li> <li>- procesado_emp_Preinscritos_08_12_2024_20_52.xlsx </li> </ul> 03.Listado_Matriculas<ul> <li>- procesado_emp_Listado_Matriculas_06_12_2024_19_08.xlsx </li> <li>- procesado_emp_Listado_Matriculas_08_12_2024_20_48.xlsx </li> <li>- procesado_emp_Listado_Matriculas_25_12_2024_11_37.xlsx </li> <li>- procesado_emp_Listado_Matriculas_25_12_2024_13_05.xlsx </li> </ul> 04.Consolidado_inasistencias<ul> <li>- procesado_emp_Consolidado_inasistencias_15_12_2024_10_03.xlsx </li> <li>- procesado_emp_Consolidado_inasistencias_15_12_2024_10_11.xlsx </li> <li>- procesado_emp_Consolidado_inasistencias_28_12_2024_07_25.xlsx </li> </ul> 05.Estudiantes_cancelados_por_inasistencias<ul> <li>- procesado_emp_Estudiantes_inasistencias_04_04_2025_05_26.xlsx </li> </ul> 06.Egresados_Graduados<ul> <li>- procesado_emp_Egresados_Graduados_06_12_2024_19_11.xlsx </li> <li>- procesado_emp_Egresados_Graduados_08_12_2024_20_55.xlsx </li> <li>- procesado_emp_Egresados_Graduados_08_12_2024_21_01.xlsx </li> <li>- procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx </li> </ul> </ul> 02.C4C <ul> Datos relevantes de la plataforma C4C, divididos en categor\u00edas de educaci\u00f3n y protecci\u00f3n social. 01.Educacion<ul> <li>-archivos_C4C_Educacion.xlsx</li> </ul> 02.Proteccion<ul> <li>-archivos_C4C_Proteccion.xlsx</li> </ul> </ul> 03.Archivos_Manuales <ul> Carpeta que agrupa archivos manuales organizados por tem\u00e1ticas y \u00e1reas espec\u00edficas. 01.Archivos_Seleccionados <ul> 01.Transversal <ul> 01.Dim_Servicios<ul> <li>- AM-TRA-08.xlsx</li> <li>- AM-TRA-08_2022.xlsx</li> <li>- AM-TRA-08_2023.xlsx</li> <li>- AM-TRA-08_2024.xlsx</li> </ul> </ul> 02.Educacion_Formal <ul> 01.Dim_Libros<ul> <li>- AM-EDF-153.xlsx</li> </ul> </ul> 03.Educacion_Tecnica <li>archivos_manuales.xlsx</li> 04.Educacion_Continua <li>archivos_manuales.xlsx</li> 05.Proteccion_Social <li>archivos_manuales.xlsx</li> 02.Estructuras_Propuestas <ul> 01.Transversal <ul> 01.Dim_Servicios<ul> <li>- EP-TRA-04.xlsx</li> <li>- EP-TRA-04_2023.xlsx</li> <li>- EP-TRA-04_2024.xlsx</li> </ul> 02.Dim_Capacidad_Fisica<ul> <li>- EP-TRA-12.xlsx</li> </ul> </ul> 02.Educacion_Formal <ul> 01.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2022.xlsx</li> <li>- EP-TRA-05_2023.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> 02.FACT_AUSENTISMO_DOCENTE<ul> <li>- EP-EDF-02.xlsx</li> </ul> 03.FACT_BIBLIOTECA<ul> <li>- EP-EDF-05.xlsx</li> </ul> 04.FACT_BIBLIOTECA_VIRTUAL<ul> <li>- EP-EDF-06.xlsx</li> </ul> 05.FACT_DESEMPENHO_DOCENTE<ul> <li>- EP-EDF-09.xlsx</li> </ul> 06.FACT_ENFERMERIA<ul> <li>- EP-EDF-01.xlsx</li> </ul> 07.FACT_LEGALIZACION<ul> <li>- EP-EDF-10.xlsx</li> </ul> 08.FACT_PERMISO_ESTUDIANTE<ul> <li>- EP-EDF-04.xlsx</li> </ul> 09.FACT_PSIORIENTACION<ul> <li>- EP-EDF-11.xlsx</li> </ul> 10.FACT_REEMPLAZO_DOCENTE<ul> <li>- EP-EDF-03.xlsx</li> </ul> 11.FACT_RESERVA_ESPACIOS<ul> <li>- EP-EDF-12.xlsx</li> </ul> 12.FACT_SABER11_COLEGIOS<ul> <li>- EP-EDF-08.xlsx</li> </ul> 13.FACT_SABER11_INDIVIDUAL<ul> <li>- EP-EDF-07.xlsx</li> </ul> 14.FACT_SERVICIO_SOCIAL<ul> <li>- EP-EDF-13.xlsx</li> </ul> 15.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2022.xlsx</li> <li>- EP-TRA-05_2023.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> 16.DIM_TARIFAS_SERVICIOS<ul> <li>- EP-TRA-04_2024.xlsx</li> </ul> </ul> 03.Educacion_Tecnica <ul> 01.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> </ul> 04.Educacion_Continua <ul> 01.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> </ul> 05.Proteccion_Social <ul> 01.Caracterizacion <ul> AM-PRS-03 <ul><li>- AM-PRS-03-2022.xlsx</li></ul> AM-PRS-10 <ul><li>- AM-PRS-10-202405.xlsx</li></ul> <ul><li>- AM-PRS-10.xlsx</li> AM-PRS-102 <ul><li>- AM-PRS-102.xlsx </li> AM-PRS-11 <ul> <li>- AM-PRS-11-202401.xlsx</li> <li>- AM-PRS-11-202402.xlsx</li> <li>- AM-PRS-11-202403.xlsx</li> <li>- AM-PRS-11-202404.xlsx</li> <li>- AM-PRS-11-202405.xlsx</li> <li>- AM-PRS-11.xlsx</li> </ul> AM-PRS-12 <ul> <li>- AM-PRS-12-2024.xlsx</li> <li>- AM-PRS-12.xlsx</li> </ul> AM-PRS-120 <ul> <li>- AM-PRS-120-202402.xlsx</li> <li>- AM-PRS-120-202403.xlsx</li> <li>- AM-PRS-120-202404.xlsx</li> <li>- AM-PRS-120-202405.xlsx</li> <li>- AM-PRS-120.xlsx</li> </ul> AM-PRS-13 <ul> <li>- AM-PRS-13-2023.xlsx</li> <li>- AM-PRS-13.xlsx</li> </ul> AM-PRS-145 <ul><li>- AM-PRS-145.xlsx </li> AM-PRS-145_CATEGORICAS <ul><li>- AM-PRS-145_CATEGORICAS.xlsx </li> AM-PRS-23 <ul><li>- AM-PRS-23.xlsx</li> AM-PRS-41 <ul><li>- AM-PRS-41.xlsx </li> AM-PRS-81 <ul><li>- AM-PRS-81.xlsx </li> AM-PRS-91 <ul><li>- AM-PRS-91.xlsx </li> AM-PRS-91_CATEGORICAS <ul><li>- AM-PRS-91_CATEGORICAS.xlsx </li> AM-TRA-11 <ul><li>- AM-TRA-11.txt </li> DIM_PROGRAMA <ul><li>- ID_PROGRAMA.xlsx </li> EP-PRS-02 <ul><li>- EP-PSR-02.xlsx </li> EP-PRS-03 <ul><li>- EP-PSR-03.xlsx </li> EP-PRS-04 <ul><li>- EP-PRS-04.xlsx </li> <ul><li>- EP-PRS-04_2024.xlsx </li> <ul><li>- EP-PRS-04_2025.xlsx </li> EP-PSR-01 <ul><li>- EP-PSR-01.xlsx </li> EP-TRA-02 <ul><li>- EP-TRA-02.xlsx </li> NSU CEC <ul> <li>CEC (2).txt </li> <li>CEC.txt </li> <li>comfenalcocec (2).txt </li> <li>comfenalcocec (3).txt </li> <li>comfenalcocec (4).txt </li> <li>comfenalcocec (5).txt </li> <li>comfenalcocec.txt </li> </ul> Cedesarrollo convenios <ul> <li>campanas comfenalcoconvenios (2).txt</li> <li>campanas comfenalcoconvenios (3).txt</li> <li>campanas comfenalcoconvenios (4).txt</li> <li>campanas comfenalcoconvenios (5).txt</li> <li>campanas comfenalcoconvenios.txt</li> <li>Convenios (2).txt</li> <li>Convenios.txt</li> </ul> Consultorias <ul> <li>campanas comfenalcoconsultorias (2).txt</li> <li>campanas comfenalcoconsultorias (3).txt</li> <li>campanas comfenalcoconsultorias (4).txt</li> <li>campanas comfenalcoconsultorias (5).txt</li> <li>campanas comfenalcoconsultorias.txt</li> <li>Consultorias (2).txt</li> <li>Consultorias.txt</li> </ul> Cursos y diplomados <ul> <li>campanas comfenalcodiplomados (2).txt</li> <li>campanas comfenalcodiplomados (3).txt</li> <li>campanas comfenalcodiplomados (4).txt</li> <li>campanas comfenalcodiplomados (5).txt</li> <li>campanas comfenalcodiplomados.txt</li> <li>Cursos y diplomados (2).txt</li> <li>Cursos y diplomados.txt</li> </ul> Egresados <ul> <li>comfenalcocedesarrolloegresados (2).txt</li> <li>comfenalcocedesarrolloegresados (3).txt</li> <li>comfenalcocedesarrolloegresados (4).txt</li> <li>comfenalcocedesarrolloegresados (5).txt</li> <li>comfenalcocedesarrolloegresados.txt</li> <li>Egresado (2).txt</li> <li>Egresado.txt</li> </ul> Estudiantes Activos <ul> <li>base1.txt</li> <li>base1Activos1.txt</li> <li>base2.txt</li> <li>base2Activos0.txt</li> <li>base3.txt</li> <li>base4.txt</li> <li>base5.txt</li> <li>Estudiantes Activos (2).txt</li> <li>Estudiantes Activos.txt</li> </ul> Proteccion social <ul> <li>campanas comfenalcoproteccion(2).txt</li> <li>campanas comfenalcoproteccion(3).txt</li> <li>campanas comfenalcoproteccion(4).txt</li> <li>campanas comfenalcoproteccion(5).txt</li> <li>Proteccion social (2).txt</li> <li>Proteccion social.txt</li> </ul> 02.DIM_PERSONAL <ul><li>- EP-TRA-05.xlsx  </li> <ul><li>- EP-TRA-02.xlsx </li> </ul> </ul> </ul> 03.Otros_Archivos <ul> <li>AM-DRE-05_08_12_2024.xlsx</li> <li>AM-DRE-05_25_12_2024.xlsx</li> <li>AM-DRE-16.xls</li> <li>AM-EPT-47.xlsx</li> <li>EP-EDF-02.xlsx</li> <li>EP-EDF-04.xlsx</li> <li>EP-EDF-09.xlsx</li> <li>EP-EPT-04.xlsx</li> <li>EP-EPT-06.xlsx</li> <li>EP-EPT-07.xlsx</li> <li>EP-EPT-08.xlsx</li> <li>EP-EPT-09.xlsx</li> <li>EP-EPT-10.xlsx</li> <li>EP-EPT-11.xlsx</li> <li>EP-EPT-12.xlsx</li> </ul> </ul> <p>Nota: Desplegar los items para ver su contenido</p>"},{"location":"05.Power_BI/00.Introduccion/","title":"Introducci\u00f3n","text":""},{"location":"05.Power_BI/00.Introduccion/#tableros-analiticos-del-proceso-de-educacion","title":"Tableros Anal\u00edticos del Proceso de Educaci\u00f3n","text":""},{"location":"05.Power_BI/00.Introduccion/#vision-general-de-los-dashboards","title":"Visi\u00f3n General de los Dashboards","text":"<p>El sistema de dashboards para el proceso de Educaci\u00f3n ofrece una perspectiva integral, abarcando tanto indicadores operativos como m\u00e9tricas de impacto social. A trav\u00e9s de diversas visualizaciones, se busca facilitar la toma de decisiones estrat\u00e9gicas y operativas, optimizando la gesti\u00f3n de las unidades de negocio. A continuaci\u00f3n se describe la estructura y funcionalidades principales de cada visualizaci\u00f3n:</p>"},{"location":"05.Power_BI/00.Introduccion/#analisis-del-perfil-del-proceso-de-educacion","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n","text":"<p>Objetivo de la Visualizaci\u00f3n: Proporcionar una visi\u00f3n integral del estado del proceso educativo, destacando indicadores clave y datos estrat\u00e9gicos que permiten evaluar el desempe\u00f1o de cada unidad de negocio. Esto incluye an\u00e1lisis de empresas atendidas, afiliados, beneficiarios y la efectividad de los servicios ofrecidos.</p>"},{"location":"05.Power_BI/00.Introduccion/#estructura-y-elementos-principales","title":"Estructura y Elementos Principales:","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite al usuario navegar entre distintos an\u00e1lisis estrat\u00e9gicos como Productividad Organizacional e Impacto Social y Comunitario.</li> <li>Facilita el acceso r\u00e1pido a las diferentes visualizaciones sin perder contexto.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo: </p> <ul> <li>Unidades de Negocio: Permite filtrar los datos por unidad (Educaci\u00f3n Formal, T\u00e9cnica, Continua, Protecci\u00f3n Social).</li> <li>Totales de Negocio: Resumen de datos clave como empresas, afiliados y beneficiarios atendidos.</li> <li>Utilizaci\u00f3n y Capacidad F\u00edsica: Informaci\u00f3n detallada sobre la disponibilidad de infraestructura y la utilizaci\u00f3n efectiva de los servicios.</li> </ul> </li> <li> <p>Zona Central - Indicadores Generales: </p> <ul> <li>Cobertura y Servicios Ofertados: Mide la efectividad de los servicios proporcionados, comparando la cobertura alcanzada con la proyectada.</li> <li>Impacto Social: Refleja el alcance y la efectividad de los programas de Educaci\u00f3n en t\u00e9rminos de beneficios sociales.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/00.Introduccion/#indicadores-de-utilizacion","title":"Indicadores de Utilizaci\u00f3n","text":"<p>Objetivo: Proporcionar una perspectiva detallada sobre la utilizaci\u00f3n de los servicios educativos, evaluando el acceso de afiliados, empresas y beneficiarios, y midiendo indicadores clave como tasas de promoci\u00f3n y deserci\u00f3n.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-destacados","title":"Elementos Destacados:","text":"<ul> <li>Afiliados Atendidos: Cantidad de usuarios que han utilizado los servicios educativos.</li> <li>Cobertura por Categor\u00eda: Distribuci\u00f3n de los servicios atendidos seg\u00fan categor\u00edas (A, B, C).</li> <li>Indicadores de Continuidad: Incluye tasas de promoci\u00f3n y deserci\u00f3n para evaluar la fidelizaci\u00f3n de los usuarios.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades","title":"Funcionalidades:","text":"<ul> <li>Comparaciones Temporales: Permite comparar la utilizaci\u00f3n de servicios a lo largo del tiempo.</li> <li>An\u00e1lisis de Trayectoria de Usuarios: Seguimiento de la evoluci\u00f3n de los afiliados desde su inscripci\u00f3n hasta su graduaci\u00f3n o deserci\u00f3n.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#indicadores-de-capacidad","title":"Indicadores de Capacidad","text":"<p>Objetivo: Analizar la capacidad operativa del sistema educativo, comparando la oferta de servicios con los servicios efectivamente vendidos y distribuyendo los recursos humanos entre las diferentes unidades de negocio.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-clave","title":"Elementos Clave:","text":"<ul> <li>Servicios Ofertados vs. Servicios Vendidos: Mide la efectividad de la conversi\u00f3n de servicios ofrecidos en servicios contratados.</li> <li>Docentes por Unidad: Visualiza la distribuci\u00f3n de los docentes en las distintas unidades, ayudando a identificar \u00e1reas de sobrecarga o escasez de recursos humanos.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades-principales","title":"Funcionalidades Principales:","text":"<ul> <li>Comparaci\u00f3n de Oferta y Venta: Facilita la identificaci\u00f3n de posibles \u00e1reas de mejora en la efectividad de la venta de servicios.</li> <li>Optimizaci\u00f3n de Recursos Humanos: Permite analizar la distribuci\u00f3n de docentes y ajustar la asignaci\u00f3n seg\u00fan la demanda.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#experiencia-de-usuario","title":"Experiencia de Usuario","text":"<p>Objetivo: Brindar una visi\u00f3n integral sobre la satisfacci\u00f3n y experiencia de los usuarios en los servicios educativos, usando m\u00e9tricas clave como el Net Promoter Score (NPS), PQR (Peticiones, Quejas y Reclamos), y la resoluci\u00f3n de problemas.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-principales","title":"Elementos Principales:","text":"<ul> <li>NPS (Net Promoter Score): Mide la disposici\u00f3n de los usuarios a recomendar los servicios educativos.</li> <li>Resoluci\u00f3n Promedio: Indica el tiempo promedio para resolver problemas o inquietudes de los usuarios.</li> <li>Causas Principales de Insatisfacci\u00f3n: Muestra los motivos m\u00e1s comunes detr\u00e1s de las quejas o reclamos.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_1","title":"Funcionalidades:","text":"<ul> <li>Seguimiento Continuo del NPS: Permite hacer un seguimiento en tiempo real de la lealtad de los usuarios.</li> <li>Identificaci\u00f3n de Causas Recurrentes: Ayuda a detectar \u00e1reas de insatisfacci\u00f3n y mejora en la experiencia del usuario.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#productividad-organizacional","title":"Productividad Organizacional","text":""},{"location":"05.Power_BI/00.Introduccion/#analisis-de-desempeno-y-calidad","title":"An\u00e1lisis de Desempe\u00f1o y Calidad","text":"<p>Objetivo: Presentar el desempe\u00f1o de las unidades educativas y su impacto en la calidad de los servicios. Mide la eficiencia en el logro de objetivos y la calidad percibida por los usuarios.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-clave_1","title":"Elementos Clave:","text":"<ul> <li>Empresas/Afiliados/Beneficiarios Atendidos: Indicadores de alcance para evaluar el impacto de los servicios.</li> <li>Tasa de Certificaci\u00f3n y Deserci\u00f3n: Analiza la efectividad de los programas y el abandono de los usuarios.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades-principales_1","title":"Funcionalidades Principales:","text":"<ul> <li>Evaluaci\u00f3n de la Calidad: Mide la satisfacci\u00f3n y los resultados alcanzados por las unidades educativas.</li> <li>Detecci\u00f3n de Oportunidades de Mejora: Ayuda a identificar \u00e1reas cr\u00edticas que requieren intervenci\u00f3n.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#comportamientos-historicos","title":"Comportamientos Hist\u00f3ricos","text":"<p>Objetivo: Proporcionar visi\u00f3n longitudinal del desempe\u00f1o educativo para identificar tendencias y patrones temporales.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-destacados_1","title":"Elementos Destacados:","text":"<ul> <li>Cantidad de Graduados: Evoluci\u00f3n hist\u00f3rica de graduaciones.</li> <li>Indicadores de Desempe\u00f1o: Datos agregados de empresas, afiliados y beneficiarios.</li> <li>Gr\u00e1ficos Comparativos: Visualizaci\u00f3n de tendencias temporales.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_2","title":"Funcionalidades:","text":"<ul> <li>Identificaci\u00f3n de tendencias, picos y comportamientos estacionales.</li> <li>Comparaciones entre diferentes per\u00edodos.</li> <li>Correlaci\u00f3n con otros indicadores (deserci\u00f3n, certificaci\u00f3n).</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#comportamiento-financiero","title":"Comportamiento Financiero","text":"<p>Objetivo: Ofrecer perspectiva financiera del proceso educativo, destacando aportes, subsidios, inversi\u00f3n y ejecuci\u00f3n presupuestal.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-principales_1","title":"Elementos Principales:","text":"<ul> <li>Aportes y Subsidios: Montos y fuentes de financiaci\u00f3n.</li> <li>Inversi\u00f3n y Ejecuci\u00f3n: Uso del presupuesto asignado.</li> <li>Top 10 Empresas Aportantes: Principales contribuyentes.</li> <li>Valor Pagado por Estado: Distribuci\u00f3n de pagos seg\u00fan estado.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_3","title":"Funcionalidades:","text":"<ul> <li>Seguimiento de ejecuci\u00f3n presupuestal.</li> <li>Identificaci\u00f3n de principales aportantes.</li> <li>Control de pagos y estado de cartera.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#experiencia-de-usuario-productividad","title":"Experiencia de Usuario (Productividad)","text":"<p>Objetivo: Brindar perspectiva clara de satisfacci\u00f3n integrando NPS, PQR por unidad y tasa de deserci\u00f3n.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-clave_2","title":"Elementos Clave:","text":"<ul> <li>PQR por Unidad: Peticiones, quejas y reclamos por \u00e1rea.</li> <li>Net Promoter Score: \u00cdndice de recomendaci\u00f3n de servicios.</li> <li>Deserci\u00f3n: Tasa de abandono de programas formativos.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_4","title":"Funcionalidades:","text":"<ul> <li>Integraci\u00f3n de PQR con \u00edndice NPS.</li> <li>Enfoque en retenci\u00f3n de estudiantes.</li> <li>Comparaci\u00f3n hist\u00f3rica de indicadores post-implementaci\u00f3n de mejoras.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#analisis-mineria","title":"An\u00e1lisis Miner\u00eda","text":"<p>Objetivo: Integrar t\u00e9cnicas de Process Mining para analizar secuencia y eficiencia de procesos educativos.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-principales_2","title":"Elementos Principales:","text":"<ul> <li>Mapa de Procesos: Recorrido gr\u00e1fico de actividades.</li> <li>Indicadores de Eficiencia: Duraci\u00f3n promedio, repeticiones.</li> <li>Visualizaci\u00f3n de Flujos: Transiciones entre estados de proceso.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_5","title":"Funcionalidades:","text":"<ul> <li>Descubrimiento de procesos reales vs. te\u00f3ricos.</li> <li>Detecci\u00f3n de cuellos de botella y retrasos.</li> <li>Optimizaci\u00f3n de flujos de trabajo.</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#diagrama-de-flujo-integral-del-sistema","title":"Diagrama de Flujo Integral del Sistema","text":"<pre><code>flowchart TD\n    A[An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n] --&gt; B1[Indicadores de Utilizaci\u00f3n]\n    A --&gt; B2[Indicadores de Capacidad]\n    A --&gt; B3[Experiencia de Usuario]\n\n    A --&gt; C[Productividad Organizacional]\n    C --&gt; C1[An\u00e1lisis de Desempe\u00f1o y Calidad]\n    C1 --&gt; C1a[Comportamientos Hist\u00f3ricos]\n    C1 --&gt; C1b[Comportamiento Financiero]\n    C1 --&gt; C1c[Experiencia de Usuario]\n    C1 --&gt; C1d[An\u00e1lisis Miner\u00eda]\n\n    C --&gt; C2[An\u00e1lisis de Eficiencia]\n    C2 --&gt; C2a[Educaci\u00f3n T\u00e9cnica]\n    C2 --&gt; C2b[Educaci\u00f3n Continua]\n    C2 --&gt; C2c[Protecci\u00f3n Social]\n\n    A --&gt; D[Impacto Social y Comunitario]\n    D --&gt; D1[An\u00e1lisis por Servicio]\n    D --&gt; D2[An\u00e1lisis por Empresa]\n    D2 --&gt; D2a[Relaci\u00f3n de Servicios y Aportes]\n    D2 --&gt; D2b[Servicios Vendidos y Subsidios]</code></pre>"},{"location":"05.Power_BI/01.Dashboard/","title":"01. DASHBOARD","text":""},{"location":"05.Power_BI/01.Dashboard/#modelo-analitico-del-proceso-de-educacion-menu-principal","title":"Modelo Anal\u00edtico del Proceso de Educaci\u00f3n \u2013\u202fMen\u00fa Principal","text":"<p>Objetivo de la Visualizaci\u00f3n: Actuar como portada y panel de navegaci\u00f3n central para todo el sistema de anal\u00edtica y estad\u00edstica del proceso de Educaci\u00f3n. Desde este men\u00fa, el usuario puede acceder r\u00e1pidamente a los seis tableros tem\u00e1ticos que conforman el modelo anal\u00edtico: visi\u00f3n global de perfiles, productividad organizacional (desempe\u00f1o\u202fy eficiencia) e impacto social (por servicio y por empresa). Facilita la orientaci\u00f3n del p\u00fablico y refuerza, a nivel visual, la identidad corporativa de la central de informaci\u00f3n.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Encabezado Modelo Anal\u00edtico del Proceso de Educaci\u00f3n en tipograf\u00eda destacada, flanqueado por el isologo de Quality Customer Service (izquierda) y el escudo de Comfenalco (derecha). Refuerza la autor\u00eda institucional. Lista de Navegaci\u00f3n (lado izquierdo) Seis botones alineados verticalmente, cada uno con un icono de gr\u00e1fico + cursor y un t\u00edtulo espec\u00edfico:1. An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n\u202f\u2013\u202fTotales2. An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n3. Productividad Organizacional\u202f\u2013\u202fAn\u00e1lisis de Desempe\u00f1o y calidad4. Productividad Organizacional\u202f\u2013\u202fAn\u00e1lisis de Eficiencia5. Impacto social y comunitario\u202f\u2013\u202fAn\u00e1lisis por servicio6. Impacto social y comunitario\u202f\u2013\u202fAn\u00e1lisis por empresa Panel Destacado (lado derecho) Bloque azul marino con la leyenda \u201cCentral de informaci\u00f3n de ANAL\u00cdTICA Y ESTAD\u00cdSTICA\u201d. Comunica el prop\u00f3sito del sistema y a\u00f1ade contraste visual. Banda inferior Pie de p\u00e1gina con l\u00edneas de color institucional (rojo/azul), que cierra la composici\u00f3n y mantiene la coherencia gr\u00e1fica con los dem\u00e1s tableros."},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave","title":"Funcionalidades Clave","text":"<ol> <li>Navegaci\u00f3n Directa: cada bot\u00f3n enlaza al tablero correspondiente, reduciendo la curva de aprendizaje y el tiempo de exploraci\u00f3n.</li> <li>Jerarqu\u00eda Visual Clara: la separaci\u00f3n en cuadrantes (navegaci\u00f3n izquierda\u202f/\u202fmensaje institucional derecha) orienta la atenci\u00f3n y evita saturaci\u00f3n.</li> <li>Identidad Corporativa: el uso consistente de logotipos, paleta crom\u00e1tica y tipograf\u00edas oficiales refuerza la marca de la central de anal\u00edtica.</li> <li>Escalabilidad: el dise\u00f1o admite la adici\u00f3n de nuevas secciones sin romper la armon\u00eda (p.\u202fej., inserci\u00f3n de un s\u00e9ptimo bot\u00f3n).</li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Experiencia de Usuario (UX) Optimizada: un punto de entrada \u00fanico simplifica el recorrido de analistas, directivos y dem\u00e1s stakeholders.</li> <li>Coherencia Informativa: al estandarizar el acceso a los tableros, se minimiza la dispersi\u00f3n de enlaces y versiones no controladas.</li> <li>Comunicaci\u00f3n Institucional: la portada funciona como tarjeta de presentaci\u00f3n de la estrategia de datos, fortaleciendo la cultura de decisiones basadas en evidencia.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-totales","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n\u202f\u2013\u202fTotales","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Ofrecer una panor\u00e1mica integral del estado general del proceso de Educaci\u00f3n y sus unidades, exponiendo los principales indicadores estrat\u00e9gicos de cobertura, beneficiarios y servicios. La vista permite filtrar la informaci\u00f3n y evaluar r\u00e1pidamente el desempe\u00f1o global para apoyar la planeaci\u00f3n y las decisiones t\u00e1cticas.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_1","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Bloque dedicado a la selecci\u00f3n de la Unidad para Analizar. Contiene una breve explicaci\u00f3n del prop\u00f3sito de la visualizaci\u00f3n y cuatro botones con iconos para elegir Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua y Protecci\u00f3n Social. Incluye una leyenda que resalta si los datos corresponden a una muestra. Tarjetas KPI Superiores Tres tarjetas alineadas que muestran los totales de empresas afiliadas, afiliados y beneficiarios. Sirven como referencia r\u00e1pida del alcance institucional. Contenedor \u201cIndicadores generales estrat\u00e9gicos\u201d \u00c1rea central que agrupa: tarjetas de cobertura (cumplimiento, ejecutada, proyectada), barras de Beneficiarios Atendidos, tarjetas de impacto (afiliados y empresas) y barras de Servicios Ofertados/Vendidos. Todo se presenta con formatos visuales uniformes para facilitar la lectura comparativa. Gr\u00e1fico \u201cCobertura por Categor\u00eda\u201d Gr\u00e1fico de barras verticales que visualiza la proporci\u00f3n de cobertura ejecutada para cada categor\u00eda de afiliaci\u00f3n, con etiquetas de porcentaje para una interpretaci\u00f3n inmediata. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega detalles sobre la interpretaci\u00f3n de la vista, ayudando al usuario a comprender definiciones y supuestos. Pie de P\u00e1gina Banda inferior con la fecha del periodo analizado y l\u00edneas de color corporativo que enmarcan la composici\u00f3n, asegurando consistencia gr\u00e1fica con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_1","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Visi\u00f3n Ejecutiva Unificada: Centraliza los indicadores clave del proceso educativo en un \u00fanico tablero, reduciendo tiempos de consulta y reporte.</li> <li>An\u00e1lisis Din\u00e1mico: Los filtros permiten segmentar la informaci\u00f3n por periodo, unidad o categor\u00eda, facilitando diagn\u00f3sticos espec\u00edficos sin necesidad de construir informes adicionales.</li> <li>Detecci\u00f3n de Brechas de Cobertura: La combinaci\u00f3n de KPI de cobertura y el gr\u00e1fico por categor\u00eda ayuda a identificar \u00e1reas con bajo alcance y priorizar acciones correctivas.</li> <li>Monitoreo de Impacto Institucional: Las tarjetas de afiliados, beneficiarios y empresas impactadas ofrecen una medici\u00f3n continua del valor social generado.</li> <li>Soporte a la Toma de Decisiones: La disponibilidad de datos consolidados y actualizados favorece decisiones informadas sobre asignaci\u00f3n de recursos, ampliaci\u00f3n de servicios y estrategias de crecimiento.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-totales-educacion-tecnica","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n\u202f\u2013\u202fTotales (Educaci\u00f3n T\u00e9cnica)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_1","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Brindar una visi\u00f3n consolidada del estado general de la unidad de Educaci\u00f3n T\u00e9cnica, resaltando los principales indicadores de cobertura, poblaci\u00f3n atendida y oferta de servicios. Esta vista sirve como punto de partida para evaluar el desempe\u00f1o global de la unidad, identificar brechas y apoyar la toma de decisiones t\u00e1cticas.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_2","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo \u00c1rea dedicada a la elecci\u00f3n de la Unidad para Analizar, con una breve explicaci\u00f3n del prop\u00f3sito del tablero. Se muestran botones con iconos para Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica (seleccionado), Educaci\u00f3n Continua y Protecci\u00f3n Social, adem\u00e1s de una leyenda que advierte cuando la visualizaci\u00f3n contiene datos de muestra. Tarjetas KPI Superiores Tarjetas que resumen los totales institucionales de empresas afiliadas, afiliados y beneficiarios, proporcionando contexto global antes de profundizar en los datos de la unidad espec\u00edfica. Contenedor \u201cIndicadores generales estrat\u00e9gicos\u201d Bloque central que agrupa: tarjetas de cobertura (cumplimiento, ejecutada y proyectada), barras de afiliados atendidos y beneficiarios atendidos, tarjetas de impacto (afiliados y empresas) y barras de servicios ofertados/vendidos. Todo se presenta con un dise\u00f1o uniforme para facilitar la comparaci\u00f3n de m\u00e9tricas clave. Gr\u00e1fico \u201cCobertura por Categor\u00eda\u201d Gr\u00e1fico de barras que visualiza la distribuci\u00f3n de la cobertura ejecutada entre las categor\u00edas de afiliaci\u00f3n para la unidad de Educaci\u00f3n T\u00e9cnica, con etiquetas de porcentaje para una interpretaci\u00f3n r\u00e1pida. Icono de Informaci\u00f3n Bot\u00f3n de ayuda contextual que despliega detalles sobre la interpretaci\u00f3n de los indicadores y definiciones utilizadas en la vista. Pie de P\u00e1gina Banda inferior que muestra el periodo analizado y l\u00edneas de color corporativo, garantizando coherencia visual con el resto de tableros."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_2","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Monitoreo Espec\u00edfico de Educaci\u00f3n T\u00e9cnica: Centraliza los indicadores clave de la unidad, permitiendo un diagn\u00f3stico r\u00e1pido del desempe\u00f1o y la cobertura alcanzada.</li> <li>Segmentaci\u00f3n Din\u00e1mica: Los filtros posibilitan ajustar el an\u00e1lisis por periodo, categor\u00eda o subunidad, facilitando la identificaci\u00f3n de tendencias y \u00e1reas cr\u00edticas.</li> <li>Detecci\u00f3n de Oportunidades de Mejora: El contraste entre cobertura y servicios ofertados/vendidos ayuda a reconocer brechas y orientar acciones de optimizaci\u00f3n.</li> <li>Contexto Institucional Integrado: Las tarjetas globales ofrecen una visi\u00f3n del impacto organizacional, situando los resultados de Educaci\u00f3n T\u00e9cnica dentro del panorama general.</li> <li>Soporte a la Planificaci\u00f3n Estrat\u00e9gica: La disponibilidad de datos consolidados respalda decisiones sobre recursos, expansi\u00f3n de programas y alineaci\u00f3n de la oferta con la demanda real.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-totales-educacion-continua","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n\u202f\u2013\u202fTotales (Educaci\u00f3n Continua)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_2","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Proporcionar una visi\u00f3n integral del estado general de la unidad de Educaci\u00f3n Continua, resaltando la cobertura, el impacto en empresas y afiliados, y la oferta de servicios. Esta vista permite evaluar el desempe\u00f1o global, identificar brechas y respaldar decisiones t\u00e1cticas relacionadas con la formaci\u00f3n continua.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_3","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo \u00c1rea de selecci\u00f3n de la Unidad para Analizar con cuatro botones (Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua, Protecci\u00f3n Social). Incluye una explicaci\u00f3n breve del prop\u00f3sito de la vista y una leyenda que se\u00f1ala si los datos son de muestra. Tarjetas KPI Superiores Tarjetas que muestran los totales institucionales de empresas afiliadas, afiliados y beneficiarios, proporcionando contexto general antes de profundizar en la unidad espec\u00edfica. Contenedor \u201cIndicadores generales estrat\u00e9gicos\u201d Bloque central que agrupa: tarjetas de cobertura (cumplimiento, ejecutada y proyectada), barras de empresas atendidas, tarjetas del impacto en afiliados, y barras de servicios ofertados/vendidos. Presenta un dise\u00f1o uniforme que facilita la comparaci\u00f3n visual. Cuadro \u201cTop\u202f10\u202fEmpresas Atendidas\u201d Tabla a la derecha con las principales empresas atendidas ordenadas por n\u00famero de afiliados impactados. Ayuda a identificar los clientes corporativos m\u00e1s relevantes para la unidad de Educaci\u00f3n Continua. Icono de Informaci\u00f3n Bot\u00f3n de ayuda contextual que despliega definiciones y pautas para interpretar los indicadores mostrados. Pie de P\u00e1gina Franja inferior con el periodo analizado y l\u00edneas de color corporativo, asegurando coherencia gr\u00e1fica con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_3","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Visi\u00f3n Consolidada de Educaci\u00f3n Continua: Centraliza los datos clave de la unidad, permitiendo un diagn\u00f3stico r\u00e1pido del desempe\u00f1o y la cobertura lograda.</li> <li>An\u00e1lisis de Clientes Corporativos: El cuadro de empresas atendidas destaca los aliados estrat\u00e9gicos y facilita la priorizaci\u00f3n de esfuerzos comerciales y de fidelizaci\u00f3n.</li> <li>Segmentaci\u00f3n Din\u00e1mica: Los filtros permiten explorar la informaci\u00f3n por periodos, categor\u00edas o subunidades, apoyando la detecci\u00f3n de tendencias y oportunidades de mejora.</li> <li>Contexto Institucional Integrado: Las tarjetas globales sit\u00faan los resultados de Educaci\u00f3n Continua dentro del panorama general, posibilitando comparaciones con otras unidades.</li> <li>Soporte a la Planificaci\u00f3n Estrat\u00e9gica: La vista ofrece datos consolidados y actualizados que son esenciales para la asignaci\u00f3n eficiente de recursos y la expansi\u00f3n de programas formativos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-totales-proteccion-social","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n\u202f\u2013\u202fTotales (Protecci\u00f3n Social)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_3","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Ofrecer una panor\u00e1mica consolidada del estado general de la unidad de Protecci\u00f3n Social, resaltando la cobertura, el impacto en afiliados y beneficiarios, as\u00ed como la oferta de servicios. La vista facilita la identificaci\u00f3n de brechas y la toma de decisiones t\u00e1cticas orientadas al fortalecimiento de los programas sociales.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_4","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo \u00c1rea dedicada a la selecci\u00f3n de la Unidad para Analizar, con botones para Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua y Protecci\u00f3n Social (resaltado). Incluye una breve explicaci\u00f3n del prop\u00f3sito de la vista y un aviso cuando se utilizan datos de muestra. Tarjetas KPI Superiores Tarjetas que muestran indicadores globales institucionales de empresas afiliadas, afiliados y beneficiarios, proporcionando contexto general antes de profundizar en la unidad espec\u00edfica. Contenedor \u201cIndicadores generales estrat\u00e9gicos\u201d Bloque central que agrupa tarjetas de cobertura, barras de afiliados y beneficiarios atendidos, m\u00e9tricas de impacto en empresas y servicios; todo presentado con un dise\u00f1o uniforme para una lectura comparativa. Gr\u00e1fico \u201cCobertura por Categor\u00eda\u201d Gr\u00e1fico de barras que ilustra la distribuci\u00f3n de la cobertura ejecutada entre las categor\u00edas de afiliaci\u00f3n, facilitando la identificaci\u00f3n visual de los niveles de alcance. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y notas metodol\u00f3gicas para interpretar los indicadores mostrados. Pie de P\u00e1gina Franja inferior con el periodo analizado y l\u00edneas de color corporativo que aseguran coherencia gr\u00e1fica con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_4","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Visi\u00f3n Integral de la Unidad: Centraliza indicadores clave de Protecci\u00f3n Social, permitiendo un diagn\u00f3stico r\u00e1pido del alcance y desempe\u00f1o.</li> <li>Segmentaci\u00f3n Flexible: Los filtros ofrecen la posibilidad de analizar los resultados por periodo, programa o categor\u00eda, identificando tendencias espec\u00edficas y oportunidades de mejora.</li> <li>Enfoque en Cobertura y Beneficio Social: La combinaci\u00f3n de m\u00e9tricas de cobertura y beneficiarios atendidos ayuda a priorizar recursos y acciones hacia poblaciones con mayor necesidad.</li> <li>Contexto Organizacional: Las tarjetas globales sit\u00faan los resultados de Protecci\u00f3n Social dentro del panorama institucional, facilitando comparaciones con otras unidades.</li> <li>Apoyo a la Planificaci\u00f3n Estrat\u00e9gica: Datos consolidados y actualizados respaldan decisiones sobre asignaci\u00f3n presupuestal, expansi\u00f3n de programas y optimizaci\u00f3n de la oferta social.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-totales-de-negocio","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n\u202f\u2013\u202fTotales de Negocio","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_4","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Presentar una perspectiva global de los aportes y subsidios asociados al proceso de Educaci\u00f3n, destacando la relaci\u00f3n entre empresas, afiliados y beneficiarios atendidos. La vista permite evaluar el impacto financiero y la distribuci\u00f3n de los recursos, as\u00ed como identificar las unidades con mayor participaci\u00f3n en los aportes.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_5","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Secci\u00f3n Aspecto para Analizar con botones para Totales de Negocio (seleccionado), Capacidad F\u00edsica y Experiencia de Usuario. Incluye una breve explicaci\u00f3n del prop\u00f3sito de la vista y una alerta cuando se utilizan datos de muestra. Tarjetas KPI Superiores Tarjetas que muestran los indicadores globales de empresas afiliadas, afiliados, beneficiarios, empresas atendidas, afiliados atendidos y beneficiarios atendidos, ofreciendo una referencia r\u00e1pida del alcance institucional. Contenedor \u201cIndicadores generales estrat\u00e9gicos\u201d Bloque central que agrupa las m\u00e9tricas de Aportes y Subsidios: cantidad y valor de aportes, participaci\u00f3n de la educaci\u00f3n sobre los aportes totales y m\u00e9tricas espec\u00edficas de empresas impactadas. Incluye una nota metodol\u00f3gica para interpretar correctamente los datos. Tabla Detalle por Unidad Tabla que desglosa, para cada unidad (Educaci\u00f3n Continua, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Formal, Protecci\u00f3n Social), la cantidad y el valor de aportes de empresas impactadas, junto con los indicadores de subsidio a la demanda. Icono de Informaci\u00f3n Bot\u00f3n contextual que ofrece definiciones y aclaraciones sobre los conceptos mostrados en la vista. Pie de P\u00e1gina Franja inferior con el periodo de an\u00e1lisis y l\u00edneas de color corporativo que enmarcan la composici\u00f3n, garantizando la coherencia gr\u00e1fica con los dem\u00e1s tableros."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_5","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Visi\u00f3n Financiera Consolidada: Centraliza los datos de aportes y subsidios, facilitando el monitoreo del soporte econ\u00f3mico al proceso educativo.</li> <li>Identificaci\u00f3n de Unidades Clave: La tabla detallada permite detectar las unidades con mayor participaci\u00f3n en los aportes, orientando estrategias de financiamiento y priorizaci\u00f3n de recursos.</li> <li>An\u00e1lisis Din\u00e1mico: Los filtros proporcionan flexibilidad para segmentar la informaci\u00f3n por periodo, unidad o categor\u00eda, apoyando diagn\u00f3sticos espec\u00edficos y comparaciones hist\u00f3ricas.</li> <li>Transparencia y Toma de Decisiones: La combinaci\u00f3n de indicadores estrat\u00e9gicos y detalle por unidad respalda decisiones basadas en datos sobre asignaci\u00f3n presupuestal y pol\u00edticas de subsidio.</li> <li>Contexto Institucional Integrado: Las tarjetas KPI iniciales sit\u00faan los resultados financieros dentro del panorama general del proceso educativo, favoreciendo la comprensi\u00f3n del impacto global.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-capacidad-fisica","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n \u2013\u202fCapacidad F\u00edsica","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_5","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Mostrar, de forma sint\u00e9tica e interactiva, los principales indicadores de capacidad institucional (espacios f\u00edsicos, servicios y estudiantes) y su distribuci\u00f3n entre las diferentes unidades de negocio. La vista permite detectar la disponibilidad de recursos y el grado de utilizaci\u00f3n para orientar decisiones sobre ampliaci\u00f3n, redistribuci\u00f3n o mejora de la infraestructura educativa.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_6","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo \u00c1rea Aspecto para Analizar con botones para Totales de Negocio, Capacidad F\u00edsica (seleccionado) y Experiencia de Usuario. Incluye una breve nota sobre el objetivo de la vista y un aviso cuando los datos son de muestra. Tarjetas KPI Superiores Conjunto de tarjetas que resumen m\u00e9tricas de capacidad: espacios f\u00edsicos disponibles, servicios ofertados y vendidos, estudiantes activos y estandarizaci\u00f3n de estudiantes por sal\u00f3n. Bloque \u201cIndicadores de capacidad\u201d Secci\u00f3n central que agrupa las tarjetas KPI y establece el contexto para las gr\u00e1ficas de distribuci\u00f3n. Gr\u00e1fico \u201cDocentes por Unidad\u201d Diagrama circular que muestra la proporci\u00f3n de docentes asignados a cada unidad de negocio, facilitando la detecci\u00f3n de concentraciones o desequilibrios en recursos humanos. Gr\u00e1fico \u201cServicios Ofertados por Unidad\u201d Diagrama circular que refleja la distribuci\u00f3n de servicios disponibles entre las unidades, permitiendo evaluar la amplitud y diversidad de la oferta educativa. Gr\u00e1fico \u201cServicios Vendidos por Unidad\u201d Diagrama circular que visualiza qu\u00e9 unidades concretan mayor n\u00famero de servicios, indicando la efectividad comercial o la demanda real por \u00e1rea. Leyenda de Unidades Identifica, con c\u00f3digo de color, a Educaci\u00f3n Continua, Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Protecci\u00f3n Social y registros sin unidad asignada. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo utilizados en los indicadores de capacidad. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que aseguran la coherencia gr\u00e1fica con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_6","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Visibilidad de Recursos Disponibles: Permite conocer, en un solo vistazo, la capacidad instalada y los recursos humanos vinculados a cada unidad.</li> <li>Identificaci\u00f3n de Desbalance: Los diagramas circulares facilitan la detecci\u00f3n de sobrecarga o subutilizaci\u00f3n de servicios y personal docente, apoyando la redistribuci\u00f3n estrat\u00e9gica.</li> <li>Soporte a la Planificaci\u00f3n de Infraestructura: Los indicadores sobre espacios f\u00edsicos y estudiantes por sal\u00f3n orientan decisiones de inversi\u00f3n en aulas, equipamiento y ampliaciones.</li> <li>Evaluaci\u00f3n de Eficiencia Comercial: Comparar servicios ofertados con vendidos ayuda a medir la efectividad en la conversi\u00f3n de la oferta educativa y a ajustar estrategias de promoci\u00f3n.</li> <li>Interactividad para An\u00e1lisis Detallado: Los filtros permiten profundizar por periodo, unidad o categor\u00eda, ofreciendo flexibilidad en el diagn\u00f3stico y la generaci\u00f3n de reportes.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-experiencia-de-usuario","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n \u2013\u202fExperiencia de Usuario","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_6","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Proporcionar una lectura integral de la satisfacci\u00f3n y la interacci\u00f3n de los usuarios con los servicios educativos, a trav\u00e9s de indicadores clave como cantidad de usos, PQR (Peticiones, Quejas y Reclamos) y Net Promoter Score (NPS). La vista facilita la detecci\u00f3n de incidencias frecuentes, la medici\u00f3n de la lealtad de los usuarios y la identificaci\u00f3n de \u00e1reas de mejora en la atenci\u00f3n.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_7","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Categor\u00eda de afiliaci\u00f3n que actualizan todos los indicadores de forma din\u00e1mica. Panel Lateral Izquierdo \u00c1rea Aspecto para Analizar con botones para Totales de Negocio, Capacidad F\u00edsica y Experiencia de Usuario (seleccionado). Incluye una breve explicaci\u00f3n del prop\u00f3sito de la vista y un aviso cuando los datos son de muestra. Tarjetas KPI Superiores Tarjetas que resumen m\u00e9tricas institucionales de empresas afiliadas, afiliados, beneficiarios y coberturas generales, aportando contexto global. Bloque \u201cExperiencia de usuario\u201d Secci\u00f3n central que muestra tarjetas con la cantidad de usos, cantidad de PQR y proporci\u00f3n de usos por PQR, ofreciendo un panorama r\u00e1pido de la interacci\u00f3n y las incidencias. Tabla de PQR por Unidad Tabla que detalla, para cada tr\u00e1mite o servicio, la cantidad y el porcentaje de PQR, resaltando los motivos principales de las solicitudes. Indicador NPS Medidor semicircular que representa el resultado de Net Promoter Score, acompa\u00f1ado de tarjetas que muestran el porcentaje de promotores y detractores. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios para interpretar correctamente los indicadores de satisfacci\u00f3n y PQR. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que aseguran coherencia gr\u00e1fica con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_7","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Monitoreo Integral de la Satisfacci\u00f3n: Re\u00fane en un solo tablero las m\u00e9tricas fundamentales de experiencia de usuario, facilitando un seguimiento continuo.</li> <li>Detecci\u00f3n de Causas Recurrentes: La tabla de PQR permite identificar r\u00e1pidamente los tr\u00e1mites o servicios con mayores incidencias, orientando planes de mejora.</li> <li>Medici\u00f3n de Lealtad: El NPS y la segmentaci\u00f3n de promotores/detractores proporcionan una visi\u00f3n clara de la percepci\u00f3n de los usuarios y su disposici\u00f3n a recomendar los servicios.</li> <li>Priorizaci\u00f3n de Recursos: Con base en la proporci\u00f3n de usos por PQR, se pueden asignar equipos y esfuerzos a las \u00e1reas con mayor demanda de atenci\u00f3n.</li> <li>Interactividad para An\u00e1lisis Profundo: Los filtros permiten segmentar la experiencia por unidad, periodo o categor\u00eda, ofreciendo flexibilidad para diagn\u00f3sticos espec\u00edficos y decisiones informadas.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y\u202fCalidad","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_7","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Ofrecer una visi\u00f3n integral del desempe\u00f1o y la calidad de las unidades de Educaci\u00f3n, destacando indicadores clave sobre cobertura, efectividad, fidelizaci\u00f3n empresarial y logros acad\u00e9micos. La vista sirve para evaluar c\u00f3mo los resultados de los programas impactan tanto en la formaci\u00f3n como en la gesti\u00f3n organizacional, facilitando la toma de decisiones orientadas a la mejora continua.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_8","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Secci\u00f3n Desempe\u00f1o y Calidad con botones para Desempe\u00f1o (seleccionado), Comportamientos Hist\u00f3ricos, Comportamiento Financiero, Experiencia de Usuario y An\u00e1lisis Miner\u00eda. Incluye una breve descripci\u00f3n del prop\u00f3sito de la vista y una alerta cuando los datos corresponden a una muestra. Tarjetas KPI Superiores Tarjetas que muestran m\u00e9tricas institucionales generales (empresas afiliadas, afiliados, beneficiarios, empresas atendidas, afiliados atendidos, beneficiarios atendidos) aportando contexto global antes de analizar la calidad y resultados espec\u00edficos. Bloque \u201cDesempe\u00f1o\u201d Contiene indicadores clave como cumplimiento de cobertura, efectividad de cotizaciones, repetici\u00f3n de compra de empresas, cobertura para empleados internos, proporciones de poblaci\u00f3n atendida en programas espec\u00edficos y variaci\u00f3n en resultados acad\u00e9micos. Gr\u00e1fico de Incremento Empresarial \u00c1rea de gr\u00e1fico de l\u00edneas destinada a visualizar la tendencia de incremento de empresas que contratan servicios de fomento empresarial, permitiendo identificar patrones temporales en la demanda. Leyendas e \u00cdconos Elementos visuales que diferencian los indicadores (por ejemplo, icono de diana para desempe\u00f1o), mejoran la legibilidad y destacan la categorizaci\u00f3n de la informaci\u00f3n. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones, notas metodol\u00f3gicas y criterios de c\u00e1lculo para la interpretaci\u00f3n correcta de los indicadores. Pie de P\u00e1gina Franja inferior con la referencia temporal analizada y l\u00edneas de color corporativo que mantienen la coherencia gr\u00e1fica con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_8","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Evaluaci\u00f3n Integral del Desempe\u00f1o: Re\u00fane en un solo espacio los principales indicadores de cobertura y calidad, proporcionando una base s\u00f3lida para medir el logro de objetivos estrat\u00e9gicos.</li> <li>Detecci\u00f3n de \u00c1reas de Mejora: El an\u00e1lisis de efectividad y repetici\u00f3n de compra corporativa ayuda a identificar oportunidades para fortalecer la propuesta de valor y la retenci\u00f3n de clientes empresariales.</li> <li>Seguimiento de Logros Acad\u00e9micos: Los indicadores acad\u00e9micos permiten monitorear el impacto de los programas de educaci\u00f3n en los resultados de aprendizaje, orientando acciones pedag\u00f3gicas y de apoyo.</li> <li>Tendencias en Demanda Empresarial: El gr\u00e1fico de incremento de empresas facilita la identificaci\u00f3n de patrones en la compra de servicios, ayudando a planificar estrategias comerciales y de fidelizaci\u00f3n.</li> <li>Interactividad para An\u00e1lisis Profundo: Los filtros y la segmentaci\u00f3n por aspecto ofrecen flexibilidad para explorar tendencias espec\u00edficas, generar reportes comparativos y sustentar decisiones basadas en datos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad-comportamientos-historicos","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y\u202fCalidad (Comportamientos Hist\u00f3ricos)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_8","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Permitir el an\u00e1lisis evolutivo de los indicadores clave del proceso educativo, brindando una herramienta interactiva para identificar tendencias, patrones y variaciones a lo largo del tiempo. La vista ayuda a comprender c\u00f3mo se comportan aspectos como graduaciones, matr\u00edculas, PQR y otros indicadores de calidad, facilitando la toma de decisiones basadas en la historia de desempe\u00f1o.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_9","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Secci\u00f3n Desempe\u00f1o y Calidad con botones para diferentes enfoques (Desempe\u00f1o, Comportamientos Hist\u00f3ricos, Comportamiento Financiero, Experiencia de Usuario, An\u00e1lisis Miner\u00eda). El bot\u00f3n Comportamientos Hist\u00f3ricos aparece resaltado. Incluye una explicaci\u00f3n breve del objetivo de la vista y una alerta cuando los datos son de muestra. Tarjetas KPI Superiores Tarjetas que presentan m\u00e9tricas institucionales globales (empresas afiliadas, afiliados, beneficiarios, empresas atendidas, etc.), proporcionando contexto antes de explorar el comportamiento hist\u00f3rico. Bloque \u201cComportamientos hist\u00f3ricos\u201d Contiene una lista de radio\u2011botones con los indicadores disponibles para an\u00e1lisis (graduados, matr\u00edculas, PQR, cobertura proyectada, porcentaje de deserci\u00f3n, entre otros). La selecci\u00f3n de un indicador actualiza el gr\u00e1fico a la derecha. Gr\u00e1fico de Tendencia Gr\u00e1fico de l\u00edneas que muestra la evoluci\u00f3n temporal del indicador elegido, permitiendo visualizar tendencias y variaciones de forma clara e inmediata. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y consideraciones metodol\u00f3gicas para interpretar adecuadamente los indicadores hist\u00f3ricos. Pie de P\u00e1gina Franja inferior con la referencia del periodo analizado y l\u00edneas de color corporativo que mantienen la coherencia gr\u00e1fica con el resto de tableros."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_9","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Detecci\u00f3n de Tendencias: Ayuda a identificar incrementos, descensos o patrones estacionales en los indicadores, facilitando la planificaci\u00f3n estrat\u00e9gica.</li> <li>Evaluaci\u00f3n de Impacto: Permite correlacionar iniciativas implementadas con cambios en los resultados, apoyando la medici\u00f3n de efectividad de proyectos y pol\u00edticas.</li> <li>Priorizaci\u00f3n de Acciones Correctivas: Al resaltar variaciones significativas, gu\u00eda la asignaci\u00f3n de recursos hacia las \u00e1reas que requieren atenci\u00f3n inmediata.</li> <li>An\u00e1lisis Flexible: Los filtros y la selecci\u00f3n de indicadores ofrecen m\u00faltiples combinaciones para profundizar en periodos o variables espec\u00edficas.</li> <li>Transparencia y Seguimiento Continuo: Proporciona una visi\u00f3n hist\u00f3rica consolidada que respalda la rendici\u00f3n de cuentas y el monitoreo permanente de la calidad educativa.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad-comportamiento-financiero","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y\u202fCalidad (Comportamiento\u202fFinanciero)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_9","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Mostrar de manera estructurada el comportamiento financiero del proceso educativo, resaltando aportes, subsidios y transacciones, adem\u00e1s de identificar a las principales empresas que invierten en educaci\u00f3n. Esta vista facilita el seguimiento de la ejecuci\u00f3n presupuestal y la toma de decisiones sobre asignaci\u00f3n de recursos y estrategias de vinculaci\u00f3n empresarial.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_10","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa Desempe\u00f1o y Calidad con botones para cambiar de enfoque (Desempe\u00f1o, Comportamientos Hist\u00f3ricos, Comportamiento Financiero, Experiencia de Usuario, An\u00e1lisis Miner\u00eda). Incluye un texto que explica el prop\u00f3sito de la vista y alerta sobre el uso de datos de muestra. Tarjetas KPI Superiores Tarjetas que ofrecen contexto institucional antes de profundizar en la secci\u00f3n financiera (empresas afiliadas, afiliados, beneficiarios, entre otras). Bloque \u201cComportamiento Financiero\u201d Conjunto de paneles que agrupan indicadores de aportes y subsidios (cantidad, valor y transacciones de afiliados), integrando notas metodol\u00f3gicas para su correcta interpretaci\u00f3n. Tabla \u201cTop\u00a010\u202fEmpresas Atendidas por Educaci\u00f3n\u201d Tabla din\u00e1mica que lista las empresas con mayor aporte al proceso educativo, destacando el valor invertido y su relevancia dentro del total. Secci\u00f3n de Ejecuci\u00f3n Presupuestal Panel inferior que contrasta los ingresos ejecutados con los ingresos presupuestados y el resultado del ejercicio, permitiendo visualizar la eficiencia del gasto. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones clave y criterios de c\u00e1lculo para comprender los indicadores financieros. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que mantienen la coherencia gr\u00e1fica con todo el tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_10","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Control Financiero Integral: Centraliza los indicadores clave de aportes y ejecuci\u00f3n, facilitando la supervisi\u00f3n del uso de recursos y la planeaci\u00f3n presupuestal.</li> <li>Identificaci\u00f3n de Socios Estrat\u00e9gicos: La tabla de empresas permite reconocer a los principales aliados y enfocar acciones de fidelizaci\u00f3n o expansi\u00f3n de convenios.</li> <li>Evaluaci\u00f3n de Eficiencia Presupuestal: El contraste entre ingresos ejecutados y presupuestados ayuda a detectar desviaciones y ajustar estrategias de inversi\u00f3n.</li> <li>Transparencia y Rendici\u00f3n de Cuentas: Presenta informaci\u00f3n financiera consolidada que respalda decisiones informadas y reportes a la alta direcci\u00f3n.</li> <li>Interactividad para An\u00e1lisis Detallado: Los filtros ofrecen flexibilidad para segmentar la informaci\u00f3n por unidad, periodo o categor\u00eda, aportando profundidad al an\u00e1lisis y soporte a iniciativas de mejora.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad-experiencia-de-usuario","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y\u202fCalidad (Experiencia de Usuario)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_10","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Ofrecer una perspectiva integral de la satisfacci\u00f3n y fidelidad de los usuarios, complementada con m\u00e9tricas de promoci\u00f3n y deserci\u00f3n acad\u00e9mica. La vista facilita la identificaci\u00f3n de unidades con mayor proporci\u00f3n de promotores, el seguimiento del \u00edndice NPS y la detecci\u00f3n temprana de riesgos de abandono institucional.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_11","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa Desempe\u00f1o y Calidad con botones para cambiar de enfoque (Desempe\u00f1o, Comportamientos Hist\u00f3ricos, Comportamiento Financiero, Experiencia de Usuario, An\u00e1lisis\u202fMiner\u00eda). Incluye una breve explicaci\u00f3n de la vista actual y un aviso sobre el uso de datos de muestra. Tarjetas KPI Superiores Tarjetas que aportan contexto institucional (empresas afiliadas, afiliados, beneficiarios, entre otros) antes de profundizar en la experiencia de usuario. Bloque \u201cExperiencia de Usuario\u201d Secci\u00f3n central con el indicador Net Promoter Score (gauge semicircular) y tarjetas que muestran la proporci\u00f3n de promotores y detractores. Tabla de Promotores/Detractores por Unidad Tabla que desglosa, para cada unidad, el porcentaje relativo de promotores y detractores, facilitando la comparaci\u00f3n de la percepci\u00f3n del servicio entre \u00e1reas. Panel \u201cPromoci\u00f3n y Deserci\u00f3n\u201d Tabla que presenta los porcentajes de promoci\u00f3n y deserci\u00f3n, as\u00ed como la cantidad de graduados por unidad, brindando una visi\u00f3n combinada de satisfacci\u00f3n y permanencia. Indicadores de Alerta Temprana Tarjetas resaltadas que muestran los valores de deserci\u00f3n temprana seg\u00fan programas espec\u00edficos, permitiendo detectar riesgos y enfocar acciones preventivas. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios metodol\u00f3gicos para interpretar correctamente los indicadores de satisfacci\u00f3n y deserci\u00f3n. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que mantienen la coherencia gr\u00e1fica con el resto de tableros."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_11","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Medici\u00f3n Continua de la Satisfacci\u00f3n: Integra el \u00edndice NPS y su desglose por unidad, permitiendo un seguimiento frecuente de la lealtad de los usuarios.</li> <li>Detecci\u00f3n de \u00c1reas Cr\u00edticas: La tabla de promotores y detractores se\u00f1ala las unidades con menor satisfacci\u00f3n, orientando iniciativas de mejora focalizadas.</li> <li>Visi\u00f3n Integrada de Permanencia: Combinar promoci\u00f3n, deserci\u00f3n y graduados facilita evaluar el impacto de la experiencia de usuario en la trayectoria acad\u00e9mica.</li> <li>Alertas Tempranas de Abandono: Los indicadores destacados permiten anticiparse a posibles incrementos de deserci\u00f3n y dise\u00f1ar acciones correctivas oportunas.</li> <li>Interactividad y Profundidad Anal\u00edtica: Los filtros ofrecen flexibilidad para segmentar por periodo o categor\u00eda, respaldando decisiones basadas en datos y reportes comparativos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad-analisis-mineria","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y\u202fCalidad (An\u00e1lisis\u202fMiner\u00eda)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_11","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Proporcionar una representaci\u00f3n interactiva de los flujos reales del proceso de matr\u00edcula mediante t\u00e9cnicas de Process Mining, permitiendo descubrir rutas frecuentes, cuellos de botella y oportunidades de optimizaci\u00f3n en la gesti\u00f3n educativa.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_12","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa Desempe\u00f1o y Calidad con botones para Desempe\u00f1o, Comportamientos Hist\u00f3ricos, Comportamiento Financiero, Experiencia de Usuario y An\u00e1lisis\u202fMiner\u00eda (seleccionado). Incluye una descripci\u00f3n breve del prop\u00f3sito de la vista y un aviso sobre el uso de datos de muestra. Tarjetas KPI Superiores Tarjetas que ofrecen contexto institucional (empresas afiliadas, afiliados, beneficiarios, empresas atendidas, afiliados atendidos, beneficiarios atendidos) antes de profundizar en la miner\u00eda de procesos. Bloque \u201cAn\u00e1lisis Miner\u00eda\u201d Contiene instrucciones para seleccionar el proceso a analizar y ajustar el n\u00famero de variantes mostradas, junto con el \u00e1rea principal donde se visualiza el diagrama de flujo real de eventos. Diagrama de Proceso Visualizaci\u00f3n interactiva que representa los pasos del proceso de matr\u00edcula, destacando los nodos y las transiciones seg\u00fan su frecuencia. Incluye controles de zoom y un deslizador para explorar variantes. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones de eventos, criterios de agrupaci\u00f3n y recomendaciones para interpretar la gr\u00e1fica. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que mantienen la coherencia gr\u00e1fica con las dem\u00e1s vistas."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_12","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Descubrimiento de Flujos Reales: Permite contrastar el proceso te\u00f3rico con el flujo real, evidenciando desviaciones y pasos innecesarios.</li> <li>Detecci\u00f3n de Cuellos de Botella: La visualizaci\u00f3n de transiciones frecuentes ayuda a identificar puntos de demora o retrabajo, orientando acciones de mejora.</li> <li>Optimizaci\u00f3n de Procesos: Al conocer las rutas m\u00e1s comunes y su duraci\u00f3n relativa, se pueden redise\u00f1ar etapas para reducir tiempos y elevar la eficiencia.</li> <li>An\u00e1lisis Interactivo: Los controles de variantes y zoom facilitan el enfoque en casos espec\u00edficos o en la totalidad del proceso, brindando flexibilidad anal\u00edtica.</li> <li>Soporte a la Mejora Continua: La informaci\u00f3n derivada de la miner\u00eda de procesos respalda decisiones basadas en datos para incrementar la calidad y la eficacia operativa.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-eficiencia","title":"Productividad Organizacional \u2013 An\u00e1lisis de Eficiencia","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_12","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Exponer, de manera clara y estructurada, el comportamiento de la capacidad operativa, la inversi\u00f3n en infraestructura y los principales indicadores de productividad de las unidades educativas. La vista permite identificar el uso de recursos, los factores que reducen la capacidad contratada y la efectividad de iniciativas acad\u00e9micas y administrativas.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_13","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis de Eficiencia con botones para Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua y Protecci\u00f3n Social; incluye una breve explicaci\u00f3n del prop\u00f3sito de la vista y una alerta cuando se utilizan datos de muestra. Tarjetas KPI Superiores Conjunto de tarjetas que presentan indicadores clave de capacidad (espacios f\u00edsicos, horas contratadas, rotaci\u00f3n de planta, iniciativas, etc.), sin mostrar cifras en la descripci\u00f3n. Bloque \u201cEducaci\u00f3n Formal\u201d Grupo de tarjetas detalladas que indican horas contratadas, horas empleadas en cubrir ausencias y porcentaje de tiempo administrativo real; se utiliza para profundizar en la unidad seleccionada. Tabla \u201cReductores de Capacidad por Causa\u201d Tabla que desglosa las causas que disminuyen la capacidad contratada, permitiendo analizar su peso relativo y planificar acciones correctivas. Panel de Indicadores Complementarios Tarjetas que muestran la utilizaci\u00f3n de bibliotecas virtuales, porcentajes de promoci\u00f3n y deserci\u00f3n, as\u00ed como res\u00famenes de inversi\u00f3n tecnol\u00f3gica y f\u00edsica. Tabla de Cursos Tabla a la derecha con informaci\u00f3n de matr\u00edculas, retiros, graduados y movilidad acad\u00e9mica por curso, facilitando la evaluaci\u00f3n granular de la eficiencia educativa. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo para interpretar adecuadamente los indicadores de eficiencia. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que mantienen la coherencia gr\u00e1fica con el resto de tableros."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_13","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Visibilidad de la Capacidad Operativa: Permite conocer el uso de espacios, tiempo laboral y recursos, identificando r\u00e1pidamente la subutilizaci\u00f3n o la sobrecarga.</li> <li>Detecci\u00f3n de Factores Limitantes: La tabla de reductores de capacidad facilita la priorizaci\u00f3n de acciones para minimizar ausencias, tiempos muertos y otros impedimentos.</li> <li>Evaluaci\u00f3n de Inversiones: Presenta el impacto de la inversi\u00f3n en infraestructura f\u00edsica y tecnol\u00f3gica sobre la eficiencia y el aprovechamiento de los servicios educativos.</li> <li>Seguimiento de Rendimiento Acad\u00e9mico: Combinar datos de curso y movilidad acad\u00e9mica con indicadores de promoci\u00f3n y deserci\u00f3n aporta una visi\u00f3n completa del ciclo formativo.</li> <li>Interactividad para An\u00e1lisis Profundo: Los filtros y la selecci\u00f3n de unidades ofrecen flexibilidad para segmentar la informaci\u00f3n por periodo o \u00e1rea, respaldando decisiones basadas en datos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-eficiencia-educacion-tecnica","title":"Productividad Organizacional \u2013 An\u00e1lisis de Eficiencia (Educaci\u00f3n T\u00e9cnica)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_13","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Presentar el desempe\u00f1o de la unidad de Educaci\u00f3n T\u00e9cnica en t\u00e9rminos de capacidad operativa, utilizaci\u00f3n de recursos e impacto de la inversi\u00f3n en infraestructura. La vista permite identificar factores que reducen la capacidad contratada, evaluar la pertinencia de la oferta formativa y analizar la movilidad acad\u00e9mica por programa.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_14","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis de Eficiencia con opciones para Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica (seleccionado), Educaci\u00f3n Continua y Protecci\u00f3n Social. Incluye una breve descripci\u00f3n del prop\u00f3sito de la vista y un aviso sobre datos de muestra. Tarjetas KPI Superiores Tarjetas que resumen la capacidad general (espacios f\u00edsicos, horas contratadas, rotaci\u00f3n de planta, iniciativas, etc.), proporcionando contexto global sin cifras en el texto. Bloque \u201cEducaci\u00f3n T\u00e9cnica\u201d Grupo de tarjetas que detallan reductores de capacidad contratada e inversiones en infraestructura f\u00edsica y tecnol\u00f3gica, as\u00ed como m\u00e9tricas de tiempo administrativo y documentaci\u00f3n estudiantil. Tabla \u201cReductores de Capacidad por Causa\u201d Tabla que desglosa las causas que disminuyen la capacidad contratada, permitiendo priorizar acciones correctivas. Panel de Indicadores Complementarios Tarjetas que muestran indicadores de utilizaci\u00f3n de bibliotecas virtuales, promoci\u00f3n, deserci\u00f3n y evaluaci\u00f3n curricular por el sector productivo. Tabla \u201cMovilidad Acad\u00e9mica por Programa\u201d Tabla con datos de matr\u00edculas, retiros, graduados y movilidad acad\u00e9mica para cada programa t\u00e9cnico, facilitando el an\u00e1lisis granular de la eficiencia formativa. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo para interpretar los indicadores de eficiencia. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que mantienen la coherencia gr\u00e1fica con el resto de tableros."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_14","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Visibilidad de Capacidad y Recursos: Permite monitorear utilizaci\u00f3n de espacios, tiempo laboral e inversiones, identificando r\u00e1pidamente subutilizaci\u00f3n o sobrecarga.</li> <li>Priorizaci\u00f3n de Acciones Correctivas: La tabla de reductores de capacidad ayuda a focalizar esfuerzos para minimizar ausencias y otros impedimentos operativos.</li> <li>Evaluaci\u00f3n de Oferta Formativa: El panel de movilidad acad\u00e9mica y la evaluaci\u00f3n curricular facilitan la alineaci\u00f3n de programas con la demanda del sector productivo.</li> <li>Seguimiento de Indicadores Clave: Combina m\u00e9tricas de promoci\u00f3n, deserci\u00f3n y documentaci\u00f3n acad\u00e9mica para medir la eficiencia educativa de manera integral.</li> <li>Interactividad Anal\u00edtica: Los filtros permiten segmentar la informaci\u00f3n por periodo o categor\u00eda, apoyando decisiones basadas en datos y reportes comparativos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-eficiencia-educacion-continua","title":"Productividad Organizacional \u2013 An\u00e1lisis de Eficiencia (Educaci\u00f3n Continua)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_14","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Ofrecer una perspectiva consolidada sobre la eficiencia operativa de la unidad de Educaci\u00f3n Continua, destacando el uso de recursos, la efectividad de las evaluaciones, la inversi\u00f3n en infraestructura y la movilidad acad\u00e9mica por programa. La vista facilita la detecci\u00f3n de oportunidades de optimizaci\u00f3n y el seguimiento de la recurrencia empresarial en la compra de servicios.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_15","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis de Eficiencia con opciones para Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua (seleccionado) y Protecci\u00f3n Social. Incluye una breve explicaci\u00f3n del prop\u00f3sito de la vista y un aviso sobre el uso de datos de muestra. Tarjetas KPI Superiores Tarjetas que presentan indicadores generales de capacidad (horas contratadas, rotaci\u00f3n de planta, n\u00famero de iniciativas) sin mostrar cifras en la descripci\u00f3n. Bloque \u201cEducaci\u00f3n Continua\u201d Conjunto de tarjetas que muestran indicadores espec\u00edficos, como la efectividad en cotizaciones, porcentaje de evaluaciones bajo el promedio y montos de inversi\u00f3n en infraestructura tecnol\u00f3gica y f\u00edsica. Tabla \u201cMovilidad Acad\u00e9mica por Programa\u201d Tabla que desglosa matr\u00edculas, retiros y certificados para cada programa de Educaci\u00f3n Continua, brindando una visi\u00f3n granular de la eficiencia formativa. Gr\u00e1fico de Recurrencia Empresarial Gr\u00e1fico de l\u00edneas que representa la proporci\u00f3n de empresas que repiten la compra de servicios de fomento empresarial, indicando la fidelizaci\u00f3n corporativa en el tiempo. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo para interpretar correctamente los indicadores de eficiencia. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que garantizan la coherencia gr\u00e1fica con el resto de tableros."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_15","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Seguimiento del Rendimiento Acad\u00e9mico: La tabla de movilidad acad\u00e9mica permite evaluar la efectividad de cada programa y detectar \u00e1reas de mejora en la oferta formativa.</li> <li>Medici\u00f3n de Eficiencia Operativa: Los indicadores de capacidad y ejecuci\u00f3n de recursos ofrecen una visi\u00f3n clara del uso de horas contratadas, infraestructura y tiempo administrativo.</li> <li>Fidelizaci\u00f3n Empresarial: El gr\u00e1fico de recurrencia empresarial ayuda a identificar la satisfacci\u00f3n de los clientes corporativos y orienta estrategias para fortalecer la relaci\u00f3n con el sector productivo.</li> <li>Priorizaci\u00f3n de Inversiones: Los datos sobre inversi\u00f3n tecnol\u00f3gica y f\u00edsica facilitan la toma de decisiones respecto a mejoras de infraestructura y optimizaci\u00f3n de recursos.</li> <li>Interactividad Anal\u00edtica: Los filtros permiten segmentar la informaci\u00f3n por periodo y categor\u00eda, aportando flexibilidad para diagn\u00f3sticos espec\u00edficos y reportes comparativos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-eficiencia-proteccion-social","title":"Productividad Organizacional \u2013 An\u00e1lisis de Eficiencia (Protecci\u00f3n\u202fSocial)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_15","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Proporcionar una visi\u00f3n consolidada de la eficiencia operativa de la unidad de Protecci\u00f3n Social, resaltando la utilizaci\u00f3n de recursos, la ejecuci\u00f3n de fondos y la cobertura de servicios destinados a poblaciones vulnerables. La vista facilita la detecci\u00f3n de oportunidades de mejora y la priorizaci\u00f3n de iniciativas que maximicen el impacto social.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_16","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis de Eficiencia con botones para Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua y Protecci\u00f3n Social (seleccionado). Incluye una breve explicaci\u00f3n del prop\u00f3sito de la vista y un aviso sobre datos de muestra. Tarjetas KPI Superiores Tarjetas que resumen indicadores generales de capacidad (horas contratadas, rotaci\u00f3n de planta, n\u00famero de iniciativas), sin mostrar cifras en el texto. Bloque \u201cProtecci\u00f3n Social\u201d Tarjetas que muestran la proporci\u00f3n de afiliados beneficiados, la ejecuci\u00f3n de fondos institucionales y m\u00e9tricas de servicios ofertados y vendidos. Tabla \u201cPoblaci\u00f3n Afiliada por Programa\u201d Tabla que desglosa categor\u00edas de poblaci\u00f3n atendida (adulto mayor, discapacidad, entre otras), indicando cobertura y atenci\u00f3n a poblaci\u00f3n vulnerable. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo para interpretar correctamente los indicadores de eficiencia. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que mantienen la coherencia visual con el resto de tableros."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_16","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Seguimiento de la Cobertura Social: Permite monitorear la proporci\u00f3n de afiliados beneficiados y la atenci\u00f3n a poblaci\u00f3n vulnerable, identificando brechas y \u00e1reas de oportunidad.</li> <li>Evaluaci\u00f3n de la Ejecuci\u00f3n de Fondos: Los indicadores de ejecuci\u00f3n presupuestal ayudan a verificar el uso eficiente de recursos destinados a programas sociales.</li> <li>Optimizaci\u00f3n de la Oferta de Servicios: La combinaci\u00f3n de servicios ofertados y vendidos facilita la identificaci\u00f3n de la demanda real y la planificaci\u00f3n de iniciativas futuras.</li> <li>Priorizaci\u00f3n Basada en Datos: La tabla de poblaci\u00f3n atendida orienta la asignaci\u00f3n de esfuerzos hacia los programas de mayor impacto y necesidad social.</li> <li>Interactividad Anal\u00edtica: Los filtros permiten segmentar la informaci\u00f3n por periodo y categor\u00eda, proporcionando flexibilidad para diagn\u00f3sticos espec\u00edficos y decisiones informadas.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-servicio-educacion-formal","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por\u202fServicio (Educaci\u00f3n\u202fFormal)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_16","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Exponer de forma clara el impacto social generado por los servicios de Educaci\u00f3n Formal, resaltando la distribuci\u00f3n de estudiantes por categor\u00eda y g\u00e9nero, la atenci\u00f3n a poblaci\u00f3n vulnerable y la calidad percibida por los usuarios. La vista permite evaluar r\u00e1pidamente la cobertura social y detectar oportunidades para fortalecer la inclusi\u00f3n y la satisfacci\u00f3n estudiantil.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_17","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis por Servicio con botones para Educaci\u00f3n Formal (seleccionado), Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua y Protecci\u00f3n Social. Incluye una breve explicaci\u00f3n del prop\u00f3sito de la vista y un aviso sobre datos de muestra. Tarjetas KPI Superiores Tarjetas que muestran indicadores globales (empresas afiliadas, afiliados, beneficiarios, empresas atendidas, afiliados atendidos y beneficiarios atendidos) para contextualizar el an\u00e1lisis de servicio. Bloque de Indicadores Sociales Tarjetas que presentan el porcentaje de promotores y detractores, la atenci\u00f3n a poblaci\u00f3n vulnerable y el indicador de accidentalidad estudiantil, ofreciendo una visi\u00f3n r\u00e1pida de la calidad percibida y la seguridad. Tabla de Servicios Vendidos Tabla que muestra el detalle de servicios ofertados y vendidos dentro de Educaci\u00f3n Formal, evidenciando la conversi\u00f3n de la oferta en impacto real. Gr\u00e1fico \u201cEstudiantes por Categor\u00eda\u201d Gr\u00e1fico de barras que visualiza la proporci\u00f3n de estudiantes atendidos seg\u00fan categor\u00eda de afiliaci\u00f3n, facilitando la evaluaci\u00f3n de la cobertura social. Gr\u00e1fico \u201cEstudiantes por G\u00e9nero\u201d Gr\u00e1fico de barras que ilustra la distribuci\u00f3n de estudiantes por g\u00e9nero, permitiendo analizar la equidad de acceso a los servicios. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo para interpretar correctamente los indicadores sociales. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que garantizan la coherencia visual con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_17","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Evaluaci\u00f3n de Cobertura Social: Permite identificar la distribuci\u00f3n de estudiantes por categor\u00eda y g\u00e9nero, orientando estrategias de inclusi\u00f3n y equidad.</li> <li>Medici\u00f3n de la Satisfacci\u00f3n: Los indicadores de promotores y detractores facilitan el seguimiento de la percepci\u00f3n de calidad y respaldan acciones de mejora continua.</li> <li>Seguimiento de Seguridad Estudiantil: El indicador de accidentalidad aporta informaci\u00f3n clave para implementar medidas preventivas y de bienestar.</li> <li>An\u00e1lisis de Conversi\u00f3n de Servicios: La tabla de servicios vendidos evidencia la efectividad en la entrega de programas, apoyando decisiones sobre oferta y demanda.</li> <li>Interactividad Anal\u00edtica: Los filtros din\u00e1micos permiten segmentar la informaci\u00f3n por periodo o categor\u00eda, proporcionando flexibilidad para diagn\u00f3sticos espec\u00edficos y reportes comparativos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-servicio-educacion-tecnica","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por\u202fServicio (Educaci\u00f3n\u202fT\u00e9cnica)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_17","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Mostrar de forma consolidada el impacto social de los servicios de Educaci\u00f3n T\u00e9cnica, resaltando la distribuci\u00f3n de estudiantes por categor\u00eda y g\u00e9nero, la calidad percibida por los usuarios y la atenci\u00f3n a poblaci\u00f3n vulnerable. La vista facilita la evaluaci\u00f3n de la cobertura social y la identificaci\u00f3n de \u00e1reas de mejora en la satisfacci\u00f3n estudiantil.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_18","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis por Servicio con botones para Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica (seleccionado), Educaci\u00f3n Continua y Protecci\u00f3n Social. Incluye una breve explicaci\u00f3n del objetivo de la vista y un aviso sobre el uso de datos de muestra. Tarjetas KPI Superiores Tarjetas que proporcionan contexto institucional sobre afiliados, beneficiarios y otros indicadores globales antes de profundizar en el servicio. Bloque de Indicadores Sociales Tarjetas que presentan la proporci\u00f3n de promotores y detractores, la atenci\u00f3n a poblaci\u00f3n vulnerable y la integridad documental de los estudiantes matriculados. Tabla de Servicios Vendidos Tabla que muestra el detalle de servicios ofertados y vendidos dentro de Educaci\u00f3n T\u00e9cnica, evidenciando la conversi\u00f3n de la oferta en impacto real. Gr\u00e1fico \u201cEstudiantes por Categor\u00eda\u201d Gr\u00e1fico de barras que ilustra la distribuci\u00f3n de estudiantes atendidos seg\u00fan categor\u00eda de afiliaci\u00f3n, facilitando el an\u00e1lisis de cobertura social. Gr\u00e1fico \u201cEstudiantes por G\u00e9nero\u201d Gr\u00e1fico de barras que representa la distribuci\u00f3n de estudiantes por g\u00e9nero, permitiendo evaluar la equidad de acceso a los servicios. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo para interpretar correctamente los indicadores sociales. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que mantienen la coherencia gr\u00e1fica con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_18","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Evaluaci\u00f3n de Cobertura Social: Permite conocer la distribuci\u00f3n de estudiantes por categor\u00eda y g\u00e9nero, orientando estrategias de inclusi\u00f3n y equidad.</li> <li>Monitoreo de Satisfacci\u00f3n: Los indicadores de promotores y detractores facilitan el seguimiento de la percepci\u00f3n de calidad y respaldan acciones de mejora continua.</li> <li>Seguimiento de Documentaci\u00f3n Estudiantil: La tarjeta de integridad documental ayuda a garantizar la conformidad de los procesos administrativos de matr\u00edcula.</li> <li>An\u00e1lisis de Conversi\u00f3n de Servicios: La tabla de servicios vendidos evidencia la efectividad en la entrega de programas, apoyando decisiones sobre oferta y demanda.</li> <li>Interactividad Anal\u00edtica: Los filtros din\u00e1micos permiten segmentar la informaci\u00f3n por periodo o categor\u00eda, proporcionando flexibilidad para diagn\u00f3sticos detallados y reportes comparativos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-servicio-educacion-continua","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por\u202fServicio (Educaci\u00f3n\u202fContinua)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_18","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Presentar, de forma estructurada e interactiva, el impacto social generado por los servicios de Educaci\u00f3n Continua, resaltando distribuci\u00f3n de estudiantes por categor\u00eda y g\u00e9nero, niveles de satisfacci\u00f3n de los usuarios y atenci\u00f3n a poblaci\u00f3n vulnerable. La vista facilita identificar oportunidades para fortalecer la inclusi\u00f3n, la calidad percibida y la fidelizaci\u00f3n de los participantes.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_19","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis por Servicio con botones para las cuatro \u00e1reas (Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua\u00a0\u2013\u202fseleccionado\u202f\u2013 y Protecci\u00f3n Social), junto a un texto que explica el prop\u00f3sito de la vista y un aviso cuando se usan datos de muestra. Tarjetas KPI Superiores Tarjetas que brindan contexto institucional (empresas afiliadas, afiliados, beneficiarios, empresas atendidas, afiliados atendidos, beneficiarios atendidos) antes de profundizar en el an\u00e1lisis del servicio. Bloque de Indicadores Sociales Tarjetas que muestran los porcentajes de detractores y promotores, la atenci\u00f3n a poblaci\u00f3n vulnerable y los indicadores de retenci\u00f3n, ofreciendo una lectura r\u00e1pida de la calidad percibida. Tabla de Servicios Vendidos Tabla que detalla los servicios ofertados y vendidos dentro de Educaci\u00f3n Continua, evidenciando la conversi\u00f3n de la oferta en impacto real. Gr\u00e1fico \u201cEstudiantes por Categor\u00eda\u201d Gr\u00e1fico de barras que visualiza la distribuci\u00f3n de estudiantes atendidos seg\u00fan la categor\u00eda de afiliaci\u00f3n, facilitando la evaluaci\u00f3n de la cobertura social. Gr\u00e1fico \u201cEstudiantes por G\u00e9nero\u201d Gr\u00e1fico de barras que representa la distribuci\u00f3n de estudiantes por g\u00e9nero, permitiendo analizar la equidad de acceso a los servicios. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo, ayudando al usuario a interpretar correctamente los indicadores sociales. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que aseguran la coherencia gr\u00e1fica con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_19","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Evaluaci\u00f3n de Cobertura Social: Permite conocer la distribuci\u00f3n de estudiantes por categor\u00eda y g\u00e9nero, orientando acciones de inclusi\u00f3n y equidad.</li> <li>Monitoreo de Satisfacci\u00f3n: Los indicadores de promotores y detractores facilitan el seguimiento de la percepci\u00f3n de calidad y respaldan decisiones de mejora continua.</li> <li>Priorizaci\u00f3n de Servicios: La tabla de servicios vendidos aporta informaci\u00f3n sobre la efectividad de la oferta, ayudando a ajustar programas seg\u00fan la demanda real.</li> <li>Seguimiento de Retenci\u00f3n y Vulnerabilidad: La visualizaci\u00f3n de atenci\u00f3n a poblaci\u00f3n vulnerable y de retenci\u00f3n temprana apoya la identificaci\u00f3n de grupos que requieren intervenciones espec\u00edficas.</li> <li>Interactividad Anal\u00edtica: Los filtros din\u00e1micos posibilitan segmentar datos por periodo o categor\u00eda, ofreciendo flexibilidad para diagn\u00f3sticos detallados y reportes comparativos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-servicio-proteccion-social","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por\u202fServicio (Protecci\u00f3n\u202fSocial)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_19","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Presentar el impacto social derivado de los servicios de Protecci\u00f3n\u202fSocial, destacando la distribuci\u00f3n de la poblaci\u00f3n atendida por categor\u00eda y g\u00e9nero, la satisfacci\u00f3n de los beneficiarios y el grado de atenci\u00f3n a grupos vulnerables. La vista facilita evaluar la cobertura y calidad de los programas, as\u00ed como identificar oportunidades para fortalecer la inclusi\u00f3n y la experiencia de los usuarios.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_20","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis por Servicio con botones para Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua y Protecci\u00f3n\u202fSocial (activo). Contiene un breve texto explicativo sobre la finalidad de la vista y un aviso cuando se utilizan datos de muestra. Tarjetas KPI Superiores Tarjetas que ofrecen contexto institucional mostrando, de forma resumida, informaci\u00f3n sobre empresas afiliadas, afiliados, beneficiarios y otros indicadores globales que respaldan la lectura de impacto social. Bloque de Indicadores Sociales Tarjetas que muestran la proporci\u00f3n de promotores y detractores, la atenci\u00f3n a poblaci\u00f3n vulnerable, la retenci\u00f3n temprana y otros indicadores claves para medir la percepci\u00f3n de calidad y la cobertura social. Tabla de Servicios Vendidos Tabla que detalla los servicios ofertados y vendidos dentro de Protecci\u00f3n\u202fSocial, reflejando la correspondencia entre oferta y utilizaci\u00f3n real. Gr\u00e1fico \u201cPoblaci\u00f3n Atendida por Categor\u00eda\u201d Gr\u00e1fico de barras que visualiza la distribuci\u00f3n de poblaci\u00f3n atendida seg\u00fan categor\u00eda de afiliaci\u00f3n, facilitando la evaluaci\u00f3n de alcance y equidad. Gr\u00e1fico \u201cPoblaci\u00f3n Atendida por G\u00e9nero\u201d Gr\u00e1fico de barras que representa la distribuci\u00f3n de poblaci\u00f3n atendida por g\u00e9nero, permitiendo analizar la inclusi\u00f3n y el acceso igualitario a los servicios. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo empleados en los indicadores sociales, ayudando al usuario a interpretar correctamente la vista. Pie de P\u00e1gina Franja inferior que muestra el periodo de an\u00e1lisis y l\u00edneas de color corporativo, preservando la coherencia gr\u00e1fica con el resto de los tableros del modelo anal\u00edtico."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_20","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Evaluaci\u00f3n de Cobertura Social: Permite identificar la distribuci\u00f3n de beneficiarios por categor\u00eda y g\u00e9nero, orientando decisiones para mejorar la equidad en la prestaci\u00f3n de servicios.</li> <li>Monitoreo de Satisfacci\u00f3n: Los indicadores de promotores y detractores facilitan el seguimiento de la calidad percibida y respaldan la implementaci\u00f3n de acciones de mejora continua.</li> <li>An\u00e1lisis de Demanda y Conversi\u00f3n: La tabla de servicios vendidos muestra la efectividad de la oferta de programas, guiando la planificaci\u00f3n de iniciativas futuras.</li> <li>Seguimiento de Atenci\u00f3n a Grupos Vulnerables: El bloque de indicadores sociales ofrece una visi\u00f3n clara del nivel de atenci\u00f3n a poblaci\u00f3n vulnerable, apoyando la priorizaci\u00f3n de recursos y esfuerzos.</li> <li>Interactividad Anal\u00edtica: Los filtros dan flexibilidad para segmentar la informaci\u00f3n, permitir diagn\u00f3sticos espec\u00edficos y generar reportes comparativos que sustenten la toma de decisiones basada en datos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-empresa","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por\u202fEmpresa","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_20","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Ofrecer una perspectiva interactiva del impacto social generado por los servicios de Educaci\u00f3n agrupado por empresa, permitiendo comparar indicadores clave (afiliados, aportes, beneficiarios, subsidios, etc.) y detectar oportunidades para fortalecer las alianzas con el sector productivo.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_21","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis por Empresa con tres opciones: Indicadores por empresa (seleccionado), Relaci\u00f3n de servicios y aportes, y Servicios vendidos y Subsidios hist\u00f3ricos. Incluye un texto explicativo y un aviso sobre datos de muestra. Tarjetas KPI Superiores Tarjetas que ofrecen contexto institucional (empresas afiliadas, afiliados, beneficiarios, empresas atendidas, afiliados atendidos, beneficiarios atendidos) antes de profundizar en el an\u00e1lisis por empresa. Bloque \u201cIndicadores por Empresa\u201d Listado de radio\u2011botones con distintos indicadores disponibles. Al seleccionar uno, el gr\u00e1fico de barras de la derecha muestra el valor correspondiente para cada empresa. Gr\u00e1fico de Barras \u201cRaz\u00f3n Social\u201d Visualizaci\u00f3n que compara el indicador elegido entre varias empresas, permitiendo identificar r\u00e1pidamente las organizaciones de mayor impacto o contribuci\u00f3n. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo de los indicadores mostrados. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que mantienen la coherencia visual con el resto del tablero."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_21","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>Comparaci\u00f3n Interempresarial Din\u00e1mica: Facilita identificar qu\u00e9 empresas aportan o se benefician m\u00e1s de los servicios educativos, orientando estrategias de fidelizaci\u00f3n y expansi\u00f3n.</li> <li>Monitoreo de Indicadores Clave: El listado de m\u00e9tricas permite evaluar afiliados, aportes, subsidios y otros aspectos relevantes para la gesti\u00f3n social y comunitaria.</li> <li>Priorizaci\u00f3n de Relaciones Estrat\u00e9gicas: El an\u00e1lisis visual ayuda a enfocar recursos y esfuerzos en las empresas con mayor impacto o potencial de crecimiento.</li> <li>Transparencia y Rendici\u00f3n de Cuentas: Centraliza la informaci\u00f3n de impacto por empresa, respaldando reportes a la direcci\u00f3n y a las partes interesadas.</li> <li>Interactividad Anal\u00edtica: Los filtros y la selecci\u00f3n de indicadores ofrecen flexibilidad para profundizar en periodos, unidades o empresas espec\u00edficas, generando diagn\u00f3sticos detallados.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-empresa-relacion-de-servicios-y-aportes","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por\u202fEmpresa (Relaci\u00f3n de Servicios y\u202fAportes)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_21","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Mostrar la correspondencia entre los servicios educativos adquiridos por cada empresa y los aportes econ\u00f3micos realizados, permitiendo identificar el grado de involucramiento y retorno social de las organizaciones vinculadas al proceso de Educaci\u00f3n.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_22","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis por Empresa con tres opciones: Indicadores por empresa, Relaci\u00f3n de servicios y aportes (seleccionado) y Servicios vendidos y Subsidios hist\u00f3ricos. Incluye una breve explicaci\u00f3n y un aviso sobre datos de muestra. Tarjetas KPI Superiores Tarjetas que aportan contexto institucional (empresas afiliadas, afiliados, beneficiarios, empresas atendidas, afiliados atendidos, beneficiarios atendidos) antes de profundizar en la relaci\u00f3n servicios\u2011aportes. Tabla \u201cRelaci\u00f3n de Servicios y Aportes\u201d Tabla central que lista cada empresa, n\u00famero de servicios vendidos, porcentaje de participaci\u00f3n, valor de aportes totales y valor de aportes destinados a educaci\u00f3n, adem\u00e1s del porcentaje que esto representa sobre el total de aportes. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo para interpretar correctamente los valores de servicios y aportes. Pie de P\u00e1gina Franja inferior con la referencia temporal del an\u00e1lisis y l\u00edneas de color corporativo que garantizan la coherencia visual con los dem\u00e1s tableros."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_22","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>An\u00e1lisis de Contribuci\u00f3n vs. Beneficio: Permite comparar el valor de los aportes realizados por cada empresa con los servicios educativos adquiridos, evaluando el equilibrio entre inversi\u00f3n y retorno social.</li> <li>Detecci\u00f3n de Oportunidades de Alianza: La tabla facilita identificar organizaciones con alto potencial de crecimiento en servicios o que requieren estrategias de fidelizaci\u00f3n.</li> <li>Priorizaci\u00f3n de Recursos Comerciales: Conocer qu\u00e9 empresas concentran mayor porcentaje de aportes ayuda a focalizar esfuerzos de acompa\u00f1amiento y fortalecimiento institucional.</li> <li>Transparencia Financiera y Social: Centraliza la informaci\u00f3n de aportes y servicios, respaldando procesos de rendici\u00f3n de cuentas y planeaci\u00f3n estrat\u00e9gica.</li> <li>Interactividad Anal\u00edtica: Los filtros permiten segmentar la informaci\u00f3n por periodo, unidad o raz\u00f3n social, ofreciendo flexibilidad para diagn\u00f3sticos espec\u00edficos y reportes comparativos.</li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-empresa-servicios-vendidos-y-subsidios-historicos","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por\u202fEmpresa (Servicios\u202fVendidos y\u202fSubsidios\u202fHist\u00f3ricos)","text":""},{"location":"05.Power_BI/01.Dashboard/#objetivo-de-la-visualizacion_22","title":"Objetivo de la Visualizaci\u00f3n","text":"<p>Mostrar la evoluci\u00f3n temporal de los servicios educativos vendidos a las empresas y el historial de subsidios otorgados (cantidad y valor), permitiendo evaluar tendencias de demanda, cuantificar el apoyo econ\u00f3mico brindado y detectar oportunidades para optimizar la relaci\u00f3n entre la organizaci\u00f3n y el sector productivo.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_23","title":"Estructura y Elementos Principales","text":"Secci\u00f3n Descripci\u00f3n Panel Lateral Izquierdo Men\u00fa An\u00e1lisis por Empresa con tres opciones: Indicadores por empresa, Relaci\u00f3n de servicios y aportes y Servicios vendidos y Subsidios hist\u00f3ricos (seleccionada). Incluye un breve texto explicativo y un aviso de datos de muestra. Tarjetas KPI Superiores Tarjetas que brindan contexto institucional (empresas afiliadas, afiliados, beneficiarios, empresas atendidas, afiliados atendidos, beneficiarios atendidos) para enmarcar el an\u00e1lisis hist\u00f3rico. Bloque \u201cServicios vendidos y subsidios hist\u00f3ricos\u201d Contenedor central subdividido en tres tarjetas\u2011gr\u00e1fico: Servicios Vendidos, Cantidad Subsidio a la Demanda y Valor Subsidio a la Demanda. Cada una muestra la evoluci\u00f3n temporal en forma de barras, permitiendo comparar picos y valles de demanda o subsidio. Icono de Informaci\u00f3n Bot\u00f3n contextual que despliega definiciones y criterios de c\u00e1lculo de los indicadores hist\u00f3ricos y las unidades monetarias empleadas. Pie de P\u00e1gina Franja inferior con el periodo de an\u00e1lisis y l\u00edneas de color corporativo, manteniendo coherencia visual con las dem\u00e1s vistas."},{"location":"05.Power_BI/01.Dashboard/#beneficios-para-la-gestion_23","title":"Beneficios para la Gesti\u00f3n","text":"<ul> <li>An\u00e1lisis de Tendencias de Demanda: Visualiza c\u00f3mo var\u00eda la compra de servicios por parte de las empresas, apoyando la planificaci\u00f3n de la oferta y las estrategias comerciales.</li> <li>Seguimiento del Apoyo Econ\u00f3mico: Permite evaluar la cantidad y el valor de los subsidios otorgados a lo largo del tiempo, asegurando la transparencia y optimizaci\u00f3n de los recursos.</li> <li>Evaluaci\u00f3n de la Relaci\u00f3n Empresa\u2011Organizaci\u00f3n: Facilita identificar empresas con mayor recurrencia en compras o subsidios, orientando programas de fidelizaci\u00f3n o expansi\u00f3n de convenios.</li> <li>Priorizaci\u00f3n de Recursos: La informaci\u00f3n hist\u00f3rica respalda decisiones sobre asignaci\u00f3n de presupuesto y esfuerzo comercial hacia periodos o sectores con mayor demanda potencial.</li> <li>Interactividad Anal\u00edtica: Los filtros din\u00e1micos ofrecen flexibilidad para segmentar datos por periodo, unidad o raz\u00f3n social, generando diagn\u00f3sticos precisos y reportes comparativos.</li> </ul>"}]}