{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"INTRODUCCI\u00d3N","text":"<p>El proyecto general de Comfenalco tiene como objetivo principal optimizar y estructurar la gesti\u00f3n de datos de la organizaci\u00f3n para facilitar la toma de decisiones informadas y estrat\u00e9gicas. A trav\u00e9s de un enfoque integral, el proyecto abarca diferentes \u00e1reas clave como educaci\u00f3n, protecci\u00f3n social, programas transversales y servicios administrativos, consolidando la informaci\u00f3n en una plataforma robusta y escalable.</p> <p>Este esfuerzo tiene como base la implementaci\u00f3n de un Data Warehouse (DWH) centralizado, el cual adopta un modelo dimensional para garantizar la eficiencia en el acceso y an\u00e1lisis de datos. Adem\u00e1s, se dise\u00f1an e implementan procesos de Extracci\u00f3n, Transformaci\u00f3n y Carga (ETL) que permiten integrar y normalizar la informaci\u00f3n proveniente de diversas fuentes operativas, asegurando su calidad y relevancia para las \u00e1reas funcionales.</p>"},{"location":"#objetivos-del-proyecto","title":"Objetivos del Proyecto","text":"<p>Objetivo General:</p> <ul> <li>Desarrollar una soluci\u00f3n tecnol\u00f3gica que permite la consolidaci\u00f3n, an\u00e1lisis y explotaci\u00f3n eficiente de los datos organizacionales para apoyar la planeaci\u00f3n estrat\u00e9gica y operativa de Comfenalco.</li> </ul> <p>Objetivos Espec\u00edficos:</p> <ol> <li>Centralizar la informaci\u00f3n de m\u00faltiples \u00e1reas en un sistema \u00fanico, garantizando la consistencia y accesibilidad de los datos.</li> <li>Dise\u00f1ar modelos de datos modulares que permiten an\u00e1lisis por dimensiones espec\u00edficas como tiempo, poblaci\u00f3n, servicios, y programas acad\u00e9micos.</li> <li>Implementar mecanismos que aseguran la integridad, seguridad y calidad de los datos procesados.</li> <li>Proveer herramientas y reportes anal\u00edticos que facilitan la supervisi\u00f3n del desempe\u00f1o y la identificaci\u00f3n de oportunidades de mejora.</li> <li>Asegurar la escalabilidad del sistema para adaptarse a futuras necesidades de informaci\u00f3n y m\u00f3dulos adicionales.</li> </ol>"},{"location":"#alcance","title":"Alcance","text":"<p>El proyecto abarca la optimizaci\u00f3n y mejora de los procesos de gesti\u00f3n de datos en \u00e1reas como:</p> <ul> <li>Educaci\u00f3n Formal y Continua: Incluyendo informaci\u00f3n sobre estudiantes, docentes, matr\u00edculas, y desempe\u00f1o acad\u00e9mico.</li> <li>Protecci\u00f3n Social: Gesti\u00f3n de poblaciones vulnerables, programas de cobertura y caracterizaci\u00f3n.</li> <li>Programas Transversales: Datos sobre servicios administrativos, financieros y operativos.</li> <li>Gesti\u00f3n de Recursos: Informaci\u00f3n de bibliotecas, transporte, y servicios auxiliares.</li> </ul> <p>La implementaci\u00f3n del DWH est\u00e1 respaldada por \u00edndices optimizados y esquemas de modelado que permiten consultas eficientes, integraciones directas con plataformas de an\u00e1lisis y reportes avanzados.</p>"},{"location":"#impacto-esperado","title":"Impacto Esperado","text":"<p>Con este proyecto, Comfenalco cuenta con una herramienta centralizada para la gesti\u00f3n y an\u00e1lisis de datos que proporciona:</p> <ul> <li>Mayor eficiencia operativa al reducir redundancias y tiempos de procesamiento.</li> <li>Toma de decisiones basada en datos con acceso r\u00e1pido a informaci\u00f3n consolidada.</li> <li>Cumplimiento normativo y de calidad gracias a procesos de auditor\u00eda y normalizaci\u00f3n.</li> <li>Escalabilidad tecnol\u00f3gica para abordar retos futuros.</li> </ul> <p>Se generan tres diagramas que integran todo el proyecto con el fin de proporcionar una visi\u00f3n clara y estructurada:</p> <ol> <li>Diagrama de flujo de datos: Representa c\u00f3mo se organizan e integran los datos desde sus fuentes hasta el Data Warehouse (DWH).</li> <li>Diagrama entidad-relaci\u00f3n: Muestra las relaciones entre las tablas principales del modelo de datos, incluyendo dimensiones y hechos.</li> <li>Diagrama de secuencia: Describe el proceso de ETL desde la extracci\u00f3n de datos hasta su carga en el DWH.</li> </ol>"},{"location":"#diagramas","title":"Diagramas","text":""},{"location":"#diagrama-1-flujo-de-datos","title":"Diagrama 1: Flujo de Datos","text":"<pre><code>graph TD\n    A(Fuentes de Datos) --&gt; B(Extracci\u00f3n)\n    B --&gt; C(Transformaci\u00f3n)\n    C --&gt; D(Carga en el Data Warehouse)\n    D --&gt; E(M\u00f3dulos Espec\u00edficos)\n    E --&gt; F(An\u00e1lisis y Reportes)\n    E --&gt; G(Integraci\u00f3n con Plataformas)\n    F --&gt; H(Toma de Decisiones Estrat\u00e9gicas)</code></pre>"},{"location":"#diagrama-2-entidad-relacion","title":"Diagrama 2: Entidad-Relaci\u00f3n","text":"<pre><code>erDiagram\n    DIM_TIEMPO {\n        int ID_FECHA PK\n        datetime FECHA\n        varchar DIA_SEMANA\n        varchar MES\n        int ANIO\n    }\n\n    DIM_ESTUDIANTES {\n        int ID_ESTUDIANTE PK\n        varchar NOMBRE\n        varchar DOCUMENTO\n        int ID_PROGRAMA FK\n    }\n\n    DIM_PROGRAMA {\n        int ID_PROGRAMA PK\n        varchar NOMBRE_PROGRAMA\n    }\n\n    FACT_MATRICULAS {\n        int ID_MATRICULA PK\n        int ID_ESTUDIANTE FK\n        int ID_FECHA FK\n        int ID_PROGRAMA FK\n        decimal COSTO\n    }\n\n    DIM_TIEMPO ||--o{ FACT_MATRICULAS : \"ID_FECHA\"\n    DIM_ESTUDIANTES ||--o{ FACT_MATRICULAS : \"ID_ESTUDIANTE\"\n    DIM_PROGRAMA ||--o{ FACT_MATRICULAS : \"ID_PROGRAMA\"</code></pre>"},{"location":"#diagrama-3-secuencia-del-proceso-etl","title":"Diagrama 3: Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    participant Fuente as Fuentes de Datos\n    participant ETL as Proceso ETL\n    participant DWH as Data Warehouse\n    participant Usuario as Usuario Final\n\n    Fuente -&gt;&gt; ETL: Proveer datos crudos\n    ETL -&gt;&gt; ETL: Limpiar y transformar datos\n    ETL -&gt;&gt; DWH: Cargar datos transformados\n    DWH -&gt;&gt; Usuario: Proveer reportes y an\u00e1lisis\n    Usuario -&gt;&gt; DWH: Consultar datos espec\u00edficos</code></pre>"},{"location":"Conexiones_BD/","title":"CONEXI\u00d3N A BASE DE DATOS","text":""},{"location":"Conexiones_BD/#documentacion-para-conexion-a-bases-de-datos-comfenalco","title":"Documentaci\u00f3n para Conexi\u00f3n a Bases de Datos Comfenalco","text":"<p>Este apartado detalla los pasos y configuraciones necesarias para acceder a las distintas fuentes de datos utilizadas en el proyecto de Comfenalco, incluyendo DWH, Q10 y C4C. </p>"},{"location":"Conexiones_BD/#requisitos-previos","title":"Requisitos Previos","text":""},{"location":"Conexiones_BD/#instalacion-y-configuracion-de-vpn","title":"Instalaci\u00f3n y Configuraci\u00f3n de VPN","text":"<ol> <li>Descargue e instale FortiClient VPN.</li> <li>Configure la conexi\u00f3n VPN de acuerdo con las instrucciones de la imagen.  </li> <li>Use las siguientes credenciales:<ul> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxxxxx</code></li> </ul> </li> </ol>"},{"location":"Conexiones_BD/#acceso-a-las-fuentes-de-datos","title":"Acceso a las Fuentes de Datos","text":""},{"location":"Conexiones_BD/#1-data-warehouse-dwh","title":"1. Data Warehouse (DWH)","text":"<ul> <li>Requisitos: Es necesario estar conectado a la VPN.</li> <li>Acceso:<ul> <li>Use SQL Server Management Studio 20 (versi\u00f3n 20.1.10.0 o posterior).</li> <li>Configure la conexi\u00f3n utilizando las instrucciones del archivo <code>\"02.ConfiguracionDWH\"</code>.</li> </ul> </li> <li>Credenciales:<ul> <li>Use las mismas credenciales configuradas para la VPN.</li> </ul> </li> </ul>"},{"location":"Conexiones_BD/#2-q10","title":"2. Q10","text":"<p>El acceso a Q10 no requiere conexi\u00f3n VPN. Siga las instrucciones seg\u00fan el portal espec\u00edfico:</p> <ul> <li> <p>Q10 Cedesarrollo:</p> <ul> <li>URL: https://site.q10.com/login?ReturnUrl=%2F&amp;aplentId=8fa60f3a-1a89-4048-a798-afd5cda72549</li> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxxxxxxx</code></li> </ul> </li> <li> <p>Q10 Desarrollo Empresarial:</p> <ul> <li>URL: https://site.q10.com/login?ReturnUrl=%2F&amp;aplentId=da5db6b7-bead-4cee-b8d0-6503733312d6</li> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxx</code></li> </ul> </li> </ul>"},{"location":"Conexiones_BD/#3-c4c","title":"3. C4C","text":"<ul> <li>Requisitos: Se requiere conexi\u00f3n previa a la VPN para acceder.</li> <li> <p>Acceso:</p> <ul> <li>Ingrese con las siguientes credenciales:</li> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxxx</code></li> <li>URL: https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime</li> </ul> </li> </ul>"},{"location":"Conexiones_BD/#notas-importantes","title":"Notas Importantes","text":"<ul> <li> <p>Licencias</p> <ul> <li><code>Q10</code> requiere licencia para el m\u00f3dulo de <code>cedesarrollo</code> y otra licencia para el m\u00f3dulo <code>desarrollo empresarial</code></li> <li><code>C4C</code> requiere licencia vinculada a <code>SAP</code> </li> </ul> </li> <li> <p>VPN:</p> <ul> <li>La conexi\u00f3n VPN es esencial para el acceso a DWH y C4C, pero no se requiere para Q10.</li> <li>Aseg\u00farese de mantener la VPN activa durante toda la sesi\u00f3n de trabajo.</li> </ul> </li> <li> <p>Seguridad:</p> <ul> <li>Evite compartir las credenciales de acceso.</li> <li>Cierre la sesi\u00f3n despu\u00e9s de utilizar las plataformas.</li> </ul> </li> <li> <p>Soporte:</p> <ul> <li>Para problemas de conexi\u00f3n o configuraci\u00f3n, comun\u00edquese con el equipo de TI o consulte los videos de referencia en los documentos de configuraci\u00f3n.</li> </ul> </li> </ul> <p>Esta gu\u00eda asegura un acceso seguro y estructurado a las fuentes de datos clave del proyecto.</p>"},{"location":"about/","title":"Acerca de este proyecto","text":"<p>Este proyecto tiene como objetivo proporcionar una soluci\u00f3n eficiente y f\u00e1cil de usar para [describir el prop\u00f3sito del proyecto]. </p>"},{"location":"about/#proposito","title":"Prop\u00f3sito","text":"<p>El prop\u00f3sito de este proyecto es [especificar el prop\u00f3sito del proyecto, por ejemplo, facilitar la edici\u00f3n de documentos, mejorar la colaboraci\u00f3n, etc.].</p>"},{"location":"about/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>Caracter\u00edstica 1: [Descripci\u00f3n de la caracter\u00edstica 1]</li> <li>Caracter\u00edstica 2: [Descripci\u00f3n de la caracter\u00edstica 2]</li> <li>Caracter\u00edstica 3: [Descripci\u00f3n de la caracter\u00edstica 3]</li> </ul>"},{"location":"about/#detalles-relevantes","title":"Detalles relevantes","text":"<p>Para m\u00e1s informaci\u00f3n sobre c\u00f3mo contribuir o utilizar este proyecto, consulte la documentaci\u00f3n en [enlace a la documentaci\u00f3n o repositorio].</p>"},{"location":"buenaspracticas/","title":"Buenas Pr\u00e1cticas Implementadas en el Proyecto Comfenalco","text":""},{"location":"buenaspracticas/#buenas-practicas-implementadas-en-el-proyecto-comfenalco","title":"Buenas Pr\u00e1cticas Implementadas en el Proyecto Comfenalco","text":"<p>El proyecto Comfenalco adopta una serie de buenas pr\u00e1cticas para garantizar la eficiencia, escalabilidad, calidad y mantenibilidad de los procesos y el Data Warehouse (DWH). A continuaci\u00f3n, se destacan las principales buenas pr\u00e1cticas identificadas y aplicadas en el proyecto, con el an\u00e1lisis adicional del archivo <code>Funciones.py</code>.</p>"},{"location":"buenaspracticas/#1-modelado-dimensional","title":"1. Modelado Dimensional","text":"<p>Descripci\u00f3n: El uso de un modelo dimensional permite organizar los datos en tablas de dimensiones y hechos, optimizando las consultas y an\u00e1lisis. Esto asegura un dise\u00f1o eficiente y escalable.</p> <p>Ejemplos: - Tablas <code>DIM_TIEMPO</code>, <code>DIM_ESTUDIANTES</code> y <code>FACT_NOTAS</code> para an\u00e1lisis temporal y acad\u00e9mico. - Separaci\u00f3n clara entre datos descriptivos (dimensiones) y m\u00e9tricas (hechos), como en los m\u00f3dulos <code>Cedesarrollo</code>, <code>Protecci\u00f3n</code> y <code>Colegio</code>.</p> <p>Beneficios: - Eficiencia en las consultas. - Flexibilidad para agregar nuevas dimensiones y hechos.</p>"},{"location":"buenaspracticas/#2-integridad-referencial","title":"2. Integridad Referencial","text":"<p>Descripci\u00f3n: El uso de claves primarias y for\u00e1neas en todas las relaciones asegura la consistencia de los datos entre tablas.</p> <p>Ejemplos: - Relaciones entre <code>DIM_ESTUDIANTES</code>, <code>DIM_PROGRAMA</code> y <code>FACT_MATRICULAS</code>. - Implementaci\u00f3n de restricciones <code>FOREIGN KEY</code> en m\u00f3dulos como <code>Transversal</code> y <code>Cedesarrollo</code>.</p> <p>Beneficios: - Evita inconsistencias y errores en los datos. - Garantiza la coherencia de las relaciones.</p>"},{"location":"buenaspracticas/#3-automatizacion-y-modularidad-en-el-etl","title":"3. Automatizaci\u00f3n y Modularidad en el ETL","text":"<p>Descripci\u00f3n: El proyecto utiliza un flujo ETL modular y automatizado para facilitar la extracci\u00f3n, transformaci\u00f3n y carga de datos.</p> <p>Ejemplos: - Uso de decoradores para registrar eventos y tiempos en funciones clave como <code>process_files_from_folder</code>. - Dise\u00f1o modular mediante funciones espec\u00edficas como <code>guardar_en_dwh</code>, <code>obtener_conexion</code> y <code>limpiar_html</code>.</p> <p>Beneficios: - Reutilizaci\u00f3n de c\u00f3digo. - Facilidad para realizar ajustes y escalabilidad.</p>"},{"location":"buenaspracticas/#4-gestion-de-credenciales-segura","title":"4. Gesti\u00f3n de Credenciales Segura","text":"<p>Descripci\u00f3n: Las credenciales se gestionan de forma centralizada y segura mediante archivos de configuraci\u00f3n externos y bibliotecas como <code>configparser</code>.</p> <p>Ejemplos: - Funci\u00f3n <code>credenciales</code> para obtener credenciales de plataformas espec\u00edficas. - Uso de archivos <code>.env</code> para almacenar credenciales sensibles.</p> <p>Beneficios: - Mejora la seguridad al evitar exposici\u00f3n directa de credenciales en el c\u00f3digo. - Facilita la configuraci\u00f3n de m\u00faltiples entornos.</p>"},{"location":"buenaspracticas/#5-registro-detallado-con-logging","title":"5. Registro Detallado con Logging","text":"<p>Descripci\u00f3n: El uso del m\u00f3dulo <code>logging</code> asegura el registro detallado de eventos, errores y tiempos de procesamiento.</p> <p>Ejemplos: - Decorador <code>log_step_decorator</code> para registrar el inicio, finalizaci\u00f3n y duraci\u00f3n de procesos. - Configuraci\u00f3n de logs personalizados para registrar eventos a nivel de consola y archivo.</p> <p>Beneficios: - Facilita la depuraci\u00f3n y el monitoreo de procesos. - Proporciona trazabilidad completa de las operaciones realizadas.</p>"},{"location":"buenaspracticas/#6-gestion-de-archivos-automatizada","title":"6. Gesti\u00f3n de Archivos Automatizada","text":"<p>Descripci\u00f3n: El proyecto incluye funciones avanzadas para procesar, descargar, renombrar y cargar archivos de forma automatizada.</p> <p>Ejemplos: - Funci\u00f3n <code>process_files_from_folder</code> para procesar archivos en una carpeta espec\u00edfica. - <code>upload_file_to_sharepoint</code> para subir archivos autom\u00e1ticamente a SharePoint.</p> <p>Beneficios: - Ahorro de tiempo y reducci\u00f3n de errores manuales. - Consistencia en la gesti\u00f3n de archivos.</p>"},{"location":"buenaspracticas/#7-limpieza-y-normalizacion-de-datos","title":"7. Limpieza y Normalizaci\u00f3n de Datos","text":"<p>Descripci\u00f3n: Se asegura la calidad de los datos mediante funciones dedicadas a la limpieza y estandarizaci\u00f3n.</p> <p>Ejemplos: - <code>limpiar_columnas</code> para eliminar columnas innecesarias y renombrar columnas clave. - <code>replace_values_df</code> para reemplazar valores basados en un diccionario.</p> <p>Beneficios: - Datos m\u00e1s precisos y consistentes. - Menor riesgo de errores en an\u00e1lisis y reportes.</p>"},{"location":"buenaspracticas/#8-escalabilidad-y-modularidad","title":"8. Escalabilidad y Modularidad","text":"<p>Descripci\u00f3n: El dise\u00f1o modular permite incorporar nuevas funciones sin afectar el flujo existente.</p> <p>Ejemplos: - Funciones espec\u00edficas para operaciones como <code>procesar_excel_con_hojas</code>, <code>Combine_and_store</code>, y <code>setup_driver</code>. - Uso de decoradores para extender la funcionalidad sin alterar el c\u00f3digo base.</p> <p>Beneficios: - Reducci\u00f3n de tiempos de implementaci\u00f3n para nuevos requerimientos. - Facilita el mantenimiento y la expansi\u00f3n del sistema.</p>"},{"location":"buenaspracticas/#9-buenas-practicas-de-programacion-en-python","title":"9. Buenas Pr\u00e1cticas de Programaci\u00f3n en Python","text":"<p>Descripci\u00f3n: El c\u00f3digo sigue las buenas pr\u00e1cticas de Python, como modularidad, uso de decoradores, y manejo seguro de excepciones.</p> <p>Ejemplos: - Decoradores como <code>log_step_decorator</code> para mejorar la legibilidad y reutilizaci\u00f3n del c\u00f3digo. - Manejo robusto de excepciones en funciones cr\u00edticas como <code>procesar</code>, <code>descargar_archivos</code> y <code>setup_logger</code>.</p> <p>Beneficios: - Mejora la mantenibilidad del c\u00f3digo. - Reduce errores inesperados durante la ejecuci\u00f3n.</p>"},{"location":"buenaspracticas/#10-uso-de-selenium-para-automatizacion-de-navegacion-web","title":"10. Uso de Selenium para Automatizaci\u00f3n de Navegaci\u00f3n Web","text":"<p>Descripci\u00f3n: Se utiliza Selenium para realizar automatizaci\u00f3n avanzada de navegaci\u00f3n web y manipulaci\u00f3n de interfaces web.</p> <p>Ejemplos: - Funci\u00f3n <code>setup_driver</code> para configurar un entorno de Selenium optimizado. - Operaciones complejas en men\u00fas desplegables y modales mediante funciones como <code>seleccionar_opcion_custom_dropdown</code>.</p> <p>Beneficios: - Automatizaci\u00f3n de tareas repetitivas. - Mayor precisi\u00f3n en la interacci\u00f3n con plataformas web.</p>"},{"location":"buenaspracticas/#11-control-de-versiones-en-descargas","title":"11. Control de Versiones en Descargas","text":"<p>Descripci\u00f3n: Las descargas y sus versiones se manejan de manera efectiva para evitar conflictos de nombres y redundancias.</p> <p>Ejemplos: - Uso de <code>corregir_nombre_archivo</code> para generar nombres \u00fanicos y manejables. - Verificaci\u00f3n de archivos existentes antes de sobrescribir.</p> <p>Beneficios: - Evita p\u00e9rdida de datos por sobrescritura accidental. - Proporciona una estructura clara para las versiones de archivos.</p>"},{"location":"buenaspracticas/#12-facilidad-para-actualizar-credenciales-de-sharepoint","title":"12. Facilidad para Actualizar Credenciales de SharePoint","text":"<p>Descripci\u00f3n: El proyecto Comfenalco incluye una implementaci\u00f3n que permite cambiar las credenciales de SharePoint de manera centralizada y sencilla sin necesidad de modificar el c\u00f3digo fuente del proyecto. Esto se logra utilizando un archivo de configuraci\u00f3n (<code>credenciales.env</code>) para almacenar las credenciales de manera externa.</p> <p>Ejemplo de Implementaci\u00f3n:</p> <ol> <li> <p>Gesti\u00f3n Centralizada de Credenciales:     Las credenciales de SharePoint se almacenan en un archivo llamado <code>credenciales.env</code> ubicado en el directorio del proyecto:</p> <pre><code>client_id = \"nuevo_client_id\"\ncert_thumbprint = \"nueva_cert_thumbprint\"\ntenant_id = \"nuevo_tenant_id\"\nscopes_sharepoint_online = \"https://new.scope.url/.default\"\nsharepoint_base_url = \"https://new.sharepoint.url\"\n</code></pre> </li> <li> <p>Carga Din\u00e1mica de Credenciales:     En el c\u00f3digo, la funci\u00f3n <code>credenciales</code> se encarga de leer este archivo y devolver las credenciales necesarias para conectarse a SharePoint:</p> <pre><code>def credenciales():\n    original_dir = os.getcwd()\n    try:\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        os.chdir(script_dir)\n\n        # Leer las credenciales desde el archivo credenciales.env\n        with open('credenciales.env', 'r') as key_file:\n            lines = key_file.readlines()\n\n        keys = {}\n        for line in lines:\n            key, value = line.strip().split(\" = \")\n            keys[key] = value.strip('\"')\n\n        return keys\n    finally:\n        os.chdir(original_dir)\n</code></pre> </li> <li> <p>Uso en el Proyecto:     Las credenciales cargadas din\u00e1micamente se utilizan para configurar la conexi\u00f3n a SharePoint sin necesidad de modificaciones adicionales en el proyecto:</p> <pre><code>keys = credenciales()\n\nmsal_app = ConfidentialClientApplication(\n    client_id=keys.get(\"client_id\"),\n    authority=f\"https://login.microsoftonline.com/{keys.get('tenant_id')}\",\n    client_credential={\n        \"private_key\": open('key.pem').read(),\n        \"thumbprint\": keys.get(\"cert_thumbprint\")\n    },\n)\n\nheaders = {\n    \"Authorization\": f\"Bearer {msal_app.acquire_token_for_client([keys.get('scopes_sharepoint_online')])['access_token']}\",\n    \"Accept\": \"application/json;odata=verbose\",\n    \"Content-Type\": \"application/json\",\n}\n</code></pre> </li> <li> <p>Cambio de Credenciales en Tiempo de Ejecuci\u00f3n:     Para actualizar las credenciales, solo se necesita modificar el archivo <code>credenciales.env</code> con los nuevos valores. No es necesario cambiar el c\u00f3digo ni reiniciar el proyecto.</p> </li> </ol> <p>Ventajas:</p> <ul> <li>Centralizaci\u00f3n: Permite un \u00fanico punto de administraci\u00f3n de credenciales.</li> <li>Seguridad: Mantiene las credenciales fuera del c\u00f3digo fuente, reduciendo riesgos de exposici\u00f3n.</li> <li>Flexibilidad: Facilita actualizaciones r\u00e1pidas en entornos de desarrollo, pruebas y producci\u00f3n.</li> <li>Escalabilidad: Compatible con m\u00faltiples entornos sin necesidad de cambios en el c\u00f3digo.</li> </ul>"},{"location":"buenaspracticas/#conclusion","title":"Conclusi\u00f3n","text":"<p>Las pr\u00e1cticas implementadas en el proyecto Comfenalco no solo garantizan la eficiencia y la escalabilidad t\u00e9cnica, sino que tambi\u00e9n aseguran la calidad y la seguridad de los procesos. Este enfoque integral establece una base s\u00f3lida para la sostenibilidad y expansi\u00f3n del sistema.</p>"},{"location":"instalacion/","title":"INSTALACI\u00d3N Y CONFIGURACI\u00d3N","text":""},{"location":"instalacion/#instalacion-y-configuracion-del-entorno-para-el-proyecto-comfenalco","title":"Instalaci\u00f3n y Configuraci\u00f3n del Entorno para el Proyecto Comfenalco","text":"<p>Este apartado detalla los pasos necesarios para configurar un entorno funcional que permita la implementaci\u00f3n y ejecuci\u00f3n de los procesos de carga, transformaci\u00f3n y an\u00e1lisis de datos utilizados en el proyecto de Comfenalco. El objetivo principal es garantizar una instalaci\u00f3n uniforme de herramientas y dependencias, configurar correctamente las conexiones a las bases de datos y estructurar el entorno para el \u00f3ptimo funcionamiento del Data Warehouse (DWH).</p>"},{"location":"instalacion/#pasos-para-la-configuracion-del-entorno","title":"Pasos para la Configuraci\u00f3n del Entorno","text":""},{"location":"instalacion/#1-instalacion-de-herramientas-necesarias","title":"1. Instalaci\u00f3n de Herramientas Necesarias","text":""},{"location":"instalacion/#versionamiento-de-herramientas","title":"Versionamiento de Herramientas","text":"<p>Los paquetes ETL del proyecto Comfenalco se desarrollaron originalmente utilizando Visual Studio Community 2022, seg\u00fan las definiciones establecidas en la fase 1 del proyecto. Posteriormente, en la entrega del proyecto, Comfenalco degrada a la versi\u00f3n Visual Studio Professional 2019 para garantizar compatibilidad con los est\u00e1ndares de la organizaci\u00f3n.</p> <p>Entre el 14 y el 17 de enero de 2025, se llevaron a cabo mesas de trabajo conjuntas con el equipo de Comfenalco. Durante estas sesiones, se validaron los paquetes y se realiz\u00f3 la migraci\u00f3n al servidor de pruebas, asegurando el correcto funcionamiento en el entorno de la organizaci\u00f3n. </p>"},{"location":"instalacion/#11-sql-server-management-studio-ssms","title":"1.1 SQL Server Management Studio (SSMS)","text":"<p>Requisitos:</p> <ul> <li>Versi\u00f3n 20.1.10.0 o posterior.</li> <li>Disponible en el siguiente enlace: Descargar SSMS.</li> </ul>"},{"location":"instalacion/#12-visual-studio","title":"1.2 Visual Studio","text":"<p>Versi\u00f3n:</p> <ul> <li>Comfenalco utiliza Visual Studio Profesional 2019 (paga).</li> <li>Para desarrollo, se utiliza Visual Studio Community 2022 (gratuita), versi\u00f3n 17.11.5.</li> <li>Disponible en el siguiente enlace: Descargar Visual Studio Community.</li> </ul>"},{"location":"instalacion/#13-integration-services-ssis","title":"1.3 Integration Services (SSIS)","text":"<p>Pasos de Instalaci\u00f3n:</p> <ol> <li>Crear un proyecto en blanco en Visual Studio.</li> <li>Ir a la pesta\u00f1a Extensiones \u2192 Administrar Extensiones.</li> <li>Buscar Integration Services e instalar la versi\u00f3n 1.3.2 (compatibilidad con Visual Studio 17.11.5).</li> </ol>"},{"location":"instalacion/#14-analysis-services-ssas","title":"1.4 Analysis Services (SSAS)","text":"<p>Pasos de Instalaci\u00f3n:</p> <ol> <li>Crear un proyecto en blanco en Visual Studio.</li> <li>Ir a la pesta\u00f1a Extensiones \u2192 Administrar Extensiones.</li> <li>Buscar Analysis Services e instalar la versi\u00f3n m\u00e1s reciente.</li> <li>Validar que no presente problemas de compatibilidad.</li> </ol>"},{"location":"instalacion/#recomendaciones","title":"Recomendaciones:","text":"<p>Se recomienda dejar las mismas estructuras. La actualizaci\u00f3n de datos de consultas y web scraping es autom\u00e1tica. Y la de archivos corresponde a los propietarios de la informaci\u00f3n.</p>"},{"location":"instalacion/#2-creacion-del-entorno-virtual","title":"2. Creaci\u00f3n del Entorno Virtual","text":"<p>Un entorno virtual permite organizar y aislar las dependencias necesarias para este proyecto. Siga estos pasos:</p> <p>1. Cree un entorno virtual ejecutando el siguiente comando:</p> <pre><code>python -m venv comfenalco_env\n</code></pre> <p>2. Active el entorno virtual:</p> <p>En Windows:</p> <pre><code>comfenalco_env\\Scripts\\activate\n</code></pre> <p>En Linux/macOS:</p> <pre><code>source comfenalco_env/bin/activate\n</code></pre>"},{"location":"instalacion/#3-instalacion-de-dependencias","title":"3. Instalaci\u00f3n de Dependencias","text":"<p>Una vez activado el entorno virtual, instale las librer\u00edas necesarias:</p> <pre><code>pip install sqlalchemy pandas beautifulsoup4 numpy logging python-dateutil concurrent.futures\n</code></pre>"},{"location":"instalacion/#configuracion-inicial-del-proyecto","title":"Configuraci\u00f3n Inicial del Proyecto","text":""},{"location":"instalacion/#1-creacion-de-conexiones","title":"1. Creaci\u00f3n de Conexiones","text":"<p>1. Configuraci\u00f3n en SSIS:</p> <ul> <li>Use el administrador de conexiones ADO.NET.</li> <li>Cree las siguientes conexiones:<ul> <li><code>DWH_COMFENALCO</code></li> <li><code>STAGE_AREA</code></li> <li><code>SAP_ERP</code></li> </ul> </li> <li>Es importante tener activa la VPN al configurar las conexiones.</li> </ul> <p>2. Configuraci\u00f3n Local:</p> <ul> <li>Cree una base de datos local en SQL Server Management Studio llamada <code>DWH_COMFENALCO_local</code> para realizar pruebas.</li> <li>Cree una conexi\u00f3n a esta base local.</li> </ul> <p>3. Parametrizaci\u00f3n de Conexiones:</p> <ul> <li>Configure las variables <code>ConnectionString</code> y <code>Password</code> en el proyecto de SSIS para cada conexi\u00f3n.</li> <li>Consulte el siguiente video (minuto 11 en adelante).</li> </ul> <p>4. Referencia de Proyecto:</p> <ul> <li>Abra el proyecto de referencia disponible en: Proyecto SSIS.</li> </ul>"},{"location":"instalacion/#funciones-principales-del-proyecto","title":"Funciones Principales del Proyecto","text":""},{"location":"instalacion/#1-configuracion-del-logger","title":"1. Configuraci\u00f3n del Logger","text":"<p>Para garantizar un registro de eventos y errores, utilice la funci\u00f3n <code>setup_logger</code>:</p> <pre><code>from Funciones import setup_logger\nimport logging\n\nlogger = setup_logger(log_filename='etl.log', log_level=logging.INFO)\nlogger.info(\"Proceso de configuraci\u00f3n iniciado.\")\n</code></pre>"},{"location":"instalacion/#2-conexion-a-la-base-de-datos","title":"2. Conexi\u00f3n a la Base de Datos","text":"<p>Configure la conexi\u00f3n a las bases de datos con la funci\u00f3n <code>obtener_conexion</code> y el uso de SQLAlchemy:</p> <pre><code>from Funciones import obtener_conexion\nfrom sqlalchemy import create_engine\n\ncadena_conexion = obtener_conexion('nombre_base_datos')\nmotor = create_engine(cadena_conexion)\n</code></pre>"},{"location":"instalacion/#3-funciones-de-procesamiento","title":"3. Funciones de Procesamiento","text":""},{"location":"instalacion/#31-guardar_en_dwh","title":"3.1 <code>guardar_en_dwh</code>","text":"<ul> <li>Prop\u00f3sito: Guarda un <code>DataFrame</code> en una tabla espec\u00edfica del DWH.</li> <li>Uso:</li> </ul> <pre><code>from Funciones import guardar_en_dwh\n\nguardar_en_dwh(df, 'nombre_tabla', logger, multiple=False, if_exists='replace')\n</code></pre>"},{"location":"instalacion/#32-limpiar_html","title":"3.2 <code>limpiar_html</code>","text":"<ul> <li>Prop\u00f3sito: Limpia el contenido de texto con etiquetas HTML.</li> <li>Uso:</li> </ul> <pre><code>from Funciones import limpiar_html\n\ntexto_limpio = limpiar_html(\"&lt;p&gt;Ejemplo&lt;/p&gt;\")\nprint(texto_limpio)  # Salida: Ejemplo\n</code></pre>"},{"location":"instalacion/#33-storeduplicated","title":"3.3 <code>StoreDuplicated</code>","text":"<ul> <li>Prop\u00f3sito: Guarda registros duplicados para an\u00e1lisis posterior.</li> <li>Uso:</li> </ul> <pre><code>from Funciones import StoreDuplicated\n\nStoreDuplicated(\"duplicados.xlsx\", ['columna1', 'columna2'], df, './output')\n</code></pre>"},{"location":"instalacion/#creacion-del-cubo","title":"Creaci\u00f3n del Cubo","text":"<p>1. Configuraci\u00f3n del Cubo:</p> <ul> <li>Use Analysis Services para crear un cubo que contenga las medidas y KPIs necesarios.</li> <li>Incluya esquemas de datos de <code>Transversal</code>, <code>Colegio</code>, <code>Cedesarrollo</code> y <code>Protecci\u00f3n</code>.</li> </ul> <p>2. Poblaci\u00f3n de Tablas:</p> <ul> <li>Llene primero las tablas Dim y posteriormente las tablas Fact.</li> <li>Aseg\u00farese de que las tablas de DWH est\u00e9n vac\u00edas antes de iniciar el proceso de carga.</li> </ul> <p>3. Consumo en Power BI:</p> <ul> <li>Todas las medidas deben estar definidas en el cubo, ya que Power BI no permite la creaci\u00f3n de medidas en tiempo de consulta.</li> </ul> <p>4. Referencias:</p> <ul> <li>Creaci\u00f3n del Cubo 1.</li> <li>Creaci\u00f3n del Cubo 2.</li> </ul>"},{"location":"instalacion/#ejemplo-de-flujo-etl","title":"Ejemplo de Flujo ETL","text":"<pre><code>from Funciones import obtener_conexion, guardar_en_dwh, setup_logger\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\n# Configurar logger\nlogger = setup_logger(log_filename='etl_proceso.log', log_level=logging.INFO)\n\n# Conectar a la base de datos\ncadena_conexion = obtener_conexion('dwh_comfenalco')\nmotor = create_engine(cadena_conexion)\n\n# Leer datos de origen\ndf_origen = pd.read_sql_query(\"SELECT * FROM tabla_origen\", motor)\n\n# Transformaciones necesarias\ndf_origen['nueva_columna'] = df_origen['columna_existente'] * 2\n\n# Cargar datos transformados al DWH\nguardar_en_dwh(df_origen, 'tabla_destino', logger, multiple=False, if_exists='append')\n</code></pre>"},{"location":"instalacion/#conclusion","title":"Conclusi\u00f3n","text":"<p>Con estos pasos, el entorno estar\u00e1 listo para manejar los procesos ETL del proyecto Comfenalco. Al seguir este flujo, se asegura una configuraci\u00f3n consistente, se minimizan errores y se facilita la integraci\u00f3n de nuevos m\u00f3dulos o expansiones del DWH.</p>"},{"location":"00.etl/00.etl_00.Introduccion/","title":"Introducci\u00f3n","text":""},{"location":"00.etl/00.etl_00.Introduccion/#introduccion-a-los-procesos-etl-basados-en-webscraping-para-educacion-tecnica-y-continua","title":"Introducci\u00f3n a los Procesos ETL Basados en Webscraping para Educaci\u00f3n T\u00e9cnica y Continua","text":"<p>La Educaci\u00f3n T\u00e9cnica y Continua exige sistemas robustos y automatizados para gestionar la creciente cantidad de datos acad\u00e9micos y administrativos. Los procesos ETL (Extract, Transform, Load), fundamentados en t\u00e9cnicas avanzadas de webscraping, aseguran la extracci\u00f3n eficiente, la transformaci\u00f3n precisa y la carga estructurada de datos desde diversas fuentes en l\u00ednea. Este enfoque permite consolidar la informaci\u00f3n en tiempo real, optimizando la toma de decisiones y fomentando la colaboraci\u00f3n a trav\u00e9s de plataformas como SharePoint y C4C.</p>"},{"location":"00.etl/00.etl_00.Introduccion/#01-q10","title":"01. Q10","text":"<p>Los flujos ETL asociados a Q10 se dividen en Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua, cada uno dise\u00f1ado para garantizar la calidad, organizaci\u00f3n y accesibilidad de la informaci\u00f3n. La metodolog\u00eda de webscraping permite extraer datos en tiempo real de sistemas acad\u00e9micos, procesarlos autom\u00e1ticamente y presentarlos de manera estructurada.</p> <ul> <li> <p>Educaci\u00f3n T\u00e9cnica:</p> <ul> <li>Docentes Cedesarrollo: Automatiza la recopilaci\u00f3n de informaci\u00f3n docente para su integraci\u00f3n en sistemas acad\u00e9micos. Ver detalle</li> <li>Dise\u00f1o Curricular: Extrae datos de planes de estudio publicados en plataformas digitales. Ver detalle</li> <li>Listado Matr\u00edculas: Captura y procesa datos de matr\u00edculas de estudiantes desde fuentes en l\u00ednea. Ver detalle</li> <li>Ingresos: Estandariza y organiza datos financieros relacionados con estudiantes. Ver detalle</li> <li>Hist\u00f3rico Notas: Recupera y ordena registros de calificaciones hist\u00f3ricos. Ver detalle</li> <li>Egresados: Automatiza el registro y consolidaci\u00f3n de datos de graduados. Ver detalle</li> <li>Desertores: Identifica y categoriza patrones de deserci\u00f3n estudiantil mediante la extracci\u00f3n de datos en l\u00ednea. Ver detalle</li> </ul> </li> <li> <p>Educaci\u00f3n Continua:</p> <ul> <li>Docentes Desarrollo Empresarial: Consolida informaci\u00f3n de instructores provenientes de plataformas empresariales. Ver detalle</li> <li>Preinscritos: Automatiza la captura y organizaci\u00f3n de registros de preinscripci\u00f3n. Ver detalle</li> <li>Listado Matr\u00edculas Empresarial: Procesa matr\u00edculas de estudiantes en el contexto empresarial. Ver detalle</li> <li>Consolidado Inasistencias: Identifica y resume patrones de inasistencias. Ver detalle</li> <li>Estudiantes Inasistencias: Procesa informaci\u00f3n de estudiantes con ausencias frecuentes. Ver detalle</li> <li>Egresados Graduados Empresarial: Establece registros detallados de egresados empresariales desde fuentes remotas. Ver detalle</li> </ul> </li> </ul>"},{"location":"00.etl/00.etl_00.Introduccion/#02-sharepoint-q10","title":"02. SharePoint Q10","text":"<p>La integraci\u00f3n de SharePoint con Q10 potencia la colaboraci\u00f3n y el acceso en tiempo real a los datos extra\u00eddos mediante webscraping. Esta integraci\u00f3n permite una gesti\u00f3n optimizada y compartida de informaci\u00f3n clave.</p> <ul> <li> <p>Cedesarrollo:</p> <ul> <li>Automatiza la extracci\u00f3n y consolidaci\u00f3n de datos sobre docentes, dise\u00f1o curricular, matr\u00edculas, ingresos y registros hist\u00f3ricos, asegurando su disponibilidad en SharePoint.</li> </ul> </li> <li> <p>Desarrollo Empresarial:</p> <ul> <li>Implementa procesos adaptados al \u00e1mbito empresarial, facilitando la gesti\u00f3n de docentes, matr\u00edculas y otros aspectos relevantes.</li> </ul> </li> </ul>"},{"location":"00.etl/00.etl_00.Introduccion/#03-c4c","title":"03. C4C","text":"<p>Los procesos ETL de C4C integran t\u00e9cnicas avanzadas de webscraping para capturar informaci\u00f3n directamente desde sitios web, proporcionando datos din\u00e1micos y de referencia hist\u00f3rica.</p> <ul> <li>Webscraping Actualizable: Captura datos din\u00e1micos que requieren actualizaciones frecuentes.</li> <li>Webscraping Hist\u00f3rico: Archiva y organiza informaci\u00f3n hist\u00f3rica para an\u00e1lisis comparativos y toma de decisiones estrat\u00e9gicas.</li> </ul>"},{"location":"00.etl/00.etl_00.Introduccion/#beneficios-del-enfoque-basado-en-webscraping","title":"Beneficios del Enfoque Basado en Webscraping","text":"<p>Este marco de procesos ETL garantiza:</p> <ul> <li>Eficiencia: Automatizaci\u00f3n de tareas repetitivas y consumo de datos en tiempo real.</li> <li>Calidad de los Datos: Transformaciones y validaciones en cada etapa del flujo.</li> <li>Accesibilidad: Integraci\u00f3n con plataformas como SharePoint y sistemas externos para compartir informaci\u00f3n.</li> <li>Toma de Decisiones Informada: Disponibilidad de datos actualizados y estructurados para an\u00e1lisis estrat\u00e9gicos.</li> </ul>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/00.Procesar_manual/","title":"00.Procesar manual","text":"<pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    procesar\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\n# Si el logger ya tiene manejadores, limpiarlos\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Crear un formateador para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Crear un manejador de archivo para guardar los logs en un archivo\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)  # Asignar el formateador al manejador de archivo\nlogger.addHandler(file_handler)  # Agregar el manejador de archivo al logger\n\n# Crear un manejador de consola para mostrar los logs en la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)  # Asignar el formateador al manejador de consola\nlogger.addHandler(console_handler)  # Agregar el manejador de consola al logger\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\nlogging.info(\"Inicio del proceso principal\")\ntry:\n    # Definir la subcarpeta de descarga\n    subcarpeta_descarga = \"Graduados\"\n    base_dir = os.path.dirname(os.path.dirname(os.getcwd()))  # Subir un nivel desde el directorio actual\n    # Llamar a setup_driver una vez con la subcarpeta deseada para definir el entorno del navegador\n    DOWNLOAD_DIR = os.path.join(base_dir, \"01.Q10\", \"Procesados\", subcarpeta_descarga) \n    # Procesar todos los informes descargados\n    procesar(\"emp_Egresados_Graduados\",DOWNLOAD_DIR)\n    logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\nfinally:\n    logging.info(\"Fin del proceso principal\")\n</code></pre> <pre><code>2024-12-27 20:36:22,094 - INFO - Inicio del proceso principal\n\n\nProcesando archivo: Graduados_Diciembre 2021.xlsx\nArchivo procesado y guardado como: Graduados_Diciembre 2021_27_12_2024.xlsx\nProcesando archivo: Graduados_Noviembre 2024.xlsx\nArchivo procesado y guardado como: Graduados_Noviembre 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2024.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2024.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2024.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Julio 2024.xlsx\nArchivo procesado y guardado como: Graduados_Julio 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Junio 2024.xlsx\nArchivo procesado y guardado como: Graduados_Junio 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Mayo 2024.xlsx\nArchivo procesado y guardado como: Graduados_Mayo 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Abril 2024.xlsx\nArchivo procesado y guardado como: Graduados_Abril 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Marzo 2024.xlsx\nArchivo procesado y guardado como: Graduados_Marzo 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Febrero 2024.xlsx\nArchivo procesado y guardado como: Graduados_Febrero 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Enero 2024.xlsx\nArchivo procesado y guardado como: Graduados_Enero 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Diciembre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Diciembre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Noviembre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Noviembre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2023.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Julio 2023.xlsx\nArchivo procesado y guardado como: Graduados_Julio 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Junio 2023.xlsx\nArchivo procesado y guardado como: Graduados_Junio 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Mayo 2023.xlsx\nArchivo procesado y guardado como: Graduados_Mayo 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Abril 2023.xlsx\nArchivo procesado y guardado como: Graduados_Abril 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Marzo 2023.xlsx\nArchivo procesado y guardado como: Graduados_Marzo 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Febrero 2023.xlsx\nArchivo procesado y guardado como: Graduados_Febrero 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Enero 2023.xlsx\nArchivo procesado y guardado como: Graduados_Enero 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Diciembre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Diciembre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Noviembre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Noviembre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2022.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Julio 2022.xlsx\nArchivo procesado y guardado como: Graduados_Julio 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Junio 2022.xlsx\nArchivo procesado y guardado como: Graduados_Junio 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Mayo 2022.xlsx\nArchivo procesado y guardado como: Graduados_Mayo 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Abril 2022.xlsx\nArchivo procesado y guardado como: Graduados_Abril 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Marzo 2022.xlsx\nArchivo procesado y guardado como: Graduados_Marzo 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Febrero 2022.xlsx\nArchivo procesado y guardado como: Graduados_Febrero 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Enero 2022.xlsx\nArchivo procesado y guardado como: Graduados_Enero 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2021.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2021_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2021.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2021_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2021.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2021_27_12_2024.xlsx\n\n\n2024-12-27 20:39:24,133 - ERROR - Error al subir el archivo Graduados_Diciembre 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2021_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2021.xlsx\n\n\n2024-12-27 20:39:27,544 - ERROR - Error al subir el archivo Graduados_Noviembre 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2024.xlsx\n\n\n2024-12-27 20:39:31,126 - ERROR - Error al subir el archivo Graduados_Octubre 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2024.xlsx\n\n\n2024-12-27 20:39:34,588 - ERROR - Error al subir el archivo Graduados_Septiembre 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2024.xlsx\n\n\n2024-12-27 20:39:38,070 - ERROR - Error al subir el archivo Graduados_Agosto 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2024.xlsx\n\n\n2024-12-27 20:39:41,622 - ERROR - Error al subir el archivo Graduados_Julio 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2024.xlsx\n\n\n2024-12-27 20:39:45,165 - ERROR - Error al subir el archivo Graduados_Junio 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2024.xlsx\n\n\n2024-12-27 20:39:48,702 - ERROR - Error al subir el archivo Graduados_Mayo 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2024.xlsx\n\n\n2024-12-27 20:39:52,235 - ERROR - Error al subir el archivo Graduados_Abril 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2024.xlsx\n\n\n2024-12-27 20:39:55,767 - ERROR - Error al subir el archivo Graduados_Marzo 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2024.xlsx\n\n\n2024-12-27 20:39:59,245 - ERROR - Error al subir el archivo Graduados_Febrero 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2024.xlsx\n\n\n2024-12-27 20:40:02,708 - ERROR - Error al subir el archivo Graduados_Enero 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2024.xlsx\n\n\n2024-12-27 20:40:06,252 - ERROR - Error al subir el archivo Graduados_Diciembre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2023.xlsx\n\n\n2024-12-27 20:40:09,955 - ERROR - Error al subir el archivo Graduados_Noviembre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2023.xlsx\n\n\n2024-12-27 20:40:13,505 - ERROR - Error al subir el archivo Graduados_Octubre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2023.xlsx\n\n\n2024-12-27 20:40:17,034 - ERROR - Error al subir el archivo Graduados_Septiembre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2023.xlsx\n\n\n2024-12-27 20:40:20,564 - ERROR - Error al subir el archivo Graduados_Agosto 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2023.xlsx\n\n\n2024-12-27 20:40:24,026 - ERROR - Error al subir el archivo Graduados_Julio 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2023.xlsx\n\n\n2024-12-27 20:40:27,668 - ERROR - Error al subir el archivo Graduados_Junio 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2023.xlsx\n\n\n2024-12-27 20:40:31,261 - ERROR - Error al subir el archivo Graduados_Mayo 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2023.xlsx\n\n\n2024-12-27 20:40:34,829 - ERROR - Error al subir el archivo Graduados_Abril 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2023.xlsx\n\n\n2024-12-27 20:40:38,378 - ERROR - Error al subir el archivo Graduados_Marzo 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2023.xlsx\n\n\n2024-12-27 20:40:41,798 - ERROR - Error al subir el archivo Graduados_Febrero 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2023.xlsx\n\n\n2024-12-27 20:40:45,253 - ERROR - Error al subir el archivo Graduados_Enero 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2023.xlsx\n\n\n2024-12-27 20:40:48,678 - ERROR - Error al subir el archivo Graduados_Diciembre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2022.xlsx\n\n\n2024-12-27 20:40:52,215 - ERROR - Error al subir el archivo Graduados_Noviembre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2022.xlsx\n\n\n2024-12-27 20:40:55,747 - ERROR - Error al subir el archivo Graduados_Octubre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2022.xlsx\n\n\n2024-12-27 20:40:59,443 - ERROR - Error al subir el archivo Graduados_Septiembre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2022.xlsx\n\n\n2024-12-27 20:41:02,934 - ERROR - Error al subir el archivo Graduados_Agosto 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2022.xlsx\n\n\n2024-12-27 20:41:06,541 - ERROR - Error al subir el archivo Graduados_Julio 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2022.xlsx\n\n\n2024-12-27 20:41:09,995 - ERROR - Error al subir el archivo Graduados_Junio 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2022.xlsx\n\n\n2024-12-27 20:41:13,458 - ERROR - Error al subir el archivo Graduados_Mayo 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2022.xlsx\n\n\n2024-12-27 20:41:16,902 - ERROR - Error al subir el archivo Graduados_Abril 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2022.xlsx\n\n\n2024-12-27 20:41:20,401 - ERROR - Error al subir el archivo Graduados_Marzo 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2022.xlsx\n\n\n2024-12-27 20:41:23,881 - ERROR - Error al subir el archivo Graduados_Febrero 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2022.xlsx\n\n\n2024-12-27 20:41:27,299 - ERROR - Error al subir el archivo Graduados_Enero 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2022.xlsx\n\n\n2024-12-27 20:41:30,710 - ERROR - Error al subir el archivo Graduados_Agosto 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2021_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2021.xlsx\n\n\n2024-12-27 20:41:34,138 - ERROR - Error al subir el archivo Graduados_Octubre 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2021_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2021.xlsx\n\n\n2024-12-27 20:41:37,540 - ERROR - Error al subir el archivo Graduados_Septiembre 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2021_27_12_2024.xlsx\n\n\n2024-12-27 20:41:40,550 - INFO - Procesamiento de periodos, jornadas y programas completado.\n2024-12-27 20:41:40,551 - INFO - Fin del proceso principal\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2021.xlsx\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/","title":"0.1. Docentes Cedesarrollo.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code> y <code>warnings</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <pre><code>import logging\nimport time\nimport os\nimport sys\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n# Importar funciones personalizadas desde Utils.Funciones\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, _descargar, close_driver, hacer_clic, procesar,\n    configurar_pasos_autenticacion_cedesarrollo, eliminar_archivos_anteriores\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\nlogging.basicConfig(level=logging.INFO)\n\n# Limpiar manejadores existentes si los hay\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Formateador para los logs\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Manejador para archivo de log\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n\n# Manejador para la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/#automatizacion-de-descarga-y-procesamiento-del-reporte-docentes","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Docentes\"","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Docentes\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>DOWNLOAD_DIR</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_cedesarrollo</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Ingresos detallados por producto\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Este enfoque modular y estructurado facilita la depuraci\u00f3n, escalabilidad y mantenimiento del flujo automatizado.</p> <pre><code>@log_step_decorator(\"Docentes Cedesarrollo\")\ndef main():\n    # Inicia el proceso principal con un mensaje en el log\n    logging.info(\"Inicio del proceso principal\")\n    driver = None  # Inicializa el objeto driver como None para asegurar que est\u00e9 definido\n\n    try:\n        # Define la subcarpeta donde se almacenar\u00e1n las descargas\n        subcarpeta_descarga = \"Docentes\"\n\n        # Configura el driver para la automatizaci\u00f3n del navegador, incluyendo la carpeta de descargas\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configura los pasos de autenticaci\u00f3n requeridos\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n        # Elimina archivos previos que podr\u00edan interferir con las descargas actuales\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        eliminar_archivos_anteriores(nombre_archivo=\"Cedesarrollo_DocenteS\", download_dir=DOWNLOAD_DIR)\n\n        # Define los pasos para la automatizaci\u00f3n del proceso\n        step_1 = pasos_autenticacion + [\n            # Paso: enviar formulario\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n\n            # Paso: acceder a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), \n            {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n\n            # Paso: seleccionar el informe de ingresos detallados por producto\n            (\"clic_Ingresos_detallados_por_producto\", log_step_decorator(\"clic_Ingresos_detallados_por_producto\")(hacer_clic), \n            {'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[5]/div[2]/div[1]/div[2]/a', 'wait_time': 5}),\n\n            # Paso: abrir el selector de fechas\n            (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), \n            {'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n\n            # Paso: descargar el archivo con el informe\n            (\"descargar_archivo\", log_step_decorator(\"descargar_archivo\")(_descargar), \n            {'driver': driver, 'xpath': '//*[@id=\"generar-reporte-btn\"]', \n            'download_dir': DOWNLOAD_DIR, \n            'archivo': f\"Cedesarrollo_Docentes_{time.strftime('%Y_%m_%d')}\", 'wait_time': 10}),\n\n            # Paso: hacer clic en el usuario\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), \n            {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', 'wait_time': 5}),\n\n            # Paso: cerrar sesi\u00f3n\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), \n            {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', 'wait_time': 5}),\n        ]\n\n        # Ejecuta todos los pasos definidos, registrando el progreso en el log\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        # Procesa los datos descargados\n        procesar('cede_Docentes', DOWNLOAD_DIR)\n\n    finally:\n        # Asegura que el driver se cierre correctamente al finalizar el proceso\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\nif __name__ == \"__main__\":\n    # Inicia el script si se ejecuta directamente\n    main()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/","title":"0.2. Dise\u00f1o Curricular.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el flujo de trabajo. Finalmente, se ajustan los niveles de registro de otros loggers configurados en el entorno para mantener la coherencia en el nivel de detalle de los logs.</p> <pre><code>import logging  # Importa el m\u00f3dulo de logging para registrar eventos\nimport os       # Permite interactuar con el sistema operativo (rutas, archivos)\nimport sys      # Proporciona acceso a variables y funciones del sistema\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\n# Esto permite importar m\u00f3dulos definidos en directorios superiores\nsys.path.append(os.path.abspath(\"../../\"))\n\n\n# Importaci\u00f3n de funciones y herramientas necesarias desde el m\u00f3dulo `Utils.Funciones`\nfrom Utils.Funciones import (\n    log_step_decorator,       # Decorador para registrar pasos en el log\n    setup_driver,             # Configura el navegador para la automatizaci\u00f3n\n    procesar,                 # Procesa archivos descargados\n    close_driver,             # Cierra el navegador de forma segura\n    hacer_clic,               # Realiza clics en elementos de la interfaz web\n    configurar_pasos_autenticacion_cedesarrollo,  # Configura pasos de autenticaci\u00f3n\n    procesar_reporte_modal,     # Maneja y valida reportes descargados\n    log_tiempo,                 # Calcula y registra el tiempo de ejecuci\u00f3n    \n)\n\n# Configuraci\u00f3n del sistema de logging\nlogger = logging.getLogger(__name__)  # Crea un logger con el nombre del m\u00f3dulo actual\nlogger.setLevel(logging.INFO)         # Define el nivel de registro como INFO\n\n# Evita duplicar manejadores si ya se han configurado previamente\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Configura el formato est\u00e1ndar para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Manejador para registrar los mensajes en un archivo de log\nfile_handler = logging.FileHandler(\"scraper.log\")  # Define el archivo de salida\nfile_handler.setFormatter(formatter)              # Aplica el formato al manejador\nlogger.addHandler(file_handler)                   # Agrega el manejador al logger\n\n# Manejador para registrar los mensajes en la consola\nconsole_handler = logging.StreamHandler()         # Define la salida por consola\nconsole_handler.setFormatter(formatter)           # Aplica el formato al manejador\nlogger.addHandler(console_handler)                # Agrega el manejador al logger\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/#automatizacion-de-descarga-y-procesamiento-del-reporte-diseno-curricular","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Dise\u00f1o Curricular\"","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Dise\u00f1o Curricular\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>download_dir</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_cedesarrollo</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Dise\u00f1o Curricular\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar_reporte_modal</code> y <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Este enfoque modular y estructurado facilita la depuraci\u00f3n, escalabilidad y mantenimiento del flujo automatizado.</p> <pre><code>@log_step_decorator(\"Dise\u00f1o Curricular\")\ndef main():\n    # Registra el inicio del proceso en el log\n    driver = None  # Inicializa el driver como None\n\n    try:\n        # Define la subcarpeta para descargas y configura el driver\n        subcarpeta_descarga = \"Dise\u00f1o_curricular\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configura los elementos clave del proceso\n        xpath_boton = '//*[@id=\"formReportes\"]/div[1]/div[3]/div/button'  # XPath del bot\u00f3n de opciones\n        xpath_contenedor_opciones = '//*[@id=\"formReportes\"]/div[1]/div[3]/div/div/ul'  # XPath del contenedor de opciones\n        excluir_opciones = {}  # Diccionario para excluir opciones, si corresponde\n\n        id_descargar = 'generar-reporte-btn'  # ID del bot\u00f3n para generar el reporte\n        nombre_archivo = 'Dise\u00f1o_curricular'  # Nombre base del archivo\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'  # Nombre completo con extensi\u00f3n\n\n        # Configura los pasos de autenticaci\u00f3n necesarios para acceder al sistema\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n        # Define los pasos del flujo de trabajo, incluyendo autenticaci\u00f3n, navegaci\u00f3n y generaci\u00f3n del reporte\n        step_1 = pasos_autenticacion + [\n            # Paso: Enviar formulario de autenticaci\u00f3n\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n            }),\n            # Paso: Entrar a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5\n            }),\n            # Paso: Seleccionar el reporte \"Dise\u00f1o Curricular\"\n            (\"dise\u00f1o_curricular\", log_step_decorator(\"dise\u00f1o_curricular\")(hacer_clic), {\n                'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[4]/div[2]/a', 'wait_time': 5\n            }),\n            # Paso: Generar el reporte\n            (\"clic_generar_reporte\", log_step_decorator(\"clic_generar_reporte\")(hacer_clic), {\n                'driver': driver, 'id': id_descargar, 'wait_time': 30\n            }),\n            # Paso: Procesar el reporte generado\n            (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {\n                'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo\n            })\n        ]\n\n        # Ejecuta los pasos del flujo, registrando el progreso en el log\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        # Procesa los datos descargados del reporte\n        procesar('cede_Dise\u00f1o_Curricular', download_dir)\n\n    finally:\n        # Cierra el driver al finalizar, garantizando que los recursos se liberen\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    # Inicia la ejecuci\u00f3n del script si es ejecutado directamente\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/","title":"0.3. Listado Matr\u00edculas.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code> y <code>argparse</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Finalmente, se ajustan los niveles de registro de otros loggers configurados en el entorno para mantener la coherencia en el nivel de detalle de los logs.</p> <pre><code>import logging, os, sys, time, argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\n# Importar funciones espec\u00edficas del m\u00f3dulo Utils.Funciones\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, generar_fechas,\n    close_driver, hacer_clic, configurar_pasos_autenticacion_cedesarrollo, procesar_reporte_modal\n)\n\n# Configuraci\u00f3n del logger\nlogger = logging.getLogger(__name__)  # Crear un logger con el nombre del m\u00f3dulo actual\nlogger.setLevel(logging.INFO)  # Establecer el nivel de registro en INFO\n\n# Limpiar los manejadores existentes si los hay\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Crear un formateador para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Crear un manejador de archivo para registrar los logs en un archivo\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)  # Asignar el formateador al manejador de archivo\nlogger.addHandler(file_handler)  # Agregar el manejador de archivo al logger\n\n# Crear un manejador de consola para mostrar los logs en la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)  # Asignar el formateador al manejador de consola\nlogger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/#automatizacion-de-descarga-de-listados-de-matriculas-por-ano","title":"Automatizaci\u00f3n de Descarga de Listados de Matr\u00edculas por A\u00f1o","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Listado_matriculas\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los rangos de fechas por a\u00f1o. Cada iteraci\u00f3n del bucle configura un rango de fechas personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar fechas y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos obligatorios: <code>--start-year</code> y <code>--end-year</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los listados de matr\u00edculas desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Listado de matr\u00edculas\")\ndef main(fechas):\n    # Registra el inicio del proceso en el log\n    driver = None  # Inicializa el driver como None para su manejo seguro\n\n    try:\n        # Define la subcarpeta para las descargas y configura el navegador\n        subcarpeta_descarga = \"Listado_matriculas\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        nombre_archivo = 'Listado_matriculas2024'  # Nombre base del archivo\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'  # Nombre completo con extensi\u00f3n\n\n        # Configura los pasos de autenticaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n        # Pasos iniciales: autenticarse y navegar al listado de matr\u00edculas\n        step_1 = pasos_autenticacion + [\n            # Enviar formulario de autenticaci\u00f3n\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n            }),\n            # Entrar a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5\n            }),\n            # Seleccionar el listado de matr\u00edculas\n            (\"listado\", log_step_decorator(\"listado\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[1]/div[2]/div[3]/div[2]/div[9]/div[1]/a', 'wait_time': 5\n            })\n        ]\n\n        # Ejecuta los pasos iniciales\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)        \n\n        # Itera por cada rango de fechas para configurar y descargar el reporte\n        for fecha in fechas:\n            logging.info(f\"Fecha: {fecha}\")\n            logging.info(f\"Desde {fechas[fecha]['desde']} hasta {fechas[fecha]['hasta']}\")\n\n            # Pasos para configurar el rango de fechas y descargar el reporte\n            step_2 = [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), {\n                    'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3\n                }),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[9]/div[3]/ul/li[7]', 'wait_time': 3\n                }),\n                (\"entrar_en_fecha1\", log_step_decorator(\"entrar_en_fecha1\")(hacer_clic), {\n                    'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', \n                    'value': fechas[fecha]['desde'], \n                    'driver': driver, 'wait_time': 3\n                }),\n                (\"entrar_en_fecha2\", log_step_decorator(\"entrar_en_fecha2\")(hacer_clic), {\n                    'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', \n                    'value': fechas[fecha]['hasta'], \n                    'driver': driver, 'wait_time': 3\n                }),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 3\n                }),\n                (\"descargar\", log_step_decorator(\"descargar\")(hacer_clic), {\n                    'driver': driver, 'xpath': '//*[@id=\"generar-reporte-btn\"]', 'wait_time': 3\n                }),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {\n                    'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo\n                })\n            ]\n            # Ejecuta los pasos del flujo para el rango de fechas actual\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                time.sleep(5)  # Pausa breve para evitar problemas de sincronizaci\u00f3n\n\n    finally:\n        # Asegura que el navegador se cierre correctamente\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n        # Procesa los datos descargados tras la finalizaci\u00f3n del flujo\n        time.sleep(5)\n        procesar(\"cede_Listado_Matriculas\", download_dir)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/04.Ingresos/","title":"0.4. Ingresos.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/04.Ingresos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, y <code>argparse</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Todos los loggers configurados en el entorno tambi\u00e9n se ajustan al nivel <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <pre><code>import logging, os, sys, time,argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, generar_fechas, _descargar,procesar,\n    close_driver, hacer_clic, configurar_pasos_autenticacion_cedesarrollo, procesar_reporte_modal,seleccionar_opcion_custom_dropdown\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/04.Ingresos/#automatizacion-de-descarga-de-ingresos","title":"Automatizaci\u00f3n de Descarga de Ingresos","text":"<p>Este script automatiza la descarga y procesamiento de listados de ingresos correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Ingresos\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los periodos por a\u00f1o generados din\u00e1micamente seg\u00fan los argumentos proporcionados. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del ultimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el ultimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Ingresos\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    # Genera el diccionario de fechas para el semestre cuando se deja semestre = True, de lo contrario hace el diccionario de acuerdo a los a\u00f1os inicio y fin\n    nombre_archivo = 'Ingresos'\n    subcarpeta_descarga = \"Ingresos\"\n    nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n\n    for fecha in fechas:\n        logging.info(f\"Fecha: {fecha}\")\n        logging.info(f\"Desde {fechas[fecha]['desde']} hasta {fechas[fecha]['hasta']}\")\n        driver = None\n        try:\n            driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n            pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n            step_1 = [\n                (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                    'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n                }),\n                (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5\n                }),\n                (\"Ingresos\", log_step_decorator(\"Ingresos\")(hacer_clic), {\n                    'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[5]/div[2]/a', 'wait_time': 3\n                }),\n                (\"descartar\", log_step_decorator(\"descartar0\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[3]/button', 'wait_time': 3\n                }),            \n                (\"descartar\", log_step_decorator(\"descartar1\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[1]/div[2]/div/button/span', 'wait_time': 3\n                }),            \n                (\"descartar1\", log_step_decorator(\"descartar2\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[3]/button', 'wait_time': 3\n                })                             \n            ]\n\n\n\n            step_2 =pasos_autenticacion + step_1 + [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[10]/div[3]/ul/li[7]', 'wait_time': 3}),\n                # (\"entrar_en_personalizado_2\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[12]/div[3]/ul/li[7]', 'wait_time': 5}),   \n                (\"entrar_en_fecha1\",log_step_decorator(\"entrar_en_fecha1\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', 'value': fechas[fecha]['desde'], 'driver': driver,'wait_time': 5}),\n                (\"entrar_en_fecha2\",log_step_decorator(\"entrar_en_fecha2\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[2]/input','value': fechas[fecha]['hasta'],'driver': driver,'wait_time': 5}),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 5}),\n                (\"programar-reporte-btn\", log_step_decorator(\"descargar\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"programar-reporte-btn\"]', 'wait_time': 80}), \n                (\"abrir-reporte\", log_step_decorator(\"descargar1\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"abrir-reporte\"]', 'wait_time': 5}),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo}),\n                (\"descartar\", log_step_decorator(\"descartar\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[3]/button', 'wait_time': 10})\n                ]\n\n            ultimo=0\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                if step_name==\"programar-reporte-btn\":\n                    time.sleep(80)\n                time.sleep(5)\n            procesar(\"cede_Ingresos\", download_dir)\n\n\n        finally:\n            if driver:\n                close_driver(driver)\n            logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular ultimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/05.Historico_notas_Cedesarrollo/","title":"0.5. Hist\u00f3rico notas.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/05.Historico_notas_Cedesarrollo/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>argparse</code> y <code>warnings</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>eliminar_archivos_anteriores</code> para gestionar los archivos descargados previamente.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Finalmente, se ajustan los niveles de otros loggers configurados para mantener la coherencia en el registro de eventos.</p> <pre><code>import logging, time, os, sys, argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar_reporte_modal, obtener_elementos_dropdown, \n    hacer_clic, procesar, seleccionar_opcion_con_js, guardar_diccionario,\n    configurar_pasos_autenticacion_cedesarrollo, eliminar_archivos_anteriores, ejecutar_pasos\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\n# Si el logger ya tiene manejadores, limpiarlos\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Crear un formateador para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Crear un manejador de archivo para guardar los logs en un archivo\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)  # Asignar el formateador al manejador de archivo\nlogger.addHandler(file_handler)  # Agregar el manejador de archivo al logger\n\n# Crear un manejador de consola para mostrar los logs en la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)  # Asignar el formateador al manejador de consola\nlogger.addHandler(console_handler)  # Agregar el manejador de consola al logger\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/05.Historico_notas_Cedesarrollo/#automatizacion-de-descarga-de-historico-notas","title":"Automatizaci\u00f3n de Descarga de H\u00edstorico Notas","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Historico_notas\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un conjunto llamado <code>consulta</code>, que contiene los periodos por a\u00f1o desde el a\u00f1o inicial hasta el a\u00f1o final. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_1</code>. Adem\u00e1s, el script incluye un fragmento comentado para generar autom\u00e1ticamente este conjunto de periodos mediante una funci\u00f3n.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>driver.quit()</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Historico de Notas\")\ndef main(consulta):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Historico_notas\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada para definir el entorno del navegador\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones en la aplicaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n        step_1 = pasos_autenticacion + [\n            # Enviar formulario de autenticaci\u00f3n\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            # Navegar a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n            # Hacer clic en el enlace de Hist\u00f3rico de Notas\n            (\"clic_historico_notas\",log_step_decorator(\"clic_historico_notas\")(hacer_clic), {'driver': driver, 'xpath': \n                '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[7]/div[2]/a',\n                'wait_time': 5}),\n        ]\n        # Ejecutar los pasos de autenticaci\u00f3n configurados\n        ejecutar_pasos(step_1)\n\n        # Definir los elementos de selecci\u00f3n del per\u00edodo (bot\u00f3n y lista desplegable)\n        _xpath_periodo  = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[1]/div[3]'\n        periodo_boton = f'{_xpath_periodo}/div/button'\n        periodo_list = f'{_xpath_periodo}/div/div/ul'        \n        nivel=1\n\n        # Obtener los periodos disponibles en el dropdown\n        _periodos = obtener_elementos_dropdown(driver, periodo_boton, periodo_list, nivel)\n\n        periodos_generados = [f\"{year}\" for year in consulta]\n\n        # Filtrar solo los per\u00edodos que comiencen con los valores generados\n        periodos = [\n            periodo for periodo in _periodos \n            if any(periodo.startswith(generado) for generado in periodos_generados)\n        ]\n\n        # Guardar los per\u00edodos seleccionados en un archivo para referencia\n        # guardar_diccionario(periodos, 'periodos')\n\n        # Eliminar archivos anteriores en la carpeta de descargas antes de procesar nuevos\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        # Procesar cada periodo seleccionado\n        if periodos:\n            for periodo in periodos:\n                # Seleccionar el per\u00edodo en el dropdown\n                hacer_clic(driver= driver, xpath=periodo_boton, wait_time= 1)\n                seleccionar_opcion_con_js(driver, periodo_boton, periodo)\n                logging.info(f\"Procesando periodo: {periodo}\")\n\n                # Obtener jornadas para el per\u00edodo seleccionado\n                xpath_jornada = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[2]/div[3]'\n                jornada_boton = f'{xpath_jornada}/div/button'\n                jornada_list = f'{xpath_jornada}/div/div/ul'\n                jornadas = obtener_elementos_dropdown(driver, jornada_boton, jornada_list, nivel=2)\n                excluir_jornadas = {'Seleccione'}\n                jornadas = [jornada for jornada in jornadas if jornada not in excluir_jornadas]                \n\n                # Procesar cada jornada seleccionada\n                if jornadas:\n                    for jornada in jornadas:\n                        # Seleccionar la jornada en el dropdown\n                        hacer_clic(driver= driver, xpath=jornada_boton, wait_time= 1)\n                        seleccionar_opcion_con_js(driver, jornada_boton, jornada)\n                        logging.info(f\"Procesando jornada: {jornada}\")\n\n                        # Obtener programas para la jornada seleccionada\n                        xpath_programa = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[3]/div[3]'\n                        programa_boton = f'{xpath_programa}/div/button'\n                        programa_list = f'{xpath_programa}/div/div/ul'\n                        programas = obtener_elementos_dropdown(driver, programa_boton, programa_list, nivel=3)\n                        excluir_opciones = {'Seleccione','Control de Calidad'}\n                        programas = [programa for programa in programas if programa not in excluir_opciones]\n\n                        # Procesar cada programa seleccionado\n                        if programas:\n                            for programa in programas:\n                                # Seleccionar el programa en el dropdown\n                                hacer_clic(driver= driver, xpath=programa_boton, wait_time= 1)\n                                seleccionar_opcion_con_js(driver, programa_boton, programa)\n                                logging.info(f\"Procesando programa: {programa}\")\n\n                                # Obtener m\u00f3dulos para el programa seleccionado\n                                xpath_modulo = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[4]/div[3]'\n                                modulo_boton = f'{xpath_modulo}/div/button'\n                                modulo_list = f'{xpath_modulo}/div/div/ul'\n                                modulos = obtener_elementos_dropdown(driver, modulo_boton, modulo_list, nivel=4)\n                                excluir_modulos = {'Seleccione'}\n                                modulos = [modulo for modulo in modulos if modulo not in excluir_modulos]\n\n                                # Procesar cada m\u00f3dulo seleccionado\n                                if modulos:\n                                    for modulo in modulos:\n                                        # Seleccionar el m\u00f3dulo en el dropdown\n                                        hacer_clic(driver= driver, xpath=modulo_boton, wait_time= 1)\n                                        seleccionar_opcion_con_js(driver, modulo_boton, modulo)\n                                        logging.info(f\"Procesando modulo: {modulo}\")\n\n                                        # Obtener cursos para el m\u00f3dulo seleccionado\n                                        xpath_curso = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[5]/div[3]'\n                                        cursos_boton = f'{xpath_curso}/div/button'\n                                        cursos_list = f'{xpath_curso}/div/div/ul'\n                                        cursos = obtener_elementos_dropdown(driver, cursos_boton, cursos_list, nivel=5)\n                                        excluir_cursos = {'Seleccione'}\n                                        cursos = [curso for curso in cursos if curso not in excluir_cursos]\n\n                                        # Procesar cada curso seleccionado\n                                        if cursos:\n                                            for curso in cursos:\n                                                # Seleccionar el curso en el dropdown\n                                                seleccionar_opcion_con_js(driver, cursos_boton, curso)\n                                                # Hacer clic en el bot\u00f3n para descargar el informe\n                                                hacer_clic(driver= driver, xpath=\n                                                    '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[7]/button'\n                                                    , wait_time=5)\n                                                # Guardar el archivo descargado con un nombre significativo\n                                                archivo = f'Cede_{periodo}_{jornada}_{programa}_{modulo}_{curso}.xlsx'\n                                                procesar_reporte_modal(driver, DOWNLOAD_DIR, archivo)\n                                                # Esperar un poco entre descargas\n                                                time.sleep(5)\n                                else: continue\n                        else: continue\n                else: continue\n\n        # Procesar todos los informes descargados\n        procesar(\"cede_Historico_Notas\",DOWNLOAD_DIR)\n        logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\n    finally:\n        # Cerrar el driver para liberar recursos\n        if driver:\n            driver.quit()\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    consulta = {_inicio, _fin}\n    main(consulta=consulta)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/06.Egresados_graduados_Cedesarrollo/","title":"0.6. Egresados.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/06.Egresados_graduados_Cedesarrollo/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>argparse</code> y <code>time</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <pre><code>import logging\nimport time\nimport os\nimport sys,argparse\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic, generar_fechas, generar_periodos,\n    configurar_pasos_autenticacion_cedesarrollo, eliminar_archivos_anteriores, pre_procesamiento_periodo\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/06.Egresados_graduados_Cedesarrollo/#automatizacion-de-descarga","title":"Automatizaci\u00f3n de Descarga","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Graduados\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>periodos</code>, que contiene los periodos por a\u00f1o desde el a\u00f1o inicial hasta el a\u00f1o final especificados por el usuario. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_1</code>. Adem\u00e1s, el script incluye un fragmento comentado para generar autom\u00e1ticamente este diccionario de periodos mediante una funci\u00f3n.</p> <p>El diccionario <code>step_1</code> contiene una serie de pasos que se ejecutan secuencialmente para automatizar el proceso de scraping. Cada entrada en el diccionario es una tupla que incluye:</p> <ol> <li>Nombre del paso: Una cadena que describe la acci\u00f3n a realizar.</li> <li>Funci\u00f3n del paso: Una funci\u00f3n decorada con <code>log_step_decorator</code> que realiza la acci\u00f3n.</li> <li>Par\u00e1metros del paso: Un diccionario de par\u00e1metros que se pasan a la funci\u00f3n del paso.</li> </ol> <p>Por ejemplo, el paso <code>(\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10})</code> indica que se debe hacer clic en el bot\u00f3n de env\u00edo del formulario, utilizando el driver de Selenium y esperando hasta 10 segundos para que el elemento est\u00e9 disponible.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Graduados\")\ndef main(periodos):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Graduados\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Graduados'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n            (\"clic_egresados\", log_step_decorator(\"clic_egresados\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[5]/div[2]/div[1]/div[3]/a', \n                'wait_time': 5\n            }),\n            (\"seleccionar_tipo_graduado\", log_step_decorator(\"seleccionar_tipo_graduado\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[1]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"seleccionperiodos\", log_step_decorator(\"seleccionperiodos\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[2]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"pre_procesamiento_periodo\", log_step_decorator(\"pre_procesamiento\")(pre_procesamiento_periodo), {\n                'driver': driver,\n                'download_dir': DOWNLOAD_DIR,\n                'id_descargar': 'generar-reporte-btn',\n                'nombre_archivo': nombre_archivo,\n                'nombre_archivo_completo': nombre_archivo_completo,\n                'xpath_boton': '//*[@id=\"form0\"]/div[4]/div[3]/div/button',\n                'tipo':'normal',\n                'xpath_contenedor_opciones':  '//*[@id=\"form0\"]/div[4]/div[3]/div/div/ul',\n                'items_opciones':periodos\n            }),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', \n                'wait_time': 5\n            }),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', \n                'wait_time': 5\n            })\n        ]\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        procesar('cede_Egresados_Graduados', DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    periodos = generar_periodos(_inicio, _fin)\n    main(periodos)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/07.Desertores/","title":"0.7. Desertores.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/07.Desertores/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, y <code>time</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos, <code>configurar_pasos_autenticacion_cedesarrollo</code> para configurar los pasos de autenticaci\u00f3n, y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <pre><code>import logging\nimport os, time\nimport sys,argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\n# Importar funciones espec\u00edficas del m\u00f3dulo Utils.Funciones\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, generar_fechas, procesar,guardar_diccionario,\n    close_driver, hacer_clic, configurar_pasos_autenticacion_cedesarrollo, procesar_reporte_modal\n)\n\n# Obtener el logger con el nombre del m\u00f3dulo actual\nlogger = logging.getLogger(__name__)  \n\n# Establecer el nivel de registro a INFO\nlogger.setLevel(logging.INFO)\n\n# Limpiar los manejadores existentes si los hay\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Formato de los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Configuraci\u00f3n del manejador de archivos para el log\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n\n# Configuraci\u00f3n del manejador de consola para el log\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/07.Desertores/#automatizacion-de-descarga","title":"Automatizaci\u00f3n de Descarga","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Desertores\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los periodos definidos por el usuario. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El diccionario <code>step_1</code> contiene una serie de pasos que se ejecutan secuencialmente para automatizar el proceso de scraping. Cada entrada en el diccionario es una tupla que incluye:</p> <ol> <li>Nombre del paso: Una cadena que describe la acci\u00f3n a realizar.</li> <li>Funci\u00f3n del paso: Una funci\u00f3n decorada con <code>log_step_decorator</code> que realiza la acci\u00f3n.</li> <li>Par\u00e1metros del paso: Un diccionario de par\u00e1metros que se pasan a la funci\u00f3n del paso.</li> </ol> <p>Por ejemplo, el paso <code>(\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10})</code> indica que se debe hacer clic en el bot\u00f3n de env\u00edo del formulario, utilizando el driver de Selenium y esperando hasta 10 segundos para que el elemento est\u00e9 disponible.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Desertores\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        subcarpeta_descarga = \"Desertores\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Dise\u00f1o_curricular'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n        # Pasar driver al configurar pasos de autenticaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n        # Definir los pasos de autenticaci\u00f3n y navegaci\u00f3n inicial\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n            (\"desertores\", log_step_decorator(\"desertores\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[3]/div[1]/a', 'wait_time': 5}),\n        ]\n\n        # Ejecutar los pasos de autenticaci\u00f3n y navegaci\u00f3n inicial\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n        guardar_diccionario(fechas, 'fechas')\n        for fecha in fechas:\n            logging.info(f\"Fecha: {fecha}\")\n\n            step_2 = [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/div[9]/div[3]/ul/li[7]', 'wait_time': 3}),\n                (\"entrar_en_fecha1\", log_step_decorator(\"entrar_en_fecha1\")(hacer_clic), {'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', 'value': fechas[fecha]['desde'], 'driver': driver, 'wait_time': 3}),\n                (\"entrar_en_fecha2\", log_step_decorator(\"entrar_en_fecha2\")(hacer_clic), {'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', 'value': fechas[fecha]['hasta'], 'driver': driver, 'wait_time': 3}),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 3}),\n                (\"descargar\", log_step_decorator(\"descargar\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"generar-reporte-btn\"]', 'wait_time': 5}),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo})\n            ]\n\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                time.sleep(5)\n\n        procesar('cede_Cancelados_Desertores',download_dir)\n\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/","title":"cede_01 procesar_docentes","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport re\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, extract_date, obtener_sharepoint,replace_values_df,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/#procesar_docentes","title":"procesar_docentes","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de docentes almacenados en SharePoint. Primero, se define una funci\u00f3n <code>obtener_sharepoint_docentes</code> que descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica el archivo m\u00e1s reciente basado en la fecha en su nombre, y elimina los archivos m\u00e1s antiguos. Luego, carga el archivo m\u00e1s reciente en un DataFrame de pandas y registra informaci\u00f3n sobre el archivo y su contenido.</p> <p>La funci\u00f3n <code>procesar_cede_Docentes</code> toma el DataFrame cargado y realiza varias transformaciones. Estas incluyen la limpieza de espacios en blanco en los nombres y apellidos, la concatenaci\u00f3n de estos en una nueva columna 'NOMBRE', y la eliminaci\u00f3n y renombrado de columnas seg\u00fan un diccionario de mapeo. Finalmente, selecciona y reordena las columnas del DataFrame para que coincidan con un formato espec\u00edfico.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se registran mensajes informativos, se obtienen y procesan los datos de SharePoint, se muestran las primeras filas del DataFrame procesado y se actualizan los datos procesados de vuelta en SharePoint.</p> <pre><code>@log_step_decorator('obtener_sharepoint_docentes')\ndef obtener_sharepoint_docentes():\n    # Obtiene la URL de la carpeta de SharePoint desde un diccionario `etl_to_folder_url`.\n    folder_url = etl_to_folder_url.get('cede_Docentes', \"URL por defecto si no se encuentra el valor de etl\")\n    # Llama a la funci\u00f3n `obtener_sharepoint` para descargar los archivos en la carpeta local `_folder`.\n    obtener_sharepoint(folder_url,_folder)\n\n    # Busca todos los archivos que coincidan con el patr\u00f3n \"Docentes_*.xlsx\" en la carpeta local.\n    files = glob.glob(os.path.join(_folder, \"Docentes_*.xlsx\"))\n\n    # Utiliza una expresi\u00f3n regular para extraer la fecha de los nombres de los archivos.\n    date_pattern = re.compile(r'Docentes_(\\d{2})_(\\d{2})_(\\d{4})\\.xlsx')\n\n    # Encuentra el archivo m\u00e1s reciente basado en la fecha extra\u00edda.\n    latest_file = max(files, key=lambda f: extract_date(f,date_pattern))\n\n    # Elimina todos los archivos excepto el m\u00e1s reciente.\n    for file in files:\n        if file != latest_file:\n            os.remove(file)\n\n    # Registra informaci\u00f3n sobre el archivo m\u00e1s reciente y su contenido.\n    logger.info(f\"El archivo m\u00e1s reciente es: {latest_file}\")\n\n    # Carga el archivo m\u00e1s reciente en un DataFrame de pandas.\n    df = pd.read_excel(latest_file)\n\n    # Registra informaci\u00f3n sobre el contenido del archivo m\u00e1s reciente.\n    logger.info(f\"Contenido del archivo {latest_file}:\")\n    return df\n\n\n@log_step_decorator('procesar_cede_Docentes')\ndef procesar_cede_Docentes(df):\n    # Reemplaza valores en el DataFrame seg\u00fan sea necesario.\n    df = replace_values_df(df)\n\n    # Elimina espacios en blanco de los nombres y apellidos.\n    df['Primer nombre'] = df['Primer nombre'].str.strip()\n    df['Segundo nombre'] = df['Segundo nombre'].str.strip()\n    df['Primer apellido'] = df['Primer apellido'].str.strip()\n    df['Segundo apellido'] = df['Segundo apellido'].str.strip()\n\n    # Concatena los nombres y apellidos en una sola columna 'NOMBRE', omitiendo los vac\u00edos.\n    df['NOMBRE'] = df[['Primer nombre', 'Segundo nombre', 'Primer apellido', 'Segundo apellido']].apply(lambda x: ' '.join(x.dropna().astype(str)).upper(), axis=1)\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = []\n    renombres = {\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'E-mail':'CORREO',\n        'Direcci\u00f3n':'DIRECCION',\n        'C\u00e9dula':'CEDULA',\n        'Municipio direcci\u00f3n':'CIUDAD',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n': 'DOCUMENTO',\n        'Fecha de nacimiento':'FECHA_NACIMIENTO',\n        'Sexo':'GENERO'\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n\n    # Selecciona y reordena las columnas del DataFrame.\n    df = df[[\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'NOMBRE',\n        'PRIMER NOMBRE',\n        'SEGUNDO NOMBRE',\n        'PRIMER APELLIDO',\n        'SEGUNDO APELLIDO',\n        'TELEFONO',\n        'CELULAR',\n        'CORREO',\n        'DIRECCION',\n        'CIUDAD',\n        'FECHA_NACIMIENTO',\n        'MUNICIPIO EXPEDICI\u00d3N',\n        'FECHA DE EXPEDICI\u00d3N',\n        'GENERO',\n        'MUNICIPIO NACIMIENTO',\n        'TIPO DE SANGRE',\n        'ESCALAF\u00d3N',\n        'ESTADO CIVIL',\n        'CALIDAD DE DESEMPE\u00d1O',\n        'ESTADO',\n        'FECHA DE INGRESO',\n        'TIEMPO LABORAL',\n        'TIPO DE VINCULACI\u00d3N',\n        'ORIGEN VINCULACI\u00d3N',\n        'NIVEL ACAD\u00c9MICO',\n        'ESPECIALIDAD',\n        'FUENTE DE RECURSOS',\n        'SALARIO',\n        'USUARIO',\n        ]]\n\n    # Retorna el DataFrame procesado.\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():\n    # Obtener los datos de SharePoint para los docentes\n    df_cede_Docentes = obtener_sharepoint_docentes()\n    # Procesar los datos obtenidos de SharePoint\n    df_cede_Docentes = procesar_cede_Docentes(df_cede_Docentes)\n    # Mostrar las primeras filas del DataFrame procesado\n    df_cede_Docentes.head()\n    # Actualizar los datos procesados de vuelta en SharePoint\n\n    # Decorar la funci\u00f3n `actualizar_sharepoint_procesado` con `log_step_decorator` para registrar el paso\n    actualizar_sharepoint_func = log_step_decorator('actualizar_sharepoint_procesado')(actualizar_sharepoint_procesado)\n\n    # Llamar a la funci\u00f3n decorada para actualizar los datos procesados en SharePoint\n    actualizar_sharepoint_func(df_cede_Docentes, 'cede_Docentes')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/","title":"cede_02 procesar_Dise\u00f1o_Curricular","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport re\nimport pandas as pd\nimport openpyxl\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, extract_date, obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/#procesar_diseno_curricular","title":"procesar_diseno_curricular","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de dise\u00f1o curricular almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. </p> <p>La funci\u00f3n <code>procesar_diseno_curricular</code> abre un archivo de Excel, procesa cada hoja del libro, identifica las tablas de datos basadas en un encabezado espec\u00edfico, y extrae las filas relevantes. Los datos extra\u00eddos se almacenan en un <code>DataFrame</code> de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_dise\u00f1o_curricular</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica el archivo m\u00e1s reciente basado en la fecha en su nombre, y elimina los archivos m\u00e1s antiguos. Luego, carga el archivo m\u00e1s reciente y lo procesa utilizando la funci\u00f3n  <code>procesar_diseno_curricular</code>. Se asegura de que no haya valores nulos en la columna <code>Nombre Modulo</code> antes de filtrar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Adem\u00e1s, se realiza una comprobaci\u00f3n temporal de la subida de archivos a una carpeta espec\u00edfica en SharePoint.</p> <pre><code>@log_step_decorator('procesar_cede_Dise\u00f1o_Curricular')\ndef procesar_diseno_curricular(file_path):\n    # Abrir el archivo de Excel con openpyxl\n    wb = openpyxl.load_workbook(file_path, data_only=True)\n    all_data = []\n\n    for sheet_name in wb.sheetnames:\n        sheet = wb[sheet_name]\n        sheet_data = []\n        header_row = None\n        registro_num = 0  # Contador para el n\u00famero de registro\n\n        for row_idx, row in enumerate(sheet.iter_rows(values_only=True), start=1):  # row_idx comienza en 1\n            if row[0] == \"C\u00f3digo \":  # Identificar el inicio de la tabla\n                header_row = row\n                header_info = sheet.cell(row=row_idx - 3, column=1).value  # Fila [C\u00f3digo - 2]\n                registro_num = 0  # Reiniciar el n\u00famero de registro\n                continue\n\n            empty_row_count = 0  # Contador de filas vac\u00edas consecutivas\n\n            if header_row and row[0] is None:\n                empty_row_count += 1\n                if empty_row_count &gt;= 10:  # Si hay 10 filas vac\u00edas consecutivas, hacer break\n                    break\n                continue\n            else:\n                empty_row_count = 0  # Reiniciar el contador si se encuentra una fila no vac\u00eda\n\n            if row[0] == \"C\u00f3digo \":  # Identificar el inicio de una nueva tabla\n                header_row = row\n                header_info = sheet.cell(row=row_idx - 3, column=1).value  # Fila [C\u00f3digo - 2]\n                registro_num = 0  # Reiniciar el n\u00famero de registro\n                continue\n\n            if header_row:\n                # Incrementar el n\u00famero de registro\n                registro_num += 1\n                # Seleccionar solo las columnas relevantes\n                data_row = {\n                    \"Registro\": registro_num,  # Agregar n\u00famero de registro\n                    \"Programa (Pensum)\": header_info, \n                    \"C\u00f3digo\": row[0],\n                    \"Nombre Modulo\": row[1],\n                    \"Abreviaci\u00f3n\": row[5],\n                    \"Nivel\": row[7],\n                    \"Intensidad Horaria\": row[9],\n                    \"Intensidad Horaria Semanal\": row[10],\n                    \"No Cr\u00e9ditos\": row[12],\n                }\n                sheet_data.append(data_row)\n\n        # Combinar los datos de cada hoja\n        if sheet_data:\n            all_data.extend(sheet_data)\n\n    # Crear un DataFrame final con todos los datos procesados\n    df = pd.DataFrame(all_data)\n    return df\n\n@log_step_decorator('obtener_sharepoint_dise\u00f1o_curricular')\ndef obtener_sharepoint_dise\u00f1o_curricular():\n    folder_url = etl_to_folder_url.get('cede_Dise\u00f1o_Curricular', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Dise\u00f1o_Curricular_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Dise\u00f1o_Curricular_*.xlsx' en la carpeta.\")\n        return None\n\n    # Expresi\u00f3n regular para extraer la fecha del nombre del archivo\n    date_pattern = re.compile(r'Dise\u00f1o_Curricular_(\\d{2})_(\\d{2})_(\\d{4})\\.xlsx')\n\n    # Encontrar el archivo con la fecha m\u00e1s reciente\n    try:\n        latest_file = max(files, key=lambda f: extract_date(f,date_pattern))\n    except ValueError:\n        logger.error(\"No se pudo encontrar un archivo con fecha v\u00e1lida.\")\n        return None\n\n    # Eliminar todos los archivos excepto el m\u00e1s reciente\n    for file in files:\n        if file != latest_file:\n            os.remove(file)\n\n    logger.info(f\"El archivo m\u00e1s reciente es: {latest_file}\")\n    # Ruta del archivo m\u00e1s reciente descargado\n    df = procesar_diseno_curricular(latest_file)\n\n    # Asegurar que no hay valores nulos en \"Nombre Modulo\" antes de filtrar\n    if \"Nombre Modulo\" in df.columns:\n        df = df.dropna(subset=[\"Nombre Modulo\"])\n    else:\n        logger.warning(\"La columna 'Nombre Modulo' no existe en el DataFrame procesado.\")\n\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = []\n    renombres = {\n            'Programa (Pensum)':'PROGRAMA',\n            'C\u00f3digo':'COD_MODULO',\n            'Nombre Modulo':'MODULO',\n            'Nivel':'SEMESTRE',\n            'Intensidad Horaria':'INTENSIDAD_HORARIA',\n            'Intensidad Horaria Semanal':'INTENSIDAD_HORARIA_SEMANAL',\n            'No Cr\u00e9ditos':'NO_CREDITOS'\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():\n    df_cede_Dise\u00f1o_Curricular = obtener_sharepoint_dise\u00f1o_curricular()\n    actualizar_sharepoint_procesado(df_cede_Dise\u00f1o_Curricular, 'cede_Dise\u00f1o_Curricular')\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/","title":"cede_03 procesar_listado_matriculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\nimport openpyxl\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/#procesar_listado_matriculas","title":"procesar_listado_matriculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de matr\u00edculas almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>procesar_listado_matriculas</code> abre un archivo de Excel, procesa cada hoja del libro, identifica las tablas de datos basadas en un encabezado espec\u00edfico, y extrae las filas relevantes. Los datos extra\u00eddos se almacenan en un <code>DataFrame</code> de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_listado_matriculas</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica el archivo m\u00e1s reciente basado en la fecha en su nombre, y elimina los archivos m\u00e1s antiguos. Luego, carga el archivo m\u00e1s reciente y lo procesa utilizando la funci\u00f3n <code>procesar_listado_matriculas</code>. Se asegura de que no haya valores nulos en la columna <code>Estudiante</code> antes de filtrar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Adem\u00e1s, se realiza una comprobaci\u00f3n temporal de la subida de archivos a una carpeta espec\u00edfica en SharePoint.</p> <pre><code>@log_step_decorator('procesar_listado_matriculas')\ndef procesar_listado_matriculas(file_path):\n    wb = openpyxl.load_workbook(file_path, data_only=True)\n    all_data = []\n\n    # Iterar sobre las hojas del archivo con \u00edndice\n    for sheet_idx, sheet_name in enumerate(wb.sheetnames):\n        sheet = wb[sheet_name]\n        sheet_data = []\n        header_row = None\n        registro_num = 0  # Contador para el n\u00famero de registro\n        empty_row_count = 0  # Contador de filas vac\u00edas consecutivas\n\n        for row_idx, row in enumerate(sheet.iter_rows(values_only=True), start=1):\n            if row[0] and row[0].strip() == \"Estudiante\":  # Detectar encabezado\n                header_row = row\n                _info = sheet.cell(row=row_idx - 3, column=1).value\n                if _info:\n                    header_info = _info\n                    registro_num = 0\n\n                # Analizar header_row y obtener los nombres de las columnas\n                if header_row:\n                    col_indices = {\n                        col_name.replace(\"\\n\", \" \"): idx\n                        for idx, col_name in enumerate(header_row)\n                        if col_name and col_name.replace(\"\\n\", \" \") in [\n                            \"Estudiante\", \"Identificaci\u00f3n\", \"Fecha Matr\u00edcula\",\n                            \"Tel\u00e9fono\", \"Celular\", \"Correo\", \"Nivel\", \"Estado\"\n                        ]\n                    }\n                continue\n\n            if header_row:\n                registro_num += 1                \n                # Validar si la fila tiene suficientes columnas\n                if row[0] is None:\n                    empty_row_count += 1\n                    if empty_row_count &gt;= 5:  \n                        break\n                    continue\n                elif row[0] == 'www.q10.com':\n                    break\n                else:\n                    empty_row_count = 0  # Reiniciar contador si se encuentra una fila v\u00e1lida\n\n                # Procesar datos\n\n                # Dividir la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n                identificacion = row[col_indices.get(\"Identificaci\u00f3n\", 1)]\n                tipo, numero = (None, None)  # Valores predeterminados en caso de error\n                if identificacion and \" \" in identificacion:\n                    tipo, numero = identificacion.split(\" \", 1)\n\n                data_row = {\n                    \"Hoja\": sheet_name,\n                    \"Registro\": registro_num,\n                    \"Sede - jornada - Programa\": header_info,\n                    \"Estudiante\": row[col_indices.get(\"Estudiante\", 0)],\n                    \"Tipo Identificaci\u00f3n\": tipo,\n                    \"Identificaci\u00f3n\": numero,\n                    \"Fecha Matr\u00edcula\": row[col_indices.get(\"Fecha Matr\u00edcula\", 2)],\n                    \"Tel\u00e9fono\": row[col_indices.get(\"Tel\u00e9fono\", 3)],\n                    \"Celular\": row[col_indices.get(\"Celular\", 4)],\n                    \"Correo\": row[col_indices.get(\"Correo\", 5)],\n                    \"Nivel\": row[col_indices.get(\"Nivel\", 6)],\n                    \"Estado\": row[col_indices.get(\"Estado\", 7)],\n                }\n                sheet_data.append(data_row)\n\n        # Combinar los datos de cada hoja\n        if sheet_data:\n            all_data.extend(sheet_data)\n\n    # Crear un DataFrame final con todos los datos procesados\n    df = pd.DataFrame(all_data)\n    df = df.dropna(subset=[\"Identificaci\u00f3n\"])  # Eliminar filas con identificaci\u00f3n nula\n    return df\n\n@log_step_decorator('obtener_sharepoint_listado_matriculas')\ndef obtener_sharepoint_listado_matriculas():\n    folder_url = etl_to_folder_url.get('cede_Listado_Matriculas', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Listado_Matriculas_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Listado_Matriculas_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        df_temp = procesar_listado_matriculas(file)\n        all_dfs.append(df_temp)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = ['Hoja','Registro']\n    #    'Sede - jornada - Programa',\n    renombres = {\n        'Estudiante': 'NOMBRE_ESTUDIANTE',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO',\n        'Identificaci\u00f3n':'DOCUMENTO_ESTUDIANTE',\n        'Fecha Matr\u00edcula':'FECHA_MATRICULA',\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'Correo':'CORREO',\n        'Nivel':'SEMESTRE',\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    # Remove dots from TIPO_DOCUMENTO\n    df['TIPO_DOCUMENTO'] = df['TIPO_DOCUMENTO'].str.replace('.', '', regex=False)\n\n    # Split column into SEDE, JORNADA, and PROGRAMA\n    df[['SEDE', 'JORNADA', 'PROGRAMA']] = df['SEDE - JORNADA - PROGRAMA'].str.extract(r'(\\w+ \\w+) (\\w+) - (.+)')\n\n    # Eliminar columna: 'SEDE - JORNADA - PROGRAMA'\n    df = df.drop(columns=['SEDE - JORNADA - PROGRAMA'])\n\n    #elimina de df los duplicados por las columnas 'Fecha Matr\u00edcula' y 'Identificaci\u00f3n'\n    df = df.drop_duplicates(subset=['FECHA_MATRICULA', 'DOCUMENTO_ESTUDIANTE'])\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Listado_Matriculas = obtener_sharepoint_listado_matriculas()\n    actualizar_sharepoint_procesado(df_cede_Listado_Matriculas, 'cede_Listado_Matriculas')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/","title":"cede_04 procesar_Ingresos","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado,get_data_range\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/#procesar_cede_ingresos","title":"procesar_cede_Ingresos","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de ingresos almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>procesar_cede_Ingresos</code>abre un archivo de Excel, procesa los datos eliminando filas y columnas innecesarias, y transforma los datos en un formato adecuado para su an\u00e1lisis. Los datos procesados se almacenan en un DataFrame de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_cede_Ingresos</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Ingresos_*.xlsx', y procesa cada archivo utilizando la funci\u00f3n <code>procesar_cede_Ingresos</code>. Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan y renombran columnas espec\u00edficas para limpiar y estandarizar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Este proceso asegura que los datos de ingresos est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>@log_step_decorator('procesar_cede_Ingresos')\ndef procesar_cede_Ingresos(file_path):\n\n    # Obtener rango de datos\n    try:\n        data = get_data_range(file_path, 0)\n    except Exception as e:\n        print(f\"Error: {e}\")\n\n    df_range = pd.DataFrame(data)\n    # Variable cargada \"df_range\" del estado del Kernel\n\n    # Remove rows from 0 to 8\n    df_range = df_range.drop(index=range(0, 9))\n\n    # Drop columns with all missing values\n    df_range = df_range.dropna(axis=1, how='all')\n    # Mostrar las primeras filas del DataFrame para verificar el contenido\n\n\n    df_range.reset_index(drop=True, inplace=True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    # Fill NaN in row 0 with values from row 2\n    df_range.iloc[0] = df_range.iloc[0].fillna(df_range.iloc[2])\n\n    #elimina las columnas 17,22,23\n    df_range = df_range.drop(columns=[17, 22, 23])\n\n\n    # Set first row as column names, enumerate duplicates\n    df_range.columns = df_range.iloc[0]\n    df_range = df_range[1:]\n\n    # Rename the second 'Valor' column to 'Valor_1'\n    df_range.columns = ['Valor_1' if (col == 'Valor' and idx == 1) else col for idx, col in enumerate(df_range.columns)]\n\n    # Filter column 'N\u00b0 Recibo' to keep non-null values\n    df_range = df_range[df_range['N\u00b0 Recibo'].notna()]\n\n    # Crear un diccionario para rastrear las columnas duplicadas y renombrarlas\n    columns = pd.Series(df_range.columns)\n    duplicates = columns[columns.duplicated()].unique()\n\n    # Crea un diccionario para rastrear las columnas duplicadas y renombrarlas adecuadamente\n    for dup in duplicates:\n        dup_indices = columns[columns == dup].index\n        for i, idx in enumerate(dup_indices):\n            if i != 0:\n                columns[idx] = f\"{dup}_{i}\"\n\n    # Asignar las nuevas columnas al DataFrame\n    df_range.columns = columns\n\n    # Reinicia el \u00edndice nuevamente\n    df_range.reset_index(drop=True, inplace=True)        \n\n    # Separar la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n    df_range[['Tipo Identificaci\u00f3n', 'Identificaci\u00f3n']] = df_range['Identificaci\u00f3n'].str.split(' ', expand=True)\n\n    # Separar la columna \"Concepto\" por \" - \"\n    df_range[['C\u00f3digo Concepto', 'Concepto']] = df_range['Concepto'].str.split(' - ', n=1, expand=True)    \n\n    df_range = df_range[['N\u00b0 Recibo', 'Fecha', 'Pagado por', 'Tipo Identificaci\u00f3n', 'Identificaci\u00f3n', 'Cajero', 'C\u00f3digo Concepto', 'Concepto', 'Valor', 'Nombre', 'Valor_1', 'Total Pagado']]\n\n    # Remove rows with None in 'Fecha' column\n    df_range = df_range[df_range['Fecha'].notna()]\n\n    return df_range\n\n\n@log_step_decorator('obtener_sharepoint_cede_Ingresos')\ndef obtener_sharepoint_cede_Ingresos():\n    folder_url = etl_to_folder_url.get('cede_Ingresos', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Ingresos_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Ingresos_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        df_temp = procesar_cede_Ingresos(file)\n        all_dfs.append(df_temp)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n\n    columnas_a_eliminar = ['Hoja','Registro']\n\n    renombres = {\n        'N\u00b0 Recibo':'NO_RECIBO',\n        'Fecha':'FECHA_CONTABLE',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO_PAGO',\n        'Identificaci\u00f3n':'DOCUMENTO_PAGO',\n        'C\u00f3digo Concepto':'ID_CONCEPTO',\n        'Valor':'VALOR_FACTURADO',\n        'Pagado por':'PAGADO_POR',\n        'Total Pagado':'VALOR_PAGADO'}\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n    # Variable cargada \"df\" del estado del Kernel\n    df['TIPO_DOCUMENTO_PAGO'] = df['TIPO_DOCUMENTO_PAGO'].str.replace('.', '', regex=False)\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_cede_Ingresos = obtener_sharepoint_cede_Ingresos()\n    actualizar_sharepoint_procesado(df_cede_cede_Ingresos, 'cede_Ingresos')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/","title":"cede_05 cede_Historico_Notas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado,procesar_excel_con_hojas\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/#cede_historico_notas","title":"cede_Historico_Notas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de notas hist\u00f3ricas almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>procesar_periodos</code> abre un archivo de Excel, procesa los datos eliminando filas y columnas innecesarias, y transforma los datos en un formato adecuado para su an\u00e1lisis. Los datos procesados se almacenan en un DataFrame de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_cede_Historico_Notas</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Historico_Notas_*.xlsx', y procesa cada archivo utilizando la funci\u00f3n <code>procesar_periodos</code>. Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan y renombran columnas espec\u00edficas para limpiar y estandarizar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Este proceso asegura que los datos de notas hist\u00f3ricas est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>@log_step_decorator('procesar_cede_Historico_Notas')\ndef procesar_corte(df, corte_nombre, columnas_a_eliminar, renombres):\n    df_corte = df[df['corte'] == corte_nombre].copy()\n    df_corte.reset_index(drop=True, inplace=True)\n    if not df_corte.empty:\n        df_corte = df_corte.drop(0).reset_index(drop=True)\n        df_corte.columns = [value if str(value).startswith('C') else col for col, value in zip(df_corte.columns, df_corte.iloc[0])]\n        df_corte = df_corte.drop(0).reset_index(drop=True)\n    df_corte = limpiar_columnas(df_corte, columnas_a_eliminar, renombres)\n    return df_corte\n\n@log_step_decorator('procesar_periodos')\ndef procesar_periodos(file_path):\n    resultado_df = procesar_excel_con_hojas(file_path)\n    df = resultado_df.copy()\n\n    # Crear diccionarios desde filas espec\u00edficas\n    _encabezados = resultado_df.iloc[3:7, [0, 2]].set_index(resultado_df.columns[0]).to_dict()[resultado_df.columns[2]]\n    dic_tempB = resultado_df.iloc[3:7, [7, 9]].set_index(resultado_df.columns[7]).to_dict()[resultado_df.columns[9]]\n    _encabezados.update(dic_tempB)\n\n    # Limpieza inicial del DataFrame\n    columnas_a_eliminar = ['Unnamed: 0', 'Cedesarrollo - Comfenalco']\n    renombres_iniciales = {'Unnamed: 1': 'Estudiante', 'Unnamed: 3': 'referencia'}\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres_iniciales)\n\n    # Crear columna 'corte' con valores que contienen 'Corte'\n    df['corte'] = df['referencia'].apply(lambda x: x if 'Corte' in str(x) else None).ffill()\n\n    # Procesar Primer y Tercer Corte\n    columnas_a_eliminar_corte = ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12']\n    df_tercer_corte = procesar_corte(df, 'Tercer Corte', columnas_a_eliminar_corte, {'Unnamed: 7': 'Nota Acum.', 'Unnamed: 8': 'Inasis Acum.'})\n    df_primer_corte = procesar_corte(df, 'Primer Corte', columnas_a_eliminar_corte, {})\n\n    # Unir Primer y Tercer Corte por 'Estudiante'\n    df_merged = pd.merge(df_primer_corte, df_tercer_corte, on='Estudiante', how='inner')\n\n    # Agregar columnas con el diccionario _encabezados\n    for key, value in _encabezados.items():\n        df_merged[key] = value\n\n    return df_merged\n\n\n@log_step_decorator('obtener_sharepoint_cede_Historico_Notas')\ndef obtener_sharepoint_cede_Historico_Notas():\n    folder_url = etl_to_folder_url.get('cede_Historico_Notas', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Historico_Notas_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Historico_Notas_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [procesar_periodos(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # Variable cargada \"df_cede_Historico_Notas\" del estado del Kernel\n\n    # Filtrar filas seg\u00fan la columna: 'Estudiante'\n    df = df[df['Estudiante'].notna()]\n\n    # Reset index of DataFrame\n    df = df.reset_index(drop=True)\n\n    # Eliminate columns with all NaN values\n    df = df.dropna(axis=1, how='all')\n\n    # Split \"Sede - jornada:\" into \"SEDE\" and \"JORNADA\"\n    df[['SEDE', 'JORNADA']] = df['Sede - jornada: '].str.split(' - ', expand=True)\n    campos = df.columns.tolist()\n    # guardar_diccionario(campos,'campos')\n    renombrar = {\n        'Estudiante':'NOMBRE_ESTUDIANTE',\n        'referencia':'PRIMER_CORTE',\n        'CP C1-E1':'PRIMER_CORTE_CP1',\n        'CP C1-E2':'PRIMER_CORTE_CP2',\n        'CT C1-E1':'PRIMER_CORTE_CT1',\n        'CT C1-E2':'PRIMER_CORTE_CT2',\n        'Unnamed: 8':'SEGUNDO_CORTE',\n        'CP C2-E1':'SEGUNDO_CORTE_CP1',\n        'CP C2-E2':'SEGUNDO_CORTE_CP2',\n        'CT C2-E1':'SEGUNDO_CORTE_CT1',\n        'CT C2-E2':'SEGUNDO_CORTE_CT2',\n        'Unnamed: 13_x':'TERCER_CORTE',\n        'CP C3-E1':'TERCER_CORTE_CP1',\n        'CP C3-E2':'TERCER_CORTE_CP2',\n        'CT C3-E1':'TERCER_CORTE_CT1',\n        'CT C3-E2':'TERCER_CORTE_CT2',\n        'Nota Acum.':'NOTA_FINAL',\n        'M\u00f3dulo: ':'MODULO',\n        'Curso: ':'CURSO',\n        'Fecha inicio: ':'FECHA_INICIO',\n        'Per\u00edodo: ':'PERIODO_ACADEMICO',\n        'Programa: ':'PROGRAMA_ACADEMICO',\n        'Docente: ':'NOMBRE_DOCENTE',\n        'Inasis Acum.':'INASISTENCIAS_ACUMULADAS',\n        'Fecha fin: ':'FECHA_FIN',\n    }\n    eliminar = ['Sede - jornada: ','corte_x','corte_y']\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Historico_Notas = obtener_sharepoint_cede_Historico_Notas()\n    actualizar_sharepoint_procesado(df_cede_Historico_Notas, 'cede_Historico_Notas')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/","title":"cede_06 cede_Egresados_Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,replace_values_df,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/#cede_egresados_graduados","title":"cede_Egresados_Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de egresados y graduados almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n </p> <p>obtener_sharepoint_cede_Egresados_Graduados</p> <p>descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Graduados_*.xlsx', y procesa cada archivo utilizando pandas para leer los datos.</p> <p>Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan columnas espec\u00edficas y se reemplazan valores en el DataFrame. Finalmente, se renombran las columnas para limpiar y estandarizar los datos.</p> <p>Este proceso asegura que los datos de egresados y graduados est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_cede_Egresados_Graduados():\n    folder_url = etl_to_folder_url.get('cede_Egresados_Graduados', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Graduados_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Graduados_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # Eliminar columna: 'Grupo'\n    df = df.drop(columns=['Grupo'])\n    df = replace_values_df(df)\n    renombrar = {\n        'C\u00f3digo de matr\u00edcula':'ID_MATRICULA',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n':'DOCUMENTO',\n        'Grupo Sisben':'GRUPO',\n        'Nivel de formaci\u00f3n':'NIVEL_FORMACION',\n        'Ocupaci\u00f3n':'OCUPACION',\n        'Sede':'SEDE',\n        'Jornada':'JORNADA',\n        'Programa':'PROGRAMA',\n        'Per\u00edodo':'PERIODO_ACADEMICO',\n        'Nivel':'SEMESTRE',\n        'Fecha graduado':'FECHA_GRADUADO',\n        'Acta graduado':'ACTA_GRADUADO',\n        'Folio graduado':'FOLIO_GRADUADO',\n        'Diploma graduado':'DIPLOMA_GRADUADO'    \n    }\n    eliminar = []\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    df = df[['ID_MATRICULA',\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'GRUPO',\n        'NIVEL_FORMACION',\n        'OCUPACION',\n        'SEDE',\n        'JORNADA',\n        'PROGRAMA',\n        'PERIODO_ACADEMICO',\n        'SEMESTRE',\n        'FECHA_GRADUADO',\n        'ACTA_GRADUADO',\n        'FOLIO_GRADUADO',\n        'DIPLOMA_GRADUADO',\n        'ZONA',\n        '\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N']]\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Egresados_Graduados = log_step_decorator(\"Obtener y procesar Egresados Graduados\")(obtener_sharepoint_cede_Egresados_Graduados)()    \n    actualizar_sharepoint_procesado(df_cede_Egresados_Graduados, 'cede_Egresados_Graduados')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/","title":"cede_07 Cancelados Desertores","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado,procesar_excel_con_hojas,actualizar_columna_programa\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/#obtener_sharepoint_cede_cancelados_desertores","title":"obtener_sharepoint_cede_Cancelados_Desertores","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de cancelados y desertores almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_cede_Cancelados_Desertores</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Cancelados_*.xlsx', y procesa cada archivo utilizando pandas para leer los datos.</p> <p>Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan columnas espec\u00edficas y se reemplazan valores en el DataFrame. Finalmente, se renombran las columnas para limpiar y estandarizar los datos.</p> <p>Este proceso asegura que los datos de cancelados y desertores est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_cede_Cancelados_Desertores():\n    folder_url = etl_to_folder_url.get('cede_Cancelados_Desertores', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Cancelados_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Cancelados_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        _df = procesar_excel_con_hojas(file)\n        all_dfs.append(_df)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n    return df\n\n@log_step_decorator(\"Procesar Cancelados Desertores\")\ndef procesar_Cancelados_Desertores(df_cede_Cancelados_Desertores):\n    # Variable cargada \"df_cede_Cancelados_Desertores\" del estado del Kernel\n\n    df_cede_Cancelados_Desertores.columns = [f'Columna_{i}' for i in range(len(df_cede_Cancelados_Desertores.columns))]\n\n\n    # Iterate over Columna_11 from row 8\n    for index, row in df_cede_Cancelados_Desertores.iloc[8:].iterrows():\n        if pd.isna(row['Columna_11']):\n            if not pd.isna(row['Columna_12']):\n                df_cede_Cancelados_Desertores.at[index, 'Columna_11'] = row['Columna_12']\n                df_cede_Cancelados_Desertores.at[index, 'Columna_12'] = row['Columna_14']\n\n    df_cede_Cancelados_Desertores['Columna_5'] = df_cede_Cancelados_Desertores['Columna_5'].combine_first(df_cede_Cancelados_Desertores['Columna_6'])\n    df_cede_Cancelados_Desertores['Columna_7'] = df_cede_Cancelados_Desertores['Columna_7'].combine_first(df_cede_Cancelados_Desertores['Columna_8'])\n    df_cede_Cancelados_Desertores['Columna_9'] = df_cede_Cancelados_Desertores['Columna_9'].combine_first(df_cede_Cancelados_Desertores['Columna_10'])\n\n\n    df_cede_Cancelados_Desertores = actualizar_columna_programa(\n        df_cede_Cancelados_Desertores, \n        columna_condicional='Columna_0', \n        columna_origen='Columna_0', \n        columna_destino='Sede',\n        texto_filtro='Sede'\n    )\n\n    # Variable cargada \"df_cede_Cancelados_Desertores\" del estado del Kernel\n\n    # Filtrar filas seg\u00fan la columna: 'Columna_0'\n    df_cede_Cancelados_Desertores = df_cede_Cancelados_Desertores[df_cede_Cancelados_Desertores['Columna_0'].notna()]\n\n    # Filtrar filas seg\u00fan la columna: 'Columna_3'\n    df_cede_Cancelados_Desertores = df_cede_Cancelados_Desertores[df_cede_Cancelados_Desertores['Columna_3'].notna()]\n\n    # Fill empty Columna_12 with Columna_13 values\n    df_cede_Cancelados_Desertores['Columna_12'] = df_cede_Cancelados_Desertores['Columna_12'].fillna(df_cede_Cancelados_Desertores['Columna_13'])\n\n    # Separar la columna \"Sede\" en SEDE y JORNADA\n    df_cede_Cancelados_Desertores[['SEDE', 'JORNADA']] = df_cede_Cancelados_Desertores['Sede'].str.split(' - ', expand=True)\n\n    # Filtrar filas seg\u00fan la columna: 'PROGRAMA'\n    df_cede_Cancelados_Desertores = df_cede_Cancelados_Desertores[df_cede_Cancelados_Desertores['Columna_0'] != \"Programa\"]\n\n\n    eliminar = [\n        'Columna_2',\n        'Columna_4',\n        'Columna_6',\n        'Columna_8',\n        'Columna_10',\n        'Columna_13',\n        'Columna_14',\n        'Columna_15',\n        'Sede',\n        'Columna_1',\n        'Columna_5'\n    ]\n    renombrar = {\n        'Columna_0':'PROGRAMA',\n        'Columna_3':'NOMBRE_ESTUDIANTE',\n        'Columna_7':'FECHA',\n        'Columna_9':'TIPO',\n        'Columna_11':'CAUSA',\n        'Columna_12':'OBSERVACIONES',\n        'Columna_5':'SEDE',\n    }\n    df_cede_Cancelados_Desertores = limpiar_columnas(df_cede_Cancelados_Desertores, eliminar, renombrar,True)\n\n\n    return df_cede_Cancelados_Desertores\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Cancelados_Desertores = log_step_decorator(\"Obtener Cancelados Desertores\")(obtener_sharepoint_cede_Cancelados_Desertores)()    \n    df_cede_Cancelados_Desertores = procesar_Cancelados_Desertores(df_cede_Cancelados_Desertores)    \n    actualizar_sharepoint_procesado(df_cede_Cancelados_Desertores, 'cede_Cancelados_Desertores')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/","title":"emp_01 Docentes Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\n\nimport logging\nimport os\nimport sys\nimport glob\nimport re\nimport datetime\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,replace_values_df,limpiar_carpeta, obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/#obtener_sharepoint_docentes","title":"obtener_sharepoint_docentes","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de docentes almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_docentes</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Docentes_*.xlsx', y selecciona el archivo m\u00e1s reciente basado en la fecha incluida en el nombre del archivo.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia. Luego, descarga los archivos desde SharePoint y filtra el archivo m\u00e1s reciente utilizando una expresi\u00f3n regular para extraer la fecha del nombre del archivo. Los archivos m\u00e1s antiguos se eliminan para mantener la carpeta organizada.</p> <p>El archivo m\u00e1s reciente se lee en un <code>DataFrame</code> de pandas, y se registra el contenido del archivo para su seguimiento. La funci\u00f3n <code>procesar_cede_Docentes</code> se encarga de reemplazar valores en el DataFrame y eliminar espacios en blanco de los nombres y apellidos, asegurando que los datos est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_docentes():\n    folder_url = etl_to_folder_url.get('emp_Docentes', \"URL por defecto si no se encuentra el valor de etl\")\n    if not os.path.exists(_folder):\n        os.makedirs(_folder)\n    else:\n        limpiar_carpeta(_folder)\n\n    obtener_sharepoint(folder_url,_folder)\n    files = glob.glob(os.path.join(_folder, \"Docentes_*.xlsx\"))\n\n    date_pattern = re.compile(r'Docentes_(\\d{2})_(\\d{2})_(\\d{4})\\.xlsx')\n\n    def extract_date(file_name):\n        match = date_pattern.search(file_name)\n        if match:\n            day, month, year = map(int, match.groups())\n            return datetime.date(year, month, day)\n        return None\n    latest_file = max(files, key=lambda f: extract_date(f))\n\n    for file in files:\n        if file != latest_file:\n            os.remove(file)\n\n    logger.info(f\"El archivo m\u00e1s reciente es: {latest_file}\")\n\n\n    df = pd.read_excel(latest_file)\n\n    logger.info(f\"Contenido del archivo {latest_file}:\")\n    return df\n\n\n@log_step_decorator('procesar_cede_Docentes')\ndef procesar_cede_Docentes(df):\n    # Reemplaza valores en el DataFrame seg\u00fan sea necesario.\n    df = replace_values_df(df)\n\n    # Elimina espacios en blanco de los nombres y apellidos.\n    df['Primer nombre'] = df['Primer nombre'].str.strip()\n    df['Segundo nombre'] = df['Segundo nombre'].str.strip()\n    df['Primer apellido'] = df['Primer apellido'].str.strip()\n    df['Segundo apellido'] = df['Segundo apellido'].str.strip()\n\n    # Concatena los nombres y apellidos en una sola columna 'NOMBRE', omitiendo los vac\u00edos.\n    df['NOMBRE'] = df[['Primer nombre', 'Segundo nombre', 'Primer apellido', 'Segundo apellido']].apply(lambda x: ' '.join(x.dropna().astype(str)).upper(), axis=1)\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = []\n    renombres = {\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'E-mail':'CORREO',\n        'Direcci\u00f3n':'DIRECCION',\n        'C\u00e9dula':'CEDULA',\n        'Municipio direcci\u00f3n':'CIUDAD',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n': 'DOCUMENTO',\n        'Fecha de nacimiento':'FECHA_NACIMIENTO',\n        'Sexo':'GENERO'\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n\n    # Selecciona y reordena las columnas del DataFrame.\n    df = df[[\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'NOMBRE',\n        'PRIMER NOMBRE',\n        'SEGUNDO NOMBRE',\n        'PRIMER APELLIDO',\n        'SEGUNDO APELLIDO',\n        'TELEFONO',\n        'CELULAR',\n        'CORREO',\n        'DIRECCION',\n        'CIUDAD',\n        'FECHA_NACIMIENTO',\n        'MUNICIPIO EXPEDICI\u00d3N',\n        'FECHA DE EXPEDICI\u00d3N',\n        'GENERO',\n        'MUNICIPIO NACIMIENTO',\n        'TIPO DE SANGRE',\n        'ESCALAF\u00d3N',\n        'ESTADO CIVIL',\n        'CALIDAD DE DESEMPE\u00d1O',\n        'ESTADO',\n        'FECHA DE INGRESO',\n        'TIEMPO LABORAL',\n        'TIPO DE VINCULACI\u00d3N',\n        'ORIGEN VINCULACI\u00d3N',\n        'NIVEL ACAD\u00c9MICO',\n        'ESPECIALIDAD',\n        'FUENTE DE RECURSOS',\n        'SALARIO',\n        'USUARIO',\n        ]]\n\n    # Retorna el DataFrame procesado.\n    # Remove empty columns\n    df = df.dropna(axis=1, how='all')\n    return df\n\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Docentes = obtener_sharepoint_docentes()\n    df_emp_Docentes = procesar_cede_Docentes(df_emp_Docentes)\n    actualizar_sharepoint_procesado(df_emp_Docentes, 'emp_Docentes')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/","title":"emp_02 Listado Matr\u00edculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\nimport openpyxl\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/#obtener_sharepoint_listado_matriculas","title":"obtener_sharepoint_listado_matriculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de matr\u00edculas almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_listado_matriculas</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Listado_Matriculas_*.xlsx', y selecciona el archivo m\u00e1s reciente basado en la fecha incluida en el nombre del archivo.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia. Luego, descarga los archivos desde SharePoint y filtra el archivo m\u00e1s reciente utilizando una expresi\u00f3n regular para extraer la fecha del nombre del archivo. Los archivos m\u00e1s antiguos se eliminan para mantener la carpeta organizada.</p> <p>El archivo m\u00e1s reciente se lee en un <code>DataFrame</code> de pandas, y se registran las columnas del archivo para su seguimiento. La funci\u00f3n <code>limpiar_columnas</code> se encarga de eliminar y renombrar columnas espec\u00edficas para limpiar y estandarizar los datos. Adem\u00e1s, se eliminan los puntos de la columna <code>TIPO_DOCUMENTO</code>, se dividen los valores de la columna <code>SEDE - JORNADA - PROGRAMA</code> en tres columnas separadas (<code>SEDE</code>, <code>JORNADA</code> y <code>PROGRAMA</code>), y se eliminan duplicados basados en las columnas <code>FECHA_MATRICULA</code> y <code>DOCUMENTO_ESTUDIANTE</code>.</p> <p>Finalmente, si la variable de control <code>ejecutar</code> est\u00e1 activada, se llama a la funci\u00f3n <code>actualizar_sharepoint_procesado</code> para actualizar los datos procesados de vuelta en SharePoint, asegurando que los datos de matr\u00edculas est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def procesar_listado_matriculas(file_path):\n    wb = openpyxl.load_workbook(file_path, data_only=True)\n    all_data = []\n\n    # Iterar sobre las hojas del archivo con \u00edndice\n    for sheet_idx, sheet_name in enumerate(wb.sheetnames):\n        sheet = wb[sheet_name]\n        sheet_data = []\n        header_row = None\n        registro_num = 0  # Contador para el n\u00famero de registro\n        empty_row_count = 0  # Contador de filas vac\u00edas consecutivas\n\n        for row_idx, row in enumerate(sheet.iter_rows(values_only=True), start=1):\n            if row[0] and row[0].strip() == \"Estudiante\":  # Detectar encabezado\n                header_row = row\n                _info = sheet.cell(row=row_idx - 3, column=1).value\n                if _info:\n                    header_info = _info\n                    registro_num = 0\n\n                # Analizar header_row y obtener los nombres de las columnas\n                if header_row:\n                    col_indices = {\n                        col_name.replace(\"\\n\", \" \"): idx\n                        for idx, col_name in enumerate(header_row)\n                        if col_name and col_name.replace(\"\\n\", \" \") in [\n                            \"Estudiante\", \"Identificaci\u00f3n\", \"Fecha Matr\u00edcula\",\n                            \"Tel\u00e9fono\", \"Celular\", \"Correo\", \"Nivel\", \"Estado\"\n                        ]\n                    }\n                continue\n\n            if header_row:\n                registro_num += 1                \n                # Validar si la fila tiene suficientes columnas\n                if row[0] is None:\n                    empty_row_count += 1\n                    if empty_row_count &gt;= 5:  \n                        break\n                    continue\n                elif row[0] == 'www.q10.com':\n                    break\n                else:\n                    empty_row_count = 0  # Reiniciar contador si se encuentra una fila v\u00e1lida\n\n                # Procesar datos\n\n                # Dividir la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n                identificacion = row[col_indices.get(\"Identificaci\u00f3n\", 1)]\n                tipo, numero = (None, None)  # Valores predeterminados en caso de error\n                if identificacion and \" \" in identificacion:\n                    tipo, numero = identificacion.split(\" \", 1)\n\n                data_row = {\n                    \"Hoja\": sheet_name,\n                    \"Registro\": registro_num,\n                    \"Sede - jornada - Programa\": header_info,\n                    \"Estudiante\": row[col_indices.get(\"Estudiante\", 0)],\n                    \"Tipo Identificaci\u00f3n\": tipo,\n                    \"Identificaci\u00f3n\": numero,\n                    \"Fecha Matr\u00edcula\": row[col_indices.get(\"Fecha Matr\u00edcula\", 2)],\n                    \"Tel\u00e9fono\": row[col_indices.get(\"Tel\u00e9fono\", 3)],\n                    \"Celular\": row[col_indices.get(\"Celular\", 4)],\n                    \"Correo\": row[col_indices.get(\"Correo\", 5)],\n                    \"Nivel\": row[col_indices.get(\"Nivel\", 6)],\n                    \"Estado\": row[col_indices.get(\"Estado\", 7)],\n                }\n                sheet_data.append(data_row)\n\n        # Combinar los datos de cada hoja\n        if sheet_data:\n            all_data.extend(sheet_data)\n\n    # Crear un DataFrame final con todos los datos procesados\n    df = pd.DataFrame(all_data)\n    df = df.dropna(subset=[\"Identificaci\u00f3n\"])  # Eliminar filas con identificaci\u00f3n nula\n    return df\n\n@log_step_decorator(\"obtener_sharepoint_listado_matriculas\")\ndef obtener_sharepoint_listado_matriculas():\n    folder_url = etl_to_folder_url.get('emp_Listado_Matriculas', \"URL por defecto si no se encuentra el valor de etl\")\n    # obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Listado_Matriculas_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Listado_Matriculas_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        df_temp = log_step_decorator(f\"Procesando {file}\")(procesar_listado_matriculas)(file)\n        all_dfs.append(df_temp)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = ['Hoja','Registro']\n    #    'Sede - jornada - Programa',\n    renombres = {\n        'Estudiante': 'NOMBRE_ESTUDIANTE',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO',\n        'Identificaci\u00f3n':'DOCUMENTO_ESTUDIANTE',\n        'Fecha Matr\u00edcula':'FECHA_MATRICULA',\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'Correo':'CORREO',\n        'Nivel':'SEMESTRE',\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres, True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    # Remove dots from TIPO_DOCUMENTO\n    df['TIPO_DOCUMENTO'] = df['TIPO_DOCUMENTO'].str.replace('.', '', regex=False)\n\n    # Split column into SEDE, JORNADA, and PROGRAMA\n    df[['SEDE', 'JORNADA', 'PROGRAMA']] = df['SEDE - JORNADA - PROGRAMA'].str.extract(r'(\\w+ \\w+) (\\w+) - (.+)')\n\n    # Eliminar columna: 'SEDE - JORNADA - PROGRAMA'\n    df = df.drop(columns=['SEDE - JORNADA - PROGRAMA'])\n\n    #elimina de df los duplicados por las columnas 'Fecha Matr\u00edcula' y 'Identificaci\u00f3n'\n    df = df.drop_duplicates(subset=['FECHA_MATRICULA', 'DOCUMENTO_ESTUDIANTE'])\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_listado_matriculas = obtener_sharepoint_listado_matriculas()\n    if df_listado_matriculas is not None:\n        # elimina de df los duplicados por las columnas 'Fecha Matr\u00edcula' y 'Identificaci\u00f3n'\n        actualizar_sharepoint_procesado(df_listado_matriculas, 'emp_Listado_Matriculas')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/","title":"emp_03 Preinscritos Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\n\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/#procesar_preinscritos","title":"procesar_preinscritos","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de preinscritos almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Preinscritos</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Preinscritos_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan las filas duplicadas basadas en las columnas <code>N\u00famero de identificaci\u00f3n</code> y <code>Fecha</code>, asegurando que los datos est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <p>La funci\u00f3n <code>procesar_preinscritos</code> se encarga de limpiar y transformar los datos. Primero, elimina los espacios en blanco de los nombres y apellidos. Luego, concatena los nombres y apellidos en una sola columna <code>NOMBRE</code>, omitiendo los valores vac\u00edos y convirtiendo todo a may\u00fasculas. Adem\u00e1s, divide la columna <code>Sede - jornada</code> en dos columnas separadas (<code>SEDE</code> y <code>JORNADA</code>). Finalmente, define las columnas a eliminar para limpiar y estandarizar los datos.</p> <pre><code>def obtener_sharepoint_emp_Preinscritos():\n    folder_url = etl_to_folder_url.get('emp_Preinscritos', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Preinscritos_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Preinscritos_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # elimina las filas duplicadas por 'N\u00famero de identificaci\u00f3n' y Fecha\n    df = df.drop_duplicates(subset=['N\u00famero de identificaci\u00f3n', 'Fecha'])\n    return df\n\ndef procesar_preinscritos(df):\n    # Elimina espacios en blanco de los nombres y apellidos.\n    df['Primer nombre'] = df['Primer nombre'].str.strip()\n    df['Segundo nombre'] = df['Segundo nombre'].str.strip()\n    df['Primer apellido'] = df['Primer apellido'].str.strip()\n    df['Segundo apellido'] = df['Segundo apellido'].str.strip()\n\n    # Concatena los nombres y apellidos en una sola columna 'NOMBRE', omitiendo los vac\u00edos.\n    df['NOMBRE'] = df[['Primer nombre', 'Segundo nombre', 'Primer apellido', 'Segundo apellido']].apply(lambda x: ' '.join(x.dropna().astype(str)).upper(), axis=1)\n    # Split column into SEDE and JORNADA\n    df[['SEDE', 'JORNADA']] = df['Sede - jornada'].str.extract(r'(.+) - (.+)')\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = [\n        'Primer nombre',\n        'Segundo nombre',\n        'Primer apellido',\n        'Segundo apellido',\n        'Sexo',\n        'Tel\u00e9fono',\n        'Celular',\n        'Correo electr\u00f3nico',\n        'Fecha de nacimiento',\n        'Direcci\u00f3n',\n        'Lugar de residencia',\n        'Sede - jornada',\n        'Barrio',    ]\n    renombres = {\n        'N\u00famero de identificaci\u00f3n':'DOCUMENTO_ESTUDIANTE',\n        'C\u00f3digo de referencia':'REFERENCIA',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)    \n    # Remove dots from TIPO_DOCUMENTO\n    df['TIPO_DOCUMENTO'] = df['TIPO_DOCUMENTO'].str.replace('.', '', regex=False)\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Preinscritos = obtener_sharepoint_emp_Preinscritos()\n    df_emp_Preinscritos = procesar_preinscritos(df_emp_Preinscritos)\n    actualizar_sharepoint_procesado(df_emp_Preinscritos, 'emp_Preinscritos')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/","title":"emp_04 Egresados Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,replace_values_df,obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/#obtener_sharepoint_emp_egresados_graduados","title":"obtener_sharepoint_emp_Egresados_Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de egresados y graduados almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Egresados_Graduados</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Graduados_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se elimina la columna <code>Grupo</code> y se reemplazan valores en el <code>DataFrame</code> utilizando la funci\u00f3n <code>replace_values_df</code>. Finalmente, se renombran las columnas para limpiar y estandarizar los datos utilizando la funci\u00f3n <code>limpiar_columnas</code>, asegurando que los datos est\u00e9n estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_emp_Egresados_Graduados():\n    folder_url = etl_to_folder_url.get('emp_Egresados_Graduados', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Graduados_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Graduados_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # Eliminar columna: 'Grupo'\n    df = df.drop(columns=['Grupo'])\n    df = replace_values_df(df)\n    renombrar = {\n        'C\u00f3digo de matr\u00edcula':'ID_MATRICULA',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n':'DOCUMENTO',\n        'Grupo Sisben':'GRUPO',\n        'Nivel de formaci\u00f3n':'NIVEL_FORMACION',\n        'Ocupaci\u00f3n':'OCUPACION',\n        'Sede':'SEDE',\n        'Jornada':'JORNADA',\n        'Programa':'PROGRAMA',\n        'Per\u00edodo':'PERIODO_ACADEMICO',\n        'Nivel':'SEMESTRE',\n        'Fecha graduado':'FECHA_GRADUADO',\n        'Acta graduado':'ACTA_GRADUADO',\n        'Folio graduado':'FOLIO_GRADUADO',\n        'Diploma graduado':'DIPLOMA_GRADUADO'    \n    }\n    eliminar = []\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    df = df[['ID_MATRICULA',\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'GRUPO',\n        'NIVEL_FORMACION',\n        'OCUPACION',\n        'SEDE',\n        'JORNADA',\n        'PROGRAMA',\n        'PERIODO_ACADEMICO',\n        'SEMESTRE',\n        'FECHA_GRADUADO',\n        'ACTA_GRADUADO',\n        'FOLIO_GRADUADO',\n        'DIPLOMA_GRADUADO',\n        'ZONA',\n        '\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N']]\n\n    # Remove empty columns\n    df = df.dropna(axis=1, how='all')\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Egresados_Graduados = obtener_sharepoint_emp_Egresados_Graduados()\n    actualizar_sharepoint_procesado(df_emp_Egresados_Graduados, 'emp_Egresados_Graduados')\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>2024-12-08 21:02:57,281 - INFO - \u001b[92mIniciando: ETL\u001b[0m\n2024-12-08 21:02:57,287 - INFO - \u001b[92mIniciando: Limpiar carpeta de descargas\u001b[0m\n2024-12-08 21:02:57,299 - INFO - Archivo eliminado: Graduados_Junio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,307 - INFO - Archivo eliminado: Graduados_Julio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,316 - INFO - Archivo eliminado: Graduados_Septiembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,325 - INFO - Archivo eliminado: Graduados_Abril 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,332 - INFO - Archivo eliminado: Graduados_Octubre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,337 - INFO - Archivo eliminado: Graduados_Marzo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,357 - INFO - Archivo eliminado: Graduados_Diciembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,366 - INFO - Archivo eliminado: Graduados_Junio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,371 - INFO - Archivo eliminado: Graduados_Noviembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,380 - INFO - Archivo eliminado: Graduados_Octubre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,386 - INFO - Archivo eliminado: Graduados_Julio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,394 - INFO - Archivo eliminado: Graduados_Octubre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,403 - INFO - Archivo eliminado: Graduados_Septiembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,411 - INFO - Archivo eliminado: Graduados_Septiembre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,418 - INFO - Archivo eliminado: Graduados_Enero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,425 - INFO - Archivo eliminado: Graduados_Agosto 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,432 - INFO - Archivo eliminado: Graduados_Agosto 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,440 - INFO - Archivo eliminado: Graduados_Noviembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,448 - INFO - Archivo eliminado: Graduados_Mayo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,455 - INFO - Archivo eliminado: Graduados_Enero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,464 - INFO - Archivo eliminado: Graduados_Abril 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,470 - INFO - Archivo eliminado: Graduados_Abril 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,478 - INFO - Archivo eliminado: Graduados_Mayo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,485 - INFO - Archivo eliminado: Graduados_Septiembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,492 - INFO - Archivo eliminado: Graduados_Enero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,500 - INFO - Archivo eliminado: Graduados_Marzo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,506 - INFO - Archivo eliminado: Graduados_Diciembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,515 - INFO - Archivo eliminado: Graduados_Diciembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,524 - INFO - Archivo eliminado: Graduados_Febrero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,532 - INFO - Archivo eliminado: Graduados_Agosto 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,538 - INFO - Archivo eliminado: Graduados_Julio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,546 - INFO - Archivo eliminado: Graduados_Febrero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,553 - INFO - Archivo eliminado: Graduados_Octubre 2019_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,561 - INFO - Archivo eliminado: Graduados_Marzo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,568 - INFO - Archivo eliminado: Graduados_Agosto 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,575 - INFO - Archivo eliminado: Graduados_Febrero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,583 - INFO - Archivo eliminado: Graduados_Octubre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,589 - INFO - Archivo eliminado: Graduados_Mayo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,596 - INFO - Archivo eliminado: Graduados_Junio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,598 - INFO - \u001b[92mProceso 'Limpiar carpeta de descargas' completado exitosamente en 0.31 segundos.\u001b[0m\n2024-12-08 21:02:57,599 - INFO - \u001b[92mIniciando: Descargar archivos de SharePoint\u001b[0m\n2024-12-08 21:02:58,772 - INFO - Archivo descargado: Graduados_Junio 2023_21_11_2024.xlsx\n2024-12-08 21:03:00,128 - INFO - Archivo descargado: Graduados_Julio 2024_21_11_2024.xlsx\n2024-12-08 21:03:01,439 - INFO - Archivo descargado: Graduados_Septiembre 2022_21_11_2024.xlsx\n2024-12-08 21:03:02,793 - INFO - Archivo descargado: Graduados_Abril 2023_21_11_2024.xlsx\n2024-12-08 21:03:04,293 - INFO - Archivo descargado: Graduados_Octubre 2023_21_11_2024.xlsx\n2024-12-08 21:03:05,531 - INFO - Archivo descargado: Graduados_Marzo 2022_21_11_2024.xlsx\n2024-12-08 21:03:06,757 - INFO - Archivo descargado: Graduados_Diciembre 2022_21_11_2024.xlsx\n2024-12-08 21:03:08,140 - INFO - Archivo descargado: Graduados_Junio 2024_21_11_2024.xlsx\n2024-12-08 21:03:09,507 - INFO - Archivo descargado: Graduados_Noviembre 2022_21_11_2024.xlsx\n2024-12-08 21:03:10,785 - INFO - Archivo descargado: Graduados_Octubre 2024_21_11_2024.xlsx\n2024-12-08 21:03:12,150 - INFO - Archivo descargado: Graduados_Julio 2023_21_11_2024.xlsx\n2024-12-08 21:03:13,729 - INFO - Archivo descargado: Graduados_Octubre 2022_21_11_2024.xlsx\n2024-12-08 21:03:14,966 - INFO - Archivo descargado: Graduados_Septiembre 2021_21_11_2024.xlsx\n2024-12-08 21:03:16,188 - INFO - Archivo descargado: Graduados_Septiembre 2024_21_11_2024.xlsx\n2024-12-08 21:03:17,471 - INFO - Archivo descargado: Graduados_Enero 2023_21_11_2024.xlsx\n2024-12-08 21:03:18,876 - INFO - Archivo descargado: Graduados_Agosto 2024_21_11_2024.xlsx\n2024-12-08 21:03:20,304 - INFO - Archivo descargado: Graduados_Agosto 2022_21_11_2024.xlsx\n2024-12-08 21:03:22,227 - INFO - Archivo descargado: Graduados_Noviembre 2023_21_11_2024.xlsx\n2024-12-08 21:03:23,650 - INFO - Archivo descargado: Graduados_Mayo 2022_21_11_2024.xlsx\n2024-12-08 21:03:25,017 - INFO - Archivo descargado: Graduados_Enero 2024_21_11_2024.xlsx\n2024-12-08 21:03:26,300 - INFO - Archivo descargado: Graduados_Abril 2022_21_11_2024.xlsx\n2024-12-08 21:03:27,795 - INFO - Archivo descargado: Graduados_Abril 2024_21_11_2024.xlsx\n2024-12-08 21:03:29,145 - INFO - Archivo descargado: Graduados_Mayo 2023_21_11_2024.xlsx\n2024-12-08 21:03:30,567 - INFO - Archivo descargado: Graduados_Septiembre 2023_21_11_2024.xlsx\n2024-12-08 21:03:31,793 - INFO - Archivo descargado: Graduados_Enero 2022_21_11_2024.xlsx\n2024-12-08 21:03:33,260 - INFO - Archivo descargado: Graduados_Marzo 2024_21_11_2024.xlsx\n2024-12-08 21:03:34,704 - INFO - Archivo descargado: Graduados_Diciembre 2023_21_11_2024.xlsx\n2024-12-08 21:03:35,986 - INFO - Archivo descargado: Graduados_Diciembre 2021_21_11_2024.xlsx\n2024-12-08 21:03:37,264 - INFO - Archivo descargado: Graduados_Febrero 2023_21_11_2024.xlsx\n2024-12-08 21:03:38,677 - INFO - Archivo descargado: Graduados_Agosto 2023_21_11_2024.xlsx\n2024-12-08 21:03:40,022 - INFO - Archivo descargado: Graduados_Julio 2022_21_11_2024.xlsx\n2024-12-08 21:03:41,313 - INFO - Archivo descargado: Graduados_Febrero 2022_21_11_2024.xlsx\n2024-12-08 21:03:42,530 - INFO - Archivo descargado: Graduados_Octubre 2019_21_11_2024.xlsx\n2024-12-08 21:03:44,019 - INFO - Archivo descargado: Graduados_Marzo 2023_21_11_2024.xlsx\n2024-12-08 21:03:45,303 - INFO - Archivo descargado: Graduados_Agosto 2021_21_11_2024.xlsx\n2024-12-08 21:03:46,667 - INFO - Archivo descargado: Graduados_Febrero 2024_21_11_2024.xlsx\n2024-12-08 21:03:47,884 - INFO - Archivo descargado: Graduados_Octubre 2021_21_11_2024.xlsx\n2024-12-08 21:03:49,438 - INFO - Archivo descargado: Graduados_Mayo 2024_21_11_2024.xlsx\n2024-12-08 21:03:50,790 - INFO - Archivo descargado: Graduados_Junio 2022_21_11_2024.xlsx\n2024-12-08 21:03:51,792 - INFO - \u001b[92mProceso 'Descargar archivos de SharePoint' completado exitosamente en 54.19 segundos.\u001b[0m\n2024-12-08 21:04:05,897 - INFO - Archivo procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx subido exitosamente a SharePoint.\n\n\nArchivo subido a SharePoint: procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx, folder_url: Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/06.Egresados_Graduados\n\n\n2024-12-08 21:04:06,408 - INFO - \u001b[92mProceso 'ETL' completado exitosamente en 1.15 minutos.\u001b[0m\n\n\nArchivo original eliminado: procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/","title":"emp_05 Estudiantes Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,procesar_excel_con_hojas,limpiar_columnas,concatenar_dataframes,\n    obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/#emp_estudiantes_inasistencias","title":"emp_Estudiantes_inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de estudiantes con inasistencias almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Estudiantes_inasistencias</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'emp_Estudiantes_inasistencias_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan las columnas innecesarias y se renombran las columnas para limpiar y estandarizar los datos utilizando la funci\u00f3n <code>limpiar_columnas</code>. Adem\u00e1s, se actualizan las columnas de programa, sede y per\u00edodo utilizando la funci\u00f3n <code>actualizar_columna_programa</code>. Finalmente, se separa la columna <code>Identificaci\u00f3n</code> en tipo y n\u00famero, y se filtran las filas seg\u00fan la columna <code>Sede - jornada</code>, asegurando que los datos est\u00e9n estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def procesar_inasistencias(file_path):\n    df=procesar_excel_con_hojas(file_path)\n    df.columns = [f'Columna_{i}' for i in range(len(df.columns))]\n\n\n    # Split column into SEDE and JORNADA\n    df[['SEDE', 'JORNADA']] = df['Columna_0'].str.extract(r'(.+) - (.+)')\n    df = df.drop(df.index[:8])\n    df_emp_Estudiantes_inasistencias =  df\n    elimina = {'Columna_1'}\n\n    # Fill empty values in Columna_12 with values from Columna_13\n    df_emp_Estudiantes_inasistencias['Columna_12'] = df_emp_Estudiantes_inasistencias['Columna_12'].fillna(df_emp_Estudiantes_inasistencias['Columna_13'])\n\n    # Asumiendo que df_emp_Estudiantes_inasistencias ya existe\n    df = df_emp_Estudiantes_inasistencias\n    # Variables para controlar el estado\n    found_porcentaje = False\n    found_creditos = False\n    # Funci\u00f3n para procesar cada fila\n    def process_row(row):\n        global found_porcentaje, found_creditos\n        if isinstance(row['Columna_15'], str) and 'Porcentaje' in row['Columna_15']:\n            found_porcentaje = True\n            found_creditos = False\n        elif row['Columna_15'] == 'Creditos':\n            found_creditos = True\n            found_porcentaje = False\n        if found_porcentaje:\n            row['Columna_16'] = row['Columna_15']\n        elif found_creditos:\n            row['Columna_14'] = row['Columna_15']\n        return row\n    # Aplicar la funci\u00f3n a cada fila del DataFrame\n    df = df.apply(process_row, axis=1)\n    # Asignar el resultado de vuelta a df_emp_Estudiantes_inasistencias\n    df_emp_Estudiantes_inasistencias = df\n\n    df = df_emp_Estudiantes_inasistencias\n    # Extraer los valores en las columnas 'Tipo Identificacion' e 'Identificacion'\n\n    # Eliminar los puntos de la columna 'Columna_7'\n    df['Columna_7'] = df['Columna_7'].str.replace('.', '', regex=False)\n\n    df[['Tipo_documento', 'Identificacion']] = df['Columna_7'].str.extract(r'(.+?)\\s+(.+)')\n\n\n    df = df.dropna(axis=1, how='all')\n\n    renombrar = {\n    }\n    eliminar = ['Columna_11',\n                'Columna_7',\n                'Columna_0',\n                'Columna_13',\n                'Columna_15',\n                ]\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n\n    # Restablecer el \u00edndice antes de renombrar las columnas\n    df = df.reset_index(drop=True)\n\n    # Rename columns starting with 'Columna_' using row 0 values in uppercase\n    df.columns = [\n        str(df.iloc[0][col]).upper() if col.startswith('COLUMNA_') else col\n        for col in df.columns\n    ]\n    df = df.drop(0).reset_index(drop=True)\n\n    # Filtrar filas seg\u00fan la columna: 'ESTUDIANTE'\n    df = df[df['ESTUDIANTE'].notna()]\n\n    # Filtrar filas seg\u00fan la columna: 'PROGRAMA'\n    df = df[df['PROGRAMA'] != \"Programa\"]\n\n    renombrar={\n        'ESTUDIANTE': 'NOMBRE_ESTUDIANTE',\n        'IDENTIFICACION': 'DOCUMENTO_ESTUDIANTE',\n        'NIVEL': 'SEMESTRE',\n        'M\u00d3DULO': 'MODULO'        \n    }\n    eliminar = []\n    df = limpiar_columnas(df, eliminar, renombrar,True)        \n    return df\n\ndef obtener_sharepoint_emp_Estudiantes_inasistencias():\n    folder_url = etl_to_folder_url.get('emp_Estudiantes_inasistencias', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"emp_Estudiantes_inasistencias_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'emp_Estudiantes_inasistencias_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [procesar_inasistencias(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    # df = pd.concat(all_dfs, ignore_index=True)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = concatenar_dataframes(all_dfs)\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Estudiantes_inasistencias = obtener_sharepoint_emp_Estudiantes_inasistencias()\n    actualizar_sharepoint_procesado(df_emp_Estudiantes_inasistencias, 'emp_Estudiantes_inasistencias')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>2024-12-08 20:56:25,939 - INFO - \u001b[92mIniciando: ETL\u001b[0m\n2024-12-08 20:56:25,945 - INFO - \u001b[92mIniciando: Limpiar carpeta de descargas\u001b[0m\n2024-12-08 20:56:25,958 - INFO - Archivo eliminado: Graduados_Junio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,966 - INFO - Archivo eliminado: Graduados_Julio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,974 - INFO - Archivo eliminado: Graduados_Septiembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,982 - INFO - Archivo eliminado: Graduados_Abril 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,991 - INFO - Archivo eliminado: Graduados_Octubre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,998 - INFO - Archivo eliminado: Graduados_Marzo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,007 - INFO - Archivo eliminado: Graduados_Diciembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,014 - INFO - Archivo eliminado: Graduados_Junio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,022 - INFO - Archivo eliminado: Graduados_Noviembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,030 - INFO - Archivo eliminado: Graduados_Octubre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,037 - INFO - Archivo eliminado: Graduados_Julio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,044 - INFO - Archivo eliminado: Graduados_Octubre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,050 - INFO - Archivo eliminado: Graduados_Septiembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,059 - INFO - Archivo eliminado: Graduados_Septiembre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,065 - INFO - Archivo eliminado: Graduados_Enero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,073 - INFO - Archivo eliminado: Graduados_Agosto 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,079 - INFO - Archivo eliminado: Graduados_Agosto 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,085 - INFO - Archivo eliminado: Graduados_Noviembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,091 - INFO - Archivo eliminado: Graduados_Mayo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,096 - INFO - Archivo eliminado: Graduados_Enero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,102 - INFO - Archivo eliminado: Graduados_Abril 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,108 - INFO - Archivo eliminado: Graduados_Abril 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,114 - INFO - Archivo eliminado: Graduados_Mayo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,120 - INFO - Archivo eliminado: Graduados_Septiembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,125 - INFO - Archivo eliminado: Graduados_Enero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,132 - INFO - Archivo eliminado: Graduados_Marzo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,138 - INFO - Archivo eliminado: Graduados_Diciembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,144 - INFO - Archivo eliminado: Graduados_Diciembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,150 - INFO - Archivo eliminado: Graduados_Febrero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,156 - INFO - Archivo eliminado: Graduados_Agosto 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,165 - INFO - Archivo eliminado: Graduados_Julio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,172 - INFO - Archivo eliminado: Graduados_Febrero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,199 - INFO - Archivo eliminado: Graduados_Octubre 2019_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,204 - INFO - Archivo eliminado: Graduados_Marzo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,210 - INFO - Archivo eliminado: Graduados_Agosto 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,215 - INFO - Archivo eliminado: Graduados_Febrero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,223 - INFO - Archivo eliminado: Graduados_Octubre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,229 - INFO - Archivo eliminado: Graduados_Mayo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,239 - INFO - Archivo eliminado: Graduados_Junio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,241 - INFO - \u001b[92mProceso 'Limpiar carpeta de descargas' completado exitosamente en 0.30 segundos.\u001b[0m\n2024-12-08 20:56:26,243 - INFO - \u001b[92mIniciando: Descargar archivos de SharePoint\u001b[0m\n2024-12-08 20:56:27,449 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Diciembre 2023.xlsx\n2024-12-08 20:56:28,866 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Septiembre 2023.xlsx\n2024-12-08 20:56:30,203 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2023.xlsx\n2024-12-08 20:56:31,566 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2024.xlsx\n2024-12-08 20:56:33,015 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2024.xlsx\n2024-12-08 20:56:34,433 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2023.xlsx\n2024-12-08 20:56:35,815 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2024.xlsx\n2024-12-08 20:56:37,379 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2023.xlsx\n2024-12-08 20:56:38,773 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Julio 2024.xlsx\n2024-12-08 20:56:39,775 - INFO - \u001b[92mProceso 'Descargar archivos de SharePoint' completado exitosamente en 13.53 segundos.\u001b[0m\n2024-12-08 20:56:41,711 - INFO - Archivo procesado_emp_Estudiantes_inasistencias_08_12_2024_20_56.xlsx subido exitosamente a SharePoint.\n\n\nArchivo subido a SharePoint: procesado_emp_Estudiantes_inasistencias_08_12_2024_20_56.xlsx, folder_url: Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/05.Estudiantes_cancelados_por_inasistencias\n\n\n2024-12-08 20:56:42,221 - INFO - \u001b[92mProceso 'ETL' completado exitosamente en 16.28 segundos.\u001b[0m\n\n\nArchivo original eliminado: procesado_emp_Estudiantes_inasistencias_08_12_2024_20_56.xlsx\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/","title":"emp_06 Consolidado Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,actualizar_columna_programa,obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/#consolidado_inasistencias","title":"consolidado_Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de estudiantes con inasistencias almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Consolidado_inasistenciass</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Consolidado_inasistencias_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan las columnas innecesarias y se renombran las columnas para limpiar y estandarizar los datos utilizando la funci\u00f3n <code>limpiar_columnas</code>. Adem\u00e1s, se actualizan las columnas de programa, sede y per\u00edodo utilizando la funci\u00f3n <code>actualizar_columna_programa</code>. Finalmente, se separa la columna <code>Identificaci\u00f3n</code> en tipo y n\u00famero, y se filtran las filas seg\u00fan la columna <code>Sede - jornada</code>, asegurando que los datos est\u00e9n estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_emp_Consolidado_inasistenciass():\n    folder_url = etl_to_folder_url.get('emp_Consolidado_inasistencias', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Consolidado_inasistencias_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Consolidado_inasistencias_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n\n    return df\n\n\ndef procesar_inasistencias(df):\n\n    df.columns = [f'Columna_{i}' for i in range(len(df.columns))]\n\n    df = actualizar_columna_programa(\n        df, \n        columna_condicional='Columna_4', \n        columna_origen='Columna_5', \n        columna_destino='Programa',\n        texto_filtro='Programa'\n    )\n\n    df = actualizar_columna_programa(\n        df, \n        columna_condicional='Columna_1', \n        columna_origen='Columna_3', \n        columna_destino='Sede',\n        texto_filtro='Sede'\n    )\n\n    df = actualizar_columna_programa(\n        df, \n        columna_condicional='Columna_11', \n        columna_origen='Columna_12', \n        columna_destino='Per\u00edodo',\n        texto_filtro='Per\u00edodo'\n    )\n\n\n    columnas_a_eliminar = ['Columna_4','Columna_11','Columna_0','Columna_1','Columna_8','Columna_9','Columna_10','Columna_12']\n    renombres = {'Columna_2': 'Identificaci\u00f3n', 'Columna_3': 'Apellidos y Nombres', 'Columna_5': 'Nivel', 'Columna_6': 'Area', 'Columna_7': 'Total'}\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres)\n\n    # Filtrar filas seg\u00fan la columna: 'Identificaci\u00f3n'\n    df = df[df['Identificaci\u00f3n'].notna()]\n\n    # Eliminar espacios adicionales en la columna 'Identificaci\u00f3n'\n    df['Identificaci\u00f3n'] = df['Identificaci\u00f3n'].str.strip()\n\n\n    # Separar la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n    df[['Tipo Identificaci\u00f3n', 'Identificaci\u00f3n']] = df['Identificaci\u00f3n'].str.split(' ', expand=True)\n    df['Tipo Identificaci\u00f3n'] = df['Tipo Identificaci\u00f3n'].apply(lambda x: str(x).replace('.', ''))\n\n\n    #filtra Identificaci\u00f3n y elimina todas las filas que contentan Identificaci\u00f3n\n    df = df[df['Identificaci\u00f3n'].str.contains('Identificaci\u00f3n')==False]\n\n    df = df[[\n        'Identificaci\u00f3n',\n        'Tipo Identificaci\u00f3n',\n        'Apellidos y Nombres',\n        'Nivel',\n        'Area',\n        'Total',\n        'Programa',\n        'Sede',\n        'Per\u00edodo'\n        ]]\n    df.to_excel(\"emp_Consolidado_inasistencias.xlsx\", index=False)\n\n    df[['SEDE', 'JORNADA']] = df['Sede'].str.extract(r'(.+) - (.+)')\n    #ELIMINA COLUMNA Sede\n    df.drop(columns=['Sede'], inplace=True)\n\n    renombres = {\n        'Identificaci\u00f3n':'DOCUMENTO',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO',\n        'Apellidos y Nombres':'ESTUDIANTE',\n        'Nivel':'SEMESTRE',\n        'Total':'TOTAL_INASISTENCIA',\n        'Programa':'CURSO',\n        'Per\u00edodo':'PERIODO_ACADEMICO'\n    }\n\n    eliminar = [\n                ]\n\n    df = limpiar_columnas(df, eliminar, renombres,True)\n\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Consolidado_inasistencias = obtener_sharepoint_emp_Consolidado_inasistenciass()\n    df_emp_Consolidado_inasistencias = procesar_inasistencias(df_emp_Consolidado_inasistencias)\n    actualizar_sharepoint_procesado(df_emp_Consolidado_inasistencias, 'emp_Consolidado_inasistencias')\n\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/","title":"0.1. Docentes Desarrollo Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se ignoran advertencias espec\u00edficas para evitar distracciones innecesarias durante la ejecuci\u00f3n del script. Si hay otros loggers configurados, tambi\u00e9n se ajusta su nivel de detalle a <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport logging\nimport time\nimport os\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, _descargar, close_driver, hacer_clic, procesar,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/#automatizacion-de-descarga-y-procesamiento-del-reporte-docentes","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Docentes\"","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Docentes\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>DOWNLOAD_DIR</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_des_empresarial</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Docentes\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Este enfoque modular y estructurado facilita la depuraci\u00f3n, escalabilidad y mantenimiento del flujo automatizado.</p> <pre><code>@log_step_decorator(\"Docentes desarrollo empresarial\")\ndef main():\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Docentes\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"clic_docentes\",log_step_decorator(\"clic_docentes\")(hacer_clic), {'driver': driver, 'xpath': \n                '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[1]/div[1]/a',\n                'wait_time': 5}),\n            (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n            (\"descargar_archivo\", log_step_decorator(\"descargar_archivo\")(_descargar), {'driver': driver, 'xpath': \n                '//*[@id=\"generar-reporte-btn\"]','download_dir': DOWNLOAD_DIR,\n                'archivo':  f\"Desarrollo_Docentes_{time.strftime('%Y_%m_%d')}\", 'wait_time': 10}),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', 'wait_time': 5}),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', 'wait_time': 5}),\n        ]\n\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        procesar('emp_Docentes', DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/","title":"0.2. Preinscritos","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>time</code>, <code>sys</code>, <code>json</code>, <code>warnings</code> y <code>datetime</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos, <code>close_driver</code> para cerrar el navegador de forma segura, <code>generar_fechas</code> para generar rangos de fechas, <code>configurar_pasos_autenticacion_des_empresarial</code> para configurar los pasos de autenticaci\u00f3n y <code>eliminar_archivos_anteriores</code> para limpiar archivos previos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con la ejecuci\u00f3n del script. Tambi\u00e9n se ajustan los niveles de detalle de otros loggers configurados en el entorno para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging, os, time, sys\nfrom datetime import datetime\nimport json\nfrom dateutil.relativedelta import relativedelta\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic,generar_fechas,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/#automatizacion-de-descarga-y-procesamiento-del-reporte-preinscritos","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Preinscritos\"","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Preinscritos\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>DOWNLOAD_DIR</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_des_empresarial</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Preinscritos\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>def guardar_json(diccionario, nombre_archivo):\n    with open(nombre_archivo, 'w') as archivo:\n        json.dump(diccionario, archivo)\n\n@log_step_decorator(\"Preinscritos\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Preinscritos\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        _eleccion = 1\n        _desde = fechas[_eleccion][\"desde\"]\n        _hasta = fechas[_eleccion][\"hasta\"]\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"clic_preinscritos\", log_step_decorator(\"clic_preinscritos\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[2]/div/a', \n                'wait_time': 5\n            }),\n            (\"abrir_fecha\", log_step_decorator(\"abrir_fecha\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '//*[@id=\"rangoFechas\"]/a/div[1]', \n                'wait_time': 3\n            }),\n            (\"seleccionar_rango_personalizado\", log_step_decorator(\"seleccionar_rango_personalizado\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/ul/li[7]', \n                'wait_time': 3\n            }),\n            (\"ingresar_fecha_inicial\", log_step_decorator(\"ingresar_fecha_inicial\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', \n                'value': _desde, \n                'wait_time': 3\n            }),\n            (\"ingresar_fecha_final\", log_step_decorator(\"ingresar_fecha_final\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', \n                'value': _hasta,  \n                'wait_time': 3\n            }),\n            (\"aceptar_fechas\", log_step_decorator(\"aceptar_fechas\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/div/button[1]', \n                'wait_time': 3\n            }),\n            (\"generar_reporte\", log_step_decorator(\"generar_reporte\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '//*[@id=\"generar-reporte-btn\"]', \n                'wait_time': 10\n            }),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', \n                'wait_time': 5\n            }),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', \n                'wait_time': 5\n            })\n        ]\n\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)  # Aqu\u00ed no se pasa `driver` directamente, solo los par\u00e1metros en `params`\n        procesar(\"emp_Preinscritos\",DOWNLOAD_DIR)\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/","title":"0.3. Listado Matr\u00edculas Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>random</code>, <code>logging</code>, <code>os</code>, <code>sys</code> y <code>time</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se importan y configuran advertencias para ignorar aquellas espec\u00edficas que no son relevantes para el proceso actual. Esto asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport argparse, random\nimport logging, os, sys, time\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n#importaa json\nimport json\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic, configurar_pasos_autenticacion_des_empresarial, \n    procesar_reporte_modal, generar_periodos,generar_fechas, generar_periodos_cortes\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/#automatizacion-de-descarga-de-listados-de-matriculas-empresarial","title":"Automatizaci\u00f3n de Descarga de Listados de Matr\u00edculas Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas empresariales desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Listado_matriculas_emp\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los rangos de fechas personalizados. Cada iteraci\u00f3n del bucle configura un rango de fechas en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar fechas y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Listado de matr\u00edculas empresarial\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        subcarpeta_descarga = \"Listado_matriculas_emp\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Listado_matriculas_emp'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n        # Pasar driver al configurar pasos de autenticaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n            }),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5\n            }),\n            (\"listado\", log_step_decorator(\"listado\")(hacer_clic), {\n                'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[4]/div[2]/a', 'wait_time': 5\n            }),\n        ]\n\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n\n\n        for fecha in fechas:\n            logging.info(f\"Fecha: {fecha}\")\n            _hash = f\"{random.randint(1000, 9999)}\"\n            nombre_archivo_completo = f'{nombre_archivo}_{_hash}.xlsx'\n\n            step_2 = [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[9]/div[3]/ul/li[7]', 'wait_time': 3}),\n                (\"entrar_en_fecha1\",log_step_decorator(\"entrar_en_fecha1\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[1]/input','value': fechas[fecha]['desde'],'driver': driver,'wait_time': 3}),\n                (\"entrar_en_fecha2\",log_step_decorator(\"entrar_en_fecha2\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', 'value': fechas[fecha]['hasta'],'driver': driver,'wait_time': 3}),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 3}),\n                (\"descargar\", log_step_decorator(\"descargar\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"generar-reporte-btn\"]', 'wait_time': 60}),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo})]\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                time.sleep(5)\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n        procesar(\"emp_Listado_Matriculas\",download_dir)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_periodos_cortes(anio_inicio=_inicio, anio_fin=_fin, tipo=4)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/","title":"0.4. Consolidado Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>warnings</code>, <code>pandas</code> y <code>selenium.webdriver.common.by.By</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>ejecutar_pasos</code> para ejecutar una serie de acciones de forma secuencial.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging\nimport time\nimport os\nimport sys\nimport pandas as pd\nfrom selenium.webdriver.common.by import By\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar_reporte_modal, obtener_elementos_dropdown, \n    hacer_clic, elemento_disponible, seleccionar_opcion_con_js, procesar, guardar_diccionario,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores,ejecutar_pasos\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/#automatizacion-de-descarga-de-consolidado-de-inasistencias","title":"Automatizaci\u00f3n de Descarga de Consolidado de Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de consolidado de inasistencias desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar periodos, jornadas, programas, m\u00f3dulos y cursos, y descargar los reportes correspondientes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Consolidado_inasistencias\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el consolidado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja la selecci\u00f3n de periodos, jornadas, programas, m\u00f3dulos y cursos. Cada iteraci\u00f3n del bucle configura estos par\u00e1metros en la interfaz de la web, genera el reporte y procesa los datos descargados. Adem\u00e1s, el script incluye la eliminaci\u00f3n de archivos anteriores en la carpeta de descargas antes de procesar nuevos.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>driver.quit()</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Consolidado_inasistencias\")\ndef main(consulta):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Consolidado_inasistencias\"\n        generar = False\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"consolidado\",log_step_decorator(\"consolidado\")(hacer_clic), {'driver': driver, 'xpath': \n                '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[1]/div[2]/a',\n                'wait_time': 5}),\n        ]\n\n        ejecutar_pasos(step_1)\n        # time.sleep(100)   \n\n\n        _xpath_periodo  = '//*[@id=\"form0\"]/div[1]/div[3]'\n        periodo_boton = f'{_xpath_periodo}/div/button'\n        periodo_list = f'{_xpath_periodo}/div/div/ul'\n        nivel = 1\n\n        # Obtener los periodos disponibles en el dropdown\n        _periodos = obtener_elementos_dropdown(driver, periodo_boton, periodo_list, nivel)\n\n        periodos_generados = [f\"{year}\" for year in consulta]\n        #elimina repetidos de periodos_generados        \n        periodos_generados = list(set(periodos_generados))\n        # Filtrar solo los per\u00edodos que comiencen con los valores generados\n        periodos = [\n            periodo for periodo in _periodos \n            if any(generado in periodo for generado in periodos_generados)\n        ]\n        # Guardar los per\u00edodos seleccionados en un archivo para referencia\n        guardar_diccionario(periodos, 'periodos')\n\n        # Eliminar archivos anteriores en la carpeta de descargas antes de procesar nuevos\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        # Procesar cada periodo seleccionado\n\n        if periodos:\n\n            for periodo in periodos:\n                # Seleccionar el periodo\n                hacer_clic(driver= driver, xpath=periodo_boton, wait_time= 1)\n                # seleccionar_opcion_custom_dropdown(driver=driver, xpath=periodo_boton, option=periodo, wait_time=1)\n                seleccionar_opcion_con_js(driver, periodo_boton, periodo)\n                logging.info(f\"Procesando periodo: {periodo}\")\n\n                # Obtener jornadas para el periodo seleccionado\n                xpath_jornada = '//*[@id=\"form0\"]/div[2]/div[3]'\n                jornada_boton = f'{xpath_jornada}/div/button'\n                jornada_list = f'{xpath_jornada}/div/div/ul'\n                jornadas = obtener_elementos_dropdown(driver, jornada_boton, jornada_list, nivel=2)\n                excluir_jornadas = {'Seleccione'}\n                jornadas = [jornada for jornada in jornadas if jornada not in excluir_jornadas]\n                jornadas = {'Programa'}\n                if jornadas:                    \n\n                    for jornada in jornadas:\n                        hacer_clic(driver= driver, xpath=jornada_boton, wait_time= 1)\n                        # Seleccionar la jornada\n                        seleccionar_opcion_con_js(driver, jornada_boton, jornada)\n                        time.sleep(4)\n                        logging.info(f\"Procesando jornada: {jornada}\")\n\n                        # Obtener programas para la jornada seleccionada\n                        if jornada == 'Curso':\n                            xpath_programa = '//*[@id=\"form0\"]/div[6]/div[3]'\n                        else:\n                            xpath_programa = '//*[@id=\"form0\"]/div[3]/div[3]' \n                        programa_boton = f'{xpath_programa}/div/button'\n                        programa_list = f'{xpath_programa}/div/div/ul'\n                        programas = obtener_elementos_dropdown(driver, programa_boton, programa_list, nivel=3)\n                        excluir_opciones = {'Seleccione'}\n                        programas = [programa for programa in programas if programa not in excluir_opciones]\n                        if programas:\n\n                            for programa in programas:\n                                hacer_clic(driver= driver, xpath=programa_boton, wait_time= 1)\n                                # Seleccionar el programa\n                                seleccionar_opcion_con_js(driver, programa_boton, programa)\n                                logging.info(f\"Procesando programa: {programa}\")\n                                # Obtener modulo para el programa seleccionado\n                                if jornada == 'Curso':\n                                    xpath_modulo = '//*[@id=\"form0\"]/div[7]/div[3]' \n                                else:\n                                    xpath_modulo = '//*[@id=\"form0\"]/div[4]/div[3]'\n                                modulo_boton = f'{xpath_modulo}/div/button'\n                                modulo_list = f'{xpath_modulo}/div/div/ul'\n                                modulos = obtener_elementos_dropdown(driver, modulo_boton, modulo_list, nivel=4)\n                                excluir_modulos = {'Seleccione'}\n                                modulo = [modulo for modulo in modulos if modulo not in excluir_modulos]\n                                if modulos:\n                                    for modulo in modulos:\n                                        hacer_clic(driver= driver, xpath=modulo_boton, wait_time= 1)\n                                        seleccionar_opcion_con_js(driver, modulo_boton, modulo)\n                                        logging.info(f\"Procesando modulo: {modulo}\")\n                                        # obtener modulo\n                                        if jornada == 'Curso':\n                                            xpath_modulo = '//*[@id=\"form0\"]/div[8]/div[3]'\n                                        else:\n                                            xpath_curso = '//*[@id=\"form0\"]/div[5]/div[3]'\n                                        cursos_boton = f'{xpath_curso}/div/button'\n                                        cursos_list = f'{xpath_curso}/div/div/ul'\n                                        cursos = obtener_elementos_dropdown(driver, cursos_boton, cursos_list, nivel=5)\n                                        excluir_cursos = {'Seleccione'}\n                                        curso = [curso for curso in cursos if curso not in excluir_cursos]\n                                        if cursos:\n                                            for curso in cursos:\n\n                                                seleccionar_opcion_con_js(driver, cursos_boton, curso)\n                                                hacer_clic(driver= driver, xpath=\n                                                    '//*[@id=\"generar-reporte-btn\"]'\n                                                    , wait_time=5)\n                                                #define la variable archivo uniendo periodo, jornada, programa y modulo\n                                                archivo = f'Cede_{periodo}_{jornada}_{programa}_{modulo}_{curso}.xlsx'\n                                                modal = elemento_disponible(driver, By.ID, \"master-modal\", timeout=10)\n                                                if modal:\n                                                    procesar_reporte_modal(driver, DOWNLOAD_DIR, archivo)\n                                                    time.sleep(5)\n                                else: continue\n                        else: continue\n                else: continue\n\n\n            procesar('emp_Consolidado_inasistencias',DOWNLOAD_DIR)\n            logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\n        #Eliminar esta linea en produccion \n        # procesar('emp_Consolidado_inasistencias',DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            # Cerrar el navegador\n            driver.quit()\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    # Generar lista de periodos de consulta (2019, 2020)\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    consulta = {_inicio, _fin}\n    main(consulta)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/","title":"0.5. Estudiantes Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>warnings</code> y <code>pandas</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, <code>procesar_reporte_modal</code>, <code>hacer_clic</code>, <code>obtener_elementos_dropdown</code>, <code>seleccionar_opcion_con_js</code>, <code>guardar_diccionario</code>, <code>configurar_pasos_autenticacion_des_empresarial</code>, <code>eliminar_archivos_anteriores</code> y <code>ejecutar_pasos</code>. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging\nimport time\nimport os\nimport sys\nimport pandas as pd\n\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar_reporte_modal, obtener_elementos_dropdown, \n    hacer_clic, procesar, seleccionar_opcion_con_js, guardar_diccionario,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores,ejecutar_pasos\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/#automatizacion-de-descarga-de-consolidado-de-inasistencias","title":"Automatizaci\u00f3n de Descarga de Consolidado de Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de consolidado de inasistencias desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar periodos y descargar los reportes correspondientes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Estudiantes_inasistencias\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el consolidado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja la selecci\u00f3n de periodos. Cada iteraci\u00f3n del bucle configura estos par\u00e1metros en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar opciones en dropdowns y descargar el archivo, est\u00e1n definidos en el c\u00f3digo. Adem\u00e1s, el script incluye la eliminaci\u00f3n de archivos anteriores en la carpeta de descargas antes de procesar nuevos.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>driver.quit()</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos periodos con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <p>El script utiliza un sistema de logging bien estructurado para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code>@log_step_decorator(\"Estudiantes inasistencias\")\ndef main(consulta):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Estudiantes_inasistencias\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 20}),\n            (\"Estudiantes_inasistencias\",log_step_decorator(\"Estudiantes_inasistencias\")(hacer_clic), {'driver': driver, 'xpath':\n                '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[2]/div[2]/a',\n                'wait_time': 5}),\n            # (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', 'wait_time': 5}),\n            # (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', 'wait_time': 5}),\n        ]\n\n        ejecutar_pasos(step_1)\n\n\n        _xpath_periodo  = '//*[@id=\"formReportes\"]/div/div[3]'\n        periodo_boton = f'{_xpath_periodo}/div/button'\n        periodo_list = f'{_xpath_periodo}/div/div/ul'        \n        nivel=1\n        # Obtener los periodos disponibles en el dropdown\n        _periodos = obtener_elementos_dropdown(driver, periodo_boton, periodo_list, nivel)        \n        periodos_generados = [f\"{year}\" for year in consulta]\n        #elimina repetidos de periodos_generados        \n        periodos_generados = list(set(periodos_generados))\n        # Filtrar solo los per\u00edodos que comiencen con los valores generados\n        periodos = [\n            periodo for periodo in _periodos \n            if any(generado in periodo for generado in periodos_generados)\n        ]\n        # Guardar los per\u00edodos seleccionados en un archivo para referencia\n        guardar_diccionario(periodos, 'periodos')\n\n        # Eliminar archivos anteriores en la carpeta de descargas antes de procesar nuevos\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        if periodos:\n            for periodo in periodos:\n                # Seleccionar el periodo\n                hacer_clic(driver= driver, xpath=periodo_boton, wait_time= 1)\n                seleccionar_opcion_con_js(driver, periodo_boton, periodo)\n                logging.info(f\"Procesando periodo: {periodo}\")\n                hacer_clic(driver= driver, xpath= '//*[@id=\"generar-reporte-btn\"]', wait_time=5)\n                #define la variable archivo uniendo periodo, jornada, programa y modulo\n                archivo = f'Cede_{periodo}.xlsx'\n                procesar_reporte_modal(driver, DOWNLOAD_DIR, archivo)\n                time.sleep(5)\n            logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\n\n\n    finally:\n        if driver:\n            driver.quit\n        logging.info(\"Fin del proceso principal\")\n        procesar('emp_Estudiantes_inasistencias', DOWNLOAD_DIR)\n\n\nif __name__ == \"__main__\":\n    # Generar lista de periodos de consulta (2019, 2020)\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    consulta = {_inicio, _fin}\n    main(consulta)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/","title":"0.6. Egresados Graduados Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code> y <code>warnings</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, <code>hacer_clic</code>, <code>configurar_pasos_autenticacion_des_empresarial</code>, <code>eliminar_archivos_anteriores</code>, <code>pre_procesamiento</code> y <code>obtener_elementos_dropdown</code>. Tambi\u00e9n se incluye <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging\nimport time\nimport os\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic,generar_periodos,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores,pre_procesamiento,obtener_elementos_dropdown\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/#automatizacion-de-descarga-de-consolidado-de-graduados","title":"Automatizaci\u00f3n de Descarga de Consolidado de Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de consolidado de graduados desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un conjunto de pasos para configurar opciones y descargar los reportes correspondientes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Graduados\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el consolidado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>El script maneja la selecci\u00f3n de opciones espec\u00edficas para el tipo de graduado y el periodo. Cada paso configura estos par\u00e1metros en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar opciones en dropdowns y descargar el archivo, est\u00e1n definidos en el c\u00f3digo. Adem\u00e1s, el script incluye la eliminaci\u00f3n de archivos anteriores en la carpeta de descargas antes de procesar nuevos.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>pre_procesamiento</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Graduados\")\ndef main(periodo):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Graduados\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Graduados'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"clic_egresados\", log_step_decorator(\"clic_egresados\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[1]/div[2]/a', \n                'wait_time': 5\n            }),\n            (\"seleccionar_tipo_graduado\", log_step_decorator(\"seleccionar_tipo_graduado\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[1]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"seleccionperiodos\", log_step_decorator(\"seleccionperiodos\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[2]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"pre_procesamiento\", log_step_decorator(\"pre_procesamiento\")(pre_procesamiento), {\n                'driver': driver,\n                'download_dir': DOWNLOAD_DIR,\n                'id_descargar': 'generar-reporte-btn',\n                'nombre_archivo': nombre_archivo,\n                'nombre_archivo_completo': nombre_archivo_completo,\n                'xpath_boton': '//*[@id=\"form0\"]/div[4]/div[3]/div/button',\n                'tipo':'normal',\n                'xpath_contenedor_opciones':  '//*[@id=\"form0\"]/div[4]/div[3]/div/div/ul',\n                'excluir_opciones': periodos\n            }),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', \n                'wait_time': 5\n            }),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', \n                'wait_time': 5\n            })\n        ]\n\n        # Ejecutar cada uno de los pasos definidos en el diccionario \n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        procesar('emp_Egresados_Graduados', DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    periodos = generar_periodos(_inicio, _fin)\n    main(periodos)\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/","title":"3.1. Webscraping Actualizable","text":""},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code> y <code>dateutil.relativedelta</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_logger</code>, para configurar el sistema de logging, <code>log_tiempo</code>, para registrar el tiempo de ejecuci\u00f3n, y <code>download_file_between_dates</code>, para manejar la descarga de archivos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se ignoran advertencias espec\u00edficas para evitar distracciones innecesarias durante la ejecuci\u00f3n del script. Si hay otros loggers configurados, tambi\u00e9n se ajusta su nivel de detalle a <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <ol> <li>Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping: Configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</li> <li>Importaci\u00f3n de Librer\u00edas: Importa las librer\u00edas necesarias como <code>selenium</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code>, y <code>dateutil.relativedelta</code>. Tambi\u00e9n se agrega la ruta de la carpeta <code>Funciones</code> al <code>sys.path</code> y se importan funciones espec\u00edficas.</li> <li>Definici\u00f3n de Selectores XPath: Define un diccionario <code>_dict</code> que contiene los selectores XPath necesarios para interactuar con los elementos de la p\u00e1gina web.</li> <li>Inicio del Proceso ETL: Registra el tiempo de inicio y configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n y Formateo de Fechas: Calcula el primer y \u00faltimo d\u00eda del mes anterior y los formatea en el formato 'dd/MM/yyyy'.</li> <li>Automatizaci\u00f3n de la Descarga de Archivos: Utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. Se inicializa el WebDriver, se abre la URL, y se llama a la funci\u00f3n <code>download_file_between_dates()</code> para realizar la descarga.</li> <li>Registro de Informaci\u00f3n y C\u00e1lculo del Tiempo: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga y calcula el tiempo total del proceso ETL.</li> </ol> <pre><code>## Import libraries\nfrom selenium import webdriver                                          ### selenium version 4.25.0\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n#from time import datetime\nimport time\nimport datetime\nimport os\nimport logging\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../\")) \n\nfrom Utils.Funciones import (\n    setup_logger,log_tiempo,download_file_between_dates\n)\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/#diccionario-de-pasos","title":"Diccionario de pasos","text":"<pre><code>_dict = {\n    \"Ticket_button\" : '//*[@id=\"__button12-img\"]',\n    \"Filter_button\" : '//*[@id=\"findformpaneLkIKPWD61a2ejhlWKfn3Bm_151-img\"]',\n    \"Dates\" : '//*[@id=\"__button51-inner\"]',\n    \"Menu\" :'//*[@id=\"__box4-arrow\"]',\n    \"Entre\" : '//*[@id=\"__item154-content\"]/div/div',\n    \"initial_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_532-datePicker-inner',\n    \"final_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_534-datePicker-inner',\n    \"Aceptar\" : '//*[@id=\"__button77-BDI-content\"]',\n    \"Categoria\" : '//*[@id=\"objectvalueselectorPbJLA_soJqak9j9Ey7mLqvW_346-inputField-vhi\"]',\n    \"Educacion\" : '//*[@id=\"statictextm9D_2UNbhq6mK7P6aHrdQ0_559-listdefintion_O68bB2vS4gwMYerXwebjm_556-9\"]',\n    \"Go_button\" : '//*[@id=\"findformpaneGLsDRJxMiqEpkW0gKJRoAW_152-goButton-BDI-content\"]',\n    \"Plus_botton\" : '//*[@id=\"actionbuttonmenuCTxPLT0i_qoT0xcR7Kdqnm_131-button-BDI-content\"]',\n    \"Export_button\" : '//*[@id=\"navigationitemQQFWfu3deac0r5R10TiQ10_144-BDI-content\"]',\n    \"Download_button\" : '//*[@id=\"__button97-content\"]' \n}\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/#etl","title":"ETL","text":"<ol> <li>Inicio del Proceso ETL: Registra el tiempo de inicio.</li> <li>Configuraci\u00f3n del Logger: Configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n de Fechas: Calcula el primer y \u00faltimo d\u00eda del mes anterior.</li> <li>Formateo de Fechas: Formatea las fechas calculadas en el formato 'dd/MM/yyyy'.</li> <li>Registro de Fechas: (Comentado) Registra las fechas calculadas.</li> </ol> <p>El c\u00f3digo configura un proceso ETL, calcula fechas relevantes y utiliza un logger para monitorear el proceso.</p> <pre><code>inicio_etl = time.time()\n#---------------------------------------------\nlogger = setup_logger(log_filename='scraper.log', log_level=logging.INFO)  # Cambiado a logging.INFO\nlogger.info('COMIENZO ETL')\n\n\n# Obtener la fecha actual\ncurrent_date = datetime.now()\n\n# Calcular el primer d\u00eda del mes anterior\nfirst_day_previous_month = (current_date.replace(day=1) - relativedelta(months=1)).replace(day=1)\n\n# Calcular el \u00faltimo d\u00eda del mes anterior\nlast_day_previous_month = current_date.replace(day=1) - relativedelta(days=1)\n\n# Formatear las fechas como texto en formato 'dd/MM/yyyy'\nstart_date = first_day_previous_month.strftime('%m/%d/%Y')\nend_date = last_day_previous_month.strftime('%m/%d/%Y')\n\n# Imprimir las fechas\n#logger.info(\"Primer d\u00eda del mes anterior:\", start_date)\n#logger.info(\"\u00daltimo d\u00eda del mes anterior:\", end_date)\n</code></pre> <pre><code>#Fecha_inicial\n#initial_date = '07/01/2017'\n#Fecha_final\n#final_date = '10/01/2017'\n</code></pre> <pre><code>#time.sleep(4)\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. A continuaci\u00f3n, se explica cada parte del c\u00f3digo en detalle:</p> <p>Primero, se define la ruta al ejecutable de ChromeDriver y se establece en la variable de entorno <code>webdriver.chrome.driver</code>. Esto es necesario para que Selenium pueda controlar el navegador Chrome. Luego, se inicializan las variables <code>initial_date</code> y <code>final_date</code> con los valores de <code>start_date</code> y <code>end_date</code>, respectivamente.</p> <p>Se crea una instancia de <code>webdriver.Chrome()</code> para iniciar una sesi\u00f3n de navegador Chrome. No es necesario proporcionar el argumento <code>executable_path</code> ya que la ruta se ha configurado previamente en las variables de entorno. A continuaci\u00f3n, se maximiza la ventana del navegador utilizando el m\u00e9todo <code>maximize_window()</code>.</p> <p>El navegador se dirige a la URL especificada mediante el m\u00e9todo <code>get()</code>. Esta URL parece ser una p\u00e1gina de inicio de sesi\u00f3n de un sistema CRM basado en SAP. Se registra un mensaje informativo indicando el rango de fechas para la descarga utilizando el m\u00e9todo <code>info()</code> del logger.</p> <p>La funci\u00f3n <code>download_file_between_dates()</code> se llama con las fechas inicial y final, as\u00ed como el controlador del navegador. Esta funci\u00f3n se encarga de conectar al sistema C4C, iterar sobre las opciones en un diccionario <code>_dict</code>, y realizar las acciones necesarias para configurar las fechas y descargar el archivo. Se incluye un tiempo de espera para asegurar que la descarga se complete antes de cerrar el navegador.</p> <p>Finalmente, se registra un mensaje informativo indicando que la descarga se ha completado y se cierra la sesi\u00f3n del navegador con <code>driver.quit()</code>. Este script automatiza el proceso de descarga de archivos, lo que puede ser \u00fatil para tareas repetitivas y ahorrar tiempo en la gesti\u00f3n de datos.</p> <pre><code># Replace with the actual path to your ChromeDriver executable\nCHROME_DRIVER_PATH = \"C:\\\\Program Files (x86)\\\\chromedriver.exe\"\nos.environ[\"webdriver.chrome.driver\"] = CHROME_DRIVER_PATH\n\n##Descargar Educacion\ninitial_date = start_date\nfinal_date = end_date\ndriver = webdriver.Chrome()  # No need for executable_path argument\n# Maximizar la ventana del navegador \ndriver.maximize_window()\ndriver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\nlogger.info(f\"Descargando archivo entre {initial_date} y {final_date}\")\ndownload_file_between_dates(initial_date, final_date, driver, _dict)\nlogger.info(f\"Descarga completa entre {initial_date} y {final_date}\")\n\nlogger.info(\"Descargas completadas.\")\n</code></pre> <pre><code>#Descargar Proteccion\n_dict = {\n    \"Ticket_button\" : '//*[@id=\"__button12-img\"]',\n    \"Filter_button\" : '//*[@id=\"findformpaneLkIKPWD61a2ejhlWKfn3Bm_151-img\"]',\n    \"Dates\" : '//*[@id=\"__button51-inner\"]',\n    \"Menu\" :'//*[@id=\"__box4-arrow\"]',\n    \"Entre\" : '//*[@id=\"__item154-content\"]/div/div',\n    \"initial_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_532-datePicker-inner',\n    \"final_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_534-datePicker-inner',\n    \"Aceptar\" : '//*[@id=\"__button77-BDI-content\"]',\n    \"Categoria\" : '//*[@id=\"objectvalueselectorPbJLA_soJqak9j9Ey7mLqvW_346-inputField-vhi\"]',\n    \"Proteccion\" : '//*[@id=\"statictextm9D_2UNbhq6mK7P6aHrdQ0_559-listdefintion_O68bB2vS4gwMYerXwebjm_556-11\"]',\n    \"Go_button\" : '//*[@id=\"findformpaneGLsDRJxMiqEpkW0gKJRoAW_152-goButton-BDI-content\"]',\n    \"Plus_botton\" : '//*[@id=\"actionbuttonmenuCTxPLT0i_qoT0xcR7Kdqnm_131-button-BDI-content\"]',\n    \"Export_button\" : '//*[@id=\"navigationitemQQFWfu3deac0r5R10TiQ10_144-BDI-content\"]',\n    \"Download_button\" : '//*[@id=\"__button97-content\"]' \n}\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde una p\u00e1gina web. Aqu\u00ed est\u00e1 el resumen:</p> <ol> <li>Inicializaci\u00f3n de Fechas: Asigna las fechas de inicio y fin para la descarga.</li> <li>Inicializaci\u00f3n del WebDriver: Inicia el WebDriver de Chrome y maximiza la ventana del navegador.</li> <li>Carga de la URL: Abre la p\u00e1gina web desde la cual se descargar\u00e1 el archivo.</li> <li>Registro de Informaci\u00f3n: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga.</li> <li>Descarga del Archivo: Llama a una funci\u00f3n para descargar el archivo entre las fechas especificadas.</li> <li>C\u00e1lculo del Tiempo: Calcula y registra el tiempo total del proceso ETL.</li> </ol> <pre><code>initial_date = start_date\nfinal_date = end_date\n#driver = webdriver.Chrome()  # Inicializar el WebDriver\ndriver = webdriver.Chrome()  # No need for executable_path argument\n# Maximizar la ventana del navegador \ndriver.maximize_window()\ndriver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\nlogger.info(f\"Descargando archivo entre {initial_date} y {final_date}\")\ndownload_file_between_dates(initial_date, final_date, driver, _dict)\nlogger.info(f\"Descarga completa entre {initial_date} y {final_date}\")\n\n\n\ntiempo_total = time.time() - inicio_etl\nlog_tiempo(logger, f'FINAL ETL --- ', tiempo_total)\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/02.C4C_webscraping_v4_Historico/","title":"3.2. Webscraping Hist\u00f3rico","text":""},{"location":"00.etl/00.etl_02.C4C/02.C4C_webscraping_v4_Historico/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code> y <code>dateutil.relativedelta</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_logger</code>, para configurar el sistema de logging, <code>log_tiempo</code>, para registrar el tiempo de ejecuci\u00f3n, y <code>download_file_between_dates</code>, para manejar la descarga de archivos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se ignoran advertencias espec\u00edficas para evitar distracciones innecesarias durante la ejecuci\u00f3n del script. Si hay otros loggers configurados, tambi\u00e9n se ajusta su nivel de detalle a <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <ol> <li>Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping: Configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</li> <li>Importaci\u00f3n de Librer\u00edas: Importa las librer\u00edas necesarias como <code>selenium</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code>, y <code>dateutil.relativedelta</code>. Tambi\u00e9n se agrega la ruta de la carpeta <code>Funciones</code> al <code>sys.path</code> y se importan funciones espec\u00edficas.</li> <li>Definici\u00f3n de Selectores XPath: Define un diccionario <code>_dict</code> que contiene los selectores XPath necesarios para interactuar con los elementos de la p\u00e1gina web.</li> <li>Inicio del Proceso ETL: Registra el tiempo de inicio y configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n y Formateo de Fechas: Calcula la lista de fechas cada tres meses desde el 06/01/2017 hasta el 06/01/2024 y las formatea en el formato 'mm/dd/yyyy'.</li> <li>Automatizaci\u00f3n de la Descarga de Archivos: Utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. Se inicializa el WebDriver, se abre la URL, y se llama a la funci\u00f3n <code>download_file_between_dates()</code> para realizar la descarga.</li> <li>Registro de Informaci\u00f3n y C\u00e1lculo del Tiempo: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga y calcula el tiempo total del proceso ETL.</li> </ol> <pre><code>## Import libraries\nfrom selenium import webdriver                                          ### selenium version 4.25.0\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\n#from time import datetime\nimport time\nimport datetime\nimport os\nimport logging\nfrom datetime import datetime, timedelta\nfrom dateutil.relativedelta import relativedelta\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../\")) \n\nfrom Utils.Funciones import (\n    setup_logger,log_tiempo,download_file_between_dates\n)\n</code></pre> <pre><code>_dict = {\n    \"Ticket_button\" : '//*[@id=\"__button12-img\"]',\n    \"Filter_button\" : '//*[@id=\"findformpaneLkIKPWD61a2ejhlWKfn3Bm_151-img\"]',\n    \"Dates\" : '//*[@id=\"__button51-inner\"]',\n    \"Menu\" :'//*[@id=\"__box4-arrow\"]',\n    \"Entre\" : '//*[@id=\"__item154-content\"]/div/div',\n    \"initial_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_532-datePicker-inner',\n    \"final_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_534-datePicker-inner',\n    \"Aceptar\" : '//*[@id=\"__button77-BDI-content\"]',\n    \"Categoria\" : '//*[@id=\"objectvalueselectorPbJLA_soJqak9j9Ey7mLqvW_346-inputField-vhi\"]',\n    \"Educacion\" : '//*[@id=\"statictextm9D_2UNbhq6mK7P6aHrdQ0_559-listdefintion_O68bB2vS4gwMYerXwebjm_556-9\"]',\n    \"Go_button\" : '//*[@id=\"findformpaneGLsDRJxMiqEpkW0gKJRoAW_152-goButton-BDI-content\"]',\n    \"Plus_botton\" : '//*[@id=\"actionbuttonmenuCTxPLT0i_qoT0xcR7Kdqnm_131-button-BDI-content\"]',\n    \"Export_button\" : '//*[@id=\"navigationitemQQFWfu3deac0r5R10TiQ10_144-BDI-content\"]',\n    \"Download_button\" : '//*[@id=\"__button97-content\"]' \n}\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/02.C4C_webscraping_v4_Historico/#etl","title":"ETL","text":"<ol> <li>Inicio del Proceso ETL: Registra el tiempo de inicio.</li> <li>Configuraci\u00f3n del Logger: Configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n de Fechas: Calcula la lista de fechas cada tres meses desde el 06/01/2017 hasta el 06/01/2024.</li> <li>Formateo de Fechas: Formatea las fechas calculadas en el formato 'mm/dd/yyyy'.</li> <li>Registro de Fechas: (Comentado) Registra las fechas calculadas.</li> </ol> <p>El c\u00f3digo configura un proceso ETL, calcula fechas relevantes y utiliza un logger para monitorear el proceso.</p> <pre><code>inicio_etl = time.time()\n#---------------------------------------------\nlogger = setup_logger(log_filename='scraper.log', log_level=logging.INFO)  # Cambiado a logging.INFO\nlogger.info('COMIENZO ETL')\n\n\n# Fecha de inicio y fecha de fin\nstart_date = datetime.strptime('06/01/2017', '%m/%d/%Y')\nend_date = datetime.strptime('06/01/2024', '%m/%d/%Y')\n\n# Generar la lista de fechas cada tres meses\ndate_list = []\ncurrent_date = start_date\nwhile current_date &lt;= end_date:\n    date_list.append(current_date.strftime('%m/%d/%Y'))\n    current_date += relativedelta(months=3)\n\n# Imprimir la lista de fechas\n#for date in date_list:\n    #print(date)\n#date_list\n</code></pre> <pre><code>#Fecha_inicial\n#initial_date = '07/01/2017'\n#Fecha_final\n#final_date = '10/01/2017'\n</code></pre> <pre><code>#time.sleep(4)\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. A continuaci\u00f3n, se explica cada parte del c\u00f3digo en detalle:</p> <p>Primero, se define la ruta al ejecutable de ChromeDriver y se establece en la variable de entorno <code>webdriver.chrome.driver</code>. Esto es necesario para que Selenium pueda controlar el navegador Chrome. Luego, se itera sobre los pares de fechas consecutivas generadas previamente en <code>date_list</code>.</p> <p>Se crea una instancia de <code>webdriver.Chrome()</code> para iniciar una sesi\u00f3n de navegador Chrome. No es necesario proporcionar el argumento <code>executable_path</code> ya que la ruta se ha configurado previamente en las variables de entorno. A continuaci\u00f3n, se maximiza la ventana del navegador utilizando el m\u00e9todo <code>maximize_window()</code>.</p> <p>El navegador se dirige a la URL especificada mediante el m\u00e9todo <code>get()</code>. Esta URL parece ser una p\u00e1gina de inicio de sesi\u00f3n de un sistema CRM basado en SAP. Se imprime un mensaje indicando el rango de fechas para la descarga.</p> <p>La funci\u00f3n <code>download_file_between_dates()</code> se llama con las fechas inicial y final, as\u00ed como el controlador del navegador. Esta funci\u00f3n se encarga de conectar al sistema C4C, iterar sobre las opciones en un diccionario <code>_dict</code>, y realizar las acciones necesarias para configurar las fechas y descargar el archivo.</p> <p>Finalmente, se imprime un mensaje indicando que la descarga se ha completado. Este script automatiza el proceso de descarga de archivos, lo que puede ser \u00fatil para tareas repetitivas y ahorrar tiempo en la gesti\u00f3n de datos.</p> <pre><code># Replace with the actual path to your ChromeDriver executable\nCHROME_DRIVER_PATH = \"C:\\\\Program Files (x86)\\\\chromedriver.exe\"\nos.environ[\"webdriver.chrome.driver\"] = CHROME_DRIVER_PATH\n\n# Iterar sobre los pares de fechas consecutivas y ejecutar la funci\u00f3n\n#for i in range(len(date_list[0:3]) - 1): #---Pruebas\nfor i in range(len(date_list) - 1): #--- Historico Total\n    initial_date = date_list[i]\n    final_date = (datetime.strptime(date_list[i + 1], '%m/%d/%Y') - timedelta(days=1)).strftime('%m/%d/%Y')\n    #driver = webdriver.Chrome()  # Inicializar el WebDriver\n    driver = webdriver.Chrome()  # No need for executable_path argument\n    # Maximizar la ventana del navegador \n    driver.maximize_window()\n    driver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\n    print(f\"Descargando archivo entre {initial_date} y {final_date}\")\n    download_file_between_dates(initial_date, final_date, driver, _dict)\n    print(f\"Descarga completa entre {initial_date} y {final_date}\")\n\nprint(\"Descargas completadas.\")\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde una p\u00e1gina web. Aqu\u00ed est\u00e1 el resumen:</p> <ol> <li>Inicializaci\u00f3n de Fechas: Asigna las fechas de inicio y fin para la descarga.</li> <li>Inicializaci\u00f3n del WebDriver: Inicia el WebDriver de Chrome y maximiza la ventana del navegador.</li> <li>Carga de la URL: Abre la p\u00e1gina web desde la cual se descargar\u00e1 el archivo.</li> <li>Registro de Informaci\u00f3n: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga.</li> <li>Descarga del Archivo: Llama a una funci\u00f3n para descargar el archivo entre las fechas especificadas.</li> <li>C\u00e1lculo del Tiempo: Calcula y registra el tiempo total del proceso ETL.</li> <li>Protecci\u00f3n de Datos: Utiliza un diccionario actualizado para seleccionar la categor\u00eda de protecci\u00f3n de datos.</li> </ol> <pre><code>initial_date = start_date.strftime('%m/%d/%Y')\nfinal_date = (end_date - timedelta(days=1)).strftime('%m/%d/%Y')\n#driver = webdriver.Chrome()  # Inicializar el WebDriver\ndriver = webdriver.Chrome()  # No need for executable_path argument\n# Maximizar la ventana del navegador \ndriver.maximize_window()\ndriver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\nprint(f\"Descargando archivo entre {initial_date} y {final_date}\")\ndownload_file_between_dates(initial_date, final_date, driver,_dict)\nprint(f\"Descarga completa entre {initial_date} y {final_date}\")\n\ntiempo_total = time.time() - inicio_etl\nlog_tiempo(logger, f'FINAL ETL --- ', tiempo_total)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/","title":"Funciones.py","text":"<p>Este archivo contiene una serie de funciones automatizadas desarrolladas para gestionar tareas comunes en la manipulaci\u00f3n de datos y la interacci\u00f3n con sistemas externos. Las funciones descritas est\u00e1n dise\u00f1adas principalmente para automatizar procesos en plataformas como SharePoint y sistemas como C4C, as\u00ed como para facilitar el procesamiento de datos utilizando herramientas como Selenium, pandas y xlwings.</p> <p>Las funciones cubren una variedad de tareas, incluyendo:</p> <ol> <li> <p>Autenticaci\u00f3n y acceso a plataformas externas:</p> <ul> <li>Funciones que automatizan el proceso de inicio de sesi\u00f3n y la autenticaci\u00f3n en plataformas como C4C y SharePoint.</li> </ul> </li> <li> <p>Interacci\u00f3n con men\u00fas desplegables y formularios web:</p> <ul> <li>Herramientas para manejar men\u00fas desplegables personalizados y formularios en p\u00e1ginas web, facilitando la automatizaci\u00f3n de interacciones con elementos HTML mediante Selenium.</li> </ul> </li> <li> <p>Descarga y procesamiento de datos:</p> <ul> <li>Funciones que permiten la descarga de archivos desde plataformas externas basadas en fechas, as\u00ed como la transformaci\u00f3n y organizaci\u00f3n de los datos descargados en un formato adecuado para an\u00e1lisis.</li> </ul> </li> <li> <p>Manejo de archivos y directorios:</p> <ul> <li>Funciones que facilitan la gesti\u00f3n de archivos en el sistema de archivos local y en plataformas como SharePoint, incluyendo el renombrado, carga y descarga de archivos.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n de datos:</p> <ul> <li>Funciones espec\u00edficas para preprocesar, normalizar y limpiar los datos antes de ser utilizados o almacenados, asegurando que la informaci\u00f3n est\u00e9 en el formato adecuado para su posterior an\u00e1lisis.</li> </ul> </li> </ol> <p>Este conjunto de herramientas es esencial para mejorar la eficiencia en tareas repetitivas, reduciendo la necesidad de intervenci\u00f3n manual y permitiendo una integraci\u00f3n m\u00e1s fluida entre los sistemas externos y el entorno de trabajo. La automatizaci\u00f3n de estos procesos optimiza el flujo de trabajo y facilita la administraci\u00f3n y procesamiento de grandes vol\u00famenes de datos.</p>"},{"location":"00.etl/Utils/Funciones/#configuracion-e-import-de-librerias","title":"Configuracion e import de Librerias","text":"<p>Este bloque de c\u00f3digo configura el entorno de trabajo importando todas las librer\u00edas necesarias para manipulaci\u00f3n de datos, automatizaci\u00f3n de Excel, autenticaci\u00f3n y automatizaci\u00f3n de navegadores web. <code>Funciones.py</code> importa varias librer\u00edas est\u00e1ndar y externas necesarias para el funcionamiento del script. </p>"},{"location":"00.etl/Utils/Funciones/#librerias-estandar","title":"Librer\u00edas est\u00e1ndar","text":"<ul> <li><code>calendar</code>: Funciones de calendario.</li> <li><code>configparser</code>: Manejo de archivos de configuraci\u00f3n.</li> <li><code>hashlib</code>: Funciones hash seguras.</li> <li><code>json</code>: Trabajo con datos JSON.</li> <li><code>logging</code>: Registro de mensajes.</li> <li><code>os</code>: Interacci\u00f3n con el sistema operativo.</li> <li><code>re</code>: Expresiones regulares.</li> <li><code>time</code>: Funciones relacionadas con el tiempo.</li> <li><code>unicodedata</code>: Manipulaci\u00f3n de datos Unicode.</li> <li><code>datetime</code>: Manejo de fechas y horas.</li> <li><code>timedelta</code>: Diferencia entre fechas o tiempos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#librerias-externas","title":"Librer\u00edas externas","text":"<ul> <li><code>numpy (np)</code>: Computaci\u00f3n num\u00e9rica.</li> <li><code>pandas (pd)</code>: Manipulaci\u00f3n y an\u00e1lisis de datos.</li> <li><code>requests</code>: Solicitudes HTTP.</li> <li><code>xlwings (xw)</code>: Automatizaci\u00f3n de Excel.</li> <li><code>msal</code>: Autenticaci\u00f3n de Microsoft.</li> <li><code>openpyxl</code>: Lectura y escritura de archivos de Excel.</li> <li><code>selenium</code>: Automatizaci\u00f3n de navegadores web.</li> </ul> <p>Dentro de <code>selenium</code>, se importan excepciones y m\u00f3dulos espec\u00edficos para manejar errores y realizar acciones complejas en el navegador.</p> <pre><code># pylint: disable=all\n# Librer\u00edas est\u00e1ndar\nimport calendar\nimport configparser\nimport hashlib\nimport json\nimport logging\nimport os\nimport re\nimport time\nimport unicodedata\nfrom datetime import datetime, timedelta\n\n# Librer\u00edas externas\nimport numpy as np\nimport pandas as pd\nimport requests\nimport xlwings as xw\nfrom msal import ConfidentialClientApplication\nfrom openpyxl import load_workbook\nfrom selenium import webdriver\nfrom selenium.common.exceptions import (\n    ElementNotInteractableException, NoSuchElementException, StaleElementReferenceException, \n    TimeoutException, WebDriverException\n)\nfrom selenium.webdriver.common.action_chains import ActionChains\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.support.ui import Select, WebDriverWait\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#autenticacion-y-configuracion-sharepoint","title":"Autenticacion y Configuracion Sharepoint","text":"<p>Este c\u00f3digo realiza varias tareas relacionadas con la autenticaci\u00f3n y configuraci\u00f3n para procesar archivos en SharePoint. A continuaci\u00f3n, se detalla cada parte del c\u00f3digo:</p> <ol> <li> <p>Inicializaci\u00f3n de Variables:</p> <ul> <li><code>csv_files</code>: Lista de archivos CSV a procesar.</li> <li><code>original_dir</code>: Guarda el directorio de trabajo actual.</li> </ul> </li> <li> <p>Cambio de Directorio:</p> <ul> <li>Guarda el directorio de trabajo actual y cambia al directorio del script.</li> </ul> </li> <li> <p>Lectura de Credenciales:</p> <ul> <li>Lee las credenciales desde un archivo <code>credenciales.env</code>.</li> <li>Procesa las claves y las almacena en un diccionario <code>keys</code>.</li> </ul> </li> <li> <p>Configuraci\u00f3n de MSAL:</p> <ul> <li>Configura la autenticaci\u00f3n usando <code>msal</code> con las credenciales le\u00eddas.</li> <li>Lee la clave privada desde un archivo <code>key.pem</code>.</li> <li>Configura la aplicaci\u00f3n <code>msal</code> con el <code>client_id</code>, <code>authority</code> y <code>client_credential</code>.</li> <li>Adquiere un token de acceso para SharePoint Online.</li> <li>Configura los encabezados de autorizaci\u00f3n para las solicitudes HTTP.</li> </ul> </li> <li> <p>Lectura de Configuraci\u00f3n Adicional:</p> <ul> <li>Lee m\u00e1s credenciales desde un archivo <code>scraping.env</code>.</li> <li>Almacena las credenciales en variables para diferentes servicios.</li> </ul> </li> <li> <p>Restauraci\u00f3n del Directorio Original:</p> <ul> <li>Restaura el directorio de trabajo original.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#resumen","title":"Resumen","text":"<p>Este c\u00f3digo realiza las siguientes tareas:</p> <ol> <li>Guarda y cambia el directorio de trabajo.</li> <li>Lee credenciales desde archivos de configuraci\u00f3n.</li> <li>Configura la autenticaci\u00f3n con MSAL para acceder a SharePoint.</li> <li>Lee configuraciones adicionales para otros servicios.</li> <li>Restaura el directorio de trabajo original.</li> </ol> <p>Este proceso es esencial para asegurar que las credenciales y configuraciones necesarias est\u00e9n disponibles y seguras para el procesamiento de archivos en SharePoint y otros servicios relacionados.</p> <pre><code>#Determina si un archivo es un archivo de Excel o csv para los procesados en Sharepoint\n#csv_files = [\"cede_Listado_Matriculas\",\"emp_Listado_Matriculas\"]\ncsv_files = []\n\n# Guardar el directorio de trabajo actual\noriginal_dir = os.getcwd()\ntry:\n    # Cambiar el directorio de trabajo al directorio del script\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    os.chdir(script_dir)\n\n    # Leer la clave privada desde el archivo key.pem\n    with open('credenciales.env', 'r') as key_file:\n        lines = key_file.readlines()\n\n    # Procesar las claves\n    keys = {}\n    for line in lines:\n        key, value = line.strip().split(\" = \")\n        keys[key] = value.strip('\"')\n\n    client_id = keys.get(\"client_id\")\n    cert_thumbprint = keys.get(\"cert_thumbprint\")\n    tenant_id = keys.get(\"tenant_id\")\n\n    authority = f\"https://login.microsoftonline.com/{tenant_id}\"\n\n    # Leer la clave privada desde el archivo key.pem\n    with open('key.pem', 'r') as key_file:\n        private_key = key_file.read()\n\n    cert = {\n        \"private_key\": private_key,\n        \"thumbprint\": cert_thumbprint,\n    }\n\n    msal_app = ConfidentialClientApplication(\n        client_id=client_id,\n        authority=authority,\n        client_credential=cert,\n    )\n\n    scopes_sharepoint_online = [keys.get(\"scopes_sharepoint_online\")]\n\n    results = msal_app.acquire_token_for_client(scopes_sharepoint_online)\n\n    if \"access_token\" in results:\n        access_token = results.get(\"access_token\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {access_token}\",\n        \"Accept\": \"application/json;odata=verbose\",\n        \"Content-Type\": \"application/json\",\n    }\n\n    sharepoint_base_url = keys.get(\"sharepoint_base_url\")\n\n\n\n    # Leer las credenciales desde el archivo credenciales.env\n    config = configparser.ConfigParser(interpolation=None)\n    config.read('scraping.env')\n\n    # Almacenar las credenciales en variables\n    desarrollo_empresarial_url = config['desarrollo_empresarial']['url'].strip('\"')\n    desarrollo_empresarial_username = config['desarrollo_empresarial']['username'].strip('\"')\n    desarrollo_empresarial_password = config['desarrollo_empresarial']['password'].strip('\"')\n\n    cedesarrollo_url = config['cedesarrollo']['url'].strip('\"')\n    cedesarrollo_username = config['cedesarrollo']['username'].strip('\"')\n    cedesarrollo_password = config['cedesarrollo']['password'].strip('\"')\n\n    C4C_username = config['C4C']['username'].strip('\"')\n    C4C_password = config['C4C']['password'].strip('\"')\nfinally:\n    # Restaurar el directorio de trabajo original\n    os.chdir(original_dir)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-credenciales","title":"Funci\u00f3n <code>credenciales</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito","title":"Prop\u00f3sito","text":"<p>La funci\u00f3n <code>credenciales</code> se utiliza para recuperar las credenciales almacenadas en un archivo de configuraci\u00f3n (<code>scraping.env</code>) seg\u00fan la plataforma especificada. Las credenciales se procesan eliminando cualquier comilla circundante en los valores.</p>"},{"location":"00.etl/Utils/Funciones/#entradas","title":"Entradas","text":"<ul> <li><code>plataforma</code> (str): El nombre de la plataforma para la cual se necesitan las credenciales. Las opciones v\u00e1lidas son:</li> <li><code>\"desarrollo_empresarial\"</code></li> <li><code>\"cedesarrollo\"</code></li> <li><code>\"C4C\"</code></li> </ul>"},{"location":"00.etl/Utils/Funciones/#salidas","title":"Salidas","text":"<p>Dependiendo de la plataforma solicitada:</p> <ul> <li><code>desarrollo_empresarial</code>:<ul> <li>URL</li> <li>Nombre de usuario</li> <li>Contrase\u00f1a</li> </ul> </li> <li><code>cedesarrollo</code>:<ul> <li>URL</li> <li>Nombre de usuario</li> <li>Contrase\u00f1a</li> </ul> </li> <li><code>C4C</code>:<ul> <li>Nombre de usuario</li> <li>Contrase\u00f1a</li> </ul> </li> </ul>"},{"location":"00.etl/Utils/Funciones/#detalles-de-implementacion","title":"Detalles de implementaci\u00f3n","text":"<ol> <li> <p>Cambio temporal del directorio:</p> <ul> <li>Guarda el directorio actual (<code>os.getcwd</code>) y cambia al directorio donde se encuentra el archivo de script (<code>__file__</code>). Esto asegura que <code>scraping.env</code> sea accesible incluso si el script se ejecuta desde un directorio diferente.</li> </ul> </li> <li> <p>Lectura del archivo de configuraci\u00f3n:</p> <ul> <li>Utiliza <code>configparser.ConfigParser</code> con <code>interpolation=None</code> para cargar los valores directamente sin interpolaci\u00f3n.</li> </ul> </li> <li> <p>Eliminaci\u00f3n de comillas:</p> <ul> <li>Se usa la funci\u00f3n <code>remove_quotes</code> para eliminar comillas simples y dobles de los valores cargados.</li> </ul> </li> <li> <p>Restauraci\u00f3n del directorio original:</p> <ul> <li>Una vez procesadas las credenciales, se restaura el directorio original, garantizando que no haya efectos secundarios en otros procesos que utilicen el directorio de trabajo actual.</li> </ul> </li> </ol> <pre><code># Funci\u00f3n para eliminar las comillas del valor\ndef remove_quotes(value):\n    return value.strip('\"').strip(\"'\")\n\ndef credenciales(plataforma):\n    # Guardar el directorio de trabajo actual\n    original_dir = os.getcwd()\n    try:\n        # Cambiar el directorio de trabajo al directorio del script\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        os.chdir(script_dir)\n        # Leer las credenciales desde el archivo scraping.env\n        config = configparser.ConfigParser(interpolation=None)\n        config.read('scraping.env')\n        # Almacenar las credenciales en variables\n        if plataforma == \"desarrollo_empresarial\":\n            desarrollo_empresarial_url = remove_quotes(config['desarrollo_empresarial']['url'])\n            desarrollo_empresarial_username = remove_quotes(config['desarrollo_empresarial']['username'])\n            desarrollo_empresarial_password = remove_quotes(config['desarrollo_empresarial']['password'])\n            return desarrollo_empresarial_url, desarrollo_empresarial_username, desarrollo_empresarial_password\n        elif plataforma == \"cedesarrollo\":\n            cedesarrollo_url = remove_quotes(config['cedesarrollo']['url'])\n            cedesarrollo_username = remove_quotes(config['cedesarrollo']['username'])\n            cedesarrollo_password = remove_quotes(config['cedesarrollo']['password'])\n            return cedesarrollo_url, cedesarrollo_username, cedesarrollo_password\n        elif plataforma == \"C4C\":\n            C4C_username = remove_quotes(config['C4C']['username'])\n            C4C_password = remove_quotes(config['C4C']['password'])\n            return C4C_username, C4C_password\n\n    finally:\n        # Restaurar el directorio de trabajo original\n        os.chdir(original_dir)\n</code></pre> <p><code>generar_periodos</code> crea un conjunto de a\u00f1os desde el a\u00f1o inicial (<code>inicio</code>) hasta el a\u00f1o final (<code>fin</code>), incluyendo ambos extremos. Devuelve un conjunto de enteros \u00fanicos representando los a\u00f1os en el rango especificado.</p> <pre><code>def generar_periodos(inicio, fin):\n    return {year for year in range(inicio, fin + 1)}\n</code></pre> <p><code>dias_del_mes</code> devuelve el n\u00famero de d\u00edas de un mes espec\u00edfico en un a\u00f1o determinado, teniendo en cuenta si el a\u00f1o es bisiesto.</p> <pre><code>def dias_del_mes(mes, anio):\n    \"\"\"Devuelve el n\u00famero de d\u00edas en un mes dado, considerando a\u00f1os bisiestos.\"\"\"\n    return calendar.monthrange(anio, mes)[1]\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-setup_logger","title":"Funci\u00f3n <code>setup_logger</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_1","title":"Prop\u00f3sito","text":"<p>Configura un logger para manejar y formatear mensajes de registro, permitiendo guardar los logs en un archivo y mostrarlos en la consola.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_1","title":"Entradas","text":"<ul> <li><code>log_filename</code> (str): Nombre del archivo donde se almacenar\u00e1n los logs (por defecto, <code>scraper.log</code>).</li> <li><code>log_level</code> (nivel de log): Nivel de severidad de los mensajes registrados (por defecto, <code>logging.DEBUG</code>).</li> <li><code>log_format</code> (str): Formato de los mensajes de log (por defecto, <code>'%(asctime)s - %(levelname)s - %(message)s'</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#salida","title":"Salida","text":"<ul> <li><code>logger</code> (logging.Logger): Objeto configurado para registrar mensajes con los manejadores y formato especificados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#detalles","title":"Detalles","text":"<ol> <li>Configura un logger con el nivel deseado.</li> <li>Define manejadores para archivo y consola.</li> <li>Establece un formato uniforme para los logs.</li> <li>Elimina manejadores existentes en caso de configuraci\u00f3n previa, evitando duplicados.</li> <li>Retorna el logger configurado.</li> </ol> <pre><code>def setup_logger(log_filename='scraper.log', log_level=logging.DEBUG, log_format='%(asctime)s - %(levelname)s - %(message)s'):\n    # Crea un logger con el nivel especificado\n    logger = logging.getLogger()\n    logger.setLevel(log_level)\n\n    # Crea un manejador para el archivo de log\n    file_handler = logging.FileHandler(log_filename)\n    file_handler.setLevel(log_level)\n\n    # Crea un manejador para la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(log_level)\n\n    # Crea un formato para los logs\n    formatter = logging.Formatter(log_format)\n    file_handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n\n    # Si el logger ya tiene manejadores, eliminar todos para evitar duplicados\n    if logger.hasHandlers():\n        logger.handlers.clear()\n\n    # A\u00f1adir los manejadores al logger\n    logger.addHandler(file_handler)\n    logger.addHandler(console_handler)\n\n    return logger\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-log_step_decorator","title":"Funci\u00f3n <code>log_step_decorator</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_2","title":"Prop\u00f3sito","text":"<p>Decora una funci\u00f3n para registrar informaci\u00f3n sobre su ejecuci\u00f3n, incluyendo inicio, finalizaci\u00f3n exitosa o errores, as\u00ed como la duraci\u00f3n del proceso.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_2","title":"Entradas","text":"<ul> <li><code>step_name</code> (str): Nombre descriptivo del paso que se est\u00e1 decorando, utilizado para identificar los registros.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento","title":"Funcionamiento","text":"<ul> <li>Inicio: Registra un mensaje indicando el inicio del paso.</li> <li>Finalizaci\u00f3n exitosa:<ul> <li>Calcula y registra la duraci\u00f3n del paso en segundos o minutos.</li> </ul> </li> <li>Error:<ul> <li>Registra un mensaje de error con la duraci\u00f3n transcurrida y el detalle de la excepci\u00f3n.</li> </ul> </li> <li>Formato: Los mensajes se registran con colores en consola (<code>\\033[92m</code> para \u00e9xito y <code>\\033[91m</code> para errores).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#salida_1","title":"Salida","text":"<ul> <li>Devuelve un decorador que envuelve la funci\u00f3n original, a\u00f1adiendo la funcionalidad de registro.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#detalles-adicionales","title":"Detalles adicionales","text":"<ul> <li>Utiliza un logger configurado previamente para registrar los eventos.</li> <li>Maneja tanto procesos exitosos como excepciones, asegurando que los logs sean informativos.</li> </ul> <pre><code>logger = setup_logger(\"scraper.log\")\ndef log_step_decorator(step_name):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            start_time = time.time()\n            logger.info(f\"\\033[92mIniciando: {step_name}\\033[0m\")\n            try:\n                result = func(*args, **kwargs)\n                duration = time.time() - start_time\n                if duration &gt;= 60:\n                    duration_minutes = duration / 60\n                    logger.info(f\"\"\"\\033[92mProceso '{step_name}' \n                                completado exitosamente en {duration_minutes:.2f} minutos.\\033[0m\"\"\")\n                else:\n                    logger.info(f\"\"\"\\033[92mProceso '{step_name}' \n                                completado exitosamente en {duration:.2f} segundos.\\033[0m\"\"\")\n                return result\n            except Exception as e:\n                duration = time.time() - start_time\n                if duration &gt;= 60:\n                    duration_minutes = duration / 60\n                    logger.error(f\"\\033[91mError en el paso '{step_name}' despu\u00e9s de {duration_minutes:.2f} minutos: {e}\\033[0m\")\n                else:\n                    logger.error(f\"\\033[91mError en el paso '{step_name}' despu\u00e9s de {duration:.2f} segundos: {e}\\033[0m\")\n                raise\n        return wrapper\n    return decorator\n</code></pre> <p><code>log_tiempo</code> registra un mensaje en el logger indicando el tiempo transcurrido, mostrando minutos si supera los 60 segundos. Toma tres par\u00e1metros: <code>logger</code> para manejar el registro, <code>message</code> como texto base y <code>tiempo_transcurrido</code> como duraci\u00f3n en segundos.</p> <pre><code>def log_tiempo(logger, message, tiempo_transcurrido):\n    \"\"\"\n    Funci\u00f3n para registrar tiempo en el logger, mostrando en minutos si es mayor a 60 segundos.\n    Par\u00e1metros:\n     - logger: instancia del logger\n     - message: mensaje base a mostrar\n     - tiempo_transcurrido: tiempo transcurrido en segundos\n    \"\"\"\n    if tiempo_transcurrido &gt;= 60:\n        tiempo_minutos = tiempo_transcurrido / 60\n        logger.info(f'{message} --- {tiempo_minutos:.2f} minutes ---')\n    else:\n        logger.info(f'{message} --- {tiempo_transcurrido:.2f} seconds ---')\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-process_files_from_folder","title":"Funci\u00f3n <code>process_files_from_folder</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_3","title":"Prop\u00f3sito","text":"<p>Procesa archivos de una carpeta de SharePoint que han sido modificados en los \u00faltimos seis meses, almacenando los datos en una lista de DataFrames.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_3","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL de la carpeta en SharePoint desde donde se obtendr\u00e1n los archivos.</li> <li><code>dfs</code> (list): Lista utilizada para almacenar los DataFrames procesados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_1","title":"Funcionamiento","text":"<ol> <li>Listar archivos: Obtiene la lista de archivos en la carpeta de SharePoint.</li> <li>Filtrar por fecha: Identifica archivos modificados en los \u00faltimos seis meses.</li> <li>Procesar archivos:<ul> <li>Recupera el contenido de los archivos seleccionados desde SharePoint.</li> <li>Lee el contenido de los archivos como DataFrames utilizando <code>pandas</code>.</li> <li>Registra informaci\u00f3n sobre el contenido y lo almacena en la lista <code>dfs</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_2","title":"Salida","text":"<ul> <li>No retorna ning\u00fan valor. Modifica la lista <code>dfs</code> proporcionada al agregar los DataFrames procesados.</li> </ul> <pre><code>@log_step_decorator(\"Procesar archivos de una carpeta de SharePoint\")\ndef process_files_from_folder(folder_url, dfs):\n    \"\"\"\n    Procesa los archivos en una carpeta de SharePoint que han sido modificados en los \u00faltimos seis meses.\n\n    Args:\n        folder_url (str): La URL de la carpeta en SharePoint.\n        dfs (list): Una lista para almacenar los DataFrames procesados.\n\n    Returns:\n        None\n    \"\"\"\n    files = list_files_from_sharepoint(folder_url)\n    six_months_ago = datetime.now() - timedelta(days=180)\n\n    for file in files:\n        file_name = file['Name']\n        file_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n        modified_date_str = file['TimeLastModified']\n        modified_date = datetime.strptime(modified_date_str, '%Y-%m-%dT%H:%M:%SZ')\n\n        if modified_date &gt;= six_months_ago:\n            # Obtener el archivo de SharePoint\n            file_content = get_file_from_sharepoint(file_url)\n\n            if file_content:\n                # Leer el archivo Excel sin descargar\n                df = pd.read_excel(file_content)\n                logger.info(\"Contenido de {}:\\n{}\".format(file_name, df.head()))\n                dfs.append(df)\n</code></pre> <p><code>list_files_from_sharepoint</code> obtiene una lista de archivos presentes en una carpeta de SharePoint indicada por la URL proporcionada. Recibe como entrada <code>folder_url</code> (str), que especifica la ubicaci\u00f3n de la carpeta, y devuelve una lista de archivos si la solicitud es exitosa o una lista vac\u00eda en caso de fallo. Tambi\u00e9n registra advertencias en caso de errores durante la solicitud.</p> <pre><code>@log_step_decorator(\"Listar archivos de SharePoint\")\ndef list_files_from_sharepoint(folder_url):\n    \"\"\"\n    Lista los archivos en una carpeta de SharePoint.\n\n    Args:\n        folder_url (str): La URL de la carpeta en SharePoint.\n\n    Returns:\n        list: Una lista de archivos en la carpeta si la solicitud es exitosa.\n        list: Una lista vac\u00eda si la solicitud falla.\n    \"\"\"\n    list_files_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n    response = requests.get(list_files_url, headers=headers)\n\n    if response.status_code == 200:\n        files = response.json()['d']['results']\n        return files\n    else:\n        logger.warning(f\"Error al listar los archivos. C\u00f3digo de estado: {response.status_code}\")\n        return []\n</code></pre> <p><code>get_file_from_sharepoint</code> descarga un archivo desde SharePoint utilizando su URL. Recibe como entrada <code>file_url</code> (str), que especifica la ubicaci\u00f3n del archivo, y devuelve el contenido del archivo como bytes si la solicitud es exitosa. En caso de error, retorna <code>None</code> y registra una advertencia con el c\u00f3digo de estado de la respuesta.</p> <pre><code>@log_step_decorator(\"Obtener archivo de SharePoint\")\ndef get_file_from_sharepoint(file_url):\n    \"\"\"\n    Descarga un archivo desde SharePoint dado su URL.\n\n    Args:\n        file_url (str): La URL del archivo en SharePoint.\n\n    Returns:\n        bytes: El contenido del archivo si la solicitud es exitosa.\n        None: Si la solicitud falla.\n    \"\"\"\n    response = requests.get(file_url, headers=headers)\n    logger.info(f\"Response Status Code: {response.status_code}\")\n\n    if response.status_code == 200:\n        return response.content\n    else:\n        logger.warning(f\"Error al acceder al archivo. C\u00f3digo de estado: {response.status_code}\")\n        return None\n</code></pre> <p><code>_extract_date</code> convierte una fecha extra\u00edda de un nombre de archivo en un objeto <code>datetime.date</code>. Recibe como entrada <code>file_name</code> (str), que contiene la fecha incrustada, y <code>date_pattern</code>, un patr\u00f3n de expresi\u00f3n regular para buscar la fecha. Si encuentra coincidencias, devuelve un objeto <code>datetime.date</code>; de lo contrario, retorna <code>None</code>.</p> <pre><code># Funci\u00f3n para convertir la fecha extra\u00edda en un objeto datetime\ndef _extract_date(file_name,date_pattern):\n    match = date_pattern.search(file_name)\n    if match:\n        day, month, year = map(int, match.groups())\n        return datetime.date(year, month, day)\n    return None\n</code></pre> <p><code>obtener_sharepoint</code> limpia una carpeta local especificada y descarga todos los archivos desde una carpeta de SharePoint hacia esa ubicaci\u00f3n. Recibe como entradas <code>folder_url</code> (str), que indica la URL de la carpeta de SharePoint, y <code>_folder</code> (str), la ruta de la carpeta local donde se guardar\u00e1n los archivos.</p> <pre><code>def obtener_sharepoint(folder_url,_folder):\n    limpiar_carpeta(_folder)\n    download_all_files_from_sharepoint(folder_url, _folder)\n</code></pre> <p>Funci\u00f3n <code>extract_date</code> para convertir la fecha extra\u00edda en un objeto datetime</p> <pre><code>def extract_date(file_name, date_pattern):\n    match = date_pattern.search(file_name)\n    if match:\n        day, month, year = map(int, match.groups())\n        return datetime(year, month, day)  # Usar datetime en lugar de date\n    return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-upload_file_to_sharepoint","title":"Funci\u00f3n <code>upload_file_to_sharepoint</code>","text":"<p>Sube un archivo local a una carpeta de SharePoint especificada. Recibe como entradas:</p> <ul> <li><code>file_path</code> (str): Ruta local del archivo que se desea subir.</li> <li><code>folder_url</code> (str): URL de la carpeta de destino en SharePoint.</li> </ul> <p>Funcionamiento: 1. Validaci\u00f3n de existencia: Verifica que el archivo local exista. 2. Lectura del archivo: Abre el archivo en modo binario y lee su contenido. 3. Preparaci\u00f3n de la URL: Construye la URL para la subida en SharePoint. 4. Encabezados: Configura el encabezado <code>Content-Length</code> con el tama\u00f1o del archivo. 5. Subida: Realiza una solicitud POST para subir el archivo a SharePoint. 6. Logs:     - Registra un mensaje de \u00e9xito si el archivo se sube correctamente (excepto si es un archivo codificado con nombre MD5).     - Registra un error si la subida falla, indicando el c\u00f3digo de estado.</p> <p>Salidas: - No retorna ning\u00fan valor; realiza acciones y registra logs seg\u00fan el resultado.</p> <pre><code>def upload_file_to_sharepoint(file_path, folder_url):\n    if not os.path.exists(file_path):\n        # logging.error(f\"Archivo no encontrado: {file_path}. No se puede subir a SharePoint.\")\n        return\n\n    with open(file_path, \"rb\") as file:\n        file_content = file.read()\n\n    file_name = os.path.basename(file_path)\n    upload_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files/add(url='{file_name}',overwrite=true)\"\n\n    headers['Content-Length'] = str(len(file_content))  # A\u00f1adir encabezado para la longitud del contenido\n\n    response = requests.post(url=upload_url, headers=headers, data=file_content)\n\n    if response.status_code == 200:\n        if re.match(r'^[a-f0-9]{32}\\.xlsx$', file_name):\n            # Archivo codificado, no hacer logging\n            pass\n        else:\n            logging.info(f\"Archivo {file_name} subido exitosamente a SharePoint.\")\n    else:\n        logging.error(f\"Error al subir el archivo {file_name}. C\u00f3digo de estado: {response.status_code}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-actualizar_sharepoint_procesado","title":"Funci\u00f3n <code>actualizar_sharepoint_procesado</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_4","title":"Prop\u00f3sito","text":"<p>Sube un archivo procesado (en formato Excel o CSV) a una carpeta espec\u00edfica en SharePoint, determinada por un identificador ETL. El archivo se genera a partir de un DataFrame proporcionado.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_4","title":"Entradas","text":"<ul> <li><code>df</code> (pandas.DataFrame): Datos procesados que se guardar\u00e1n y subir\u00e1n como archivo.</li> <li><code>etl</code> (str): Identificador del tipo de proceso ETL, utilizado para determinar la carpeta de destino en SharePoint.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_2","title":"Funcionamiento","text":"<ol> <li>Mapeo de ETL a carpeta: Determina la URL de destino en SharePoint seg\u00fan el identificador <code>etl</code> usando el diccionario <code>etl_to_folder_url</code>.</li> <li>Generaci\u00f3n de archivo temporal:<ul> <li>Crea un archivo Excel (<code>.xlsx</code>) o CSV (<code>.csv</code>) a partir del DataFrame.</li> <li>El formato depende de si <code>etl</code> est\u00e1 presente en <code>csv_files</code>.</li> <li>El archivo incluye un timestamp en el nombre para garantizar unicidad.</li> </ul> </li> <li>Subida a SharePoint: Llama a <code>upload_file_to_sharepoint</code> para subir el archivo temporal a la URL correspondiente.</li> <li>Manejo de errores: Si ocurre un error durante la subida, registra un mensaje de error.</li> <li>Limpieza: Elimina el archivo temporal despu\u00e9s de subirlo, asegurando que no queden residuos en el sistema local.</li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_3","title":"Salida","text":"<ul> <li>No retorna valores. Realiza acciones y muestra mensajes en consola para registrar el \u00e9xito o errores durante el proceso.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#excepciones","title":"Excepciones","text":"<ul> <li>Maneja excepciones relacionadas con la subida a SharePoint e informa del error en consola. Limpia siempre los archivos temporales, incluso si ocurre un error.</li> </ul> <pre><code>def actualizar_sharepoint_procesado(df,etl):   \n\n    etl_to_folder_url = {\n        \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/01.Docentes',\n        \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/02.Disenio_Curricular',\n        \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/03.Listado_Matriculas',\n        \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/04.Ingresos',\n        \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/05.Historico_Notas',\n        \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/06.Egresados_Graduados',\n        \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/07.Cancelados_Desertores',\n        \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/01.Docentes',\n        \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/02.Preinscritos',\n        \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/03.Listado_Matriculas',\n        \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/04.Consolidado_inasistencias',\n        \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/05.Estudiantes_cancelados_por_inasistencias',\n        \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/06.Egresados_Graduados'    \n        }\n    # \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'\n    folder_url = etl_to_folder_url.get(etl, \"URL por defecto si no se encuentra el valor de etl\")\n    # Guardar en un archivo Excel temporal del df recibido\n    hoy = datetime.now().strftime(\"%d_%m_%Y_%H_%M\")\n\n    #si etl no esta en csv_files\n    if etl not in csv_files:\n        archivo_temporal = f\"procesado_{etl}_{hoy}.xlsx\"\n        df.to_excel(archivo_temporal, index=False)\n    else:\n        archivo_temporal = f\"procesado_{etl}_{hoy}.csv\"\n        #utf-8-sig para evitar problemas con caracteres especiales\n        df.to_csv(archivo_temporal, index=False, encoding='utf-8-sig')\n    try:\n        upload_file_to_sharepoint(file_path=archivo_temporal, folder_url=folder_url)\n        print(f\"Archivo subido a SharePoint: {archivo_temporal}, folder_url: {folder_url}\")\n    except Exception as e:\n        print(f\"Error al subir el archivo {archivo_temporal} a SharePoint: {e}\")\n    finally:\n        # cerrar el archivo temporal\n        # Eliminar el archivo original despu\u00e9s de procesarlo\n        time.sleep(0.5)  # Pausa de 500ms\n        os.remove(archivo_temporal)\n        print(f\"Archivo original eliminado: {archivo_temporal}\")\n</code></pre> <p><code>actualizar_columna_programa</code> actualiza una columna de destino en un DataFrame bas\u00e1ndose en condiciones de otra columna. Si la columna condicional no es nula y contiene un texto espec\u00edfico (si se proporciona), el valor de una columna origen se copia a la columna destino. Posteriormente, los valores nulos en la columna destino se rellenan usando el m\u00e9todo forward fill. Devuelve el DataFrame actualizado.</p> <pre><code>def actualizar_columna_programa(df, columna_condicional, columna_origen, columna_destino, texto_filtro=None):\n    \"\"\"\n    Actualiza una columna destino en un DataFrame en base a una condici\u00f3n de otra columna.\n    Si el valor en columna_condicional no es nulo y contiene un texto espec\u00edfico (opcional),\n    se copia el valor de columna_origen a columna_destino.\n    Luego, los valores nulos en columna_destino se rellenan usando el m\u00e9todo forward fill.\n\n    :param df: DataFrame a procesar.\n    :param columna_condicional: Nombre de la columna para evaluar la condici\u00f3n.\n    :param columna_origen: Nombre de la columna de donde copiar el valor.\n    :param columna_destino: Nombre de la columna destino que ser\u00e1 actualizada.\n    :param texto_filtro: Texto que debe estar presente en la columna_condicional (opcional).\n    :return: DataFrame actualizado.\n    \"\"\"\n    df[columna_destino] = df.apply(\n        lambda row: row[columna_origen]\n        if pd.notnull(row[columna_condicional]) and \n            (texto_filtro in str(row[columna_condicional]) if texto_filtro else True)\n        else None, \n        axis=1\n    )\n    df[columna_destino] = df[columna_destino].ffill()\n    return df\n</code></pre> <p><code>concatenar_dataframes</code> combina m\u00faltiples DataFrames en uno solo, ignorando los \u00edndices originales. Filtra y excluye DataFrames vac\u00edos o aquellos cuyos valores sean completamente nulos antes de la concatenaci\u00f3n. Si no hay DataFrames v\u00e1lidos, retorna un DataFrame vac\u00edo.</p> <pre><code>def concatenar_dataframes(dataframes):\n    # Filtrar DataFrames vac\u00edos o con todos los valores como NA\n    dataframes = [df for df in dataframes if not df.empty and not df.isna().all().all()]\n    if dataframes:\n        return pd.concat(dataframes, ignore_index=True)\n    else:\n        return pd.DataFrame()\n</code></pre> <p><code>process_row</code> procesa una fila de un DataFrame modificando columnas espec\u00edficas en funci\u00f3n del contenido de la columna <code>'Columna_15'</code>. Tambi\u00e9n actualiza dos indicadores booleanos, <code>found_porcentaje</code> y <code>found_creditos</code>, que rastrean si se encontraron palabras clave espec\u00edficas:</p> <ul> <li> <p>Condiciones:</p> <ul> <li>Si <code>'Columna_15'</code> es una cadena que contiene \"Porcentaje\", activa <code>found_porcentaje</code> y desactiva <code>found_creditos</code>.</li> <li>Si <code>'Columna_15'</code> es \"Creditos\", activa <code>found_creditos</code> y desactiva <code>found_porcentaje</code>.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Si <code>found_porcentaje</code> es <code>True</code>, copia el valor de <code>'Columna_15'</code> en <code>'Columna_16'</code>.</li> <li>Si <code>found_creditos</code> es <code>True</code>, copia el valor de <code>'Columna_15'</code> en <code>'Columna_14'</code>.</li> </ul> </li> </ul> <p>Devuelve la fila actualizada junto con los valores actualizados de <code>found_porcentaje</code> y <code>found_creditos</code>.</p> <pre><code>def process_row(row, found_porcentaje, found_creditos):\n    if isinstance(row['Columna_15'], str) and 'Porcentaje' in row['Columna_15']:\n        found_porcentaje = True\n        found_creditos = False\n    elif row['Columna_15'] == 'Creditos':\n        found_creditos = True\n        found_porcentaje = False\n    if found_porcentaje:\n        row['Columna_16'] = row['Columna_15']\n    elif found_creditos:\n        row['Columna_14'] = row['Columna_15']\n    return row, found_porcentaje, found_creditos\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar_excel_con_hojas","title":"Funci\u00f3n <code>procesar_excel_con_hojas</code>","text":"<p>Procesa un archivo Excel con m\u00faltiples hojas, combinando los datos seg\u00fan reglas espec\u00edficas:</p> <ol> <li> <p>Lectura inicial:</p> <ul> <li>Carga todas las hojas del archivo Excel.</li> <li>Procesa la primera hoja directamente.</li> </ul> </li> <li> <p>Procesamiento de hojas restantes:</p> <ul> <li>Identifica el inicio de los datos en cada hoja mediante la primera fila no nula de la columna A.</li> <li>Si los datos de la hoja comienzan con \"1\" en la columna A, combina alineando por esta columna usando un merge.</li> <li>Si no comienzan con \"1\", concatena los datos al final, continuando el listado.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve un \u00fanico DataFrame que combina los datos procesados de todas las hojas seg\u00fan las reglas descritas.</li> </ul> </li> </ol> <pre><code>def procesar_excel_con_hojas(file_path):\n    # Leer todas las hojas\n    excel_data = pd.ExcelFile(file_path)\n    hojas = excel_data.sheet_names\n\n    # Procesar la primera hoja directamente\n    hoja1 = pd.read_excel(file_path, sheet_name=hojas[0])\n\n    # Procesar las dem\u00e1s hojas\n    for sheet_name in hojas[1:]:\n        hoja_actual = pd.read_excel(file_path, sheet_name=sheet_name)\n\n        # Identificar d\u00f3nde empiezan los datos en la columna A\n        inicio_datos = hoja_actual[hoja_actual.iloc[:, 0].notna()].index[0]\n        hoja_actual = hoja_actual.iloc[inicio_datos:].reset_index(drop=True)\n\n        # Verificar si la columna A comienza con 1\n        if hoja_actual.iloc[0, 0] == 1:\n            # Combinar alineando por la columna A\n            hoja1 = pd.merge(\n                hoja1,\n                hoja_actual,\n                left_on=hoja1.columns[0],\n                right_on=hoja_actual.columns[0],\n                how=\"left\",\n            )\n        else:\n            # Agregar datos debajo continuando el listado\n\n            if not hoja_actual.empty:\n                hoja1 = pd.concat([hoja1, hoja_actual], ignore_index=True)\n\n    return hoja1\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-limpiar_columnas","title":"Funci\u00f3n <code>limpiar_columnas</code>","text":"<p>Realiza tareas de limpieza y transformaci\u00f3n en un DataFrame:</p> <ol> <li> <p>Eliminaci\u00f3n de columnas:</p> <ul> <li>Elimina las columnas especificadas en <code>columnas_a_eliminar</code> si existen en el DataFrame.</li> </ul> </li> <li> <p>Renombrado de columnas:</p> <ul> <li>Renombra columnas seg\u00fan el mapeo proporcionado en el diccionario <code>renombres</code>.</li> </ul> </li> <li> <p>Conversi\u00f3n a may\u00fasculas:</p> <ul> <li>Convierte todos los nombres de columnas a may\u00fasculas si se proporciona <code>columnas_a_mayusculas</code>.</li> </ul> </li> </ol> <p>Par\u00e1metros: - <code>df</code>: DataFrame a procesar. - <code>columnas_a_eliminar</code> (list): Lista de nombres de columnas a eliminar. - <code>renombres</code> (dict): Diccionario de renombramiento <code>{nombre_actual: nuevo_nombre}</code>. - <code>columnas_a_mayusculas</code> (bool, opcional): Si se proporciona, convierte los nombres de todas las columnas a may\u00fasculas.</p> <p>Salida: Devuelve el DataFrame transformado.</p> <pre><code>def limpiar_columnas(df, columnas_a_eliminar, renombres, columnas_a_mayusculas=None):\n    df = df.drop(columns=[col for col in columnas_a_eliminar if col in df.columns], errors='ignore')\n    df = df.rename(columns=renombres)\n    # COLOCAR TODAS LAS COLUMNAS EN MAY\u00daSCULAS\n    if columnas_a_mayusculas:\n        df.columns = df.columns.str.upper()\n    return df\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-replace_values_df","title":"Funci\u00f3n <code>replace_values_df</code>","text":"<p>Reemplaza valores en un DataFrame bas\u00e1ndose en un diccionario de sustituciones. Si no se especifica un diccionario <code>replacements</code>, utiliza uno predeterminado donde la columna <code>'Tipo de documento'</code> mapea valores largos como <code>'C\u00e9dula de Ciudadan\u00eda'</code> a formas abreviadas como <code>'CC'</code>. Itera por las columnas del diccionario y aplica los cambios definidos, devolviendo el DataFrame actualizado.</p> <p><code>_dict</code> contiene las claves y valores para reemplazar los tipos de documentos en espa\u00f1ol con sus correspondientes abreviaturas:</p> <ul> <li>C\u00e9dula de Ciudadan\u00eda: 'CC'</li> <li>Tarjeta de Identidad: 'TI'</li> <li>Registro Civil de Nacimiento: 'RC'</li> <li>C\u00e9dula \u00f3 Identificaci\u00f3n de Extranjer\u00eda: 'CE'</li> <li>Permiso de Protecci\u00f3n Temporal: 'PPT'</li> <li>Permiso Especial de Permanencia: 'PEP'</li> <li>N\u00famero de Identificaci\u00f3n Tributaria: 'NIT'</li> <li>C\u00f3digo NES: 'NES'</li> <li>Pasaporte: 'PA'</li> <li>Otros: 'OTRO' <pre><code>```python\n# Define the dictionary with the replacements\n_dict = {\n            'C\u00e9dula de Ciudadan\u00eda': 'CC',\n            'Tarjeta de Identidad': 'TI',\n            'Registro Civil de Nacimiento': 'RC',\n            'C\u00e9dula \u00f3 Identificaci\u00f3n de Extranjer\u00eda': 'CE',\n            'Permiso de Protecci\u00f3n Temporal': 'PPT',\n            'Permiso Especial de Permanencia': 'PEP',\n            'N\u00famero de Identificaci\u00f3n Tributaria': 'NIT',\n            'C\u00f3digo NES': 'NES',\n            'Pasaporte': 'PA',\n            'Otros': 'OTRO',\n            }\n\n# Define the function to replace values based on a dictionary\ndef replace_values_df(df, replacements=None):\n    if replacements is None:\n        replacements = {'Tipo de documento': _dict}\n\n    for column, changes in replacements.items():\n        df[column] = df[column].replace(changes)\n    return df\n</code></pre></li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcion-download_all_files_from_sharepoint","title":"Funci\u00f3n <code>download_all_files_from_sharepoint</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_5","title":"Prop\u00f3sito","text":"<p>Descarga todos los archivos de una carpeta de SharePoint a un directorio local especificado, asegurando que el directorio local sea creado o limpiado antes de la descarga.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_5","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL relativa de la carpeta en SharePoint.</li> <li><code>local_folder_path</code> (str): Ruta local donde se descargar\u00e1n los archivos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_3","title":"Funcionamiento","text":"<ol> <li> <p>Preparaci\u00f3n del directorio local:</p> <ul> <li>Verifica si el directorio existe:</li> <li>Si existe, elimina los archivos existentes.</li> <li>Si no existe, lo crea.</li> </ul> </li> <li> <p>Listado de archivos en SharePoint:</p> <ul> <li>Env\u00eda una solicitud HTTP para obtener la lista de archivos en la carpeta especificada.</li> <li>Procesa la respuesta JSON para obtener los detalles de los archivos.</li> </ul> </li> <li> <p>Descarga de archivos:</p> <ul> <li>Itera sobre la lista de archivos.</li> <li>Descarga cada archivo desde SharePoint y lo guarda en el directorio local.</li> <li>Registra informaci\u00f3n sobre cada archivo descargado o errores si ocurren durante la descarga.</li> </ul> </li> <li> <p>Manejo de sesiones HTTP:</p> <ul> <li>Utiliza una sesi\u00f3n HTTP para realizar las solicitudes.</li> <li>Configura un timeout para prevenir bloqueos.</li> <li>Cierra la sesi\u00f3n al finalizar.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_4","title":"Salida","text":"<ul> <li>No retorna valores. Registra los eventos relacionados con la limpieza del directorio, descarga de archivos y manejo de errores en el logger configurado.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#manejo-de-errores","title":"Manejo de errores","text":"<ul> <li>Registra errores en:</li> <li>Listado de archivos (problemas de red, tiempo de espera, etc.).</li> <li>Descarga de archivos individuales (problemas con la conexi\u00f3n o permisos).</li> <li>Asegura la limpieza del directorio local y el cierre de la sesi\u00f3n HTTP incluso en caso de errores.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones","title":"Consideraciones","text":"<ul> <li>La funci\u00f3n utiliza un decorador <code>log_step_decorator</code> para registrar el inicio, \u00e9xito o error del proceso completo.</li> </ul> <pre><code># Funci\u00f3n para descargar todos los archivos de una carpeta en SharePoint\n@log_step_decorator(\"Descargar archivos de SharePoint\")\ndef download_all_files_from_sharepoint(folder_url, local_folder_path):\n    # Asegurarnos de que el directorio local existe y limpiarlo\n    if os.path.exists(local_folder_path):\n        for file in os.listdir(local_folder_path):\n            file_path = os.path.join(local_folder_path, file)\n            try:\n                os.remove(file_path)\n                logger.info(f\"Archivo eliminado: {file}\")\n            except Exception as e:\n                logger.error(f\"No se pudo eliminar el archivo {file}. Error: {e}\")\n    else:\n        os.makedirs(local_folder_path)\n\n    # Crear una sesi\u00f3n para manejar las solicitudes HTTP\n    session = requests.Session()\n    session.headers.update(headers)  # Asegurar que los encabezados est\u00e1n configurados\n\n    # URL para listar los archivos de la carpeta en SharePoint\n    list_files_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n\n    try:\n        # Solicitud para obtener la lista de archivos\n        response = session.get(list_files_url, timeout=30)  # Configurar un timeout para evitar bloqueos\n        response.raise_for_status()  # Levantar un error si el c\u00f3digo de estado no es 200\n    except requests.exceptions.RequestException as e:\n        logger.error(f\"Error al listar los archivos de la carpeta. Detalles: {e}\")\n        session.close()\n        return\n\n    # Procesar la respuesta JSON\n    files = response.json().get('d', {}).get('results', [])\n    if not files:\n        logger.info(\"No hay archivos en la carpeta especificada.\")\n        session.close()\n        return\n\n    # Descargar cada archivo\n    for file in files:\n        file_name = file['Name']\n        file_url = file['ServerRelativeUrl']\n        download_url = f\"{sharepoint_base_url}/_api/web/GetFileByServerRelativeUrl('{file_url}')/$value\"\n        local_file_path = os.path.join(local_folder_path, file_name)\n\n        try:\n            file_response = session.get(download_url, timeout=30)  # Configurar timeout para cada descarga\n            file_response.raise_for_status()\n            with open(local_file_path, \"wb\") as local_file:\n                local_file.write(file_response.content)\n            logger.info(f\"Archivo descargado: {file_name}\")\n        except requests.exceptions.RequestException as e:\n            logger.error(f\"Error al descargar el archivo {file_name}. Detalles: {e}\")\n        time.sleep(1)  # A\u00f1adir un peque\u00f1o retraso entre descargas para evitar saturar el servidor\n\n    # Cerrar la sesi\u00f3n HTTP\n    session.close()\n</code></pre> <p><code>corregir_nombre_archivo</code> ajusta un nombre de archivo para cumplir con las restricciones del sistema de archivos. Reemplaza caracteres prohibidos (<code>\\ / : * ? \" &lt; &gt; |</code>) con guiones bajos, elimina guiones bajos consecutivos, y asegura que la longitud total no exceda los 255 caracteres. Retorna el nombre corregido.</p> <pre><code>def corregir_nombre_archivo(nuevo_nombre):\n    # Reemplazar caracteres prohibidos por un guion bajo\n    nuevo_nombre = re.sub(r'[\\\\/:*?\"&lt;&gt;|]', '_', nuevo_nombre)\n\n    # Reemplazar m\u00faltiples guiones bajos consecutivos por uno solo\n    nuevo_nombre = re.sub(r'_+', '_', nuevo_nombre)\n\n    # Limitar la longitud total a 255 caracteres\n    base_name, extension = os.path.splitext(nuevo_nombre)\n    if len(base_name) + len(extension) &gt; 255:\n        base_name = base_name[:127] + base_name[-(127 - len(extension)):]\n\n    # Retornar nombre corregido\n    return base_name + extension\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar","title":"Funci\u00f3n <code>procesar</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_6","title":"Prop\u00f3sito","text":"<p>Gestiona el procesamiento y renombrado de archivos en un directorio de descargas basado en un tipo de proceso ETL especificado. Los archivos se renombran seg\u00fan reglas espec\u00edficas y se cargan en una ubicaci\u00f3n correspondiente en SharePoint.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_6","title":"Entradas","text":"<ul> <li><code>etl</code> (str): Identificador del tipo de proceso ETL que determina las reglas de procesamiento y el destino en SharePoint.</li> <li><code>download_dir</code> (str): Ruta del directorio donde se encuentran los archivos a procesar.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_4","title":"Funcionamiento","text":"<ol> <li> <p>Iteraci\u00f3n sobre archivos:</p> <ul> <li>Procesa \u00fanicamente archivos con la extensi\u00f3n <code>.xlsx</code>.</li> <li>Intenta cargar y analizar cada archivo usando <code>openpyxl</code>.</li> </ul> </li> <li> <p>Reglas de procesamiento espec\u00edficas por ETL:</p> <ul> <li>Renombra los archivos bas\u00e1ndose en contenido de celdas espec\u00edficas o estructuras predefinidas.</li> <li>Aplica reglas personalizadas seg\u00fan el tipo de ETL, como extracci\u00f3n de fechas, nombres descriptivos o combinaci\u00f3n de valores en celdas.</li> </ul> </li> <li> <p>Renombrado de archivos:</p> <ul> <li>Genera nombres corregidos que cumplen con las restricciones del sistema de archivos.</li> <li>Verifica la existencia del archivo renombrado antes de continuar.</li> </ul> </li> <li> <p>Subida a SharePoint:</p> <ul> <li>Determina la carpeta de destino en SharePoint seg\u00fan el identificador ETL.</li> <li>Sube los archivos procesados a la carpeta correspondiente.</li> </ul> </li> <li> <p>Limpieza:</p> <ul> <li>Elimina archivos originales y temporales despu\u00e9s del procesamiento o subida.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_5","title":"Salida","text":"<ul> <li>No retorna valores. Registra mensajes en consola sobre el estado del procesamiento, subida o errores encontrados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#manejo-de-errores_1","title":"Manejo de errores","text":"<ul> <li>Captura y maneja excepciones en:</li> <li>Lectura y procesamiento de archivos.</li> <li>Renombrado de archivos.</li> <li>Subida a SharePoint.</li> <li>Registra detalles del error o marca archivos omitidos para su posterior revisi\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_1","title":"Consideraciones","text":"<ul> <li>Las reglas espec\u00edficas por ETL permiten flexibilidad para distintos tipos de procesamiento.</li> </ul> <pre><code>def procesar(etl, download_dir):\n    # Lista para almacenar las rutas completas de los archivos procesados y originales\n    archivos_a_subir = []\n\n    # Iterar sobre todos los archivos en el directorio de descargas\n    for archivo in os.listdir(download_dir):\n        if archivo.endswith('.xlsx'):  # Procesar solo archivos Excel\n            archivo_path = os.path.join(download_dir, archivo)\n            print(f\"Procesando archivo: {archivo}\")\n            # Intentar cargar el archivo Excel\n            try:\n                wb = load_workbook(archivo_path,data_only=True)\n                try:\n                    ws = wb.active\n                    fecha = datetime.now().strftime(\"%d_%m_%Y\")\n                    match etl:\n                        case \"C4C\":\n                            nuevo_nombre = f\"archivo_{fecha}.xlsx\"\n                            nuevo_path = os.path.join(download_dir, nuevo_nombre)\n                            os.makedirs(os.path.dirname(nuevo_path), exist_ok=True)  # Ensure directory exists\n\n                        case \"emp_Consolidado_inasistencias\":\n                            sede_jornada = ws['D6'].value.strip() if ws['D6'].value else \"SIN_SEDE\"\n                            curso = ws['F6'].value.strip() if ws['F6'].value else \"SIN_CURSO\"\n                            periodo = ws['M6'].value.strip() if ws['M6'].value else \"SIN_PERIODO\"\n\n                            nuevo_nombre = f\"Inasistencias_{sede_jornada}_{curso}_{periodo}_{fecha}.xlsx\"\n                            nuevo_path = os.path.join(download_dir, nuevo_nombre)\n                            os.makedirs(os.path.dirname(nuevo_path), exist_ok=True)  # Ensure directory exists\n\n                            if \"SIN\" in [sede_jornada, curso, periodo]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue\n\n                        case \"cede_Cancelados_Desertores\":\n                            # Filtrar y limpiar las fechas\n                            filtro_fechas = [cell.value for cell in ws['I'] if cell.value is not None and cell.value != 'Fecha']\n                            # Eliminar el primer valor si existe\n                            if filtro_fechas:\n                                filtro_fechas.pop(0)\n                            if not filtro_fechas:\n                                filtro_fechas = [cell.value for cell in ws['H'] if cell.value is not None and cell.value != 'Fecha']\n                            # Convertir todas las fechas a objetos datetime\n                            fechas = []\n                            for fecha in filtro_fechas:\n                                try:\n                                    if isinstance(fecha, str):\n                                        fechas.append(datetime.strptime(fecha, \"%d/%m/%Y\"))\n                                    elif isinstance(fecha, datetime):\n                                        fechas.append(fecha)\n                                except ValueError:\n                                    continue\n\n                            if fechas:\n                                fecha_inicio = min(fechas).strftime(\"%d_%m_%Y\")\n                                fecha_fin = max(fechas).strftime(\"%d_%m_%Y\")\n                                nuevo_nombre = f\"Cancelados_desertores_{fecha_inicio}_{fecha_fin}.xlsx\"\n                            else:\n                                fecha = datetime.now().strftime(\"%d_%m_%Y\")\n                                nuevo_nombre = f\"Cancelados_desertores_{fecha}.xlsx\"\n\n\n\n                        case \"cede_Dise\u00f1o_Curricular\":\n                            nuevo_nombre = f\"Dise\u00f1o_Curricular_{fecha}.xlsx\"\n\n\n                        case \"cede_Docentes\" | \"emp_Docentes\":\n                            nuevo_nombre = f\"Docentes_{fecha}.xlsx\"\n\n\n                        case \"cede_Egresados_Graduados\" | \"emp_Egresados_Graduados\":\n                            archivo_sin_ext = os.path.splitext(archivo)[0]\n                            nuevo_nombre = f\"{archivo_sin_ext}_{fecha}.xlsx\"\n\n                        case \"emp_Estudiantes_inasistencias\":\n                            periodo = ws['A7'].value.strip() if ws['A7'].value else \"SIN_DPTO\"\n                            periodo = periodo.replace(\":\", \"\").strip()\n                            nuevo_nombre = f\"emp_Estudiantes_inasistencias_{periodo}.xlsx\"\n\n\n                            if \"SIN_DPTO\" in [periodo]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue\n                        case \"cede_Historico_Notas\":\n                            periodo = ws['J5'].value.strip() if ws['J5'].value else \"SIN_CURSO\"\n                            nuevo_nombre = f\"Historico_Notas_{periodo}\"\n                            #elimina cualquier espacio en nuevo_nombre\n                            nuevo_nombre = nuevo_nombre.replace(\" \", \"\").replace(\"/\", \"_\").replace(\"-\", \"_\")\n                            #agrega un hash al final del nombre del archivo para que no se repitan\n                            nuevo_nombre = f\"{nuevo_nombre}_{os.urandom(4).hex()}_{fecha}.xlsx\"\n                            if \"SIN_CURSO\" in [periodo]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue\n                        case \"cede_Ingresos\":\n                            # nombre = \"Cajero: Todos  |  Desde: 01/01/2020  |  Hasta: 31/01/2020\"\n                            #estraer de nombre Todos_01_01_2020_31_01_2020\n                            nombre = ws['A7'].value.strip() if ws['A7'].value else \"SIN_CURSO\"\n                            nombre = nombre.replace(\"Cajero: \", \"\")\n                            nombre = nombre.replace(\"Todos\", \"Ingresos\")\n                            nombre = nombre.replace(\"  |  Desde: \", \"_\")\n                            nombre = nombre.replace(\"  |  Hasta: \", \"_\")\n                            nombre = nombre.replace(\"/\", \"_\")\n                            nombre = nombre.replace(\" \", \"\")\n\n                            nuevo_nombre = f\"{nombre}_{fecha}.xlsx\"\n\n\n                            if \"SIN_CURSO\" in [nombre]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue                            \n                            nuevo_nombre\n                        case \"cede_Listado_Matriculas\" | \"emp_Listado_Matriculas\":\n                            nombre = ws['A7'].value.strip() if ws['A7'].value else \"SIN_CURSO\"\n                            # texto de la celda Estado: Todos  |  Desde: 01/01/2016  |  Hasta: 31/12/2016\n                            #nombre final del archivo Listado_Matriculas_01_01_2016_31_12_2016\n                            nombre = nombre.replace(\"Estado: \", \"\")\n                            nombre = nombre.replace(\"Todos\", \"Listado_Matriculas\")                            \n                            nombre = nombre.replace(\"  |  Desde: \", \"_\")\n                            nombre = nombre.replace(\"  |  Hasta: \", \"_\")\n                            nombre = nombre.replace(\"/\", \"_\")\n                            nombre = nombre.replace(\" \", \"\")\n\n                            nuevo_nombre = f\"{nombre}_Act_{fecha}.xlsx\"\n\n\n                            if \"SIN_CURSO\" in [nombre]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue                            \n\n                        case \"emp_Preinscritos\":\n                            archivo_sin_ext = os.path.splitext(archivo)[0]\n                            nuevo_nombre = f\"{archivo_sin_ext}_{fecha}.xlsx\"                           \n                        case _:\n                            print(\"ETL no reconocido, se omite procesamiento.\")\n                            continue\n                except Exception as e:\n                    print(f\"Error al procesar el archivo {archivo}: {e}\")\n                    wb.close() \n                    continue\n                finally:\n                    wb.close()\n                nuevo_nombre = corregir_nombre_archivo(nuevo_nombre)\n                nuevo_path = os.path.join(download_dir, nuevo_nombre)\n                os.makedirs(os.path.dirname(nuevo_path), exist_ok=True)                \n                time.sleep(1)\n                if os.path.exists(nuevo_path):\n                    os.remove(nuevo_path)\n                time.sleep(1.5)  \n\n                # Intentar renombrar el archivo\n                try:\n                    os.rename(archivo_path, nuevo_path)\n                except Exception as e:\n                    print(f\"Error al renombrar el archivo: {e}\")\n                    # input(\"Presione Enter para continuar...\")\n\n                #Verificar que existe el nuevo archivo nuevo_nombre\n                if not os.path.exists(nuevo_path):\n                    print(f\"Error al procesar el archivo {nuevo_nombre}\")\n                    #pausa de teclado\n                    # input(\"Presione Enter para continuar...\")\n                else:\n                    print(f\"Archivo procesado y guardado como: {nuevo_nombre}\")\n                    archivos_a_subir.append(nuevo_path)\n                    # Eliminar el archivo original despu\u00e9s de procesarlo\n                    time.sleep(1)  # Pausa de 500ms\n                    os.remove(archivo_path)\n\n                print(f\"Archivo original eliminado: {archivo}\")\n\n            except Exception as e:\n                if not \"WinError 2\" in str(e):\n                    print(f\"Error al procesar el archivo {archivo}: {e}\")\n                # Agregar el archivo original a la lista de subida incluso si no se proces\u00f3\n                archivos_a_subir.append(archivo_path)\n            time.sleep(1)  # Pausa de 1 segundo entre archivos\n\n    etl_to_folder_url = {\n        \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n        \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n        \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n        \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n        \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n        \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n        \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n        \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n        \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n        \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n        \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n        \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n        \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados',\n        \"C4C\":'Documentos compartidos/02.C4C'   \n        }\n\n    folder_url = etl_to_folder_url.get(etl, \"URL por defecto si no se encuentra el valor de etl\")\n\n    for archivo in archivos_a_subir:\n        try:\n            upload_file_to_sharepoint(file_path=archivo, folder_url=folder_url)\n            time.sleep(1)  # Esperar 1 segundo \n            #pausa de teclado\n            # input(\"Presione Enter para continuar...\")\n            print(f\"Archivo subido a SharePoint: {archivo}\")\n            os.remove(archivo)\n            time.sleep(1)  # Esperar 1 segundo \n        except Exception as e:\n            if re.match(r'^[a-f0-9]{32}\\.xlsx$', archivo):\n                # Archivo codificado, no hacer logging\n                pass\n            else:        \n                print(f\"--Archivo {archivo}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-seleccionar_opcion_con_js","title":"Funci\u00f3n <code>seleccionar_opcion_con_js</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_7","title":"Prop\u00f3sito","text":"<p>Selecciona una opci\u00f3n en un men\u00fa desplegable (dropdown) utilizando JavaScript, lo que permite forzar la interacci\u00f3n en casos donde los m\u00e9todos est\u00e1ndar de Selenium pueden fallar.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_7","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador de Selenium para manejar el navegador.</li> <li><code>xpath_dropdown</code> (str): XPath del bot\u00f3n del dropdown que se desea abrir.</li> <li><code>opcion</code> (str): Texto exacto de la opci\u00f3n que se desea seleccionar en el men\u00fa desplegable.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_5","title":"Funcionamiento","text":"<ol> <li> <p>Abrir el dropdown:</p> <ul> <li>Localiza el elemento del dropdown mediante su XPath.</li> <li>Usa JavaScript para forzar la apertura del men\u00fa desplegable.</li> </ul> </li> <li> <p>Seleccionar la opci\u00f3n:</p> <ul> <li>Busca la opci\u00f3n deseada dentro del men\u00fa desplegable usando su texto.</li> <li>Utiliza JavaScript para hacer clic en la opci\u00f3n seleccionada.</li> </ul> </li> <li> <p>Manejo de tiempos:</p> <ul> <li>Incluye pausas breves entre las acciones para asegurar que los elementos se carguen correctamente.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li><code>TimeoutException</code>: Si el elemento tarda demasiado en cargarse.</li> <li><code>NoSuchElementException</code>: Si no se encuentra la opci\u00f3n especificada.</li> <li><code>Exception</code>: Captura cualquier otro error inesperado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_6","title":"Salida","text":"<ul> <li>No retorna valores. Registra en el log el estado del proceso, incluyendo \u00e9xito o errores. </li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_2","title":"Consideraciones","text":"<ul> <li>Es \u00fatil para casos donde los men\u00fas desplegables tienen comportamientos din\u00e1micos que dificultan su manejo con clics est\u00e1ndar de Selenium.</li> </ul> <pre><code>def seleccionar_opcion_con_js(driver, xpath_dropdown, opcion):\n    \"\"\"\n    Selecciona una opci\u00f3n en un dropdown utilizando JavaScript para forzar el cambio.\n\n    Args:\n        driver: Instancia del controlador de Selenium.\n        xpath_dropdown: XPath del bot\u00f3n del dropdown.\n        opcion: Texto de la opci\u00f3n a seleccionar.\n    \"\"\"\n    try:\n        # Encontrar el elemento dropdown\n        dropdown = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, xpath_dropdown)))\n\n        # Ejecutar JavaScript para abrir el dropdown\n        logging.info(f\"Abriendo dropdown ubicado en: {xpath_dropdown}\")\n        driver.execute_script(\"arguments[0].click();\", dropdown)\n        time.sleep(1)  # Breve pausa para permitir que el dropdown se abra\n\n        # Localizar la opci\u00f3n deseada en el men\u00fa desplegable\n        opcion_xpath = f\"//ul[contains(@class, 'dropdown-menu')]//span[text()='{opcion}']\"\n        opcion_elemento = WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.XPATH, opcion_xpath))\n        )\n\n        # Ejecutar JavaScript para hacer clic en la opci\u00f3n\n        logging.info(f\"Seleccionando opci\u00f3n: {opcion}\")\n        driver.execute_script(\"arguments[0].click();\", opcion_elemento)\n        time.sleep(5)  # Breve pausa para permitir que la opci\u00f3n se seleccione\n        logging.info(f\"Opci\u00f3n '{opcion}' seleccionada correctamente.\")\n    except TimeoutException as e:\n        logging.error(f\"Timeout al intentar seleccionar la opci\u00f3n '{opcion}' en el dropdown: {e}\")\n    except NoSuchElementException as e:\n        logging.error(f\"No se encontr\u00f3 la opci\u00f3n '{opcion}' en el dropdown: {e}\")\n    except Exception as e:\n        logging.error(f\"Error al seleccionar la opci\u00f3n '{opcion}': {e}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-configurar_pasos_autenticacion_des_empresarial","title":"Funci\u00f3n <code>configurar_pasos_autenticacion_des_empresarial</code>","text":"<p>Configura y devuelve una lista de pasos necesarios para autenticar al usuario en el sistema de Desarrollo Empresarial. </p> <p>Funcionamiento:</p> <ol> <li>Obtenci\u00f3n de credenciales: Recupera la URL, el nombre de usuario y la contrase\u00f1a mediante la funci\u00f3n <code>credenciales</code>.</li> <li>Definici\u00f3n de pasos:<ul> <li>Cada paso est\u00e1 representado como una tupla con:<ul> <li>Nombre del paso: Identificador descriptivo del paso.</li> <li>Funci\u00f3n decorada: Acci\u00f3n espec\u00edfica asociada al paso, como abrir la p\u00e1gina de inicio de sesi\u00f3n o ingresar credenciales.</li> <li>Par\u00e1metros: Diccionario con los argumentos requeridos por cada funci\u00f3n.</li> </ul> </li> </ul> </li> <li>Devoluci\u00f3n: Retorna una lista con los pasos configurados, lista para ejecutarse en un flujo de autenticaci\u00f3n.</li> </ol> <pre><code>def configurar_pasos_autenticacion_des_empresarial(driver):\n    \"\"\"\n    Configura y devuelve los pasos de autenticaci\u00f3n para acceder al sistema.\n    \"\"\"\n    # Configuraci\u00f3n de credenciales y URL de autenticaci\u00f3n\n    url, username, password = credenciales(\"desarrollo_empresarial\")\n    pasos_autenticacion = [\n        (\"abrir_pagina\", \n            log_step_decorator(\"abrir_pagina\")(open_login_page), \n            {\n                'driver': driver,\n                'url': url,\n                'wait_time': 10\n            }\n        ),\n        (\"ingresar_credenciales\", \n            log_step_decorator(\"ingresar_credenciales\")(enter_credentials), \n            {\n                'driver': driver,\n                'username': username,\n                'password': password,\n                'wait_time': 10\n            }\n        )\n    ]\n    return pasos_autenticacion\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-configurar_pasos_autenticacion_cedesarrollo","title":"Funci\u00f3n <code>configurar_pasos_autenticacion_cedesarrollo</code>","text":"<p>Configura y devuelve los pasos necesarios para autenticar al usuario en el sistema de Cedesarrollo.</p> <p>Funcionamiento:</p> <ol> <li>Obtenci\u00f3n de credenciales: Recupera la URL, el nombre de usuario y la contrase\u00f1a utilizando la funci\u00f3n <code>credenciales</code> con el identificador <code>\"cedesarrollo\"</code>.</li> <li>Definici\u00f3n de pasos: <ul> <li>Abrir p\u00e1gina: Usa <code>open_login_page</code> para cargar la URL del sistema.</li> <li>Ingresar credenciales: Utiliza <code>enter_credentials</code> para completar los campos de inicio de sesi\u00f3n con el nombre de usuario y la contrase\u00f1a.</li> <li>Cada paso incluye su nombre, la funci\u00f3n asociada decorada con <code>log_step_decorator</code>, y los par\u00e1metros requeridos.</li> </ul> </li> <li>Registro de informaci\u00f3n: Registra la URL utilizada en el log.</li> <li>Salida: Devuelve una lista de pasos configurados para ejecutar el flujo de autenticaci\u00f3n.</li> </ol> <pre><code>def configurar_pasos_autenticacion_cedesarrollo(driver):\n    \"\"\"\n    Configura y devuelve los pasos de autenticaci\u00f3n para acceder al sistema.\n    \"\"\"\n\n    # Configuraci\u00f3n de credenciales y URL de autenticaci\u00f3n\n    url, username, password = credenciales(\"cedesarrollo\")\n    # url = f\"https://site.q10.com/login?ReturnUrl=%2F&amp;aplentId=8fa60f3a-1a89-4048-a798-afd5cda72549\"\n    logging.info(f\"URL: {url}\")\n    pasos_autenticacion = [\n        (\"abrir_pagina\", \n            log_step_decorator(\"abrir_pagina\")(open_login_page), \n            {\n                'driver': driver,\n                'url': url,\n                'wait_time': 10\n            }\n        ),\n        (\"ingresar_credenciales\", \n            log_step_decorator(\"ingresar_credenciales\")(enter_credentials), \n            {\n                'driver': driver,\n                'username': username,\n                'password': password,\n                'wait_time': 10\n            }\n        )\n    ]\n    return pasos_autenticacion\n</code></pre> <p><code>esperar_y_renombrar_archivo</code> monitorea un directorio de descargas para detectar la aparici\u00f3n de un nuevo archivo, esperando hasta 10 segundos, y lo renombra con un nombre base especificado.</p> <p>Funcionamiento:</p> <ol> <li>Detecci\u00f3n de nuevos archivos:     -Obtiene la lista de archivos antes y despu\u00e9s de la espera.     -Identifica los archivos nuevos comparando ambas listas.</li> <li>Renombrar archivo:     -Si se encuentra un archivo nuevo, selecciona el m\u00e1s reciente seg\u00fan la fecha de creaci\u00f3n.     -Renombra el archivo con el nombre base y extensi\u00f3n proporcionados.</li> <li>Manejo de tiempos:     -Espera hasta 10 segundos, verificando cada segundo si hay un archivo nuevo.</li> <li>Resultados:     -Devuelve <code>True</code> si el archivo fue renombrado exitosamente.     -Devuelve <code>False</code> si no se encuentra un nuevo archivo dentro del tiempo l\u00edmite.</li> </ol> <p>Entradas: - <code>download_dir</code> (str): Ruta al directorio donde se espera el archivo. - <code>archivo</code> (str): Nombre base del archivo para renombrar.</p> <p>Salida: - <code>bool</code>: Indica si el renombrado fue exitoso (<code>True</code>) o no (<code>False</code>).</p> <pre><code>def esperar_y_renombrar_archivo(download_dir, archivo):\n    \"\"\"\n    Espera a que un archivo nuevo aparezca en el directorio de descargas y lo renombra.\n\n    Args:\n        download_dir (str): Directorio de descargas.\n        archivo (str): Nombre base del archivo.\n        opcion (str): Opci\u00f3n para renombrar el archivo.\n\n    Returns:\n        bool: True si el archivo fue renombrado exitosamente, False en caso contrario.\n    \"\"\"\n    archivos_antes = set(os.listdir(download_dir))\n\n    # Esperar a que un archivo nuevo aparezca en el directorio\n    for _ in range(10):\n        archivos_despues = set(os.listdir(download_dir))\n        archivos_nuevos = archivos_despues - archivos_antes  # Detectar nuevos archivos\n        if archivos_nuevos:\n            # Obtener el archivo nuevo m\u00e1s reciente\n            latest_file = max(archivos_nuevos, key=lambda f: os.path.getctime(os.path.join(download_dir, f)))\n            latest_file_path = os.path.join(download_dir, latest_file)\n\n            # Renombrar el archivo descargado\n            base_name, extension = os.path.splitext(archivo)\n            new_file_path = os.path.join(download_dir, f'{base_name}{extension}')\n            os.rename(latest_file_path, new_file_path)\n            logging.info(f\"Archivo renombrado a: {new_file_path}\")\n            return True\n        logging.info(\"Esperando que la descarga se complete...\")\n        time.sleep(1)\n\n    logging.error(\"No se encontr\u00f3 un archivo nuevo en el tiempo esperado.\")\n    return False\n</code></pre> <p><code>elemento_disponible</code> verifica si un elemento en el DOM es clickeable dentro de un tiempo de espera especificado. Recibe como argumentos el controlador de Selenium (<code>driver</code>), el tipo de localizador (<code>by</code>), el valor del localizador (<code>value</code>), y un tiempo m\u00e1ximo de espera (<code>timeout</code>). Retorna el elemento web si est\u00e1 disponible, o <code>None</code> en caso de que no sea clickeable en el tiempo especificado, registrando una advertencia en el log.</p> <pre><code>def elemento_disponible(driver, by, value, timeout=5):\n    \"\"\"\n    Verifica si un elemento est\u00e1 presente y es clickeable en el DOM dentro del tiempo especificado.\n\n    Args:\n        driver: Instancia del controlador de Selenium.\n        by: Tipo de localizaci\u00f3n (By.ID, By.XPATH, etc.).\n        value: Valor del localizador.\n        timeout: Tiempo m\u00e1ximo de espera (en segundos).\n\n    Returns:\n        WebElement si el elemento est\u00e1 disponible, None en caso contrario.\n    \"\"\"\n    try:\n        return WebDriverWait(driver, timeout).until(EC.element_to_be_clickable((by, value)))\n    except TimeoutException:\n        logging.warning(f\"Elemento no disponible: {value}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar_reporte_modal","title":"Funci\u00f3n <code>procesar_reporte_modal</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_8","title":"Prop\u00f3sito","text":"<p>Gestiona la exportaci\u00f3n de un reporte desde un modal con un <code>iframe</code>, descargando el archivo en formato <code>XLSX</code>, verificando su aparici\u00f3n en el directorio de descargas y renombr\u00e1ndolo con un nombre espec\u00edfico.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_8","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>download_dir</code> (str): Ruta del directorio de descargas donde se guardar\u00e1 el archivo.</li> <li><code>archivo</code> (str): Nombre con el que se renombrar\u00e1 el archivo descargado.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_6","title":"Funcionamiento","text":"<ol> <li> <p>Acceso al modal:</p> <ul> <li>Espera a que el modal sea visible y cambia al contexto del <code>iframe</code>.</li> </ul> </li> <li> <p>Interacci\u00f3n con el men\u00fa de exportaci\u00f3n:</p> <ul> <li>Hace clic en el elemento <code>exportSelect</code>.</li> <li>Intenta seleccionar la opci\u00f3n <code>XLSX</code>:</li> <li>Navega mediante teclas (flechas y Enter).</li> <li>Alternativamente, utiliza JavaScript para forzar la selecci\u00f3n.</li> </ul> </li> <li> <p>Gesti\u00f3n del archivo descargado:</p> <ul> <li>Verifica la aparici\u00f3n de nuevos archivos en el directorio de descargas.</li> <li>Renombra el archivo m\u00e1s reciente al nombre especificado (<code>archivo</code>).</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera o problemas al interactuar con elementos.</li> <li>Intenta cerrar el modal si ocurre un error.</li> </ul> </li> <li> <p>Finalizaci\u00f3n:</p> <ul> <li>Cierra el modal y regresa al contexto principal del navegador.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_7","title":"Salida","text":"<ul> <li>No retorna valores. Registra eventos y errores en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#manejo-de-errores_2","title":"Manejo de errores","text":"<ul> <li><code>TimeoutException</code>: Si un elemento no est\u00e1 disponible dentro del tiempo l\u00edmite.</li> <li><code>Exception</code>: Captura otros errores inesperados e intenta cerrar el modal.</li> </ul> <pre><code>def procesar_reporte_modal(driver, download_dir, archivo):\n    try:\n        # Esperar hasta que el modal est\u00e9 visible\n        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, \"master-modal\")))\n\n        # Cambiar al contexto del `iframe` dentro del modal\n        WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, \"report\")))\n\n        # Esperar hasta que el elemento 'exportSelect' est\u00e9 visible y hacer clic en \u00e9l\n        export_select = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"exportSelect\")))\n        export_select.click()\n        logging.info(\"Elemento exportSelect clickeado exitosamente.\")\n\n        # Espera adicional para que el men\u00fa de exportaci\u00f3n se despliegue\n        time.sleep(2)\n\n        # Intento 1: Navegar con teclas para seleccionar XLSX\n        export_select.send_keys(Keys.ARROW_DOWN)  # Baja una vez en el men\u00fa\n        export_select.send_keys(Keys.ARROW_DOWN)  # Baja dos veces (ajustar seg\u00fan sea necesario)\n        export_select.send_keys(Keys.ENTER)  # Seleccionar\n\n        logging.info(\"Intento de seleccionar XLSX usando teclas.\")\n\n        # Esperar unos segundos para que el efecto del clic se procese\n        time.sleep(2)\n\n        # Intento 2: Forzar clic en la opci\u00f3n 'XLSX' mediante JavaScript\n        try:\n            xlsx_option_js = driver.find_element(By.XPATH, \"//li[text()='XLSX']\")\n            driver.execute_script(\"arguments[0].click();\", xlsx_option_js)\n            logging.info(\"Opci\u00f3n XLSX seleccionada exitosamente mediante JavaScript.\")\n            time.sleep(2)\n\n\n            # Espera adicional para asegurar el procesamiento del cierre\n            time.sleep(2)\n\n            export_select.send_keys(Keys.ESCAPE)  # Baja una vez en el men\u00fa\n\n\n        except Exception as e:\n            logging.error(f\"No se pudo seleccionar la opci\u00f3n XLSX con JavaScript:\")\n\n        time.sleep(2)\n\n        # Verificar y renombrar el archivo\n        archivos_antes = set(os.listdir(download_dir))\n\n        #eliminar archivo anterior\n        # Eliminar solo el archivo espec\u00edfico si existe\n        file_path = os.path.join(download_dir, archivo)\n        if os.path.exists(file_path):\n            os.remove(file_path)\n            logging.info(f\"Archivo {archivo} eliminado correctamente\")\n\n        for _ in range(2):  # Reducir el tiempo de espera a m\u00e1ximo 5 segundos\n            time.sleep(1)  # Intervalos m\u00e1s cortos\n            archivos_despues = set(os.listdir(download_dir))\n            archivos_nuevos = archivos_despues - archivos_antes\n\n            if archivos_nuevos:\n                # Detectar el archivo m\u00e1s reciente\n                latest_file = max(\n                    archivos_nuevos,\n                    key=lambda f: os.path.getctime(os.path.join(download_dir, f))\n                )\n                latest_file_path = os.path.join(download_dir, latest_file)\n\n                # Renombrar el archivo descargado\n                base_name, extension = os.path.splitext(archivo)\n                new_file_path = os.path.join(download_dir, f'{base_name}{extension or \".xlsx\"}')\n\n                os.rename(latest_file_path, new_file_path)\n                logging.info(f\"Archivo renombrado a: {new_file_path}\")\n                break # Salir del bucle si se renombr\u00f3 correctamente\n        logging.warning(\"No se detect\u00f3 un nuevo archivo en el tiempo l\u00edmite.\")        \n        # Espera adicional para asegurar el procesamiento de la selecci\u00f3n\n        time.sleep(2)\n    except TimeoutException as te:\n        logging.error(f\"Tiempo de espera excedido al procesar el reporte: {te}\")\n    except Exception as e:\n        logging.error(f\"Error al procesar el reporte en el iframe: {e}\")\n        # Esperar hasta que el elemento 'exportSelect' est\u00e9 visible y hacer clic en \u00e9l\n        export_select = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"close\")))\n        export_select.click()\n    finally:\n        # Esperar hasta que el elemento 'exportSelect' est\u00e9 visible y hacer clic en \u00e9l\n        export_select = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"close\")))\n        export_select.click()\n        # Regresar al contexto principal si necesitas realizar m\u00e1s acciones fuera del iframe\n        driver.switch_to.default_content()\n</code></pre> <p><code>normalizar_texto</code> elimina tildes y caracteres especiales de un texto dado. Utiliza <code>unicodedata.normalize</code> para convertir caracteres Unicode a una representaci\u00f3n compatible con ASCII, eliminando acentos y caracteres no est\u00e1ndar. Retorna el texto normalizado.</p> <pre><code>def normalizar_texto(texto):\n    \"\"\"\n    Normaliza un texto eliminando tildes y caracteres especiales.\n    \"\"\"\n    return unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n</code></pre> <p><code>ejecutar_pasos</code> ejecuta de forma secuencial una lista de pasos definidos. Cada paso es una tupla que contiene el nombre del paso (<code>step_name</code>), la funci\u00f3n a ejecutar (<code>step_function</code>), y un diccionario de par\u00e1metros (<code>params</code>). Registra el nombre de cada paso antes de ejecutarlo y llama a la funci\u00f3n correspondiente con los par\u00e1metros proporcionados.</p> <pre><code>\"\"\"\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n\"\"\"\n        # Ejecutar cada uno de los pasos definidos en el diccionario\ndef ejecutar_pasos(pasos):\n    for step_name, step_function, params in pasos:\n        logging.info(f\"Ejecutando el paso: {step_name}\")\n        step_function(**params)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar_opciones_descarga","title":"Funci\u00f3n <code>procesar_opciones_descarga</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_9","title":"Prop\u00f3sito","text":"<p>Automatiza la selecci\u00f3n de opciones en un men\u00fa desplegable (dropdown), descarga los archivos correspondientes y los renombra con base en las opciones seleccionadas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_9","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Controlador de Selenium para manejar el navegador.</li> <li><code>opciones</code> (list): Lista de opciones del dropdown.</li> <li><code>xpath_boton</code> (str): XPath del bot\u00f3n para abrir el dropdown.</li> <li><code>id_descargar</code> (str): ID del bot\u00f3n de descarga.</li> <li><code>nombre_archivo</code> (str): Nombre base del archivo para el renombrado.</li> <li><code>nombre_archivo_completo</code> (str): Nombre completo del archivo descargado.</li> <li><code>download_dir</code> (str): Directorio donde se guardan las descargas.</li> <li><code>wait_time</code> (int): Tiempo de espera despu\u00e9s de cada acci\u00f3n (por defecto 2 segundos).</li> <li><code>xpath_omitir</code> (str, opcional): XPath para omitir popups opcionales.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_7","title":"Funcionamiento","text":"<ol> <li> <p>Preparaci\u00f3n inicial:</p> <ul> <li>Llama a <code>eliminar_archivos_anteriores</code> para limpiar descargas previas en el directorio.</li> </ul> </li> <li> <p>Interacci\u00f3n con el dropdown:</p> <ul> <li>Hace clic en el bot\u00f3n del dropdown para abrirlo.</li> <li>Itera sobre las opciones de la lista:</li> <li>Selecciona una opci\u00f3n usando <code>seleccionar_opcion_custom_dropdown</code>.</li> </ul> </li> <li> <p>Descarga de archivos:</p> <ul> <li>Para cada opci\u00f3n seleccionada:</li> <li>Si el tipo es <code>\"modal\"</code>, procesa la descarga mediante <code>procesar_reporte_modal</code>.</li> <li>En otros casos, utiliza <code>cola_descargar</code> para manejar la descarga y verificarla.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_8","title":"Salida","text":"<ul> <li>No retorna valores. Realiza acciones relacionadas con selecci\u00f3n, descarga y renombrado de archivos.</li> </ul> <pre><code>def procesar_opciones_descarga(driver, opciones, xpath_boton, id_descargar, nombre_archivo, tipo, nombre_archivo_completo, download_dir, wait_time=2, xpath_omitir=None):\n    \"\"\"\n    Itera sobre las opciones de un dropdown, selecciona cada opci\u00f3n, descarga el archivo\n    y renombra el archivo descargado con la opci\u00f3n seleccionada.\n\n    Args:\n        driver (WebDriver): El controlador de Selenium.\n        opciones (list): Lista de opciones del dropdown.\n        xpath_boton (str): XPath del bot\u00f3n para abrir el dropdown.\n        id_descargar (str): ID del bot\u00f3n de descarga.\n        nombre_archivo (str): Nombre base del archivo para renombrar.\n        nombre_archivo_completo (str): Nombre completo del archivo descargado.\n        download_dir (str): Directorio donde se guardan las descargas.\n        wait_time (int): Tiempo de espera despu\u00e9s de cada acci\u00f3n.\n        xpath_omitir (str): XPath opcional para omitir un popup.\n    \"\"\"\n    # Llamada a eliminar archivos anteriores usando el directorio especificado\n    eliminar_archivos_anteriores(nombre_archivo_completo, download_dir=download_dir)\n\n    # Clic en el bot\u00f3n de apertura del dropdown\n    hacer_clic(driver=driver, xpath=xpath_boton, wait_time=5)\n\n    # Itera sobre las opciones para seleccionar y descargar\n    for opcion in opciones:\n        seleccionar_opcion_custom_dropdown(driver=driver, xpath=xpath_boton, option=opcion, wait_time=wait_time)\n\n        # Descargar el archivo\n        if tipo == \"modal\":\n            procesar_reporte_modal(driver)\n        else:\n            se_descargo = cola_descargar(opcion=opcion,download_dir= download_dir,driver=driver, id=id_descargar, archivo=nombre_archivo_completo, wait_time=15, xpath_omitir=xpath_omitir)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-setup_driver","title":"Funci\u00f3n <code>setup_driver</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_10","title":"Prop\u00f3sito","text":"<p>Configura un controlador de Selenium con opciones personalizadas, estableciendo un directorio espec\u00edfico para las descargas de archivos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_10","title":"Entradas","text":"<ul> <li><code>subcarpeta</code> (str): Nombre de la subcarpeta dentro del directorio de descargas base donde se guardar\u00e1n los archivos (por defecto: <code>\"default\"</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_8","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n del directorio de descargas:</p> <ul> <li>Construye la ruta completa para las descargas en la subcarpeta especificada, ubicada dentro de <code>01.Q10/Procesados</code>.</li> <li>Crea el directorio si no existe y registra su creaci\u00f3n o existencia en el log.</li> </ul> </li> <li> <p>Configuraci\u00f3n de Chrome:</p> <ul> <li>Define preferencias espec\u00edficas para descargas:</li> <li>Descargas autom\u00e1ticas sin confirmaci\u00f3n.</li> <li>Actualizaci\u00f3n del directorio de descargas.</li> <li>Habilitaci\u00f3n de la navegaci\u00f3n segura.</li> <li>A\u00f1ade configuraciones para optimizar el navegador:</li> <li>Maximizaci\u00f3n de ventana.</li> <li>Deshabilitaci\u00f3n de caracter\u00edsticas innecesarias y controles autom\u00e1ticos.</li> </ul> </li> <li> <p>Inicia el controlador de Selenium:</p> <ul> <li>Configura un tiempo de espera para la carga de p\u00e1ginas (30 segundos).</li> <li>Registra la configuraci\u00f3n del controlador y la ruta de descargas en el log.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Retorna la instancia del controlador <code>driver</code> y la ruta completa del directorio de descargas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_9","title":"Salida","text":"<ul> <li><code>driver</code> (WebDriver): Instancia configurada del controlador de Selenium.</li> <li><code>download_dir</code> (str): Ruta absoluta del directorio de descargas configurado.</li> </ul> <pre><code>DOWNLOAD_DIR = os.path.join(os.path.abspath(os.getcwd()), \"Procesados\")\n\ndef setup_driver(subcarpeta=\"default\"):\n    \"\"\"\n    Configura el controlador de Selenium y crea la ruta de descargas en la subcarpeta especificada.\n    \"\"\"\n    # Define la ruta completa de descarga en la subcarpeta especificada\n    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # Subir un nivel desde `Codigos`\n    download_dir = os.path.join(base_dir, \"01.Q10\", \"Procesados\", subcarpeta)  # Ruta hacia `01.Q10\\Procesados`\n\n    # Crear el directorio si no existe\n    if not os.path.exists(download_dir):\n        os.makedirs(download_dir)\n        logging.info(f\"Directorio de descargas creado en: {download_dir}\")\n    else:\n        logging.info(f\"Directorio de descargas ya existe: {download_dir}\")\n\n    # Configura las preferencias de Chrome para las descargas\n    chrome_options = webdriver.ChromeOptions()\n    prefs = {\n        \"download.default_directory\": download_dir,\n        \"download.prompt_for_download\": False,\n        \"download.directory_upgrade\": True,\n        \"safebrowsing.enabled\": True\n    }\n    chrome_options.add_experimental_option(\"prefs\", prefs)\n    chrome_options.add_argument('--disable-gpu')\n    chrome_options.add_argument('--no-sandbox')\n    chrome_options.add_argument('--disable-dev-shm-usage')\n    chrome_options.add_argument('--window-size=1920x1080')\n    chrome_options.add_argument('--ignore-certificate-errors')\n    chrome_options.add_argument('--disable-extensions')\n    chrome_options.add_argument('--disable-infobars')\n    chrome_options.add_argument('--start-maximized')\n    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n\n    # Inicia el controlador\n    driver = webdriver.Chrome(options=chrome_options)\n    driver.set_page_load_timeout(30)\n    logging.info(f\"Controlador de Selenium configurado con el directorio de descargas en: {download_dir}\")\n\n    # Retorna el controlador y la ruta de descarga\n    return driver, download_dir\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-setup_driver_c4c","title":"Funci\u00f3n <code>setup_driver_C4C</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_11","title":"Prop\u00f3sito","text":"<p>Configura un controlador de Selenium para automatizaciones en el entorno C4C, estableciendo un directorio espec\u00edfico para descargas en una subcarpeta determinada.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_11","title":"Entradas","text":"<ul> <li><code>subcarpeta</code> (str): Nombre de la subcarpeta dentro del directorio base de descargas, donde se almacenar\u00e1n los archivos (por defecto: <code>\"default\"</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_9","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n del directorio de descargas:</p> <ul> <li>Construye la ruta completa del directorio de descargas en <code>02.C4C/Procesados</code>.</li> <li>Crea el directorio si no existe y registra el resultado en el log.</li> </ul> </li> <li> <p>Configuraci\u00f3n del navegador Chrome:</p> <ul> <li>Define preferencias para la gesti\u00f3n autom\u00e1tica de descargas:</li> <li>Descargas sin solicitud de confirmaci\u00f3n.</li> <li>Navegaci\u00f3n segura habilitada.</li> <li>Actualizaci\u00f3n autom\u00e1tica del directorio de descargas.</li> <li>Configura argumentos adicionales para optimizar el rendimiento y la experiencia del navegador:</li> <li>Maximiza la ventana y deshabilita extensiones y notificaciones innecesarias.</li> </ul> </li> <li> <p>Inicia el controlador de Selenium:</p> <ul> <li>Configura un tiempo de espera m\u00e1ximo para la carga de p\u00e1ginas (30 segundos).</li> <li>Registra en el log la ruta de descargas y la configuraci\u00f3n del controlador.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Retorna el controlador <code>driver</code> y la ruta absoluta del directorio de descargas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_10","title":"Salida","text":"<ul> <li><code>driver</code> (WebDriver): Instancia configurada del controlador de Selenium.</li> <li><code>download_dir</code> (str): Ruta completa del directorio de descargas configurado.</li> </ul> <pre><code># En Funciones.py\ndef setup_driver_C4C(subcarpeta=\"default\"):\n    \"\"\"\n    Configura el controlador de Selenium y crea la ruta de descargas en la subcarpeta especificada.\n    \"\"\"\n    # Define la ruta completa de descarga en la subcarpeta especificada\n    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # Subir un nivel desde `Codigos`\n    download_dir = os.path.join(base_dir, \"02.C4C\", \"Procesados\", subcarpeta)  # Ruta hacia `01.Q10\\Procesados`\n\n    # Crear el directorio si no existe\n    if not os.path.exists(download_dir):\n        os.makedirs(download_dir)\n        logging.info(f\"Directorio de descargas creado en: {download_dir}\")\n    else:\n        logging.info(f\"Directorio de descargas ya existe: {download_dir}\")\n\n    # Configura las preferencias de Chrome para las descargas\n    chrome_options = webdriver.ChromeOptions()\n    prefs = {\n        \"download.default_directory\": download_dir,\n        \"download.prompt_for_download\": False,\n        \"download.directory_upgrade\": True,\n        \"safebrowsing.enabled\": True\n    }\n    chrome_options.add_experimental_option(\"prefs\", prefs)\n    chrome_options.add_argument('--disable-gpu')\n    chrome_options.add_argument('--no-sandbox')\n    chrome_options.add_argument('--disable-dev-shm-usage')\n    chrome_options.add_argument('--window-size=1920x1080')\n    chrome_options.add_argument('--ignore-certificate-errors')\n    chrome_options.add_argument('--disable-extensions')\n    chrome_options.add_argument('--disable-infobars')\n    chrome_options.add_argument('--start-maximized')\n    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n\n    # Inicia el controlador\n    driver = webdriver.Chrome(options=chrome_options)\n    driver.set_page_load_timeout(30)\n    logging.info(f\"Controlador de Selenium configurado con el directorio de descargas en: {download_dir}\")\n\n    # Retorna el controlador y la ruta de descarga\n    return driver, download_dir\n</code></pre> <p><code>open_login_page</code> abre una p\u00e1gina de inicio de sesi\u00f3n en un navegador controlado por Selenium y espera a que el cuerpo de la p\u00e1gina se cargue completamente. Recibe el controlador (<code>driver</code>), la URL de la p\u00e1gina a abrir (<code>url</code>) y un tiempo de espera opcional (<code>wait_time</code>). Registra en el log tanto el inicio como la confirmaci\u00f3n de que la p\u00e1gina se ha abierto correctamente.</p> <pre><code>def open_login_page(driver, url, wait_time=2):\n    logger.info(f\"Abriendo la p\u00e1gina de inicio de sesi\u00f3n: {url}\")\n    driver.get(url)\n    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n    logger.info(f\"P\u00e1gina de inicio de sesi\u00f3n abierta: {url}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-enter_credentials","title":"Funci\u00f3n <code>enter_credentials</code>","text":"<p>Automatiza el ingreso de credenciales en una p\u00e1gina de inicio de sesi\u00f3n controlada por Selenium. </p> <p>Funcionamiento:</p> <ol> <li> <p>Ingreso del nombre de usuario:</p> <ul> <li>Espera hasta que el campo de entrada de usuario est\u00e9 presente (<code>NombreUsuario</code>).</li> <li>Ingresa el valor proporcionado en <code>username</code>.</li> </ul> </li> <li> <p>Ingreso de la contrase\u00f1a:</p> <ul> <li>Espera hasta que el campo de entrada de contrase\u00f1a est\u00e9 presente (<code>Contrasena</code>).</li> <li>Ingresa el valor proporcionado en <code>password</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas, y registra el error en el log antes de lanzarlo nuevamente.</li> </ul> </li> </ol> <p>Entradas:</p> <ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>username</code> (str): Nombre de usuario a ingresar.</li> <li><code>password</code> (str): Contrase\u00f1a asociada al usuario.</li> <li><code>wait_time</code> (int, opcional): Tiempo de espera entre interacciones (por defecto, 1 segundo).</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Realiza acciones y registra eventos o errores en el log.</li> </ul> <pre><code>def enter_credentials(driver, username, password, wait_time=1):\n    # Ingresa las credenciales de usuario en los campos correspondientes\n    try:\n        logging.info(\"Ingresando usuario\")\n        # Esperar hasta que el campo de nombre de usuario est\u00e9 presente y luego ingresar el nombre de usuario\n        username_field = WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.NAME, 'NombreUsuario'))\n        )\n        username_field.send_keys(username)\n        logging.info(\"Nombre de usuario ingresado correctamente\")\n\n        logging.info(\"Ingresando contrase\u00f1a\")\n        # Esperar hasta que el campo de contrase\u00f1a est\u00e9 presente y luego ingresar la contrase\u00f1a\n        password_field = WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.NAME, 'Contrasena'))\n        )\n        password_field.send_keys(password)\n        logging.info(\"Credenciales ingresadas correctamente\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error durante el ingreso de credenciales: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-submit_login","title":"Funci\u00f3n <code>submit_login</code>","text":"<p>Env\u00eda el formulario de inicio de sesi\u00f3n en una p\u00e1gina web controlada por Selenium y verifica que el inicio de sesi\u00f3n haya sido exitoso.</p> <p>Funcionamiento:</p> <ol> <li> <p>Interacci\u00f3n con el bot\u00f3n de inicio de sesi\u00f3n:</p> <ul> <li>Espera hasta que el bot\u00f3n del formulario est\u00e9 presente y sea clickeable (<code>//button[@type=\"submit\"]</code>).</li> <li>Hace clic en el bot\u00f3n para enviar el formulario.</li> </ul> </li> <li> <p>Verificaci\u00f3n del inicio de sesi\u00f3n:</p> <ul> <li>Espera a que un elemento indicativo del post-login (<code>elemento_post_login</code>) est\u00e9 presente para confirmar el \u00e9xito.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o no interactuables, registra el error en el log y lanza nuevamente la excepci\u00f3n.</li> </ul> </li> </ol> <p>Entradas:</p> <ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>wait_time</code> (int, opcional): Tiempo de espera entre interacciones (por defecto, 3 segundos).</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Realiza acciones en la p\u00e1gina y registra en el log el estado del proceso o errores.</li> </ul> <pre><code>def submit_login(driver, wait_time=3):\n    # Env\u00eda el formulario de inicio de sesi\u00f3n\n    try:\n        logging.info(\"Enviando formulario de inicio de sesi\u00f3n\")\n        # Esperar hasta que el bot\u00f3n de inicio de sesi\u00f3n est\u00e9 presente y luego hacer clic\n        login_button = WebDriverWait(driver, 10).until(\n            EC.element_to_be_clickable((By.XPATH, '//button[@type=\"submit\"]'))\n        )\n        login_button.click()\n        # Esperar hasta que un elemento post-login est\u00e9 presente para confirmar el \u00e9xito del inicio de sesi\u00f3n\n        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'elemento_post_login')))\n        logging.info(\"Formulario de inicio de sesi\u00f3n enviado\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException) as e:\n        logging.error(f\"Error al enviar el formulario de inicio de sesi\u00f3n: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-close_driver","title":"Funci\u00f3n <code>close_driver</code>","text":"<p>Cierra de manera segura el navegador controlado por Selenium.</p> <p>Funcionamiento:</p> <ol> <li> <p>Cierre del navegador:</p> <ul> <li>Intenta cerrar la instancia del controlador mediante <code>driver.quit()</code>.</li> <li>Registra en el log que el navegador se cerr\u00f3 correctamente.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura posibles excepciones (<code>WebDriverException</code>) durante el cierre y registra el error en el log.</li> </ul> </li> </ol> <p>Entradas:</p> <ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium que se desea cerrar.</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Realiza la acci\u00f3n de cierre y registra el estado del proceso en el log.</li> </ul> <pre><code>def close_driver(driver):\n    # Cierra el navegador de manera segura\n    logging.info(\"Cerrando el navegador\")\n    try:\n        driver.quit()\n        logging.info(\"Navegador cerrado correctamente\")\n    except WebDriverException as e:\n        logging.error(f\"Error al cerrar el navegador: {e}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-seleccionar_dropdown","title":"Funci\u00f3n <code>seleccionar_dropdown</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_12","title":"Prop\u00f3sito","text":"<p>Selecciona una opci\u00f3n de un men\u00fa desplegable (<code>dropdown</code>) en una p\u00e1gina web controlada por Selenium, utilizando diversos identificadores de localizaci\u00f3n.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_12","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para configurar la selecci\u00f3n:</li> <li><code>option</code> (str): Texto visible de la opci\u00f3n a seleccionar.</li> <li><code>n_option</code> (int): \u00cdndice de la opci\u00f3n a seleccionar.</li> <li><code>wait_time</code> (int, opcional): Tiempo en segundos para esperar despu\u00e9s de realizar la selecci\u00f3n (por defecto: <code>0</code>).</li> <li>Localizadores: Uno de los siguientes:<ul> <li><code>xpath</code> (str): Localizaci\u00f3n del dropdown usando XPath.</li> <li><code>id</code> (str): Identificaci\u00f3n del elemento.</li> <li><code>name</code> (str): Nombre del elemento.</li> <li><code>class_name</code> (str): Clase del elemento.</li> <li><code>css_selector</code> (str): Selector CSS.</li> </ul> </li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_10","title":"Funcionamiento","text":"<ol> <li> <p>Localizaci\u00f3n del dropdown:</p> <ul> <li>Determina el tipo de localizador (<code>id</code>, <code>xpath</code>, etc.) y su valor.</li> <li>Encuentra el elemento correspondiente en el DOM usando <code>WebDriverWait</code>.</li> </ul> </li> <li> <p>Selecci\u00f3n de la opci\u00f3n:</p> <ul> <li>Si se proporciona <code>option</code>, selecciona la opci\u00f3n por texto visible.</li> <li>Si se proporciona <code>n_option</code>, selecciona la opci\u00f3n por \u00edndice.</li> <li>Lanza un error si no se proporciona ninguna opci\u00f3n v\u00e1lida.</li> </ul> </li> <li> <p>Espera opcional:</p> <ul> <li>Realiza una pausa tras la selecci\u00f3n si se especifica <code>wait_time</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas.</li> <li>Registra el error en el log y lanza la excepci\u00f3n.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_11","title":"Salida","text":"<ul> <li>No retorna valores. Realiza la selecci\u00f3n en el dropdown y registra el estado del proceso en el log.</li> </ul> <pre><code>def seleccionar_dropdown(driver, **kwargs):\n    try:\n        logging.info(f\"Seleccionando opci\u00f3n del dropdown especificado\")\n\n        # Recoger 'wait_time' de kwargs o establecer un valor por defecto\n        wait_time = kwargs.get('wait_time', 0)\n\n        # Recorrer las posibles opciones de identificador y localizar el elemento\n        locator_type, locator_value, option_value, n_option = None, None, None, None\n        for key, value in kwargs.items():\n            if key == 'option':\n                option_value = value\n            elif key == 'n_option':\n                n_option = value\n            elif value is not None and key != 'wait_time':\n                locator_type = key\n                locator_value = value\n\n        # Verificar si se proporcion\u00f3 un localizador v\u00e1lido\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar una ubicaci\u00f3n v\u00e1lida para seleccionar un dropdown\")\n\n        # Convertir el identificador a By adecuado\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR\n        }\n        dropdown_element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((by_mapping[locator_type], locator_value)))\n        select = Select(dropdown_element)\n\n        # Seleccionar la opci\u00f3n por texto visible o por \u00edndice\n        if option_value is not None:\n            select.select_by_visible_text(option_value)\n            logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente en el dropdown\")\n        elif n_option is not None:\n            select.select_by_index(n_option)\n            logging.info(f\"Opci\u00f3n en el \u00edndice '{n_option}' seleccionada correctamente en el dropdown\")\n        else:\n            raise ValueError(\"Debe proporcionar un valor v\u00e1lido para seleccionar una opci\u00f3n en el dropdown\")\n\n        # Esperar el tiempo especificado si se proporcion\u00f3\n        if wait_time &gt; 0:\n            time.sleep(wait_time)\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al seleccionar la opci\u00f3n del dropdown: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-hacer_clic","title":"Funci\u00f3n <code>hacer_clic</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_13","title":"Prop\u00f3sito","text":"<p>Localiza un elemento en una p\u00e1gina web mediante un tipo de localizador, realiza clic en \u00e9l y, opcionalmente, interact\u00faa con un campo de entrada configurando un valor.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_13","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para la operaci\u00f3n:</li> <li>Localizadores (uno obligatorio):<ul> <li><code>xpath</code> (str): Localizaci\u00f3n del elemento mediante XPath.</li> <li><code>id</code> (str): Identificaci\u00f3n del elemento.</li> <li><code>name</code> (str): Nombre del elemento.</li> <li><code>class_name</code> (str): Clase CSS del elemento.</li> <li><code>css_selector</code> (str): Selector CSS del elemento.</li> <li><code>link_text</code> (str): Texto completo del enlace.</li> <li><code>partial_link_text</code> (str): Texto parcial del enlace.</li> <li><code>tag_name</code> (str): Nombre de la etiqueta del elemento.</li> </ul> </li> <li><code>value</code> (opcional): Valor para ingresar en un campo de entrada.</li> <li><code>wait_time</code> (int, opcional): Tiempo de espera despu\u00e9s de realizar la acci\u00f3n (por defecto: 2 segundos).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_11","title":"Funcionamiento","text":"<ol> <li> <p>Identificaci\u00f3n del elemento:</p> <ul> <li>Determina el tipo y valor del localizador (<code>locator_type</code> y <code>locator_value</code>) a partir de los argumentos proporcionados.</li> <li>Utiliza <code>WebDriverWait</code> para esperar hasta que el elemento sea clickeable.</li> <li>Si no se encuentra el elemento, registra una advertencia en el log y retorna <code>None</code>.</li> </ul> </li> <li> <p>Clic en el elemento:</p> <ul> <li>Realiza clic en el elemento localizado y espera el tiempo especificado (<code>wait_time</code>).</li> </ul> </li> <li> <p>Interacci\u00f3n con campos de entrada:</p> <ul> <li>Si el elemento es un campo de entrada (<code>&lt;input&gt;</code>) y se proporciona un valor (<code>value</code>):</li> <li>Si el valor es un objeto <code>datetime</code>, lo formatea como cadena (<code>'%d/%m/%Y'</code>).</li> <li>Limpia el campo, establece el valor, y registra la acci\u00f3n en el log.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas.</li> <li>Registra los errores en el log y retorna sin lanzar la excepci\u00f3n.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_12","title":"Salida","text":"<ul> <li><code>None</code>: Si el elemento no se encuentra o hay un error durante la operaci\u00f3n.</li> <li>Registra en el log el estado del proceso (clic o interacci\u00f3n con el campo de entrada).</li> </ul> <pre><code>def hacer_clic(driver, **kwargs):\n    try:\n        locator_type = None\n        locator_value = None\n        input_value = kwargs.get('value')\n        wait_time = kwargs.get('wait_time', 2)  # Manejar 'wait_time' con valor por defecto\n\n        for key, value in kwargs.items():\n            if key == 'value':\n                continue  # Ya se maneja 'value' arriba\n            elif key in ['xpath', 'id', 'name', 'class_name', 'css_selector', 'link_text', 'partial_link_text', 'tag_name']:\n                locator_type = key\n                locator_value = value\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos\")\n\n        # Convertir el identificador a By adecuado\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n        try:\n            elemento = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((by_mapping[locator_type], locator_value)))\n        except TimeoutException:\n            elemento = None\n            logging.warning(f\"Elemento no encontrado: {locator_type} = {locator_value}\")\n            #FINALIZAR retornando error\n            return None\n\n        logging.info(f\"Elemento localizado, realizando clic en {locator_type}: {locator_value}\")\n        elemento.click()\n        time.sleep(wait_time)\n        logging.info(f\"Clic realizado correctamente en {locator_type}: {locator_value}\")\n\n        # Si el elemento es un input y se proporcion\u00f3 un valor de fecha, formatear correctamente\n        if elemento.tag_name == 'input' and input_value is not None:\n            if isinstance(input_value, datetime):\n                input_value = input_value.strftime('%d/%m/%Y')  # Convertir datetime a cadena de texto\n\n            elemento.clear()\n            elemento.send_keys(input_value)\n            logging.info(f\"Valor '{input_value}' establecido en el elemento input correctamente\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        # logging.error(f\"Error al intentar hacer clic en el elemento con {locator_type}: {locator_value} - Detalles: {e}\")\n        logging.error(f\"Error al intentar hacer clic en el elemento con {locator_type}: {locator_value} \")\n        #raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-hacer_clic_modal","title":"Funci\u00f3n <code>hacer_clic_modal</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_14","title":"Prop\u00f3sito","text":"<p>Interact\u00faa con un modal en una p\u00e1gina web controlada por Selenium, localizando y haciendo clic en un elemento dentro del modal. Opcionalmente, permite realizar acciones adicionales dentro del modal y gestionar cambios de contexto hacia y desde un <code>iframe</code>.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_14","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Par\u00e1metros clave para la operaci\u00f3n:</li> <li><code>xpath_modal</code> (str, requerido): Localizador del modal usando XPath.</li> <li><code>iframe</code> (str, opcional): Nombre del iframe al que cambiar el contexto.</li> <li><code>elementos</code> (list, opcional): Lista de pasos adicionales a ejecutar dentro del modal. Cada paso debe estar definido como una tupla <code>(nombre_paso, funci\u00f3n, par\u00e1metros)</code>.</li> <li>Localizadores: <ul> <li><code>xpath</code> (str): XPath del elemento a interactuar.</li> <li><code>id</code>, <code>name</code>, <code>class_name</code>, <code>css_selector</code>, <code>link_text</code>, <code>partial_link_text</code>, <code>tag_name</code> (str): Alternativas de localizaci\u00f3n del elemento.</li> </ul> </li> <li><code>wait_time</code> (int, opcional): Tiempo de espera en segundos tras realizar la acci\u00f3n (por defecto: <code>2</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_12","title":"Funcionamiento","text":"<ol> <li> <p>Cambio al <code>iframe</code> (opcional):</p> <ul> <li>Si se proporciona un <code>iframe</code>, cambia al contexto del iframe indicado antes de realizar otras operaciones.</li> </ul> </li> <li> <p>Localizaci\u00f3n del modal:</p> <ul> <li>Espera hasta que el modal especificado por <code>xpath_modal</code> sea visible en el DOM.</li> </ul> </li> <li> <p>Interacci\u00f3n con el elemento:</p> <ul> <li>Localiza y verifica la clicabilidad del elemento especificado.</li> <li>Intenta realizar clic est\u00e1ndar. Si no es posible, utiliza JavaScript como alternativa.</li> </ul> </li> <li> <p>Ejecuci\u00f3n de pasos adicionales (opcional):</p> <ul> <li>Si se proporcionan pasos adicionales, los ejecuta dentro del contexto del modal.</li> </ul> </li> <li> <p>Cambio de regreso al contexto principal (si aplica):</p> <ul> <li>Regresa al contenido principal si se cambi\u00f3 previamente al <code>iframe</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura y registra excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_13","title":"Salida","text":"<ul> <li>No retorna valores. Realiza las acciones en el modal y registra el estado del proceso en el log.</li> </ul> <pre><code>def hacer_clic_modal(driver, **kwargs):\n    try:\n        modal_locator_type = None\n        modal_locator_value = kwargs.get('xpath_modal')\n        iframe_name = kwargs.get('iframe')\n        locator_type = None\n        locator_value = None\n        wait_time = kwargs.get('wait_time', 2)\n        elementos = kwargs.get('elementos', [])\n\n        if iframe_name:\n            try:\n                logging.info(f\"Cambiando al iframe con nombre: {iframe_name}\")\n                WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.NAME, iframe_name)))\n                logging.info(\"Cambio al iframe exitoso\")\n            except TimeoutException:\n                logging.error(f\"No se pudo cambiar al iframe '{iframe_name}' dentro del tiempo l\u00edmite.\")\n                raise\n\n        for key, value in kwargs.items():\n            if key in ['xpath_modal', 'iframe', 'elementos']:\n                continue\n            elif value is not None and key in ['xpath', 'id', 'name', 'class_name', 'css_selector', 'link_text', 'partial_link_text', 'tag_name']:\n                locator_type = key\n                locator_value = value\n\n        if not modal_locator_value:\n            raise ValueError(\"Debe proporcionar un localizador v\u00e1lido para el modal (por ejemplo, 'xpath_modal')\")\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos para el elemento de clic\")\n\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n\n        logging.info(f\"Esperando la visibilidad del modal con xpath: {modal_locator_value}\")\n        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, modal_locator_value)))\n        logging.info(f\"Modal localizado y visible: {modal_locator_value}\")\n\n        elemento = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((by_mapping[locator_type], locator_value)))\n        WebDriverWait(driver, 20).until(EC.element_to_be_clickable((by_mapping[locator_type], locator_value)))\n        logging.info(f\"Elemento localizado dentro del modal, realizando clic en {locator_type}: {locator_value}\")\n\n        try:\n            elemento.click()\n        except ElementNotInteractableException:\n            logging.warning(f\"No se pudo hacer clic en {locator_type}: {locator_value} con el m\u00e9todo est\u00e1ndar, intentando con JavaScript\")\n            driver.execute_script(\"arguments[0].click();\", elemento)\n\n        time.sleep(wait_time)\n        logging.info(f\"Clic realizado correctamente en {locator_type}: {locator_value}\")\n\n        if elementos:\n            for step_name, step_function, params in elementos:\n                logging.info(f\"Ejecutando el paso adicional dentro del modal: {step_name}\")\n                step_function(driver=driver, **params)\n\n        if iframe_name:\n            driver.switch_to.default_content()\n            logging.info(\"Cambio de regreso al contenido principal realizado\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al intentar hacer clic en el elemento dentro del modal con {locator_type}: {locator_value} - Detalles: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-hacer_clic_por_coordenadas","title":"Funci\u00f3n <code>hacer_clic_por_coordenadas</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_15","title":"Prop\u00f3sito","text":"<p>Realiza un clic en un elemento ubicado en una p\u00e1gina web controlada por Selenium utilizando sus coordenadas. Es \u00fatil cuando los clics tradicionales no son efectivos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_15","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para configurar la operaci\u00f3n:</li> <li>Localizadores (uno obligatorio):<ul> <li><code>xpath</code> (str): Localizador del elemento mediante XPath.</li> <li><code>id</code>, <code>name</code>, <code>class_name</code>, <code>css_selector</code>, <code>link_text</code>, <code>partial_link_text</code>, <code>tag_name</code> (str): Alternativas de localizaci\u00f3n del elemento.</li> </ul> </li> <li><code>iframe</code> (str, opcional): Nombre del iframe para cambiar el contexto antes de la operaci\u00f3n.</li> <li><code>wait_time</code> (int, opcional): Tiempo en segundos para esperar despu\u00e9s del clic (por defecto: <code>2</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_13","title":"Funcionamiento","text":"<ol> <li> <p>Cambio de contexto al iframe (opcional):</p> <ul> <li>Cambia al contexto del iframe especificado, si se proporciona.</li> </ul> </li> <li> <p>Localizaci\u00f3n del elemento:</p> <ul> <li>Encuentra el elemento utilizando el tipo y valor del localizador proporcionado.</li> <li>Asegura que el elemento est\u00e9 visible en la ventana mediante <code>scrollIntoView</code>.</li> </ul> </li> <li> <p>Obtenci\u00f3n de coordenadas:</p> <ul> <li>Calcula las coordenadas centrales del elemento (<code>x</code> y <code>y</code>) usando su posici\u00f3n y tama\u00f1o.</li> </ul> </li> <li> <p>Clic en las coordenadas:</p> <ul> <li>Usa <code>ActionChains</code> para mover el puntero a las coordenadas calculadas y realizar el clic.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o referencias obsoletas, registrando el error en el log.</li> </ul> </li> <li> <p>Restauraci\u00f3n del contexto principal:</p> <ul> <li>Si se cambi\u00f3 al iframe, regresa al contexto principal al finalizar.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_14","title":"Salida","text":"<ul> <li>No retorna valores. Realiza el clic en las coordenadas especificadas y registra en el log el estado del proceso.</li> </ul> <pre><code>def hacer_clic_por_coordenadas(driver, **kwargs):\n    try:\n        logging.info(\"Iniciando el proceso de clic por coordenadas\")\n\n        locator_type = None\n        locator_value = None\n        iframe = kwargs.get('iframe')  # Nombre del iframe si es necesario cambiar de contexto\n        wait_time = kwargs.get('wait_time', 2)  # Manejar 'wait_time' con valor por defecto\n\n        # Obtener el localizador del elemento de clic\n        for key, value in kwargs.items():\n            if key in ['iframe', 'wait_time']:\n                continue  # Omitir estos par\u00e1metros\n            elif value is not None and key in ['xpath', 'id', 'name', 'class_name', 'css_selector', 'link_text', 'partial_link_text', 'tag_name']:\n                locator_type = key\n                locator_value = value\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos\")\n\n        # Cambiar al contexto del iframe si se proporciona\n        if iframe:\n            logging.info(f\"Cambiando al contexto del iframe: {iframe}\")\n            WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.NAME, iframe)))\n            logging.info(\"Cambio al contexto del iframe completado\")\n\n        # Convertir el identificador a By adecuado\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n\n        logging.info(f\"Esperando la presencia del elemento {locator_type}: {locator_value}\")\n        elemento = WebDriverWait(driver, 10).until(EC.presence_of_element_located((by_mapping[locator_type], locator_value)))\n        logging.info(f\"Elemento encontrado: {locator_type} = {locator_value}\")\n\n        driver.execute_script(\"arguments[0].scrollIntoView(true);\", elemento)  # Asegurarse de que el elemento est\u00e9 visible en la ventana\n        logging.info(\"Elemento desplazado a la vista\")\n\n        # Obtener las coordenadas del elemento\n        location = elemento.location\n        size = elemento.size\n        x, y = location['x'] + (size['width'] / 2), location['y'] + (size['height'] / 2)\n\n        logging.info(f\"Coordenadas obtenidas - X: {x}, Y: {y}\")\n\n        # Hacer clic en las coordenadas usando ActionChains\n        action = ActionChains(driver)\n        action.move_by_offset(x, y).click().perform()\n\n        logging.info(\"Clic realizado en las coordenadas especificadas\")\n        time.sleep(wait_time)\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al intentar hacer clic en el elemento por coordenadas: {e}\")\n        raise\n    finally:\n        # Volver al contexto principal si se cambi\u00f3 al iframe\n        if iframe:\n            driver.switch_to.default_content()\n            logging.info(\"Cambio al contexto principal despu\u00e9s de la operaci\u00f3n en el iframe\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funciones-actualizar_nombre_archivo-y-verificar_descarga","title":"Funciones <code>actualizar_nombre_archivo</code> y <code>verificar_descarga</code>","text":""},{"location":"00.etl/Utils/Funciones/#funcion-actualizar_nombre_archivo","title":"Funci\u00f3n <code>actualizar_nombre_archivo</code>","text":"<p>Prop\u00f3sito:</p> <p>Actualiza el objeto global <code>proceso_info</code> con el nombre del archivo procesado.</p> <p>Entradas:</p> <ul> <li><code>nombre_archivo</code> (str): Nombre del archivo descargado.</li> </ul> <p>Funcionamiento:</p> <ul> <li>Establece el valor de <code>'nombre_archivo'</code> en el objeto global <code>proceso_info</code>.</li> <li>Registra en el log el nombre actualizado.</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Actualiza el objeto global y registra el cambio.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcion-verificar_descarga","title":"Funci\u00f3n <code>verificar_descarga</code>","text":"<p>Prop\u00f3sito:</p> <p>Verifica si un archivo espec\u00edfico se ha descargado correctamente dentro de un tiempo de espera m\u00e1ximo.</p> <p>Entradas:</p> <ul> <li><code>nombre_archivo</code> (str): Nombre del archivo a verificar.</li> <li><code>download_dir</code> (str, opcional): Directorio de descargas donde se busca el archivo (por defecto: <code>DOWNLOAD_DIR</code>).</li> <li><code>timeout</code> (int, opcional): Tiempo m\u00e1ximo de espera en segundos (por defecto: <code>10</code>).</li> </ul> <p>Funcionamiento:</p> <ol> <li>Construye la ruta completa del archivo a partir del nombre y el directorio de descargas.</li> <li>Monitorea la existencia del archivo en el sistema de archivos:<ul> <li>Si el archivo no se encuentra dentro del tiempo especificado, devuelve <code>False</code>.</li> <li>Si el archivo aparece, registra el \u00e9xito y devuelve <code>True</code>.</li> </ul> </li> </ol> <p>Salida:</p> <ul> <li><code>True</code>: Si el archivo se descarg\u00f3 correctamente.</li> <li><code>False</code>: Si el archivo no se descarg\u00f3 dentro del tiempo especificado.</li> </ul> <pre><code># Objeto global para almacenar detalles del proceso\nproceso_info = {\n    'nombre_archivo': None\n}\n\n# Funci\u00f3n que actualiza el objeto con el nombre del archivo descargado\ndef actualizar_nombre_archivo(nombre_archivo):\n    proceso_info['nombre_archivo'] = nombre_archivo\n    logging.info(f\"Nombre del archivo actualizado en el objeto: {nombre_archivo}\")\n\n\ndef verificar_descarga(nombre_archivo, download_dir=DOWNLOAD_DIR, timeout=10):\n    \"\"\"\n    Verifica que un archivo con el nombre especificado se descargue correctamente en el \n    directorio de descargas, con un tiempo de espera m\u00e1ximo.\n    \"\"\"\n    file_path = os.path.join(download_dir, nombre_archivo)\n    logging.info(f\"Verificando la presencia del archivo: {nombre_archivo}\")\n\n    start_time = time.time()\n    while not os.path.exists(file_path):\n        if time.time() - start_time &gt; timeout:\n            # logging.warning(f\"Tiempo de espera agotado para la descarga del archivo: {nombre_archivo}\")\n            return False  # Indica que el archivo no se descarg\u00f3 en el tiempo dado\n        logging.info(\"Esperando la descarga...\")\n        time.sleep(1)\n\n    logging.info(f\"Archivo {nombre_archivo} descargado correctamente.\")\n    return True  # Indica que el archivo se descarg\u00f3 con \u00e9xito\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-cargar_archivo_excel","title":"Funci\u00f3n <code>cargar_archivo_excel</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_16","title":"Prop\u00f3sito","text":"<p>Carga un archivo Excel desde el directorio de descargas y lo convierte en un DataFrame de pandas. Utiliza el nombre del archivo almacenado en el objeto global <code>proceso_info</code>.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_16","title":"Entradas","text":"<ul> <li>No recibe argumentos. Utiliza el nombre del archivo desde el objeto global <code>proceso_info</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_14","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n del nombre del archivo:</p> <ul> <li>Recupera el nombre del archivo desde <code>proceso_info['nombre_archivo']</code>.</li> <li>Si el nombre no est\u00e1 definido, registra una advertencia y retorna <code>None</code>.</li> </ul> </li> <li> <p>Cargado del archivo:</p> <ul> <li>Construye la ruta completa del archivo a partir del nombre y el directorio <code>DOWNLOAD_DIR</code>.</li> <li>Verifica si el archivo existe en la ruta:</li> <li>Si existe, lo carga en un DataFrame de pandas.</li> <li>Si no existe, registra una advertencia y retorna <code>None</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones durante la carga y registra el error en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_15","title":"Salida","text":"<ul> <li><code>pandas.DataFrame</code>: DataFrame cargado desde el archivo Excel si la operaci\u00f3n es exitosa.</li> <li><code>None</code>: Si el archivo no se encuentra o ocurre un error.</li> </ul> <pre><code>def cargar_archivo_excel():\n    \"\"\"\n    Carga un archivo de Excel desde el directorio de descargas en un DataFrame de pandas.\n    Utiliza el nombre del archivo almacenado en el objeto global.\n    \"\"\"\n    nombre_archivo = proceso_info.get('nombre_archivo')\n    if not nombre_archivo:\n        logging.warning(\"El nombre del archivo no se ha registrado en el objeto global.\")\n        return None\n\n    file_path = os.path.join(DOWNLOAD_DIR, nombre_archivo)\n    try:\n        if os.path.exists(file_path):\n            logging.info(f\"Cargando archivo {nombre_archivo} en DataFrame.\")\n            return pd.read_excel(file_path)\n        else:\n            logging.warning(f\"Archivo {nombre_archivo} no encontrado.\")\n            return None\n    except Exception as e:\n        logging.error(f\"Error al cargar el archivo {nombre_archivo} en DataFrame: {e}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-generar_fechas","title":"Funci\u00f3n <code>generar_fechas</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_17","title":"Prop\u00f3sito","text":"<p>Genera un diccionario con rangos de fechas por a\u00f1o o semestre, seg\u00fan los par\u00e1metros proporcionados.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_17","title":"Entradas","text":"<ul> <li><code>inicio</code> (int, opcional): A\u00f1o inicial del rango (requerido si <code>semestre</code> es <code>False</code>).</li> <li><code>fin</code> (int, opcional): A\u00f1o final del rango (requerido si <code>semestre</code> es <code>False</code>).</li> <li><code>semestre</code> (bool, opcional): Si es <code>True</code>, genera fechas del semestre anterior basado en la fecha actual (por defecto: <code>False</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_15","title":"Funcionamiento","text":"<ol> <li> <p>Generaci\u00f3n basada en semestres:</p> <ul> <li>Si <code>semestre</code> es <code>True</code>:</li> <li>Determina el semestre anterior con base en el mes actual:<ul> <li>Enero a junio: Devuelve el rango del segundo semestre del a\u00f1o anterior.</li> <li>Julio a diciembre: Devuelve el rango del primer semestre del a\u00f1o actual.</li> </ul> </li> <li>Retorna un diccionario con un \u00fanico rango de fechas.</li> </ul> </li> <li> <p>Generaci\u00f3n por a\u00f1os:</p> <ul> <li>Si <code>semestre</code> es <code>False</code>:</li> <li>Itera desde el a\u00f1o <code>inicio</code> hasta el a\u00f1o <code>fin</code> (inclusive).</li> <li>Genera un diccionario donde cada clave es el \u00edndice del a\u00f1o en el rango, y los valores son los rangos de fechas para todo el a\u00f1o.</li> </ul> </li> <li> <p>Registro de informaci\u00f3n:</p> <ul> <li>Registra en el log los rangos generados.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_16","title":"Salida","text":"<ul> <li><code>dict</code>: Diccionario con rangos de fechas. Formato:<ul> <li>Por semestre: <code>{1: {'desde': 'fecha_inicio', 'hasta': 'fecha_fin'}}</code></li> <li>Por a\u00f1os: <code>{\u00edndice: {'desde': '01-01-a\u00f1o', 'hasta': '12-31-a\u00f1o'}}</code></li> </ul> </li> </ul> <pre><code># Funci\u00f3n para generar el diccionario de fechas entre dos a\u00f1os dados\ndef generar_fechas(inicio=None, fin=None, semestre=False):\n\n    if semestre:\n        # Verificar si se solicita el semestre\n        #mes fecha actual\n        mes = datetime.now().month\n        #a\u00f1o fecha actual\n        a\u00f1o = datetime.now().year\n\n        if mes &lt;= 6:\n            # Primer semestre: el semestre anterior es el segundo semestre del a\u00f1o anterior\n            return {\n                1: {'desde': f'07-01-{a\u00f1o-1}', 'hasta': f'12-31-{a\u00f1o-1}'}\n            }\n        else:\n            # Segundo semestre: el semestre anterior es el primer semestre del mismo a\u00f1o\n            return {\n                1: {'desde': f'01-01-{a\u00f1o}', 'hasta': f'06-30-{a\u00f1o}'}\n            }\n\n\n    fechas = {}\n    for a\u00f1o in range(inicio, fin + 1):\n        fechas[a\u00f1o - inicio + 1] = {'desde': f'01-01-{a\u00f1o}', 'hasta': f'12-31-{a\u00f1o}'}\n    logging.info(f\"fechas: {json.dumps(fechas, indent=4)}\")\n    # input(\"Presione Enter para continuar...\")\n    return fechas\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-generar_periodos_cortes","title":"Funci\u00f3n <code>generar_periodos_cortes</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_18","title":"Prop\u00f3sito","text":"<p>Genera un diccionario que contiene periodos de tiempo divididos en cortes mensuales dentro de un rango de a\u00f1os.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_18","title":"Entradas","text":"<ul> <li><code>anio_inicio</code> (int): A\u00f1o inicial del rango.</li> <li><code>anio_fin</code> (int): A\u00f1o final del rango.</li> <li><code>tipo</code> (int, opcional): N\u00famero de cortes por a\u00f1o (por defecto: <code>2</code>). Debe estar entre <code>1</code> y <code>12</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_16","title":"Funcionamiento","text":"<ol> <li> <p>Validaci\u00f3n del par\u00e1metro <code>tipo</code>:</p> <ul> <li>Asegura que el valor de <code>tipo</code> sea un n\u00famero entre 1 y 12.</li> <li>Lanza un <code>ValueError</code> si el valor est\u00e1 fuera del rango.</li> </ul> </li> <li> <p>C\u00e1lculo de periodos:</p> <ul> <li>Divide los meses del a\u00f1o en cortes iguales seg\u00fan el valor de <code>tipo</code>:</li> <li>Calcula la cantidad de meses por periodo: <code>meses_por_periodo = 12 // tipo</code>.</li> <li>Itera sobre los a\u00f1os entre <code>anio_inicio</code> y <code>anio_fin</code> (inclusive).</li> <li>Dentro de cada a\u00f1o:</li> <li>Calcula el mes de inicio y el mes final de cada periodo.</li> <li>Genera los rangos de fechas, considerando el \u00faltimo d\u00eda del mes (<code>dias_del_mes</code>).</li> </ul> </li> <li> <p>Estructura del diccionario:</p> <ul> <li>Cada clave es un n\u00famero de periodo incremental.</li> <li>Cada valor es un rango de fechas con formato:</li> <li><code>desde</code> (str): Fecha de inicio del periodo (formato <code>MM-DD-AAAA</code>).</li> <li><code>hasta</code> (str): Fecha de fin del periodo (formato <code>MM-DD-AAAA</code>).</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Registra en el log los periodos generados.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_17","title":"Salida","text":"<ul> <li><code>dict</code>: Diccionario con los periodos generados. Ejemplo:   <pre><code>{\n    1: {'desde': '01-01-2023', 'hasta': '06-30-2023'},\n    2: {'desde': '07-01-2023', 'hasta': '12-31-2023'}\n}\n</code></pre></li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_3","title":"Consideraciones","text":"<ul> <li>La funci\u00f3n usa <code>dias_del_mes</code> para calcular correctamente el \u00faltimo d\u00eda de cada mes.</li> </ul> <pre><code>def generar_periodos_cortes(anio_inicio=None, anio_fin=None, tipo=2):\n    if tipo &lt; 1 or tipo &gt; 12:\n        raise ValueError(\"El par\u00e1metro 'tipo' debe ser un n\u00famero entre 1 y 12.\")\n\n    fechas = {}\n    periodo = 1\n    meses_por_periodo = 12 // tipo\n\n    for anio in range(anio_inicio, anio_fin + 1):\n        for i in range(tipo):\n            mes_inicio = i * meses_por_periodo + 1\n            mes_fin = (i + 1) * meses_por_periodo\n            fechas[periodo] = {\n                'desde': f\"{mes_inicio:02d}-01-{anio}\",\n                'hasta': f\"{mes_fin:02d}-{dias_del_mes(mes_fin, anio):02d}-{anio}\"\n            }\n            periodo += 1\n    logging.info(f\"fechas: {json.dumps(fechas, indent=4)}\")\n    return fechas\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-cola_descargar","title":"Funci\u00f3n <code>cola_descargar</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_19","title":"Prop\u00f3sito","text":"<p>Inicia la descarga de un archivo desde un bot\u00f3n en una p\u00e1gina web, espera la finalizaci\u00f3n de la descarga, y renombra el archivo m\u00e1s reciente en el directorio de descargas con un nombre basado en una opci\u00f3n especificada.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_19","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>archivo</code> (str): Nombre base para renombrar el archivo descargado.</li> <li><code>download_dir</code> (str): Ruta del directorio donde se descargan los archivos.</li> <li><code>opcion</code> (str): Valor adicional que se a\u00f1adir\u00e1 al nombre del archivo al renombrarlo.</li> <li><code>kwargs</code> (dict, opcional): Argumentos adicionales:</li> <li><code>wait_time</code> (int): Tiempo de espera en segundos para la descarga (por defecto: <code>10</code>).</li> <li><code>xpath_omitir</code> (str): XPath de un bot\u00f3n opcional para omitir antes de iniciar la descarga.</li> <li>Localizadores del bot\u00f3n de descarga (<code>xpath</code>, <code>id</code>, <code>name</code>, etc.).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_17","title":"Funcionamiento","text":"<ol> <li> <p>Omisi\u00f3n de popups:</p> <ul> <li>Si se proporciona <code>xpath_omitir</code>, busca el elemento correspondiente y hace clic en \u00e9l si est\u00e1 presente.</li> </ul> </li> <li> <p>Configuraci\u00f3n del bot\u00f3n de descarga:</p> <ul> <li>Determina el tipo y valor del localizador para identificar el bot\u00f3n de descarga.</li> <li>Espera hasta que el bot\u00f3n sea clickeable y realiza clic.</li> </ul> </li> <li> <p>Monitoreo del directorio de descargas:</p> <ul> <li>Compara el estado del directorio antes y despu\u00e9s de la descarga.</li> <li>Espera hasta 10 segundos para detectar un nuevo archivo.</li> </ul> </li> <li> <p>Renombrar archivo descargado:</p> <ul> <li>Identifica el archivo nuevo m\u00e1s reciente en el directorio.</li> <li>Renombra el archivo con el formato: <code>nombre_base_opcion.extension</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o no interactuables, y registra el error en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_18","title":"Salida","text":"<ul> <li><code>True</code>: Si el archivo se descarg\u00f3 y renombr\u00f3 correctamente.</li> <li><code>False</code>: Si no se detect\u00f3 el archivo dentro del tiempo especificado o hubo un error durante el proceso.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_4","title":"Consideraciones","text":"<ul> <li>Aseg\u00farese de proporcionar un localizador v\u00e1lido (<code>locator_type</code> y <code>locator_value</code>) para identificar el bot\u00f3n de descarga.</li> <li>La funci\u00f3n maneja escenarios donde puede ser necesario omitir popups antes de descargar.</li> <li>Dise\u00f1ada para flujos de automatizaci\u00f3n que requieren monitorear y renombrar archivos descargados din\u00e1micamente.</li> </ul> <pre><code>def cola_descargar(driver, archivo, download_dir, opcion, **kwargs):\n    \"\"\"\n    Inicia la descarga de un archivo, espera el tiempo especificado y renombra\n    el archivo m\u00e1s reciente en la carpeta de descargas con el nombre y la opci\u00f3n especificados.\n    \"\"\"\n    try:\n        # Verificar si se pasa un 'xpath_omitir' y, en caso afirmativo, si el elemento existe\n        xpath_omitir = kwargs.get('xpath_omitir')\n        if xpath_omitir:\n            try:\n                omitir_button = driver.find_element(By.XPATH, xpath_omitir)\n                omitir_button.click()\n                logging.info(f\"Omitido el clic en el bot\u00f3n de descarga: {xpath_omitir}\")\n                return True\n            except NoSuchElementException:\n                logging.info(f\"Elemento con xpath_omitir '{xpath_omitir}' no encontrado, continuando con la descarga\")\n\n        # Configuraci\u00f3n de los par\u00e1metros de localizaci\u00f3n del bot\u00f3n de descarga\n        locator_type = None\n        locator_value = None\n        wait_time = kwargs.get('wait_time', 10)\n\n        for key, value in kwargs.items():\n            if key not in {'wait_time', 'archivo', 'xpath_omitir'} and value:\n                locator_type = key\n                locator_value = value\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos\")\n\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n        # Obtener el n\u00famero de archivos antes de la descarga\n        archivos_antes = set(os.listdir(download_dir))\n\n        logging.info(f\"Esperando la presencia del elemento {locator_type}: {locator_value}\")\n        download_button = WebDriverWait(driver, 10).until(\n            EC.element_to_be_clickable((by_mapping[locator_type], locator_value))\n        )\n        download_button.click()\n        logging.info(f\"Bot\u00f3n de descarga clickeado, esperando {wait_time} segundos para la descarga\")\n        time.sleep(10)\n\n        # Esperar a que un archivo nuevo aparezca en el directorio\n        for _ in range(10):\n            archivos_despues = set(os.listdir(download_dir))\n            archivos_nuevos = archivos_despues - archivos_antes  # Detectar nuevos archivos\n            if archivos_nuevos:\n                # Obtener el archivo nuevo m\u00e1s reciente\n                latest_file = max(archivos_nuevos, key=lambda f: os.path.getctime(os.path.join(download_dir, f)))\n                latest_file_path = os.path.join(download_dir, latest_file)\n\n                # Renombrar el archivo descargado\n                base_name, extension = os.path.splitext(archivo)\n                new_file_path = os.path.join(download_dir, f'{base_name}_{opcion}{extension}')\n                os.rename(latest_file_path, new_file_path)\n                logging.info(f\"Archivo renombrado a: {new_file_path}\")\n                return True\n            logging.info(\"Esperando que la descarga se complete...\")\n            time.sleep(1)\n\n        logging.error(\"No se encontr\u00f3 el archivo descargado.\")\n        return False\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al intentar descargar el archivo con {locator_type}: {locator_value} - Detalles: {e}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-seleccionar_opcion_custom_dropdown","title":"Funci\u00f3n <code>seleccionar_opcion_custom_dropdown</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_20","title":"Prop\u00f3sito","text":"<p>Selecciona una opci\u00f3n espec\u00edfica en un men\u00fa desplegable personalizado (custom dropdown) en una p\u00e1gina web controlada por Selenium.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_20","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para configurar la operaci\u00f3n:</li> <li><code>xpath</code> (str): Localizaci\u00f3n del bot\u00f3n del men\u00fa desplegable.</li> <li><code>option</code> (str): Texto de la opci\u00f3n que se desea seleccionar.</li> <li><code>wait_time</code> (int, opcional): Tiempo en segundos para esperar despu\u00e9s de desplegar el men\u00fa (por defecto: <code>2</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_18","title":"Funcionamiento","text":"<ol> <li> <p>Verificaci\u00f3n de par\u00e1metros:</p> <ul> <li>Verifica que se hayan proporcionado un <code>xpath</code> v\u00e1lido para el bot\u00f3n del dropdown y un <code>option</code> para seleccionar.</li> </ul> </li> <li> <p>Desplegar el men\u00fa:</p> <ul> <li>Localiza el bot\u00f3n del men\u00fa usando <code>xpath</code>.</li> <li>Hace clic para desplegar el men\u00fa.</li> </ul> </li> <li> <p>Seleccionar la opci\u00f3n:</p> <ul> <li>Intenta localizar y seleccionar la opci\u00f3n utilizando texto exacto.</li> <li>Si no encuentra la opci\u00f3n, intenta con una b\u00fasqueda flexible que utiliza <code>contains</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o no interactuables, y registra el error en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_19","title":"Salida","text":"<ul> <li>No retorna valores. Realiza la acci\u00f3n en el men\u00fa desplegable y registra el estado del proceso en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_5","title":"Consideraciones","text":"<ul> <li>Dise\u00f1ada para trabajar con men\u00fas desplegables personalizados que contienen opciones identificadas por texto.</li> <li>Incluye una l\u00f3gica de respaldo para localizar opciones cuando no se encuentran con texto exacto.</li> </ul> <pre><code>def seleccionar_opcion_custom_dropdown(driver, **kwargs):\n    try:\n        logging.info(\"Seleccionando opci\u00f3n en un men\u00fa desplegable personalizado\")\n        xpath_boton = kwargs.get('xpath')\n        option_value = kwargs.get('option')\n        wait_time = kwargs.get('wait_time', 2)  # Manejar 'wait_time' con valor por defecto\n\n        if not xpath_boton or not option_value:\n            raise ValueError(\"Debe proporcionar 'xpath' y 'option' v\u00e1lidos\")\n\n        # Hacer clic en el bot\u00f3n para desplegar el men\u00fa\n        logging.info(f\"Haciendo clic en el men\u00fa desplegable con xpath: {xpath_boton}\")\n        dropdown = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath_boton)))\n        dropdown.click()\n        time.sleep(2)  # Pausa breve para que el men\u00fa se despliegue completamente\n\n        try:\n            # Seleccionar la opci\u00f3n del men\u00fa desplegable\n            logging.info(f\"Seleccionando la opci\u00f3n '{option_value}' en el men\u00fa desplegable\")\n\n            # Intentar buscar la opci\u00f3n con texto exacto\n            opcion = WebDriverWait(driver, 10).until(\n                EC.element_to_be_clickable((By.XPATH, f\"//ul[contains(@class, 'dropdown-menu')]//span[text()='{option_value}']\"))\n            )\n            opcion.click()\n            logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente.\")\n        except TimeoutException:\n            logging.warning(f\"No se encontr\u00f3 la opci\u00f3n '{option_value}' con texto exacto. Intentando con b\u00fasqueda flexible...\")\n            try:\n                # Intentar con b\u00fasqueda m\u00e1s flexible usando `contains`\n                opcion = WebDriverWait(driver, 10).until(\n                    EC.element_to_be_clickable((By.XPATH, f\"//ul[contains(@class, 'dropdown-menu')]//span[contains(normalize-space(text()), '{option_value}')]\"))\n                )\n                opcion.click()\n                logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente usando b\u00fasqueda flexible.\")\n            except Exception as e:\n                logging.error(f\"Error al seleccionar la opci\u00f3n '{option_value}': {e}\")\n        logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente en el men\u00fa desplegable\")\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al seleccionar la opci\u00f3n en el men\u00fa desplegable personalizado: {e}\")\n        #raise\n</code></pre> <p><code>listar_archivos_descargados</code> lista y registra los nombres de los archivos presentes en el directorio de descargas especificado.</p> <pre><code>def listar_archivos_descargados():\n    archivos = os.listdir(DOWNLOAD_DIR)\n    logging.info(f\"Archivos en la carpeta '{DOWNLOAD_DIR}': {archivos}\")\n    return archivos\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-obtener_elementos_dropdown","title":"Funci\u00f3n <code>obtener_elementos_dropdown</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_21","title":"Prop\u00f3sito","text":"<p>Extrae las opciones disponibles en un men\u00fa desplegable (<code>dropdown</code>) en una p\u00e1gina web controlada por Selenium.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_21","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>boton_xpath</code> (str): XPath del bot\u00f3n para abrir el men\u00fa desplegable.</li> <li><code>elementos_xpath</code> (str): XPath del contenedor que contiene las opciones del men\u00fa.</li> <li><code>nivel</code> (int): Nivel o jerarqu\u00eda del dropdown para fines de registro y depuraci\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_19","title":"Funcionamiento","text":"<ol> <li> <p>Interacci\u00f3n con el bot\u00f3n del dropdown:</p> <ul> <li>Espera hasta que el bot\u00f3n est\u00e9 visible y clickeable.</li> <li>Hace scroll para asegurar que el bot\u00f3n est\u00e9 en la vista.</li> <li>Usa JavaScript para forzar el clic en caso necesario.</li> </ul> </li> <li> <p>Extracci\u00f3n de opciones:</p> <ul> <li>Espera a que el contenedor de opciones est\u00e9 visible.</li> <li>Encuentra todos los elementos <code>&lt;li&gt;</code> dentro del contenedor <code>&lt;ul&gt;</code>.</li> <li>Para cada elemento:</li> <li>Obtiene el texto de la opci\u00f3n.</li> <li>Filtra opciones vac\u00edas o con texto no deseado como \"Seleccione\".</li> <li>Agrega el texto al resultado.</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Registra en el log el nivel del dropdown y las opciones extra\u00eddas.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones por tiempo de espera o errores generales, las registra y devuelve una lista vac\u00eda.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_20","title":"Salida","text":"<ul> <li><code>list</code>: Lista de textos de las opciones extra\u00eddas del men\u00fa desplegable.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_6","title":"Consideraciones","text":"<ul> <li>Excluye opciones con texto vac\u00edo o \"Seleccione\".</li> <li>Dise\u00f1ada para manejar men\u00fas desplegables con opciones representadas como elementos <code>&lt;li&gt;</code>.</li> <li>El par\u00e1metro <code>nivel</code> permite rastrear jerarqu\u00edas de dropdowns en procesos complejos.</li> </ul> <pre><code>@log_step_decorator(\"Obtener elementos dropdown\")\ndef obtener_elementos_dropdown(driver, boton_xpath, elementos_xpath, nivel):\n\n    opciones = []\n    try:\n        logging.info(f\"[Nivel {nivel}] Intentando abrir dropdown en: {boton_xpath}\")\n\n        # Esperar hasta que el bot\u00f3n est\u00e9 habilitado y visible en la pantalla\n        boton_dropdown = WebDriverWait(driver, 15).until(\n            EC.element_to_be_clickable((By.XPATH, boton_xpath))\n        )\n\n        # Intentar hacer scroll para que el bot\u00f3n sea visible\n        driver.execute_script(\"arguments[0].scrollIntoView();\", boton_dropdown)\n\n        # Usar JavaScript para forzar el clic si es necesario\n        driver.execute_script(\"arguments[0].click();\", boton_dropdown)\n        time.sleep(1)  # Pausa breve para permitir la expansi\u00f3n completa del dropdown\n\n        # Esperar a que el contenedor de opciones del dropdown est\u00e9 visible\n        elementos_ul = WebDriverWait(driver, 15).until(\n            EC.visibility_of_element_located((By.XPATH, elementos_xpath))\n        )\n\n        # Obtener todos los elementos &lt;li&gt; visibles dentro de `ul`\n        elementos_li = elementos_ul.find_elements(By.XPATH, \"./li\")\n\n        # Extraer y almacenar el texto y XPath de cada opci\u00f3n en el dropdown\n        for index, elemento in enumerate(elementos_li):\n            try:\n                # Obtener el texto de la opci\u00f3n\n                texto_opcion = elemento.find_element(By.XPATH, \".//span[@class='text']\").text.strip()\n\n                if texto_opcion and texto_opcion != \"Seleccione\":  # Excluir texto vac\u00edo y \"Seleccione\"\n                    # Construir un XPath \u00fanico para el elemento basado en su posici\u00f3n (index)\n                    xpath_opcion = f\"{elementos_xpath}/li[{index + 1}]/a\"  # Ejemplo de XPath con \u00edndice\n\n                    # Agregar el texto y el XPath al resultado\n                    opciones.append(texto_opcion)                    \n                    # _opciones.append({\"text\": texto_opcion,\"xpath\": xpath_opcion})\n            except Exception as inner_e:\n                logging.warning(f\"[Nivel {nivel}] No se pudo obtener el texto de una opci\u00f3n: {inner_e}\")\n\n        logging.info(f\"[Nivel {nivel}] Opciones obtenidas: {opciones}\")\n        return opciones\n\n    except TimeoutException:\n        logging.error(f\"[Nivel {nivel}] El dropdown no se pudo abrir debido a un Timeout.\")\n        return []\n    except Exception as e:\n        logging.error(f\"[Nivel {nivel}] Error al obtener elementos del dropdown: {e}\")\n        return []\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-eliminar_archivos_anteriores","title":"Funci\u00f3n <code>eliminar_archivos_anteriores</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_22","title":"Prop\u00f3sito","text":"<p>Elimina todos los archivos en un directorio de descargas que coincidan con un nombre base especificado, incluyendo variantes como <code>'Nombre'</code>, <code>'Nombre (1)'</code>, <code>'Nombre (2)'</code>, etc.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_22","title":"Entradas","text":"<ul> <li><code>nombre_archivo</code> (str): Nombre base del archivo cuyos duplicados o variantes deben ser eliminados.</li> <li><code>download_dir</code> (str): Ruta del directorio donde se buscar\u00e1n los archivos a eliminar.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_20","title":"Funcionamiento","text":"<ol> <li> <p>Construcci\u00f3n del patr\u00f3n de coincidencia:</p> <ul> <li>Extrae el nombre base del archivo sin extensi\u00f3n.</li> <li>Crea un patr\u00f3n de expresi\u00f3n regular que coincida con el nombre base seguido de cualquier texto adicional (como <code>' (1)'</code>) y cualquier extensi\u00f3n.</li> </ul> </li> <li> <p>B\u00fasqueda y eliminaci\u00f3n de archivos:</p> <ul> <li>Itera sobre los archivos en el directorio especificado.</li> <li>Si un archivo coincide con el patr\u00f3n, lo elimina y registra la acci\u00f3n en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_21","title":"Salida","text":"<ul> <li>No retorna valores. Realiza acciones directamente en el sistema de archivos y registra los archivos eliminados en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_7","title":"Consideraciones","text":"<ul> <li>Dise\u00f1ada para gestionar directorios de descargas en flujos automatizados, asegurando que no queden residuos de ejecuciones anteriores.</li> <li>Verifica patrones de archivos con extensiones gen\u00e9ricas (<code>.txt</code>, <code>.xlsx</code>, etc.). Si se espera un tipo espec\u00edfico, aseg\u00farese de que el nombre y patr\u00f3n sean precisos.</li> </ul> <pre><code>def eliminar_archivos_anteriores(nombre_archivo, download_dir):\n    \"\"\"\n    Elimina todos los archivos en el directorio de descargas que coincidan con el nombre\n    especificado o patrones como 'Nombre', 'Nombre (1)', 'Nombre (2)', etc.\n\n    Args:\n        nombre_archivo (str): El nombre base del archivo a eliminar.\n        download_dir (str): El directorio donde se buscar\u00e1n los archivos.\n    \"\"\"\n    nombre_base = os.path.splitext(nombre_archivo)[0]  # Remueve la extensi\u00f3n del archivo\n    patron = re.compile(rf\"^{re.escape(nombre_base)}.*\\.[a-zA-Z0-9]+$\")  # Coincidir con cualquier extensi\u00f3n de archivo\n\n    for archivo in os.listdir(download_dir):\n        if patron.match(archivo):\n            os.remove(os.path.join(download_dir, archivo))\n            logging.info(f\"Archivo eliminado: {archivo} en {download_dir}\")\n</code></pre> <p><code>limpiar_carpeta</code> elimina todos los archivos con extensiones <code>.csv</code>, <code>.xls</code> y <code>.xlsx</code> del directorio de descargas especificado (<code>download_dir</code>). Utiliza un decorador para registrar el inicio y finalizaci\u00f3n del proceso, adem\u00e1s de registrar cada archivo eliminado en el log.</p> <pre><code>@log_step_decorator(\"Limpiar carpeta de descargas\")\ndef limpiar_carpeta(download_dir):\n    #Eliminar todos los archivos (scv,xls,xlsx) de la carpeta \n    for archivo in os.listdir(download_dir):\n        if archivo.endswith(\".csv\") or archivo.endswith(\".xls\") or archivo.endswith(\".xlsx\"):\n            os.remove(os.path.join(download_dir, archivo))\n            logging.info(f\"Archivo eliminado: {archivo} en {download_dir}\")    \n</code></pre> <p><code>verificar_y_hacer_clic</code> localiza un elemento en la p\u00e1gina mediante un XPath proporcionado, realiza un clic en \u00e9l y env\u00eda un texto seguido de la tecla Enter. Si el elemento no se encuentra, captura la excepci\u00f3n y contin\u00faa sin interrupciones. Retorna <code>True</code> si la acci\u00f3n fue exitosa; de lo contrario, no retorna valor.</p> <pre><code>def verificar_y_hacer_clic(driver, xpath, wait_time=2):\n    \"\"\"\n    Verifica si un elemento con el XPath especificado existe.\n    Si existe, hace clic en \u00e9l.\n\n    :param driver: instancia del controlador de Selenium.\n    :param xpath: cadena XPath del elemento a verificar y hacer clic.\n    :param wait_time: tiempo opcional para esperar despu\u00e9s del clic.\n    \"\"\"\n    try:\n        elemento = driver.find_element(By.XPATH, xpath)\n        elemento.click()\n        elemento.send_keys(\"texto para enviar\" + Keys.ENTER)        \n        print(f\"Elemento encontrado y clic realizado en el XPath: {xpath}\")\n        time.sleep(wait_time)\n        return True\n    except NoSuchElementException:\n        print(f\"Elemento no encontrado en el XPath: {xpath}, continuando.\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-pre_procesamiento","title":"Funci\u00f3n <code>pre_procesamiento</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_23","title":"Prop\u00f3sito","text":"<p>Automatiza la selecci\u00f3n de opciones en un men\u00fa desplegable, filtra opciones no deseadas y gestiona las descargas asociadas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_23","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Controlador Selenium utilizado para interactuar con la p\u00e1gina.</li> <li><code>download_dir</code> (str): Ruta al directorio donde se guardan las descargas.</li> <li><code>id_descargar</code> (str): ID del bot\u00f3n que inicia la descarga.</li> <li><code>nombre_archivo</code> (str): Nombre base para los archivos descargados.</li> <li><code>nombre_archivo_completo</code> (str): Nombre completo esperado del archivo descargado.</li> <li><code>xpath_boton</code> (str): XPath del bot\u00f3n para desplegar el men\u00fa.</li> <li><code>xpath_contenedor_opciones</code> (str): XPath del contenedor que contiene las opciones del men\u00fa.</li> <li><code>tipo</code> (str): Tipo de descarga:</li> <li><code>modal</code>: Descargas que requieren interacci\u00f3n con un modal.</li> <li><code>directa</code>: Descargas iniciadas directamente desde el men\u00fa desplegable.</li> <li><code>excluir_opciones</code> (list): Lista de opciones que no deben ser procesadas.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_21","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n de opciones:</p> <ul> <li>Utiliza la funci\u00f3n <code>obtener_elementos_dropdown</code> para extraer todas las opciones visibles en el men\u00fa desplegable.</li> </ul> </li> <li> <p>Filtrado de opciones:</p> <ul> <li>Excluye las opciones especificadas en <code>excluir_opciones</code>.</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Registra las opciones finales que ser\u00e1n procesadas en el log para facilitar la depuraci\u00f3n.</li> </ul> </li> <li> <p>Procesamiento de cada opci\u00f3n:</p> <ul> <li>Itera sobre las opciones filtradas y llama a la funci\u00f3n <code>procesar_opciones_descarga</code>:</li> <li>Gestiona la interacci\u00f3n con el men\u00fa desplegable.</li> <li>Inicia las descargas seg\u00fan el tipo especificado (<code>modal</code> o <code>directa</code>).</li> <li>Asegura el manejo adecuado de archivos en el directorio de descargas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_22","title":"Salida","text":"<ul> <li>No retorna valores. Realiza las acciones de selecci\u00f3n, exclusi\u00f3n y descarga autom\u00e1ticamente.</li> </ul> <pre><code>def pre_procesamiento(driver, \n                download_dir,\n                id_descargar,\n                nombre_archivo,\n                nombre_archivo_completo,\n                xpath_boton,\n                xpath_contenedor_opciones,\n                tipo,\n                excluir_opciones):\n\n    opciones = obtener_elementos_dropdown(driver, xpath_boton, xpath_contenedor_opciones, nivel=1)\n    opciones = [opcion for opcion in opciones if opcion not in excluir_opciones]\n    logging.info(f\"Opciones a seleccionar: {opciones}\")\n\n    procesar_opciones_descarga(\n        driver=driver,\n        opciones=opciones,\n        xpath_boton=xpath_boton,\n        id_descargar=id_descargar,\n        nombre_archivo=nombre_archivo,\n        nombre_archivo_completo=nombre_archivo_completo,\n        download_dir=download_dir,\n        wait_time=2,\n        tipo=tipo,\n        xpath_omitir='/html/body/div[10]'\n    )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-pre_procesamiento_periodo","title":"Funci\u00f3n <code>pre_procesamiento_periodo</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_24","title":"Prop\u00f3sito","text":"<p>Automatiza la selecci\u00f3n de per\u00edodos espec\u00edficos desde un men\u00fa desplegable, filtra los per\u00edodos disponibles en funci\u00f3n de un conjunto de a\u00f1os, y gestiona las descargas asociadas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_24","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Controlador Selenium para manejar la interacci\u00f3n con la p\u00e1gina.</li> <li><code>download_dir</code> (str): Directorio donde se guardar\u00e1n las descargas.</li> <li><code>id_descargar</code> (str): ID del bot\u00f3n de descarga.</li> <li><code>nombre_archivo</code> (str): Nombre base del archivo descargado.</li> <li><code>nombre_archivo_completo</code> (str): Nombre completo esperado del archivo descargado.</li> <li><code>xpath_boton</code> (str): XPath del bot\u00f3n para desplegar el men\u00fa de per\u00edodos.</li> <li><code>xpath_contenedor_opciones</code> (str): XPath del contenedor de opciones del men\u00fa desplegable.</li> <li><code>tipo</code> (str): Tipo de descarga:</li> <li><code>modal</code>: Descargas que requieren interacci\u00f3n con un modal.</li> <li><code>directa</code>: Descargas iniciadas directamente desde el men\u00fa desplegable.</li> <li><code>items_opciones</code> (list): Lista de a\u00f1os a generar como per\u00edodos para consulta (e.g., <code>[2019, 2020]</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_22","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n de opciones del dropdown:</p> <ul> <li>Llama a <code>obtener_elementos_dropdown</code> para extraer todas las opciones disponibles en el men\u00fa desplegable.</li> </ul> </li> <li> <p>Generaci\u00f3n de per\u00edodos de consulta:</p> <ul> <li>Genera una lista de per\u00edodos en formato de cadena (<code>\"2019\"</code>, <code>\"2020\"</code>) a partir de los a\u00f1os en <code>items_opciones</code>.</li> <li>Guarda los per\u00edodos generados en un diccionario para registro y depuraci\u00f3n.</li> </ul> </li> <li> <p>Filtrado de per\u00edodos:</p> <ul> <li>Filtra las opciones del dropdown, reteniendo \u00fanicamente aquellas que comiencen con los per\u00edodos generados.</li> </ul> </li> <li> <p>Registro de opciones:</p> <ul> <li>Guarda las opciones filtradas en un diccionario y las registra en el log.</li> </ul> </li> <li> <p>Procesamiento de opciones:</p> <ul> <li>Llama a <code>procesar_opciones_descarga</code> para gestionar la interacci\u00f3n con el dropdown y realizar las descargas para cada per\u00edodo filtrado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_23","title":"Salida","text":"<ul> <li>No retorna valores. Realiza las acciones de selecci\u00f3n, filtrado y descarga autom\u00e1ticamente.</li> </ul> <pre><code>def pre_procesamiento_periodo(driver, \n                download_dir,\n                id_descargar,\n                nombre_archivo,\n                nombre_archivo_completo,\n                xpath_boton,\n                xpath_contenedor_opciones,\n                tipo,\n                items_opciones):\n\n    opciones = obtener_elementos_dropdown(driver, xpath_boton, xpath_contenedor_opciones, nivel=1)\n\n    # Obtener los periodos disponibles en el dropdown\n    _periodos = opciones\n\n    # Generar lista de periodos de consulta (2019, 2020)\n    consulta = items_opciones\n    periodos_generados = [f\"{year}\" for year in consulta]\n    guardar_diccionario(periodos_generados, 'periodos_generados')\n    # Filtrar solo los per\u00edodos que comiencen con los valores generados\n    opciones = [\n        periodo for periodo in _periodos \n        if any(periodo.startswith(generado) for generado in periodos_generados)\n    ]\n    guardar_diccionario(opciones, 'opciones')    \n    logging.info(f\"Opciones a seleccionar: {opciones}\")\n\n    procesar_opciones_descarga(\n        driver=driver,\n        opciones=opciones,\n        xpath_boton=xpath_boton,\n        id_descargar=id_descargar,\n        nombre_archivo=nombre_archivo,\n        nombre_archivo_completo=nombre_archivo_completo,\n        download_dir=download_dir,\n        wait_time=2,\n        tipo=tipo,\n        xpath_omitir='/html/body/div[10]'\n    )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-get_data_range","title":"Funci\u00f3n <code>get_data_range</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_25","title":"Prop\u00f3sito","text":"<p>Obtiene un rango de datos de una hoja de un archivo Excel y devuelve los valores contenidos en ese rango.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_25","title":"Entradas","text":"<ul> <li><code>file_path</code> (str): Ruta del archivo Excel a procesar.</li> <li><code>sheet_index</code> (int): \u00cdndice de la hoja en el archivo Excel de donde se extraer\u00e1n los datos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_23","title":"Funcionamiento","text":"<ol> <li> <p>Carga del archivo:</p> <ul> <li>Abre el archivo Excel en modo de solo lectura (<code>data_only=True</code>).</li> </ul> </li> <li> <p>Validaci\u00f3n del \u00edndice de la hoja:</p> <ul> <li>Verifica que el \u00edndice proporcionado est\u00e9 dentro del rango v\u00e1lido de hojas disponibles.</li> <li>Lanza un <code>IndexError</code> si el \u00edndice no es v\u00e1lido.</li> </ul> </li> <li> <p>Detecci\u00f3n del rango de datos:</p> <ul> <li>Itera sobre las celdas de la hoja para identificar los l\u00edmites m\u00ednimos y m\u00e1ximos (filas y columnas) donde existen valores no vac\u00edos.</li> </ul> </li> <li> <p>Extracci\u00f3n de datos:</p> <ul> <li>Con los l\u00edmites detectados (<code>min_row</code>, <code>min_col</code>, <code>max_row</code>, <code>max_col</code>), se genera un rango.</li> <li>Crea un iterador con los valores dentro del rango utilizando <code>sheet.iter_rows</code> con <code>values_only=True</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_24","title":"Salida","text":"<ul> <li><code>data</code> (iterable): Valores contenidos en el rango detectado de la hoja Excel.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-rango-detectado","title":"Ejemplo de rango detectado","text":"<p>Si el rango de datos encontrado es: - Desde la fila 2, columna 1 - Hasta la fila 10, columna 5</p> <p>El rango corresponde a las celdas <code>A2:E10</code> en el archivo Excel.</p> <pre><code>def get_data_range(file_path, sheet_index):\n    # Cargar el archivo de Excel\n    workbook = load_workbook(file_path, data_only=True)\n\n    # Verificar si el \u00edndice de la hoja es v\u00e1lido\n    if sheet_index &lt; 0 or sheet_index &gt;= len(workbook.sheetnames):\n        raise IndexError(f\"\u00cdndice de hoja inv\u00e1lido. Hay {len(workbook.sheetnames)} hojas disponibles.\")\n\n    # Obtener la hoja por \u00edndice\n    sheet_name = workbook.sheetnames[sheet_index]\n    sheet = workbook[sheet_name]\n\n    # Variables para rastrear los l\u00edmites del rango\n    min_row, min_col = None, None\n    max_row, max_col = None, None\n\n    # Recorrer las celdas para encontrar el rango de datos\n    for row in sheet.iter_rows():\n        for cell in row:\n            if cell.value is not None:\n                if min_row is None or cell.row &lt; min_row:\n                    min_row = cell.row\n                if max_row is None or cell.row &gt; max_row:\n                    max_row = cell.row\n                if min_col is None or cell.column &lt; min_col:\n                    min_col = cell.column\n                if max_col is None or cell.column &gt; max_col:\n                    max_col = cell.column\n\n    # return min_row, min_col, max_row, max_col\n    sheet_index = 0  # \u00cdndice de la hoja (empezando en 0)\n\n    print(f\"Rango de datos: Desde la fila {min_row}, columna {min_col} hasta la fila {max_row}, columna {max_col}\")\n    # Crear un DataFrame con el rango de datos obtenido\n    workbook = load_workbook(file_path, data_only=True)\n    sheet = workbook[workbook.sheetnames[sheet_index]]\n    data = sheet.iter_rows(min_row=min_row, max_row=max_row, min_col=min_col, max_col=max_col, values_only=True)\n    return data\n</code></pre> <p><code>guardar_diccionario</code> Guarda los valores de un diccionario o lista en un archivo CSV, creando una columna llamada Item para almacenar los datos.</p> <pre><code>def guardar_diccionario(diccionario, nombre_archivo):\n    # Almacenar periodos en un Archivo, en modo de pruebas\n    df = pd.DataFrame(diccionario, columns=['Item'])\n    df.to_csv(f'{nombre_archivo}.csv', index=False)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-crea_dataframes","title":"Funci\u00f3n <code>crea_dataframes</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_26","title":"Prop\u00f3sito","text":"<p>Procesa una lista de archivos Excel desde una carpeta, carg\u00e1ndolos en pandas DataFrames, y aplica renombramientos espec\u00edficos de columnas para cada archivo.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_26","title":"Entradas","text":"<ul> <li><code>files</code> (list): Lista de nombres de archivos Excel a procesar.</li> <li><code>upload_folder</code> (str): Ruta de la carpeta donde se encuentran los archivos Excel.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_24","title":"Funcionamiento","text":"<ol> <li> <p>Carga de archivos Excel:</p> <ul> <li>Itera sobre los nombres de los archivos en <code>files</code>.</li> <li>Carga cada archivo Excel desde la carpeta especificada (<code>upload_folder</code>) en un DataFrame y lo almacena en el diccionario <code>data_frames</code>, donde la clave es el nombre del archivo.</li> </ul> </li> <li> <p>Renombramiento de columnas:</p> <ul> <li>Aplica renombramientos espec\u00edficos para las columnas de cada archivo:</li> <li>Estandariza los nombres de columnas relevantes como <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>FECHA</code>, y otros campos seg\u00fan la estructura particular de cada archivo.</li> <li>Se realiza un mapeo detallado de las columnas para cada archivo en <code>files[0]</code>, <code>files[1]</code>, <code>files[2]</code> y <code>files[3]</code>.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve un diccionario <code>data_frames</code> donde:</li> <li>Las claves son los nombres de los archivos.</li> <li>Los valores son los DataFrames procesados.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_25","title":"Salida","text":"<ul> <li><code>data_frames</code> (dict): Diccionario con los DataFrames procesados y renombrados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-estructura-de-salida","title":"Ejemplo de estructura de salida","text":"<p>Si <code>files</code> contiene: <pre><code>['archivo1.xlsx', 'archivo2.xlsx']\n</code></pre> El diccionario <code>data_frames</code> tendr\u00e1: <pre><code>{\n    'archivo1.xlsx': DataFrame con columnas renombradas,\n    'archivo2.xlsx': DataFrame con columnas renombradas\n}\n</code></pre></p> <pre><code>################################################################################################################################\n@log_step_decorator(\"Procesar dataframes\")\ndef crea_dataframes(files, upload_folder):\n    data_frames = {}\n    for file in files:\n        data_frames[file] = pd.read_excel( upload_folder + \"\\\\\" + file )\n        #columnsTotal = columnsTotal + data_frames[file].columns.tolist()\n\n\n\n    data_frames[files[0]] = data_frames[files[0]].rename(columns={'TIPO DE IDENTIFICACION': 'TIPO_DOCUMENTO',\n                                                                'IDENTIFICACION': 'DOCUMENTO',\n                                                                'FECHA DEL PRODUCTO O SERVICIO PRESTADO': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO'})\n    data_frames[files[1]] = data_frames[files[1]].rename(columns={'TIPO DE IDENTIFICACION': 'TIPO_DOCUMENTO',\n                                                                'IDENTIFICACION': 'DOCUMENTO',\n                                                                'FECHA DEL PRODUCTO O SERVICIO PRESTADO': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO',\n                                                                'TELEFONO CELULAR':'TELEFONO'})\n    data_frames[files[2]] = data_frames[files[2]].rename(columns={'TIPO DE IDENTIFICACION DEL BENEFICIARIO': 'TIPO_DOCUMENTO',\n                                                                'IDENTIFICACION DEL BENEFICIARIO': 'DOCUMENTO',\n                                                                'FECHA DEL PRODUCTO O SERVICIO PRESTADO': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL NINIO O NINIA BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO',\n                                                                'PRIMER NOMBRE DEL BENEFICIARIO':'PRIMER NOMBRE',\n                                                                'PRIMER APELLIDO DEL BENEFICIARIO':'PRIMER APELLIDO',\n                                                                'SEGUNDO NOMBRE DEL BENEFICIARIO':'SEGUNDO NOMBRE',\n                                                                'SEGUNDO APELLIDO DEL BENEFICIARIO':'SEGUNDO APELLIDO',\n                                                                'PRIMER NOMBRE PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'PRIMER NOMBRE DEL ACUDIENTE', \n                                                                'SEGUNDO NOMBRE PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'SEGUNDO NOMBRE DEL ACUDIENTE',\n                                                                'PRIMER APELLIDO PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'PRIMER APELLIDO DEL ACUDIENTE',\n                                                                'SEGUNDO APELLIDO PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'SEGUNDO APELLIDO DEL ACUDIENTE',\n                                                                'EDAD DEL BENEFICIARIO':'EDAD',\n                                                                'TELEFONO\\xa0DEL ESTUDIANTE':'TELEFONO',\n                                                                'UBICACION DEL\\xa0 ESTABLECIMIENTO EDUCATIVO DEL ESTUDIANTE':'UBICACION DEL ESTABLECIMIENTO EDUCATIVO DEL ESTUDIANTE'})\n    data_frames[files[3]] = data_frames[files[3]].rename(columns={'TIPO DE IDENTIFICACION DEL BENEFICIARIO': 'TIPO_DOCUMENTO',\n                                                                'NUMERODEIDENTIFICACION': 'DOCUMENTO',\n                                                                'FECHA DE VINCULACION A PAIN': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL NINIO O NINIA BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO',\n                                                                'FECHA DE NACIMIENTO(DD/MM/AAAA)':'FECHA NACIMIENTO',\n                                                                'SEGUNDO\\xa0APELLIDO DEL ACUDIENTE':'SEGUNDO APELLIDO DEL ACUDIENTE',\n                                                                'SEGUNDO\\xa0NOMBRE DEL ACUDIENTE':'SEGUNDO NOMBRE DEL ACUDIENTE',\n                                                                'UBICACION DEL\\xa0 ESTABLECIMIENTO EDUCATIVO DEL BENEFICIARIO':'UBICACION DEL ESTABLECIMIENTO EDUCATIVO DEL BENEFICIARIO'})\n    return data_frames\n</code></pre> <p><code>normalize</code> elimina las tildes de un texto, reemplaz\u00e1ndolas por sus versiones sin acento, tanto en min\u00fasculas como en may\u00fasculas.</p> <pre><code>def normalize(s):\n    replacements = (\n        (\"\u00e1\", \"a\"),\n        (\"\u00e9\", \"e\"),\n        (\"\u00ed\", \"i\"),\n        (\"\u00f3\", \"o\"),\n        (\"\u00fa\", \"u\"),\n    )\n    for a, b in replacements:\n        s = s.replace(a, b).replace(a.upper(), b.upper())\n    return s\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-presave","title":"Funci\u00f3n <code>PreSave</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_27","title":"Prop\u00f3sito","text":"<p>Realiza un preprocesamiento de columnas en un DataFrame, limpiando y normalizando valores textuales, y opcionalmente eliminando signos de puntuaci\u00f3n espec\u00edficos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_27","title":"Entradas","text":"<ul> <li><code>df</code> (DataFrame): DataFrame original que se desea procesar.</li> <li><code>columnList</code> (list): Lista de columnas del DataFrame que ser\u00e1n procesadas.</li> <li><code>signs</code> (bool, opcional): Si es <code>True</code>, elimina signos de puntuaci\u00f3n como <code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code> de las columnas. Por defecto: <code>False</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_25","title":"Funcionamiento","text":"<ol> <li> <p>Copiar el DataFrame:</p> <ul> <li>Crea una copia del DataFrame original para evitar modificaciones en el objeto original.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n:</p> <ul> <li>Reemplazos espec\u00edficos:<ul> <li>Convierte <code>\\xf1</code> a <code>ni</code> (e.g., \"\u00f1\" a \"ni\").</li> <li>Convierte <code>\\xD1</code> a <code>NI</code> (e.g., \"\u00d1\" a \"NI\").</li> <li>Sustituye caracteres no rompibles (<code>\\u00A0</code>) por espacios.</li> </ul> </li> <li>Eliminaci\u00f3n de espacios:<ul> <li>Reemplaza espacios dobles por simples.</li> <li>Elimina espacios al inicio y final de las cadenas.</li> </ul> </li> <li>Normalizaci\u00f3n de texto:<ul> <li>Convierte los valores a cadenas en may\u00fasculas.</li> <li>Aplica la funci\u00f3n <code>normalize</code> para eliminar tildes.</li> <li>Reemplaza comas por espacios.</li> </ul> </li> <li>Gesti\u00f3n de valores nulos:<ul> <li>Sustituye valores <code>\"NAN\"</code> por <code>np.nan</code>.</li> </ul> </li> </ul> </li> <li> <p>Eliminaci\u00f3n de signos (opcional):</p> <ul> <li>Si <code>signs=True</code>, elimina signos de puntuaci\u00f3n (<code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code>) utilizando expresiones regulares.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_26","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame con las columnas especificadas procesadas y normalizadas.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-uso","title":"Ejemplo de uso","text":"<p>Si la entrada es: <pre><code>df = pd.DataFrame({'col1': ['\u00a1Hola, mundo!', '\u00bfQu\u00e9 tal?']})\nPreSave(df, ['col1'], signs=True)\n</code></pre></p> <p>La salida ser\u00e1: <pre><code>      col1\n0    HOLA MUNDO\n1    QUE TAL\n</code></pre></p> <pre><code>def PreSave(df , columnList, signs = False):\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xf1', 'ni'))\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xD1', 'NI'))\n\n    datfra = df.copy()\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xf1', 'ni'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xD1', 'NI'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('\\u00A0', ' '))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('  ', ' '))\n    datfra[columnList] = datfra[columnList].astype(str)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.strip())\n    datfra[columnList] = datfra[columnList].map(normalize)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.upper())\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(',', ' '))\n    datfra[columnList] = datfra[columnList].replace('NAN', np.nan)\n\n    if signs == True:\n        for col in columnList:\n            try:\n                datfra[col] = datfra[col].apply(lambda x: re.sub(r'[\u00a1!?\u00bf]', '', x) )\n            except:\n                print('Not Signs fixed for '+ col)\n\n    return datfra\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funciones-sorted_answer-y-fix_table_answers","title":"Funciones <code>Sorted_Answer</code> y <code>Fix_Table_Answers</code>","text":""},{"location":"00.etl/Utils/Funciones/#funcion-sorted_answer","title":"Funci\u00f3n <code>Sorted_Answer</code>","text":"<p>Prop\u00f3sito: Ordena alfab\u00e9ticamente las respuestas separadas por punto y coma (<code>;</code>) dentro de una cadena. Elimina valores vac\u00edos si existen.</p> <p>Entradas:</p> <ul> <li><code>x</code> (str o NaN): Cadena de texto con respuestas separadas por punto y coma o un valor nulo.</li> </ul> <p>Funcionamiento:</p> <ol> <li>Verifica si la entrada es nula (<code>NaN</code>). Si es as\u00ed, retorna la entrada sin cambios.</li> <li>Divide la cadena en una lista utilizando <code>split(';')</code>.</li> <li>Si hay m\u00e1s de una respuesta:<ul> <li>Ordena alfab\u00e9ticamente la lista.</li> <li>Elimina entradas vac\u00edas si est\u00e1n presentes.</li> <li>Reconstruye la cadena uniendo los valores con <code>;</code>.</li> </ul> </li> <li>Retorna la cadena ordenada o la entrada original si no se cumplen las condiciones.</li> </ol> <p>Salida:</p> <ul> <li><code>str</code> o <code>NaN</code>: Cadena con las respuestas ordenadas alfab\u00e9ticamente o valor original si no hay cambios.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcion-fix_table_answers","title":"Funci\u00f3n <code>Fix_Table_Answers</code>","text":"<p>Prop\u00f3sito:</p> <p>Aplica la funci\u00f3n <code>Sorted_Answer</code> a una columna espec\u00edfica de un DataFrame, actualizando la columna con las respuestas ordenadas.</p> <pre><code>def Sorted_Answer(x):\n    if pd.isnull(x):\n        return x\n    p =  x.split(';') \n    if len(p) &gt; 1:\n        p = sorted(p)\n        p.remove('')\n        p = ';'.join(p)\n        return p\n    return x\n\n\ndef Fix_Table_Answers( table , column_name ):\n    table['RESPUESTA_LIST'] = table[column_name].apply( lambda x: Sorted_Answer(x) )\n    table = table.drop([ column_name ], axis=1)\n    table = table.rename(columns={'RESPUESTA_LIST': column_name})\n\n    return table\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-fix_id_type_caract","title":"Funci\u00f3n <code>Fix_Id_Type_Caract</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_28","title":"Prop\u00f3sito","text":"<p>Estandariza y transforma diferentes representaciones de tipos de identificaci\u00f3n en c\u00f3digos abreviados predefinidos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_28","title":"Entradas","text":"<ul> <li><code>id_type</code> (str): Cadena de texto que representa un tipo de identificaci\u00f3n, como \"CEDULA DE CIUDADANIA\" o \"TARJETA DE IDENTIDAD\".</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_26","title":"Funcionamiento","text":"<ol> <li>Utiliza una estructura <code>match-case</code> para comparar el valor de <code>id_type</code> con diferentes representaciones conocidas.</li> <li>Devuelve el c\u00f3digo abreviado correspondiente:<ul> <li><code>CC</code>: C\u00e9dula de ciudadan\u00eda.</li> <li><code>TI</code>: Tarjeta de identidad.</li> <li><code>RC</code>: Registro civil.</li> <li><code>PE</code>: Permiso especial de permanencia.</li> <li><code>PPT</code>: Permiso especial de permanencia temporal.</li> <li><code>PA</code>: Pasaporte.</li> <li><code>CE</code>: Identificaci\u00f3n extranjera.</li> <li><code>NI</code>: NIT.</li> <li><code>NA</code>: No aplica o no reconocido.</li> </ul> </li> <li>Si no encuentra una coincidencia, devuelve el valor por defecto <code>NA</code>.</li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_27","title":"Salida","text":"<ul> <li><code>str</code>: C\u00f3digo abreviado del tipo de identificaci\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-uso_1","title":"Ejemplo de uso","text":"<p>Entrada: <pre><code>Fix_Id_Type_Caract('CEDULA DE CIUDADANIA')\n</code></pre></p> <p>Salida: <pre><code>'CC'\n</code></pre></p> <pre><code>def Fix_Id_Type_Caract(id_type):\n    match id_type:\n        case '1.CEDULA DE CIUDADANIA':\n             return 'CC'\n        case '2.TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3.REGISTRO CIVIL':\n             return 'RC'\n        case '1. CEDULA':\n             return 'CC'\n        case 'TARJETA DE IDENTIDAD':\n             return 'TI'\n        case 'CEDULA DE CIUDADANIA':\n             return 'CC'\n        case 'REGISTRO CIVIL':\n             return 'RC'\n        case '2. TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3. REGISTRO CIVIL':\n             return 'RC'\n        case '9. PERMISO ESPECIAL DE PERMANENCIA (P.E.P)':\n             return 'PE'\n        case '15. PERMISO ESPECIAL DE PERMANENCIA TEMPORAL':\n             return 'PPT'\n        case '11.\\xa0 IDENTIFICACION DADA POR LA SECRETARIA DE EDUCACION':\n             return 'NA'\n        case '14. ID EXTRANJEROS DIFERENTE A LA CEDULA DE EXTRANJERIA (SOLO PARA FONINIEZ)':\n             return 'C1X'\n        case '6. PASAPORTE':\n             return 'PA'\n        case '5. NUIP':\n             return 'NA'\n        case 'CERTIFICADO DE NACIMIENTO':\n             return 'RC'\n        case 'ID EXTRANJERO':\n             return 'CE'   \n        case 'NIT':\n             return 'NI' \n        case 'NONE':\n             return 'NA'         \n        case _:\n            return 'NA'\n\n    return 'NA'\n</code></pre> <p><code>Fix_Id_Type</code> aplica la transformaci\u00f3n de tipos de identificaci\u00f3n en una columna espec\u00edfica de una tabla si el nombre de la tabla es <code>\"CARACTERIZACION\"</code>.</p> <p><code>Truncate_Column</code> trunca el contenido de las columnas especificadas a un m\u00e1ximo de 255 caracteres. Por otro lado, <code>Fix_Datetime</code> convierte valores tipo <code>NaT</code> a un valor predeterminado (<code>2009-01-01 00:00:00</code>) y agrega la hora inicial a fechas v\u00e1lidas. </p> <p>Finalmente, <code>Fix_DatetimeFinal</code> normaliza una columna de fechas en un DataFrame, convirti\u00e9ndolas a formato <code>datetime</code>, estableciendo la hora como 00:00:00, y manejando errores de conversi\u00f3n de forma segura.</p> <pre><code>def Fix_Id_Type( table , typeIdColumn , tableName ):\n    if tableName == 'CARACTERIZACION':\n        table[typeIdColumn] = table[typeIdColumn].apply( Fix_Id_Type_Caract )\n\ndef Truncate_Column( table , columnsToTruncate ):\n    table[columnsToTruncate] = table[columnsToTruncate].astype(str).apply(lambda x: x.str[:255])\n\n\ndef Fix_Datetime(x):\n    if x == 'NaT':\n        return '2009-01-01 00:00:00'    \n    return x + ' 00:00:00'\n\ndef Fix_DatetimeFinal(table, columnName):\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = pd.to_datetime(table[columnName], format='%Y-%m-%d %H:%M:%S', errors='coerce',dayfirst=True)\n    table[columnName] = table[columnName].apply(lambda x: x.replace(hour=0, minute=0, second=0))\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = table[columnName].apply(lambda x: Fix_Datetime(x)   )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-fix_questions","title":"Funci\u00f3n <code>Fix_Questions</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_29","title":"Prop\u00f3sito","text":"<p>Transforma y organiza un DataFrame de respuestas de encuestas, estructur\u00e1ndolo para an\u00e1lisis, incluyendo la identificaci\u00f3n de preguntas relacionadas con NPS (Net Promoter Score).</p>"},{"location":"00.etl/Utils/Funciones/#entradas_29","title":"Entradas","text":"<ul> <li><code>data</code> (DataFrame): DataFrame original con datos de encuestas.</li> <li><code>servicio</code> (str): Nombre del servicio asociado a las encuestas.</li> <li><code>nps</code> (dict): Diccionario que mapea servicios a preguntas relacionadas con NPS.</li> <li><code>filename</code> (str): Nombre del archivo relacionado para fines de registro.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_27","title":"Funcionamiento","text":"<ol> <li> <p>Renombramiento de columnas:</p> <ul> <li>Cambia el nombre de las columnas <code>fecha</code> a <code>FECHA_ENCUESTA</code> y <code>identificacion</code> a <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas:</p> <ul> <li>Busca columnas cuyo nombre comience con <code>\"etapa3\"</code>, que representan preguntas con calificaci\u00f3n.</li> </ul> </li> <li> <p>Filtrado de columnas relevantes:</p> <ul> <li>Redefine el DataFrame para incluir solo las columnas: <code>FECHA_ENCUESTA</code>, <code>DOCUMENTO</code>, y las preguntas identificadas.</li> </ul> </li> <li> <p>Transformaci\u00f3n de datos:</p> <ul> <li>Transforma el DataFrame a un formato largo utilizando <code>melt</code>:<ul> <li><code>id_vars</code>: Columnas constantes (<code>FECHA_ENCUESTA</code> y <code>DOCUMENTO</code>).</li> <li><code>var_name</code>: Nombre de las columnas de preguntas (<code>PREGUNTA</code>).</li> <li><code>value_name</code>: Valores asociados a las preguntas (<code>CALIFICACION</code>).</li> </ul> </li> </ul> </li> <li> <p>Adici\u00f3n de columnas constantes:</p> <ul> <li>Agrega columnas adicionales:<ul> <li><code>SERVICIO</code>: Nombre del servicio.</li> <li><code>TIPO_DOCUMENTO</code>: Fijado como <code>'CC'</code>.</li> <li><code>NPS</code>: Inicializado como <code>'NO'</code>.</li> </ul> </li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas NPS:</p> <ul> <li>Actualiza la columna <code>NPS</code> a <code>'SI'</code> para las preguntas que coinciden con el servicio especificado en el diccionario <code>nps</code>.</li> </ul> </li> <li> <p>Salida del DataFrame:</p> <ul> <li>Registra el nombre del servicio y archivo procesado.</li> <li>Devuelve el DataFrame transformado.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>En caso de error, registra el servicio y archivo no procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_28","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame transformado en formato largo con las siguientes columnas:</li> <li><code>FECHA_ENCUESTA</code></li> <li><code>DOCUMENTO</code></li> <li><code>PREGUNTA</code></li> <li><code>CALIFICACION</code></li> <li><code>SERVICIO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NPS</code></li> </ul> <pre><code>def Fix_Questions( data , servicio , nps, filename):\n\n    try:\n        df = data  \n        #Modificaciones a columnas\n        df = df.rename(columns={'fecha': 'FECHA_ENCUESTA',\n                                'identificacion':'DOCUMENTO'\n                            })\n\n        #Buscar preguntas con nota\n        dfColumns = df.columns.tolist()\n        columnsWithObs = [val for val in dfColumns if val.startswith(\"etapa3\") ]\n\n        #Redefinir columna\n        df = df[['FECHA_ENCUESTA','DOCUMENTO']+columnsWithObs]\n\n        #Modificaciones y transpocision \n        df_unp = df.melt( id_vars = ['FECHA_ENCUESTA','DOCUMENTO'] , var_name=\"PREGUNTA\", value_name=\"CALIFICACION\")\n        df_unp['SERVICIO'] = servicio\n        df_unp['TIPO_DOCUMENTO'] = 'CC'\n        df_unp['NPS'] = 'NO'\n\n\n        df_unp.loc[df_unp[\"PREGUNTA\"] == nps[servicio], \"NPS\"] = 'SI'\n        print('Agregado: ' +  servicio + filename )\n        return df_unp\n    except:\n        print('Sin formato: ' +  servicio + filename )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-charge_excel_fixed","title":"Funci\u00f3n <code>Charge_Excel_Fixed</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_30","title":"Prop\u00f3sito","text":"<p>Carga un archivo Excel utilizando <code>xlwings</code>, procesa los datos de la primera hoja, y los guarda en un DataFrame despu\u00e9s de limpiar filas y columnas vac\u00edas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_30","title":"Entradas","text":"<ul> <li><code>ruta</code> (str): Ruta del archivo Excel a cargar.</li> <li><code>dfs</code> (dict): Diccionario donde se almacenar\u00e1 el DataFrame procesado, con el nombre del archivo como clave.</li> <li><code>file</code> (str): Nombre del archivo para usarlo como clave en el diccionario <code>dfs</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_28","title":"Funcionamiento","text":"<ol> <li> <p>Carga del archivo Excel:</p> <ul> <li>Utiliza <code>xlwings</code> para abrir el archivo Excel y seleccionar la primera hoja (<code>sheet[0]</code>).</li> </ul> </li> <li> <p>Lectura de datos:</p> <ul> <li>Lee todos los datos de la hoja utilizando <code>sheet.used_range.value</code>.</li> </ul> </li> <li> <p>Creaci\u00f3n del DataFrame:</p> <ul> <li>Convierte los datos le\u00eddos en un DataFrame de pandas.</li> </ul> </li> <li> <p>Limpieza de datos:</p> <ul> <li>Elimina filas y columnas que est\u00e9n completamente vac\u00edas utilizando <code>dropna()</code>.</li> <li>Resetea el \u00edndice del DataFrame con <code>reset_index(drop=True)</code>.</li> </ul> </li> <li> <p>Ajustes adicionales:</p> <ul> <li>Elimina las primeras dos filas (<code>df.drop([0, 1])</code>).</li> <li>Asigna la primera fila como los nombres de las columnas (<code>df.columns = df.iloc[0]</code>).</li> <li>Elimina la primera fila despu\u00e9s de asignarla como encabezado.</li> </ul> </li> <li> <p>Guardar el DataFrame:</p> <ul> <li>Guarda el DataFrame limpio en el diccionario <code>dfs</code> con el nombre del archivo como clave.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_29","title":"Salida","text":"<ul> <li>No retorna valores. El DataFrame limpio se almacena en el diccionario <code>dfs</code> bajo la clave <code>file</code>.</li> </ul> <pre><code>def Charge_Excel_Fixed( ruta , dfs , file ):\n    # Cargar el archivo Excel utilizando xlwings\n    wb = xw.Book(ruta)\n    sheet = wb.sheets[0]  # Seleccionar la primera hoja\n\n    # Leer todos los datos de la hoja\n    data = sheet.used_range.value\n\n    # Crear un DataFrame a partir de los datos le\u00eddos\n    df = pd.DataFrame(data)\n\n    # Eliminar filas completamente en blanco\n    df.dropna(how='all', inplace=True)\n\n    # Eliminar columnas completamente en blanco\n    df.dropna(axis=1, how='all', inplace=True)\n\n    wb.close()\n\n    df.reset_index(drop=True, inplace=True)\n    df = df.drop([0, 1])\n\n    df.columns = df.iloc[0]  \n    df = df[1:].reset_index(drop=True)  \n\n    dfs[file] = df\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funciones-combine_and_store_unparametro-y-combine_and_store","title":"Funciones <code>Combine_and_store_unparametro</code> y <code>Combine_and_store</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_31","title":"Prop\u00f3sito","text":"<p>Las funciones combinan m\u00faltiples archivos de una carpeta en un solo DataFrame, y opcionalmente, guardan el DataFrame combinado en un archivo Excel en una carpeta de destino especificada.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_31","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL de la carpeta que contiene los archivos a combinar.</li> <li><code>download_folder</code> (str, opcional): Ruta del directorio donde se guardar\u00e1 el archivo Excel combinado. Si es <code>None</code>, el DataFrame no se guarda.</li> <li><code>names_file</code> (str, opcional): Nombre del archivo donde se guardar\u00e1 el DataFrame combinado (solo si <code>download_folder</code> no es <code>None</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_29","title":"Funcionamiento","text":"<ol> <li> <p>Carga y procesamiento de archivos:</p> <ul> <li>Ambas funciones utilizan <code>process_files_from_folder</code> para procesar los archivos dentro de <code>folder_url</code>, almacenando los DataFrames en la lista <code>dfs</code>.</li> </ul> </li> <li> <p>Combinaci\u00f3n de DataFrames:</p> <ul> <li>Si se encontraron archivos, los DataFrames en <code>dfs</code> se combinan utilizando <code>pd.concat(dfs, ignore_index=True)</code>.</li> <li>El DataFrame combinado se registra en el log mostrando las primeras filas con <code>df_combined.head()</code>.</li> </ul> </li> <li> <p>Guardado del DataFrame combinado (si aplica):</p> <ul> <li>Si se proporciona <code>download_folder</code>, se verifica si la carpeta existe. Si no, se crea utilizando <code>os.makedirs()</code>.</li> <li>Luego, guarda el DataFrame combinado en un archivo Excel dentro de <code>download_folder</code> con el nombre especificado en <code>names_file</code>.</li> <li>Registra la ruta donde se guarda el archivo en el log.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Si <code>download_folder</code> es <code>None</code>, devuelve el DataFrame combinado.</li> <li>Si <code>download_folder</code> se especifica, guarda el archivo y no retorna nada.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_30","title":"Salida","text":"<ul> <li><code>DataFrame</code>: Si <code>download_folder</code> es <code>None</code>, retorna el DataFrame combinado.</li> <li><code>None</code>: Si se guarda el archivo Excel, no retorna ning\u00fan valor.</li> </ul> <pre><code># Funcion para almacenar los DataFrames &lt;-------------------------------------------\ndef Combine_and_store_unparametro(folder_url,download_folder =None, names_file=None):\n    dfs = []\n    process_files_from_folder(folder_url, dfs)\n    if dfs:\n        df_combined = pd.concat(dfs, ignore_index=True)\n        logger.info(\"Contenido combinado: \\n{}\".format(df_combined.head()))        \n        return df_combined\n\ndef Combine_and_store(folder_url,  download_folder =None , names_file =None):\n    dfs = []\n    process_files_from_folder(folder_url, dfs)\n    if dfs:\n        df_combined = pd.concat(dfs, ignore_index=True)\n        logger.info(\"Contenido combinado: \\n{}\".format(df_combined.head()))\n\n        # si download_folder no es None\n        if download_folder is not None:            \n            # Verificar si la carpeta de destino existe, si no, crearla\n            if not os.path.exists(download_folder):\n                os.makedirs(download_folder, exist_ok=True)\n\n            # Guardar el DataFrame combinado en un archivo Excel\n            output_path = os.path.join(download_folder, names_file)\n            df_combined.to_excel(output_path, index=False)\n            print(f\"Archivo guardado en {output_path}\")\n        else:\n            return df_combined\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-conection_to_c4c","title":"Funci\u00f3n <code>conection_to_C4C</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_32","title":"Prop\u00f3sito","text":"<p>Automatiza el proceso de inicio de sesi\u00f3n en la p\u00e1gina de C4C utilizando Selenium, ingresando las credenciales proporcionadas y haciendo clic en el bot\u00f3n de inicio de sesi\u00f3n.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_32","title":"Entradas","text":"<ul> <li><code>driver</code> (webdriver.Chrome): Instancia de Selenium WebDriver utilizada para interactuar con la p\u00e1gina web.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_30","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n de credenciales:</p> <ul> <li>Recupera el nombre de usuario y la contrase\u00f1a para el inicio de sesi\u00f3n en C4C mediante la funci\u00f3n <code>credenciales(\"C4C\")</code>.</li> </ul> </li> <li> <p>Localizaci\u00f3n de los elementos de inicio de sesi\u00f3n:</p> <ul> <li>Utiliza <code>WebDriverWait</code> para esperar hasta que los elementos necesarios para el inicio de sesi\u00f3n (campos de usuario y contrase\u00f1a, y el bot\u00f3n de login) sean visibles y clickeables.</li> <li>Los elementos son localizados por sus identificadores (<code>USERNAME_FIELD-inner</code>, <code>PASSWORD_FIELD-inner</code>) y el bot\u00f3n de inicio de sesi\u00f3n por su XPath.</li> </ul> </li> <li> <p>Ingreso de credenciales:</p> <ul> <li>Escribe el nombre de usuario y la contrase\u00f1a en los campos correspondientes.</li> </ul> </li> <li> <p>Env\u00edo del formulario de inicio de sesi\u00f3n:</p> <ul> <li>Hace clic en el bot\u00f3n de inicio de sesi\u00f3n para completar el proceso de login.</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Si el inicio de sesi\u00f3n es exitoso, registra un mensaje en el log indicando que el login fue exitoso.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_31","title":"Salida","text":"<ul> <li>No retorna valores. Realiza el inicio de sesi\u00f3n y registra el resultado en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#excepciones_1","title":"Excepciones","text":"<ul> <li><code>TimeoutException</code>: Si alguno de los elementos de la p\u00e1gina (campo de usuario, campo de contrase\u00f1a o bot\u00f3n de inicio de sesi\u00f3n) no se encuentra dentro del tiempo especificado.</li> </ul> <pre><code>def conection_to_C4C(driver):\n    username, password = credenciales(\"C4C\")\n\n    \"\"\"\n    Logs in to the C4C website using the provided credentials.\n\n    Args:\n        driver (webdriver.Chrome): The Selenium WebDriver instance.\n        username (str): The username for C4C login.\n        password (str): The password for C4C login.\n\n    Raises:\n        TimeoutException: If the login elements are not found within the timeout window.\n    \"\"\"\n\n    # Find login elements\n    username_field = WebDriverWait(driver, 10).until(\n        EC.presence_of_element_located((By.ID, \"USERNAME_FIELD-inner\"))\n    )\n    password_field = WebDriverWait(driver, 10).until(\n        EC.presence_of_element_located((By.ID, \"PASSWORD_FIELD-inner\"))\n    )\n    login_button = WebDriverWait(driver, 15).until(\n            EC.element_to_be_clickable((By.XPATH, \"//button[@type='submit']\"))\n    )\n\n    # Enter credentials and submit\n    username_field.send_keys(username)\n    password_field.send_keys(password)\n    login_button.click()\n\n    logging.info(\"Login Successful\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-download_file_between_dates","title":"Funci\u00f3n <code>download_file_between_dates</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_33","title":"Prop\u00f3sito","text":"<p>Automatiza el proceso de descargar un archivo de C4C entre dos fechas especificadas, interactuando con los campos de fecha y las opciones del formulario.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_33","title":"Entradas","text":"<ul> <li><code>initial_date</code> (str): Fecha de inicio en formato de texto (ej. <code>'01/01/2022'</code>).</li> <li><code>final_date</code> (str): Fecha de finalizaci\u00f3n en formato de texto (ej. <code>'12/31/2022'</code>).</li> <li><code>driver</code> (webdriver.Chrome): Instancia de Selenium WebDriver utilizada para interactuar con la p\u00e1gina de C4C.</li> <li><code>_dict</code> (dict): Diccionario que mapea nombres de campos de fecha y otras opciones a sus localizadores correspondientes (por ejemplo, <code>{'initial_date': 'field_id', 'final_date': 'field_id', 'option_1': 'option_xpath'}</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_31","title":"Funcionamiento","text":"<ol> <li> <p>Conexi\u00f3n a C4C:</p> <ul> <li>Llama a la funci\u00f3n <code>conection_to_C4C(driver)</code> para iniciar sesi\u00f3n en C4C utilizando las credenciales.</li> </ul> </li> <li> <p>Interacci\u00f3n con el formulario:</p> <ul> <li>Itera sobre las claves del diccionario <code>_dict</code>.</li> <li>Si la clave no es <code>'initial_date'</code> ni <code>'final_date'</code>, hace clic en el elemento correspondiente usando la funci\u00f3n <code>click_and_wait(driver, _dict[option])</code>.</li> <li>Si la clave es <code>'initial_date'</code>, ingresa la fecha de inicio en el campo correspondiente.</li> <li>Si la clave es <code>'final_date'</code>, ingresa la fecha de finalizaci\u00f3n en el campo correspondiente.</li> </ul> </li> <li> <p>Esperas:</p> <ul> <li>Se utiliza un <code>time.sleep(4)</code> despu\u00e9s de llenar las fechas para asegurarse de que los campos se actualicen correctamente.</li> <li>Se espera 40 segundos (<code>time.sleep(40)</code>) para dar tiempo a que la descarga se complete.</li> </ul> </li> <li> <p>Cierre del WebDriver:</p> <ul> <li>Despu\u00e9s de completar la acci\u00f3n, cierra el WebDriver con <code>driver.quit()</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_32","title":"Salida","text":"<ul> <li>No retorna valores. Realiza la descarga del archivo y cierra la sesi\u00f3n del WebDriver.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#excepciones_2","title":"Excepciones","text":"<ul> <li>Posibles excepciones de Selenium: Si los elementos no son encontrados, la funci\u00f3n podr\u00eda lanzar errores relacionados con la localizaci\u00f3n de elementos o interacci\u00f3n con los campos.</li> </ul> <pre><code>def download_file_between_dates(initial_date, final_date, driver,_dict):\n    # Conexi\u00f3n a C4C\n    conection_to_C4C(driver)\n    # Iterar sobre las opciones en el diccionario\n    for option in _dict:\n        if option not in (\"initial_date\", \"final_date\"):\n            click_and_wait(driver, _dict[option])\n        elif option == \"initial_date\":\n            date_input = driver.find_element(By.ID, _dict[option])\n            date_input.send_keys(initial_date)\n        elif option == \"final_date\":\n            date_input = driver.find_element(By.ID, _dict[option])\n            date_input.send_keys(final_date)\n        time.sleep(4)\n\n    # Tiempo de espera adicional para asegurarse de que la descarga se complete\n    time.sleep(40)  \n\n    # Cerrar el WebDriver\n    driver.quit()\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-click_and_wait","title":"Funci\u00f3n <code>click_and_wait</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_34","title":"Prop\u00f3sito","text":"<p>Hace clic en un elemento localizado mediante XPath y espera a que la p\u00e1gina se cargue o el elemento est\u00e9 listo para interactuar.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_34","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia de Selenium WebDriver utilizada para interactuar con la p\u00e1gina.</li> <li><code>xpath</code> (str): Expresi\u00f3n XPath que localiza el elemento en el DOM.</li> <li><code>timeout</code> (int, opcional): Tiempo m\u00e1ximo en segundos para esperar a que el elemento sea clickeable. El valor predeterminado es <code>30</code> segundos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_32","title":"Funcionamiento","text":"<ol> <li> <p>Esperar hasta que el elemento est\u00e9 clickeable:</p> <ul> <li>Utiliza <code>WebDriverWait</code> para esperar hasta que el elemento identificado por el XPath proporcionado est\u00e9 listo para ser clickeado.</li> </ul> </li> <li> <p>Clic en el elemento:</p> <ul> <li>Una vez que el elemento es clickeable, se realiza el clic en \u00e9l.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_33","title":"Salida","text":"<ul> <li>No retorna valores. Realiza el clic en el elemento especificado y espera a que se cargue.</li> </ul> <pre><code>def click_and_wait(driver, xpath, timeout=30):\n    \"\"\"\n    Clicks on an element identified by xpath and waits for the page to load.\n\n    Args:\n        driver: The WebDriver instance.\n        xpath: The xpath expression to locate the element.\n        timeout: The maximum wait time in seconds (default: 20).\n    \"\"\"\n    link_to_click = WebDriverWait(driver, timeout).until(\n        EC.element_to_be_clickable((By.XPATH, xpath))\n    )\n    link_to_click.click()\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/","title":"Funciones_DM.py","text":"<p>Este archivo contiene una serie de funciones automatizadas desarrolladas para gestionar tareas comunes en la manipulaci\u00f3n de datos y la interacci\u00f3n con sistemas externos. Las funciones descritas est\u00e1n dise\u00f1adas principalmente para automatizar procesos en plataformas como SharePoint y sistemas como C4C, as\u00ed como para facilitar el procesamiento de datos utilizando herramientas como pandas y xlwings.</p> <p>Las funciones cubren una variedad de tareas, incluyendo:</p> <ol> <li> <p>Autenticaci\u00f3n y acceso a plataformas externas:</p> <ul> <li><code>get_file_from_sharepoint</code>: Automatiza la descarga de archivos desde SharePoint.</li> <li><code>list_files_from_sharepoint</code>: Lista archivos en una carpeta de SharePoint.</li> <li><code>process_files_from_folder</code>: Procesa archivos en una carpeta de SharePoint.</li> </ul> </li> <li> <p>Interacci\u00f3n con men\u00fas desplegables y formularios web:</p> <ul> <li>No se incluyen funciones espec\u00edficas para esta tarea en el c\u00f3digo proporcionado.</li> </ul> </li> <li> <p>Descarga y procesamiento de datos:</p> <ul> <li><code>get_file_from_sharepoint</code>: Descarga archivos desde SharePoint.</li> <li><code>process_files_from_folder</code>: Procesa y lee archivos Excel sin descargarlos.</li> </ul> </li> <li> <p>Manejo de archivos y directorios:</p> <ul> <li><code>Charge_Excel_Fixed</code>: Carga y procesa archivos Excel, incluso si est\u00e1n comprimidos en un archivo ZIP.</li> <li><code>_Charge_Excel_Fixed</code>: Carga archivos Excel utilizando xlwings.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n de datos:</p> <ul> <li><code>normalize</code>: Normaliza cadenas de texto.</li> <li><code>PreSave</code>: Preprocesa y limpia datos en un DataFrame.</li> <li><code>Sorted_Answer</code>: Ordena respuestas en una cadena separada por punto y coma.</li> <li><code>Fix_Table_Answers</code>: Ajusta respuestas en una tabla.</li> <li><code>Fix_Id_Type_Caract</code> y <code>Fix_Id_Type</code>: Normalizan tipos de identificaci\u00f3n.</li> <li><code>Truncate_Column</code>: Trunca columnas a una longitud espec\u00edfica.</li> <li><code>Fix_Datetime</code> y <code>Fix_DatetimeFinal</code>: Ajustan formatos de fecha y hora.</li> <li><code>Fix_Questions</code>: Modifica y transpone columnas de preguntas en un DataFrame.</li> </ul> </li> </ol> <p>Este conjunto de herramientas es esencial para mejorar la eficiencia en tareas repetitivas, reduciendo la necesidad de intervenci\u00f3n manual y permitiendo una integraci\u00f3n m\u00e1s fluida entre los sistemas externos y el entorno de trabajo. La automatizaci\u00f3n de estos procesos optimiza el flujo de trabajo y facilita la administraci\u00f3n y procesamiento de grandes vol\u00famenes de datos.</p>"},{"location":"00.etl/Utils/Funciones_DM/#configuracion-e-importacion-de-librerias","title":"Configuraci\u00f3n e importaci\u00f3n de Librer\u00edas","text":"<p>Este bloque de c\u00f3digo configura el entorno de trabajo importando todas las librer\u00edas necesarias para manipulaci\u00f3n de datos, automatizaci\u00f3n de Excel, autenticaci\u00f3n y automatizaci\u00f3n de navegadores web. <code>Funciones.py</code> importa varias librer\u00edas est\u00e1ndar y externas necesarias para el funcionamiento del script.</p>"},{"location":"00.etl/Utils/Funciones_DM/#librerias-estandar","title":"Librer\u00edas est\u00e1ndar","text":"<ul> <li><code>datetime</code></li> <li><code>json</code></li> <li><code>re</code></li> <li><code>requests</code></li> <li><code>timedelta</code></li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#librerias-externas","title":"Librer\u00edas externas","text":"<ul> <li><code>numpy</code></li> <li><code>pandas</code></li> <li><code>xlwings</code></li> <li><code>zipfile</code></li> <li><code>log_step_decorator</code> (de <code>Utils.Funciones</code>)</li> </ul> <pre><code># pylint: disable=all\n# import pandas lib as pd\nimport numpy as np\nimport pandas as pd\nimport re\nimport xlwings as xw\nimport json\nimport requests\nfrom datetime import datetime, timedelta\nfrom Utils.Funciones import log_step_decorator\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#get_file_from_sharepoint","title":"<code>get_file_from_sharepoint</code>","text":"<p>Descarga un archivo desde SharePoint utilizando su URL. Recibe como entrada <code>file_url</code> (str), que especifica la ubicaci\u00f3n del archivo, y devuelve el contenido del archivo como bytes si la solicitud es exitosa. En caso de error, retorna <code>None</code> y registra una advertencia con el c\u00f3digo de estado de la respuesta.</p> <pre><code>@log_step_decorator(\"Obtener archivo de SharePoint\")\ndef get_file_from_sharepoint(file_url, headers):\n    response = requests.get(file_url, headers=headers)\n    print(f\"Response Status Code: {response.status_code}\")\n\n    if response.status_code == 200:\n        return response.content\n    else:\n        print(f\"Error al acceder al archivo. C\u00f3digo de estado: {response.status_code}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#list_files_from_sharepoint","title":"<code>list_files_from_sharepoint</code>","text":"<p>Obtiene una lista de archivos presentes en una carpeta de SharePoint indicada por la URL proporcionada. Recibe como entrada <code>folder_url</code> (str), que especifica la ubicaci\u00f3n de la carpeta, y devuelve una lista de archivos si la solicitud es exitosa o una lista vac\u00eda en caso de fallo. Tambi\u00e9n registra advertencias en caso de errores durante la solicitud.</p> <pre><code>@log_step_decorator(\"Listar archivos de SharePoint\")\ndef list_files_from_sharepoint(folder_url,headers,sharepoint_base_url):\n    list_files_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n    response = requests.get(list_files_url, headers=headers)\n\n\n    if response.status_code == 200:\n        files = response.json()['d']['results']\n        return files\n    else:\n        print(f\"Error al listar los archivos. C\u00f3digo de estado: {response.status_code}\")\n        return []\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-process_files_from_folder","title":"Funci\u00f3n <code>process_files_from_folder</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito","title":"Prop\u00f3sito","text":"<p>Procesa archivos de una carpeta de SharePoint que han sido modificados en los \u00faltimos seis meses, almacenando los datos en una lista de DataFrames.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL de la carpeta en SharePoint desde donde se obtendr\u00e1n los archivos.</li> <li><code>dfs</code> (list): Lista utilizada para almacenar los DataFrames procesados.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento","title":"Funcionamiento","text":"<ol> <li>Listar archivos: Obtiene la lista de archivos en la carpeta de SharePoint.</li> <li>Filtrar por fecha: Identifica archivos modificados en los \u00faltimos seis meses.</li> <li>Procesar archivos:<ul> <li>Recupera el contenido de los archivos seleccionados desde SharePoint.</li> <li>Lee el contenido de los archivos como DataFrames utilizando <code>pandas</code>.</li> <li>Registra informaci\u00f3n sobre el contenido y lo almacena en la lista <code>dfs</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida","title":"Salida","text":"<ul> <li>No retorna ning\u00fan valor. Modifica la lista <code>dfs</code> proporcionada al agregar los DataFrames procesados.</li> </ul> <pre><code>@log_step_decorator(\"Procesar archivos\")\ndef process_files_from_folder(folder_url, dfs,headers, sharepoint_base_url):\n\n    files = list_files_from_sharepoint(folder_url, headers, sharepoint_base_url)\n    six_months_ago = datetime.now() - timedelta(days=180)\n\n\n\n    for file in files:\n        file_name = file['Name']\n        file_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n        modified_date_str = file['TimeLastModified']\n        modified_date = datetime.strptime(modified_date_str, '%Y-%m-%dT%H:%M:%SZ')\n        print('MODIFY', modified_date)\n\n        if modified_date &gt;= six_months_ago:\n\n            # Obtener el archivo de SharePoint\n            file_content = get_file_from_sharepoint(file_url, headers)\n\n            if file_content:\n                # Leer el archivo Excel sin descargar\n                df = pd.read_excel(file_content)\n                print(f\"Contenido de {file_name}:\\n\", df.head())\n                dfs.append(df)\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#normalize","title":"<code>normalize</code>","text":"<p>Elimina las tildes de un texto, reemplaz\u00e1ndolas por sus versiones sin acento, tanto en min\u00fasculas como en may\u00fasculas.</p> <pre><code>def normalize(s):\n    replacements = (\n        (\"\u00e1\", \"a\"),\n        (\"\u00e9\", \"e\"),\n        (\"\u00ed\", \"i\"),\n        (\"\u00f3\", \"o\"),\n        (\"\u00fa\", \"u\"),\n    )\n    for a, b in replacements:\n        s = s.replace(a, b).replace(a.upper(), b.upper())\n    return s\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-presave","title":"Funci\u00f3n <code>PreSave</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_1","title":"Prop\u00f3sito","text":"<p>Realiza un preprocesamiento de columnas en un DataFrame, limpiando y normalizando valores textuales, y opcionalmente eliminando signos de puntuaci\u00f3n espec\u00edficos.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_1","title":"Entradas","text":"<ul> <li><code>df</code> (DataFrame): DataFrame original que se desea procesar.</li> <li><code>columnList</code> (list): Lista de columnas del DataFrame que ser\u00e1n procesadas.</li> <li><code>signs</code> (bool, opcional): Si es <code>True</code>, elimina signos de puntuaci\u00f3n como <code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code> de las columnas. Por defecto: <code>False</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_1","title":"Funcionamiento","text":"<ol> <li> <p>Copiar el DataFrame:</p> <ul> <li>Crea una copia del DataFrame original para evitar modificaciones en el objeto original.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n:</p> <ul> <li>Reemplazos espec\u00edficos:<ul> <li>Convierte <code>\\xf1</code> a <code>ni</code> (e.g., \"\u00f1\" a \"ni\").</li> <li>Convierte <code>\\xD1</code> a <code>NI</code> (e.g., \"\u00d1\" a \"NI\").</li> <li>Sustituye caracteres no rompibles (<code>\\u00A0</code>) por espacios.</li> </ul> </li> <li>Eliminaci\u00f3n de espacios:<ul> <li>Reemplaza espacios dobles por simples.</li> <li>Elimina espacios al inicio y final de las cadenas.</li> </ul> </li> <li>Normalizaci\u00f3n de texto:<ul> <li>Convierte los valores a cadenas en may\u00fasculas.</li> <li>Aplica la funci\u00f3n <code>normalize</code> para eliminar tildes.</li> <li>Reemplaza comas por espacios.</li> </ul> </li> <li>Gesti\u00f3n de valores nulos:<ul> <li>Sustituye valores <code>\"NAN\"</code> por <code>np.nan</code>.</li> </ul> </li> </ul> </li> <li> <p>Eliminaci\u00f3n de signos (opcional):</p> <ul> <li>Si <code>signs=True</code>, elimina signos de puntuaci\u00f3n (<code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code>) utilizando expresiones regulares.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_1","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame con las columnas especificadas procesadas y normalizadas.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#ejemplo-de-uso","title":"Ejemplo de uso","text":"<p>Si la entrada es: <pre><code>df = pd.DataFrame({'col1': ['\u00a1Hola, mundo!', '\u00bfQu\u00e9 tal?']})\nPreSave(df, ['col1'], signs=True)\n</code></pre></p> <p>La salida ser\u00e1: <pre><code>      col1\n0    HOLA MUNDO\n1    QUE TAL\n</code></pre></p> <pre><code>def PreSave(df , columnList, signs = False):\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xf1', 'ni'))\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xD1', 'NI'))\n\n    datfra = df.copy()\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xf1', 'ni'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xD1', 'NI'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('\\u00A0', ' '))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('  ', ' '))\n    datfra[columnList] = datfra[columnList].astype(str)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.strip())\n    datfra[columnList] = datfra[columnList].map(normalize)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.upper())\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(',', ' '))\n    datfra[columnList] = datfra[columnList].replace('NAN', np.nan)\n\n    if signs == True:\n        for col in columnList:\n            try:\n                datfra[col] = datfra[col].apply(lambda x: re.sub(r'[\u00a1!?\u00bf]', '', x) )\n            except:\n                print('Not Signs fixed for '+ col)\n\n    return datfra\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funciones-sorted_answer-y-fix_table_answers","title":"Funciones <code>Sorted_Answer</code> y <code>Fix_Table_Answers</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#funcion-sorted_answer","title":"Funci\u00f3n <code>Sorted_Answer</code>","text":"<p>Prop\u00f3sito: Ordena alfab\u00e9ticamente las respuestas separadas por punto y coma (<code>;</code>) dentro de una cadena. Elimina valores vac\u00edos si existen.</p> <p>Entradas:</p> <ul> <li><code>x</code> (str o NaN): Cadena de texto con respuestas separadas por punto y coma o un valor nulo.</li> </ul> <p>Funcionamiento:</p> <ol> <li>Verifica si la entrada es nula (<code>NaN</code>). Si es as\u00ed, retorna la entrada sin cambios.</li> <li>Divide la cadena en una lista utilizando <code>split(';')</code>.</li> <li>Si hay m\u00e1s de una respuesta:<ul> <li>Ordena alfab\u00e9ticamente la lista.</li> <li>Elimina entradas vac\u00edas si est\u00e1n presentes.</li> <li>Reconstruye la cadena uniendo los valores con <code>;</code>.</li> </ul> </li> <li>Retorna la cadena ordenada o la entrada original si no se cumplen las condiciones.</li> </ol> <p>Salida:</p> <ul> <li><code>str</code> o <code>NaN</code>: Cadena con las respuestas ordenadas alfab\u00e9ticamente o valor original si no hay cambios.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-fix_table_answers","title":"Funci\u00f3n <code>Fix_Table_Answers</code>","text":"<p>Prop\u00f3sito:</p> <p>Aplica la funci\u00f3n <code>Sorted_Answer</code> a una columna espec\u00edfica de un DataFrame, actualizando la columna con las respuestas ordenadas.</p> <pre><code>def Sorted_Answer(x):\n    if pd.isnull(x):\n        return x\n    p =  x.split(';') \n    if len(p) &gt; 1:\n        p = sorted(p)\n        p.remove('')\n        p = ';'.join(p)\n        return p\n    return x\n</code></pre> <pre><code>def Fix_Table_Answers( table , column_name ):\n    table['RESPUESTA_LIST'] = table[column_name].apply( lambda x: Sorted_Answer(x) )\n    table = table.drop([ column_name ], axis=1)\n    table = table.rename(columns={'RESPUESTA_LIST': column_name})\n\n    return table\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-fix_id_type_caract","title":"Funci\u00f3n <code>Fix_Id_Type_Caract</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_2","title":"Prop\u00f3sito","text":"<p>Estandariza y transforma diferentes representaciones de tipos de identificaci\u00f3n en c\u00f3digos abreviados predefinidos.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_2","title":"Entradas","text":"<ul> <li><code>id_type</code> (str): Cadena de texto que representa un tipo de identificaci\u00f3n, como \"CEDULA DE CIUDADANIA\" o \"TARJETA DE IDENTIDAD\".</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_2","title":"Funcionamiento","text":"<ol> <li>Utiliza una estructura <code>match-case</code> para comparar el valor de <code>id_type</code> con diferentes representaciones conocidas.</li> <li>Devuelve el c\u00f3digo abreviado correspondiente:<ul> <li><code>CC</code>: C\u00e9dula de ciudadan\u00eda.</li> <li><code>TI</code>: Tarjeta de identidad.</li> <li><code>RC</code>: Registro civil.</li> <li><code>PE</code>: Permiso especial de permanencia.</li> <li><code>PPT</code>: Permiso especial de permanencia temporal.</li> <li><code>PA</code>: Pasaporte.</li> <li><code>CE</code>: Identificaci\u00f3n extranjera.</li> <li><code>NI</code>: NIT.</li> <li><code>NA</code>: No aplica o no reconocido.</li> </ul> </li> <li>Si no encuentra una coincidencia, devuelve el valor por defecto <code>NA</code>.</li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_2","title":"Salida","text":"<ul> <li><code>str</code>: C\u00f3digo abreviado del tipo de identificaci\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#ejemplo-de-uso_1","title":"Ejemplo de uso","text":"<p>Entrada: <pre><code>Fix_Id_Type_Caract('CEDULA DE CIUDADANIA')\n</code></pre></p> <p>Salida: <pre><code>'CC'\n</code></pre></p> <p><pre><code>def Fix_Id_Type_Caract(id_type):\n    match id_type:\n        case '1.CEDULA DE CIUDADANIA':\n             return 'CC'\n        case '2.TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3.REGISTRO CIVIL':\n             return 'RC'\n        case '1. CEDULA':\n             return 'CC'\n        case 'TARJETA DE IDENTIDAD':\n             return 'TI'\n        case 'CEDULA DE CIUDADANIA':\n             return 'CC'\n        case 'REGISTRO CIVIL':\n             return 'RC'\n        case '2. TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3. REGISTRO CIVIL':\n             return 'RC'\n        case '9. PERMISO ESPECIAL DE PERMANENCIA (P.E.P)':\n             return 'PE'\n        case '15. PERMISO ESPECIAL DE PERMANENCIA TEMPORAL':\n             return 'PPT'\n        case '11.\\xa0 IDENTIFICACION DADA POR LA SECRETARIA DE EDUCACION':\n             return 'NA'\n        case '14. ID EXTRANJEROS DIFERENTE A LA CEDULA DE EXTRANJERIA (SOLO PARA FONINIEZ)':\n             return 'C1X'\n        case '6. PASAPORTE':\n             return 'PA'\n        case '5. NUIP':\n             return 'NA'\n        case 'CERTIFICADO DE NACIMIENTO':\n             return 'RC'\n        case 'ID EXTRANJERO':\n             return 'CE'   \n        case 'NIT':\n             return 'NI' \n        case 'NONE':\n             return 'NA'         \n        case _:\n            return 'NA'\n\n    return 'NA'\n</code></pre> <code>Fix_Id_Type</code> aplica la transformaci\u00f3n de tipos de identificaci\u00f3n en una columna espec\u00edfica de una tabla si el nombre de la tabla es <code>\"CARACTERIZACION\"</code>.</p> <p><code>Truncate_Column</code> trunca el contenido de las columnas especificadas a un m\u00e1ximo de 255 caracteres. Por otro lado, <code>Fix_Datetime</code> convierte valores tipo <code>NaT</code> a un valor predeterminado (<code>2009-01-01 00:00:00</code>) y agrega la hora inicial a fechas v\u00e1lidas. </p> <p>Finalmente, <code>Fix_DatetimeFinal</code> normaliza una columna de fechas en un DataFrame, convirti\u00e9ndolas a formato <code>datetime</code>, estableciendo la hora como 00:00:00, y manejando errores de conversi\u00f3n de forma segura.</p> <pre><code>def Fix_Id_Type( table , typeIdColumn , tableName ):\n    if tableName == 'CARACTERIZACION':\n        table[typeIdColumn] = table[typeIdColumn].apply( Fix_Id_Type_Caract )\n</code></pre> <pre><code>def Truncate_Column( table , columnsToTruncate ):\n    table[columnsToTruncate] = table[columnsToTruncate].astype(str).apply(lambda x: x.str[:255])\n</code></pre> <pre><code>def Fix_Datetime(x):\n    if x == 'NaT':\n        return '2009-01-01 00:00:00'    \n    return x + ' 00:00:00'\n</code></pre> <pre><code>def Fix_DatetimeFinal(table, columnName):\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = pd.to_datetime(table[columnName], format='%Y-%m-%d %H:%M:%S', errors='coerce',dayfirst=True)\n    table[columnName] = table[columnName].apply(lambda x: x.replace(hour=0, minute=0, second=0))\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = table[columnName].apply(lambda x: Fix_Datetime(x)   )\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-fix_questions","title":"Funci\u00f3n <code>Fix_Questions</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_3","title":"Prop\u00f3sito","text":"<p>Transforma y organiza un DataFrame de respuestas de encuestas, estructur\u00e1ndolo para an\u00e1lisis, incluyendo la identificaci\u00f3n de preguntas relacionadas con NPS (Net Promoter Score).</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_3","title":"Entradas","text":"<ul> <li><code>data</code> (DataFrame): DataFrame original con datos de encuestas.</li> <li><code>servicio</code> (str): Nombre del servicio asociado a las encuestas.</li> <li><code>nps</code> (dict): Diccionario que mapea servicios a preguntas relacionadas con NPS.</li> <li><code>filename</code> (str): Nombre del archivo relacionado para fines de registro.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_3","title":"Funcionamiento","text":"<ol> <li> <p>Renombramiento de columnas:</p> <ul> <li>Cambia el nombre de las columnas <code>fecha</code> a <code>FECHA_ENCUESTA</code> y <code>identificacion</code> a <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas:</p> <ul> <li>Busca columnas cuyo nombre comience con <code>\"etapa3\"</code>, que representan preguntas con calificaci\u00f3n.</li> </ul> </li> <li> <p>Filtrado de columnas relevantes:</p> <ul> <li>Redefine el DataFrame para incluir solo las columnas: <code>FECHA_ENCUESTA</code>, <code>DOCUMENTO</code>, y las preguntas identificadas.</li> </ul> </li> <li> <p>Transformaci\u00f3n de datos:</p> <ul> <li>Transforma el DataFrame a un formato largo utilizando <code>melt</code>:<ul> <li><code>id_vars</code>: Columnas constantes (<code>FECHA_ENCUESTA</code> y <code>DOCUMENTO</code>).</li> <li><code>var_name</code>: Nombre de las columnas de preguntas (<code>PREGUNTA</code>).</li> <li><code>value_name</code>: Valores asociados a las preguntas (<code>CALIFICACION</code>).</li> </ul> </li> </ul> </li> <li> <p>Adici\u00f3n de columnas constantes:</p> <ul> <li>Agrega columnas adicionales:<ul> <li><code>SERVICIO</code>: Nombre del servicio.</li> <li><code>TIPO_DOCUMENTO</code>: Fijado como <code>'CC'</code>.</li> <li><code>NPS</code>: Inicializado como <code>'NO'</code>.</li> </ul> </li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas NPS:</p> <ul> <li>Actualiza la columna <code>NPS</code> a <code>'SI'</code> para las preguntas que coinciden con el servicio especificado en el diccionario <code>nps</code>.</li> </ul> </li> <li> <p>Salida del DataFrame:</p> <ul> <li>Registra el nombre del servicio y archivo procesado.</li> <li>Devuelve el DataFrame transformado.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>En caso de error, registra el servicio y archivo no procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_3","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame transformado en formato largo con las siguientes columnas:</li> <li><code>FECHA_ENCUESTA</code></li> <li><code>DOCUMENTO</code></li> <li><code>PREGUNTA</code></li> <li><code>CALIFICACION</code></li> <li><code>SERVICIO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NPS</code></li> </ul> <pre><code>def Fix_Questions( data , servicio , nps, filename):\n\n    try:\n        df = data  \n        #Modificaciones a columnas\n        df = df.rename(columns={'fecha': 'FECHA_ENCUESTA',\n                                'identificacion':'DOCUMENTO'\n                            })\n\n        #Buscar preguntas con nota\n        dfColumns = df.columns.tolist()\n        columnsWithObs = [val for val in dfColumns if val.startswith(\"etapa3\") ]\n\n        #Redefinir columna\n        df = df[['FECHA_ENCUESTA','DOCUMENTO']+columnsWithObs]\n\n        #Modificaciones y transpocision \n        df_unp = df.melt( id_vars = ['FECHA_ENCUESTA','DOCUMENTO'] , var_name=\"PREGUNTA\", value_name=\"CALIFICACION\")\n        df_unp['SERVICIO'] = servicio\n        df_unp['TIPO_DOCUMENTO'] = 'CC'\n        df_unp['NPS'] = 'NO'\n\n\n        df_unp.loc[df_unp[\"PREGUNTA\"] == nps[servicio], \"NPS\"] = 'SI'\n        print('Agregado: ' +  servicio + filename )\n        return df_unp\n    except:\n        print('Sin formato: ' +  servicio + filename )\n</code></pre> <pre><code>import pandas as pd\nfrom zipfile import ZipFile\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-charge_excel_fixed","title":"Funci\u00f3n <code>Charge_Excel_Fixed</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_4","title":"Prop\u00f3sito","text":"<p>Carga un archivo Excel comprimido en formato ZIP, procesa los datos en un DataFrame de pandas, y lo limpia eliminando filas y columnas vac\u00edas antes de almacenarlo en un diccionario.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_4","title":"Entradas","text":"<ul> <li><code>ruta</code> (str): Ruta del archivo Excel, que puede estar comprimido en formato ZIP.</li> <li><code>dfs</code> (dict): Diccionario donde se almacenar\u00e1 el DataFrame procesado, con el nombre del archivo como clave.</li> <li><code>file</code> (str): Nombre del archivo para usarlo como clave en el diccionario <code>dfs</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_4","title":"Funcionamiento","text":"<ol> <li> <p>Verificaci\u00f3n del archivo ZIP:</p> <ul> <li>Intenta abrir el archivo como un archivo ZIP utilizando <code>ZipFile</code>. Si es un archivo ZIP v\u00e1lido, continua con el procesamiento.</li> </ul> </li> <li> <p>Carga del archivo Excel:</p> <ul> <li>Intenta cargar el archivo Excel utilizando pandas (<code>pd.read_excel</code>) con el motor <code>openpyxl</code>.</li> <li>Si se encuentra alg\u00fan error en la carga, se captura y se registra un mensaje.</li> </ul> </li> <li> <p>Procesamiento y limpieza del DataFrame:</p> <ul> <li>Se crea un DataFrame a partir de los datos cargados.</li> <li>Se eliminan filas y columnas vac\u00edas con <code>dropna(how='all')</code> y <code>dropna(axis=1, how='all')</code>.</li> <li>Se restablece el \u00edndice del DataFrame y se asigna la primera fila como nombres de columna.</li> <li>Se elimina la primera fila (que ahora se utiliza como encabezado).</li> <li>El DataFrame limpio se guarda en el diccionario <code>dfs</code> con la clave proporcionada por <code>file</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura y registra cualquier error que ocurra durante la carga o el procesamiento del archivo.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_4","title":"Salida","text":"<ul> <li>No retorna valores. El DataFrame procesado se almacena en el diccionario <code>dfs</code> bajo la clave <code>file</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#consideraciones","title":"Consideraciones","text":"<ul> <li>Se verifica si el archivo es un ZIP v\u00e1lido antes de intentar cargar el archivo Excel.</li> <li>El DataFrame es limpiado de cualquier fila o columna vac\u00eda antes de su procesamiento.</li> <li>Aseg\u00farese de que el archivo Excel est\u00e9 correctamente formateado para que las primeras filas contengan los encabezados.</li> </ul> <pre><code>def Charge_Excel_Fixed(ruta, dfs, file):\n    try:\n        # Verificar si es un archivo ZIP v\u00e1lido\n        with ZipFile(ruta, 'r'):\n            print(\"El archivo es un ZIP v\u00e1lido.\")\n\n        # Intentar cargar con pandas y openpyxl\n        data = pd.read_excel(ruta, engine='openpyxl')\n        print(\"Archivo cargado exitosamente con pandas y openpyxl.\")\n    except Exception as e:\n        print(f\"Error al cargar el archivo: {e}\")\n        return\n\n    # Procesar el DataFrame\n    try:\n        df = pd.DataFrame(data)\n        df.dropna(how='all', inplace=True)\n        df.dropna(axis=1, how='all', inplace=True)\n        df.reset_index(drop=True, inplace=True)\n        df.columns = df.iloc[0]\n        df = df[1:].reset_index(drop=True)\n        dfs[file] = df\n        print(\"Archivo procesado exitosamente.\")\n    except Exception as e:\n        print(f\"Error procesando el DataFrame: {e}\")\n</code></pre>"},{"location":"00.etl/Utils/c4c_from_sharepoint/","title":"c4c_from_sharepoint","text":"<p>Este script automatiza la descarga de archivos desde una carpeta de SharePoint utilizando el API de SharePoint y los m\u00f3dulos <code>requests</code> y <code>msal</code> para autenticar y obtener datos. El script tambi\u00e9n incluye funcionalidades de procesamiento de archivos, creaci\u00f3n de carpetas y manejo de archivos descargados. A continuaci\u00f3n, se describe el funcionamiento y prop\u00f3sito de cada componente y funci\u00f3n del script.</p>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#dependencias-y-configuracion","title":"Dependencias y configuraci\u00f3n","text":"<ol> <li> <p>Librer\u00edas:</p> <ul> <li>El script importa varias librer\u00edas como <code>argparse</code>, <code>io</code>, <code>logging</code>, <code>os</code>, <code>requests</code>, <code>pandas</code>, <code>msal</code>, entre otras, para realizar tareas de autenticaci\u00f3n, procesamiento de datos y manejo de archivos.</li> </ul> </li> <li> <p>Archivo <code>credenciales.env</code>:</p> <ul> <li>Se cargan las credenciales de acceso desde el archivo <code>credenciales.env</code>, que contiene las claves necesarias para autenticar la aplicaci\u00f3n en Microsoft Azure.</li> </ul> </li> <li> <p>Autenticaci\u00f3n en Microsoft Azure:</p> <ul> <li>Utiliza <code>msal</code> para obtener un token de acceso que se usar\u00e1 en las solicitudes de la API de SharePoint.</li> </ul> </li> <li> <p>Configuraci\u00f3n de logging:</p> <ul> <li>Se configura un logger para registrar los eventos en un archivo <code>scraper_SSIS.log</code> y en la consola. Esto permite el monitoreo del proceso de descarga y cualquier error que pueda ocurrir.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#funciones-principales","title":"Funciones principales","text":"<ol> <li> <p><code>download_file_from_sharepoint</code>:</p> <ul> <li>Esta funci\u00f3n se encarga de descargar un archivo desde SharePoint utilizando la URL del archivo y el token de autenticaci\u00f3n.</li> <li>La funci\u00f3n recibe el nombre del archivo, la URL de la carpeta de SharePoint y la ruta de destino para guardar el archivo descargado.</li> <li>Si la solicitud es exitosa (<code>status_code == 200</code>), guarda el archivo en el directorio indicado.</li> </ul> </li> <li> <p><code>download_all_files_from_sharepoint</code>:</p> <ul> <li>Descarga todos los archivos de una carpeta espec\u00edfica en SharePoint.</li> <li>Llama a la API de SharePoint para obtener la lista de archivos en la carpeta especificada.</li> <li>Filtra los archivos que coinciden con un modelo de archivo (por ejemplo, <code>Listadesolicitudesdeservicio__ES.xlsx</code>) y descarga cada uno de ellos utilizando la funci\u00f3n <code>download_file_from_sharepoint</code>.</li> </ul> </li> <li> <p><code>run_etl</code>:</p> <ul> <li>Esta funci\u00f3n envuelve el proceso de descarga de archivos de SharePoint, llamando a <code>download_all_files_from_sharepoint</code> con la URL de la carpeta y el directorio de destino.</li> </ul> </li> <li> <p>Autenticaci\u00f3n con <code>msal</code>:</p> <ul> <li>El script usa la librer\u00eda <code>msal</code> para obtener un token de acceso mediante las credenciales proporcionadas en el archivo <code>credenciales.env</code>. Este token se usa para autorizar las solicitudes a la API de SharePoint.</li> </ul> </li> <li> <p>Ejecuci\u00f3n del proceso de descarga:</p> <ul> <li>Dentro de la funci\u00f3n <code>run_etl</code>, se configuran los par\u00e1metros de carpeta y directorio de destino, y se inicia el proceso de descarga de los archivos de SharePoint.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#flujo-del-script","title":"Flujo del script","text":"<ol> <li> <p>Autenticaci\u00f3n:</p> <ul> <li>Se obtienen las credenciales y el token de acceso a la API de SharePoint utilizando <code>msal</code> con las credenciales proporcionadas en el archivo <code>credenciales.env</code>.</li> </ul> </li> <li> <p>Obtenci\u00f3n y descarga de archivos:</p> <ul> <li>El script obtiene los archivos de SharePoint desde la carpeta especificada (<code>folder_url</code>), filtra los archivos relevantes y los descarga al directorio de destino.</li> </ul> </li> <li> <p>Proceso ETL:</p> <ul> <li>El proceso ETL se lleva a cabo con el decorador <code>log_step_decorator</code>, lo que permite registrar el avance de cada paso en el proceso de descarga.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#consideraciones","title":"Consideraciones","text":"<ul> <li>Dependencias: Es necesario tener las librer\u00edas <code>msal</code>, <code>pandas</code>, <code>requests</code>, y <code>xlwings</code> instaladas para que el script funcione correctamente.</li> <li>Carpetas de destino: El script crea el directorio de descarga si no existe previamente, asegurando que los archivos descargados se almacenen en la ubicaci\u00f3n correcta.</li> <li>Manejo de errores: Se incluye un manejo b\u00e1sico de errores a trav\u00e9s del registro en logs para que cualquier error durante la descarga sea f\u00e1cilmente rastreable.</li> </ul> <p>Este script facilita la integraci\u00f3n y automatizaci\u00f3n del proceso de descarga de archivos C4C desde SharePoint, ideal para sistemas de gesti\u00f3n de archivos y procesamiento de datos.</p> <pre><code>import argparse\nimport io\nimport logging\nimport os\nimport re\nimport requests\nimport time\nfrom datetime import datetime\nimport pandas as pd\nfrom msal import ConfidentialClientApplication\n</code></pre> <pre><code>from Funciones import (\n    log_step_decorator, csv_files\n)\n</code></pre> <pre><code># Cambiar el directorio de trabajo al directorio del script\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nos.chdir(script_dir)\n</code></pre> <pre><code># Leer la clave privada desde el archivo key.pem\nwith open('credenciales.env', 'r') as key_file:\n    lines = key_file.readlines()\n</code></pre> <pre><code># Procesar las claves\nkeys = {}\nfor line in lines:\n    key, value = line.strip().split(\" = \")\n    keys[key] = value.strip('\"')\n</code></pre> <pre><code>client_id = keys.get(\"client_id\")\ncert_thumbprint = keys.get(\"cert_thumbprint\")\ntenant_id = keys.get(\"tenant_id\")\n</code></pre> <pre><code>authority = f\"https://login.microsoftonline.com/{tenant_id}\"\n</code></pre> <pre><code># Leer la clave privada desde el archivo key.pem\nwith open('key.pem', 'r') as key_file:\n    private_key = key_file.read()\n</code></pre> <pre><code>cert = {\n    \"private_key\": private_key,\n    \"thumbprint\": cert_thumbprint,\n}\n</code></pre> <pre><code>msal_app = ConfidentialClientApplication(\n    client_id=client_id,\n    authority=authority,\n    client_credential=cert,\n)\n</code></pre> <pre><code>scopes_sharepoint_online = [keys.get(\"scopes_sharepoint_online\")]\n</code></pre> <pre><code>results = msal_app.acquire_token_for_client(scopes_sharepoint_online)\n</code></pre> <pre><code>if \"access_token\" in results:\n    access_token = results.get(\"access_token\")\n</code></pre> <pre><code>headers = {\n    \"Authorization\": f\"Bearer {access_token}\",\n    \"Accept\": \"application/json;odata=verbose\",\n    \"Content-Type\": \"application/json\",\n}\n</code></pre> <pre><code>sharepoint_base_url = keys.get(\"sharepoint_base_url\")\n</code></pre> <pre><code># Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n</code></pre> <pre><code>if logger.hasHandlers():\n    logger.handlers.clear()\n</code></pre> <pre><code>formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper_SSIS.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n</code></pre> <pre><code>import warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n</code></pre> <pre><code># Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre> <pre><code>@log_step_decorator(\"Descargar archivo de SharePoint\")\ndef download_file_from_sharepoint(file_name, folder_url, download_path):\n    # Crear las carpetas si no existen\n    if not os.path.exists(os.path.dirname(download_path)):\n        os.makedirs(os.path.dirname(download_path))\n        logging.info(f\"Carpeta creada: {os.path.dirname(download_path)}\")\n\n    # Ruta completa del archivo en SharePoint\n    logging.info(f\"Ruta completa del archivo a descargar: {download_path}\")\n\n    download_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n    response = requests.get(download_url, headers=headers)\n\n    if response.status_code == 200:\n        # Eliminar la marca de fecha y hora del nombre del archivo\n        clean_file_name = file_name\n        clean_download_path = os.path.join(os.path.dirname(download_path), clean_file_name)\n\n        # Guardar el archivo descargado con el nuevo nombre\n        with open(clean_download_path, \"wb\") as file:\n            file.write(response.content)\n        logging.info(f\"Archivo descargado exitosamente como: {clean_file_name}\")\n    else:\n        logging.info(f\"Error al descargar el archivo. C\u00f3digo de estado: {response.status_code}\")\n        logging.info(f\"Error: {response.text}\")\n</code></pre> <pre><code># @log_step_decorator(\"ETL\")\ndef download_all_files_from_sharepoint(folder_url, download_directory):\n    # Construye la URL para acceder a los archivos de una carpeta espec\u00edfica en SharePoint\n    folder_api_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n\n    # Realiza una solicitud GET a la URL de la API de SharePoint para obtener los archivos de la carpeta\n    response = requests.get(folder_api_url, headers=headers)\n    # Imprime la URL a la que se est\u00e1 conectando\n    logging.info(f\"Conectando a {folder_api_url}\")\n    # Imprime el estado de la respuesta de la solicitud\n    logging.info(f\"Estado de la respuesta: {response.status_code}\")\n\n    if response.status_code == 200:\n        # Extrae la lista de archivos de la respuesta JSON de la solicitud GET\n        files = response.json().get('d', {}).get('results', [])\n        logging.info(f\"Se encontraron {len(files)} archivos en la carpeta especificada.\")        \n        if not files:\n            logging.info(\"No se encontraron archivos en la carpeta especificada.\")\n            return\n\n        if key in csv_files:\n            extension = \"csv\"\n        else:\n            extension = \"xlsx\"\n\n        # Obtiene el nombre del archivo sin la extensi\u00f3n\n        archivo = \"Listadesolicitudesdeservicio__ES.xlsx\"\n        if archivo:\n            archivo_modelo = os.path.splitext(archivo)[0]\n            # filtra todos los archivos que inicien con archivo_modelo sin extencion y los guarda en una lista \n            files = [file for file in files if file.get('Name').startswith(archivo_modelo)]    \n            logging.info(f\"Se encontraron {len(files)} archivos que coinciden con el modelo de archivo: {archivo_modelo}\")\n        else:\n            logging.info(f\"Se encontraron {len(files)} archivos\")\n            archivo = f\"procesado_{key}.{extension}\"\n\n\n        # Itera sobre la lista de archivos y descarga cada uno\n        for file in files:\n            file_name = file.get('Name')\n            download_path = os.path.join(download_directory, file_name)\n            download_file_from_sharepoint(file_name, folder_url, download_path)\n</code></pre> <pre><code>if __name__ == \"__main__\":\n    logging.info(f'Procesando Sharepoint C4C')\n    # Actualizar root_directory para que etl_destino lo asigne\n    root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n    destino = '02.Archivos/01.Transversal/PQRs'\n    root_directory = os.path.abspath(os.path.join(root_directory1, destino))\n    logging.info(root_directory + \" \\n \" + destino)\n    # Obtener la carpeta desde la clave proporcionada\n    folder_url = 'Documentos compartidos/02.C4C'\n\n    # Descargar archivos\n    @log_step_decorator(f\"ETL Sharepoint C4C\")\n    def run_etl():\n        download_all_files_from_sharepoint(folder_url, root_directory)\n\n    run_etl()\n</code></pre>"},{"location":"00.etl/Utils/dim_Estudiantes/","title":"dim_Estudiantes","text":"<p>Este script realiza las siguientes acciones:</p> <ol> <li> <p>Carga y concatena los archivos:</p> <ul> <li><code>procesado_cede_Listado_Matriculas.xlsx</code> ubicado en <code>02.Archivos/02.Cedesarrollo/01/03.Listado_Matriculas</code>.</li> <li><code>procesado_emp_Listado_Matriculas.xlsx</code> ubicado en <code>02.Archivos/02.Cedesarrollo/02/03.Listado_Matriculas</code>.</li> </ul> </li> <li> <p>Selecciona ciertas columnas espec\u00edficas de los archivos concatenados </p> <ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO_ESTUDIANTE</code></li> <li><code>NOMBRE_ESTUDIANTE</code></li> </ul> </li> <li> <p>Guarda el resultado como <code>dim_Estudiantes.xlsx</code> en el directorio <code>02.Archivos/02.Cedesarrollo</code>.</p> </li> </ol> <p>El directorio de destino se construye din\u00e1micamente utilizando <code>os.path.join</code> y <code>os.path.abspath</code> para asegurar que la ruta sea correcta y compatible con el sistema operativo. Si el directorio no existe, el script lo crea antes de guardar el archivo <code>dim_Estudiantes.xlsx</code>.</p>"},{"location":"00.etl/Utils/dim_Estudiantes/#resumen-del-script","title":"Resumen del Script","text":"<ol> <li> <p>Importaci\u00f3n de M\u00f3dulos:</p> <ul> <li><code>os</code>: Para manejar rutas y directorios.</li> <li><code>pandas</code>: Para manipulaci\u00f3n y procesamiento de datos.</li> </ul> </li> <li> <p>Funci\u00f3n <code>genera</code>:</p> <ul> <li>Verifica si un archivo existe en una ruta espec\u00edfica.</li> <li>Lee un archivo Excel utilizando <code>pandas.read_excel</code>.</li> </ul> </li> <li> <p>Construcci\u00f3n de Directorios:</p> <ul> <li>Usa <code>os.path.join</code> para crear rutas relativas para archivos y carpetas.</li> </ul> </li> <li> <p>Concatenaci\u00f3n de Archivos:</p> <ul> <li>Concatena dos DataFrames obtenidos de los archivos Excel especificados.</li> <li>Filtra las columnas <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO_ESTUDIANTE</code>, y <code>NOMBRE_ESTUDIANTE</code>.</li> </ul> </li> <li> <p>Exportaci\u00f3n del Resultado:</p> <ul> <li>Guarda el DataFrame resultante como un archivo Excel en el directorio especificado.</li> <li>Crea el directorio si no existe.</li> </ul> </li> </ol> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo, value):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede,2)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"02\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'procesado_emp_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp,3)\n</code></pre> <pre><code>#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n# Variable cargada \"df\" del estado del Kernel\n</code></pre> <pre><code># Keep only TIPO_DOCUMENTO and DOCUMENTO columns\ndf = df[['TIPO_DOCUMENTO', 'DOCUMENTO_ESTUDIANTE','NOMBRE_ESTUDIANTE']]\nroot_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'dim_Estudiantes.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/dim_periodo_academico/","title":"dim_periodo_academico","text":"<p>Este script procesa dos archivos de excel <code>procesado_cede_Listado_Matriculas</code> y <code>procesado_emp_Listado_Matriculas</code>, genera un DataFrame con informaci\u00f3n de periodos acad\u00e9micos y lo guarda en <code>dim_periodo_academico.xlsx</code>. A continuaci\u00f3n, se desgloza las secciones m\u00e1s importantes del c\u00f3digo:</p>"},{"location":"00.etl/Utils/dim_periodo_academico/#flujo-del-script","title":"Flujo del Script","text":"<ol> <li> <p>Importaci\u00f3n de M\u00f3dulos:</p> <ul> <li><code>os</code>: Para manejar rutas de directorios.</li> <li><code>pandas</code>: Para procesar datos.</li> </ul> </li> <li> <p>Funci\u00f3n <code>genera</code>:</p> <ul> <li>Lee un archivo Excel desde una ruta especificada.</li> <li>Extrae y procesa el a\u00f1o desde la columna <code>FECHA_MATRICULA</code>.</li> <li>Duplica las filas para generar los semestres acad\u00e9micos (<code>-1</code> y <code>-2</code>).</li> <li>A\u00f1ade una columna <code>ID_UNIDAD</code> con el valor recibido como par\u00e1metro.</li> </ul> <p>Comentarios:     - Utiliza pandas para transformar fechas y manejar valores \u00fanicos.     - Crea semestres autom\u00e1ticamente con l\u00f3gica de repetici\u00f3n y sufijos.</p> </li> <li> <p>Procesamiento de Archivos:</p> <ul> <li>Carga dos archivos de Excel (<code>procesado_cede_Listado_Matriculas.xlsx</code> y <code>procesado_emp_Listado_Matriculas.xlsx</code>).</li> <li>Concatena ambos DataFrames en uno solo.</li> </ul> </li> <li> <p>C\u00e1lculo de Fechas de Inicio y Fin:</p> <ul> <li>Divide la columna <code>PERIODO</code> en <code>YEAR</code> y <code>PERIOD</code>.</li> <li>Genera <code>FECHA_INICIO</code> y <code>FECHA_FIN</code> para cada semestre:<ul> <li><code>FECHA_INICIO</code>: Calcula el primer d\u00eda del semestre.</li> <li><code>FECHA_FIN</code>: Calcula el \u00faltimo d\u00eda del semestre.</li> </ul> </li> </ul> <p>L\u00f3gica:</p> <ul> <li><code>PERIOD</code> se usa para determinar el semestre: <code>-1</code> (Enero-Junio) y <code>-2</code> (Julio-Diciembre).</li> <li>Usa <code>DateOffset</code> para sumar meses y restar d\u00edas.</li> </ul> </li> <li> <p>Exportaci\u00f3n del Resultado:</p> <ul> <li>Crea un directorio de destino si no existe.</li> <li>Guarda el DataFrame resultante en un archivo Excel llamado <code>dim_periodo_academico.xlsx</code>.</li> </ul> </li> </ol> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo, value):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    # Imprimir los nombres de las columnas\n    df = df[['FECHA_MATRICULA']]\n    # Extraer el a\u00f1o de la columna FECHA_MATRICULA\n    df['PERIODO'] = df['FECHA_MATRICULA'].dt.year\n    # Eliminar columna: 'FECHA_MATRICULA'\n    df = df.drop(columns=['FECHA_MATRICULA'])\n\n    # Dejar solo los valores \u00fanicos en df\n    df = df.drop_duplicates()\n\n    # Crear dos valores por cada valor en PERIODO\n    df = df.loc[df.index.repeat(2)].reset_index(drop=True)\n\n\n    # Add \"-1\" and \"-2\" to each PERIODO value in the same column\n    df['PERIODO'] = df['PERIODO'].astype(str) + [\"-1\", \"-2\"] * (len(df) // 2)\n\n    # Add column ID_UNIDAD with value \n    df['ID_UNIDAD'] = value\n\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede,2)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"02\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'procesado_emp_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp,3)\n</code></pre> <pre><code>#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n</code></pre> <pre><code># Convert PERIODO to datetime range\ndf[['YEAR', 'PERIOD']] = df['PERIODO'].str.split('-', expand=True)\ndf['YEAR'] = df['YEAR'].astype(int)\ndf['PERIOD'] = df['PERIOD'].astype(int)\n# Define start and end dates\ndf['FECHA_INICIO'] = pd.to_datetime(df['YEAR'].astype(str) + '-' + ((df['PERIOD'] - 1) * 6 + 1).astype(str) + '-01')\ndf['FECHA_FIN'] = df['FECHA_INICIO'] + pd.DateOffset(months=6) - pd.DateOffset(days=1)\n# Drop temporary columns\ndf.drop(columns=['YEAR', 'PERIOD'], inplace=True)\n</code></pre> <pre><code>root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'dim_periodo_academico.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\nexit(0)\n</code></pre>"},{"location":"00.etl/Utils/download/","title":"Download.py","text":""},{"location":"00.etl/Utils/download/#manual-de-usuario-y-documentacion-del-script-etl","title":"Manual de Usuario y Documentaci\u00f3n del Script ETL","text":"<p>Esta documentaci\u00f3n explica el funcionamiento del script que descarga y procesa archivos desde SharePoint.</p>"},{"location":"00.etl/Utils/download/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El script realiza las siguientes acciones:</p> <ul> <li>Configura el entorno y cambia el directorio de trabajo.</li> <li>Lee las credenciales de autenticaci\u00f3n y configura MSAL para obtener un token.</li> <li>Define los headers para las solicitudes a SharePoint.</li> <li>Configura el logging para el registro de eventos.</li> <li>Define funciones para:<ul> <li>Eliminar marcas de fecha de los nombres de archivo.</li> <li>Descargar archivos desde SharePoint.</li> <li>Extraer la fecha de modificaci\u00f3n de los nombres de archivo.</li> <li>Filtrar archivos recientes (\u00faltimos 6 meses).</li> <li>Concatenar y procesar los datos descargados (CSV y Excel).</li> </ul> </li> <li>Define diccionarios que mapean claves a rutas y nombres de archivo.</li> <li>Orquesta el proceso ETL a trav\u00e9s del bloque principal, que configura argumentos y ejecuta la descarga y procesamiento.</li> </ul>"},{"location":"00.etl/Utils/download/#detalle-de-funciones-principales","title":"Detalle de funciones principales","text":"<ul> <li> <p>remove_datetime_from_filename(file_name):   Elimina la marca de fecha y hora del nombre del archivo mediante una expresi\u00f3n regular.</p> </li> <li> <p>download_file_from_sharepoint(file_name, folder_url, download_path):   Descarga el archivo indicado desde SharePoint, creando directorios y renombrando el archivo sin la marca de fecha.</p> </li> <li> <p>extract_datetime_from_filename(filename):   Extrae la fecha y hora del nombre del archivo para identificar la versi\u00f3n m\u00e1s reciente.</p> </li> <li> <p>find_most_recent_file(files, key):   Filtra la lista de archivos para retornar aquellos modificados en los \u00faltimos 6 meses.</p> </li> <li> <p>download_content_from_sharepoint(file_name, folder_url):   Descarga y retorna el contenido de un archivo desde SharePoint, validando la respuesta.</p> </li> <li> <p>download_all_files_from_sharepoint(folder_url, download_directory, key):   Coordinaci\u00f3n del proceso ETL:</p> <ul> <li>Consulta la API de SharePoint para obtener archivos.</li> <li>Filtra archivos relevantes usando el modelo de nombre.</li> <li>Descarga y procesa el contenido (CSV o Excel).</li> <li>Realiza la concatenaci\u00f3n y eliminaci\u00f3n de duplicados en el DataFrame.</li> <li>Guarda el DataFrame consolidado en el directorio destino.</li> </ul> </li> </ul>"},{"location":"00.etl/Utils/download/#instrucciones-de-uso","title":"Instrucciones de uso","text":"<p>Para ejecutar el script desde la l\u00ednea de comandos: <pre><code>python download.py --key &lt;clave&gt; --pausa &lt;True/False&gt;\n</code></pre> - Utiliza la opci\u00f3n --key para indicar la clave del diccionario correspondiente a la carpeta de SharePoint. - La opci\u00f3n --pausa indica si se debe pausar la ejecuci\u00f3n al finalizar.</p> <pre><code>import json&lt;br&gt;\nimport argparse\nimport io\nimport logging\nimport os\nimport re\nimport requests\nimport time\nfrom datetime import datetime\nimport pandas as pd\nfrom msal import ConfidentialClientApplication\n</code></pre> <pre><code>from Funciones import (\n    log_step_decorator, csv_files\n)\n</code></pre>"},{"location":"00.etl/Utils/download/#configuracion-del-directorio-de-trabajo","title":"Configuraci\u00f3n del Directorio de Trabajo","text":"<p>El siguiente c\u00f3digo establece el directorio de trabajo al directorio donde se encuentra el script actual. Esto es importante para asegurar que todas las rutas relativas utilizadas en el script funcionen correctamente, independientemente de desde d\u00f3nde se ejecute el script.</p> <p>La funci\u00f3n <code>os.path.abspath(__file__)</code> devuelve la ruta completa al archivo actual, y <code>os.path.dirname()</code> extrae el directorio que contiene ese archivo. Luego, <code>os.chdir()</code> cambia el directorio de trabajo actual a esa ubicaci\u00f3n.</p> <pre><code>script_dir = os.path.dirname(os.path.abspath(__file__))\nos.chdir(script_dir)\n</code></pre>"},{"location":"00.etl/Utils/download/#configuracion-del-directorio-de-trabajo_1","title":"Configuraci\u00f3n del Directorio de Trabajo","text":"<p>El siguiente c\u00f3digo establece el directorio de trabajo al directorio donde se encuentra el script actual. Esto es importante para asegurar que todas las rutas relativas utilizadas en el script funcionen correctamente, independientemente de desde d\u00f3nde se ejecute el script.</p> <p>La funci\u00f3n <code>os.path.abspath(__file__)</code> devuelve la ruta completa al archivo actual, y <code>os.path.dirname()</code> extrae el directorio que contiene ese archivo. Luego, <code>os.chdir()</code> cambia el directorio de trabajo actual a esa ubicaci\u00f3n.</p>"},{"location":"00.etl/Utils/download/#lectura-de-credenciales","title":"Lectura de Credenciales","text":"<p>El siguiente c\u00f3digo lee las credenciales necesarias para la autenticaci\u00f3n con Microsoft SharePoint. Estas credenciales se almacenan en un archivo de texto llamado 'credenciales.env' para mantener la seguridad y facilitar la gesti\u00f3n de configuraci\u00f3n.</p> <p>El archivo de credenciales contiene informaci\u00f3n importante como:</p> <ul> <li>Client ID: Identificador \u00fanico de la aplicaci\u00f3n registrada en Azure AD</li> <li>Certificate Thumbprint: Huella digital del certificado utilizado para autenticar</li> <li>Tenant ID: Identificador \u00fanico del directorio de Azure AD</li> <li>Otros par\u00e1metros de configuraci\u00f3n como URLs y scopes</li> </ul> <p>Este enfoque permite separar la configuraci\u00f3n sensible del c\u00f3digo, mejorando la seguridad y facilitando los despliegues en diferentes entornos sin necesidad de modificar el c\u00f3digo fuente.</p> <pre><code>with open('credenciales.env', 'r') as key_file:\n    lines = key_file.readlines()\nkeys = {}\nfor line in lines:\n    key, value = line.strip().split(\" = \")\n    keys[key] = value.strip('\"')\nclient_id = keys.get(\"client_id\")\ncert_thumbprint = keys.get(\"cert_thumbprint\")\ntenant_id = keys.get(\"tenant_id\")\nauthority = f\"https://login.microsoftonline.com/{tenant_id}\"\n</code></pre>"},{"location":"00.etl/Utils/download/#lectura-de-clave-privada","title":"Lectura de Clave Privada","text":"<p>El siguiente c\u00f3digo lee la clave privada almacenada en el archivo 'key.pem'. Esta clave es parte esencial del proceso de autenticaci\u00f3n basado en certificados con Microsoft SharePoint.</p> <p>La clave privada, junto con el thumbprint del certificado previamente cargado, se utiliza para crear las credenciales necesarias para que la aplicaci\u00f3n MSAL (Microsoft Authentication Library) obtenga un token de acceso. Este enfoque de autenticaci\u00f3n con certificado es m\u00e1s seguro que usar contrase\u00f1as y es recomendado para aplicaciones en entornos de producci\u00f3n.</p> <p>Una vez que se carga la clave privada, se configura la aplicaci\u00f3n MSAL y se solicita un token de acceso que ser\u00e1 utilizado en las cabeceras (headers) de todas las solicitudes HTTP posteriores a SharePoint.</p> <pre><code>with open('key.pem', 'r') as key_file:\n    private_key = key_file.read()\ncert = {\n    \"private_key\": private_key,\n    \"thumbprint\": cert_thumbprint,\n}\nmsal_app = ConfidentialClientApplication(\n    client_id=client_id,\n    authority=authority,\n    client_credential=cert,\n)\nscopes_sharepoint_online = [keys.get(\"scopes_sharepoint_online\")]\nresults = msal_app.acquire_token_for_client(scopes_sharepoint_online)\nif \"access_token\" in results:\n    access_token = results.get(\"access_token\")\nheaders = {\n    \"Authorization\": f\"Bearer {access_token}\",\n    \"Accept\": \"application/json;odata=verbose\",\n    \"Content-Type\": \"application/json\",\n}\nsharepoint_base_url = keys.get(\"sharepoint_base_url\")\n</code></pre>"},{"location":"00.etl/Utils/download/#configuracion-de-logging","title":"Configuraci\u00f3n de Logging","text":"<p>El siguiente c\u00f3digo configura el sistema de logging para registrar informaci\u00f3n durante la ejecuci\u00f3n del script. El logging es esencial para monitorear el proceso ETL, identificar problemas y depurar errores.</p> <pre><code># Configuraci\u00f3n del logger principal\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Configuraci\u00f3n del formato de los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Configuraci\u00f3n para guardar logs en archivo\nfile_handler = logging.FileHandler(\"scraper_SSIS.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n\n# Configuraci\u00f3n para mostrar logs en consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n# Suprimir advertencias que puedan distraer durante la ejecuci\u00f3n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n</code></pre> <p>El sistema de logging est\u00e1 configurado para:</p> <ul> <li>Guardar registros en archivo: Los registros se almacenan en \"scraper_SSIS.log\"</li> <li>Mostrar mensajes en consola: Proporciona retroalimentaci\u00f3n en tiempo real</li> <li>Formato de tiempo: Cada mensaje incluye fecha/hora, nivel de severidad y contenido</li> <li>Niveles de detalle: Configurado en INFO para capturar informaci\u00f3n operativa importante</li> </ul> <p>Adicionalmente, se ajustan los niveles de registro para otros loggers que pudieran estar activos:</p> <pre><code># Ajustar nivel de logging para otros loggers\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre> <p>Este enfoque de logging proporciona visibilidad completa del proceso ETL, facilitando la identificaci\u00f3n de posibles problemas o errores durante la ejecuci\u00f3n del script.</p>"},{"location":"00.etl/Utils/download/#remove_datetime_from_filename","title":"remove_datetime_from_filename","text":"<pre><code>def remove_datetime_from_filename(file_name):\n    \"\"\"\n    Elimina la marca de fecha y hora del nombre del archivo.\n    \"\"\"\n    # Usa una expresi\u00f3n regular para eliminar la fecha y hora en formato DD_MM_YYYY_HH_MM\n    return re.sub(r'_\\d{2}_\\d{2}_\\d{4}_\\d{2}_\\d{2}', '', file_name)\n</code></pre> <p>La funci\u00f3n <code>remove_datetime_from_filename()</code> elimina las marcas de fecha y hora de los nombres de archivo. Utiliza una expresi\u00f3n regular para identificar y remover patrones con formato <code>DD_MM_YYYY_HH_MM</code> (d\u00eda_mes_a\u00f1o_hora_minuto) que suelen a\u00f1adirse a los nombres de archivos para versionar documentos.</p> <p>Esta funci\u00f3n es especialmente \u00fatil durante el proceso ETL para normalizar los nombres de los archivos descargados, permitiendo una identificaci\u00f3n y procesamiento consistente independientemente de cu\u00e1ndo fueron generados los archivos.</p>"},{"location":"00.etl/Utils/download/#download_file_from_sharepoint","title":"download_file_from_sharepoint","text":"<p>La funci\u00f3n <code>download_file_from_sharepoint()</code> descarga archivos individuales desde SharePoint y los guarda en el sistema de archivos local. Esta funci\u00f3n:</p> <ol> <li>Crea directorios necesarios: Verifica si la ruta de destino existe y la crea si es necesaria</li> <li>Construye la URL de descarga: Genera la URL completa para acceder al archivo en SharePoint</li> <li>Realiza la petici\u00f3n: Obtiene el contenido del archivo mediante una solicitud HTTP</li> <li>Normaliza el nombre: Elimina las marcas de fecha/hora del nombre del archivo usando <code>remove_datetime_from_filename()</code></li> <li>Guarda el archivo: Escribe el contenido descargado en el sistema de archivos local</li> </ol> <p>Esta funci\u00f3n es esencial para el proceso ETL, permitiendo obtener datos actualizados desde SharePoint para su posterior procesamiento. Maneja tanto la autenticaci\u00f3n como la gesti\u00f3n de errores para garantizar descargas confiables.</p> <pre><code>@log_step_decorator(\"Descargar archivo de SharePoint\")\ndef download_file_from_sharepoint(file_name, folder_url, download_path):\n    \"\"\"\n    Descarga un archivo espec\u00edfico desde SharePoint y lo guarda localmente.\n\n    Args:\n        file_name: Nombre del archivo en SharePoint\n        folder_url: URL relativa de la carpeta en SharePoint\n        download_path: Ruta local donde se guardar\u00e1 el archivo\n    \"\"\"\n    # Crear las carpetas si no existen\n    if not os.path.exists(os.path.dirname(download_path)):\n        os.makedirs(os.path.dirname(download_path))\n        logging.info(f\"Carpeta creada: {os.path.dirname(download_path)}\")\n\n    # Ruta completa del archivo en SharePoint\n    logging.info(f\"Ruta completa del archivo a descargar: {download_path}\")\n    download_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n    response = requests.get(download_url, headers=headers)\n    if response.status_code == 200:\n        # Eliminar la marca de fecha y hora del nombre del archivo\n        clean_file_name = remove_datetime_from_filename(file_name)\n        clean_download_path = os.path.join(os.path.dirname(download_path), clean_file_name)\n\n        # Guardar el archivo descargado con el nuevo nombre\n        with open(clean_download_path, \"wb\") as file:\n            file.write(response.content)\n        logging.info(f\"Archivo descargado exitosamente como: {clean_file_name}\")\n    else:\n        logging.info(f\"Error al descargar el archivo. C\u00f3digo de estado: {response.status_code}\")\n        logging.info(f\"Error: {response.text}\")\n</code></pre>"},{"location":"00.etl/Utils/download/#funciones-de-manejo-de-archivo","title":"Funciones de Manejo de Archivo","text":""},{"location":"00.etl/Utils/download/#extract_datetime_from_filename","title":"extract_datetime_from_filename","text":"<pre><code>def extract_datetime_from_filename(filename):\n    \"\"\"\n    Extrae la fecha y hora del nombre del archivo en formato DD_MM_YYYY_HH_MM.\n    \"\"\"\n    match = re.search(r'(\\d{2}_\\d{2}_\\d{4}_\\d{2}_\\d{2})', filename)\n    if match:\n        return datetime.strptime(match.group(1), '%d_%m_%Y_%H_%M')\n    match = re.search(r'(\\d{2}_\\d{2}_\\d{4})', filename)\n    if match:\n        return datetime.strptime(match.group(1), '%d_%m_%Y')    \n    return None\n</code></pre> <p>La funci\u00f3n <code>extract_datetime_from_filename()</code> extrae informaci\u00f3n de fecha y hora de los nombres de archivo. Esta funci\u00f3n:</p> <ol> <li>Busca patrones de fecha/hora usando expresiones regulares</li> <li>Primero intenta encontrar el formato completo DD_MM_YYYY_HH_MM (d\u00eda_mes_a\u00f1o_hora_minuto)</li> <li>Si no encuentra ese formato, busca un formato m\u00e1s simple DD_MM_YYYY (d\u00eda_mes_a\u00f1o)</li> <li>Convierte la cadena encontrada en un objeto datetime para facilitar operaciones de comparaci\u00f3n</li> <li>Si no encuentra ning\u00fan formato de fecha v\u00e1lido, retorna None</li> </ol> <p>Esta funci\u00f3n es crucial para identificar la versi\u00f3n m\u00e1s reciente de archivos que incluyen marcas de tiempo en sus nombres, permitiendo al proceso ETL trabajar siempre con los datos m\u00e1s actualizados.</p>"},{"location":"00.etl/Utils/download/#find_most_recent_file","title":"find_most_recent_file","text":"<pre><code>@log_step_decorator(\"Filtrar archivos recientes\")\ndef find_most_recent_file(files, key):\n    \"\"\"\n    Encuentra el archivo m\u00e1s reciente en la lista de archivos bas\u00e1ndose en la fecha y hora en el nombre.\n    \"\"\"\n    most_recent_file = None\n    most_recent_datetime = None\n\n    # Itera sobre la lista de archivos\n    archivos_validos = []\n    for file in files:\n        # Obtiene el nombre del archivo\n        file_name = file.get('Name')\n\n        logging.info(f\"Archivo: {file_name}\")\n\n        # Extrae la fecha y hora del nombre del archivo\n        file_datetime = extract_datetime_from_filename(file_name)\n        # Si se pudo extraer la fecha y hora del nombre del archivo\n        if file_datetime:\n            # Si no hay una fecha y hora m\u00e1s reciente almacenada o si la fecha y hora actual es m\u00e1s reciente\n            if most_recent_datetime is None or file_datetime &gt; most_recent_datetime:\n                # Verifica si la fecha y hora est\u00e1 dentro de los \u00faltimos 6 meses\n                if (datetime.now() - file_datetime).days &lt;= 180:\n                    # Agrega el archivo a la lista de archivos v\u00e1lidos\n                    archivos_validos.append(file_name)\n        else:\n            archivos_validos.append(file_name)\n    # Registra los archivos v\u00e1lidos encontrados\n    logging.info(f\"Archivos v\u00e1lidos: {archivos_validos}\")\n    return archivos_validos\n</code></pre> <p>La funci\u00f3n <code>find_most_recent_file()</code> filtra una lista de archivos de SharePoint para identificar aquellos que son relevantes para el proceso ETL. Esta funci\u00f3n:</p> <ol> <li>Itera a trav\u00e9s de una lista de archivos obtenidos de SharePoint</li> <li>Para cada archivo, intenta extraer la informaci\u00f3n de fecha/hora del nombre utilizando <code>extract_datetime_from_filename()</code></li> <li>Si el archivo tiene una marca de tiempo v\u00e1lida:</li> <li>Verifica que la fecha est\u00e9 dentro de los \u00faltimos 6 meses</li> <li>Si cumple con este criterio, lo agrega a la lista de archivos v\u00e1lidos</li> <li>Si el archivo no tiene una marca de tiempo reconocible, lo incluye directamente en la lista de archivos v\u00e1lidos</li> <li>Retorna la lista completa de archivos v\u00e1lidos para su posterior procesamiento</li> </ol> <p>Esta funci\u00f3n implementa una pol\u00edtica de retenci\u00f3n de datos, asegurando que solo los archivos suficientemente recientes (menos de 6 meses de antig\u00fcedad) sean considerados para el proceso ETL, evitando as\u00ed el procesamiento de datos obsoletos.</p>"},{"location":"00.etl/Utils/download/#archivos-sharepoint","title":"Archivos Sharepoint","text":""},{"location":"00.etl/Utils/download/#download_content_from_sharepoint","title":"<code>download_content_from_sharepoint</code>","text":"<p>Esta funci\u00f3n  es responsable de recuperar archivos almacenados en SharePoint utilizando la API REST de Microsoft. La funci\u00f3n est\u00e1 decorada con <code>log_step_decorator</code>, lo que proporciona capacidades autom\u00e1ticas de registro para monitorear el proceso de descarga.</p> <p>El c\u00f3digo construye una URL espec\u00edfica de la API combinando una URL base de SharePoint con la ruta de la carpeta y el nombre del archivo solicitado. Esta construcci\u00f3n sigue el patr\u00f3n est\u00e1ndar de la API REST de SharePoint para obtener el contenido de un archivo (<code>/$value</code>). La funci\u00f3n realiza una solicitud HTTP GET a esta URL, incluyendo los encabezados de autenticaci\u00f3n necesarios.</p> <p>El manejo de respuestas implementa verificaciones b\u00e1sicas de errores: cuando la descarga es exitosa (c\u00f3digo de estado 200), la funci\u00f3n devuelve el contenido binario del archivo. En caso de error, registra tanto el c\u00f3digo de estado como el mensaje de error completo para facilitar la depuraci\u00f3n, y devuelve <code>None</code> para que el c\u00f3digo que la invoca pueda implementar l\u00f3gica de manejo de errores adecuada.</p> <p>Este enfoque es particularmente \u00fatil para integraciones automatizadas que necesitan acceder a documentos almacenados en SharePoint como parte de flujos de trabajo o procesos ETL.</p> <pre><code>@log_step_decorator(\"Descargar contenido de SharePoint\")\ndef download_content_from_sharepoint(file_name, folder_url):\n    download_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n    response = requests.get(download_url, headers=headers)\n    if response.status_code == 200:\n        logging.info(f\"Archivo {file_name} descargado exitosamente.\")\n        return response.content\n    else:\n        logging.info(f\"Error al descargar el archivo. C\u00c3\u00b3digo de estado: {response.status_code}\")\n        logging.info(f\"Error: {response.text}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/download/#download_all_files_from_sharepoint","title":"<code>download_all_files_from_sharepoint</code>","text":"<p>Este c\u00f3digo automatiza la descarga de archivos desde SharePoint, los procesa y los combina en un \u00fanico archivo de salida. </p> <p>La funci\u00f3n primero construye una URL para acceder a los archivos de una carpeta espec\u00edfica en SharePoint utilizando la API REST. Realiza una solicitud HTTP GET para obtener la lista de archivos disponibles, registrando el proceso mediante logging. Si la solicitud es exitosa (c\u00f3digo 200), extrae la informaci\u00f3n de los archivos del JSON de respuesta.</p> <p>Dependiendo del par\u00e1metro <code>key</code> proporcionado, la funci\u00f3n determina si debe trabajar con archivos CSV o Excel. Luego busca en un diccionario el nombre del archivo modelo correspondiente a esa clave, y filtra la lista de archivos para incluir solo aquellos que coincidan con ese modelo.</p> <p>La funci\u00f3n <code>find_most_recent_file</code> (que no se muestra en el c\u00f3digo proporcionado) se utiliza para identificar los archivos m\u00e1s recientes. Para cada archivo seleccionado, descarga su contenido, lo convierte en un DataFrame de pandas seg\u00fan su formato (Excel o CSV), y concatena todos los DataFrames en uno solo, eliminando duplicados.</p> <p>El c\u00f3digo incluye tambi\u00e9n un procesamiento espec\u00edfico para las columnas \"DOCUMENTO_ESTUDIANTE\" y \"DOCUMENTO\", convirti\u00e9ndolas a formato num\u00e9rico entero cuando est\u00e1n presentes.</p> <p>Finalmente, la funci\u00f3n crea el directorio de destino si no existe y guarda el DataFrame combinado como un archivo CSV o Excel en la ubicaci\u00f3n especificada. Si ocurre alg\u00fan error durante el proceso, registra los detalles para facilitar la depuraci\u00f3n.</p> <p>Esta utilidad es especialmente valiosa para automatizar la recopilaci\u00f3n y consolidaci\u00f3n de datos distribuidos en m\u00faltiples archivos en SharePoint, manteniendo un registro detallado de cada paso del proceso.</p> <pre><code>def download_all_files_from_sharepoint(folder_url, download_directory, key):\n    # Construye la URL para acceder a los archivos de una carpeta espec\u00edfica en SharePoint\n    folder_api_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n\n    # Realiza una solicitud GET a la URL de la API de SharePoint para obtener los archivos de la carpeta\n    response = requests.get(folder_api_url, headers=headers)\n    # Imprime la URL a la que se est\u00e1 conectando\n    logging.info(f\"Conectando a {folder_api_url}\")\n    # Imprime el estado de la respuesta de la solicitud\n    logging.info(f\"Estado de la respuesta: {response.status_code}\")\n\n    if response.status_code == 200:\n        # Extrae la lista de archivos de la respuesta JSON de la solicitud GET\n        files = response.json().get('d', {}).get('results', [])\n        logging.info(f\"Se encontraron {len(files)} archivos en la carpeta especificada.\")        \n        if not files:\n            logging.info(\"No se encontraron archivos en la carpeta especificada.\")\n            return\n\n        if key in csv_files:\n            extension = \"csv\"\n        else:\n            extension = \"xlsx\"\n\n        # Obtiene el nombre del archivo sin la extensi\u00f3n\n        archivo = diccionarios.get(key)\n        if archivo:\n            archivo_modelo = os.path.splitext(archivo)[0]\n            # filtra todos los archivos que inicien con archivo_modelo sin extencion y los guarda en una lista \n            files = [file for file in files if file.get('Name').startswith(archivo_modelo)]    \n            logging.info(f\"Se encontraron {len(files)} archivos que coinciden con el modelo de archivo: {archivo_modelo}\")\n        else:\n            logging.info(f\"Se encontraron {len(files)} archivos\")\n            archivo = f\"procesado_{key}.{extension}\"\n\n\n        most_recent_files = find_most_recent_file(files, key)\n        if not most_recent_files:\n            logging.info(f\"No se encontr\u00f3 ning\u00fan archivo v\u00e1lido.\")\n            return\n        all_df = pd.DataFrame()\n        for most_recent_file in most_recent_files:\n            if isinstance(most_recent_file, str):\n                file_name = most_recent_file\n            else:\n                file_name = most_recent_file.get('Name')\n\n            file_content = download_content_from_sharepoint(file_name, folder_url)\n            logging.info(f\"Descargando archivo: {file_name}\")\n            if file_content:\n                if file_name.endswith('.xlsx'):\n                    df = pd.read_excel(io.BytesIO(file_content))\n                elif file_name.endswith('.csv'):\n                    df = pd.read_csv(io.StringIO(file_content.decode('utf-8')))\n                else:\n                    logging.info(f\"Formato de archivo no soportado: {file_name}\")\n                    continue\n                all_df = pd.concat([all_df, df], ignore_index=True)  # Concatena el DataFrame descargado al DataFrame existente\n                all_df = all_df.drop_duplicates() # Eliminar duplicados\n        logging.info(all_df)\n\n        #Si all_df contiene una columna DOCUMENTO_ESTUDIANTE hay que pasarla a entero\n        if \"DOCUMENTO_ESTUDIANTE\" in all_df.columns:\n            all_df['DOCUMENTO_ESTUDIANTE'] = pd.to_numeric(\n                all_df['DOCUMENTO_ESTUDIANTE'].astype(str).str.replace('[^0-9]', '', regex=True),\n                errors='coerce'\n            ).astype('Int64')\n\n        if \"DOCUMENTO\" in all_df.columns:\n            all_df['DOCUMENTO'] = pd.to_numeric(\n                all_df['DOCUMENTO'].astype(str).str.replace('[^0-9]', '', regex=True),\n                errors='coerce'\n            ).astype('Int64')\n\n\n\n        # Verifica si el directorio de descarga existe, si no, lo crea\n        if not os.path.exists(download_directory):\n            os.makedirs(download_directory)\n\n        #guarda all_df en un archivo excel\n        logging.info(f\"Guardando archivo en {download_directory}\")\n        if extension == \"csv\":\n            all_df.to_csv(os.path.join(download_directory, archivo), index=False, encoding='utf-8-sig')\n        else:\n            all_df.to_excel(os.path.join(download_directory, archivo), index=False)\n    else:\n        logging.info(f\"Error al obtener la lista de archivos. C\u00f3digo de estado: {response.status_code}\")\n        logging.info(f\"Contenido del error: {response.text}\")\n</code></pre>"},{"location":"00.etl/Utils/download/#diccionarios-y-main","title":"Diccionarios y Main()","text":"<p>Este c\u00f3digo implementa un sistema para la descarga automatizada de archivos desde SharePoint hacia ubicaciones locales espec\u00edficas. La estructura principal se basa en diccionarios que mapean identificadores a rutas y archivos.</p>"},{"location":"00.etl/Utils/download/#estructura-de-datos","title":"Estructura de datos","text":"<p>El c\u00f3digo define varios diccionarios clave: - <code>manuales</code> y <code>sin_fecha</code>: Mapean c\u00f3digos (como \"EPEPT06\") a nombres de archivos Excel espec\u00edficos - <code>etl_to_folder_url</code>: Contiene las rutas de origen en SharePoint para cada tipo de archivo - <code>etl_destino</code>: Especifica las rutas de destino local donde se guardar\u00e1n los archivos</p> <p>Los diccionarios auxiliares como <code>archivos_manuales_etl_destino</code> y <code>archivos_manuales_etl_to_folder_url</code> generan mapeos adicionales que luego se integran a los diccionarios principales.</p>"},{"location":"00.etl/Utils/download/#funcionamiento","title":"Funcionamiento","text":"<p>El script utiliza <code>argparse</code> para procesar dos par\u00e1metros principales desde la l\u00ednea de comandos: - <code>--key</code>: Especifica qu\u00e9 conjunto de archivos descargar (usando un identificador de los diccionarios) - <code>--pausa</code>: Determina si el script debe hacer una pausa al finalizar</p> <p>Cuando se ejecuta, el programa: 1. Determina la clave a utilizar (usa \"EPEPT04\" por defecto si no se proporciona) 2. Configura el directorio de destino bas\u00e1ndose en la clave 3. Obtiene la URL de SharePoint correspondiente 4. Ejecuta la descarga de archivos mediante la funci\u00f3n <code>download_all_files_from_sharepoint</code> 5. Registra el proceso utilizando un sistema de logging</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para facilitar la automatizaci\u00f3n de descargas desde diferentes secciones de SharePoint, como datos de educaci\u00f3n t\u00e9cnica, educaci\u00f3n continua y archivos de estructuras propuestas, organiz\u00e1ndolos autom\u00e1ticamente en carpetas locales predefinidas.</p> <pre><code>manuales  = {\n    \"EPEPT06\":\"EP-EPT-06.xlsx\", \n    \"EPEPT04\":\"EP-EPT-04.xlsx\",\n    \"EPEDF02\":\"EP-EDF-02.xlsx\",\n    \"EPEDF04\":\"EP-EDF-04.xlsx\",\n    \"AMDRE05\":\"AM-DRE-05.xlsx\",\n    \"EPEPT07\":\"EP-EPT-07.xlsx\",\n    \"EPEPT08\":\"EP-EPT-08.xlsx\",\n    \"EPEDF09\":\"EP-EDF-09.xlsx\",\n    \"EPEPT11\":\"EP-EPT-11.xlsx\",\n    \"EPEPT09\":\"EP-EPT-09.xlsx\",\n    \"EPEPT10\":\"EP-EPT-10.xlsx\",\n    \"EPEPT12\":\"EP-EPT-12.xlsx\",\n    \"EPEPT05\":\"EP-EPT-05.xlsx\",\n    }\n\n\nsin_fecha = {\n    \"EP-EDF-05\":\"EP-EDF-05.xlsx\",\n    \"EP-EDF-02\":'EP-EDF-02.xlsx',\n    \"EP-EDF-06\":'EP-EDF-06.xlsx',\n    \"EP-EDF-09\":'EP-EDF-09.xlsx',\n    \"EP-EDF-01\":'EP-EDF-01.xlsx',\n    \"EP-EDF-10\":'EP-EDF-10.xlsx',\n    \"EP-EDF-04\":'EP-EDF-04.xlsx',\n    \"EP-EDF-11\":'EP-EDF-11.xlsx',\n    \"EP-EDF-03\":'EP-EDF-03.xlsx',\n    \"EP-EDF-12\":'EP-EDF-12.xlsx',\n    \"EP-EDF-08\":'EP-EDF-08.xlsx',\n    \"EP-EDF-07\":'EP-EDF-07.xlsx',\n    }\n\n#une los diccionarios\ndiccionarios = {**manuales, **sin_fecha}\n\n# Generar el nuevo diccionario\narchivos_manuales_etl_destino = {clave: '02.Archivos/02.Cedesarrollo/' for clave in manuales.keys()}\narchivos_manuales_etl_to_folder_url = {clave: 'Documentos compartidos/03.Archivos_Manuales/03.Otros_Archivos' for clave in manuales.keys()}\n\n\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/06.Egresados_Graduados',\n    \"EP-EDF-01\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/06.FACT_ENFERMERIA',\n    \"EP-EDF-02\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/02.FACT_AUSENTISMO_DOCENTE',\n    \"EP-EDF-03\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/10.FACT_REEMPLAZO_DOCENTE',\n    \"EP-EDF-04\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/08.FACT_PERMISO_ESTUDIANTE',\n    \"EP-EDF-05\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/03.FACT_BIBLIOTECA',\n    \"EP-EDF-06\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/04.FACT_BIBLIOTECA_VIRTUAL',\n    \"EP-EDF-07\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/13.FACT_SABER11_INDIVIDUAL',\n    \"EP-EDF-08\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/12.FACT_SABER11_COLEGIOS',\n    \"EP-EDF-09\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/05.FACT_DESEMPENHO_DOCENTE',\n    \"EP-EDF-10\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/07.FACT_LEGALIZACION',\n    \"EP-EDF-11\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/09.FACT_PSIORIENTACION', \n    \"EP-EDF-12\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/11.FACT_RESERVA_ESPACIOS',\n    \"EP-EDF-13\":'Documentos compartidos/03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/14.FACT_SERVICIO_SOCIAL',\n    \"C4C\":'Documentos compartidos/02.C4C',\n    }\n\netl_destino = {\n    \"cede_Docentes\":'02.Archivos/02.Cedesarrollo/01/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'02.Archivos/02.Cedesarrollo/01/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'02.Archivos/02.Cedesarrollo/01/03.Listado_Matriculas',\n    \"cede_Ingresos\":'02.Archivos/02.Cedesarrollo/01/04.Ingresos',\n    \"cede_Historico_Notas\":'02.Archivos/02.Cedesarrollo/01/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'02.Archivos/02.Cedesarrollo/01/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'02.Archivos/02.Cedesarrollo/01/07.Cancelados_Desertores',\n    \"emp_Docentes\":'02.Archivos/02.Cedesarrollo/02/01.Docentes',\n    \"emp_Preinscritos\":'02.Archivos/02.Cedesarrollo/02/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'02.Archivos/02.Cedesarrollo/02/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'02.Archivos/02.Cedesarrollo/02/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'02.Archivos/02.Cedesarrollo/02/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'02.Archivos/02.Cedesarrollo/02/06.Egresados_Graduados',\n    \"EP-EDF-01\":'02.Archivos/04.Colegio',\n    \"EP-EDF-02\":'02.Archivos/04.Colegio',\n    \"EP-EDF-03\":'02.Archivos/04.Colegio',\n    \"EP-EDF-04\":'02.Archivos/04.Colegio',\n    \"EP-EDF-05\":'02.Archivos/04.Colegio',\n    \"EP-EDF-06\":'02.Archivos/04.Colegio',\n    \"EP-EDF-07\":'02.Archivos/04.Colegio',\n    \"EP-EDF-08\":'02.Archivos/04.Colegio',\n    \"EP-EDF-09\":'02.Archivos/04.Colegio',\n    \"EP-EDF-10\":'02.Archivos/04.Colegio',\n    \"EP-EDF-11\":'02.Archivos/04.Colegio',\n    \"EP-EDF-12\":'02.Archivos/04.Colegio',\n    \"EP-EDF-13\":'02.Archivos/04.Colegio',\n    \"C4C\"      :'02.Archivos/01.Transversal/PQRs',\n\n    }\n\netl_to_folder_url.update(archivos_manuales_etl_to_folder_url)\netl_destino.update(archivos_manuales_etl_destino)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--key\", type=str, help=\"Clave del diccionario etl_to_folder_url para seleccionar la carpeta en SharePoint.\")\n    parser.add_argument(\"--pausa\", type=bool, default=False, help=\"Segunda clave con valores posibles True o False.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    __key = args.key if args.key else \"EPEPT04\"  # Valor predeterminado\n    _pausa = args.pausa if args.pausa else False\n    logging.info(f'Procesando download.py con la clave: {__key}')\n    # Actualizar root_directory para que etl_destino lo asigne\n    root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n    root_directory = os.path.abspath(os.path.join(root_directory1, etl_destino.get(__key, \"\").replace(\"/\", os.sep)))\n    logging.info(root_directory + \" \\n \" + etl_destino.get(__key, \"\"))\n\n    # Obtener la carpeta desde la clave proporcionada\n    folder_url = etl_to_folder_url.get(__key)\n    if not folder_url:\n        logging.info(f\"Error: La clave '{__key}' no existe en etl_to_folder_url.\")\n        exit(1)\n\n    # Descargar archivos\n    @log_step_decorator(f\"ETL {__key}\")\n    def run_etl():\n        download_all_files_from_sharepoint(folder_url, root_directory, __key)\n\n    run_etl()\n    if _pausa:\n        input(\"Presione Enter para continuar...\")\n</code></pre>"},{"location":"00.etl/Utils/fact_cotizacion/","title":"fact_cotizacion","text":""},{"location":"00.etl/Utils/fact_cotizacion/#fact-cotizacion","title":"FACT COTIZACI\u00d3N","text":""},{"location":"00.etl/Utils/fact_cotizacion/#explicacion-del-codigo-de-procesamiento-de-datos-de-cotizaciones","title":"Explicaci\u00f3n del C\u00f3digo de Procesamiento de Datos de Cotizaciones","text":"<p>Este script de Python realiza un proceso ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para datos relacionados con cotizaciones de servicios del Departamento de Desarrollo Empresarial. </p> <p>El c\u00f3digo comienza importando las bibliotecas necesarias y definiendo funciones auxiliares para normalizar texto y preparar los datos. La funci\u00f3n <code>normalize</code> elimina los acentos de las cadenas de texto, mientras que <code>PreSave</code> realiza m\u00faltiples transformaciones para limpiar y estandarizar los datos en columnas espec\u00edficas, como reemplazar caracteres especiales, convertir texto a may\u00fasculas y eliminar signos de puntuaci\u00f3n.</p> <p>En la parte central, el c\u00f3digo define rutas de directorio para localizar y almacenar archivos. La funci\u00f3n <code>genera</code> lee un archivo Excel espec\u00edfico ('AM-DRE-05.xlsx') y elimina columnas vac\u00edas. La funci\u00f3n <code>transformar_fecha</code> convierte las fechas al formato 'dd/mm/yy'.</p> <p>El flujo principal del programa: 1. Lee el archivo Excel con informaci\u00f3n de cotizaciones 2. Limpia los datos eliminando filas vac\u00edas y duplicados 3. Renombra columnas para estandarizar nombres 4. Elimina columnas innecesarias 5. Transforma los datos de formato amplio a formato largo usando <code>melt</code> 6. Limpia y estandariza el texto en las columnas relevantes 7. Formatea las fechas correctamente 8. Gestiona valores faltantes y trunca campos largos 9. Exporta el resultado final a un archivo Excel llamado 'fact_cotizaciones.xlsx'</p> <p>Este procesamiento permite convertir datos operativos de cotizaciones en un formato m\u00e1s adecuado para an\u00e1lisis o integraci\u00f3n con otros sistemas de informaci\u00f3n.</p> <pre><code>import os\nimport pandas as pd\nimport numpy as np\n# pylint: disable=all\nfrom Funciones import (\n    get_file_content_from_sharepoint\n)\ndef normalize(s):\n    replacements = (\n        (\"\u00e1\", \"a\"),\n        (\"\u00e9\", \"e\"),\n        (\"\u00ed\", \"i\"),\n        (\"\u00f3\", \"o\"),\n        (\"\u00fa\", \"u\"),\n    )\n    for a, b in replacements:\n        s = s.replace(a, b).replace(a.upper(), b.upper())\n    return s\ndef PreSave(df , columnList, signs = False):\n\n    datfra = df.copy()\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xf1', 'ni'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xD1', 'NI'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('\\u00A0', ' '))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('  ', ' '))\n    datfra[columnList] = datfra[columnList].astype(str)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.strip())\n    datfra[columnList] = datfra[columnList].map(normalize)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.upper())\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(',', ' '))\n    datfra[columnList] = datfra[columnList].replace('NAN', np.nan)\n\n    if signs == True:\n        for col in columnList:\n            try:\n                datfra[col] = datfra[col].apply(lambda x: re.sub(r'[\u00a1!?\u00bf]', '', x) )\n            except:\n                print('Not Signs fixed for '+ col)\n\n    return datfra\nfolder_url = \"Documentos compartidos/03.Archivos_Manuales/03.Otros_Archivos\"\n\n\n\ndef genera(root_directory, archivo):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    #elimina las columnas vacias\n    df = df.dropna(axis=1, how='all')\n    return df\n\ndef transformar_fecha(df, columna):\n    # Asegurarse de que la columna es de tipo datetime\n    df[columna] = pd.to_datetime(df[columna])\n\n    # Transformar la columna al formato \"dd/mm/yy\"\n    df[columna] = df[columna].dt.strftime('%d/%m/%y')\n\n    return \n\n\nroot_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n    \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n    )\n)\nprint('--------------------------------------')\nprint(os.getcwd())\n# Nombre del archivo\narchivo_emp = 'AM-DRE-05.xlsx'\n\ndf_emp = genera(root_directory, archivo_emp)\n\n#concatenar los df\ndf = pd.concat([df_emp], ignore_index=True)\ndf = df.dropna(how='all')\n# Eliminar filas que tienen NaN en la columna 'nombre_columna'\ndf = df.dropna(subset=['Fecha de registro'])\n\n#Modificaciones a columnas\ndf = df.rename(columns={'Fecha de registro': 'FECHA_REGISTRO',\n                          'Persona Contacto:': 'NOMBRE',\n                         'Identificaci\u00f3n': 'DOCUMENTO',\n                         'SOLICITUD DE SERVICIOS DEPARTAMENTO DE DESARROLLO EMPRESARIAL:':'SERVICIO',\n                       'Estado negocio':'ESTADO_COTIZACION'})\ndf['TIPO_DOCUMENTO'] = 'CC'\ndf = df.drop(columns=['Fecha tentativa de cierre', 'Fecha \u00faltima actividad','Fecha Final del evento', \n                      'Seguimiento Informe 1', 'Fecha Seguimiento Informe 1',\n                       'Seguimiento Informe 2', 'Fecha Seguimiento informe 2',\n                       'Seguimiento Informe Final', 'Fecha Seguimiento Informe Final','Mes de Inicio', \n                      'Facilitador - Consultor  asignado', 'Fecha inicio',\n                       'Acta de Inicio', 'Mes Reprogramaci\u00f3n', 'Fecha Reprogramaci\u00f3n','Tel\u00e9fono', 'Direcci\u00f3n', \n                      'Municipio', 'Barrio', 'Asesor','Correo electr\u00f3nico', 'Celular','Fecha Envi\u00f3 Propuesta'])\n\n#Eliminar duplicados\ndf = df.drop_duplicates()\nprint(type(df))\n\n\n\n#Limpiar y almacenar\nAMDRE05 = df.melt(id_vars=['FECHA_REGISTRO','NOMBRE','TIPO_DOCUMENTO','DOCUMENTO','SERVICIO','ESTADO_COTIZACION'] , var_name=\"PREGUNTA\", value_name=\"RESPUESTA\")\nAMDRE05['COD_SERVICIO'] = -1\nAMDRE05= PreSave( AMDRE05 , [ 'NOMBRE','TIPO_DOCUMENTO','DOCUMENTO','SERVICIO','ESTADO_COTIZACION',\"RESPUESTA\"] )\ndf_transformada = transformar_fecha(AMDRE05, 'FECHA_REGISTRO')\n\n\nAMDRE05['DOCUMENTO'] = AMDRE05['DOCUMENTO'].fillna('00000000')\nAMDRE05['DOCUMENTO'] = AMDRE05['DOCUMENTO'].astype(str).apply(lambda x: x[:20])\nAMDRE05['RESPUESTA'] = AMDRE05['RESPUESTA'].astype(str).apply(lambda x: x[:40])\nAMDRE05['PREGUNTA'] = AMDRE05['PREGUNTA'].str.replace(':', '')\nAMDRE05.to_excel(os.path.join(root_directory, 'fact_cotizaciones.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/fact_facturacion/","title":"fact_facturacion","text":"<p>El script procesa <code>procesado_cede_Ingresos.xlsx</code> y <code>EP-EPT-06.xlsx</code> provenientes de diferentes directorios, los limpia, los concatena, convierte una columna a formato de fecha y luego guarda el DataFrame combinado en un nuevo archivo Excel <code>fact_facturacion.xlsx</code>.</p>"},{"location":"00.etl/Utils/fact_facturacion/#funcionamiento","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n de la funci\u00f3n <code>genera</code>:</p> <ul> <li> <p>Entradas:</p> <ul> <li><code>root_directory</code> (str): Directorio base donde se encuentra el archivo.</li> <li><code>archivo</code> (str): Nombre del archivo Excel a procesar.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Verifica si el archivo existe en la ruta especificada.</li> <li>Lee el archivo Excel utilizando <code>pd.read_excel</code>.</li> <li>Elimina las columnas vac\u00edas utilizando <code>dropna(axis=1, how='all')</code>.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame del archivo procesado.</li> </ul> </li> </ul> </li> <li> <p>Lectura de archivos:</p> <ul> <li>Se leen dos archivos Excel: <code>procesado_cede_Ingresos.xlsx</code> y <code>EP-EPT-06.xlsx</code>, desde sus respectivas rutas base.</li> <li>La funci\u00f3n <code>genera</code> se aplica para procesar ambos archivos.</li> </ul> </li> <li> <p>Concatenaci\u00f3n de DataFrames:</p> <ul> <li>Los DataFrames obtenidos de ambos archivos se concatenan utilizando <code>pd.concat</code>, combinando las filas de ambos archivos.</li> </ul> </li> <li> <p>Conversi\u00f3n de tipo de datos:</p> <ul> <li>La columna <code>'FECHA_CONTABLE'</code> se convierte al tipo <code>datetime64[ns]</code> utilizando <code>df.astype({'FECHA_CONTABLE': 'datetime64[ns]'})</code>.</li> </ul> </li> <li> <p>Exportaci\u00f3n a Excel:</p> <ul> <li>El DataFrame combinado se guarda en un nuevo archivo Excel (<code>fact_facturacion.xlsx</code>) en el directorio de destino especificado, creando el directorio si no existe previamente.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/fact_facturacion/#entradas","title":"Entradas","text":"<ul> <li><code>root_directory</code>: Directorio base donde se encuentran los archivos a procesar.</li> <li><code>archivo</code>: Nombre del archivo Excel a procesar.</li> </ul>"},{"location":"00.etl/Utils/fact_facturacion/#salida","title":"Salida","text":"<ul> <li><code>df</code>: DataFrame combinado y procesado de los dos archivos.</li> <li>Archivo Excel exportado: El DataFrame procesado se guarda como <code>fact_facturacion.xlsx</code> en el directorio de destino.</li> </ul> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    #elimina las columnas vacias\n    df = df.dropna(axis=1, how='all')\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"04.Ingresos\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Ingresos.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'EP-EPT-06.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp)\n</code></pre> <pre><code>#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n</code></pre> <pre><code># Cambia el tipo de columna por datetime64[ns] para la columna: 'FECHA'\ndf = df.astype({'FECHA_CONTABLE': 'datetime64[ns]'})\n</code></pre> <pre><code>root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'fact_facturacion.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/fact_graduados/","title":"fact_graduados","text":""},{"location":"00.etl/Utils/fact_graduados/#fact-graduados","title":"FACT GRADUADOS","text":"<p>Este script en Python procesa informaci\u00f3n de graduados o egresados de dos fuentes distintas, las combina y guarda el resultado en un nuevo archivo Excel. A continuaci\u00f3n se detalla su funcionamiento:</p>"},{"location":"00.etl/Utils/fact_graduados/#funcion-principal","title":"Funci\u00f3n Principal","text":"<p>El c\u00f3digo define una funci\u00f3n <code>genera()</code> que: - Recibe la ruta base, nombre de archivo y un valor identificador - Verifica la existencia del archivo especificado - Lee datos desde un archivo Excel utilizando pandas - Asigna un identificador de unidad acad\u00e9mica (ID_UNIDAD) - Limpia columnas vac\u00edas - Devuelve un DataFrame procesado</p>"},{"location":"00.etl/Utils/fact_graduados/#procesamiento-de-archivos","title":"Procesamiento de Archivos","text":"<p>El script procesa dos archivos Excel diferentes: 1. Un archivo relacionado con \"CEDE\" (ID_UNIDAD=2) 2. Un archivo relacionado con \"EMP\" (ID_UNIDAD=3)</p> <p>Ambos archivos se encuentran en rutas espec\u00edficas dentro de una estructura de directorios predefinida.</p>"},{"location":"00.etl/Utils/fact_graduados/#combinacion-y-limpieza-de-datos","title":"Combinaci\u00f3n y Limpieza de Datos","text":"<p>Despu\u00e9s de leer los archivos: - A\u00f1ade una columna vac\u00eda llamada 'DIPLOMA_GRADUADO' al DataFrame de CEDE - Concatena ambos DataFrames en uno solo - Realiza un tratamiento especial sobre la columna 'DOCUMENTO', convirti\u00e9ndola a un formato num\u00e9rico entero si existe</p>"},{"location":"00.etl/Utils/fact_graduados/#exportacion-de-resultados","title":"Exportaci\u00f3n de Resultados","text":"<p>Finalmente, el c\u00f3digo: - Establece una ruta de destino para el archivo final - Crea el directorio destino si no existe - Guarda el DataFrame combinado como 'fact_egresados.xlsx' - Confirma la exportaci\u00f3n exitosa mediante un mensaje en consola</p> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n\n\n\ndef genera(root_directory, archivo, value):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    # Add column ID_UNIDAD with value \n    df['ID_UNIDAD'] = value    \n    #elimina las columnas vacias\n    df = df.dropna(axis=1, how='all')\n    return df\n\nroot_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"06.Egresados_Graduados\"\n    )\n)\n\n# Nombre del archivo\narchivo_cede = 'procesado_cede_Egresados_Graduados.xlsx'\n\ndf_cede = genera(root_directory, archivo_cede,2)\n\nroot_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"02\",\n        \"06.Egresados_Graduados\"\n    )\n)\n\n\n# Nombre del archivo\narchivo_emp = 'procesado_emp_Egresados_Graduados.xlsx'\n\ndf_emp = genera(root_directory, archivo_emp,3)\n\ndf_cede['DIPLOMA_GRADUADO'] = ''\n#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n\n\n#Si all_df contiene una columna DOCUMENTO_ESTUDIANTE hay que pasarla a entero\nif \"DOCUMENTO\" in df.columns:\n    df['DOCUMENTO'] = pd.to_numeric(\n        df['DOCUMENTO'].astype(str).str.replace('[^0-9]', '', regex=True),\n        errors='coerce'\n    ).astype('Int64')\n\n\nroot_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n\n# Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'fact_egresados.xlsx'), index=False)\n#abrir el excel\n#os.system('start excel.exe \"%s\"' % os.path.join(root_directory, 'fact_egresados.xlsx'))\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/fact_listado_matriculas/","title":"fact_listado_matriculas","text":"<p>Este script procesa dos archivos CSV relacionados con el listado de matr\u00edculas, les agrega una columna con un identificador de unidad, los concatena en un solo DataFrame y guarda el resultado en un nuevo archivo CSV <code>fact_listado_matriculas.csv</code>. </p>"},{"location":"00.etl/Utils/fact_listado_matriculas/#funcionamiento","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n de la funci\u00f3n <code>genera</code>:</p> <ul> <li> <p>Entradas:</p> <ul> <li><code>root_directory</code> (str): Directorio base donde se encuentra el archivo.</li> <li><code>archivo</code> (str): Nombre del archivo CSV a procesar.</li> <li><code>value</code> (int): Valor que se asignar\u00e1 a la nueva columna <code>ID_UNIDAD</code> en el DataFrame.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Verifica si el archivo existe en la ruta especificada.</li> <li>Lee el archivo CSV utilizando <code>pd.read_csv</code>, con codificaci\u00f3n UTF-8.</li> <li>Agrega una nueva columna <code>ID_UNIDAD</code> con el valor proporcionado.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame con la columna adicional <code>ID_UNIDAD</code>.</li> </ul> </li> </ul> </li> <li> <p>Lectura de archivos:</p> <ul> <li> <p>Se leen dos archivos CSV:</p> <ul> <li><code>procesado_cede_Listado_Matriculas.csv</code> desde el directorio <code>02.Archivos/02.Cedesarrollo/01/03.Listado_Matriculas</code>.</li> <li><code>procesado_emp_Listado_Matriculas.csv</code> desde el directorio <code>02.Archivos/02.Cedesarrollo/02/03.Listado_Matriculas</code>.</li> </ul> </li> <li> <p>Se aplica la funci\u00f3n <code>genera</code> a ambos archivos, agregando los valores de <code>ID_UNIDAD</code> como 2 y 3 respectivamente.</p> </li> </ul> </li> <li> <p>Concatenaci\u00f3n de DataFrames:</p> <ul> <li>Los DataFrames <code>df_cede</code> y <code>df_emp</code> se concatenan en un \u00fanico DataFrame (<code>df</code>).</li> </ul> </li> <li> <p>Exportaci\u00f3n a CSV:</p> <ul> <li>El DataFrame combinado se guarda en un nuevo archivo CSV llamado <code>fact_listado_matriculas.csv</code> en el directorio de destino <code>02.Archivos/02.Cedesarrollo</code>.</li> </ul> </li> <li> <p>Creaci\u00f3n del directorio de destino (si no existe):</p> <ul> <li>Si el directorio de destino no existe, se crea utilizando <code>os.makedirs()</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/fact_listado_matriculas/#entradas","title":"Entradas","text":"<ul> <li><code>root_directory</code>: Directorio base donde se encuentran los archivos a procesar.</li> <li><code>archivo</code>: Nombre del archivo CSV a procesar.</li> <li><code>value</code>: Valor para la columna <code>ID_UNIDAD</code>.</li> </ul>"},{"location":"00.etl/Utils/fact_listado_matriculas/#salida","title":"Salida","text":"<ul> <li><code>df</code>: DataFrame combinado y procesado de los dos archivos.</li> <li>Archivo CSV exportado: El DataFrame combinado se guarda como <code>fact_listado_matriculas.csv</code> en el directorio de destino.</li> </ul> <pre><code># pylint: disable=all\nimport os\nimport pandas as pd\nfrom Funciones import log_step_decorator\n</code></pre> <pre><code>@log_step_decorator(\"Generando el DataFrame a partir del archivo...\")\ndef genera(root_directory, archivo, value):\n    print(f\"Generando el DataFrame a partir del archivo '{archivo}'...\")\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    # df = pd.read_excel(ruta_archivo)\n\n    # Leer el archivo csv\n    df = pd.read_csv(ruta_archivo, sep=',', encoding='utf-8')\n\n    #agrega ID_UNIDAD al df con valor value\n    df['ID_UNIDAD'] = value\n\n    print(\"El DataFrame ha sido generado exitosamente. No de registros cargados: \", len(df))\n\n    return df\n</code></pre> <pre><code>@log_step_decorator(\"Procesando Listado Matriculas emp y cede\")\ndef main():\n    root_directory = os.path.abspath(\n        os.path.join(\n            os.getcwd(),\n            \"..\",\n            \"..\",\n            \"02.Archivos\",\n            \"02.Cedesarrollo\",\n            \"01\",\n            \"03.Listado_Matriculas\"\n        )\n    )\n\n    # Nombre del archivo\n    archivo_cede = 'procesado_cede_Listado_Matriculas.csv'\n\n    df_cede = genera(root_directory, archivo_cede,2)\n\n    root_directory = os.path.abspath(\n        os.path.join(\n            os.getcwd(),\n            \"..\",\n            \"..\",\n            \"02.Archivos\",\n            \"02.Cedesarrollo\",\n            \"02\",\n            \"03.Listado_Matriculas\"\n        )\n    )\n\n\n    # Nombre del archivo\n    archivo_emp = 'procesado_emp_Listado_Matriculas.csv'\n\n    df_emp = genera(root_directory, archivo_emp,3)\n\n    #concatenar los df\n    print(\"Concatenando los DataFrames...\")\n    df = pd.concat([df_cede, df_emp], ignore_index=True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    print(\"El DataFrame ha sido concatenado exitosamente. No de registros cargados: \", len(df))\n\n    root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n    # Actualizar root_directory para que etl_destino lo asigne\n    destino = '02.Archivos/02.Cedesarrollo'\n    root_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n\n    # Crear el directorio si no existe\n    if not os.path.exists(root_directory):\n        os.makedirs(root_directory)\n    #guarda en excel \n    df.to_csv(os.path.join(root_directory, 'fact_listado_matriculas.csv'), index=False, encoding='utf-8')\n</code></pre> <pre><code>if __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/","title":"00.DimTiempo","text":""},{"location":"01.scripts/00.DimTiempo/#documentacion-del-script-sql-para-el-esquema-dimensiones-tiempo","title":"Documentaci\u00f3n del Script SQL para el Esquema <code>Dimensiones Tiempo</code>","text":""},{"location":"01.scripts/00.DimTiempo/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL pertenece a un sistema de manejo de datos en un Data Warehouse, espec\u00edficamente en el esquema <code>Dwh</code>. Su prop\u00f3sito es eliminar restricciones de claves for\u00e1neas en las tablas del esquema, eliminar las tablas y el esquema, y luego crear el esquema y la tabla <code>DIM_TIEMPO</code>. A continuaci\u00f3n, se detallan las secciones del c\u00f3digo.</p>"},{"location":"01.scripts/00.DimTiempo/#descripcion-del-codigo","title":"Descripci\u00f3n del C\u00f3digo","text":""},{"location":"01.scripts/00.DimTiempo/#1-contexto-inicial","title":"1. Contexto Inicial","text":"<p>El script comienza seleccionando la base de datos <code>DWH_COMFENALCO</code> y establece configuraciones iniciales como <code>ANSI_NULLS</code> y <code>QUOTED_IDENTIFIER</code> para asegurar el comportamiento est\u00e1ndar de SQL Server.</p> <pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n</code></pre> <ul> <li><code>USE DWH_COMFENALCO</code>: Cambia el contexto de ejecuci\u00f3n a la base de datos <code>DWH_COMFENALCO</code>.</li> <li><code>SET ANSI_NULLS ON</code>: Habilita el tratamiento est\u00e1ndar de valores <code>NULL</code> en operaciones comparativas.</li> <li><code>SET QUOTED_IDENTIFIER ON</code>: Permite usar nombres de identificadores entre comillas dobles.</li> </ul>"},{"location":"01.scripts/00.DimTiempo/#2-eliminar-restricciones-de-claves-foraneas","title":"2. Eliminar Restricciones de Claves For\u00e1neas","text":"<p>Se utiliza un procedimiento din\u00e1mico para eliminar todas las restricciones de claves for\u00e1neas asociadas al esquema <code>Dwh</code>.</p> <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Dwh';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/#desglose","title":"Desglose:","text":"<ol> <li><code>sys.foreign_keys</code>: Obtiene informaci\u00f3n de todas las claves for\u00e1neas en las tablas.</li> <li><code>sys.tables</code> y <code>sys.schemas</code>: Se utiliza para vincular las tablas a sus esquemas.</li> <li>Construcci\u00f3n din\u00e1mica: El c\u00f3digo genera comandos <code>ALTER TABLE</code> para eliminar cada restricci\u00f3n.</li> <li><code>EXEC sp_executesql</code>: Ejecuta los comandos generados din\u00e1micamente.</li> </ol> <p>Motivaci\u00f3n: Esto es \u00fatil para realizar cambios en las estructuras de las tablas sin conflictos con dependencias existentes.</p>"},{"location":"01.scripts/00.DimTiempo/#3-eliminar-tablas-y-esquema","title":"3. Eliminar Tablas y Esquema","text":"<p>El script elimina todas las tablas del esquema <code>Dwh</code> y luego elimina el esquema.</p> <pre><code>-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Dwh';\nEXEC sp_executesql @sql;\n\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Dwh')\nBEGIN\n    DROP SCHEMA Dwh;\nEND\nGO\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/#desglose_1","title":"Desglose:","text":"<ol> <li>Eliminar tablas: Genera y ejecuta comandos <code>DROP TABLE</code> para eliminar todas las tablas del esquema <code>Dwh</code>.</li> <li>Eliminar esquema: Verifica si el esquema <code>Dwh</code> existe y lo elimina si es as\u00ed.</li> </ol> <p>Motivaci\u00f3n: Esto asegura que el esquema <code>Dwh</code> y sus tablas sean eliminados antes de recrearlos.</p>"},{"location":"01.scripts/00.DimTiempo/#4-crear-esquema-y-tabla-dim_tiempo","title":"4. Crear Esquema y Tabla <code>DIM_TIEMPO</code>","text":"<p>El script crea el esquema <code>Dwh</code> y la tabla <code>DIM_TIEMPO</code> con sus respectivas columnas.</p> <pre><code>-- Crear el esquema Dwh\nCREATE SCHEMA Dwh;\nGO\n\n-- Crear DIM_TIEMPO\nCREATE TABLE [Dwh].[DIM_TIEMPO](\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NULL,\n    [DESC_FECHA] [varchar](50) NULL,\n    [ID_SEMANA] [int] NULL,\n    [DESC_SEMANA] [varchar](50) NULL,\n    [ID_NO_MES] [int] NULL,\n    [DESC_NO_MES] [varchar](50) NULL,\n    [ID_MES] [int] NULL,\n    [DESC_MES] [varchar](50) NULL,\n    [DESC_MES_CORTA] [varchar](50) NULL,\n    [ID_BIMESTRE] [int] NULL,\n    [DESC_BIMESTRE] [varchar](50) NULL,\n    [ID_TRIMESTRE] [int] NULL,\n    [DESC_TRIMESTRE] [varchar](50) NULL,\n    [ID_CUATRIMESTRE] [int] NULL,\n    [DESC_CUATRIMESTRE] [varchar](50) NULL\n);\nGO\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/#desglose_2","title":"Desglose:","text":"<ol> <li>Crear esquema: Crea el esquema <code>Dwh</code>.</li> <li>Crear tabla <code>DIM_TIEMPO</code>: Define la tabla <code>DIM_TIEMPO</code> con sus columnas y tipos de datos.</li> </ol> <p>Motivaci\u00f3n: Esto establece la estructura necesaria para almacenar datos de tiempo en el esquema <code>Dwh</code>.</p>"},{"location":"01.scripts/00.DimTiempo/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li> <p>Uso de Restricciones de Integridad:</p> <ul> <li>La eliminaci\u00f3n y recreaci\u00f3n de restricciones asegura la integridad de los datos.</li> </ul> </li> <li> <p>Automatizaci\u00f3n en la Eliminaci\u00f3n de Restricciones:</p> <ul> <li>Permite realizar modificaciones estructurales masivas sin errores manuales.</li> </ul> </li> <li> <p>Configuraciones Iniciales:</p> <ul> <li>Se asegura un comportamiento est\u00e1ndar al trabajar con valores <code>NULL</code> y nombres de columnas.</li> </ul> </li> <li> <p>Modularidad y Dinamismo:</p> <ul> <li>El script est\u00e1 dise\u00f1ado para ser modular y din\u00e1mico, facilitando modificaciones estructurales complejas.</li> </ul> </li> <li> <p>Uso de Procedimientos Din\u00e1micos:</p> <ul> <li>La construcci\u00f3n din\u00e1mica de comandos SQL permite una mayor flexibilidad y adaptabilidad.</li> </ul> </li> <li> <p>Definici\u00f3n Clara de Esquemas:</p> <ul> <li>Las tablas y sus relaciones est\u00e1n claramente definidas, lo que mejora la comprensi\u00f3n y mantenimiento del c\u00f3digo.</li> </ul> </li> </ol>"},{"location":"01.scripts/00.DimTiempo/#diagrama-de-relacion-de-tablas","title":"Diagrama de Relaci\u00f3n de Tablas","text":"<pre><code>erDiagram\n    DIM_TIEMPO {\n        int ID_FECHA PK\n        datetime FECHA\n        varchar(50) DESC_FECHA\n        int ID_SEMANA\n        varchar(50) DESC_SEMANA\n        int ID_NO_MES\n        varchar(50) DESC_NO_MES\n        int ID_MES\n        varchar(50) DESC_MES\n        varchar(50) DESC_MES_CORTA\n        int ID_BIMESTRE\n        varchar(50) DESC_BIMESTRE\n        int ID_TRIMESTRE\n        varchar(50) DESC_TRIMESTRE\n        int ID_CUATRIMESTRE\n        varchar(50) DESC_CUATRIMESTRE\n    }</code></pre>"},{"location":"01.scripts/00.DimTiempo/#conclusion","title":"Conclusi\u00f3n","text":"<p>Este script SQL est\u00e1 dise\u00f1ado para gestionar de manera eficiente la eliminaci\u00f3n y creaci\u00f3n de estructuras de datos en el esquema <code>Dwh</code>. La automatizaci\u00f3n y modularidad implementadas aseguran que las operaciones se realicen de manera consistente y sin errores, facilitando el mantenimiento y la evoluci\u00f3n del Data Warehouse.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/","title":"00.DimensionesColegio a local","text":""},{"location":"01.scripts/00.DimensionesColegio_a_local/#documentacion-del-script-sql-para-el-esquema-dimensiones-colegio","title":"Documentaci\u00f3n del Script SQL para el Esquema <code>Dimensiones Colegio</code>","text":""},{"location":"01.scripts/00.DimensionesColegio_a_local/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL pertenece a un sistema de manejo de datos en un Data Warehouse, espec\u00edficamente en el esquema <code>Colegio</code>. Su prop\u00f3sito es eliminar restricciones de claves for\u00e1neas en las tablas del esquema, y luego realizar configuraciones de integridad referencial mediante la definici\u00f3n de claves primarias. A continuaci\u00f3n, se detallan las secciones del c\u00f3digo.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#descripcion-del-codigo","title":"Descripci\u00f3n del C\u00f3digo","text":""},{"location":"01.scripts/00.DimensionesColegio_a_local/#1-contexto-inicial","title":"1. Contexto Inicial","text":"<p>El script comienza seleccionando la base de datos <code>DWH_COMFENALCO</code> y establece configuraciones iniciales como <code>ANSI_NULLS</code> y <code>QUOTED_IDENTIFIER</code> para asegurar el comportamiento est\u00e1ndar de SQL Server.</p> <pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n</code></pre> <ul> <li><code>USE DWH_COMFENALCO</code>: Cambia el contexto de ejecuci\u00f3n a la base de datos <code>DWH_COMFENALCO</code>.</li> <li><code>SET ANSI_NULLS ON</code>: Habilita el tratamiento est\u00e1ndar de valores <code>NULL</code> en operaciones comparativas.</li> <li><code>SET QUOTED_IDENTIFIER ON</code>: Permite usar nombres de identificadores entre comillas dobles.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#2-eliminar-restricciones-de-claves-foraneas","title":"2. Eliminar Restricciones de Claves For\u00e1neas","text":"<p>Se utiliza un procedimiento din\u00e1mico para eliminar todas las restricciones de claves for\u00e1neas asociadas al esquema <code>Colegio</code>.</p> <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Colegio';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#desglose","title":"Desglose:","text":"<ol> <li><code>sys.foreign_keys</code>: Obtiene informaci\u00f3n de todas las claves for\u00e1neas en las tablas.</li> <li><code>sys.tables</code> y <code>sys.schemas</code>: Se utiliza para vincular las tablas a sus esquemas.</li> <li>Construcci\u00f3n din\u00e1mica: El c\u00f3digo genera comandos <code>ALTER TABLE</code> para eliminar cada restricci\u00f3n.</li> <li><code>EXEC sp_executesql</code>: Ejecuta los comandos generados din\u00e1micamente.</li> </ol> <p>Motivaci\u00f3n: Esto es \u00fatil para realizar cambios en las estructuras de las tablas sin conflictos con dependencias existentes.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#3-creacion-de-tablas-comentarios","title":"3. Creaci\u00f3n de Tablas (Comentarios)","text":"<p>Las tablas <code>DIM_CURSO</code>, <code>DIM_GRADO</code> y <code>DIM_POBLACION_MATRICULA</code> est\u00e1n definidas en comentarios como referencia.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#definicion-de-la-tablas","title":"Definici\u00f3n de la tablas","text":"<pre><code>CREATE TABLE [Colegio].[DIM_CURSO](\n    [ID_CURSO] [int] NOT NULL,\n    [DESC_CURSO] [nvarchar](100) NULL,\n    [FECHA_CREACION] [date] NULL,\n    [ESTADO_REGISTRO] [nvarchar](20) NULL\n) ON [PRIMARY]\n\nCREATE TABLE [Colegio].[DIM_GRADO](\n    [ID_GRADO] [int] IDENTITY(1,1) NOT NULL,\n    [DESC_GRADO] [nvarchar](100) NULL,\n    [FECHA_CREACION] [date] NULL,\n    [ESTADO_REGISTRO] [nvarchar](20) NULL\n) ON [PRIMARY]\n\nCREATE TABLE [Colegio].[DIM_POBLACION_MATRICULA](\n    [ID_POBLACION_MATRICULA] [int] IDENTITY(1,1) NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [NOMBRE_COMPLETO] [nvarchar](4000) NULL,\n    [GENERO] [varchar](20) NULL,\n    [DIRECCION] [nvarchar](300) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [CORREO] [nvarchar](250) NULL,\n    [FECHA_NACIMIENTO] [int] NULL\n) ON [PRIMARY]\n</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#campos-de-la-tabla-dim_curso","title":"Campos de la Tabla <code>DIM_CURSO</code>","text":"<ul> <li><code>ID_CURSO</code>: Identificador \u00fanico de la tabla <code>DIM_CURSO</code> (clave primaria).</li> <li><code>DESC_CURSO</code>: Descripci\u00f3n del curso en la tabla <code>DIM_CURSO</code>.</li> <li><code>FECHA_CREACION</code>: Fecha en que se cre\u00f3 el curso en la tabla <code>DIM_CURSO</code>.</li> <li><code>ESTADO_REGISTRO</code>: Indica si el registro est\u00e1 activo o inactivo en la tabla <code>DIM_CURSO</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#campos-de-la-tabla-dim_grado","title":"Campos de la Tabla <code>DIM_GRADO</code>","text":"<ul> <li><code>ID_GRADO</code>: Identificador \u00fanico de la tabla <code>DIM_GRADO</code> (clave primaria).</li> <li><code>DESC_GRADO</code>: Descripci\u00f3n del grado en la tabla <code>DIM_GRADO</code>.</li> <li><code>FECHA_CREACION</code>: Fecha en que se cre\u00f3 el grado en la tabla <code>DIM_GRADO</code>.</li> <li><code>ESTADO_REGISTRO</code>: Indica si el registro est\u00e1 activo o inactivo en la tabla <code>DIM_GRADO</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#campos-de-la-tabla-dim_poblacion_matricula","title":"Campos de la Tabla <code>DIM_POBLACION_MATRICULA</code>","text":"<ul> <li><code>ID_POBLACION_MATRICULA</code>: Identificador \u00fanico de la tabla <code>DIM_POBLACION_MATRICULA</code> (clave primaria).</li> <li><code>PARTNER</code>: Identificador del socio en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>TIPO_DOCUMENTO</code>: Tipo de documento en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>DOCUMENTO</code>: N\u00famero de documento en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>NOMBRE_COMPLETO</code>: Nombre completo del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>GENERO</code>: G\u00e9nero del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>DIRECCION</code>: Direcci\u00f3n del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>TELEFONO</code>: Tel\u00e9fono del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>CORREO</code>: Correo electr\u00f3nico del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>FECHA_NACIMIENTO</code>: Fecha de nacimiento del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#4-definicion-de-claves-primarias","title":"4. Definici\u00f3n de Claves Primarias","text":"<p>El script define claves primarias para las tablas <code>DIM_POBLACION_MATRICULA</code>, <code>DIM_CURSO</code> y <code>DIM_GRADO</code>.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#claves-primarias","title":"Claves primarias","text":"<pre><code>ALTER TABLE [Colegio].[DIM_POBLACION_MATRICULA]  WITH NOCHECK ADD  CONSTRAINT [PK_DIM_POBLACION_MATRICULA] PRIMARY KEY CLUSTERED ([ID_POBLACION_MATRICULA])\n\nALTER TABLE [Colegio].[DIM_CURSO]  WITH NOCHECK ADD  CONSTRAINT [PK_DIM_CURSO] PRIMARY KEY CLUSTERED ([ID_CURSO])\n\nALTER TABLE [Colegio].[DIM_GRADO]  WITH NOCHECK ADD  CONSTRAINT [PK_DIM_GRADO] PRIMARY KEY CLUSTERED ([ID_GRADO])\n</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#detalles","title":"Detalles:","text":"<ul> <li><code>WITH NOCHECK</code>: No verifica los datos existentes en la tabla antes de aplicar la restricci\u00f3n.</li> <li><code>PRIMARY KEY CLUSTERED</code>: Define una clave primaria con un \u00edndice cl\u00fasterado basado en <code>ID_POBLACION_MATRICULA</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#claves-primarias-definidas","title":"Claves Primarias Definidas:","text":"Tabla Clave Primaria <code>DIM_POBLACION_MATRICULA</code> <code>ID_POBLACION_MATRICULA</code> <code>DIM_CURSO</code> <code>ID_CURSO</code> <code>DIM_GRADO</code> <code>ID_GRADO</code>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#diagrama-de-relacion-de-tablas","title":"Diagrama de Relaci\u00f3n de Tablas","text":"<pre><code>erDiagram\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION_MATRICULA PK\n        nvarchar(10) PARTNER\n        nvarchar(4) TIPO_DOCUMENTO\n        nvarchar(20) DOCUMENTO\n        nvarchar(4000) NOMBRE_COMPLETO\n        varchar(20) GENERO\n        nvarchar(300) DIRECCION\n        nvarchar(30) TELEFONO\n        nvarchar(250) CORREO\n        int FECHA_NACIMIENTO\n    }\n\n    DIM_CURSO {\n        int ID_CURSO PK\n        nvarchar(100) DESC_CURSO\n        date FECHA_CREACION\n        nvarchar(20) ESTADO_REGISTRO\n    }\n\n    DIM_GRADO {\n        int ID_GRADO PK\n        nvarchar(100) DESC_GRADO\n        date FECHA_CREACION\n        nvarchar(20) ESTADO_REGISTRO\n    }</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li> <p>Uso de Restricciones de Integridad:</p> <ul> <li>Claves primarias garantizan la unicidad de registros y optimizan las consultas.</li> </ul> </li> <li> <p>Automatizaci\u00f3n en la Eliminaci\u00f3n de Restricciones:</p> <ul> <li>Permite realizar modificaciones estructurales masivas sin errores manuales.</li> </ul> </li> <li> <p>Comentarios:</p> <ul> <li>Las definiciones de tablas est\u00e1n comentadas como referencia.</li> </ul> </li> <li> <p>Configuraciones Iniciales:</p> <ul> <li>Se asegura un comportamiento est\u00e1ndar al trabajar con valores <code>NULL</code> y nombres de columnas.</li> </ul> </li> <li> <p>Modularidad y Dinamismo:</p> <ul> <li>El script est\u00e1 dise\u00f1ado para ser modular y din\u00e1mico, facilitando modificaciones estructurales complejas.</li> </ul> </li> <li> <p>Uso de Procedimientos Din\u00e1micos:</p> <ul> <li>La construcci\u00f3n din\u00e1mica de comandos SQL permite una mayor flexibilidad y adaptabilidad.</li> </ul> </li> <li> <p>Definici\u00f3n Clara de Esquemas:</p> <ul> <li>Las tablas y sus relaciones est\u00e1n claramente definidas, lo que mejora la comprensi\u00f3n y mantenimiento del c\u00f3digo.</li> </ul> </li> <li> <p>Garant\u00eda de Integridad Referencial:</p> <ul> <li>La definici\u00f3n de claves primarias y la eliminaci\u00f3n controlada de restricciones aseguran la integridad referencial del esquema.</li> </ul> </li> </ol>"},{"location":"01.scripts/00.Eliminar_todo/","title":"00. Eliminar Todo","text":""},{"location":"01.scripts/00.Eliminar_todo/#eliminar-todo","title":"Eliminar Todo","text":""},{"location":"01.scripts/00.Eliminar_todo/#descripcion-del-script","title":"Descripci\u00f3n del Script","text":"<p>El prop\u00f3sito del script SQL proporcionado es realizar una limpieza completa de los esquemas en una base de datos denominada <code>DWH_COMFENALCO</code>. Incluye la eliminaci\u00f3n de restricciones, tablas y esquemas espec\u00edficos para preparar la base de datos para un nuevo esquema o estructura de datos. A continuaci\u00f3n, se detalla el proceso ejecutado:</p>"},{"location":"01.scripts/00.Eliminar_todo/#componentes-y-pasos-del-script","title":"Componentes y Pasos del Script","text":""},{"location":"01.scripts/00.Eliminar_todo/#1-uso-del-contexto-de-la-base-de-datos","title":"1. Uso del Contexto de la Base de Datos","text":"<p><pre><code>USE DWH_COMFENALCO;\nGO\n</code></pre> Selecciona la base de datos <code>DWH_COMFENALCO</code> como contexto para las operaciones subsecuentes.</p>"},{"location":"01.scripts/00.Eliminar_todo/#2-configuraciones-iniciales","title":"2. Configuraciones Iniciales","text":"<p><pre><code>SET ANSI_NULLS ON;\nSET QUOTED_IDENTIFIER ON;\nGO\n</code></pre> Configura opciones para garantizar compatibilidad con valores nulos y el uso de identificadores entre comillas dobles en las consultas.</p>"},{"location":"01.scripts/00.Eliminar_todo/#3-eliminacion-de-restricciones-de-clave-foranea","title":"3. Eliminaci\u00f3n de Restricciones de Clave For\u00e1nea","text":"<p>Por cada esquema (<code>Colegio</code>, <code>Protecci\u00f3n</code>, <code>Cedesarrollo</code>, y <code>Transversal</code>), el script: 1. Busca las restricciones de clave for\u00e1nea. 2. Genera din\u00e1micamente comandos <code>ALTER TABLE ... DROP CONSTRAINT</code>. 3. Ejecuta estos comandos utilizando <code>sp_executesql</code>.</p> <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Colegio';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.Eliminar_todo/#4-eliminacion-de-tablas","title":"4. Eliminaci\u00f3n de Tablas","text":"<p>Una vez eliminadas las restricciones, el script elimina las tablas del esquema utilizando un proceso similar: 1. Genera comandos <code>DROP TABLE</code> din\u00e1micamente. 2. Ejecuta los comandos para cada tabla del esquema correspondiente.</p> <pre><code>SET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Proteccion';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.Eliminar_todo/#5-eliminacion-de-esquemas","title":"5. Eliminaci\u00f3n de Esquemas","text":"<p>Si un esquema existe despu\u00e9s de la eliminaci\u00f3n de tablas, se elimina con <code>DROP SCHEMA</code>.</p> <pre><code>IF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Transversal')\nBEGIN\n    DROP SCHEMA Transversal;\nEND\n</code></pre>"},{"location":"01.scripts/00.Eliminar_todo/#6-esquemas-y-tablas-afectados","title":"6. Esquemas y Tablas Afectados","text":"Esquema Tablas Incluidas Colegio <code>FACT_LEGALIZACION</code>, <code>FACT_ENFERMERIA</code>, <code>FACT_NOTAS</code>, etc. Proteccion <code>FACT_PLAN_COBERTURA</code>, <code>FACT_DESERCION</code>, etc. Cedesarrollo <code>FACT_NOTAS</code>, <code>FACT_INASISTENCIAS</code>, etc. Transversal Todas las tablas asociadas."},{"location":"01.scripts/00.Eliminar_todo/#consideraciones","title":"Consideraciones","text":"<ol> <li>Impacto del Script:</li> <li>Elimina de manera irreversible todas las tablas, restricciones y esquemas mencionados.</li> <li> <p>Se debe realizar una copia de seguridad previa si se requiere preservar datos.</p> </li> <li> <p>Ejecutar con Precauci\u00f3n:</p> </li> <li>Valide que los esquemas y tablas ya no son necesarios antes de ejecutar el script.</li> <li> <p>Considere ambientes de desarrollo para pruebas iniciales.</p> </li> <li> <p>Optimizaci\u00f3n del Proceso:</p> </li> <li>Los comandos din\u00e1micos utilizados son eficientes para manejar grandes cantidades de tablas y restricciones de forma automatizada.</li> </ol>"},{"location":"01.scripts/00.Eliminar_todo/#uso-sugerido","title":"Uso Sugerido","text":"<p>Este script es \u00fatil para: - Reiniciar un Data Warehouse antes de una nueva carga de datos. - Eliminar estructuras no necesarias en ambientes de desarrollo o pruebas.</p>"},{"location":"01.scripts/00.Inicio/","title":"Introducci\u00f3n","text":""},{"location":"01.scripts/00.Inicio/#documentacion-de-diseno-e-implementacion-del-data-warehouse-dwh_comfenalco","title":"Documentaci\u00f3n de Dise\u00f1o e Implementaci\u00f3n del Data Warehouse: <code>DWH_COMFENALCO</code>","text":""},{"location":"01.scripts/00.Inicio/#introduccion","title":"Introducci\u00f3n","text":"<p>El <code>DWH_COMFENALCO</code> es un Data Warehouse dise\u00f1ado para gestionar y analizar informaci\u00f3n relacionada con diversas \u00e1reas de la organizaci\u00f3n, como la educaci\u00f3n, bienestar social, protecci\u00f3n, y programas transversales. Este proyecto se estructura bajo un enfoque de modelado dimensional para optimizar la consulta y an\u00e1lisis de datos, y se apoya en una organizaci\u00f3n jer\u00e1rquica y relacional de tablas <code>dimensionales</code> y <code>hechos</code>.</p>"},{"location":"01.scripts/00.Inicio/#objetivos","title":"Objetivos","text":""},{"location":"01.scripts/00.Inicio/#objetivo-general","title":"Objetivo General","text":"<p>Crear una plataforma de datos robusta y optimizada que permita a las \u00e1reas interesadas acceder a informaci\u00f3n estrat\u00e9gica para la toma de decisiones basada en datos hist\u00f3ricos y actuales.</p>"},{"location":"01.scripts/00.Inicio/#objetivos-especificos","title":"Objetivos Espec\u00edficos","text":"<ol> <li>Estandarizar y centralizar la informaci\u00f3n proveniente de diferentes fuentes operativas.</li> <li>Dise\u00f1ar un esquema relacional que permita realizar an\u00e1lisis detallados por dimensiones clave (e.g., tiempo, poblaci\u00f3n, programas, etc.).</li> <li>Implementar \u00edndices y claves for\u00e1neas para optimizar el rendimiento de las consultas.</li> <li>Facilitar la integraci\u00f3n y an\u00e1lisis de informaci\u00f3n para \u00e1reas como colegios, protecci\u00f3n social y desarrollo acad\u00e9mico.</li> <li>Garantizar la escalabilidad para futuros m\u00f3dulos o esquemas.</li> </ol>"},{"location":"01.scripts/00.Inicio/#esquema-relacional","title":"Esquema Relacional","text":""},{"location":"01.scripts/00.Inicio/#arquitectura-general","title":"Arquitectura General","text":"<p>El Data Warehouse se organiza en m\u00f3dulos independientes que comparten dimensiones clave, cada uno enfocado en un \u00e1rea funcional:</p> <ol> <li>Dimensiones Comunes:</li> <li><code>DIM_TIEMPO</code>: Dimensi\u00f3n temporal que permite analizar datos por fechas espec\u00edficas.</li> <li> <p><code>DIM_PERSONAL</code>, <code>DIM_SERVICIOS</code>, y otras dimensiones transversales.</p> </li> <li> <p>M\u00f3dulos Espec\u00edficos:</p> </li> <li>Cedesarrollo: Datos relacionados con estudiantes, programas acad\u00e9micos y notas.</li> <li>Protecci\u00f3n: Informaci\u00f3n sobre caracterizaci\u00f3n, poblaci\u00f3n y planes de cobertura.</li> <li>Colegio: Gesti\u00f3n de notas, transporte, biblioteca y servicios sociales en colegios.</li> </ol>"},{"location":"01.scripts/00.Inicio/#esquema-relacional-simplificado","title":"Esquema Relacional Simplificado","text":"<pre><code>erDiagram\n    DIM_TIEMPO {\n        int ID_FECHA PK\n        date FECHA\n        varchar DIA_SEMANA\n        varchar MES\n        int ANIO\n    }\n\n    Transversal {\n        int ID_PERSONAL PK\n        int ID_SERVICIO PK\n        varchar NOMBRE_SERVICIO\n    }\n\n    Cedesarrollo {\n        int ID_ESTUDIANTE PK\n        int ID_PROGRAMA FK\n        int ID_PERIODO FK\n        decimal NOTA_FINAL\n    }\n\n    Proteccion {\n        int ID_POBLACION PK\n        int ID_PROGRAMA FK\n        int ID_FECHA FK\n    }\n\n    Colegio {\n        int ID_NOTA PK\n        int ID_POBLACION_MATRICULA FK\n        int ID_GRADO FK\n        int ID_CURSO FK\n        decimal NOTA_FINAL\n    }\n\n    DIM_TIEMPO ||--o{ Transversal: \"relaci\u00f3n temporal\"\n    DIM_TIEMPO ||--o{ Cedesarrollo: \"relaci\u00f3n temporal\"\n    DIM_TIEMPO ||--o{ Proteccion: \"relaci\u00f3n temporal\"\n    DIM_TIEMPO ||--o{ Colegio: \"relaci\u00f3n temporal\"\n    Transversal ||--o{ Cedesarrollo: \"uso compartido\"\n    Transversal ||--o{ Proteccion: \"uso compartido\"\n    Transversal ||--o{ Colegio: \"uso compartido\"</code></pre>"},{"location":"01.scripts/00.Inicio/#detalles-por-modulo","title":"Detalles por M\u00f3dulo","text":""},{"location":"01.scripts/00.Inicio/#1-dimensiones-comunes","title":"1. Dimensiones Comunes","text":"<p>Estas dimensiones son utilizadas transversalmente en todos los m\u00f3dulos:</p> <ul> <li><code>DIM_TIEMPO</code>: Estructura central para an\u00e1lisis temporal. Contiene informaci\u00f3n granular de fechas, d\u00edas de la semana, meses y a\u00f1os.</li> <li><code>DIM_SERVICIOS</code>: Identifica los servicios ofrecidos en diferentes programas.</li> <li><code>DIM_PERSONAL</code>: Informaci\u00f3n de personal administrativo y docente.</li> </ul>"},{"location":"01.scripts/00.Inicio/#2-cedesarrollo","title":"2. Cedesarrollo","text":"<p>Este m\u00f3dulo se enfoca en la informaci\u00f3n acad\u00e9mica de estudiantes:</p> <ul> <li>Tablas principales:</li> <li><code>DIM_ESTUDIANTES</code>: Informaci\u00f3n general de los estudiantes.</li> <li><code>DIM_PROGRAMA</code>: Datos de los programas acad\u00e9micos.</li> <li><code>FACT_NOTAS</code>: Notas por m\u00f3dulo, estudiante y periodo acad\u00e9mico.</li> </ul>"},{"location":"01.scripts/00.Inicio/#3-proteccion","title":"3. Protecci\u00f3n","text":"<p>M\u00f3dulo que gestiona informaci\u00f3n de poblaci\u00f3n vulnerable y programas sociales:</p> <ul> <li>Tablas principales:</li> <li><code>DIM_POBLACION</code>: Identificaci\u00f3n de beneficiarios de programas.</li> <li><code>FACT_CARACTERIZACION</code>: Caracterizaci\u00f3n de poblaciones seg\u00fan criterios.</li> <li><code>FACT_PLAN_COBERTURA</code>: Proyecciones y coberturas de programas sociales.</li> </ul>"},{"location":"01.scripts/00.Inicio/#4-colegio","title":"4. Colegio","text":"<p>Dise\u00f1ado para gestionar datos operativos y acad\u00e9micos en colegios:</p> <ul> <li>Tablas principales:</li> <li><code>DIM_PLAN_CURRICULAR</code>: Estructura acad\u00e9mica por asignaturas y cursos.</li> <li><code>FACT_NOTAS</code>: Notas obtenidas por estudiantes en diversas materias.</li> <li><code>FACT_BIBLIOTECA</code>: Registro de pr\u00e9stamos en bibliotecas f\u00edsicas y virtuales.</li> </ul>"},{"location":"01.scripts/00.Inicio/#nota","title":"Nota","text":"<ul> <li>La creaci\u00f3n de tablas se hace desde los scritps SQL. Incluidos en esta secci\u00f3n.</li> <li>Las funciones se encuentran en los scritps de Python y la explicaci\u00f3n de los paquetes.</li> <li>El unico procedimiento almacenado se ejecuta en el paquete 3 para calcular <code>FACT_RETIROS</code></li> <li>Parametros de SSIS. Se explican en la introducci\u00f3n de SSIS.</li> </ul>"},{"location":"01.scripts/00.Inicio/#conclusion","title":"Conclusi\u00f3n","text":"<p>El <code>DWH_COMFENALCO</code> es una herramienta poderosa y escalable que permite a los usuarios finales obtener insights r\u00e1pidos y precisos a trav\u00e9s de la integraci\u00f3n y an\u00e1lisis de datos en m\u00faltiples dominios. Con un dise\u00f1o modular y el uso eficiente de dimensiones compartidas, este Data Warehouse est\u00e1 preparado para soportar el crecimiento futuro y nuevos requisitos de an\u00e1lisis.</p>"},{"location":"01.scripts/00.Inicio/#pagina-principal","title":"P\u00e1gina Principal","text":"<p>Bienvenido a la documentaci\u00f3n.</p>"},{"location":"01.scripts/00.Inicio/#indice","title":"\u00cdndice","text":"<p>{{ pagetree }}</p>"},{"location":"01.scripts/01.Transversal%20copy/","title":"Documentaci\u00f3n SQL para el Esquema <code>Transversal</code>","text":""},{"location":"01.scripts/01.Transversal%20copy/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL est\u00e1 dise\u00f1ado para gestionar el esquema <code>Transversal</code> dentro de un Data Warehouse (DWH). Implementa una arquitectura dimensional compuesta por tablas de dimensiones y tablas de hechos, siguiendo las mejores pr\u00e1cticas de modelado dimensional.</p>"},{"location":"01.scripts/01.Transversal%20copy/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li>Eliminaci\u00f3n y Creaci\u00f3n del Esquema:</li> <li>Limpieza del esquema existente <code>Transversal</code> eliminando restricciones de claves for\u00e1neas, tablas y el esquema en s\u00ed.</li> <li> <p>Reinstalaci\u00f3n del esquema <code>Transversal</code> desde cero.</p> </li> <li> <p>Creaci\u00f3n de Tablas Dimensionales y de Hechos:</p> </li> <li>Tablas de Dimensiones (<code>DIM</code>): Contienen atributos descriptivos y categ\u00f3ricos relacionados con empresas, afiliados, beneficiarios, aportantes no afiliados, entre otros.</li> <li> <p>Tablas de Hechos (<code>FACT</code>): Contienen m\u00e9tricas y claves for\u00e1neas que conectan con las dimensiones, facilitando an\u00e1lisis transaccionales y operativos.</p> </li> <li> <p>Relaciones entre Tablas:</p> </li> <li>Configuraci\u00f3n de restricciones <code>FOREIGN KEY</code> para garantizar integridad referencial.</li> </ol>"},{"location":"01.scripts/01.Transversal%20copy/#detalle-de-las-tablas-y-relacion-dimensional","title":"Detalle de las Tablas y Relaci\u00f3n Dimensional","text":""},{"location":"01.scripts/01.Transversal%20copy/#tablas-dimensionales","title":"Tablas Dimensionales","text":""},{"location":"01.scripts/01.Transversal%20copy/#1-dim_empresas","title":"1. DIM_EMPRESAS","text":"<p>Contiene informaci\u00f3n b\u00e1sica sobre empresas, incluyendo tipo de documento, raz\u00f3n social, sector y estado.</p> Columna Tipo Descripci\u00f3n <code>ID_EMPRESA</code> <code>int</code> Identificador \u00fanico de la empresa. <code>RAZON_SOCIAL</code> <code>nvarchar</code> Nombre de la empresa. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento (NIT, CC). <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero del documento."},{"location":"01.scripts/01.Transversal%20copy/#2-dim_afiliados","title":"2. DIM_AFILIADOS","text":"<p>Contiene datos de los afiliados como nombre, g\u00e9nero, estado civil, y afiliaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_AFILIADO</code> <code>int</code> Identificador \u00fanico del afiliado. <code>NOMBRE_COMPLETO</code> <code>nvarchar</code> Nombre completo del afiliado. <code>GENERO</code> <code>nvarchar</code> G\u00e9nero del afiliado. <code>FECHA_AFILIACION</code> <code>nvarchar</code> Fecha de afiliaci\u00f3n."},{"location":"01.scripts/01.Transversal%20copy/#3-dim_beneficiarios","title":"3. DIM_BENEFICIARIOS","text":"<p>Contiene informaci\u00f3n de los beneficiarios relacionados con los afiliados.</p> Columna Tipo Descripci\u00f3n <code>ID_BENEFICIARIO</code> <code>int</code> Identificador \u00fanico del beneficiario. <code>NOMBRE_COMPLETO</code> <code>nvarchar</code> Nombre completo del beneficiario. <code>PARENTESCO</code> <code>nvarchar</code> Relaci\u00f3n del beneficiario con el titular."},{"location":"01.scripts/01.Transversal%20copy/#diagrama-de-las-tablas-dimensionales","title":"Diagrama de las Tablas Dimensionales","text":"<pre><code>erDiagram\n    DIM_EMPRESAS {\n        int ID_EMPRESA PK\n        nvarchar RAZON_SOCIAL\n        nvarchar TIPO_DOCUMENTO\n        nvarchar DOCUMENTO\n    }\n\n    DIM_AFILIADOS {\n        int ID_AFILIADO PK\n        nvarchar NOMBRE_COMPLETO\n        nvarchar GENERO\n        nvarchar FECHA_AFILIACION\n    }\n    DIM_BENEFICIARIOS {\n        int ID_BENEFICIARIO PK\n        nvarchar NOMBRE_COMPLETO\n        nvarchar PARENTESCO\n    }\n\n    DIM_EMPRESAS ||--o{ DIM_AFILIADOS : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ DIM_BENEFICIARIOS : \"ID_AFILIADO\"</code></pre>"},{"location":"01.scripts/01.Transversal%20copy/#tablas-de-hechos","title":"Tablas de Hechos","text":""},{"location":"01.scripts/01.Transversal%20copy/#1-fact_aportes_shr_det","title":"1. FACT_APORTES_SHR_DET","text":"<p>Registra detalles financieros de aportes realizados por empresas y afiliados.</p> Columna Tipo Descripci\u00f3n <code>ID_EMPRESA</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_EMPRESAS</code>. <code>ID_AFILIADO</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_AFILIADOS</code>. <code>PERIODO</code> <code>varchar</code> Per\u00edodo de los aportes. <code>APORTE_NUEVO</code> <code>numeric</code> Monto del aporte registrado."},{"location":"01.scripts/01.Transversal%20copy/#2-fact_detalle_contable","title":"2. FACT_DETALLE_CONTABLE","text":"<p>Registra operaciones contables como ingresos, gastos y resultados financieros.</p> Columna Tipo Descripci\u00f3n <code>ID_CEBE</code> <code>bigint</code> Relaci\u00f3n con la tabla <code>DIM_UNIDADES_ORGANIZATIVAS</code>. <code>ID_CUENTA</code> <code>bigint</code> Relaci\u00f3n con la tabla <code>DIM_CUENTA_CONTABLE</code>. <code>IMPORTE</code> <code>decimal</code> Importe de la operaci\u00f3n contable."},{"location":"01.scripts/01.Transversal%20copy/#3-fact_encuestas","title":"3. FACT_ENCUESTAS","text":"<p>Registra resultados de encuestas relacionadas con servicios y satisfacci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_UNIDAD</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_UNIDAD</code>. <code>SERVICIO</code> <code>nvarchar</code> Servicio evaluado en la encuesta. <code>CALIFICACION</code> <code>nvarchar</code> Puntuaci\u00f3n otorgada en la encuesta."},{"location":"01.scripts/01.Transversal%20copy/#diagrama-de-las-tablas-de-hechos","title":"Diagrama de las Tablas de Hechos","text":"<pre><code>erDiagram\n    FACT_APORTES_SHR_DET {\n        int ID_EMPRESA FK\n        int ID_AFILIADO FK\n        varchar PERIODO\n        numeric APORTE_NUEVO\n    }\n\n    FACT_DETALLE_CONTABLE {\n        bigint ID_CEBE FK\n        bigint ID_CUENTA FK\n        decimal IMPORTE\n    }\n\n    FACT_ENCUESTAS {\n        int ID_UNIDAD FK\n        nvarchar SERVICIO\n        nvarchar CALIFICACION\n    }\n\n    DIM_EMPRESAS ||--o{ FACT_APORTES_SHR_DET : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ FACT_APORTES_SHR_DET : \"ID_AFILIADO\"\n    DIM_UNIDADES_ORGANIZATIVAS ||--o{ FACT_DETALLE_CONTABLE : \"ID_CEBE\"\n    DIM_CUENTA_CONTABLE ||--o{ FACT_DETALLE_CONTABLE : \"ID_CUENTA\"\n    DIM_UNIDAD ||--o{ FACT_ENCUESTAS : \"ID_UNIDAD\"</code></pre>"},{"location":"01.scripts/01.Transversal%20copy/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li>Integridad Referencial:</li> <li> <p>Uso de claves for\u00e1neas para garantizar relaciones consistentes entre dimensiones y hechos.</p> </li> <li> <p>Arquitectura Modular:</p> </li> <li> <p>Separaci\u00f3n de tablas <code>DIM</code> y <code>FACT</code> para optimizar consultas y mantener un dise\u00f1o limpio.</p> </li> <li> <p>Documentaci\u00f3n:</p> </li> <li>Las descripciones de columnas y relaciones facilitan el entendimiento del modelo.</li> </ol>"},{"location":"01.scripts/01.Transversal%20copy/#conclusion","title":"Conclusi\u00f3n","text":"<p>El script implementa un esquema <code>Transversal</code> eficiente para an\u00e1lisis en un Data Warehouse. Las tablas de dimensiones proporcionan atributos descriptivos, mientras que las tablas de hechos registran transacciones y m\u00e9tricas clave. Este modelo es escalable y adaptable a m\u00faltiples casos de uso anal\u00edtico.</p>"},{"location":"01.scripts/01.Transversal/","title":"01. Transversal","text":""},{"location":"01.scripts/01.Transversal/#documentacion-del-esquema-transversal-en-sql","title":"Documentaci\u00f3n del Esquema <code>Transversal</code> en SQL","text":""},{"location":"01.scripts/01.Transversal/#1-introduccion","title":"1. Introducci\u00f3n","text":"<p>El esquema <code>Transversal</code> es un componente cr\u00edtico de un Data Warehouse (DWH) dise\u00f1ado para integrar datos de m\u00faltiples fuentes y facilitar an\u00e1lisis multidimensionales. Este manual detalla su estructura, tablas, relaciones y buenas pr\u00e1cticas.</p>"},{"location":"01.scripts/01.Transversal/#2-objetivos-del-esquema","title":"2. Objetivos del Esquema","text":"<ul> <li>Integraci\u00f3n: Consolidar datos de empresas, afiliados, transacciones financieras, encuestas y m\u00e1s.</li> <li>An\u00e1lisis: Habilitar consultas complejas para m\u00e9tricas como aportes, presupuestos, satisfacci\u00f3n de usuarios y PQRS.</li> <li>Escalabilidad: Dise\u00f1o modular para incorporar nuevas tablas sin afectar la estructura existente.</li> </ul>"},{"location":"01.scripts/01.Transversal/#3-arquitectura-del-esquema","title":"3. Arquitectura del Esquema","text":""},{"location":"01.scripts/01.Transversal/#31-componentes-principales","title":"3.1. Componentes Principales","text":"<ul> <li>Tablas de Dimensiones (<code>DIM_*</code>): Almacenan entidades descriptivas (empresas, afiliados, cuentas contables).</li> <li>Tablas de Hechos (<code>FACT_*</code>): Registran eventos transaccionales (aportes, movimientos contables, encuestas).</li> <li>Relaciones: Claves for\u00e1neas para garantizar integridad referencial.</li> </ul>"},{"location":"01.scripts/01.Transversal/#32-diagrama-general","title":"3.2. Diagrama General","text":"<pre><code>erDiagram\n    DIM_EMPRESAS ||--o{ DIM_AFILIADOS : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ DIM_BENEFICIARIOS : \"ID_AFILIADO\"\n    DIM_EMPRESAS ||--o{ FACT_APORTES_SHR_DET : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ FACT_APORTES_SHR_DET : \"ID_AFILIADO\"\n    DIM_CUENTA_CONTABLE ||--o{ FACT_DETALLE_CONTABLE : \"ID_CUENTA\"\n    DIM_UNIDADES_ORGANIZATIVAS ||--o{ FACT_DETALLE_CONTABLE : \"ID_CEBE\"\n    DIM_UNIDAD ||--o{ FACT_ENCUESTAS : \"ID_UNIDAD\"</code></pre>"},{"location":"01.scripts/01.Transversal/#4-tablas-clave-y-descripcion-detallada","title":"4. Tablas Clave y Descripci\u00f3n Detallada","text":""},{"location":"01.scripts/01.Transversal/#41-dimensiones-principales","title":"4.1. Dimensiones Principales","text":""},{"location":"01.scripts/01.Transversal/#dim_empresas","title":"DIM_EMPRESAS","text":"<ul> <li>Prop\u00f3sito: Datos maestros de empresas aportantes.</li> <li>Columnas Relevantes:<ul> <li><code>ID_EMPRESA</code> (PK): Identificador \u00fanico.</li> <li><code>RAZON_SOCIAL</code>: Nombre legal.</li> <li><code>TIPO_DOCUMENTO</code>: NIT, CC, etc.</li> <li><code>ESTADO</code>: Activa, inactiva, retirada.</li> </ul> </li> <li>Relaciones: Relacionada con <code>DIM_AFILIADOS</code> y <code>FACT_APORTES_SHR_DET</code>.</li> </ul>"},{"location":"01.scripts/01.Transversal/#dim_afiliados","title":"DIM_AFILIADOS","text":"<ul> <li>Prop\u00f3sito: Informaci\u00f3n demogr\u00e1fica y laboral de afiliados.</li> <li>Columnas Relevantes:<ul> <li><code>ID_AFILIADO</code> (PK): Identificador \u00fanico.</li> <li><code>NOMBRE_COMPLETO</code>: Nombre del afiliado.</li> <li><code>FECHA_AFILIACION</code>: Fecha de registro en el sistema.</li> <li><code>ID_EMPRESA</code> (FK): Empresa asociada.</li> </ul> </li> <li>Relaciones: Vinculada a <code>DIM_BENEFICIARIOS</code> y <code>FACT_APORTES_SHR_DET</code>.</li> </ul>"},{"location":"01.scripts/01.Transversal/#dim_beneficiarios","title":"DIM_BENEFICIARIOS","text":"<ul> <li>Prop\u00f3sito: Beneficiarios vinculados a afiliados (familiares).</li> <li>Columnas Clave:<ul> <li><code>ID_BENEFICIARIO</code> (PK): Identificador \u00fanico.</li> <li><code>PARENTESCO</code>: Relaci\u00f3n con el afiliado (hijo, c\u00f3nyuge).</li> <li><code>ID_AFILIADO</code> (FK): Afiliado titular.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#42-tablas-de-hechos","title":"4.2. Tablas de Hechos","text":""},{"location":"01.scripts/01.Transversal/#fact_aportes_shr_det","title":"FACT_APORTES_SHR_DET","text":"<ul> <li>Prop\u00f3sito: Detalle de aportes financieros.</li> <li>M\u00e9tricas:<ul> <li><code>APORTE_NUEVO</code>: Monto del aporte.</li> <li><code>PERIODO</code>: Per\u00edodo contable (ej. <code>2023M01</code>).</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_EMPRESA</code> (FK): Empresa que realiza el aporte.</li> <li><code>ID_AFILIADO</code> (FK): Afiliado beneficiario.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#fact_detalle_contable","title":"FACT_DETALLE_CONTABLE","text":"<ul> <li>Prop\u00f3sito: Movimientos contables (ingresos, gastos).</li> <li>M\u00e9tricas:<ul> <li><code>IMPORTE</code>: Valor total de la transacci\u00f3n.</li> <li><code>INGRESOS_OPERACIONALES</code>: Ingresos core del negocio.</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_CUENTA</code> (FK): Cuenta contable (<code>DIM_CUENTA_CONTABLE</code>).</li> <li><code>ID_CEBE</code> (FK): Unidad organizativa (<code>DIM_UNIDADES_ORGANIZATIVAS</code>).</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#fact_encuestas","title":"FACT_ENCUESTAS","text":"<ul> <li>Prop\u00f3sito: Resultados de encuestas de satisfacci\u00f3n.</li> <li>M\u00e9tricas:<ul> <li><code>CALIFICACION</code>: Puntuaci\u00f3n del servicio (ej. 1-5).</li> <li><code>SERVICIO</code>: Tipo de servicio evaluado.</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_UNIDAD</code> (FK): Unidad responsable (<code>DIM_UNIDAD</code>).</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#5-relaciones-y-dependencias","title":"5. Relaciones y Dependencias","text":""},{"location":"01.scripts/01.Transversal/#51-reglas-de-integridad","title":"5.1. Reglas de Integridad","text":"<ul> <li>Claves For\u00e1neas: Todas las tablas de hechos incluyen FK a dimensiones.</li> <li>Valores por Defecto: <ul> <li><code>-1</code> para indicar \"No aplica\" o datos faltantes (ej. <code>ID_EMPRESA</code> en <code>FACT_ENCUESTAS</code>).</li> <li><code>20090101</code> para fechas m\u00ednimas (ej. <code>ID_FECHA</code> en <code>FACT_APORTES_SHR_DET</code>).</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#52-script","title":"5.2. Script","text":"<pre><code>USE DWH_COMFENALCO\nGO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- Eliminar restricciones de clave for\u00e1nea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Transversal')\nBEGIN\n    DROP SCHEMA Transversal;\nEND\nGO\n-- Crear el esquema Transversal\nCREATE SCHEMA Transversal;\nGO\n-- Crear DIM_EMPRESAS\nCREATE TABLE [Transversal].[DIM_EMPRESAS](\n    [ID_EMPRESA] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [RAZON_SOCIAL] [nvarchar](300) NULL,\n    [ID_ESTADO] [nvarchar](2) NULL,\n    [ESTADO] [nvarchar](40) NULL,\n    [ID_SECTOR] [nvarchar](2) NULL,\n    [SECTOR] [nvarchar](40) NULL,\n    [ID_CLASE] [nvarchar](2) NULL,\n    [CLASE] [nvarchar](40) NULL,\n    [ID_ACT_ECONOMICA] [nvarchar](4) NULL,\n    [ACT_ECONOMICA] [nvarchar](200) NULL,\n    [ES_NUEVO] [int] NULL,\n    [ID_TIPO_APORTANTE] [nvarchar](2) NULL,\n    [TIPO_APORTANTE] [nvarchar](40) NULL,\n    [FECHA_AFILIACION] [datetime] NULL,\n    [FECHA_FUNDACION] [nvarchar](50) NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_MOTIVO_RETIRO] [int] NULL,\n    [MOTIVO_RETIRO] [nvarchar](80) NULL,\n    [FECHA_DESDE] [datetime] NULL,\n    [FECHA_HASTA] [datetime] NULL,\n    [DIRECCION] [nvarchar](300) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [COD_CIUDAD] [nvarchar](5) NULL,\n    [NUMERO_PROCESO_SQL] [bigint] NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [ESTADOREGISTRO] [nvarchar](10) NULL,\n    [CORREO] [nvarchar](200) NULL,\n    [TIPO_PERSONA] [nvarchar](1) NULL,\n    [PRIMER_NOMBRE] [nvarchar](50) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](50) NULL,\n    [PRIMER_APELLIDO] [nvarchar](50) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](50) NULL,\n    [CONVENIO_LIB] [int] NULL,\n    [FECHA_PRIMER_APORTE] [int] NULL,\n    [DIGITO_VERIFICACON] [varchar](1) NULL,\n    [CAJA_COMPEN] [varchar](2) NULL,\n    [SITUACION_1429] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_1429] [nvarchar](10) NULL,\n    [SITUACION_590] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_590] [nvarchar](10) NULL,\n    [ORIGEN_EXTRACCION] [varchar](50) NULL,\n    CONSTRAINT [PK_DIM_EMPRESAS] PRIMARY KEY CLUSTERED ([ID_EMPRESA])\n) ON [PRIMARY]\nGO\n-- Crear DIM_AFILIADOS\nCREATE TABLE [Transversal].[DIM_AFILIADOS](\n    [ID_AFILIADO] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [NUMERO_DOCUMENTO] [nvarchar](20) NULL,\n    [NOMBRE_COMPLETO] [nvarchar](200) NULL,\n    [PRIMER_APELLIDO] [nvarchar](50) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](50) NULL,\n    [PRIMER_NOMBRE] [nvarchar](50) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](50) NULL,\n    [ID_TIPO_AFILIADO] [nvarchar](2) NULL,\n    [TIPO_AFILIADO] [varchar](80) NULL,\n    [ID_CATEGORIA] [nvarchar](2) NULL,\n    [CATEGORIA] [nvarchar](10) NULL,\n    [ID_ESTADO_AFILIACION] [nvarchar](4) NULL,\n    [ESTADO_AFILIACION] [nvarchar](40) NULL,\n    [FECHA_AFILIACION] [nvarchar](50) NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_MOTIVORETIRO] [nvarchar](2) NULL,\n    [MOTIVORETIRO] [nvarchar](50) NULL,\n    [ID_NIVEL_EDUCATIVO] [nvarchar](2) NULL,\n    [NIVEL_EDUCATIVO] [varchar](50) NULL,\n    [ID_GENERO] [nvarchar](2) NULL,\n    [GENERO] [varchar](20) NULL,\n    [ID_ORIENTACION_SEXUAL] [nvarchar](2) NULL,\n    [ORIENTACION_SEXUAL] [nvarchar](40) NULL,\n    [ID_ESTADO_CIVIL] [nvarchar](2) NULL,\n    [ESTADO_CIVIL] [nvarchar](40) NULL,\n    [COD_OCUPACION] [nvarchar](4) NULL,\n    [OCUPACION] [nvarchar](100) NULL,\n    [ID_PERTENENCIA_ETNICA] [nvarchar](2) NULL,\n    [PERTENENCIA_ETNICA] [nvarchar](100) NULL,\n    [ID_FACTOR_VULNERABILIDAD] [nvarchar](2) NULL,\n    [FACTOR_VULNERABILIDAD] [nvarchar](50) NULL,\n    [CONDICION_ESPECIAL] [nvarchar](2) NULL,\n    [FECHA_NACIMIENTO] [nvarchar](10) NULL,\n    [DIRECCION] [nvarchar](60) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [BARRIO] [nvarchar](40) NULL,\n    [ESTRATO] [nvarchar](2) NULL,\n    [ID_CIUDAD] [nvarchar](5) NULL,\n    [ID_AREA_GEOGRAFICA] [nvarchar](2) NULL,\n    [AREA_GEOGRAFICA] [nvarchar](10) NULL,\n    [CORREO] [nvarchar](250) NULL,\n    [SALARIO_BASICO] [nvarchar](50) NULL,\n    [ES_NUEVO] [nvarchar](50) NULL,\n    [TIPO_SALARIO] [nvarchar](50) NULL,\n    [HORAS_LAB_MENSUAL] [nvarchar](50) NULL,\n    [TIPO_APORTANTE] [nvarchar](50) NOT NULL,\n    [APORTANTE] [nvarchar](10) NULL,\n    [FEC_DESDE] [datetime] NULL,\n    [FEC_HASTA] [datetime] NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [ESTADOREGISTRO] [nvarchar](20) NULL,\n    [ID_RESGUARDO] [int] NULL,\n    [RESGUARDO] [varchar](100) NULL,\n    [COD_PAIS_RESIDENCIA] [int] NULL,\n    [PAIS_RESIDENCIA] [varchar](100) NULL,\n    [COD_MUN_LABOR_DANE] [varchar](5) NULL,\n    [AREA_GEOGRA_LABOR] [varchar](2) NULL,\n    [FECHA_INGRESO_EMPRESA] [varchar](50) NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [EMPRESA_PRINCIPAL] [varchar](1) NULL,\n    [VALOR_SALARIO_UVT] [numeric](18, 2) NULL,\n    [ID_CATEGORIA_UVT] [varchar](2) NULL,\n    [CATEGORIA_UVT] [varchar](10) NULL,\n CONSTRAINT [PK_DIM_AFILIADOS] PRIMARY KEY CLUSTERED \n(\n    [ID_AFILIADO] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, FILLFACTOR = 100, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY],\nCONSTRAINT [FK_DIM_AFILIADOS_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA])\n) ON [PRIMARY]\nGO\n-- Crear DIM_BENEFICIARIOS\nCREATE TABLE [Transversal].[DIM_BENEFICIARIOS](\n    [ID_BENEFICIARIO] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [TITULAR] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [NUMERO_DOCUMENTO] [nvarchar](20) NULL,\n    [NOMBRE_COMPLETO] [nvarchar](81) NULL,\n    [PRIMER_APELLIDO] [nvarchar](40) NOT NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](40) NULL,\n    [PRIMER_NOMBRE] [nvarchar](40) NOT NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](40) NULL,\n    [ID_PARENTESCO] [nvarchar](8) NULL,\n    [PARENTESCO] [varchar](50) NULL,\n    [FECHA_AFILIACION] [nvarchar](50) NOT NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_GENERO] [varchar](1) NOT NULL,\n    [GENERO] [varchar](9) NOT NULL,\n    [ID_NIVEL_EDUCATIVO] [nvarchar](2) NULL,\n    [NIVEL_EDUCATIVO] [nvarchar](50) NULL,\n    [ID_ESTADO_CIVIL] [nvarchar](2) NULL,\n    [ESTADO_CIVIL] [nvarchar](40) NULL,\n    [DISCAPACIDAD] [nvarchar](1) NULL,\n    [FECHA_NACIMIENTO] [datetime] NOT NULL,\n    [DIRECCION] [nvarchar](60) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [BARRIO] [nvarchar](40) NULL,\n    [ESTRATO] [nvarchar](2) NULL,\n    [ID_CIUDAD] [nvarchar](5) NULL,\n    [ID_AREA_GEOGRAFICA] [nvarchar](2) NULL,\n    [AREA_GEOGRAFICA] [nvarchar](10) NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](40) NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [ESTADOREGISTRO] [nvarchar](10) NULL,\n    [ID_PARENT_SAP] [nvarchar](10) NULL,\n    [PARENT_SAP] [nvarchar](30) NULL,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [APORTANTE] [nvarchar](10) NULL,\n    [TIPO_AFILIADO] [nvarchar](50) NOT NULL,\n    [TIPO_APORTANTE] [nvarchar](50) NOT NULL,\n    [FEC_DESDE] [datetime] NULL,\n    [FEC_HASTA] [datetime] NULL,\n    [ESTADO_BEN] [int] NULL,\n    [FECHA_INGRESO_EMPRESA] [varchar](50) NULL,\n CONSTRAINT [PK_DIM_BENENEFICIARIOS] PRIMARY KEY CLUSTERED \n(\n    [ID_BENEFICIARIO] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, FILLFACTOR = 100, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY],\nCONSTRAINT [FK_DIM_BENEFICIARIOS_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO])\n) ON [PRIMARY]\nGO\n-- Crear DIM_APORTANTE_NOAFILIADO\nCREATE TABLE [Transversal].[DIM_APORTANTE_NOAFILIADO](\n    [ID_APORTANTE] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [RAZON_SOCIAL] [nvarchar](300) NULL,\n    [ID_ESTADO] [nvarchar](2) NULL,\n    [ESTADO] [nvarchar](40) NULL,\n    [ID_SECTOR] [nvarchar](2) NULL,\n    [SECTOR] [nvarchar](40) NULL,\n    [ID_CLASE] [nvarchar](2) NULL,\n    [CLASE] [nvarchar](40) NULL,\n    [ID_ACT_ECONOMICA] [nvarchar](4) NULL,\n    [ACT_ECONOMICA] [nvarchar](200) NULL,\n    [ES_NUEVO] [int] NULL,\n    [ID_TIPO_APORTANTE] [nvarchar](2) NULL,\n    [TIPO_APORTANTE] [nvarchar](40) NULL,\n    [FECHA_AFILIACION] [datetime] NULL,\n    [FECHA_FUNDACION] [nvarchar](50) NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_MOTIVO_RETIRO] [int] NULL,\n    [MOTIVO_RETIRO] [nvarchar](80) NULL,\n    [FECHA_DESDE] [datetime] NULL,\n    [FECHA_HASTA] [datetime] NULL,\n    [DIRECCION] [nvarchar](300) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [COD_CIUDAD] [nvarchar](5) NULL,\n    [NUMERO_PROCESO_SQL] [bigint] NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [ESTADOREGISTRO] [nvarchar](10) NULL,\n    [CORREO] [nvarchar](200) NULL,\n    [TIPO_PERSONA] [nvarchar](1) NULL,\n    [PRIMER_NOMBRE] [nvarchar](50) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](50) NULL,\n    [PRIMER_APELLIDO] [nvarchar](50) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](50) NULL,\n    [CONVENIO_LIB] [int] NULL,\n    [FECHA_PRIMER_APORTE] [int] NULL,\n    [DIGITO_VERIFICACON] [varchar](1) NULL,\n    [CAJA_COMPEN] [varchar](2) NULL,\n    [SITUACION_1429] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_1429] [nvarchar](10) NULL,\n    [SITUACION_590] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_590] [nvarchar](10) NULL,\n    [FECHA_NACIMIENTO] [varchar](8) NULL,\n    [GENERO] [int] NULL,\n    CONSTRAINT [PK_DIM_APORTANTE_NOAFILIADO] PRIMARY KEY CLUSTERED ([ID_APORTANTE])\n) ON [PRIMARY]\nGO\n-- Crear FACT_APORTES_SHR_DET\nCREATE TABLE [Transversal].[FACT_APORTES_SHR_DET](\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [PERIODO] [varchar](10) NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [OPBEL] [varchar](50) NULL,\n    [BELNR] [varchar](50) NULL,\n    [MOVIMIENTO] [varchar](50) NULL,\n    [FECHA_CONTABLE] [int] NULL,\n    [NUM_CUENTA] [varchar](50) NULL,\n    [APORTE] [varchar](50) NULL,\n    [INTERES] [varchar](50) NULL,\n    [ESTADOREGISTRO] [varchar](50) NULL,\n    [FECHA_ACTUALIZACION] [datetime] NULL,\n    [DESDE] [datetime] NULL,\n    [HASTA] [datetime] NULL,\n    [PROCESO] [nvarchar](50) NULL,\n    [BP_EMPRESA] [varchar](10) NULL,\n    [BP_AFILIADO] [varchar](10) NULL,\n    [TIPO_APORTANTE] [int] NULL,\n    [SW_AJUSTE] [int] NULL,\n    [APORTE_NUEVO] [numeric](18, 0) NULL,\n    CONSTRAINT [FK_FACT_APORTES_SHR_DET_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_APORTES_SHR_DET_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_APORTES_SHR_DET_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n) ON [PRIMARY]\nGO\nALTER TABLE [Transversal].[FACT_APORTES_SHR_DET] ADD  DEFAULT ((0)) FOR [SW_AJUSTE]\nGO\nALTER TABLE [Transversal].[FACT_APORTES_SHR_DET] ADD  DEFAULT ((0)) FOR [APORTE_NUEVO]\nGO\nCREATE TABLE [Transversal].[DIM_CUENTA_CONTABLE](\n    [ID_CUENTA] [bigint] IDENTITY(1,1) NOT NULL,\n    [CUENTA_NUMERO] [bigint] NOT NULL,\n    [CUENTA] [nvarchar](10) NOT NULL,\n    [CUENTA_HOMOLOGA] [nvarchar](10) NOT NULL,\n    [DESCRIPCION] [nvarchar](50) NOT NULL,\n    [TIPO_CUENTA] [nvarchar](100) NOT NULL,\n    [TIPO_OPERACION] [nvarchar](100) NOT NULL,\n    [GRUPO_CUENTA] [nvarchar](100) NOT NULL,\n    [SUBGRUPO_CUENTA] [nvarchar](50) NOT NULL,\n    [GRUPO_OPERACION] [nvarchar](100) NOT NULL,\n    [FEC_PROCESO] [datetime] NOT NULL,\n    [UDATE] [datetime] NOT NULL,\n    [CUENTA_SSF] [int] NOT NULL,\n    [DESCRIPCION_SSF] [nvarchar](255) NOT NULL,\n    [CUENTA_DESCRIPCION]  AS (([CUENTA]+'-')+[DESCRIPCION]),\n    [CUENTA_DESCRIPCION_SSF]  AS ((rtrim(CONVERT([varchar],[CUENTA_SSF]))+'-')+[DESCRIPCION_SSF]),\n    [SIGNO_INGRESOS]  AS (case when [TIPO_CUENTA]='INGRESOS' then (1) else (0) end),\n    [NUMERO_PROCESO_SQL] [bigint] NOT NULL,\n    [CLASIFICACION] [int] NULL,\n    [USUARIO_PROCESO] [nvarchar](50) NOT NULL,\n    [ESTADO_REGISTRO] [nvarchar](10) NULL,\n    [NIVEL_1_TIPO_CUENTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(1))),\n    [DESC_NIVEL_1_TIPO_CUENTA]  AS ([TIPO_CUENTA]),\n    [NIVEL_2_TIPO_OPERAC]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(2))),\n    [DES_NIVEL_2_TIPO_OPERAC]  AS ([TIPO_OPERACION]),\n    [NIVEL_4_GRUPO_CTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(4))),\n    [DESC_NIVEL_4_GRUPO_CTA]  AS ([GRUPO_CUENTA]),\n    [NIVEL_6_SUBG_CTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(6))),\n    [DESC_NIVEL_6_SUBG_CTA]  AS ([SUBGRUPO_CUENTA]),\n    [NIVEL_8_GRUPO_OPERAC]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(8))),\n    [DESC_NIVEL_8_GRUPO_OPERAC]  AS ([GRUPO_OPERACION]),\n    [NIVEL_10_CUENTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(10))),\n    [DESC_NIVEL_10_CUENTA_NUMERO]  AS ([DESCRIPCION]),\n    [ID_CUENTA_AUXILIAR] AS ([ID_CUENTA]),\n CONSTRAINT [PK_DIM_CUENTA_CONTABLE] PRIMARY KEY CLUSTERED \n(\n    [ID_CUENTA] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY]\n) ON [PRIMARY]\nGO\n-- Crear DIM_UNIDAD\n CREATE TABLE [Transversal].[DIM_UNIDAD] (\n    [ID_UNIDAD] [int] IDENTITY(1,1) NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    CONSTRAINT [PK_DIM_UNIDAD] PRIMARY KEY CLUSTERED ([ID_UNIDAD])\n)\nGO\n-- Crear DIM_UNIDADES_ORGANIZATIVAS\nCREATE TABLE [Transversal].[DIM_UNIDADES_ORGANIZATIVAS](\n    [ID_CEBE] [bigint] NOT NULL,\n    [CEBE] [varchar](10) NOT NULL,\n    [DESCRIPCION_BREVE] [varchar](50) NOT NULL,\n    [DESCRIPCION_COMPLETA] [varchar](100) NOT NULL,\n    [CEBE_DESCRIPCION]  AS ((rtrim(CONVERT([char],[CEBE]))+'-')+[DESCRIPCION_COMPLETA]),\n    [DEPARTAMENTO] [varchar](100) NOT NULL,\n    [AREA] [varchar](100) NOT NULL,\n    [SUBAREA] [varchar](100) NOT NULL,\n    [SEGMENTO] [bigint] NOT NULL,\n    [DESCRIPCION_SEGMENTO] [varchar](50) NOT NULL,\n    [SEGMENTO_DESCRIPCION]  AS ((rtrim(CONVERT([char],[SEGMENTO]))+'-')+[DESCRIPCION_SEGMENTO]),\n    [CODIGO_SSF] [int] NOT NULL,\n    [NOMBRE_SSF] [varchar](100) NOT NULL,\n    [CODIGO_NOMBRE_SSF]  AS ((rtrim(CONVERT([char],[CODIGO_SSF]))+'-')+[NOMBRE_SSF]),\n    [UDATE] [smalldatetime] NOT NULL,\n    [NUMERO_PROCESO_SQL] [bigint] NOT NULL,\n    [FEC_PROCESO] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [GRUPO_CEBE] [varchar](50) NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n CONSTRAINT [PK__DIM_UNIDADES_ORGANIZATIVAS] PRIMARY KEY CLUSTERED \n(\n    [ID_CEBE] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY]\n) ON [PRIMARY]\nGO\nALTER TABLE [Transversal].[DIM_UNIDADES_ORGANIZATIVAS]  WITH NOCHECK ADD  CONSTRAINT [FK_DIM_UNIDADES_ORGANIZATIVAS_DIM_UNIDAD] FOREIGN KEY([ID_UNIDAD])\nREFERENCES [Transversal].[DIM_UNIDAD] ([ID_UNIDAD])\nGO\n-- FACT_DETALLE_CONTABLE\nCREATE TABLE [Transversal].[FACT_DETALLE_CONTABLE](\n    [ID_CEBE] [bigint] NOT NULL,\n    [ID_CUENTA] [bigint] NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [SEGMENT] [bigint] NOT NULL,\n    [IMPORTE] [decimal](28, 2),-- NOT NULL,\n    [INGRESOS] [decimal](28, 2) ,--NOT NULL,\n    [INGRESOS_OPERACIONALES] [decimal](28, 2),-- NOT NULL,\n    [GASTOS] [decimal](28, 2) ,--NOT NULL,\n    [GASTOS_OPERACIONALES] [decimal](28, 2),-- NOT NULL,\n    [GASTOS_OPERACIONALES_ADMIN] [decimal](28, 2),-- NOT NULL,\n    [RESULTADO_EJERCICIO] [decimal](28, 2),-- NOT NULL,\n    [COSTOS] [decimal](28, 2),-- NOT NULL,\n    [ACTIVO] [decimal](28, 2),-- NOT NULL,\n    [PASIVO] [decimal](28, 2),-- NOT NULL,\n    [PATRIMONIO] [decimal](28, 2),-- NOT NULL,\n    [GASTOS_CON_DISTRIBUCION] [decimal](28, 2),-- NOT NULL,\n    [GASTOS_SIN_DISTRIBUCION] [decimal](28, 2),-- NOT NULL,\n    [FECHA_REGISTRO_SAP] [datetime] NOT NULL,\n    [FECHA_PROCESO] [datetime] NOT NULL,\n    [USUARIO_PROCESO] [varchar](50) NOT NULL\n) ON [PRIMARY]\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_CUENTA_CONTABLE] FOREIGN KEY([ID_CUENTA])\nREFERENCES [Transversal].[DIM_CUENTA_CONTABLE] ([ID_CUENTA])\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE] CHECK CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_CUENTA_CONTABLE]\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_DETALLE_CONTABLE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA])\nREFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE] CHECK CONSTRAINT [FK_FACT_DETALLE_CONTABLE_Dim_TIEMPO]\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_UNIDADES_ORGANIZATIVAS] FOREIGN KEY([ID_CEBE])\nREFERENCES [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] ([ID_CEBE])\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE] CHECK CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_UNIDADES_ORGANIZATIVAS]\nGO\n\n-- Crear FACT_PRESUPUESTO\nCREATE TABLE [Transversal].[FACT_PRESUPUESTO](\n    [ID_CEBE] [bigint] NOT NULL,\n    [ID_CUENTA] [bigint] NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [ID_TIPO_PRESUPUESTO] [int] NOT NULL,\n    [SEGMENT] [bigint] NOT NULL,\n    [VALOR] [decimal](28, 2) NOT NULL,\n    [INGRESOS] [decimal](28, 2) NOT NULL,\n    [INGRESOS_OPERACIONALES] [decimal](28, 2) NOT NULL,\n    [GASTOS] [decimal](28, 2) NOT NULL,\n    [GASTOS_OPERACIONALES] [decimal](28, 2) NOT NULL,\n    [GASTOS_OPERACIONALES_ADMIN] [decimal](28, 2) NOT NULL,\n    [COSTOS] [decimal](28, 2) NOT NULL,\n    [GASTOS_CON_DISTRIBUCION] [decimal](28, 2) NOT NULL,\n    [GASTOS_SIN_DISTRIBUCION] [decimal](28, 2) NOT NULL,\n    [FECHA_PROCESO] [datetime] NOT NULL,\n    [USUARIO_PROCESO] [varchar](50) NOT NULL\n) ON [PRIMARY]\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_CUENTA_CONTABLE] FOREIGN KEY([ID_CUENTA])\nREFERENCES [Transversal].[DIM_CUENTA_CONTABLE] ([ID_CUENTA])\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO] CHECK CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_CUENTA_CONTABLE]\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_PRESUPUESTO_Dim_TIEMPO] FOREIGN KEY([ID_FECHA])\nREFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO] CHECK CONSTRAINT [FK_FACT_PRESUPUESTO_Dim_TIEMPO]\nGO\n\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_UNIDADES_ORGANIZATIVAS] FOREIGN KEY([ID_CEBE])\nREFERENCES [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] ([ID_CEBE])\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO] CHECK CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_UNIDADES_ORGANIZATIVAS]\nGO\n\n-- Crear DIM_SERVICIOS\n /*CREATE TABLE [Transversal].[DIM_SERVICIOS] (\n    [ID_SERVICIO] [int] IDENTITY(1,1) NOT NULL,\n    [SERVICIO] [nvarchar](40) NOT NULL,\n    [ID_UNIDAD] [int]  NOT NULL,\n    [CON_OBJETO_TARIFA] [nvarchar](40) NOT NULL,\n    [VAL_TARIFA] [decimal](28, 2) NOT NULL,\n    [COD_CATEGORIA] [nvarchar](40) NOT NULL,\n    [CATEGORIA] [nvarchar](40) NOT NULL,\n    [LINEA_INTERVENCION] [nvarchar](40),\n    [CUPOS_DISPONIBLES] [int] NOT NULL,\n    [ANIO_TARIFA] [varchar](10) NOT NULL,\n    [CIUDAD] [nvarchar](40) NOT NULL,\n    [ID_ESTABLECIMIENTO] [nvarchar](40) NOT NULL,\n    [NOMBRE_ESTABLECIMIENTO] [nvarchar](40) NOT NULL,\n    [SEDE_ESTABLECIMIENTO] [nvarchar](40) NOT NULL,\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](40) NOT NULL,\n    CONSTRAINT [PK_DIM_SERVICIOS] PRIMARY KEY CLUSTERED ([ID_SERVICIO]),\n    CONSTRAINT [FK_DIM_SERVICIOS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO*/\n\n-- Crear DIM_INFRAESTRUCTURA_CCF\n CREATE TABLE [Transversal].[DIM_INFRAESTRUCTURA_CCF] (\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](40) NOT NULL,\n    [DESCRIPCION] [nvarchar](40) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5,\n    CONSTRAINT [PK_DIM_INFRAESTRUCTURA_CCF] PRIMARY KEY CLUSTERED ([COD_INFRAESTRUCTURA_CCF]),\n    CONSTRAINT [FK_COD_INFRAESTRUCTURA_CCF_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO\n-- Crear DIM_CATEGORIA\n CREATE TABLE [Transversal].[DIM_CATEGORIA] (\n    [COD_CATEGORIA] [nvarchar](40) NOT NULL,\n    [DESCRIPCION] [nvarchar](40) NOT NULL,\n    CONSTRAINT [PK_DIM_CATEGORIA] PRIMARY KEY CLUSTERED ([COD_CATEGORIA])\n)\nGO\n\n-- Crear DIM_TARIFA_SERVICIOS\n CREATE TABLE [Transversal].[DIM_TARIFAS_SERVICIOS] (\n    [ID_TARIFA] [int] IDENTITY(1,1) NOT NULL,\n    [COD_SERVICIO] [int] NOT NULL,\n    [CON_OBJETO_TARIFA] [nvarchar](255) NOT NULL,\n    [COS_UNITARIO_CONCEPTO] [decimal](28, 2) NOT NULL,\n    [VAL_TARIFA] [decimal](28, 2) NOT NULL,\n    [COD_CATEGORIA] [nvarchar](40) NULL DEFAULT 3, -- Asignar valor por defecto de 3 categoria C,\n    [ANIO_TARIFA] [varchar](10) NOT NULL,\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](40) NOT NULL,\n    [ID_TARIFA_AUXILIAR] AS ( [ANIO_TARIFA] + '_' + [COD_INFRAESTRUCTURA_CCF] + '_' + CAST([COD_SERVICIO] AS NVARCHAR(10)) + '_' + [COD_CATEGORIA] ) PERSISTED,\n    CONSTRAINT [PK_DIM_TARIFA_SERVICIOS] PRIMARY KEY CLUSTERED ([ID_TARIFA]),\n    CONSTRAINT [FK_DIM_TARIFA_SERVICIOS_DIM_CATEGORIA] FOREIGN KEY ([COD_CATEGORIA]) REFERENCES [Transversal].[DIM_CATEGORIA]([COD_CATEGORIA]),\n    CONSTRAINT [FK_DIM_TARIFA_SERVICIOS_DIM_INFRAESTRUCTURA_CCF] FOREIGN KEY ([COD_INFRAESTRUCTURA_CCF]) REFERENCES [Transversal].[DIM_INFRAESTRUCTURA_CCF]([COD_INFRAESTRUCTURA_CCF])\n)\nGO\n\n-- Crear DIM_PERSONAL\n CREATE TABLE [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL] [int] IDENTITY(1,1) NOT NULL,\n    [COD_PERSONA_UNIDAD] [nvarchar](40),\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5,\n    [SERVICIO] [nvarchar](255),\n    [NOMBRE] [nvarchar](255),\n    [TELEFONO] [nvarchar](40),\n    [CELULAR] [nvarchar](40),\n    [CORREO] [nvarchar](255),\n    [DIRECCION] [nvarchar](300),\n    [CIUDAD] [nvarchar](255),\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [FECHA_NACIMIENTO] [datetime],\n    [GENERO] [nvarchar](40),\n    [HORAS_CONTRATADAS_MENSUAL] [decimal](18, 2) ,\n    [HORAS_CONTRATADAS_TOTALES] [decimal](18, 2) ,\n    [VALOR_TOTAL] [decimal](18, 2) ,\n    [TIPO_CONTRATACION] [nvarchar](40),\n    [FECHA_INICIO_CONTRATACION] [datetime],\n    [FECHA_FIN_CONTRATACION] [datetime],\n    [CAUSA_TERMINACION_CONTRATO] [nvarchar](40),\n    [PREGRADO] [nvarchar](255),\n    [POSGRADO_ESPECIALIDAD] [nvarchar](255),\n    [POSGRADO_MAESTRIA] [nvarchar](255),\n    [POSGRADO_DOCTORADO] [nvarchar](255),\n    [NIVEL_INGLES] [nvarchar](40),\n    [AREA] [nvarchar](255),\n    CONSTRAINT [PK_DIM_PERSONAL] PRIMARY KEY CLUSTERED ([ID_PERSONAL]),\n    CONSTRAINT [FK_DIM_PERSONAL_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO\n-- Crear FACT_ENCUESTAS\n CREATE TABLE [Transversal].[FACT_ENCUESTAS] (\n    [ID_ENCUESTA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [FECHA_ENCUESTA] [datetime] NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](40),\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [PREGUNTA] [nvarchar](255) NOT NULL,\n    [SERVICIO] [nvarchar](40) NOT NULL,\n    [NPS] [nvarchar](40) NOT NULL,\n    [CALIFICACION] [nvarchar](255) NOT NULL,\n    CONSTRAINT [PK_FACT_ENCUESTAS] PRIMARY KEY CLUSTERED ([ID_ENCUESTA]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear FACT_ENCUESTAS_PSR\n CREATE TABLE [Transversal].[FACT_ENCUESTAS_PSR] (\n    [ID_ENCUESTA_PSR] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [FECHA_ENCUESTA] [datetime] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [PROGRAMA] [nvarchar](40) NOT NULL,\n    [ACTIVIDAD_PREGUNTA] [nvarchar](255) NOT NULL,\n    [CALIFICACION] [nvarchar](40) NOT NULL,\n    CONSTRAINT [PK_FACT_ENCUESTAS_PSR] PRIMARY KEY CLUSTERED ([ID_ENCUESTA_PSR]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear DIM_SEDES\n CREATE TABLE [Transversal].[DIM_SEDES] (\n    [ID_SEDE] [int] IDENTITY(1,1) NOT NULL,\n    [SEDE] [nvarchar](60),\n    CONSTRAINT [PK_DIM_SEDES] PRIMARY KEY CLUSTERED ([ID_SEDE])\n)\nGO\n-- Crear DIM_CAPACIDAD_FISICA\n CREATE TABLE [Transversal].[DIM_CAPACIDAD_FISICA] (\n    [ID_CAPACIDAD] [int] IDENTITY(1,1) NOT NULL,\n    [ID_SALON] [nvarchar](10) NOT NULL,\n    [CAPACIDAD] [int] NOT NULL,\n    [DESCRIPCION_ESPACIO] [nvarchar](255),\n    [JORNADA] [nvarchar](40),\n    [BLOQUE] [nvarchar](40),\n    [GRUPO] [nvarchar](40),\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [ID_SEDE] [int] NOT NULL,\n    [SEDE] [nvarchar](40),\n    [ESTADO] [nvarchar](40),\n    [FECHA_ESTADO] [datetime] NOT NULL,\n    [ID_CAPACIDAD_AUXILIAR] AS ( [ID_SALON] + '_' + [JORNADA] + '_' + CAST([ID_UNIDAD] AS NVARCHAR(10)) ) PERSISTED,\n    CONSTRAINT [PK_DIM_CAPACIDAD_FISICA] PRIMARY KEY CLUSTERED ([ID_CAPACIDAD]),\n    CONSTRAINT [FK_DIM_CAPACIDAD_FISICA_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_DIM_CAPACIDAD_FISICA_DIM_SEDES] FOREIGN KEY ([ID_SEDE]) REFERENCES [Transversal].[DIM_SEDES]([ID_SEDE])\n)\nGO\n\n\n-- Crear FACT_INICIATIVAS\n CREATE TABLE [Transversal].[FACT_INICIATIVAS] (\n    [ID_INICIATIVA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [FECHA_INICIO] [datetime] NOT NULL,\n    [FECHA_FIN] [datetime] NOT NULL,\n    [NOMBRE_INICIATIVA] [nvarchar](255),\n    [DESCRIPCION_INICIATIVA] [nvarchar](255),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_FACT_INICIATIVAS] PRIMARY KEY CLUSTERED ([ID_INICIATIVA]),\n    CONSTRAINT [FK_FACT_INICIATIVAS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_INICIATIVAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear FACT_PQRS\n CREATE TABLE [Transversal].[FACT_PQRS] (\n    [ID_PQR] [nvarchar](40) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [ASUNTO] [nvarchar](255),\n    [CREADO_POR] [nvarchar](255),\n    [ASIGNADO_A] [nvarchar](255),\n    [ESTADO] [nvarchar](40),\n    [TIPO_DOCUMENTO] [nvarchar](40),\n    [DOCUMENTO] [nvarchar](20),\n    [NOMBRE] [nvarchar](255),\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [FECHA_CREACION] [datetime] NOT NULL,\n    [FECHA_RESOLUCION] [datetime] NOT NULL,\n    [FECHA_VENCIMIENTO] [datetime] NOT NULL,\n    [EQUIPO] [nvarchar](40),\n    [UNIDAD] [nvarchar](255),\n    [PROGRAMA_INCIDENTE] [nvarchar](255),\n    [ID_CAUSA] [nvarchar](40),\n    [CAUSA] [nvarchar](40),\n    [TIPO_PQRS] [nvarchar](40),\n    [TIPO_RESOLUCION] [nvarchar](40),\n    [UBICACION] [nvarchar](255),\n    CONSTRAINT [PK_FACT_PQRS] PRIMARY KEY CLUSTERED ([ID_PQR]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE]),\n    CONSTRAINT [FK_FACT_PQRS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear FACT_CONVENIOS\n CREATE TABLE [Transversal].[FACT_CONVENIOS] (\n    [ID_CONVENIO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [ID_UNIDAD] [int],-- NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    [PROGRAMA] [nvarchar](40),\n    [NOMBRE_CONVENIO] [nvarchar](255),\n    [IDENTIFICACION_ACTO_CONVENIO] [nvarchar](255),\n    [ENTIDAD_CONVENIO] [nvarchar](255),\n    [COD_MUNICIPIO] [nvarchar](40),\n    [VALOR_CONVENIO] [decimal](28, 2) NOT NULL,\n    [APORTE_COMFENALCO] [nvarchar](40),\n    [ESTADO_CONVENIO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NOT NULL,\n    [FECHA_FIN] [datetime] NOT NULL,\n    CONSTRAINT [PK_FACT_CONVENIOS] PRIMARY KEY CLUSTERED ([ID_CONVENIO]),\n    --CONSTRAINT [FK_FACT_CONVENIOS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_CONVENIOS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\n\nGO\n-- Tablas para el cubo\nCREATE TABLE [Transversal].[FACT_MINERIA](\n    [BP] [nvarchar](20) NULL,\n    [ID_FECHA_MENSUAL] [int] NULL,\n    [ID_ANIO_ACADEMICO] [nvarchar](4) NULL,\n    [ID_UNIDAD] [int] NULL,\n    [FECHA_INICIAL] [datetime] NULL,\n    [FECHA_FINAL] [datetime] NULL,\n    [ACTIVIDAD] [nvarchar](100) NULL,\n    [TIEMPO_SEGUNDOS] [int] NULL,\n    [VALOR_PAGADO] [int] NULL,\n    [ID_CATEGORIA] [int] NULL,\n    [ID_CURSO] [int] NULL,\n    [ID_TIPO_ESTUDIANTE] [int] NULL,\n    [ID_PROGRAMA] [int] NULL DEFAULT -1\n) ON [PRIMARY]\nGO\nCREATE TABLE [Transversal].[DIM_TIEMPO_MENSUAL](\n    [ID_FECHA] [int] NULL,\n    [FECHA] [datetime] NULL,\n    [DESC_FECHA] [nvarchar](50) NULL,\n    [ID_SEMANA] [int] NULL,\n    [DESC_SEMANA] [nvarchar](50) NULL,\n    [ID_NO_MES] [int] NULL,\n    [DESC_NO_MES] [nvarchar](50) NULL,\n    [ID_MES] [int] NULL,\n    [DESC_MES] [nvarchar](50) NULL,\n    [DESC_MES_CORTA] [nvarchar](50) NULL,\n    [ID_BIMESTRE] [int] NULL,\n    [DESC_BIMESTRE] [nvarchar](50) NULL,\n    [ID_TRIMESTRE] [int] NULL,\n    [DESC_TRIMESTRE] [nvarchar](50) NULL,\n    [ID_CUATRIMESTRE] [int] NULL,\n    [DESC_CUATRIMESTRE] [nvarchar](50) NULL,\n    [ID_SEMESTRE] [int] NULL,\n    [DESC_SEMESTRE] [nvarchar](50) NULL,\n    [ID_ANIO] [int] NULL,\n    [ID_ANIO_ANT] [int] NULL,\n    [NUM_DIA_SEMANA] [int] NULL,\n    [FESTIVO] [int] NULL,\n    [FECHA_CORTA] [date] NULL\n) ON [PRIMARY]\nGO\nCREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_UNIDADES] (\n    ID_CURSO INT,\n    GRADO VARCHAR(255),\n    ID_UNIDAD INT,\n    CATEGORIA VARCHAR(255),\n    ID_PLAN_COBERTURA INT,\n    ID_ESTABLECIMIENTO_EDUCATIVO VARCHAR(255),\n    ID_PROGRAMA INT,\n    ID_FECHA_MENSUAL INT,\n    POBLACION_PROYECTADA INT,\n    ORIGEN VARCHAR(255),\n    ACTIVIDAD VARCHAR(255),\n    RESULTADO VARCHAR(255),\n    CATEGORIA_SABER11 VARCHAR(255),\n    CAUSA VARCHAR(255),\n    NUM_POBLACION INT,\n    CALIFICACION VARCHAR(255),\n    DOCUMENTOS_COMPLETOS VARCHAR(255),\n    NUM_ESTUDIANTES INT,\n    NUM_MAYOR_250 INT,\n    TEMATICA VARCHAR(255)\n)\nGO\n CREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_PERSONAL] (\n    ID_FECHA INT NULL,\n    ID_PERSONAL INT NULL,\n    NOMBRE NVARCHAR(255) ,\n    CONCEPTO NVARCHAR(50) NULL,\n    DESCRIPCION NVARCHAR(255) ,\n    FECHA_FIN DATETIME ,\n    HORAS_CONTRATADAS_MENSUAL INT ,\n    ID_UNIDAD INT\n)\nGO\nCREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA] (\n    ID_FECHA INT NULL,\n    ID_ANIO INT NULL,\n    ID_MES INT NULL,\n    ID_CEBE NVARCHAR(40) ,\n    CEBE NVARCHAR(20) NULL,\n    DESCRIPCION_CEBE NVARCHAR(255) NULL,\n    DEPARTAMENTO NVARCHAR(100) NULL,\n    AREA NVARCHAR(100) NULL,\n    SUBAREA NVARCHAR(150) NULL,\n    SEGMENTO NVARCHAR(40) \n    ,DESCRIPCION_SEGMENTO NVARCHAR(150)\n    ,CODIGO_SSF INT\n    ,NOMBRE_SSF NVARCHAR(150)\n    ,ID_CUENTA NVARCHAR(50)\n    ,CUENTA NVARCHAR(50)\n    ,CUENTA_HOMOLOGA NVARCHAR(50)\n    ,DESCRIPCION NVARCHAR(255)\n    ,TIPO_CUENTA NVARCHAR(255)\n    ,TIPO_OPERACION NVARCHAR(255)\n    ,GRUPO_CUENTA NVARCHAR(255)\n    ,SUBGRUPO_CUENTA NVARCHAR(255)\n    ,GRUPO_OPERACION NVARCHAR(255)\n    ,CUENTA_SSF NVARCHAR(255)\n    ,DESCRIPCION_SSF NVARCHAR(255)\n    ,CUENTA_DESCRIPCION NVARCHAR(255)\n    ,CUENTA_DESCRIPCION_SSF NVARCHAR(255)\n    ,SIGNO_INGRESOS INT\n    ,CLASIFICACION INT\n    ,SEGMENT NVARCHAR(40)\n    ,IMPORTE BIGINT\n    ,INGRESOS INT\n    ,INGRESOS_OPERACIONALES INT\n    ,GASTOS INT\n    ,GASTOS_OPERACIONALES INT\n    ,GASTOS_OPERACIONALES_ADMIN INT\n    ,RESULTADO_EJERCICIO INT\n    ,COSTOS INT\n    ,ACTIVO BIGINT\n    ,PASIVO INT\n    ,PATRIMONIO INT\n    ,GASTOS_CON_DISTRIBUCION INT\n    ,GASTOS_SIN_DISTRIBUCION INT\n    ,[ACTIVIDAD] [nvarchar](255) NULL\n    ,ID_UNIDAD INT\n)\nGO\n CREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE] (\n PERIODO_ACADEMICO NVARCHAR(50)\n,ID_UNIDAD INT\n,ID_PERSONAL INT NULL\n,NOMBRE_DOCENTE NVARCHAR(255)\n,CALIFICACION_DEFINITIVA NVARCHAR(50)\n, ID_FECHA INT NULL\n)\nGO\nCREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES] (\n    [ACTIVIDAD] NVARCHAR(255),\n    [ADEUDA] DECIMAL(18, 2) NULL,\n    [ANIO_ACADEMICO] INT NULL,\n    [CANTIDAD_MATERIAL] INT NULL,\n    [CALIFICACION] NVARCHAR(255) NULL,\n    [CAUSA] NVARCHAR(255) NULL,\n    [CATEGORIA_VENTA] NVARCHAR(255) NULL,\n    [COSTO] DECIMAL(18, 2) NULL,\n    [CURSO] NVARCHAR(255) NULL,\n    [DESCRIPCION] NVARCHAR(255) NULL,\n    [ESTADO] NVARCHAR(255) NULL,\n    [ESTADOREGISTRO] NVARCHAR(50),\n    [ESTADO_PAGO] NVARCHAR(255) NULL,\n    [ESTRATO] INT NULL,\n    [FECHA_AFILIACION] DATE NULL,\n    [FECHA_MENSUAL] DATE,\n    [FECHA_RETIRO] DATE NULL,\n    [FECHA_ADMISION] DATE NULL,\n    [ID_AFILIADO] INT NULL,\n    [ID_CATEGORIA] INT NULL,\n    [ID_CIUDAD] INT NULL,\n    [ID_CONCEPTO] INT NULL,\n    [ID_CURSO] INT NULL,\n    [ID_EMPRESA] INT NULL,\n    [ID_ESTADO_CIVIL] INT NULL,\n    [ID_ESTADO_GESTION] INT NULL,\n    [ID_FACTOR_VULNERABILIDAD] INT NULL,\n    [ID_FECHA] INT,\n    [ID_GENERO] INT NULL,\n    [ID_GRADO] INT NULL,\n    [ID_MATERIAL] INT NULL,\n    [ID_PERTENENCIA_ETNICA] INT NULL,\n    [ID_POBLACION] INT NULL,\n    [ID_PROGRAMA] INT NULL,\n    [ID_PREGUNTA] INT NULL,\n    [ID_TIPO_AFILIADO] INT NULL,\n    [ID_UNIDAD] INT NULL,\n    [NO_PRESTAMOS] INT NULL,\n    [NUMERO_APORTES] INT,\n    [PARTNER] NVARCHAR(50),\n    [PARTNER_AFILIADO] NVARCHAR(50) NULL,\n    [PARTNER_EMPRESA] NVARCHAR(50) NULL,\n    [RESPUESTA] NVARCHAR(255) NULL,\n    [SALARIO_BASICO] DECIMAL(18, 2) NULL,\n    [SERVICIO_TRANSPORTE] NVARCHAR(255) NULL,\n    [SUBSIDIO] DECIMAL(20, 2) NULL,\n    [TIPO_AFILIADO] NVARCHAR(255) NULL,\n    [TIPO_POBLACION] NVARCHAR(50),\n    [TOTAL_APORTES] DECIMAL(18, 2),\n    [VALOR_FACTURADO] DECIMAL(18, 2) NULL,\n    [VALOR_MATERIAL] DECIMAL(18, 2) NULL,\n    [VALOR_PAGADO] DECIMAL(18, 2) NULL,\n    [VALOR_PAGADO_SIN_IMP] DECIMAL(18, 2) NULL,\n    [POBLACION_EDUCACION] NVARCHAR(50) NULL,\n    [ID_PQR] [nvarchar](40) NULL DEFAULT -1,\n    [ESTADO_PQR] [nvarchar](40),\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1,\n    [CAUSA_PQR] [nvarchar](40),\n    [TIPO_PQRS] [nvarchar](40),\n    [ID_TARIFA] [int] NULL DEFAULT -1\n)\nGO\n\n-- Tabla DIM_GENERO\nCREATE TABLE [Transversal].[DIM_GENERO] (\n    [ID_GENERO] INT PRIMARY KEY,\n    [GENERO] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_GENERO] ([ID_GENERO], [GENERO])\nSELECT DISTINCT\n    [ID_GENERO],\n    [GENERO]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_ORIENTACION_SEXUAL\nCREATE TABLE [Transversal].[DIM_ORIENTACION_SEXUAL] (\n    [ID_ORIENTACION_SEXUAL] INT PRIMARY KEY,\n    [ORIENTACION_SEXUAL] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_ORIENTACION_SEXUAL] ([ID_ORIENTACION_SEXUAL], [ORIENTACION_SEXUAL])\nSELECT DISTINCT\n    [ID_ORIENTACION_SEXUAL],\n    [ORIENTACION_SEXUAL]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_ESTADO_CIVIL\nCREATE TABLE [Transversal].[DIM_ESTADO_CIVIL] (\n    [ID_ESTADO_CIVIL] INT PRIMARY KEY,\n    [ESTADO_CIVIL] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_ESTADO_CIVIL] ([ID_ESTADO_CIVIL], [ESTADO_CIVIL])\nSELECT DISTINCT\n    [ID_ESTADO_CIVIL],\n    [ESTADO_CIVIL]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_FACTOR_DE_VULNERABILIDAD\nCREATE TABLE [Transversal].[DIM_FACTOR_DE_VULNERABILIDAD] (\n    [ID_FACTOR_VULNERABILIDAD] INT PRIMARY KEY,\n    [FACTOR_VULNERABILIDAD] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_FACTOR_DE_VULNERABILIDAD] ([ID_FACTOR_VULNERABILIDAD], [FACTOR_VULNERABILIDAD])\nSELECT DISTINCT\n    [ID_FACTOR_VULNERABILIDAD],\n    [FACTOR_VULNERABILIDAD]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_PERTENENCIA_ETNICA\nCREATE TABLE [Transversal].[DIM_PERTENENCIA_ETNICA] (\n    [ID_PERTENENCIA_ETNICA] INT PRIMARY KEY,\n    [PERTENENCIA_ETNICA] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_PERTENENCIA_ETNICA] ([ID_PERTENENCIA_ETNICA], [PERTENENCIA_ETNICA])\nSELECT DISTINCT\n    [ID_PERTENENCIA_ETNICA]\n      ,[PERTENENCIA_ETNICA]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n</code></pre>"},{"location":"01.scripts/02.Cedesarrollo%20copy/","title":"Documentaci\u00f3n SQL para el Esquema <code>Cedesarrollo</code>","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL implementa el esquema <code>Cedesarrollo</code> dentro del Data Warehouse <code>DWH_COMFENALCO</code>. El modelo sigue las mejores pr\u00e1cticas de modelado dimensional, con tablas de dimensiones (<code>DIM</code>) y hechos (<code>FACT</code>) que permiten un an\u00e1lisis integral de datos relacionados con estudiantes, personal, programas acad\u00e9micos, y evaluaciones.</p>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li>Limpieza del Esquema:</li> <li> <p>Eliminaci\u00f3n de tablas, restricciones de claves for\u00e1neas y el esquema existente para asegurar una implementaci\u00f3n limpia.</p> </li> <li> <p>Creaci\u00f3n de un Modelo Dimensional:</p> </li> <li>Tablas de Dimensiones (<code>DIM</code>): Almacenan datos descriptivos y categorizados de estudiantes, programas, periodos acad\u00e9micos, etc.</li> <li> <p>Tablas de Hechos (<code>FACT</code>): Contienen m\u00e9tricas y relaciones con dimensiones, enfoc\u00e1ndose en datos transaccionales y anal\u00edticos.</p> </li> <li> <p>Integridad Referencial:</p> </li> <li>Relaciones estrictas mediante claves for\u00e1neas entre las dimensiones y los hechos.</li> </ol>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#tablas-dimensionales","title":"Tablas Dimensionales","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#1-dim_estudiantes","title":"1. DIM_ESTUDIANTES","text":"<p>Informaci\u00f3n b\u00e1sica de los estudiantes, como su tipo de documento y relaciones con otras dimensiones.</p> Columna Tipo Descripci\u00f3n <code>ID_ESTUDIANTE</code> <code>int</code> Identificador \u00fanico del estudiante. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento del estudiante. <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero de documento del estudiante. <code>ID_EMPRESA</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_EMPRESAS</code>. <code>ID_AFILIADO</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_AFILIADOS</code>."},{"location":"01.scripts/02.Cedesarrollo%20copy/#2-dim_periodo_academico","title":"2. DIM_PERIODO_ACADEMICO","text":"<p>Define los periodos acad\u00e9micos asociados a programas y estudiantes.</p> Columna Tipo Descripci\u00f3n <code>ID_PERIODO</code> <code>int</code> Identificador \u00fanico del periodo acad\u00e9mico. <code>PERIODO_ACADEMICO</code> <code>nvarchar</code> Descripci\u00f3n del periodo acad\u00e9mico. <code>FECHA_INICIO</code> <code>datetime</code> Fecha de inicio del periodo acad\u00e9mico. <code>FECHA_FIN</code> <code>datetime</code> Fecha de finalizaci\u00f3n del periodo acad\u00e9mico."},{"location":"01.scripts/02.Cedesarrollo%20copy/#3-dim_programa","title":"3. DIM_PROGRAMA","text":"<p>Programas acad\u00e9micos asociados a estudiantes.</p> Columna Tipo Descripci\u00f3n <code>ID_PROGRAMA</code> <code>int</code> Identificador \u00fanico del programa. <code>PROGRAMA</code> <code>nvarchar</code> Nombre del programa."},{"location":"01.scripts/02.Cedesarrollo%20copy/#tablas-de-hechos","title":"Tablas de Hechos","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#1-fact_notas","title":"1. FACT_NOTAS","text":"<p>Registra las notas de estudiantes por periodos acad\u00e9micos y m\u00f3dulos.</p> Columna Tipo Descripci\u00f3n <code>ID_NOTA</code> <code>int</code> Identificador \u00fanico de la nota. <code>ID_ESTUDIANTE</code> <code>int</code> Relaci\u00f3n con <code>DIM_ESTUDIANTES</code>. <code>ID_PERIODO</code> <code>int</code> Relaci\u00f3n con <code>DIM_PERIODO_ACADEMICO</code>. <code>PRIMER_CORTE</code> <code>decimal</code> Nota del primer corte. <code>SEGUNDO_CORTE</code> <code>decimal</code> Nota del segundo corte. <code>TERCER_CORTE</code> <code>decimal</code> Nota del tercer corte. <code>NOTA_FINAL</code> <code>decimal</code> Nota final acumulada."},{"location":"01.scripts/02.Cedesarrollo%20copy/#2-fact_horario","title":"2. FACT_HORARIO","text":"<p>Registra los horarios acad\u00e9micos por estudiante y m\u00f3dulo.</p> Columna Tipo Descripci\u00f3n <code>ID_HORARIO</code> <code>int</code> Identificador \u00fanico del horario. <code>ID_MODULO</code> <code>int</code> Relaci\u00f3n con <code>DIM_PLAN_CURRICULAR</code>. <code>ID_JORNADA</code> <code>int</code> Relaci\u00f3n con <code>DIM_JORNADA</code>. <code>DIA</code> <code>nvarchar</code> D\u00eda de la clase. <code>HORA_INICIO</code> <code>nvarchar</code> Hora de inicio de la clase. <code>HORA_FIN</code> <code>nvarchar</code> Hora de fin de la clase."},{"location":"01.scripts/02.Cedesarrollo%20copy/#relaciones-dimensionales-y-tablas-de-hechos","title":"Relaciones Dimensionales y Tablas de Hechos","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#diagrama-general-del-modelo","title":"Diagrama General del Modelo","text":"<pre><code>erDiagram\n    DIM_ESTUDIANTES {\n        int ID_ESTUDIANTE PK\n        nvarchar TIPO_DOCUMENTO\n        nvarchar DOCUMENTO\n    }\n\n    DIM_PROGRAMA {\n        int ID_PROGRAMA PK\n        nvarchar PROGRAMA\n    }\n\n    DIM_PERIODO_ACADEMICO {\n        int ID_PERIODO PK\n        nvarchar PERIODO_ACADEMICO\n        datetime FECHA_INICIO\n        datetime FECHA_FIN\n    }\n\n    DIM_JORNADA {\n        int ID_JORNADA PK\n        nvarchar JORNADA\n    }\n\n    DIM_PLAN_CURRICULAR {\n        int ID_MODULO PK\n        nvarchar MODULO\n    }\n\n    FACT_NOTAS {\n        int ID_NOTA PK\n        int ID_ESTUDIANTE FK\n        int ID_PERIODO FK\n        int ID_MODULO FK\n        decimal PRIMER_CORTE\n        decimal NOTA_FINAL\n    }\n\n    FACT_HORARIO {\n        int ID_HORARIO PK\n        int ID_PERIODO FK\n        int ID_MODULO FK\n        int ID_JORNADA FK\n    }\n\n    DIM_ESTUDIANTES ||--o{ FACT_NOTAS : \"ID_ESTUDIANTE\"\n    DIM_PERIODO_ACADEMICO ||--o{ FACT_NOTAS : \"ID_PERIODO\"\n    DIM_PLAN_CURRICULAR ||--o{ FACT_NOTAS : \"ID_MODULO\"\n    DIM_PLAN_CURRICULAR ||--o{ FACT_HORARIO : \"ID_MODULO\"\n    DIM_PERIODO_ACADEMICO ||--o{ FACT_HORARIO : \"ID_PERIODO\"\n    DIM_JORNADA ||--o{ FACT_HORARIO : \"ID_JORNADA\"</code></pre>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li>Integridad Referencial:</li> <li> <p>Uso de claves for\u00e1neas para mantener la consistencia entre dimensiones y hechos.</p> </li> <li> <p>Eficiencia del Modelo:</p> </li> <li>Modelado dimensional para facilitar consultas anal\u00edticas.</li> <li> <p>Separaci\u00f3n entre datos descriptivos (<code>DIM</code>) y m\u00e9tricas (<code>FACT</code>).</p> </li> <li> <p>Flexibilidad y Escalabilidad:</p> </li> <li> <p>Las tablas permiten agregar nuevas dimensiones y hechos sin afectar el esquema general.</p> </li> <li> <p>Normalizaci\u00f3n:</p> </li> <li>Uso de dimensiones comunes para evitar redundancia.</li> </ol>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#conclusion","title":"Conclusi\u00f3n","text":"<p>El esquema <code>Cedesarrollo</code> ofrece un modelo integral y escalable para gestionar datos acad\u00e9micos y administrativos en un entorno anal\u00edtico. La estructura permite un an\u00e1lisis detallado de estudiantes, programas y resultados acad\u00e9micos, con un dise\u00f1o flexible para futuros requerimientos.</p>"},{"location":"01.scripts/02.Cedesarrollo/","title":"02. Cedesarrollo","text":""},{"location":"01.scripts/02.Cedesarrollo/#documentacion-del-esquema-cedesarrollo","title":"Documentaci\u00f3n del Esquema <code>Cedesarrollo</code>","text":""},{"location":"01.scripts/02.Cedesarrollo/#1-proposito-del-esquema","title":"1. Prop\u00f3sito del Esquema","text":"<p>El esquema <code>Cedesarrollo</code> est\u00e1 dise\u00f1ado para gestionar datos acad\u00e9micos y operativos de una instituci\u00f3n educativa dentro de un Data Warehouse. Su estructura dimensional facilita el an\u00e1lisis de:</p> <ul> <li>Rendimiento acad\u00e9mico (notas, asistencia, deserci\u00f3n).</li> <li>Gesti\u00f3n docente (ausentismo, evaluaci\u00f3n de desempe\u00f1o).</li> <li>Procesos administrativos (matr\u00edculas, facturaci\u00f3n, horarios).</li> <li>Planificaci\u00f3n curricular (programas, m\u00f3dulos, jornadas).</li> </ul>"},{"location":"01.scripts/02.Cedesarrollo/#2-estructura-del-esquema","title":"2. Estructura del Esquema","text":""},{"location":"01.scripts/02.Cedesarrollo/#21-tablas-de-dimensiones-dim_","title":"2.1. Tablas de Dimensiones (<code>DIM_*</code>)","text":"Tabla Descripci\u00f3n Columnas Clave Relaciones DIM_ESTUDIANTES Registra estudiantes y sus v\u00ednculos con entidades externas (empresas, afiliados). <code>ID_ESTUDIANTE</code> (PK) <code>DIM_EMPRESAS</code>, <code>DIM_AFILIADOS</code>, <code>DIM_BENEFICIARIOS</code>, <code>DIM_APORTANTE_NOAFILIADO</code> DIM_PERIODO_ACADEMICO Define per\u00edodos acad\u00e9micos (ej. semestres). <code>ID_PERIODO</code> (PK) <code>DIM_UNIDAD</code> DIM_PROGRAMA Cataloga programas acad\u00e9micos ofrecidos. <code>ID_PROGRAMA</code> (PK) - DIM_JORNADA Jornadas disponibles (diurna, nocturna). <code>ID_JORNADA</code> (PK) - DIM_PLAN_CURRICULAR Detalla m\u00f3dulos/cursos de cada programa. <code>ID_MODULO</code> (PK) <code>DIM_PROGRAMA</code>"},{"location":"01.scripts/02.Cedesarrollo/#22-tablas-de-hechos-fact_","title":"2.2. Tablas de Hechos (<code>FACT_*</code>)","text":"Tabla Descripci\u00f3n M\u00e9tricas Principales Relaciones FACT_NOTAS Calificaciones por m\u00f3dulo y per\u00edodo. <code>PRIMER_CORTE</code>, <code>NOTA_FINAL</code> <code>DIM_ESTUDIANTES</code>, <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PLAN_CURRICULAR</code> FACT_HORARIO Horarios de clases. <code>HORA_INICIO</code>, <code>HORA_FIN</code> <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_JORNADA</code> FACT_AUSENTISMO_DOCENTE Ausencias del personal docente. <code>AUSENCIA_HORAS</code>, <code>TIPO_AUSENCIA</code> <code>DIM_PERSONAL</code>, <code>DIM_PERIODO_ACADEMICO</code> FACT_DESERCION Deserci\u00f3n estudiantil. <code>TIPO</code>, <code>CAUSA</code> <code>DIM_ESTUDIANTES</code>, <code>DIM_PERIODO_ACADEMICO</code> FACT_FACTURACION Transacciones financieras (matr\u00edculas, pagos). <code>VALOR_FACTURADO</code>, <code>ADEUDA</code> <code>DIM_TARIFAS_SERVICIOS</code> FACT_DESEMPENHO_DOCENTE_DE Evaluaci\u00f3n docente por estudiantes. <code>CALIFICACION</code> <code>DIM_PERSONAL</code>, <code>DIM_PERIODO_ACADEMICO</code>"},{"location":"01.scripts/02.Cedesarrollo/#3-diagrama-de-relaciones-clave","title":"3. Diagrama de Relaciones Clave","text":"<pre><code>erDiagram\n    DIM_ESTUDIANTES ||--o{ FACT_NOTAS : \"ID_ESTUDIANTE\"\n    DIM_PERIODO_ACADEMICO ||--o{ FACT_NOTAS : \"ID_PERIODO\"\n    DIM_PLAN_CURRICULAR ||--o{ FACT_NOTAS : \"ID_MODULO\"\n    DIM_JORNADA ||--o{ FACT_HORARIO : \"ID_JORNADA\"\n    DIM_PROGRAMA ||--o{ DIM_PLAN_CURRICULAR : \"ID_PROGRAMA\"\n    DIM_PERSONAL ||--o{ FACT_AUSENTISMO_DOCENTE : \"ID_PERSONAL\"</code></pre>"},{"location":"01.scripts/02.Cedesarrollo/#4-buenas-practicas-implementadas","title":"4. Buenas Pr\u00e1cticas Implementadas","text":"<ul> <li>Valores por Defecto: <ul> <li><code>-1</code> para claves for\u00e1neas no definidas (ej. <code>ID_EMPRESA</code> en <code>DIM_ESTUDIANTES</code>).</li> <li>Registro <code>ID_ESTUDIANTE = -1</code> para casos de datos faltantes.</li> </ul> </li> <li>Integridad Referencial: <ul> <li>Claves for\u00e1neas en todas las tablas de hechos.</li> <li>Eliminaci\u00f3n segura del esquema previo (<code>DROP</code> de constraints antes de tablas).</li> </ul> </li> <li>Normalizaci\u00f3n: <ul> <li>Separaci\u00f3n clara entre dimensiones (entidades est\u00e1ticas) y hechos (eventos din\u00e1micos).</li> </ul> </li> </ul>"},{"location":"01.scripts/02.Cedesarrollo/#5-script","title":"5. Script","text":"<pre><code>USE DWH_COMFENALCO\nGO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- Eliminar restricciones de clave for\u00e1nea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Cedesarrollo';\nEXEC sp_executesql @sql;\n-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Cedesarrollo';\nEXEC sp_executesql @sql;\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Cedesarrollo')\nBEGIN\n    DROP SCHEMA Cedesarrollo;\nEND\nGO\n-- Crear el esquema Cedesarrollo\nCREATE SCHEMA Cedesarrollo;\nGO \n-- Crear Cedesarrollo.DIM_ESTUDIANTES\nCREATE TABLE [Cedesarrollo].[DIM_ESTUDIANTES] (\n    [ID_ESTUDIANTE] [int] IDENTITY(1,1) NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    CONSTRAINT [PK_DIM_ESTUDIANTES] PRIMARY KEY CLUSTERED ([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE])\n)\nGO\n-- Crear Cedesarrollo.DIM_PERIODO_ACADEMICO\nCREATE TABLE [Cedesarrollo].[DIM_PERIODO_ACADEMICO] (\n    [ID_PERIODO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [PERIODO_ACADEMICO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NULL, -- QUITE NOT\n    [FECHA_FIN] [datetime] NULL, -- QUITE NOT\n    CONSTRAINT [PK_DIM_PERIODO_ACADEMICO] PRIMARY KEY CLUSTERED ([ID_PERIODO]),\n    CONSTRAINT [FK_DIM_PERIODO_ACADEMICO_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO\n-- Crear Cedesarrollo.DIM_PROGRAMA\nCREATE TABLE [Cedesarrollo].[DIM_PROGRAMA] (\n    [ID_PROGRAMA] [int] IDENTITY(1,1) NOT NULL,\n    [PROGRAMA] [nvarchar](255)\n    CONSTRAINT [PK_DIM_PROGRAMA] PRIMARY KEY CLUSTERED ([ID_PROGRAMA])\n)\nGO\n\n-- Crear Cedesarrollo.DIM_JORNADA\nCREATE TABLE [Cedesarrollo].[DIM_JORNADA] (\n    [ID_JORNADA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [JORNADA] [nvarchar](40),\n    CONSTRAINT [PK_DIM_JORNADA] PRIMARY KEY CLUSTERED ([ID_JORNADA])\n)\nGO\n\n-- Crear Cedesarrollo.DIM_PLAN_CURRICULAR\nCREATE TABLE [Cedesarrollo].[DIM_PLAN_CURRICULAR] (\n    [ID_MODULO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PROGRAMA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [MODULO] [nvarchar](200), \n    --[ID_PERIODO] [int] NOT NULL,\n    [INTENSIDAD_HORARIA] [nvarchar](40),\n    [INTENSIDAD_HORARIA_SEMANAL] [nvarchar](40),\n    [NO_CREDITOS] [nvarchar](40),\n    [SEMESTRE] [nvarchar](40),\n    CONSTRAINT [PK_DIM_PLAN_CURRICULAR] PRIMARY KEY CLUSTERED ([ID_MODULO]),\n    CONSTRAINT [FK_DIM_PLAN_CURRICULAR_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_NOTAS\nCREATE TABLE [Cedesarrollo].[FACT_NOTAS] (\n    [ID_NOTA] [int] IDENTITY(1,1) NOT NULL,\n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NOT NULL,\n    [ID_MODULO] [int] NULL,  -- QUITE NULL\n    [CURSO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NULL, -- QUITE NULL\n    [ID_PERIODO] [int] NOT NULL,\n    --[PROGRAMA_ACADEMICO] [nvarchar](60),\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [FECHA_FIN] [datetime] NULL, -- QUITE NULL\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [NOMBRE_ESTUDIANTE] [nvarchar](200),\n    [PRIMER_CORTE] [decimal](10, 2),\n    [PRIMER_CORTE_CP1] [decimal](10, 2),\n    [PRIMER_CORTE_CP2] [decimal](10, 2),\n    [PRIMER_CORTE_CT1] [decimal](10, 2),\n    [PRIMER_CORTE_CT2] [decimal](10, 2),\n    [SEGUNDO_CORTE] [decimal](10, 2),\n    [SEGUNDO_CORTE_CP1] [decimal](10, 2),\n    [SEGUNDO_CORTE_CP2] [decimal](10, 2),\n    [SEGUNDO_CORTE_CT1] [decimal](10, 2),\n    [SEGUNDO_CORTE_CT2] [decimal](10, 2),\n    [TERCER_CORTE] [decimal](10, 2),\n    [TERCER_CORTE_CP1] [decimal](10, 2),\n    [TERCER_CORTE_CP2] [decimal](10, 2),\n    [TERCER_CORTE_CT1] [decimal](10, 2),\n    [TERCER_CORTE_CT2] [decimal](10, 2),\n    [NOTA_FINAL] [decimal](10, 2),\n    [PESO_CORTE] [decimal](10, 2),\n    CONSTRAINT [PK_FACT_NOTAS] PRIMARY KEY CLUSTERED ([ID_NOTA]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_PLAN_CURRICULAR] FOREIGN KEY ([ID_MODULO]) REFERENCES [Cedesarrollo].[DIM_PLAN_CURRICULAR]([ID_MODULO]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA])\n\n)\nGO\n\n-- Crear Cedesarrollo.FACT_HORARIO\nCREATE TABLE [Cedesarrollo].[FACT_HORARIO] (\n    [ID_HORARIO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [ID_MODULO] [int] NULL,\n    --[MODULO] [nvarchar](40),\n    [ID_JORNADA] [int] NULL,\n    --[JORNADA] [nvarchar](40),\n    [SEMESTRE] [nvarchar](40),\n    [GRUPO] [nvarchar](40),\n    [DIA] [nvarchar](40),\n    [SALON] [nvarchar](40),\n    [HORA_INICIO] [nvarchar](40),\n    [HORA_FIN] [nvarchar](40),\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [COD_ESTABLECIMIENTO] [nvarchar](40),\n    CONSTRAINT [PK_FACT_HORARIO] PRIMARY KEY CLUSTERED ([ID_HORARIO]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_PLAN_CURRICULAR] FOREIGN KEY ([ID_MODULO]) REFERENCES [Cedesarrollo].[DIM_PLAN_CURRICULAR]([ID_MODULO]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA])\n)\nGO\n\n\n\n-- Crear Cedesarrollo.FACT_AUSENTISMO_DOCENTE\nCREATE TABLE [Cedesarrollo].[FACT_AUSENTISMO_DOCENTE] (\n    [ID_AUSENTISMO_DOCENTE] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [FECHA] [datetime] NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [CARGO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NOT NULL,\n    [FECHA_FIN] [datetime] NOT NULL,\n    [AUSENCIA_HORAS] [nvarchar](40),\n    [AUSENCIA_DIAS] [nvarchar](40),\n    [TIPO_AUSENCIA] [nvarchar](40),\n    [PERMISO] [nvarchar](40),\n    [MOTIVO_AUSENCIA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_AUSENTISMO_DOCENTE] PRIMARY KEY CLUSTERED ([ID_AUSENTISMO_DOCENTE]),\n    CONSTRAINT [FK_FACT_AUSENTISMO_DOCENTE_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_AUSENTISMO_DOCENTE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_AUSENTISMO_DOCENTE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_PERMISO_ESTUDIANTE\nCREATE TABLE [Cedesarrollo].[FACT_PERMISO_ESTUDIANTE] (\n    [ID_PERMISO_ESTUDIANTE] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [MODULO] [nvarchar](40),\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [HORA] [nvarchar](40),\n    [MOTIVO_AUSENCIA] [nvarchar](40),\n    [SOPORTE_AUSENCIA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_PERMISO_ESTUDIANTE] PRIMARY KEY CLUSTERED ([ID_PERMISO_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_PERMISO_ESTUDIANTE_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_PERMISO_ESTUDIANTE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_PERMISO_ESTUDIANTE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_INASISTENCIAS\nCREATE TABLE [Cedesarrollo].[FACT_INASISTENCIAS] (\n    [ID_INASISTENCIAS] [int] IDENTITY(1,1) NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NOT NULL,\n    --[JORNADA] [nvarchar](40),\n    [ID_MODULO] [int] NULL, -- QUITE NOT\n    --[MODULO] [nvarchar](40),\n    [CURSO] [nvarchar](40) NULL,\n    [CORTE] [nvarchar](40) NULL,\n    [ID_FECHA] [int] NULL, -- QUITE NOT\n    [FECHA] [datetime] NULL, -- QUITE NOT\n    [HORA] [nvarchar](40) NULL,\n    [TOTAL_INASISTENCIA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_INASISTENCIAS] PRIMARY KEY CLUSTERED ([ID_INASISTENCIAS]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_PLAN_CURRICULAR] FOREIGN KEY ([ID_MODULO]) REFERENCES [Cedesarrollo].[DIM_PLAN_CURRICULAR]([ID_MODULO]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_DESERCION\nCREATE TABLE [Cedesarrollo].[FACT_DESERCION] (\n    [ID_DESERCION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL, /* NOT lo quite temporalmente ya que se llena posteriormente en la ETL*/\n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NULL, /* NOT lo quite temporalmente ya que se llena posteriormente en la ETL*/\n    --[JORNADA] [nvarchar](40),\n    --[PROGRAMA] [nvarchar](40),\n    [NOMBRE_ESTUDIANTE] [nvarchar](255),\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [GRUPO] [nvarchar](40),\n    --[MODULO] [nvarchar](40),\n    [SEMESTRE] [nvarchar](40),\n    [ID_FECHA] [int] NULL, /* NOT lo quite temporalmente*/\n    [FECHA] [datetime] NOT NULL,\n    [TIPO] [nvarchar](40),\n    [CAUSA] [nvarchar](40),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_FACT_DESERCION] PRIMARY KEY CLUSTERED ([ID_DESERCION]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_DESERCION_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_ESTADO_MATRICULAS\nCREATE TABLE [Cedesarrollo].[FACT_ESTADO_MATRICULAS] (\n    [ID_MATRICULA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL,\n    [ID_PROGRAMA] [int] NULL, -- QUITE NOT  \n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NULL, -- QUITE NOT  \n    --[JORNADA] [nvarchar](40),\n    [NOMBRE_ESTUDIANTE] [nvarchar](200),\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [ID_FECHA] [int] NULL, -- QUITE NOT  \n    [FECHA_MATRICULA] [datetime] NOT NULL,\n    [TELEFONO] [nvarchar](40),\n    [CELULAR] [nvarchar](40),\n    [CORREO] [nvarchar](200),\n    [FECHA_OPORTUNA] [datetime] NULL, -- QUITE NOT  \n    [FECHA_ACTUALIZACION] [datetime] NULL, -- QUITE NOT  \n    [DOCUMENTOS_COMPLETOS] [nvarchar](20) NULL, -- QUITE NOT  \n    [SEMESTRE] [nvarchar](40),\n    CONSTRAINT [PK_FACT_ESTADO_MATRICULAS] PRIMARY KEY CLUSTERED ([ID_MATRICULA]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_INSCRIPCION_MATRICULAS\nCREATE TABLE [Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] (\n    [ID_INSCRIPCION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL, -- QUITE NOT  \n    [ID_PROGRAMA] [int] NOT NULL,\n    --[TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    --[DOCUMENTO_ESTUDIANTE] [nvarchar](20) NOT NULL,\n    --[JORNADA] [nvarchar](40),\n    --[PROGRAMA] [nvarchar](40),\n    [ID_FECHA] [int] NULL, -- QUITE NOT  \n    [FECHA] [datetime] NOT NULL,\n    [ID_JORNADA] [int] NOT NULL,\n    [ESTADO] [nvarchar](40),\n    [TIPO_ESTUDIANTE] [nvarchar](40),\n    [CATEGORIA_COBERTURA] [nvarchar](40),\n    [CATEGORIA_SUBSIDIO] [nvarchar](40),\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    CONSTRAINT [PK_FACT_INSCRIPCION_MATRICULAS] PRIMARY KEY CLUSTERED ([ID_INSCRIPCION]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_FACTURACION\nCREATE TABLE [Cedesarrollo].[FACT_FACTURACION] (\n    [ID_FACTURACION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int]  NULL, -- NO HAY UN CAMPO ELEGIBLE\n    [TIPO_DOCUMENTO_PAGO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO_PAGO] [nvarchar](20) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA_CONTABLE] [datetime] NOT NULL,\n    [ID_TARIFA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_CONCEPTO] [int] NOT NULL,\n    [CONCEPTO] [nvarchar](255),\n    [VALOR_FACTURADO] [decimal](28, 2),\n    [SUBSIDIO] [decimal](28, 2),\n    [VALOR_PAGADO] [decimal](28, 2),\n    [ADEUDA] [nvarchar](40),\n    [ESTADO_PAGO] [nvarchar](40),\n    [FECHA_OPORTUNA_PAGO] [datetime] NULL,\n    [NO_RECIBO] [nvarchar](40),\n    [CATEGORIA] [nvarchar](40),\n    [FUENTE_RECURSOS] [nvarchar](40) NULL DEFAULT 'PROPIOS'\n    CONSTRAINT [PK_FACT_FACTURACION] PRIMARY KEY CLUSTERED ([ID_FACTURACION]),\n    --CONSTRAINT [FK_FACT_FACTURACION_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_FACTURACION_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear Cedesarrollo.DIM_PREGUNTAS_COTIZACION\nCREATE TABLE [Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] (\n    [ID_PREGUNTA] [int] IDENTITY(1,1) NOT NULL,\n    [PREGUNTA] [nvarchar](255),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_DIM_PREGUNTAS_COTIZACION] PRIMARY KEY CLUSTERED ([ID_PREGUNTA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_COTIZACIONES\nCREATE TABLE [Cedesarrollo].[FACT_COTIZACIONES] (\n    [ID_COTIZACION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA_REGISTRO] [datetime] NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [NOMBRE] [nvarchar](200),\n    [ID_TARIFA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ESTADO_COTIZACION] [nvarchar](40),\n    [ID_PREGUNTA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [RESPUESTA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_COTIZACIONES] PRIMARY KEY CLUSTERED ([ID_COTIZACION]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_DIM_PREGUNTAS_COTIZACION] FOREIGN KEY ([ID_PREGUNTA]) REFERENCES [Cedesarrollo].[DIM_PREGUNTAS_COTIZACION]([ID_PREGUNTA]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_DIM_TARIFAS_SERVICIOS] FOREIGN KEY ([ID_TARIFA]) REFERENCES [Transversal].[DIM_TARIFAS_SERVICIOS]([ID_TARIFA]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n\n-- Crear Cedesarrollo.FACT_PLAN_COBERTURA\nCREATE TABLE [Cedesarrollo].[FACT_PLAN_COBERTURA] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    [MODALIDAD] [nvarchar](40),\n    [CATEGORIA] [nvarchar](40),\n    [ID_PROGRAMA] [int] NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [USOS_PROYECTADOS] [nvarchar](40),\n    [USUARIOS_PROYECTADOS] [nvarchar](40),\n    CONSTRAINT [PK_FACT_PLAN_COBERTURA] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_PLAN_COBERTURA_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    --CONSTRAINT [FK_FACT_PLAN_COBERTURA_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE\nCREATE TABLE [Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_DE] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 3, -- Asignar valor por defecto de 3\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_PERIODO] [int] NOT NULL,\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [TIPO_DOCUMENTO_ENCUESTADO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO_ENCUESTADO] [nvarchar](20) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [PROGRAMA] [nvarchar](40),\n    [CALIFICACION] [nvarchar](40),\n    CONSTRAINT [PK_FACT_DESEMPENHO_DOCENTE_DE] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_DE_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_DE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_DE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE\nCREATE TABLE [Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_CE] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 2, -- Asignar valor por defecto de 2\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_PERIODO] [int] NOT NULL,\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [TIPO_CONTRATACION] [nvarchar](40),\n    [CALIFICACION_ESTUDIANTES] [nvarchar](40),\n    [CALIFICACION_UNIDAD] [nvarchar](40),\n    [CALIFICACION_DOCENTE] [nvarchar](40),\n    [CALIFICACION_DEFINITIVA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_DESEMPENHO_DOCENTE_CE] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_CE_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_CE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_GRADUADOS\nCREATE TABLE [Cedesarrollo].[FACT_GRADUADOS] (\n    [ID_GRADUADO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_JORNADA] [int] NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    [GRUPO] [nvarchar](40),\n    [ESTADO] [nvarchar](40),\n    [ZONA] [nvarchar](40),\n    [NIVEL_FORMACION] [nvarchar](40),\n    [OCUPACION] [nvarchar](40),\n    [SEDE] [nvarchar](255),\n    [JORNADA] [nvarchar](40),\n    [PROGRAMA] [nvarchar](255),\n    [SEMESTRE] [nvarchar](40),\n    [FECHA_ACTUALIZACION] [datetime] NOT NULL,\n    [FECHA_GRADUADO] [datetime] NOT NULL,\n    [ACTA_GRADUADO] [nvarchar](40),\n    [FOLIO_GRADUADO] [nvarchar](40),\n    [DIPLOMA_GRADUADO] [nvarchar](40),\n    CONSTRAINT [PK_FACT_GRADUADOS] PRIMARY KEY CLUSTERED ([ID_GRADUADO]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR\nCREATE TABLE [Cedesarrollo].[FACT_ASISTENCIA_ACT_BIENESTAR] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [ACTIVIDAD] [nvarchar](40),\n    [ASISTIO] [nvarchar](40),\n    CONSTRAINT [PK_FACT_ASISTENCIA_ACT_BIENESTAR] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_ASISTENCIA_ACT_BIENESTAR_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_ASISTENCIA_ACT_BIENESTAR_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_ASISTENCIA_ACT_BIENESTAR_DE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR\nCREATE TABLE [Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    [ID_PERIODO] [int] NOT NULL,\n    [CALIFICACION] [nvarchar](40),\n    [OBSERVACIONES] [nvarchar](40),\n    CONSTRAINT [PK_FACT_EVALUACION_PLAN_CURRICULAR] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_EVALUACION_PLAN_CURRICULAR_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_EVALUACION_FORMACION\nCREATE TABLE [Cedesarrollo].[FACT_EVALUACION_FORMACION] (\n    [ID_EVALUACION_FORMACION] [int] IDENTITY(1,1) NOT NULL,\n    [TIPO_DOCUMENTO_ENCUESTADO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO_ENCUESTADO] [nvarchar](20) NOT NULL,\n    [FECHA_REALIZACION_EVENTO] [datetime] NOT NULL,\n    [ASPECTO_1] [nvarchar](40),\n    [ASPECTO_2] [nvarchar](40),\n    [ASPECTO_3] [nvarchar](40),\n    [ASPECTO_4] [nvarchar](40),\n    [ASPECTO_5] [nvarchar](40),\n    [ASPECTO_6] [nvarchar](40),\n    [ASPECTO_7] [nvarchar](40),\n    [ASPECTO_8] [nvarchar](40),\n    [ASPECTO_9] [nvarchar](40),\n    CONSTRAINT [PK_FACT_EVALUACION_FORMACION] PRIMARY KEY CLUSTERED ([ID_EVALUACION_FORMACION]),\n)\nGO\n\n-- Disable identity insert to manually insert -1 in the identity column\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_ESTUDIANTES] ON;\n\nINSERT INTO [Cedesarrollo].[DIM_ESTUDIANTES] ([ID_ESTUDIANTE], [TIPO_DOCUMENTO], [DOCUMENTO], [ID_EMPRESA], [ID_AFILIADO], [ID_BENEFICIARIO], [ID_APORTANTE])\nVALUES (-1, 'N/A', 'N/A', -1, -1, -1, -1);\n\n-- Enable identity insert back\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_ESTUDIANTES] OFF;\n</code></pre>"},{"location":"01.scripts/03.Proteccion/","title":"Documentaci\u00f3n SQL para el Esquema <code>Protecci\u00f3n</code>","text":""},{"location":"01.scripts/03.Proteccion/#introduccion","title":"Introducci\u00f3n","text":"<p>El script SQL establece el esquema <code>Protecci\u00f3n</code> en el Data Warehouse <code>DWH_COMFENALCO</code>. Este esquema est\u00e1 dise\u00f1ado para gestionar informaci\u00f3n relacionada con poblaci\u00f3n, establecimientos educativos, programas, caracterizaci\u00f3n y actividades relacionadas con protecci\u00f3n y visitas.</p>"},{"location":"01.scripts/03.Proteccion/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li> <p>Limpieza del Esquema Existente:</p> <ul> <li>Elimina restricciones de claves for\u00e1neas, tablas y el esquema si ya existe, para permitir una implementaci\u00f3n limpia.</li> </ul> </li> <li> <p>Creaci\u00f3n de Estructuras Dimensionales:</p> <ul> <li>Tablas Dimensionales (<code>DIM</code>): Almacenan datos est\u00e1ticos o descriptivos relacionados con poblaci\u00f3n, programas, y caracter\u00edsticas.</li> <li>Tablas de Hechos (<code>FACT</code>): Contienen registros transaccionales y m\u00e9tricas relacionadas con actividades de protecci\u00f3n.</li> </ul> </li> <li> <p>Gesti\u00f3n de Integridad:</p> <ul> <li>Claves for\u00e1neas y primarias para garantizar relaciones consistentes entre dimensiones y hechos.</li> </ul> </li> </ol>"},{"location":"01.scripts/03.Proteccion/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/03.Proteccion/#tablas-dimensionales","title":"Tablas Dimensionales","text":""},{"location":"01.scripts/03.Proteccion/#1-dim_poblacion","title":"1. DIM_POBLACION","text":"<p>Contiene informaci\u00f3n b\u00e1sica de la poblaci\u00f3n objeto de an\u00e1lisis.</p> Columna Tipo Descripci\u00f3n <code>ID_POBLACION</code> <code>int</code> Identificador \u00fanico de la poblaci\u00f3n. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento de identidad. <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero de documento de identidad. <code>ID_EMPRESA</code> <code>int</code> Relaci\u00f3n con empresas en otros esquemas."},{"location":"01.scripts/03.Proteccion/#2-dim_establecimiento_educativo","title":"2. DIM_ESTABLECIMIENTO_EDUCATIVO","text":"<p>Informaci\u00f3n sobre los establecimientos educativos vinculados al sistema.</p> Columna Tipo Descripci\u00f3n <code>ID_ESTABLECIMIENTO_EDUCATIVO</code> <code>int</code> Identificador \u00fanico del establecimiento. <code>NOMBRE_ESTABLECIMIENTO</code> <code>nvarchar</code> Nombre del establecimiento. <code>DIRECCION</code> <code>nvarchar</code> Direcci\u00f3n del establecimiento. <code>COD_CIUDAD</code> <code>nvarchar</code> C\u00f3digo de la ciudad."},{"location":"01.scripts/03.Proteccion/#3-dim_programa","title":"3. DIM_PROGRAMA","text":"<p>Programas asociados a actividades de protecci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_PROGRAMA</code> <code>int</code> Identificador \u00fanico del programa. <code>PROGRAMA</code> <code>nvarchar</code> Nombre del programa."},{"location":"01.scripts/03.Proteccion/#4-dim_campos_caract","title":"4. DIM_CAMPOS_CARACT","text":"<p>Contiene las preguntas utilizadas en caracterizaciones.</p> Columna Tipo Descripci\u00f3n <code>ID_PREGUNTA</code> <code>int</code> Identificador \u00fanico de la pregunta. <code>PREGUNTA</code> <code>nvarchar</code> Texto de la pregunta. <code>OBSERVACIONES</code> <code>nvarchar</code> Observaciones relacionadas con la pregunta."},{"location":"01.scripts/03.Proteccion/#tablas-de-hechos","title":"Tablas de Hechos","text":""},{"location":"01.scripts/03.Proteccion/#1-fact_caracterizacion","title":"1. FACT_CARACTERIZACION","text":"<p>Registra las respuestas y observaciones relacionadas con la caracterizaci\u00f3n de la poblaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_CARACTERIZACION</code> <code>int</code> Identificador \u00fanico del registro de caracterizaci\u00f3n. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO</code>). <code>ID_POBLACION</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de poblaci\u00f3n. <code>ID_PROGRAMA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de programas. <code>RESPUESTA</code> <code>nvarchar</code> Respuesta de la caracterizaci\u00f3n."},{"location":"01.scripts/03.Proteccion/#2-fact_venta","title":"2. FACT_VENTA","text":"<p>Registro de ventas asociadas a servicios y poblaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_VENTA</code> <code>int</code> Identificador \u00fanico de la venta. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO</code>). <code>ID_POBLACION</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de poblaci\u00f3n. <code>ID_SERVICIO</code> <code>int</code> Relaci\u00f3n con servicios (<code>DIM_SERVICIOS</code>). <code>COSTO</code> <code>decimal</code> Costo asociado al servicio."},{"location":"01.scripts/03.Proteccion/#3-fact_desercion","title":"3. FACT_DESERCION","text":"<p>Registra casos de deserci\u00f3n en establecimientos educativos.</p> Columna Tipo Descripci\u00f3n <code>ID_REGISTRO</code> <code>int</code> Identificador \u00fanico del registro de deserci\u00f3n. <code>ID_ESTABLECIMIENTO_EDUCATIVO</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de establecimientos educativos. <code>ID_POBLACION</code> <code>int</code> Relaci\u00f3n con la poblaci\u00f3n. <code>ANIO_ACADEMICO</code> <code>nvarchar</code> A\u00f1o acad\u00e9mico de la deserci\u00f3n. <code>CAUSA</code> <code>nvarchar</code> Causa de la deserci\u00f3n."},{"location":"01.scripts/03.Proteccion/#relaciones-dimensionales-y-tablas-de-hechos","title":"Relaciones Dimensionales y Tablas de Hechos","text":""},{"location":"01.scripts/03.Proteccion/#diagrama-general-del-modelo","title":"Diagrama General del Modelo","text":"<pre><code>erDiagram\n    DIM_POBLACION {\n        int ID_POBLACION PK\n        nvarchar TIPO_DOCUMENTO\n        nvarchar DOCUMENTO\n    }\n\n    DIM_ESTABLECIMIENTO_EDUCATIVO {\n        int ID_ESTABLECIMIENTO_EDUCATIVO PK\n        nvarchar NOMBRE_ESTABLECIMIENTO\n    }\n\n    DIM_PROGRAMA {\n        int ID_PROGRAMA PK\n        nvarchar PROGRAMA\n    }\n\n    DIM_CAMPOS_CARACT {\n        int ID_PREGUNTA PK\n        nvarchar PREGUNTA\n    }\n\n    FACT_CARACTERIZACION {\n        int ID_CARACTERIZACION PK\n        int ID_POBLACION FK\n        int ID_PROGRAMA FK\n        int ID_FECHA FK\n    }\n\n    FACT_DESERCION {\n        int ID_REGISTRO PK\n        int ID_ESTABLECIMIENTO_EDUCATIVO FK\n        int ID_POBLACION FK\n        int ID_PROGRAMA FK\n    }\n\n    FACT_VENTA {\n        int ID_VENTA PK\n        int ID_POBLACION FK\n        int ID_SERVICIO FK\n        int ID_FECHA FK\n    }\n\n    DIM_POBLACION ||--o{ FACT_CARACTERIZACION : \"ID_POBLACION\"\n    DIM_PROGRAMA ||--o{ FACT_CARACTERIZACION : \"ID_PROGRAMA\"\n    DIM_ESTABLECIMIENTO_EDUCATIVO ||--o{ FACT_DESERCION : \"ID_ESTABLECIMIENTO_EDUCATIVO\"\n    DIM_POBLACION ||--o{ FACT_DESERCION : \"ID_POBLACION\"\n    DIM_PROGRAMA ||--o{ FACT_DESERCION : \"ID_PROGRAMA\"\n    DIM_POBLACION ||--o{ FACT_VENTA : \"ID_POBLACION\"\n    DIM_PROGRAMA ||--o{ FACT_VENTA : \"ID_SERVICIO\"</code></pre>"},{"location":"01.scripts/03.Proteccion/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li> <p>Modularidad:</p> <ul> <li>Separaci\u00f3n clara entre datos descriptivos (<code>DIM</code>) y registros transaccionales (<code>FACT</code>).</li> </ul> </li> <li> <p>Integridad Referencial:</p> <ul> <li>Uso de claves for\u00e1neas para garantizar la consistencia entre las tablas.</li> </ul> </li> <li> <p>Escalabilidad:</p> <ul> <li>Permite la adici\u00f3n de nuevas dimensiones y hechos sin impactar la estructura existente.</li> </ul> </li> <li> <p>Eficiencia:</p> <ul> <li>\u00cdndices primarios y relaciones bien definidas para optimizar las consultas.</li> </ul> </li> </ol>"},{"location":"01.scripts/03.Proteccion/#conclusion","title":"Conclusi\u00f3n","text":"<p>El esquema <code>Protecci\u00f3n</code> es una soluci\u00f3n integral para gestionar datos relacionados con actividades de protecci\u00f3n y caracterizaci\u00f3n. Su dise\u00f1o facilita el an\u00e1lisis y la generaci\u00f3n de reportes, asegurando integridad y eficiencia en el almacenamiento y consulta de datos.</p>"},{"location":"01.scripts/04.Colegio/","title":"Documentaci\u00f3n SQL para el Esquema <code>Colegio</code>","text":""},{"location":"01.scripts/04.Colegio/#introduccion","title":"Introducci\u00f3n","text":"<p>El script SQL crea un modelo de datos en el esquema <code>Colegio</code> dentro del Data Warehouse <code>DWH_COMFENALCO</code>. Este modelo est\u00e1 dise\u00f1ado para gestionar informaci\u00f3n educativa, incluyendo datos sobre matr\u00edcula, planes curriculares, evaluaciones, ausencias, bibliotecas, y resultados acad\u00e9micos.</p>"},{"location":"01.scripts/04.Colegio/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li> <p>Eliminaci\u00f3n de estructuras previas:</p> <ul> <li>Limpia el esquema <code>Colegio</code> eliminando tablas y claves for\u00e1neas existentes si ya est\u00e1n definidas.</li> </ul> </li> <li> <p>Creaci\u00f3n del esquema <code>Colegio</code>:</p> <ul> <li>Construcci\u00f3n de un modelo dimensional con tablas de hechos (<code>FACT</code>) y dimensiones (<code>DIM</code>) para representar datos educativos.</li> </ul> </li> <li> <p>Establecimiento de relaciones:</p> <ul> <li>Configuraci\u00f3n de claves for\u00e1neas para garantizar la integridad referencial y las conexiones l\u00f3gicas entre entidades.</li> </ul> </li> </ol>"},{"location":"01.scripts/04.Colegio/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/04.Colegio/#tablas-dimensionales-dim","title":"Tablas Dimensionales (<code>DIM</code>)","text":""},{"location":"01.scripts/04.Colegio/#1-dim_anio_academico","title":"1. DIM_ANIO_ACADEMICO","text":"<p>Registra los a\u00f1os acad\u00e9micos.</p> Columna Tipo Descripci\u00f3n <code>ANIO_ACADEMICO</code> <code>numeric(4,0)</code> A\u00f1o acad\u00e9mico (ejemplo: 2024)."},{"location":"01.scripts/04.Colegio/#2-dim_plan_curricular","title":"2. DIM_PLAN_CURRICULAR","text":"<p>Define las asignaturas ofrecidas en un curso espec\u00edfico.</p> Columna Tipo Descripci\u00f3n <code>ID_ASIGNATURA</code> <code>int</code> Identificador \u00fanico de la asignatura. <code>ID_CURSO</code> <code>int</code> Relaci\u00f3n con el curso. <code>ANIO_ACADEMICO</code> <code>numeric(4,0)</code> A\u00f1o acad\u00e9mico. <code>ASIGNATURA</code> <code>nvarchar</code> Nombre de la asignatura."},{"location":"01.scripts/04.Colegio/#3-dim_libros","title":"3. DIM_LIBROS","text":"<p>Informaci\u00f3n sobre libros disponibles en la biblioteca.</p> Columna Tipo Descripci\u00f3n <code>ID_LIBRO</code> <code>int</code> Identificador \u00fanico del libro. <code>NOMBRE_LIBRO</code> <code>nvarchar</code> T\u00edtulo del libro. <code>AUTOR</code> <code>nvarchar</code> Autor del libro."},{"location":"01.scripts/04.Colegio/#tablas-de-hechos-fact","title":"Tablas de Hechos (<code>FACT</code>)","text":""},{"location":"01.scripts/04.Colegio/#1-fact_legalizacion","title":"1. FACT_LEGALIZACION","text":"<p>Almacena informaci\u00f3n sobre procesos de legalizaci\u00f3n de instituciones educativas.</p> Columna Tipo Descripci\u00f3n <code>ID_LEGALIZACION</code> <code>int</code> Identificador \u00fanico del registro. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo. <code>RAZON_SOCIAL</code> <code>nvarchar</code> Raz\u00f3n social de la instituci\u00f3n educativa."},{"location":"01.scripts/04.Colegio/#2-fact_transporte","title":"2. FACT_TRANSPORTE","text":"<p>Gesti\u00f3n del uso del transporte escolar.</p> Columna Tipo Descripci\u00f3n <code>ID_REGISTRO</code> <code>int</code> Identificador \u00fanico del registro. <code>ID_POBLACION_MATRICULA</code> <code>int</code> Relaci\u00f3n con la poblaci\u00f3n matriculada. <code>ANIO_ACADEMICO</code> <code>numeric(4,0)</code> A\u00f1o acad\u00e9mico relacionado."},{"location":"01.scripts/04.Colegio/#3-fact_notas","title":"3. FACT_NOTAS","text":"<p>Registra las calificaciones de los estudiantes.</p> Columna Tipo Descripci\u00f3n <code>ID_NOTA</code> <code>int</code> Identificador \u00fanico de la nota. <code>ID_ASIGNATURA</code> <code>int</code> Relaci\u00f3n con la asignatura. <code>NOTA_FINAL</code> <code>decimal</code> Nota final obtenida por el estudiante."},{"location":"01.scripts/04.Colegio/#4-fact_biblioteca","title":"4. FACT_BIBLIOTECA","text":"<p>Registra pr\u00e9stamos de libros en la biblioteca.</p> Columna Tipo Descripci\u00f3n <code>ID_REGISTRO</code> <code>int</code> Identificador \u00fanico del registro. <code>ID_LIBRO</code> <code>int</code> Relaci\u00f3n con la tabla de libros. <code>FECHA_PRESTAMO</code> <code>datetime</code> Fecha en que se realiz\u00f3 el pr\u00e9stamo."},{"location":"01.scripts/04.Colegio/#relaciones-entre-tablas","title":"Relaciones entre Tablas","text":""},{"location":"01.scripts/04.Colegio/#diagrama-relacional","title":"Diagrama Relacional","text":"<pre><code>erDiagram\n    DIM_ANIO_ACADEMICO {\n        numeric ANIO_ACADEMICO PK\n    }\n\n    DIM_PLAN_CURRICULAR {\n        int ID_ASIGNATURA PK\n        int ID_CURSO FK\n        numeric ANIO_ACADEMICO FK\n    }\n\n    DIM_LIBROS {\n        int ID_LIBRO PK\n        nvarchar NOMBRE_LIBRO\n        nvarchar AUTOR\n    }\n\n    FACT_TRANSPORTE {\n        int ID_REGISTRO PK\n        int ID_POBLACION_MATRICULA FK\n        numeric ANIO_ACADEMICO FK\n    }\n\n    FACT_NOTAS {\n        int ID_NOTA PK\n        int ID_ASIGNATURA FK\n        decimal NOTA_FINAL\n    }\n\n    FACT_BIBLIOTECA {\n        int ID_REGISTRO PK\n        int ID_LIBRO FK\n        datetime FECHA_PRESTAMO\n    }\n\n    DIM_ANIO_ACADEMICO ||--o{ DIM_PLAN_CURRICULAR : AnioAcademico\n    DIM_PLAN_CURRICULAR ||--o{ FACT_NOTAS : Asignatura\n    DIM_LIBROS ||--o{ FACT_BIBLIOTECA : Libro</code></pre>"},{"location":"01.scripts/04.Colegio/#consideraciones-tecnicas","title":"Consideraciones T\u00e9cnicas","text":"<ol> <li> <p>Integridad Referencial:</p> <ul> <li>Uso de claves for\u00e1neas para relacionar hechos con dimensiones.</li> </ul> </li> <li> <p>Eficiencia:</p> <ul> <li>\u00cdndices primarios en todas las tablas para optimizar consultas.</li> </ul> </li> <li> <p>Escalabilidad:</p> <ul> <li>Modelo adaptable para incluir nuevas dimensiones y hechos.</li> </ul> </li> <li> <p>Separaci\u00f3n L\u00f3gica:</p> <ul> <li>Diferenciaci\u00f3n clara entre tablas de hechos y dimensiones para an\u00e1lisis OLAP.</li> </ul> </li> </ol>"},{"location":"01.scripts/04.Colegio/#conclusion","title":"Conclusi\u00f3n","text":"<p>El esquema <code>Colegio</code> proporciona una estructura robusta para almacenar y analizar datos relacionados con la gesti\u00f3n escolar, facilitando la generaci\u00f3n de reportes y an\u00e1lisis avanzados de rendimiento acad\u00e9mico, recursos educativos y actividades administrativas.</p>"},{"location":"01.scripts/05.Index/","title":"05.Index","text":""},{"location":"01.scripts/05.Index/#documentacion-sql-indices-para-el-esquema","title":"Documentaci\u00f3n SQL: \u00cdndices para el Esquema","text":""},{"location":"01.scripts/05.Index/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL define la creaci\u00f3n de \u00edndices no agrupados (<code>NONCLUSTERED</code>) para optimizar el rendimiento de las consultas en las tablas del esquema <code>Colegio</code> dentro del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"01.scripts/05.Index/#proposito-de-los-indices","title":"Prop\u00f3sito de los \u00cdndices","text":"<ol> <li> <p>Optimizaci\u00f3n de consultas:    Aceleraci\u00f3n de operaciones <code>SELECT</code> en columnas com\u00fanmente filtradas o buscadas.</p> </li> <li> <p>Integridad y organizaci\u00f3n:    Facilitar accesos r\u00e1pidos a los datos relacionados con fechas, poblaci\u00f3n matriculada, personal, entre otros.</p> </li> <li> <p>Mejoras en rendimiento general:    Disminuci\u00f3n de tiempos de respuesta en consultas anal\u00edticas.</p> </li> </ol>"},{"location":"01.scripts/05.Index/#indices-definidos","title":"\u00cdndices Definidos","text":""},{"location":"01.scripts/05.Index/#indices-por-tabla","title":"\u00cdndices por Tabla","text":""},{"location":"01.scripts/05.Index/#1-dim_anio_academico","title":"1. <code>DIM_ANIO_ACADEMICO</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_DIM_ANIO_ACADEMICO_ANIO</code> <code>ANIO_ACADEMICO</code> \u00cdndice \u00fanico para identificar a\u00f1os acad\u00e9micos."},{"location":"01.scripts/05.Index/#2-dim_plan_curricular","title":"2. <code>DIM_PLAN_CURRICULAR</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_DIM_PLAN_CURRICULAR_CURSO</code> <code>ID_CURSO</code> Filtrado r\u00e1pido por curso relacionado. <code>IX_DIM_PLAN_CURRICULAR_ANIO</code> <code>ANIO_ACADEMICO</code> Optimiza las consultas por a\u00f1o acad\u00e9mico."},{"location":"01.scripts/05.Index/#3-dim_libros","title":"3. <code>DIM_LIBROS</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_DIM_LIBROS_NOMBRE</code> <code>NOMBRE_LIBRO</code> B\u00fasquedas r\u00e1pidas por el nombre del libro."},{"location":"01.scripts/05.Index/#4-fact_legalizacion","title":"4. <code>FACT_LEGALIZACION</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_LEGALIZACION_FECHA</code> <code>ID_FECHA</code> Filtrado r\u00e1pido por fechas de registro. <code>IX_FACT_LEGALIZACION_DOCUMENTO</code> <code>DOCUMENTO_DE_IDENTIDAD</code> Identificaci\u00f3n \u00e1gil por documento."},{"location":"01.scripts/05.Index/#5-fact_transporte","title":"5. <code>FACT_TRANSPORTE</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_TRANSPORTE_FECHA</code> <code>ID_FECHA</code> Optimiza las b\u00fasquedas por fecha. <code>IX_FACT_TRANSPORTE_POBLACION</code> <code>ID_POBLACION_MATRICULA</code> Filtrado r\u00e1pido por poblaci\u00f3n matriculada."},{"location":"01.scripts/05.Index/#6-fact_reserva_espacios","title":"6. <code>FACT_RESERVA_ESPACIOS</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_RESERVA_ESPACIOS_FECHA</code> <code>ID_FECHA</code> Consultas eficientes por fecha. <code>IX_FACT_RESERVA_ESPACIOS_PERSONAL</code> <code>ID_PERSONAL</code> B\u00fasquedas r\u00e1pidas por personal."},{"location":"01.scripts/05.Index/#7-fact_enfermeria","title":"7. <code>FACT_ENFERMERIA</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_ENFERMERIA_FECHA</code> <code>ID_FECHA</code> Consultas eficientes por fecha. <code>IX_FACT_ENFERMERIA_POBLACION</code> <code>ID_POBLACION_MATRICULA</code> Filtrado r\u00e1pido por poblaci\u00f3n matriculada."},{"location":"01.scripts/05.Index/#8-fact_psicorientacion","title":"8. <code>FACT_PSICORIENTACION</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_PSICORIENTACION_FECHA</code> <code>ID_FECHA</code> Consultas eficientes por fecha. <code>IX_FACT_PSICORIENTACION_POBLACION</code> <code>ID_POBLACION_MATRICULA</code> Filtrado r\u00e1pido por poblaci\u00f3n matriculada."},{"location":"01.scripts/05.Index/#9-fact_notas","title":"9. <code>FACT_NOTAS</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_NOTAS_FECHA</code> <code>ID_FECHA</code> Optimiza consultas por fecha. <code>IX_FACT_NOTAS_POBLACION</code> <code>ID_POBLACION_MATRICULA</code> Filtrado r\u00e1pido por poblaci\u00f3n matriculada."},{"location":"01.scripts/05.Index/#10-fact_biblioteca","title":"10. <code>FACT_BIBLIOTECA</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_BIBLIOTECA_LIBRO</code> <code>ID_LIBRO</code> Consultas r\u00e1pidas por libros prestados."},{"location":"01.scripts/05.Index/#11-fact_desempenho_docente","title":"11. <code>FACT_DESEMPENHO_DOCENTE</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_DESEMPENHO_DOCENTE_PERSONAL</code> <code>ID_PERSONAL</code> Filtrado eficiente por docentes evaluados."},{"location":"01.scripts/06.Index_Cedesarrollo/","title":"06.Index Cedesarrollo","text":""},{"location":"01.scripts/06.Index_Cedesarrollo/#indices-cedesarrollo","title":"Indices Cedesarrollo","text":""},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_estudiantes","title":"DIM_ESTUDIANTES","text":"<ol> <li> <p>\u00cdndice \u00fanico no cl\u00faster en el campo <code>DOCUMENTO</code>:    Garantiza consultas r\u00e1pidas y \u00fanicas basadas en el n\u00famero de documento, generalmente usado para identificar estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_EMPRESA</code>:    Optimiza consultas relacionadas con empresas asociadas a los estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_AFILIADO</code>:    Mejora la eficiencia de las b\u00fasquedas relacionadas con afiliados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_BENEFICIARIO</code>:    Facilita las consultas relacionadas con beneficiarios de estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_APORTANTE</code>:    Aumenta la velocidad de las consultas que usan el campo de aportantes no afiliados.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster en <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Se orienta a optimizar b\u00fasquedas que combinen ambos campos, usados frecuentemente como filtro conjunto.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li>Eficiencia en consultas frecuentes: Los \u00edndices en campos individuales (<code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, etc.) y combinados (<code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>) aceleran las operaciones de b\u00fasqueda y filtros.</li> <li>Evitar redundancias: Los \u00edndices se dise\u00f1an para no replicar informaci\u00f3n ya cubierta por \u00edndices primarios o claves for\u00e1neas.</li> <li>Mejorar la unicidad: El \u00edndice \u00fanico en <code>DOCUMENTO</code> asegura que este campo no contenga duplicados, previniendo inconsistencias.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice \u00fanico no cl\u00faster en el campo DOCUMENTO\nCREATE UNIQUE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_DOCUMENTO\nON Cedesarrollo.DIM_ESTUDIANTES (DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_EMPRESA\nON Cedesarrollo.DIM_ESTUDIANTES (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_AFILIADO\nON Cedesarrollo.DIM_ESTUDIANTES (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_BENEFICIARIO\nON Cedesarrollo.DIM_ESTUDIANTES (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_APORTANTE\nON Cedesarrollo.DIM_ESTUDIANTES (ID_APORTANTE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster en TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_TIPO_DOCUMENTO_DOCUMENTO\nON Cedesarrollo.DIM_ESTUDIANTES (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_jornada","title":"DIM_JORNADA","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Optimiza las b\u00fasquedas y filtros relacionados con la unidad asociada a la jornada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>JORNADA</code>:    Facilita y acelera las consultas basadas en el nombre de la jornada, como b\u00fasquedas por texto.</p> </li> </ol> <p>**Justificaci\u00f3nDIM_JORNADA</p> <ul> <li><code>ID_UNIDAD</code>: Este campo es clave para unir esta tabla con otras que dependan de la identificaci\u00f3n de la unidad. Las b\u00fasquedas frecuentes en relaciones o filtros sobre unidades se beneficiar\u00e1n de este \u00edndice.</li> <li><code>JORNADA</code>: Usualmente, las consultas por nombre son comunes y al tratarse de un campo <code>nvarchar</code>, un \u00edndice espec\u00edfico mejora significativamente el rendimiento en b\u00fasquedas textuales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_JORNADA_ID_UNIDAD\nON Cedesarrollo.DIM_JORNADA (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo JORNADA\nCREATE NONCLUSTERED INDEX IX_DIM_JORNADA_NOMBRE\nON Cedesarrollo.DIM_JORNADA (JORNADA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_periodo_academico","title":"DIM_PERIODO_ACADEMICO","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Mejora el rendimiento de consultas relacionadas con las unidades asociadas a los per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>PERIODO_ACADEMICO</code>:    Optimiza b\u00fasquedas y filtros basados en el nombre o descripci\u00f3n del per\u00edodo acad\u00e9mico.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Dise\u00f1ado para acelerar consultas relacionadas con rangos de fechas, como per\u00edodos activos o hist\u00f3ricos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>: Este campo es clave en las relaciones con la tabla [DIM_UNIDAD]. Un \u00edndice en esta columna agiliza consultas de uni\u00f3n o b\u00fasquedas relacionadas.</li> <li><code>PERIODO_ACADEMICO</code>: Al tratarse de un campo descriptivo, puede usarse com\u00fanmente en filtros por texto, por lo que un \u00edndice acelera estas b\u00fasquedas.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Al ser campos utilizados frecuentemente para filtrar per\u00edodos dentro de un rango de tiempo, el \u00edndice compuesto asegura eficiencia en este tipo de consultas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_PERIODO_ACADEMICO_ID_UNIDAD\nON Cedesarrollo.DIM_PERIODO_ACADEMICO (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PERIODO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_DIM_PERIODO_ACADEMICO_NOMBRE\nON Cedesarrollo.DIM_PERIODO_ACADEMICO (PERIODO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_DIM_PERIODO_ACADEMICO_FECHAS\nON Cedesarrollo.DIM_PERIODO_ACADEMICO (FECHA_INICIO, FECHA_FIN);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_plan_curricular","title":"DIM_PLAN_CURRICULAR","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Mejora las consultas y uniones relacionadas con los programas a los que pertenece cada m\u00f3dulo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MODULO</code>:    Optimiza las b\u00fasquedas de m\u00f3dulos espec\u00edficos por su nombre o descripci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Facilita la recuperaci\u00f3n de datos agrupados o filtrados por semestre.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>INTENSIDAD_HORARIA</code> y <code>INTENSIDAD_HORARIA_SEMANAL</code>:    Acelera las consultas que involucren filtros o an\u00e1lisis relacionados con las intensidades horarias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PROGRAMA</code>: Este campo es clave en la relaci\u00f3n con [DIM_PROGRAMA] y es com\u00fanmente utilizado en uniones o filtros.</li> <li><code>MODULO</code>: Al ser descriptivo, es probable que se utilice para b\u00fasquedas directas o comparativas.</li> <li><code>SEMESTRE</code>: Las consultas que involucren planes curriculares por semestre se beneficiar\u00e1n del \u00edndice en este campo.</li> <li><code>INTENSIDAD_HORARIA</code> y <code>INTENSIDAD_HORARIA_SEMANAL</code>: Un \u00edndice compuesto en estos campos es \u00fatil para an\u00e1lisis o filtros relacionados con la carga horaria de los m\u00f3dulos.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_ID_PROGRAMA\nON Cedesarrollo.DIM_PLAN_CURRICULAR (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MODULO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_MODULO\nON Cedesarrollo.DIM_PLAN_CURRICULAR (MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_SEMESTRE\nON Cedesarrollo.DIM_PLAN_CURRICULAR (SEMESTRE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos INTENSIDAD_HORARIA y INTENSIDAD_HORARIA_SEMANAL\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_INTENSIDADES\nON Cedesarrollo.DIM_PLAN_CURRICULAR (INTENSIDAD_HORARIA, INTENSIDAD_HORARIA_SEMANAL);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_preguntas_cotizacion","title":"DIM_PREGUNTAS_COTIZACION","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>PREGUNTA</code>:    Facilita b\u00fasquedas y filtros basados en el texto de las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>OBSERVACIONES</code>:    Optimiza consultas que necesiten filtrar o analizar observaciones relacionadas con las preguntas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>PREGUNTA</code>: Este campo, al ser descriptivo, es probable que se utilice en consultas textuales para b\u00fasquedas directas o parciales de preguntas.</li> <li><code>OBSERVACIONES</code>: Aunque menos com\u00fan, este campo puede ser relevante en an\u00e1lisis que requieran obtener detalles adicionales relacionados con las preguntas, como comentarios o especificaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_COTIZACION_PREGUNTA\nON Cedesarrollo.DIM_PREGUNTAS_COTIZACION (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_COTIZACION_OBSERVACIONES\nON Cedesarrollo.DIM_PREGUNTAS_COTIZACION (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_programa","title":"DIM_PROGRAMA","text":"<ol> <li>\u00cdndice no cl\u00faster para el campo <code>PROGRAMA</code>:    Optimiza las b\u00fasquedas y filtros basados en el nombre o descripci\u00f3n del programa.</li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>PROGRAMA</code>: Al ser un campo descriptivo, es utilizado frecuentemente en b\u00fasquedas textuales o filtros para identificar programas espec\u00edficos.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PROGRAMA_NOMBRE\nON Cedesarrollo.DIM_PROGRAMA (PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_asistencia_act_bienestar","title":"FACT_ASISTENCIA_ACT_BIENESTAR","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza las consultas que involucren filtros o uniones basadas en fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora el rendimiento en consultas relacionadas con la asistencia de estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Dise\u00f1ado para b\u00fasquedas y filtros que combinen ambos campos como identificadores \u00fanicos del estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ACTIVIDAD</code>:    Facilita consultas y filtros basados en actividades espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ASISTIO</code>:    \u00datil para consultas relacionadas con el registro de asistencia.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>, <code>ID_ESTUDIANTE</code>, <code>ID_PERIODO</code>: Estos campos est\u00e1n com\u00fanmente relacionados con uniones y filtros en tablas de dimensi\u00f3n, optimizando las consultas frecuentes.</li> <li><code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>: Este \u00edndice compuesto permite b\u00fasquedas r\u00e1pidas utilizando estos identificadores \u00fanicos de los estudiantes.</li> <li><code>ACTIVIDAD</code> y <code>ASISTIO</code>: Estos \u00edndices optimizan an\u00e1lisis relacionados con las actividades y asistencia registrada en las mismas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ID_FECHA\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ID_ESTUDIANTE\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ID_PERIODO\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_TIPO_DOCUMENTO_DOCUMENTO\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ACTIVIDAD\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ACTIVIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ASISTIO\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ASISTIO\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ASISTIO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_ausentismo_docente","title":"FACT_AUSENTISMO_DOCENTE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora la eficiencia de las consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con el personal docente afectado por ausentismo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Dise\u00f1ado para mejorar el rendimiento en b\u00fasquedas por rangos de fechas relacionadas con ausencias.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO_AUSENCIA</code>:    Facilita consultas y an\u00e1lisis basados en el tipo de ausencia registrada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MOTIVO_AUSENCIA</code>:    Acelera consultas relacionadas con los motivos espec\u00edficos de las ausencias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_PERSONAL</code>, <code>ID_FECHA</code>: Estos campos son claves en uniones con tablas de dimensi\u00f3n y filtros comunes.</li> <li><code>FECHA_INICIO</code>, <code>FECHA_FIN</code>: Un \u00edndice compuesto en estos campos es crucial para b\u00fasquedas por rangos de fechas de ausencias.</li> <li><code>TIPO_AUSENCIA</code> y <code>MOTIVO_AUSENCIA</code>: Estos campos son \u00fatiles en an\u00e1lisis descriptivos o consultas sobre ausencias espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_PERIODO\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_PERSONAL\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_FECHA\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_FECHAS\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_TIPO_AUSENCIA\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (TIPO_AUSENCIA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_MOTIVO_AUSENCIA\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (MOTIVO_AUSENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_cotizaciones","title":"FACT_COTIZACIONES","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza las consultas basadas en fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Dise\u00f1ado para b\u00fasquedas r\u00e1pidas de cotizaciones basadas en la identificaci\u00f3n del estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora la eficiencia de consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_SERVICIO</code>:    Acelera consultas relacionadas con servicios espec\u00edficos asociados a las cotizaciones.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PREGUNTA</code>:    Facilita las b\u00fasquedas y an\u00e1lisis de cotizaciones basados en preguntas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO_COTIZACION</code>:    Mejora consultas relacionadas con los estados de las cotizaciones.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Campo clave en consultas basadas en tiempo y filtros por fechas.</li> <li><code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>: La identificaci\u00f3n compuesta de los estudiantes permite b\u00fasquedas precisas y r\u00e1pidas.</li> <li><code>ID_ESTUDIANTE</code>: Es esencial para relaciones y filtros basados en estudiantes espec\u00edficos.</li> <li><code>ID_SERVICIO</code>: Las consultas sobre servicios ofrecidos est\u00e1n directamente optimizadas con este \u00edndice.</li> <li><code>ID_PREGUNTA</code>: Facilita an\u00e1lisis espec\u00edficos relacionados con preguntas asociadas a cotizaciones.</li> <li><code>ESTADO_COTIZACION</code>: \u00datil para analizar y filtrar cotizaciones por sus estados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_FECHA\nON Cedesarrollo.FACT_COTIZACIONES (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_TIPO_DOCUMENTO_DOCUMENTO\nON Cedesarrollo.FACT_COTIZACIONES (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_ESTUDIANTE\nON Cedesarrollo.FACT_COTIZACIONES (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_SERVICIO\nON Cedesarrollo.FACT_COTIZACIONES (ID_SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_PREGUNTA\nON Cedesarrollo.FACT_COTIZACIONES (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO_COTIZACION\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ESTADO_COTIZACION\nON Cedesarrollo.FACT_COTIZACIONES (ESTADO_COTIZACION);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_desempenho_docente_ce","title":"FACT_DESEMPENHO_DOCENTE_CE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Mejora la eficiencia de consultas relacionadas con las unidades acad\u00e9micas asociadas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Optimiza las consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>CALIFICACION_ESTUDIANTES</code>, <code>CALIFICACION_UNIDAD</code> y <code>CALIFICACION_DOCENTE</code>:    Mejora el rendimiento en an\u00e1lisis relacionados con las calificaciones en los diferentes niveles.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO_CONTRATACION</code>:    Facilita las consultas basadas en el tipo de contrataci\u00f3n del personal docente.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>, <code>ID_PERSONAL</code>, <code>ID_PERIODO</code>: Estos campos son clave en uniones y filtros comunes en consultas relacionadas con dimensiones acad\u00e9micas y personal docente.</li> <li><code>CALIFICACION_ESTUDIANTES</code>, <code>CALIFICACION_UNIDAD</code>, <code>CALIFICACION_DOCENTE</code>: Este \u00edndice compuesto agiliza consultas anal\u00edticas y comparativas de calificaciones en diferentes categor\u00edas.</li> <li><code>TIPO_CONTRATACION</code>: \u00datil para an\u00e1lisis espec\u00edficos o filtros relacionados con las modalidades de contrataci\u00f3n.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_ID_UNIDAD\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_ID_PERSONAL\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_ID_PERIODO\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CALIFICACION_ESTUDIANTES, CALIFICACION_UNIDAD y CALIFICACION_DOCENTE\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_CALIFICACIONES\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (CALIFICACION_ESTUDIANTES, CALIFICACION_UNIDAD, CALIFICACION_DOCENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_CONTRATACION\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_TIPO_CONTRATACION\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (TIPO_CONTRATACION);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_desempenho_docente_de","title":"FACT_DESEMPENHO_DOCENTE_DE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Optimiza consultas relacionadas con las unidades acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Mejora b\u00fasquedas relacionadas con el desempe\u00f1o de docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>:    Optimiza b\u00fasquedas que combinen ambos campos para identificar encuestados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora el rendimiento en consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>PROGRAMA</code>:    Facilita b\u00fasquedas y an\u00e1lisis basados en programas acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CALIFICACION</code>:    Acelera consultas relacionadas con el an\u00e1lisis de calificaciones.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>, <code>ID_PERSONAL</code>, <code>ID_PERIODO</code>: Son claves en consultas relacionadas con las dimensiones acad\u00e9micas y personal docente.</li> <li><code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>: Un \u00edndice compuesto asegura b\u00fasquedas r\u00e1pidas y precisas de encuestados.</li> <li><code>ID_FECHA</code>: Este \u00edndice es esencial para optimizar consultas relacionadas con tiempo y filtros por fechas.</li> <li><code>PROGRAMA</code> y <code>CALIFICACION</code>: Estos \u00edndices mejoran el an\u00e1lisis y filtrado por programas y desempe\u00f1o en las evaluaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_UNIDAD\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_PERSONAL\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_PERIODO\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO_ENCUESTADO y DOCUMENTO_ENCUESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_DOCUMENTO_ENCUESTADO\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (TIPO_DOCUMENTO_ENCUESTADO, DOCUMENTO_ENCUESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_FECHA\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_PROGRAMA\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_CALIFICACION\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (CALIFICACION);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_desercion","title":"FACT_DESERCION","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera consultas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza el rendimiento en consultas basadas en fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO</code>:    Facilita consultas y an\u00e1lisis relacionados con el tipo de deserci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CAUSA</code>:    Acelera b\u00fasquedas relacionadas con las causas de deserci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Mejora consultas relacionadas con los semestres afectados por la deserci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_JORNADA</code>, <code>ID_ESTUDIANTE</code>, <code>ID_FECHA</code>: Estos campos son claves en consultas comunes relacionadas con per\u00edodos, jornadas, estudiantes y fechas.</li> <li><code>TIPO</code> y <code>CAUSA</code>: Son fundamentales para an\u00e1lisis descriptivos y consultas relacionadas con categor\u00edas de deserci\u00f3n.</li> <li><code>SEMESTRE</code>: Optimiza consultas espec\u00edficas sobre semestres impactados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_PERIODO\nON Cedesarrollo.FACT_DESERCION (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_JORNADA\nON Cedesarrollo.FACT_DESERCION (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_ESTUDIANTE\nON Cedesarrollo.FACT_DESERCION (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_FECHA\nON Cedesarrollo.FACT_DESERCION (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_TIPO\nON Cedesarrollo.FACT_DESERCION (TIPO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CAUSA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_CAUSA\nON Cedesarrollo.FACT_DESERCION (CAUSA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_SEMESTRE\nON Cedesarrollo.FACT_DESERCION (SEMESTRE);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_estado_matriculas","title":"FACT_ESTADO_MATRICULAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Optimiza las b\u00fasquedas relacionadas con programas acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera consultas basadas en jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Facilita b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora el rendimiento en consultas relacionadas con fechas de matr\u00edcula.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TELEFONO</code>, <code>CELULAR</code> y <code>CORREO</code>:    Acelera b\u00fasquedas o filtros relacionados con informaci\u00f3n de contacto.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Facilita consultas basadas en el semestre acad\u00e9mico.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>DOCUMENTOS_COMPLETOS</code>:    Mejora b\u00fasquedas relacionadas con el estado de documentaci\u00f3n de los estudiantes.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_PROGRAMA</code>, <code>ID_JORNADA</code>, <code>ID_ESTUDIANTE</code>, <code>ID_FECHA</code>: Campos clave para uniones y filtros en consultas frecuentes relacionadas con dimensiones acad\u00e9micas y estudiantes.</li> <li><code>TELEFONO</code>, <code>CELULAR</code>, <code>CORREO</code>: Facilitan an\u00e1lisis y consultas basadas en datos de contacto de los estudiantes.</li> <li><code>SEMESTRE</code> y <code>DOCUMENTOS_COMPLETOS</code>: Optimizan an\u00e1lisis espec\u00edficos de estado y organizaci\u00f3n acad\u00e9mica.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_PERIODO\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_PROGRAMA\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_JORNADA\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_FECHA\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TELEFONO, CELULAR y CORREO\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_CONTACTO\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (TELEFONO, CELULAR, CORREO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_SEMESTRE\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (SEMESTRE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTOS_COMPLETOS\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_DOCUMENTOS_COMPLETOS\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (DOCUMENTOS_COMPLETOS);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_evaluacion_formacion","title":"FACT_EVALUACION_FORMACION","text":"<ol> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>:    Mejora la eficiencia de b\u00fasquedas basadas en la identificaci\u00f3n del encuestado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_SERVICIO</code>:    Acelera consultas relacionadas con servicios espec\u00edficos evaluados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>FECHA_REALIZACION_EVENTO</code>:    Optimiza consultas basadas en la fecha de realizaci\u00f3n de los eventos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>ASPECTO_1</code> a <code>ASPECTO_9</code>:    Facilita an\u00e1lisis y b\u00fasquedas relacionadas con las evaluaciones de m\u00faltiples aspectos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>: Permiten identificar de manera eficiente al encuestado en consultas combinadas.</li> <li><code>ID_SERVICIO</code>: Es clave para filtrar o analizar evaluaciones basadas en servicios espec\u00edficos.</li> <li><code>FECHA_REALIZACION_EVENTO</code>: Facilita consultas relacionadas con el an\u00e1lisis temporal de las evaluaciones.</li> <li><code>ASPECTO_1</code> a <code>ASPECTO_9</code>: Estos campos son cr\u00edticos para an\u00e1lisis descriptivos y de calidad en evaluaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO_ENCUESTADO y DOCUMENTO_ENCUESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_DOCUMENTO_ENCUESTADO\nON Cedesarrollo.FACT_EVALUACION_FORMACION (TIPO_DOCUMENTO_ENCUESTADO, DOCUMENTO_ENCUESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_ID_SERVICIO\nON Cedesarrollo.FACT_EVALUACION_FORMACION (ID_SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_REALIZACION_EVENTO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_FECHA_REALIZACION_EVENTO\nON Cedesarrollo.FACT_EVALUACION_FORMACION (FECHA_REALIZACION_EVENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ASPECTO_1 a ASPECTO_9\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_ASPECTOS\nON Cedesarrollo.FACT_EVALUACION_FORMACION (ASPECTO_1, ASPECTO_2, ASPECTO_3, ASPECTO_4, ASPECTO_5, ASPECTO_6, ASPECTO_7, ASPECTO_8, ASPECTO_9);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_evaluacion_plan_curricular","title":"FACT_EVALUACION_PLAN_CURRICULAR","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Optimiza consultas relacionadas con unidades acad\u00e9micas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera b\u00fasquedas y an\u00e1lisis relacionados con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CALIFICACION</code>:    Mejora el rendimiento en consultas basadas en las calificaciones asignadas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>OBSERVACIONES</code>:    Facilita b\u00fasquedas relacionadas con comentarios o notas adicionales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>: Este \u00edndice es esencial para optimizar consultas relacionadas con la evaluaci\u00f3n de unidades acad\u00e9micas espec\u00edficas.</li> <li><code>ID_PERIODO</code>: Clave en an\u00e1lisis temporales y filtros basados en per\u00edodos acad\u00e9micos.</li> <li><code>CALIFICACION</code>: Facilita consultas relacionadas con m\u00e9tricas de desempe\u00f1o o an\u00e1lisis de resultados.</li> <li><code>OBSERVACIONES</code>: \u00datil para b\u00fasquedas y an\u00e1lisis de comentarios asociados con las evaluaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_ID_UNIDAD\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_ID_PERIODO\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_CALIFICACION\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (CALIFICACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_OBSERVACIONES\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_facturacion","title":"FACT_FACTURACION","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO_PAGO</code> y <code>DOCUMENTO_PAGO</code>:    Acelera b\u00fasquedas relacionadas con las identificaciones de los pagadores.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora consultas basadas en fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_SERVICIO</code>:    Facilita an\u00e1lisis relacionados con servicios facturados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_CONCEPTO</code>:    Optimiza consultas basadas en conceptos espec\u00edficos de facturaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO_PAGO</code>:    Mejora consultas relacionadas con el estado de los pagos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>NO_RECIBO</code>:    Facilita b\u00fasquedas espec\u00edficas por n\u00famero de recibo.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_FECHA</code>: Estos \u00edndices son esenciales para optimizar an\u00e1lisis temporales y b\u00fasquedas relacionadas con per\u00edodos y fechas espec\u00edficas.</li> <li><code>TIPO_DOCUMENTO_PAGO</code>, <code>DOCUMENTO_PAGO</code>: Permiten identificar de manera eficiente a los pagadores.</li> <li><code>ID_SERVICIO</code>, <code>ID_CONCEPTO</code>: Facilitan consultas espec\u00edficas sobre servicios y conceptos facturados.</li> <li><code>ESTADO_PAGO</code>, <code>NO_RECIBO</code>: Son claves para b\u00fasquedas relacionadas con el seguimiento de pagos y recibos.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_PERIODO\nON Cedesarrollo.FACT_FACTURACION (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO_PAGO y DOCUMENTO_PAGO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_DOCUMENTO_PAGO\nON Cedesarrollo.FACT_FACTURACION (TIPO_DOCUMENTO_PAGO, DOCUMENTO_PAGO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_FECHA\nON Cedesarrollo.FACT_FACTURACION (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_SERVICIO\nON Cedesarrollo.FACT_FACTURACION (ID_SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CONCEPTO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_CONCEPTO\nON Cedesarrollo.FACT_FACTURACION (ID_CONCEPTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO_PAGO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ESTADO_PAGO\nON Cedesarrollo.FACT_FACTURACION (ESTADO_PAGO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NO_RECIBO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_NO_RECIBO\nON Cedesarrollo.FACT_FACTURACION (NO_RECIBO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_graduados","title":"FACT_GRADUADOS","text":"<ol> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Optimiza b\u00fasquedas relacionadas con la identificaci\u00f3n de los graduados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Facilita b\u00fasquedas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Optimiza consultas basadas en programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>FECHA_GRADUADO</code>:    Mejora el rendimiento de consultas basadas en la fecha de graduaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO</code>:    Facilita an\u00e1lisis relacionados con el estado de los graduados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ZONA</code>:    Acelera b\u00fasquedas relacionadas con la zona geogr\u00e1fica de los graduados.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ID_ESTUDIANTE</code>: Claves esenciales para identificar y consultar informaci\u00f3n espec\u00edfica de los graduados.</li> <li><code>ID_PERIODO</code>, <code>ID_JORNADA</code>, <code>ID_PROGRAMA</code>: Estos \u00edndices optimizan consultas relacionadas con dimensiones acad\u00e9micas clave.</li> <li><code>FECHA_GRADUADO</code>: Facilita el an\u00e1lisis temporal de las graduaciones.</li> <li><code>ESTADO</code>, <code>ZONA</code>: Estos \u00edndices son \u00fatiles para an\u00e1lisis geogr\u00e1ficos y de estado del graduado.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_DOCUMENTO\nON Cedesarrollo.FACT_GRADUADOS (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_GRADUADOS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_PERIODO\nON Cedesarrollo.FACT_GRADUADOS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_JORNADA\nON Cedesarrollo.FACT_GRADUADOS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_PROGRAMA\nON Cedesarrollo.FACT_GRADUADOS (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_GRADUADO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_FECHA_GRADUADO\nON Cedesarrollo.FACT_GRADUADOS (FECHA_GRADUADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ESTADO\nON Cedesarrollo.FACT_GRADUADOS (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ZONA\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ZONA\nON Cedesarrollo.FACT_GRADUADOS (ZONA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_horario","title":"FACT_HORARIO","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora el rendimiento en consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_MODULO</code>:    Optimiza consultas relacionadas con m\u00f3dulos espec\u00edficos del plan curricular.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera b\u00fasquedas basadas en jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Facilita consultas relacionadas con docentes asignados al horario.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Optimiza an\u00e1lisis relacionados con horarios organizados por semestre.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>DIA</code>:    Mejora consultas relacionadas con horarios organizados por d\u00edas espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>HORA_INICIO</code> y <code>HORA_FIN</code>:    Facilita an\u00e1lisis y consultas basadas en intervalos horarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>COD_ESTABLECIMIENTO</code>:    Acelera b\u00fasquedas espec\u00edficas por c\u00f3digo de establecimiento.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_MODULO</code>, <code>ID_JORNADA</code>, <code>ID_PERSONAL</code>: Estos campos son claves para optimizar consultas relacionadas con dimensiones acad\u00e9micas y personal.</li> <li><code>SEMESTRE</code>, <code>DIA</code>: Facilitan el an\u00e1lisis de horarios basados en organizaci\u00f3n acad\u00e9mica y d\u00edas espec\u00edficos.</li> <li><code>HORA_INICIO</code>, <code>HORA_FIN</code>: Un \u00edndice compuesto en estos campos mejora an\u00e1lisis de intervalos horarios.</li> <li><code>COD_ESTABLECIMIENTO</code>: Este \u00edndice permite b\u00fasquedas eficientes en consultas relacionadas con ubicaciones espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_PERIODO\nON Cedesarrollo.FACT_HORARIO (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_MODULO\nON Cedesarrollo.FACT_HORARIO (ID_MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_JORNADA\nON Cedesarrollo.FACT_HORARIO (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_PERSONAL\nON Cedesarrollo.FACT_HORARIO (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_SEMESTRE\nON Cedesarrollo.FACT_HORARIO (SEMESTRE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DIA\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_DIA\nON Cedesarrollo.FACT_HORARIO (DIA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos HORA_INICIO y HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_HORAS\nON Cedesarrollo.FACT_HORARIO (HORA_INICIO, HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_ESTABLECIMIENTO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_COD_ESTABLECIMIENTO\nON Cedesarrollo.FACT_HORARIO (COD_ESTABLECIMIENTO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_inasistencias","title":"FACT_INASISTENCIAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Optimiza consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera b\u00fasquedas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>DOCUMENTO</code>:    Facilita b\u00fasquedas basadas en la identificaci\u00f3n del estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Mejora el rendimiento en consultas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_MODULO</code>:    Optimiza b\u00fasquedas relacionadas con m\u00f3dulos espec\u00edficos del plan curricular.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora el rendimiento en consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>CURSO</code> y <code>CORTE</code>:    Facilita an\u00e1lisis y b\u00fasquedas relacionadas con cursos y cortes acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TOTAL_INASISTENCIA</code>:    Optimiza an\u00e1lisis basados en la cantidad total de inasistencias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTUDIANTE</code>, <code>DOCUMENTO</code>, <code>ID_PERIODO</code>: Claves principales para identificar estudiantes y sus per\u00edodos relacionados con inasistencias.</li> <li><code>ID_JORNADA</code>, <code>ID_MODULO</code>, <code>ID_FECHA</code>: Campos clave para consultas relacionadas con dimensiones acad\u00e9micas y temporales.</li> <li><code>CURSO</code>, <code>CORTE</code>: Un \u00edndice compuesto facilita b\u00fasquedas organizadas por estructura acad\u00e9mica.</li> <li><code>TOTAL_INASISTENCIA</code>: Es clave para an\u00e1lisis y m\u00e9tricas sobre inasistencias totales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_INASISTENCIAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_PERIODO\nON Cedesarrollo.FACT_INASISTENCIAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_DOCUMENTO\nON Cedesarrollo.FACT_INASISTENCIAS (DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_JORNADA\nON Cedesarrollo.FACT_INASISTENCIAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_MODULO\nON Cedesarrollo.FACT_INASISTENCIAS (ID_MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_FECHA\nON Cedesarrollo.FACT_INASISTENCIAS (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CURSO y CORTE\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_CURSO_CORTE\nON Cedesarrollo.FACT_INASISTENCIAS (CURSO, CORTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TOTAL_INASISTENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_TOTAL_INASISTENCIA\nON Cedesarrollo.FACT_INASISTENCIAS (TOTAL_INASISTENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_inscripcion_matriculas","title":"FACT_INSCRIPCION_MATRICULAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora el rendimiento en consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Optimiza b\u00fasquedas relacionadas con programas acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Facilita an\u00e1lisis y b\u00fasquedas basadas en fechas de inscripci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Mejora consultas relacionadas con jornadas acad\u00e9micas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Acelera b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO</code>:    Facilita an\u00e1lisis y b\u00fasquedas relacionadas con el estado de las inscripciones.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO_ESTUDIANTE</code>:    Mejora el rendimiento de consultas basadas en las categor\u00edas de tipo de estudiante.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>CATEGORIA_COBERTURA</code> y <code>CATEGORIA_SUBSIDIO</code>:    Optimiza an\u00e1lisis y b\u00fasquedas relacionadas con la cobertura y subsidios.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_PROGRAMA</code>, <code>ID_FECHA</code>, <code>ID_JORNADA</code>, <code>ID_ESTUDIANTE</code>: Estos \u00edndices son claves para optimizar consultas frecuentes relacionadas con dimensiones acad\u00e9micas y temporales.</li> <li><code>ESTADO</code>, <code>TIPO_ESTUDIANTE</code>: Facilitan an\u00e1lisis descriptivos y filtros en el estado y tipo de estudiante inscrito.</li> <li><code>CATEGORIA_COBERTURA</code>, <code>CATEGORIA_SUBSIDIO</code>: Un \u00edndice compuesto mejora an\u00e1lisis detallados relacionados con subsidios y coberturas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_PERIODO\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_PROGRAMA\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_FECHA\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_JORNADA\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ESTADO\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_TIPO_ESTUDIANTE\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (TIPO_ESTUDIANTE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CATEGORIA_COBERTURA y CATEGORIA_SUBSIDIO\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_CATEGORIAS\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (CATEGORIA_COBERTURA, CATEGORIA_SUBSIDIO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_notas","title":"FACT_NOTAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera b\u00fasquedas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_MODULO</code>:    Optimiza consultas relacionadas con m\u00f3dulos del plan curricular.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora el rendimiento en consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Facilita an\u00e1lisis relacionados con docentes asignados a los cursos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Optimiza b\u00fasquedas basadas en intervalos temporales para analizar notas en per\u00edodos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>NOTA_FINAL</code>:    Mejora consultas relacionadas con an\u00e1lisis de desempe\u00f1o acad\u00e9mico.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>PRIMER_CORTE</code>, <code>SEGUNDO_CORTE</code> y <code>TERCER_CORTE</code>:    Facilita an\u00e1lisis detallados de las notas por cortes acad\u00e9micos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTUDIANTE</code>, <code>ID_JORNADA</code>, <code>ID_MODULO</code>, <code>ID_PERIODO</code>, <code>ID_PERSONAL</code>: Claves esenciales para optimizar consultas frecuentes relacionadas con dimensiones acad\u00e9micas y estudiantes.</li> <li><code>FECHA_INICIO</code>, <code>FECHA_FIN</code>: Cruciales para an\u00e1lisis temporales y segmentaci\u00f3n de notas.</li> <li><code>NOTA_FINAL</code>: Facilita an\u00e1lisis de resultados globales de los estudiantes.</li> <li><code>PRIMER_CORTE</code>, <code>SEGUNDO_CORTE</code>, <code>TERCER_CORTE</code>: Un \u00edndice compuesto mejora el an\u00e1lisis de desempe\u00f1o por cortes.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_NOTAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_JORNADA\nON Cedesarrollo.FACT_NOTAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_MODULO\nON Cedesarrollo.FACT_NOTAS (ID_MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_PERIODO\nON Cedesarrollo.FACT_NOTAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_PERSONAL\nON Cedesarrollo.FACT_NOTAS (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_FECHAS\nON Cedesarrollo.FACT_NOTAS (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOTA_FINAL\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_NOTA_FINAL\nON Cedesarrollo.FACT_NOTAS (NOTA_FINAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_CORTE, SEGUNDO_CORTE y TERCER_CORTE\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_CORTES\nON Cedesarrollo.FACT_NOTAS (PRIMER_CORTE, SEGUNDO_CORTE, TERCER_CORTE);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_permiso_estudiante","title":"FACT_PERMISO_ESTUDIANTE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>    Facilita las consultas y filtros relacionados con permisos de estudiantes espec\u00edficos, as\u00ed como uniones con la tabla de dimensiones [DIM_ESTUDIANTES].</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>    Optimiza el rendimiento en consultas que agrupan o filtran los datos por per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>    Mejora el acceso a los registros relacionados con fechas espec\u00edficas, especialmente en an\u00e1lisis cronol\u00f3gicos o uniones con la tabla de dimensi\u00f3n [DIM_TIEMPO].</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MODULO</code>    Acelera las consultas que necesitan identificar m\u00f3dulos asociados con los permisos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MOTIVO_AUSENCIA</code>    Facilita el an\u00e1lisis y b\u00fasqueda de registros basados en las razones de ausencia.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SOPORTE_AUSENCIA</code>    Optimiza las b\u00fasquedas relacionadas con documentos o justificaciones de las ausencias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTUDIANTE</code>: Usualmente, las consultas incluyen uniones con la tabla de estudiantes o filtros para permisos espec\u00edficos de un estudiante.</li> <li><code>ID_PERIODO</code>: Este campo es clave para an\u00e1lisis por per\u00edodos acad\u00e9micos o tendencias relacionadas con ausencias en un per\u00edodo.</li> <li><code>ID_FECHA</code>: Al ser un campo relacionado con fechas, permite optimizar consultas que buscan patrones temporales o filtros de rangos.</li> <li><code>MODULO</code>: Las ausencias pueden ser analizadas en relaci\u00f3n con m\u00f3dulos espec\u00edficos, haciendo relevante este \u00edndice.</li> <li><code>MOTIVO_AUSENCIA</code>: Es \u00fatil para an\u00e1lisis descriptivos o categorizaci\u00f3n de razones de ausencias.</li> <li><code>SOPORTE_AUSENCIA</code>: Permite identificar r\u00e1pidamente los registros asociados con un tipo espec\u00edfico de soporte.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_ESTUDIANTE\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_PERIODO\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_FECHA\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_MODULO\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_MOTIVO_AUSENCIA\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (MOTIVO_AUSENCIA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SOPORTE_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_SOPORTE_AUSENCIA\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (SOPORTE_AUSENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_plan_cobertura","title":"FACT_PLAN_COBERTURA","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>    Optimiza consultas y an\u00e1lisis relacionados con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>    Mejora el rendimiento de las consultas asociadas a las unidades que forman parte del plan de cobertura.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>    Facilita las b\u00fasquedas y uniones relacionadas con programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MODALIDAD</code>    Acelera consultas que involucren an\u00e1lisis o filtrados por modalidades del plan.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CATEGORIA</code>    Optimiza b\u00fasquedas y agrupaciones relacionadas con categor\u00edas espec\u00edficas dentro del plan.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>USOS_PROYECTADOS</code> y <code>USUARIOS_PROYECTADOS</code>    Mejora el rendimiento de las consultas y an\u00e1lisis basados en las proyecciones de uso y usuarios.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>: Es clave en las relaciones con per\u00edodos acad\u00e9micos y permite optimizar consultas agrupadas o filtradas por per\u00edodos.</li> <li><code>ID_UNIDAD</code>: Asociado a las unidades del plan, es crucial para consultas sobre cobertura por unidad.</li> <li><code>ID_PROGRAMA</code>: Facilita las consultas relacionadas con los programas que componen el plan.</li> <li><code>MODALIDAD</code> y <code>CATEGORIA</code>: Campos descriptivos frecuentemente usados en filtros y an\u00e1lisis de agrupaci\u00f3n.</li> <li><code>USOS_PROYECTADOS</code> y <code>USUARIOS_PROYECTADOS</code>: Los \u00edndices compuestos en estos campos son \u00fatiles para an\u00e1lisis combinados de las proyecciones de uso y usuarios.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_PERIODO\nON Cedesarrollo.FACT_PLAN_COBERTURA (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_UNIDAD\nON Cedesarrollo.FACT_PLAN_COBERTURA (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_PROGRAMA\nON Cedesarrollo.FACT_PLAN_COBERTURA (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MODALIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_MODALIDAD\nON Cedesarrollo.FACT_PLAN_COBERTURA (MODALIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_CATEGORIA\nON Cedesarrollo.FACT_PLAN_COBERTURA (CATEGORIA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos USOS_PROYECTADOS y USUARIOS_PROYECTADOS\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_PROYECCIONES\nON Cedesarrollo.FACT_PLAN_COBERTURA (USOS_PROYECTADOS, USUARIOS_PROYECTADOS);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/","title":"07.Index Colegio","text":""},{"location":"01.scripts/07.Index_Colegio/#indices-colegio","title":"\u00cdndices Colegio","text":""},{"location":"01.scripts/07.Index_Colegio/#dim_anio_academico","title":"DIM_ANIO_ACADEMICO","text":"<ol> <li>\u00cdndice cl\u00faster existente para <code>ANIO_ACADEMICO</code> (PRIMARY KEY):    Este \u00edndice asegura acceso eficiente y ordenado mediante el identificador \u00fanico de cada a\u00f1o acad\u00e9mico.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ANIO_ACADEMICO\n-- (No requiere creaci\u00f3n adicional)\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_curso","title":"DIM_CURSO","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CURSO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de cada curso.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DESC_CURSO</code>:    Facilita b\u00fasquedas relacionadas con descripciones de cursos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>:    Optimiza consultas relacionadas con el estado de los cursos y su fecha de creaci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CURSO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>DESC_CURSO</code>: Mejora el rendimiento en b\u00fasquedas textuales.</li> <li><code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>: Mejora an\u00e1lisis combinados por estado y fecha.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CURSO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DESC_CURSO\nCREATE NONCLUSTERED INDEX IX_DIM_CURSO_DESC_CURSO\nON [Colegio].[DIM_CURSO] (DESC_CURSO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para ESTADO_REGISTRO y FECHA_CREACION\nCREATE NONCLUSTERED INDEX IX_DIM_CURSO_ESTADO_FECHA\nON [Colegio].[DIM_CURSO] (ESTADO_REGISTRO, FECHA_CREACION);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_grado","title":"DIM_GRADO","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_GRADO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DESC_GRADO</code>:    Facilita b\u00fasquedas relacionadas con descripciones de grados.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>:    Optimiza consultas combinadas por estado y fecha.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_GRADO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>DESC_GRADO</code>: Mejora el rendimiento en b\u00fasquedas textuales.</li> <li><code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>: Mejora an\u00e1lisis combinados por estado y fecha.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_GRADO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DESC_GRADO\nCREATE NONCLUSTERED INDEX IX_DIM_GRADO_DESC_GRADO\nON [Colegio].[DIM_GRADO] (DESC_GRADO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para ESTADO_REGISTRO y FECHA_CREACION\nCREATE NONCLUSTERED INDEX IX_DIM_GRADO_ESTADO_FECHA\nON [Colegio].[DIM_GRADO] (ESTADO_REGISTRO, FECHA_CREACION);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_libros","title":"DIM_LIBROS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_LIBRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_LIBRO</code>:    Mejora b\u00fasquedas relacionadas con el nombre del libro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>AUTOR</code>:    Optimiza consultas relacionadas con autores.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>NOMBRE_LIBRO</code> y <code>AUTOR</code>:    Mejora b\u00fasquedas combinadas por nombre y autor.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_LIBRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>NOMBRE_LIBRO</code>: Mejora b\u00fasquedas textuales relacionadas con los libros.</li> <li><code>AUTOR</code>: Optimiza b\u00fasquedas textuales relacionadas con autores.</li> <li><code>NOMBRE_LIBRO</code> y <code>AUTOR</code>: Mejora an\u00e1lisis combinados por nombre y autor.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_LIBRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_LIBRO\nCREATE NONCLUSTERED INDEX IX_DIM_LIBROS_NOMBRE_LIBRO\nON [Colegio].[DIM_LIBROS] (NOMBRE_LIBRO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo AUTOR\nCREATE NONCLUSTERED INDEX IX_DIM_LIBROS_AUTOR\nON [Colegio].[DIM_LIBROS] (AUTOR);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para NOMBRE_LIBRO y AUTOR\nCREATE NONCLUSTERED INDEX IX_DIM_LIBROS_NOMBRE_AUTOR\nON [Colegio].[DIM_LIBROS] (NOMBRE_LIBRO, AUTOR);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_plan_curricular","title":"DIM_PLAN_CURRICULAR","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_ASIGNATURA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de las asignaturas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Optimiza b\u00fasquedas relacionadas con cursos y uniones con la tabla [DIM_CURSO].</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos y uniones con la tabla [DIM_ANIO_ACADEMICO].</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PERIODO</code> y <code>GRADO</code>:    Facilita an\u00e1lisis combinados por per\u00edodo y grado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>INTENSIDAD_HORARIA</code>:    Mejora consultas relacionadas con la intensidad horaria de las asignaturas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ASIGNATURA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_CURSO</code>: Optimiza consultas relacionadas con los cursos.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en consultas por a\u00f1os acad\u00e9micos.</li> <li><code>PERIODO</code> y <code>GRADO</code>: Facilita an\u00e1lisis combinados relacionados con per\u00edodos y grados.</li> <li><code>INTENSIDAD_HORARIA</code>: Acelera b\u00fasquedas relacionadas con este atributo.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_ASIGNATURA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_ID_CURSO\nON [Colegio].[DIM_PLAN_CURRICULAR] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_ANIO_ACADEMICO\nON [Colegio].[DIM_PLAN_CURRICULAR] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para PERIODO y GRADO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_PERIODO_GRADO\nON [Colegio].[DIM_PLAN_CURRICULAR] (PERIODO, GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo INTENSIDAD_HORARIA\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_INTENSIDAD\nON [Colegio].[DIM_PLAN_CURRICULAR] (INTENSIDAD_HORARIA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_poblacion_matricula","title":"DIM_POBLACION_MATRICULA","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_POBLACION_MATRICULA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de la poblaci\u00f3n matriculada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PARTNER</code>:    Optimiza b\u00fasquedas relacionadas con socios o identificadores externos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code>:    Mejora b\u00fasquedas relacionadas con documentos de identificaci\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>GENERO</code> y <code>FECHA_NACIMIENTO</code>:    Facilita an\u00e1lisis demogr\u00e1ficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code>:    Mejora consultas relacionadas con direcciones de correo electr\u00f3nico.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_POBLACION_MATRICULA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>PARTNER</code>: Mejora b\u00fasquedas relacionadas con identificadores externos.</li> <li><code>DOCUMENTO</code>: Optimiza consultas relacionadas con identificadores \u00fanicos de estudiantes.</li> <li><code>GENERO</code> y <code>FECHA_NACIMIENTO</code>: Facilita an\u00e1lisis demogr\u00e1ficos y de grupos etarios.</li> <li><code>CORREO</code>: Acelera b\u00fasquedas relacionadas con direcciones de correo.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_POBLACION_MATRICULA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PARTNER\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_PARTNER\nON [Colegio].[DIM_POBLACION_MATRICULA] (PARTNER);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_DOCUMENTO\nON [Colegio].[DIM_POBLACION_MATRICULA] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para GENERO y FECHA_NACIMIENTO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_GENERO_FECHA\nON [Colegio].[DIM_POBLACION_MATRICULA] (GENERO, FECHA_NACIMIENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_CORREO\nON [Colegio].[DIM_POBLACION_MATRICULA] (CORREO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_ausentismo_docente","title":"FACT_AUSENTISMO_DOCENTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_AUSENTISMO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de cada registro de ausentismo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Mejora consultas relacionadas con docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza b\u00fasquedas por a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Mejora consultas relacionadas con per\u00edodos de ausencia.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_AUSENCIA</code>:    Acelera b\u00fasquedas relacionadas con tipos espec\u00edficos de ausencia.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_AUSENTISMO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_PERSONAL</code>: Facilita b\u00fasquedas por docente.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_FECHA</code>: Optimiza consultas espec\u00edficas por fechas.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Facilita an\u00e1lisis por rangos de fechas.</li> <li><code>TIPO_AUSENCIA</code>: Mejora b\u00fasquedas categ\u00f3ricas por tipo de ausencia.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_AUSENTISMO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_PERSONAL\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ANIO_ACADEMICO\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_FECHA\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_FECHAS\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_TIPO_AUSENCIA\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (TIPO_AUSENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_biblioteca","title":"FACT_BIBLIOTECA","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de biblioteca.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Mejora consultas relacionadas con personal asociado a registros de biblioteca.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_LIBRO</code>:    Facilita b\u00fasquedas relacionadas con libros espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza consultas por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_PRESTAMO</code>, <code>FECHA_VENCIMIENTO</code> y <code>FECHA_ENTREGA</code>:    Mejora an\u00e1lisis relacionados con el ciclo de pr\u00e9stamo de libros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>BIBLIOTECA</code>:    Mejora consultas relacionadas con nombres de bibliotecas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Optimiza uniones y consultas relacionadas con estudiantes.</li> <li><code>ID_PERSONAL</code>: Mejora b\u00fasquedas por personal responsable.</li> <li><code>ID_LIBRO</code>: Facilita consultas relacionadas con libros espec\u00edficos.</li> <li><code>ID_FECHA</code>: Acelera an\u00e1lisis por fechas.</li> <li><code>FECHA_PRESTAMO</code>, <code>FECHA_VENCIMIENTO</code> y <code>FECHA_ENTREGA</code>: Mejora rendimiento en an\u00e1lisis temporales de pr\u00e9stamos.</li> <li><code>BIBLIOTECA</code>: Acelera b\u00fasquedas categ\u00f3ricas por nombre de biblioteca.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_POBLACION\nON [Colegio].[FACT_BIBLIOTECA] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_PERSONAL\nON [Colegio].[FACT_BIBLIOTECA] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_LIBRO\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_LIBRO\nON [Colegio].[FACT_BIBLIOTECA] (ID_LIBRO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_FECHA\nON [Colegio].[FACT_BIBLIOTECA] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_PRESTAMO, FECHA_VENCIMIENTO y FECHA_ENTREGA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_FECHAS\nON [Colegio].[FACT_BIBLIOTECA] (FECHA_PRESTAMO, FECHA_VENCIMIENTO, FECHA_ENTREGA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo BIBLIOTECA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_BIBLIOTECA\nON [Colegio].[FACT_BIBLIOTECA] (BIBLIOTECA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_biblioteca_virtual","title":"FACT_BIBLIOTECA_VIRTUAL","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de biblioteca virtual.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Mejora consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Optimiza b\u00fasquedas relacionadas con personal asociado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Optimiza consultas relacionadas con per\u00edodos de uso de la biblioteca virtual.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ACTIVIDAD</code>:    Mejora b\u00fasquedas relacionadas con actividades espec\u00edficas realizadas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita uniones con la dimensi\u00f3n de poblaci\u00f3n matriculada.</li> <li><code>ID_PERSONAL</code>: Mejora b\u00fasquedas relacionadas con personal responsable.</li> <li><code>ID_FECHA</code>: Acelera consultas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Facilita an\u00e1lisis temporales sobre per\u00edodos de uso.</li> <li><code>ACTIVIDAD</code>: Optimiza b\u00fasquedas relacionadas con actividades espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ID_POBLACION\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ID_PERSONAL\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ID_FECHA\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ANIO_ACADEMICO\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_FECHAS\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ACTIVIDAD\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ACTIVIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_desempenho_docente","title":"FACT_DESEMPENHO_DOCENTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de desempe\u00f1o docente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Optimiza b\u00fasquedas relacionadas con docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>ID_PERSONAL</code>:    Mejora b\u00fasquedas combinadas por fecha y docente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TOTAL_GENERAL</code>:    Optimiza consultas relacionadas con calificaciones totales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_PERSONAL</code>: Facilita b\u00fasquedas por docente.</li> <li><code>ANIO_ACADEMICO</code>: Mejora rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_FECHA</code>: Acelera an\u00e1lisis por fechas espec\u00edficas.</li> <li><code>FECHA</code> y <code>ID_PERSONAL</code>: Mejora an\u00e1lisis combinados por fecha y docente.</li> <li><code>TOTAL_GENERAL</code>: Optimiza b\u00fasquedas relacionadas con el desempe\u00f1o total.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_ID_PERSONAL\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_ANIO_ACADEMICO\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_ID_FECHA\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_FECHA_PERSONAL\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (FECHA, ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TOTAL_GENERAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_TOTAL_GENERAL\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (TOTAL_GENERAL);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_enfermeria","title":"FACT_ENFERMERIA","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CASO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada caso de enfermer\u00eda.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>:    Optimiza b\u00fasquedas relacionadas con los rangos temporales de los casos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO</code>:    Acelera b\u00fasquedas relacionadas con estados espec\u00edficos del caso.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CAUSA_ACCIDENTE</code>:    Mejora consultas relacionadas con las causas de accidentes reportados.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CASO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita uniones y b\u00fasquedas relacionadas con estudiantes.</li> <li><code>ID_FECHA</code>: Mejora el rendimiento en an\u00e1lisis por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Optimiza b\u00fasquedas por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>: Acelera an\u00e1lisis relacionados con los per\u00edodos de atenci\u00f3n y soluci\u00f3n.</li> <li><code>ESTADO</code>: Facilita b\u00fasquedas por estado del caso.</li> <li><code>CAUSA_ACCIDENTE</code>: Mejora el rendimiento en an\u00e1lisis de causas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CASO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ID_POBLACION\nON [Colegio].[FACT_ENFERMERIA] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ID_FECHA\nON [Colegio].[FACT_ENFERMERIA] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ANIO_ACADEMICO\nON [Colegio].[FACT_ENFERMERIA] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_ATENCION y FECHA_SOLUCION\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_FECHAS\nON [Colegio].[FACT_ENFERMERIA] (FECHA_ATENCION, FECHA_SOLUCION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ESTADO\nON [Colegio].[FACT_ENFERMERIA] (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CAUSA_ACCIDENTE\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_CAUSA_ACCIDENTE\nON [Colegio].[FACT_ENFERMERIA] (CAUSA_ACCIDENTE);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_horario_grupos","title":"FACT_HORARIO_GRUPOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_HORARIO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de horario de grupos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Optimiza b\u00fasquedas relacionadas con grados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Facilita consultas relacionadas con cursos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SALON</code>:    Mejora b\u00fasquedas relacionadas con salones.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>HORA_INICIO</code> y <code>HORA_FIN</code>:    Acelera b\u00fasquedas relacionadas con intervalos horarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Optimiza b\u00fasquedas relacionadas con docentes.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>NUMERO_DIA</code> y <code>BLOQUE_HORARIO</code>:    Mejora an\u00e1lisis relacionados con d\u00edas y bloques horarios.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_HORARIO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ANIO_ACADEMICO</code>: Facilita b\u00fasquedas y an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_GRADO</code>: Mejora consultas relacionadas con grados.</li> <li><code>ID_CURSO</code>: Acelera b\u00fasquedas espec\u00edficas por cursos.</li> <li><code>ID_SALON</code>: Mejora el rendimiento en consultas relacionadas con salones.</li> <li><code>HORA_INICIO</code> y <code>HORA_FIN</code>: Facilita an\u00e1lisis de horarios.</li> <li><code>ID_PERSONAL</code>: Optimiza consultas relacionadas con docentes espec\u00edficos.</li> <li><code>NUMERO_DIA</code> y <code>BLOQUE_HORARIO</code>: Mejora b\u00fasquedas relacionadas con d\u00edas espec\u00edficos y bloques horarios.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_HORARIO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ANIO_ACADEMICO\nON [Colegio].[FACT_HORARIO_GRUPOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_GRADO\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_CURSO\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SALON\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_SALON\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_SALON);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para HORA_INICIO y HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_HORAS\nON [Colegio].[FACT_HORARIO_GRUPOS] (HORA_INICIO, HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_PERSONAL\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para NUMERO_DIA y BLOQUE_HORARIO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_BLOQUE_DIA\nON [Colegio].[FACT_HORARIO_GRUPOS] (NUMERO_DIA, BLOQUE_HORARIO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_legalizacion","title":"FACT_LEGALIZACION","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_LEGALIZACION</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de legalizaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO_DE_IDENTIDAD</code>:    Facilita b\u00fasquedas relacionadas con identificadores legales.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RAZON_SOCIAL</code>:    Optimiza b\u00fasquedas relacionadas con razones sociales espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>CODIGO_DANE</code>:    Acelera consultas relacionadas con fechas y c\u00f3digos institucionales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_LEGALIZACION</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_FECHA</code>: Facilita an\u00e1lisis por fechas.</li> <li><code>DOCUMENTO_DE_IDENTIDAD</code>: Mejora b\u00fasquedas relacionadas con identificaci\u00f3n de personas o instituciones.</li> <li><code>RAZON_SOCIAL</code>: Optimiza b\u00fasquedas por razones sociales.</li> <li><code>FECHA</code> y <code>CODIGO_DANE</code>: Mejora consultas combinadas relacionadas con fechas y c\u00f3digos institucionales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_LEGALIZACION\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_ID_FECHA\nON [Colegio].[FACT_LEGALIZACION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO_DE_IDENTIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_DOCUMENTO\nON [Colegio].[FACT_LEGALIZACION] (DOCUMENTO_DE_IDENTIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RAZON_SOCIAL\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_RAZON_SOCIAL\nON [Colegio].[FACT_LEGALIZACION] (RAZON_SOCIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y CODIGO_DANE\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_FECHA_DANE\nON [Colegio].[FACT_LEGALIZACION] (FECHA, CODIGO_DANE);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_notas","title":"FACT_NOTAS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_NOTA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada nota registrada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Facilita an\u00e1lisis por estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Mejora b\u00fasquedas relacionadas con cursos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Optimiza consultas relacionadas con grados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ASIGNATURA</code>:    Mejora b\u00fasquedas relacionadas con asignaturas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_LOGRO</code>:    Facilita consultas relacionadas con logros acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PERIODO</code> y <code>NOTA_FINAL</code>:    Acelera b\u00fasquedas relacionadas con per\u00edodos y calificaciones finales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_NOTA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_FECHA</code>: Mejora b\u00fasquedas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita consultas agrupadas por a\u00f1os acad\u00e9micos.</li> <li><code>ID_POBLACION_MATRICULA</code>: Optimiza an\u00e1lisis relacionados con estudiantes.</li> <li><code>ID_CURSO</code>: Mejora el rendimiento de b\u00fasquedas por cursos.</li> <li><code>ID_GRADO</code>: Acelera b\u00fasquedas relacionadas con grados.</li> <li><code>ID_ASIGNATURA</code>: Facilita consultas por asignaturas espec\u00edficas.</li> <li><code>ID_LOGRO</code>: Mejora b\u00fasquedas relacionadas con logros.</li> <li><code>PERIODO</code> y <code>NOTA_FINAL</code>: Optimiza consultas de an\u00e1lisis por per\u00edodo y resultados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_NOTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_FECHA\nON [Colegio].[FACT_NOTAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ANIO_ACADEMICO\nON [Colegio].[FACT_NOTAS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_POBLACION\nON [Colegio].[FACT_NOTAS] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_CURSO\nON [Colegio].[FACT_NOTAS] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_GRADO\nON [Colegio].[FACT_NOTAS] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ASIGNATURA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_ASIGNATURA\nON [Colegio].[FACT_NOTAS] (ID_ASIGNATURA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_LOGRO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_LOGRO\nON [Colegio].[FACT_NOTAS] (ID_LOGRO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para PERIODO y NOTA_FINAL\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_PERIODO_NOTA\nON [Colegio].[FACT_NOTAS] (PERIODO, NOTA_FINAL);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_permiso_estudiante","title":"FACT_PERMISO_ESTUDIANTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PERMISO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada permiso de estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Mejora b\u00fasquedas relacionadas con grados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Facilita an\u00e1lisis por cursos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza b\u00fasquedas por a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>HORA</code>:    Acelera b\u00fasquedas relacionadas con registros de permisos en momentos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO_ACUDIENTE</code>:    Mejora consultas relacionadas con documentos de acudientes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>MOTIVO_SALIDA</code>:    Facilita b\u00fasquedas relacionadas con motivos de salida.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERMISO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora el rendimiento en b\u00fasquedas relacionadas con estudiantes.</li> <li><code>ID_GRADO</code>: Optimiza b\u00fasquedas relacionadas con grados espec\u00edficos.</li> <li><code>ID_CURSO</code>: Facilita consultas por cursos.</li> <li><code>ID_FECHA</code>: Acelera b\u00fasquedas relacionadas con fechas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA</code> y <code>HORA</code>: Mejora consultas relacionadas con horarios de permisos.</li> <li><code>DOCUMENTO_ACUDIENTE</code>: Optimiza b\u00fasquedas relacionadas con acudientes.</li> <li><code>MOTIVO_SALIDA</code>: Acelera b\u00fasquedas por motivos de salida.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PERMISO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_POBLACION\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_GRADO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_CURSO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_FECHA\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ANIO_ACADEMICO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y HORA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_FECHA_HORA\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (FECHA, HORA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO_ACUDIENTE\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_DOCUMENTO_ACUDIENTE\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (DOCUMENTO_ACUDIENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_SALIDA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_MOTIVO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (MOTIVO_SALIDA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_psicorientacion","title":"FACT_PSICORIENTACION","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CASO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada caso de psicorientaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Facilita b\u00fasquedas agrupadas por a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>:    Acelera an\u00e1lisis relacionados con per\u00edodos de atenci\u00f3n y soluci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO</code>:    Mejora b\u00fasquedas relacionadas con estados espec\u00edficos del caso.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>MOTIVO_ATENCION</code>:    Facilita b\u00fasquedas relacionadas con motivos de atenci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CASO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita uniones y consultas relacionadas con estudiantes.</li> <li><code>ID_FECHA</code>: Optimiza b\u00fasquedas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>: Acelera consultas relacionadas con per\u00edodos temporales.</li> <li><code>ESTADO</code>: Facilita an\u00e1lisis y filtros relacionados con estados de los casos.</li> <li><code>MOTIVO_ATENCION</code>: Mejora b\u00fasquedas relacionadas con motivos espec\u00edficos de atenci\u00f3n.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CASO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ID_POBLACION\nON [Colegio].[FACT_PSICORIENTACION] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ID_FECHA\nON [Colegio].[FACT_PSICORIENTACION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ANIO_ACADEMICO\nON [Colegio].[FACT_PSICORIENTACION] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_ATENCION y FECHA_SOLUCION\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_FECHAS\nON [Colegio].[FACT_PSICORIENTACION] (FECHA_ATENCION, FECHA_SOLUCION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ESTADO\nON [Colegio].[FACT_PSICORIENTACION] (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_ATENCION\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_MOTIVO\nON [Colegio].[FACT_PSICORIENTACION] (MOTIVO_ATENCION);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_reemplazo_docente","title":"FACT_REEMPLAZO_DOCENTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REEMPLAZO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de reemplazo docente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL_AUSENTE</code>:    Mejora b\u00fasquedas relacionadas con docentes ausentes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL_REEMPLAZA</code>:    Optimiza b\u00fasquedas relacionadas con docentes reemplazantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Acelera consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Facilita b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_GRADO</code> y <code>ID_CURSO</code>:    Mejora consultas relacionadas con grados y cursos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>BLOQUE_HORARIO</code>:    Optimiza an\u00e1lisis relacionados con fechas y bloques horarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCENTE_AUSENTE</code>:    Facilita b\u00fasquedas relacionadas con nombres de docentes ausentes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCENTE_REEMPLAZA</code>:    Mejora b\u00fasquedas relacionadas con nombres de docentes que reemplazan.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REEMPLAZO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_PERSONAL_AUSENTE</code>: Facilita an\u00e1lisis por docentes ausentes.</li> <li><code>ID_PERSONAL_REEMPLAZA</code>: Mejora b\u00fasquedas relacionadas con reemplazos.</li> <li><code>ID_FECHA</code>: Acelera b\u00fasquedas relacionadas con fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_GRADO</code> y <code>ID_CURSO</code>: Optimiza consultas combinadas relacionadas con grados y cursos.</li> <li><code>FECHA</code> y <code>BLOQUE_HORARIO</code>: Facilita an\u00e1lisis de bloques horarios por fechas espec\u00edficas.</li> <li><code>DOCENTE_AUSENTE</code>: Acelera b\u00fasquedas relacionadas con los nombres de docentes ausentes.</li> <li><code>DOCENTE_REEMPLAZA</code>: Mejora consultas relacionadas con docentes que reemplazan.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REEMPLAZO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL_AUSENTE\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_PERSONAL_AUSENTE\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_PERSONAL_AUSENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL_REEMPLAZA\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_PERSONAL_REEMPLAZA\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_PERSONAL_REEMPLAZA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_ID_FECHA\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_ANIO_ACADEMICO\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para ID_GRADO y ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_GRADO_CURSO\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_GRADO, ID_CURSO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y BLOQUE_HORARIO\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_FECHA_BLOQUE\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (FECHA, BLOQUE_HORARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCENTE_AUSENTE\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_DOCENTE_AUSENTE\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (DOCENTE_AUSENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCENTE_REEMPLAZA\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_DOCENTE_REEMPLAZA\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (DOCENTE_REEMPLAZA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_reserva_espacios","title":"FACT_RESERVA_ESPACIOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESERVA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de reserva.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_SOLICITUD</code> y <code>FECHA_RESERVA</code>:    Facilita an\u00e1lisis relacionados con el tiempo de solicitud y la reserva.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RECURSO_RESERVA</code>:    Mejora b\u00fasquedas relacionadas con recursos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con los responsables de la reserva.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>HORA_INICIO</code> y <code>HORA_FIN</code>:    Optimiza consultas relacionadas con intervalos de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO_DOCENTE</code>:    Facilita an\u00e1lisis por correos electr\u00f3nicos de los docentes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ACTIVIDAD_PLANEADA</code>:    Mejora b\u00fasquedas relacionadas con actividades espec\u00edficas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESERVA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_FECHA</code>: Mejora el rendimiento de b\u00fasquedas relacionadas con fechas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita consultas relacionadas con agrupaciones por a\u00f1os.</li> <li><code>FECHA_SOLICITUD</code> y <code>FECHA_RESERVA</code>: Optimiza el an\u00e1lisis de tiempos entre solicitud y ejecuci\u00f3n.</li> <li><code>RECURSO_RESERVA</code>: Mejora b\u00fasquedas relacionadas con recursos espec\u00edficos.</li> <li><code>ID_PERSONAL</code>: Acelera consultas relacionadas con responsables de la reserva.</li> <li><code>HORA_INICIO</code> y <code>HORA_FIN</code>: Facilita an\u00e1lisis relacionados con horarios espec\u00edficos.</li> <li><code>CORREO_DOCENTE</code>: Optimiza b\u00fasquedas por docentes en funci\u00f3n de sus correos electr\u00f3nicos.</li> <li><code>ACTIVIDAD_PLANEADA</code>: Mejora consultas relacionadas con actividades registradas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESERVA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ID_FECHA\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ANIO_ACADEMICO\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_SOLICITUD y FECHA_RESERVA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_FECHAS\nON [Colegio].[FACT_RESERVA_ESPACIOS] (FECHA_SOLICITUD, FECHA_RESERVA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RECURSO_RESERVA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_RECURSO\nON [Colegio].[FACT_RESERVA_ESPACIOS] (RECURSO_RESERVA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ID_PERSONAL\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para HORA_INICIO y HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_HORAS\nON [Colegio].[FACT_RESERVA_ESPACIOS] (HORA_INICIO, HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO_DOCENTE\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_CORREO\nON [Colegio].[FACT_RESERVA_ESPACIOS] (CORREO_DOCENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD_PLANEADA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ACTIVIDAD\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ACTIVIDAD_PLANEADA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_resultados","title":"FACT_RESULTADOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESULTADO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada resultado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Facilita an\u00e1lisis relacionados con cursos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Acelera b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>RESULTADO</code>:    Mejora an\u00e1lisis relacionados con resultados y fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GRADUADO</code>:    Optimiza b\u00fasquedas relacionadas con el estado de graduaci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESULTADO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ANIO_ACADEMICO</code>: Facilita agrupaciones y consultas por a\u00f1os.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora an\u00e1lisis relacionados con estudiantes.</li> <li><code>ID_CURSO</code>: Optimiza consultas relacionadas con cursos espec\u00edficos.</li> <li><code>ID_FECHA</code>: Acelera b\u00fasquedas por fechas de registro.</li> <li><code>FECHA</code> y <code>RESULTADO</code>: Facilita an\u00e1lisis de tendencias y resultados por fechas.</li> <li><code>GRADUADO</code>: Mejora b\u00fasquedas relacionadas con estados de graduaci\u00f3n.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESULTADO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ANIO_ACADEMICO\nON [Colegio].[FACT_RESULTADOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ID_POBLACION\nON [Colegio].[FACT_RESULTADOS] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ID_CURSO\nON [Colegio].[FACT_RESULTADOS] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ID_FECHA\nON [Colegio].[FACT_RESULTADOS] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y RESULTADO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_FECHA_RESULTADO\nON [Colegio].[FACT_RESULTADOS] (FECHA, RESULTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GRADUADO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_GRADUADO\nON [Colegio].[FACT_RESULTADOS] (GRADUADO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_servicio_social","title":"FACT_SERVICIO_SOCIAL","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Facilita b\u00fasquedas relacionadas con grados acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Mejora an\u00e1lisis relacionados con cursos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>HORARIO</code>:    Acelera b\u00fasquedas relacionadas con horarios asignados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PROYECTO</code>:    Optimiza b\u00fasquedas relacionadas con proyectos asociados al servicio social.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PAZ_Y_SALVO</code>:    Mejora an\u00e1lisis relacionados con el estado del estudiante respecto a sus requisitos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>HORAS_EJECUTADAS</code>:    Acelera consultas relacionadas con las horas acumuladas en el servicio social.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ANIO_ACADEMICO</code>: Facilita an\u00e1lisis por per\u00edodos acad\u00e9micos.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora b\u00fasquedas por estudiantes espec\u00edficos.</li> <li><code>ID_GRADO</code>: Optimiza an\u00e1lisis relacionados con niveles educativos.</li> <li><code>ID_CURSO</code>: Mejora b\u00fasquedas por grupos acad\u00e9micos.</li> <li><code>HORARIO</code>: Facilita consultas relacionadas con la asignaci\u00f3n de horarios.</li> <li><code>PROYECTO</code>: Mejora an\u00e1lisis por proyectos espec\u00edficos del servicio social.</li> <li><code>PAZ_Y_SALVO</code>: Acelera b\u00fasquedas relacionadas con el cumplimiento de requisitos.</li> <li><code>HORAS_EJECUTADAS</code>: Optimiza el an\u00e1lisis de acumulaci\u00f3n de horas en el servicio social.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ANIO_ACADEMICO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ID_POBLACION\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ID_GRADO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ID_CURSO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo HORARIO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_HORARIO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (HORARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PROYECTO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_PROYECTO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (PROYECTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PAZ_Y_SALVO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_PAZ_Y_SALVO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (PAZ_Y_SALVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo HORAS_EJECUTADAS\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_HORAS\nON [Colegio].[FACT_SERVICIO_SOCIAL] (HORAS_EJECUTADAS);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_transporte","title":"FACT_TRANSPORTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Mejora b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza consultas relacionadas con fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Facilita b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Mejora an\u00e1lisis relacionados con rangos de fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SERVICIO_TRANSPORTE</code>:    Acelera consultas relacionadas con tipos de transporte.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SERVICIO</code>:    Facilita b\u00fasquedas relacionadas con identificadores de servicios espec\u00edficos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora b\u00fasquedas por estudiantes.</li> <li><code>ID_FECHA</code>: Optimiza an\u00e1lisis por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita agrupaciones por per\u00edodos acad\u00e9micos.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Acelera b\u00fasquedas por rangos de fechas.</li> <li><code>SERVICIO_TRANSPORTE</code>: Mejora b\u00fasquedas relacionadas con tipos de servicios.</li> <li><code>ID_SERVICIO</code>: Facilita an\u00e1lisis por identificadores de servicios.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ID_POBLACION\nON [Colegio].[FACT_TRANSPORTE] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ID_FECHA\nON [Colegio].[FACT_TRANSPORTE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ANIO_ACADEMICO\nON [Colegio].[FACT_TRANSPORTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_FECHAS\nON [Colegio].[FACT_TRANSPORTE] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SERVICIO_TRANSPORTE\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_SERVICIO\nON [Colegio].[FACT_TRANSPORTE] (SERVICIO_TRANSPORTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ID_SERVICIO\nON [Colegio].[FACT_TRANSPORTE] (ID_SERVICIO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_saber11_colegios","title":"FACT_SABER11_COLEGIOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>COD_ESTABLECIMIENTO_EDUCATIVO</code>:    Facilita b\u00fasquedas relacionadas con el c\u00f3digo del establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_EE</code>:    Acelera b\u00fasquedas por el nombre del establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESULTADO</code>:    Optimiza consultas relacionadas con los resultados espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CATEGORIA_SABER11</code>:    Mejora an\u00e1lisis relacionados con las categor\u00edas asignadas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura acceso eficiente.</li> <li><code>ID_FECHA</code>: Optimiza b\u00fasquedas por fechas espec\u00edficas en an\u00e1lisis temporales.</li> <li><code>ANIO_ACADEMICO</code>: Mejora agrupaciones por per\u00edodos acad\u00e9micos.</li> <li><code>COD_ESTABLECIMIENTO_EDUCATIVO</code>: Facilita consultas relacionadas con c\u00f3digos de instituciones.</li> <li><code>NOMBRE_EE</code>: Acelera b\u00fasquedas relacionadas con nombres de instituciones educativas.</li> <li><code>RESULTADO</code>: Mejora an\u00e1lisis y agrupaciones por resultados obtenidos.</li> <li><code>CATEGORIA_SABER11</code>: Optimiza b\u00fasquedas relacionadas con las clasificaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_ID_FECHA\nON [Colegio].[FACT_SABER11_COLEGIOS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_ANIO_ACADEMICO\nON [Colegio].[FACT_SABER11_COLEGIOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_COD_ESTABLECIMIENTO\nON [Colegio].[FACT_SABER11_COLEGIOS] (COD_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_EE\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_NOMBRE_EE\nON [Colegio].[FACT_SABER11_COLEGIOS] (NOMBRE_EE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RESULTADO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_RESULTADO\nON [Colegio].[FACT_SABER11_COLEGIOS] (RESULTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA_SABER11\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_CATEGORIA\nON [Colegio].[FACT_SABER11_COLEGIOS] (CATEGORIA_SABER11);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_saber11_individual","title":"FACT_SABER11_INDIVIDUAL","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Facilita b\u00fasquedas relacionadas con los estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TEMATICA</code>:    Mejora an\u00e1lisis relacionados con tem\u00e1ticas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESULTADO</code>:    Optimiza b\u00fasquedas relacionadas con resultados obtenidos por los estudiantes.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura acceso eficiente.</li> <li><code>ID_FECHA</code>: Acelera consultas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora an\u00e1lisis agrupados por per\u00edodos acad\u00e9micos.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita b\u00fasquedas relacionadas con estudiantes individuales.</li> <li><code>TEMATICA</code>: Acelera an\u00e1lisis por \u00e1reas tem\u00e1ticas espec\u00edficas.</li> <li><code>RESULTADO</code>: Mejora consultas relacionadas con los puntajes individuales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_ID_FECHA\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_ANIO_ACADEMICO\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_ID_POBLACION\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TEMATICA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_TEMATICA\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (TEMATICA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RESULTADO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_RESULTADO\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (RESULTADO);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/","title":"08.Index Proteccion","text":""},{"location":"01.scripts/08.Index_Proteccion/#indices-proteccion","title":"Indices Protecci\u00f3n","text":""},{"location":"01.scripts/08.Index_Proteccion/#dim_campos_caract","title":"[DIM_CAMPOS_CARACT]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PREGUNTA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PREGUNTA</code>:    Optimiza b\u00fasquedas y filtros basados en el texto de la pregunta.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>OBSERVACIONES</code>:    Facilita b\u00fasquedas y consultas relacionadas con observaciones espec\u00edficas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PREGUNTA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>PREGUNTA</code>: Campo clave para b\u00fasquedas o filtros basados en el texto de la pregunta.</li> <li><code>OBSERVACIONES</code>: Mejora la velocidad de an\u00e1lisis y b\u00fasquedas cuando se necesitan filtros o an\u00e1lisis basados en observaciones espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PREGUNTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_CAMPOS_CARACT_PREGUNTA\nON [Proteccion].[DIM_CAMPOS_CARACT] (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_DIM_CAMPOS_CARACT_OBSERVACIONES\nON [Proteccion].[DIM_CAMPOS_CARACT] (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_establecimiento_educativo","title":"[DIM_ESTABLECIMIENTO_EDUCATIVO]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>COD_ESTABLECIMIENTO_EDUCATIVO</code>:    Optimiza b\u00fasquedas relacionadas con el c\u00f3digo del establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_ESTABLECIMIENTO</code>:    Facilita b\u00fasquedas y filtros por el nombre del establecimiento.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code>:    Mejora consultas relacionadas con documentos espec\u00edficos de los establecimientos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>REPRESENTANTE_LEGAL</code>:    Acelera b\u00fasquedas relacionadas con los representantes legales de los establecimientos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>COD_CIUDAD</code>:    Optimiza an\u00e1lisis y filtros basados en la ciudad de ubicaci\u00f3n del establecimiento.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Clave primaria para garantizar un acceso r\u00e1pido y ordenado.</li> <li><code>COD_ESTABLECIMIENTO_EDUCATIVO</code>: Es un identificador alternativo usado frecuentemente en consultas.</li> <li><code>NOMBRE_ESTABLECIMIENTO</code>: Se utiliza para b\u00fasquedas textuales en an\u00e1lisis y reportes.</li> <li><code>DOCUMENTO</code>: Permite b\u00fasquedas espec\u00edficas para identificar establecimientos.</li> <li><code>REPRESENTANTE_LEGAL</code>: Optimiza consultas basadas en responsables legales.</li> <li><code>COD_CIUDAD</code>: Mejora an\u00e1lisis agrupados por ubicaci\u00f3n geogr\u00e1fica.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_ESTABLECIMIENTO_EDUCATIVO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo COD_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_COD_ESTABLECIMIENTO\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (COD_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_ESTABLECIMIENTO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_NOMBRE\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (NOMBRE_ESTABLECIMIENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_DOCUMENTO\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo REPRESENTANTE_LEGAL\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_REPRESENTANTE\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (REPRESENTANTE_LEGAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_CIUDAD\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_COD_CIUDAD\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (COD_CIUDAD);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_poblacion","title":"[DIM_POBLACION]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_POBLACION</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Optimiza consultas basadas en la combinaci\u00f3n del tipo de documento y su n\u00famero.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code>:    Mejora b\u00fasquedas relacionadas con la empresa asociada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_AFILIADO</code>:    Facilita consultas relacionadas con los afiliados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_BENEFICIARIO</code>:    Acelera an\u00e1lisis relacionados con los beneficiarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_APORTANTE</code>:    Optimiza b\u00fasquedas relacionadas con aportantes espec\u00edficos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_POBLACION</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>: La combinaci\u00f3n de estos campos permite b\u00fasquedas r\u00e1pidas de individuos espec\u00edficos.</li> <li><code>ID_EMPRESA</code>: Facilita el an\u00e1lisis de datos a nivel empresarial.</li> <li><code>ID_AFILIADO</code>: Optimiza consultas relacionadas con individuos afiliados.</li> <li><code>ID_BENEFICIARIO</code>: Mejora el acceso a datos de beneficiarios en reportes y an\u00e1lisis.</li> <li><code>ID_APORTANTE</code>: Permite b\u00fasquedas r\u00e1pidas relacionadas con quienes realizan aportes.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_POBLACION\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_TIPO_DOCUMENTO_DOCUMENTO\nON [Proteccion].[DIM_POBLACION] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_EMPRESA\nON [Proteccion].[DIM_POBLACION] (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_AFILIADO\nON [Proteccion].[DIM_POBLACION] (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_BENEFICIARIO\nON [Proteccion].[DIM_POBLACION] (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_APORTANTE\nON [Proteccion].[DIM_POBLACION] (ID_APORTANTE);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_preguntas_ee_aipi","title":"[DIM_PREGUNTAS_EE_AIPI]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PREGUNTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PREGUNTA</code>:    Optimiza b\u00fasquedas basadas en el texto de las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Mejora la eficiencia de consultas relacionadas con programas espec\u00edficos, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PREGUNTA</code>: Es la clave primaria que asegura un acceso eficiente a cada registro de manera \u00fanica.</li> <li><code>PREGUNTA</code>: Este campo puede ser usado en b\u00fasquedas textuales o filtros en reportes.</li> <li><code>ID_PROGRAMA</code>: Como clave for\u00e1nea, se usa en uniones y an\u00e1lisis vinculados con programas, lo que justifica su \u00edndice para mejorar el rendimiento.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PREGUNTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_AIPI_PREGUNTA\nON [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_AIPI_ID_PROGRAMA\nON [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (ID_PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_preguntas_ee_jec","title":"[DIM_PREGUNTAS_EE_JEC]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PREGUNTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PREGUNTA</code>:    Facilita b\u00fasquedas y an\u00e1lisis basados en el texto de las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Mejora la eficiencia de consultas relacionadas con programas espec\u00edficos, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PREGUNTA</code>: Es la clave primaria que asegura un acceso eficiente a cada registro de manera \u00fanica.</li> <li><code>PREGUNTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales y reportes relacionados con las preguntas.</li> <li><code>ID_PROGRAMA</code>: Como clave for\u00e1nea, este campo se utiliza para unir o filtrar datos basados en los programas asociados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PREGUNTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_JEC_PREGUNTA\nON [Proteccion].[DIM_PREGUNTAS_EE_JEC] (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_JEC_ID_PROGRAMA\nON [Proteccion].[DIM_PREGUNTAS_EE_JEC] (ID_PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_programa","title":"[DIM_PROGRAMA]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PROGRAMA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PROGRAMA</code>:    Optimiza consultas relacionadas con el nombre o descripci\u00f3n de los programas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PROGRAMA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>PROGRAMA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales, reportes y an\u00e1lisis relacionados con los programas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PROGRAMA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PROGRAMA_PROGRAMA\nON [Proteccion].[DIM_PROGRAMA] (PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_respuestas_ee_aipi","title":"[DIM_RESPUESTAS_EE_AIPI]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESPUESTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESPUESTA</code>:    Optimiza b\u00fasquedas relacionadas con el texto de las respuestas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de consultas que relacionan respuestas con preguntas espec\u00edficas, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESPUESTA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>RESPUESTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales y reportes relacionados con las respuestas.</li> <li><code>ID_PREGUNTA</code>: Como clave for\u00e1nea, es importante para unir o filtrar datos basados en preguntas asociadas a las respuestas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESPUESTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo RESPUESTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_AIPI_RESPUESTA\nON [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (RESPUESTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_AIPI_ID_PREGUNTA\nON [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (ID_PREGUNTA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_respuestas_ee_jec","title":"[DIM_RESPUESTAS_EE_JEC]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESPUESTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESPUESTA</code>:    Optimiza b\u00fasquedas relacionadas con el texto de las respuestas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de consultas que relacionan respuestas con preguntas espec\u00edficas, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESPUESTA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>RESPUESTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales y an\u00e1lisis relacionados con las respuestas.</li> <li><code>ID_PREGUNTA</code>: Como clave for\u00e1nea, facilita uniones y filtros en consultas que relacionan respuestas con preguntas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESPUESTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo RESPUESTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_JEC_RESPUESTA\nON [Proteccion].[DIM_RESPUESTAS_EE_JEC] (RESPUESTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_JEC_ID_PREGUNTA\nON [Proteccion].[DIM_RESPUESTAS_EE_JEC] (ID_PREGUNTA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_caracterizacion","title":"[FACT_CARACTERIZACION]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CARACTERIZACION</code> (PRIMARY KEY):    Garantiza un acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora el rendimiento de consultas que utilizan la fecha para an\u00e1lisis o relaciones con otras tablas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code>:    Optimiza consultas relacionadas con la poblaci\u00f3n asociada a cada caracterizaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Acelera b\u00fasquedas y relaciones con programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de uniones o filtros relacionados con preguntas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>RESPUESTA</code>:    Optimiza b\u00fasquedas textuales relacionadas con las respuestas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_FECHA</code> y <code>ID_PROGRAMA</code>:    Dise\u00f1ado para consultas frecuentes que combinen fechas y programas en filtros o an\u00e1lisis.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CARACTERIZACION</code>: Clave primaria que asegura un acceso eficiente y ordenado a los registros.</li> <li><code>ID_FECHA</code>: Frecuentemente utilizado para an\u00e1lisis basados en tiempo o relaciones con la tabla de tiempo.</li> <li><code>ID_POBLACION</code>: Como clave for\u00e1nea, se utiliza para uniones y an\u00e1lisis relacionados con datos de poblaci\u00f3n.</li> <li><code>ID_PROGRAMA</code>: Fundamental para consultas que filtran o agrupan por programas asociados.</li> <li><code>ID_PREGUNTA</code>: Importante para relacionar y analizar preguntas espec\u00edficas.</li> <li><code>RESPUESTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales o an\u00e1lisis relacionados con respuestas espec\u00edficas.</li> <li>\u00cdndice compuesto para <code>ID_FECHA</code> y <code>ID_PROGRAMA</code>: Facilita an\u00e1lisis multidimensionales en escenarios con m\u00faltiples dimensiones (fecha y programa).</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CARACTERIZACION\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_FECHA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_POBLACION\nON [Proteccion].[FACT_CARACTERIZACION] (ID_POBLACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_PROGRAMA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_PREGUNTA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_RESPUESTA\nON [Proteccion].[FACT_CARACTERIZACION] (RESPUESTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_FECHA y ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_FECHA_PROGRAMA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_FECHA, ID_PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_desercion","title":"[FACT_DESERCION]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Optimiza las consultas relacionadas con establecimientos educativos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code>:    Mejora el rendimiento de b\u00fasquedas o uniones relacionadas con poblaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Acelera las consultas relacionadas con programas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora el rendimiento en an\u00e1lisis basados en tiempo y uniones con la tabla de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ANIO_ACADEMICO</code>:    Optimiza consultas que analizan registros por a\u00f1o acad\u00e9mico.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CAUSA</code>:    Acelera b\u00fasquedas y agrupaciones relacionadas con las causas de deserci\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_FECHA</code> y <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Dise\u00f1ado para consultas que filtran por tiempo y establecimiento educativo.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code> y <code>ID_POBLACION</code>: Claves for\u00e1neas usadas frecuentemente en uniones y an\u00e1lisis relacionados con datos espec\u00edficos.</li> <li><code>ID_PROGRAMA</code>: Usado en consultas para agrupar o filtrar datos por programa.</li> <li><code>ID_FECHA</code>: Clave for\u00e1nea que permite uniones r\u00e1pidas con la dimensi\u00f3n de tiempo para an\u00e1lisis temporales.</li> <li><code>ANIO_ACADEMICO</code> y <code>CAUSA</code>: Campos comunes en an\u00e1lisis y agrupaciones espec\u00edficas sobre deserci\u00f3n.</li> <li>\u00cdndice compuesto para <code>ID_FECHA</code> y <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Acelera consultas multidimensionales que incluyen filtros por tiempo y establecimiento.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_DESERCION] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_POBLACION\nON [Proteccion].[FACT_DESERCION] (ID_POBLACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_PROGRAMA\nON [Proteccion].[FACT_DESERCION] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_FECHA\nON [Proteccion].[FACT_DESERCION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ANIO_ACADEMICO\nON [Proteccion].[FACT_DESERCION] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CAUSA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_CAUSA\nON [Proteccion].[FACT_DESERCION] (CAUSA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_FECHA y ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_FECHA_ESTABLECIMIENTO\nON [Proteccion].[FACT_DESERCION] (ID_FECHA, ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_diagnosticos_ee_aipi","title":"[FACT_DIAGNOSTICOS_EE_AIPI]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza las consultas relacionadas con el tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Acelera las b\u00fasquedas relacionadas con establecimientos educativos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de consultas relacionadas con las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_RESPUESTA</code>:    Optimiza b\u00fasquedas o an\u00e1lisis relacionados con las respuestas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_FECHA</code> y <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Dise\u00f1ado para acelerar consultas que filtran por tiempo y establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CIUDAD</code>:    Acelera b\u00fasquedas y agrupaciones por ciudad.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>:    Optimiza las consultas que cruzan las preguntas con sus respuestas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Utilizado en uniones con la dimensi\u00f3n de tiempo para an\u00e1lisis temporales.</li> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Com\u00fan en uniones y an\u00e1lisis espec\u00edficos por establecimiento educativo.</li> <li><code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>: Claves for\u00e1neas para enlazar preguntas y respuestas, necesarias para an\u00e1lisis detallados.</li> <li><code>CIUDAD</code>: Campo usado en agrupaciones y an\u00e1lisis geogr\u00e1ficos.</li> <li>\u00cdndices compuestos: Aceleran consultas multidimensionales, como las que combinan fechas con establecimientos educativos o preguntas con respuestas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_FECHA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_PREGUNTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_RESPUESTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_FECHA y ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_FECHA_ESTABLECIMIENTO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_FECHA, ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CIUDAD\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_CIUDAD\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (CIUDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_PREGUNTA y ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_PREGUNTA_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_PREGUNTA, ID_RESPUESTA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_diagnosticos_ee_jec","title":"[FACT_DIAGNOSTICOS_EE_JEC]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Acelera consultas relacionadas con la dimensi\u00f3n de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Optimiza b\u00fasquedas y uniones relacionadas con establecimientos educativos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento en consultas relacionadas con preguntas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_RESPUESTA</code>:    Facilita el an\u00e1lisis y recuperaci\u00f3n de datos basados en respuestas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_HORA_INICIO</code> y <code>FECHA_HORA_FIN</code>:    Dise\u00f1ado para consultas que analizan rangos de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CORREO_FUNCIONARIO</code>:    Acelera b\u00fasquedas espec\u00edficas relacionadas con el correo de los funcionarios.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>:    Optimiza el an\u00e1lisis cruzado de preguntas y respuestas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>RECTOR</code>:    Acelera consultas relacionadas con los rectores.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Utilizado para uniones con la dimensi\u00f3n de tiempo y an\u00e1lisis temporales.</li> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Com\u00fan en an\u00e1lisis espec\u00edficos por establecimiento educativo.</li> <li><code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>: Campos esenciales para uniones y an\u00e1lisis cruzados entre preguntas y respuestas.</li> <li>Campos de tiempo (<code>FECHA_HORA_INICIO</code>, <code>FECHA_HORA_FIN</code>): Importantes para an\u00e1lisis basados en periodos.</li> <li>Campos relacionados con funcionarios (<code>CORREO_FUNCIONARIO</code>, <code>RECTOR</code>): \u00datiles para segmentaciones y an\u00e1lisis detallados por personal.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_FECHA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_PREGUNTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_RESPUESTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_HORA_INICIO y FECHA_HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_FECHA_RANGO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (FECHA_HORA_INICIO, FECHA_HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO_FUNCIONARIO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_CORREO_FUNCIONARIO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (CORREO_FUNCIONARIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_PREGUNTA y ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_PREGUNTA_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_PREGUNTA, ID_RESPUESTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RECTOR\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_RECTOR\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (RECTOR);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_entrega_material","title":"[FACT_ENTREGA_MATERIAL]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_ENTREGA</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza uniones y consultas basadas en la dimensi\u00f3n de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Mejora el rendimiento de consultas relacionadas con programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con personal asignado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_MATERIAL</code>:    Facilita b\u00fasquedas espec\u00edficas por material.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_MATERIAL</code> y <code>CANTIDAD_MATERIAL</code>:    Dise\u00f1ado para consultas que analizan tipos y cantidades de material.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>VALOR_MATERIAL</code> y <code>ID_FECHA</code>:    Mejora an\u00e1lisis financieros relacionados con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code>:    Optimiza consultas y an\u00e1lisis centrados en poblaci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Utilizado para uniones y an\u00e1lisis relacionados con periodos de tiempo.  </li> <li><code>ID_PROGRAMA</code> y <code>ID_PERSONAL</code>: Campos claves para an\u00e1lisis por programa y personal.  </li> <li><code>ID_MATERIAL</code>: Esencial para identificar materiales entregados.  </li> <li>Campos compuestos (<code>TIPO_MATERIAL</code>, <code>CANTIDAD_MATERIAL</code> y <code>VALOR_MATERIAL</code>): Relevantes para an\u00e1lisis detallados de distribuci\u00f3n y valor.  </li> <li><code>ID_POBLACION</code>: Clave en consultas relacionadas con la poblaci\u00f3n beneficiaria.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_ENTREGA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_FECHA\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_PROGRAMA\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_PERSONAL\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MATERIAL\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_MATERIAL\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_MATERIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_MATERIAL y CANTIDAD_MATERIAL\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_TIPO_CANTIDAD\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (TIPO_MATERIAL, CANTIDAD_MATERIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos VALOR_MATERIAL y ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_VALOR_FECHA\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (VALOR_MATERIAL, ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_POBLACION\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_POBLACION);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_plan_cobertura","title":"[FACT_PLAN_COBERTURA]","text":"<p>Justificaci\u00f3n</p> <ol> <li>\u00cdndice cl\u00faster existente para <code>ID_PLAN_COBERTURA</code></li> <li> <p>La clave primaria asegura acceso ordenado y r\u00e1pido a los registros mediante un \u00edndice cl\u00faster.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> </li> <li> <p>Mejora las consultas relacionadas con el tiempo y permite uniones r\u00e1pidas con la dimensi\u00f3n temporal.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code></p> </li> <li> <p>Optimiza consultas relacionadas con establecimientos educativos y permite uniones eficientes con la dimensi\u00f3n correspondiente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code></p> </li> <li> <p>Facilita el acceso r\u00e1pido a los datos relacionados con programas espec\u00edficos y optimiza las uniones con su dimensi\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ZONA</code> y <code>MUNICIPIO</code></p> </li> <li> <p>Optimiza las consultas que analizan datos por zona y municipio.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>LINEA_INTERVENCION</code></p> </li> <li> <p>Mejora el rendimiento en consultas que filtran o agrupan datos por l\u00ednea de intervenci\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>SEDE</code> y <code>COBERTURA_PROYECTADA</code></p> </li> <li>Acelera las b\u00fasquedas y an\u00e1lisis relacionados con las sedes y su cobertura proyectada.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PLAN_COBERTURA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_FECHA\nON [Proteccion].[FACT_PLAN_COBERTURA] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_PLAN_COBERTURA] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_PROGRAMA\nON [Proteccion].[FACT_PLAN_COBERTURA] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ZONA y MUNICIPIO\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ZONA_MUNICIPIO\nON [Proteccion].[FACT_PLAN_COBERTURA] (ZONA, MUNICIPIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo LINEA_INTERVENCION\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_LINEA_INTERVENCION\nON [Proteccion].[FACT_PLAN_COBERTURA] (LINEA_INTERVENCION);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos SEDE y COBERTURA_PROYECTADA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_SEDE_COBERTURA\nON [Proteccion].[FACT_PLAN_COBERTURA] (SEDE, COBERTURA_PROYECTADA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_venta","title":"[FACT_VENTA]","text":"<p>Justificaci\u00f3n</p> <ol> <li>\u00cdndice cl\u00faster existente para <code>ID_VENTA</code></li> <li> <p>Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> </li> <li> <p>Optimiza consultas relacionadas con el tiempo y permite uniones r\u00e1pidas con la dimensi\u00f3n temporal.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code></p> </li> <li> <p>Mejora el rendimiento de consultas centradas en la poblaci\u00f3n objetivo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SERVICIO</code></p> </li> <li> <p>Acelera b\u00fasquedas relacionadas con servicios y permite uniones r\u00e1pidas con la dimensi\u00f3n de servicios.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code></p> </li> <li> <p>Facilita b\u00fasquedas r\u00e1pidas basadas en documentos espec\u00edficos de usuarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CATEGORIA_VENTA</code></p> </li> <li> <p>Permite consultas eficientes sobre las categor\u00edas de ventas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>COSTO</code>, <code>SUBSIDIO</code>, y <code>VALOR_PAGADO_SIN_IMP</code></p> </li> <li>Optimiza an\u00e1lisis relacionados con valores econ\u00f3micos de las ventas.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_VENTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_ID_FECHA\nON [Proteccion].[FACT_VENTA] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_ID_POBLACION\nON [Proteccion].[FACT_VENTA] (ID_POBLACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_ID_SERVICIO\nON [Proteccion].[FACT_VENTA] (ID_SERVICIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_DOCUMENTOS\nON [Proteccion].[FACT_VENTA] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA_VENTA\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_CATEGORIA\nON [Proteccion].[FACT_VENTA] (CATEGORIA_VENTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos COSTO, SUBSIDIO, y VALOR_PAGADO_SIN_IMP\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_VALORES\nON [Proteccion].[FACT_VENTA] (COSTO, SUBSIDIO, VALOR_PAGADO_SIN_IMP);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_visitas","title":"[FACT_VISITAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li>\u00cdndice cl\u00faster existente para <code>ID_VISITA</code></li> <li> <p>La clave primaria asegura acceso ordenado y r\u00e1pido a los registros mediante un \u00edndice cl\u00faster.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> </li> <li> <p>Optimiza las consultas relacionadas con fechas y permite uniones eficientes con la dimensi\u00f3n temporal.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code></p> </li> <li> <p>Mejora el rendimiento en consultas que agrupan o filtran datos por programas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code></p> </li> <li> <p>Acelera las b\u00fasquedas relacionadas con el personal involucrado en las visitas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>MUNICIPIO</code> y <code>LUGAR</code></p> </li> <li> <p>Facilita an\u00e1lisis y b\u00fasquedas basadas en la ubicaci\u00f3n de las visitas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_PLANEADA</code> y <code>FECHA_EJECUTADA</code></p> </li> <li> <p>Permite comparar las fechas planeadas con las ejecutadas, optimizando las consultas relacionadas con la ejecuci\u00f3n de visitas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ACTIVIDAD</code></p> </li> <li>Mejora el rendimiento de consultas que filtran o agrupan datos por actividades.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_VISITA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ID_FECHA\nON [Proteccion].[FACT_VISITAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ID_PROGRAMA\nON [Proteccion].[FACT_VISITAS] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ID_PERSONAL\nON [Proteccion].[FACT_VISITAS] (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos MUNICIPIO y LUGAR\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_MUNICIPIO_LUGAR\nON [Proteccion].[FACT_VISITAS] (MUNICIPIO, LUGAR);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_PLANEADA y FECHA_EJECUTADA\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_FECHAS\nON [Proteccion].[FACT_VISITAS] (FECHA_PLANEADA, FECHA_EJECUTADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ACTIVIDAD\nON [Proteccion].[FACT_VISITAS] (ACTIVIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/","title":"09.Index Transversal","text":""},{"location":"01.scripts/09.Index_Transversal/#indices-transversal","title":"Indices Transversal","text":""},{"location":"01.scripts/09.Index_Transversal/#dim_afiliados","title":"[DIM_AFILIADOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_AFILIADO</code></p> <ul> <li>La clave primaria garantiza un acceso eficiente y ordenado a los registros.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NUMERO_DOCUMENTO</code></p> <ul> <li>Este \u00edndice es esencial para las b\u00fasquedas frecuentes por el n\u00famero de documento, ya que suele ser un identificador \u00fanico en sistemas de afiliados.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>NUMERO_DOCUMENTO</code></p> <ul> <li>Optimiza las consultas que combinan tipo y n\u00famero de documento para validar registros.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code></p> <ul> <li>Facilita las b\u00fasquedas y uniones con la dimensi\u00f3n de empresas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code></p> <ul> <li>Mejora las b\u00fasquedas por correo electr\u00f3nico, a menudo usado como identificador \u00fanico o para comunicaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PRIMER_APELLIDO</code> y <code>SEGUNDO_APELLIDO</code></p> <ul> <li>Optimiza las consultas de b\u00fasqueda y agrupaci\u00f3n por apellidos, comunes en an\u00e1lisis demogr\u00e1ficos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GENERO</code></p> <ul> <li>Mejora el rendimiento en an\u00e1lisis de g\u00e9nero, com\u00fan en reportes de afiliados.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_AFILIACION</code> y <code>FECHA_AFILIACION</code></p> <ul> <li>Facilita el an\u00e1lisis y la segmentaci\u00f3n por estado y fecha de afiliaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FEC_DESDE</code> y <code>FEC_HASTA</code></p> <ul> <li>Optimiza consultas de rangos temporales, como la validez de afiliaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADOREGISTRO</code></p> <ul> <li>Mejora el rendimiento de consultas que filtran registros activos o inactivos.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_AFILIADO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_NUMERO_DOCUMENTO\nON [Transversal].[DIM_AFILIADOS] (NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_TIPO_Y_DOCUMENTO\nON [Transversal].[DIM_AFILIADOS] (TIPO_DOCUMENTO, NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_ID_EMPRESA\nON [Transversal].[DIM_AFILIADOS] (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_CORREO\nON [Transversal].[DIM_AFILIADOS] (CORREO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_APELLIDO y SEGUNDO_APELLIDO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_APELLIDOS\nON [Transversal].[DIM_AFILIADOS] (PRIMER_APELLIDO, SEGUNDO_APELLIDO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GENERO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_GENERO\nON [Transversal].[DIM_AFILIADOS] (GENERO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ESTADO_AFILIACION y FECHA_AFILIACION\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_ESTADO_FECHA\nON [Transversal].[DIM_AFILIADOS] (ESTADO_AFILIACION, FECHA_AFILIACION);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FEC_DESDE y FEC_HASTA\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_FECHAS\nON [Transversal].[DIM_AFILIADOS] (FEC_DESDE, FEC_HASTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADOREGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_ESTADOREGISTRO\nON [Transversal].[DIM_AFILIADOS] (ESTADOREGISTRO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_aportante_noafiliado","title":"[DIM_APORTANTE_NOAFILIADO]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_APORTANTE</code> </p> <ul> <li>Clave primaria que garantiza un acceso r\u00e1pido y ordenado.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code> </p> <ul> <li>Optimiza b\u00fasquedas frecuentes por el documento, clave com\u00fan en registros de aportantes.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code> </p> <ul> <li>Mejora el rendimiento en validaciones combinadas por tipo y documento, frecuentemente usadas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RAZON_SOCIAL</code> </p> <ul> <li>Facilita b\u00fasquedas por la raz\u00f3n social, \u00fatil para identificar aportantes empresariales.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTADO</code> y <code>ESTADO</code> </p> <ul> <li>Optimiza filtros por estado del aportante, comunes en an\u00e1lisis de activos/inactivos.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>SECTOR</code> y <code>CLASE</code> </p> <ul> <li>Mejora la eficiencia de consultas relacionadas con caracter\u00edsticas sectoriales y clasificaciones.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_DESDE</code> y <code>FECHA_HASTA</code> </p> <ul> <li>Facilita an\u00e1lisis y consultas en rangos temporales sobre periodos de validez.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code> </p> <ul> <li>Mejora el rendimiento de b\u00fasquedas por correo electr\u00f3nico.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PRIMER_APELLIDO</code> y <code>SEGUNDO_APELLIDO</code> </p> <ul> <li>\u00datil para b\u00fasquedas por nombres y apellidos en casos de aportantes individuales.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADOREGISTRO</code> </p> <ul> <li>Filtra registros seg\u00fan su estado actual, \u00fatil para segmentaciones de datos.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_APORTANTE\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_DOCUMENTO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_TIPO_Y_DOCUMENTO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RAZON_SOCIAL\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_RAZON_SOCIAL\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (RAZON_SOCIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_ESTADO y ESTADO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_ESTADO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (ID_ESTADO, ESTADO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos SECTOR y CLASE\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_SECTOR_CLASE\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (SECTOR, CLASE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_DESDE y FECHA_HASTA\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_FECHAS\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (FECHA_DESDE, FECHA_HASTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_CORREO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (CORREO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_APELLIDO y SEGUNDO_APELLIDO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_APELLIDOS\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (PRIMER_APELLIDO, SEGUNDO_APELLIDO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADOREGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_ESTADOREGISTRO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (ESTADOREGISTRO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_beneficiarios","title":"[DIM_BENEFICIARIOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_BENEFICIARIO</code> </p> <ul> <li>Clave primaria que garantiza acceso r\u00e1pido a registros \u00fanicos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NUMERO_DOCUMENTO</code> </p> <ul> <li>Optimiza b\u00fasquedas frecuentes por el documento del beneficiario.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>NUMERO_DOCUMENTO</code> </p> <ul> <li>Mejora el rendimiento en consultas que combinan tipo y n\u00famero de documento.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_AFILIADO</code> </p> <ul> <li>Facilita consultas relacionadas con afiliados vinculados a beneficiarios.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PRIMER_NOMBRE</code> y <code>PRIMER_APELLIDO</code> </p> <ul> <li>\u00datil en b\u00fasquedas por nombres y apellidos, especialmente en beneficiarios individuales.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_AFILIACION</code> y <code>FECHA_RETIRO</code> </p> <ul> <li>Mejora an\u00e1lisis temporales relacionados con la afiliaci\u00f3n y retiro de beneficiarios.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GENERO</code> </p> <ul> <li>Permite segmentar y filtrar beneficiarios por g\u00e9nero.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADOREGISTRO</code> </p> <ul> <li>Facilita la segmentaci\u00f3n y an\u00e1lisis por estado del registro.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FEC_DESDE</code> y <code>FEC_HASTA</code> </p> <ul> <li>Optimiza consultas en rangos temporales sobre la validez del beneficiario.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DIRECCION</code> </p> <ul> <li>Mejora b\u00fasquedas relacionadas con la localizaci\u00f3n de beneficiarios.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_BENEFICIARIO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_DOCUMENTO\nON [Transversal].[DIM_BENEFICIARIOS] (NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_TIPO_Y_DOCUMENTO\nON [Transversal].[DIM_BENEFICIARIOS] (TIPO_DOCUMENTO, NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_AFILIADO\nON [Transversal].[DIM_BENEFICIARIOS] (ID_AFILIADO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_NOMBRE y PRIMER_APELLIDO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_NOMBRES\nON [Transversal].[DIM_BENEFICIARIOS] (PRIMER_NOMBRE, PRIMER_APELLIDO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_AFILIACION y FECHA_RETIRO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_FECHAS\nON [Transversal].[DIM_BENEFICIARIOS] (FECHA_AFILIACION, FECHA_RETIRO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GENERO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_GENERO\nON [Transversal].[DIM_BENEFICIARIOS] (GENERO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADOREGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_ESTADOREGISTRO\nON [Transversal].[DIM_BENEFICIARIOS] (ESTADOREGISTRO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FEC_DESDE y FEC_HASTA\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_FECHAS_VALIDACION\nON [Transversal].[DIM_BENEFICIARIOS] (FEC_DESDE, FEC_HASTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DIRECCION\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_DIRECCION\nON [Transversal].[DIM_BENEFICIARIOS] (DIRECCION);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_capacidad_fisica","title":"[DIM_CAPACIDAD_FISICA]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_SALON</code> </p> <ul> <li>Clave primaria que asegura el acceso \u00fanico y r\u00e1pido a los registros de la tabla.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CAPACIDAD</code> </p> <ul> <li>Optimiza b\u00fasquedas y an\u00e1lisis basados en la capacidad f\u00edsica de los salones.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>JORNADA</code> y <code>BLOQUE_HORARIO</code> </p> <ul> <li>Facilita consultas relacionadas con horarios y turnos en una jornada espec\u00edfica.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GRUPO</code> </p> <ul> <li>Mejora las consultas que filtran por el grupo asignado al sal\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SEDE</code> </p> <ul> <li>Ayuda a optimizar las consultas relacionadas con sedes espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code> </p> <ul> <li>Mejora el rendimiento en consultas que relacionan las capacidades f\u00edsicas con unidades espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_SEDE</code> y <code>ID_UNIDAD</code> </p> <ul> <li>Permite consultas eficientes que cruzan datos de sedes y unidades.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_SALON\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo CAPACIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_CAPACIDAD\nON [Transversal].[DIM_CAPACIDAD_FISICA] (CAPACIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos JORNADA y BLOQUE_HORARIO\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_JORNADA_BLOQUE\nON [Transversal].[DIM_CAPACIDAD_FISICA] (JORNADA, BLOQUE_HORARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GRUPO\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_GRUPO\nON [Transversal].[DIM_CAPACIDAD_FISICA] (GRUPO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SEDE\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_ID_SEDE\nON [Transversal].[DIM_CAPACIDAD_FISICA] (ID_SEDE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_ID_UNIDAD\nON [Transversal].[DIM_CAPACIDAD_FISICA] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_SEDE y ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_SEDE_UNIDAD\nON [Transversal].[DIM_CAPACIDAD_FISICA] (ID_SEDE, ID_UNIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_cuenta_contable","title":"[DIM_CUENTA_CONTABLE]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CUENTA</code></p> <ul> <li>Es la clave primaria y asegura el acceso \u00fanico y eficiente a los registros.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CUENTA_NUMERO</code></p> <ul> <li>Optimiza consultas que filtran o agrupan por el n\u00famero de cuenta.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>CUENTA</code> y <code>CUENTA_HOMOLOGA</code></p> <ul> <li>Facilita b\u00fasquedas relacionadas con la cuenta y su homologaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_CUENTA</code></p> <ul> <li>Mejora el rendimiento de consultas que analizan o filtran cuentas por tipo.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>GRUPO_CUENTA</code> y <code>SUBGRUPO_CUENTA</code></p> <ul> <li>Acelera consultas que cruzan datos entre grupos y subgrupos de cuentas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO_REGISTRO</code></p> <ul> <li>Permite consultas r\u00e1pidas relacionadas con el estado de registro de las cuentas.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CUENTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo CUENTA_NUMERO\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_CUENTA_NUMERO\nON [Transversal].[DIM_CUENTA_CONTABLE] (CUENTA_NUMERO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CUENTA y CUENTA_HOMOLOGA\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_CUENTA_HOMOLOGA\nON [Transversal].[DIM_CUENTA_CONTABLE] (CUENTA, CUENTA_HOMOLOGA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_CUENTA\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_TIPO_CUENTA\nON [Transversal].[DIM_CUENTA_CONTABLE] (TIPO_CUENTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos GRUPO_CUENTA y SUBGRUPO_CUENTA\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_GRUPO_SUBGRUPO\nON [Transversal].[DIM_CUENTA_CONTABLE] (GRUPO_CUENTA, SUBGRUPO_CUENTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO_REGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_ESTADO_REGISTRO\nON [Transversal].[DIM_CUENTA_CONTABLE] (ESTADO_REGISTRO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_empresas","title":"[DIM_EMPRESAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_EMPRESA</code></p> <ul> <li>Es la clave primaria y permite b\u00fasquedas r\u00e1pidas por el identificador \u00fanico de empresa.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code></p> <ul> <li>Optimiza b\u00fasquedas y validaciones de empresas por n\u00famero de documento.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>RAZON_SOCIAL</code> y <code>SECTOR</code></p> <ul> <li>Facilita las b\u00fasquedas combinadas de empresas por raz\u00f3n social y sector.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>FECHA_AFILIACION</code></p> <ul> <li>Mejora el rendimiento en consultas relacionadas con la fecha de afiliaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADOREGISTRO</code> y <code>ESTADO</code></p> <ul> <li>Acelera consultas que filtran por el estado del registro y el estado de la empresa.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ACT_ECONOMICA</code></p> <ul> <li>Permite b\u00fasquedas m\u00e1s eficientes al filtrar por actividad econ\u00f3mica.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_EMPRESA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_DOCUMENTO\nON [Transversal].[DIM_EMPRESAS] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos RAZON_SOCIAL y SECTOR\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_RAZON_SOCIAL_SECTOR\nON [Transversal].[DIM_EMPRESAS] (RAZON_SOCIAL, SECTOR);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_AFILIACION\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_FECHA_AFILIACION\nON [Transversal].[DIM_EMPRESAS] (FECHA_AFILIACION);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ESTADOREGISTRO y ESTADO\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_ESTADO_REGISTRO_ESTADO\nON [Transversal].[DIM_EMPRESAS] (ESTADOREGISTRO, ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ACT_ECONOMICA\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_ID_ACT_ECONOMICA\nON [Transversal].[DIM_EMPRESAS] (ID_ACT_ECONOMICA);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_personal","title":"[DIM_PERSONAL]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PERSONAL</code></p> <ul> <li>Es la clave primaria que permite b\u00fasquedas r\u00e1pidas por el identificador \u00fanico del personal.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code></p> <ul> <li>Facilita b\u00fasquedas frecuentes por n\u00famero de documento, que es una consulta com\u00fan en sistemas de personal.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_UNIDAD</code> y <code>ID_SERVICIO</code></p> <ul> <li>Mejora la eficiencia de consultas relacionadas con la asignaci\u00f3n de personal a unidades y servicios.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO_CONTRATACION</code> y <code>FECHA_FIN_CONTRATACION</code></p> <ul> <li>Optimiza consultas que filtran registros por periodos de contrataci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code></p> <ul> <li>Permite b\u00fasquedas r\u00e1pidas por correo electr\u00f3nico, \u00fatil en sistemas de contacto.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>GENERO</code> y <code>NIVEL_INGLES</code></p> <ul> <li>Acelera consultas relacionadas con la demograf\u00eda del personal y sus habilidades ling\u00fc\u00edsticas.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PERSONAL\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_DOCUMENTO\nON [Transversal].[DIM_PERSONAL] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_UNIDAD e ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_ID_UNIDAD_ID_SERVICIO\nON [Transversal].[DIM_PERSONAL] (ID_UNIDAD, ID_SERVICIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO_CONTRATACION y FECHA_FIN_CONTRATACION\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_FECHA_CONTRATACION\nON [Transversal].[DIM_PERSONAL] (FECHA_INICIO_CONTRATACION, FECHA_FIN_CONTRATACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_CORREO\nON [Transversal].[DIM_PERSONAL] (CORREO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos GENERO y NIVEL_INGLES\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_GENERO_NIVEL_INGLES\nON [Transversal].[DIM_PERSONAL] (GENERO, NIVEL_INGLES);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_sedes","title":"[DIM_SEDES]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_SEDE</code></p> <ul> <li>Es la clave primaria que asegura la unicidad de cada sede y permite b\u00fasquedas r\u00e1pidas por su identificador.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SEDE</code></p> <ul> <li>Optimiza consultas que filtran o buscan registros por el nombre de la sede, lo cual es com\u00fan en reportes o visualizaciones.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_SEDE\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo SEDE\nCREATE NONCLUSTERED INDEX IX_DIM_SEDES_SEDE\nON [Transversal].[DIM_SEDES] (SEDE);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_servicios","title":"[DIM_SERVICIOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_SERVICIO</code></p> <ul> <li>Es la clave primaria que asegura la unicidad de cada servicio y permite b\u00fasquedas r\u00e1pidas por este identificador.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SERVICIO</code></p> <ul> <li>Optimiza consultas que buscan informaci\u00f3n espec\u00edfica por el nombre del servicio, com\u00fan en reportes y an\u00e1lisis.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CATEGORIA</code> y <code>COD_CATEGORIA</code></p> <ul> <li>Mejora el rendimiento de las consultas que agrupan o filtran servicios por categor\u00eda o c\u00f3digo de categor\u00eda.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ANIO_TARIFA</code> y <code>VAL_TARIFA</code></p> <ul> <li>Facilita las consultas que analizan las tarifas anuales de los servicios.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Permite relacionar eficientemente los servicios con su unidad correspondiente.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>CIUDAD</code> y <code>NOMBRE_ESTABLECIMIENTO</code></p> <ul> <li>Optimiza consultas relacionadas con la ubicaci\u00f3n y establecimiento del servicio.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_SERVICIO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo SERVICIO\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_SERVICIO\nON [Transversal].[DIM_SERVICIOS] (SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_CATEGORIA\nON [Transversal].[DIM_SERVICIOS] (CATEGORIA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_CATEGORIA\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_COD_CATEGORIA\nON [Transversal].[DIM_SERVICIOS] (COD_CATEGORIA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ANIO_TARIFA y VAL_TARIFA\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_ANIO_VAL_TARIFA\nON [Transversal].[DIM_SERVICIOS] (ANIO_TARIFA, VAL_TARIFA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_ID_UNIDAD\nON [Transversal].[DIM_SERVICIOS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CIUDAD y NOMBRE_ESTABLECIMIENTO\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_CIUDAD_ESTABLECIMIENTO\nON [Transversal].[DIM_SERVICIOS] (CIUDAD, NOMBRE_ESTABLECIMIENTO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_unidad","title":"[DIM_UNIDAD]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_UNIDAD</code></p> <ul> <li>Es la clave primaria, garantiza la unicidad de cada unidad y optimiza las b\u00fasquedas por este identificador.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>UNIDAD</code></p> <ul> <li>Facilita las consultas que filtran o buscan datos espec\u00edficos por el nombre de la unidad, com\u00fan en reportes y an\u00e1lisis.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_UNIDAD\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDAD_UNIDAD\nON [Transversal].[DIM_UNIDAD] (UNIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_unidades_organizativas","title":"[DIM_UNIDADES_ORGANIZATIVAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CEBE</code></p> <ul> <li>Es la clave primaria, asegura unicidad y optimiza b\u00fasquedas espec\u00edficas por el identificador de unidad organizativa.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CEBE</code></p> <ul> <li>Facilita b\u00fasquedas r\u00e1pidas y filtrados por el c\u00f3digo de la unidad organizativa (<code>CEBE</code>).</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DESCRIPCION_BREVE</code> y <code>DESCRIPCION_COMPLETA</code></p> <ul> <li>Acelera las consultas que buscan por descripciones espec\u00edficas o detalladas de la unidad.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>DEPARTAMENTO</code>, <code>AREA</code>, y <code>SUBAREA</code></p> <ul> <li>Optimiza consultas relacionadas con la jerarqu\u00eda organizativa (departamentos, \u00e1reas, sub\u00e1reas).</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>SEGMENTO</code> y <code>DESCRIPCION_SEGMENTO</code></p> <ul> <li>Mejora el rendimiento de consultas segmentadas por estos campos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CODIGO_SSF</code> y <code>NOMBRE_SSF</code></p> <ul> <li>Soporta b\u00fasquedas relacionadas con los c\u00f3digos y nombres del sistema de soporte financiero.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CEBE\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo CEBE\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_CEBE\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (CEBE);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos DESCRIPCION_BREVE y DESCRIPCION_COMPLETA\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_DESCRIPCION\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (DESCRIPCION_BREVE, DESCRIPCION_COMPLETA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos DEPARTAMENTO, AREA y SUBAREA\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_DEPARTAMENTO_AREA\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (DEPARTAMENTO, AREA, SUBAREA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos SEGMENTO y DESCRIPCION_SEGMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_SEGMENTO\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (SEGMENTO, DESCRIPCION_SEGMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos CODIGO_SSF y NOMBRE_SSF\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_CODIGO_SSF\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (CODIGO_SSF, NOMBRE_SSF);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_aportes_shr_det","title":"[FACT_APORTES_SHR_DET]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code> y <code>ID_AFILIADO</code></p> <ul> <li>Optimiza las b\u00fasquedas y relaciones con las tablas de dimensiones relacionadas como DIM_EMPRESAS y DIM_AFILIADOS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PERIODO</code></p> <ul> <li>Mejora las consultas que filtran o agrupan por periodos espec\u00edficos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Acelera las b\u00fasquedas y an\u00e1lisis de datos basados en fechas, que suelen ser comunes en tablas de hechos.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>OPBEL</code>, <code>BELNR</code> y <code>MOVIMIENTO</code></p> <ul> <li>Facilita la recuperaci\u00f3n de datos relacionados con transacciones espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_CONTABLE</code> y <code>NUM_CUENTA</code></p> <ul> <li>Optimiza consultas basadas en las cuentas contables y fechas asociadas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>APORTE</code> y <code>INTERES</code></p> <ul> <li>Acelera consultas que analizan montos de aportes e intereses.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>FECHA_ACTUALIZACION</code></p> <ul> <li>Mejora el rendimiento en la detecci\u00f3n de cambios recientes.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para los campos ID_EMPRESA y ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_EMPRESA_AFILIADO\nON [Transversal].[FACT_APORTES_SHR_DET] (ID_EMPRESA, ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_PERIODO\nON [Transversal].[FACT_APORTES_SHR_DET] (PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_FECHA\nON [Transversal].[FACT_APORTES_SHR_DET] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos OPBEL, BELNR y MOVIMIENTO\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_TRANSACCION\nON [Transversal].[FACT_APORTES_SHR_DET] (OPBEL, BELNR, MOVIMIENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_CONTABLE y NUM_CUENTA\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_CONTABLE_CUENTA\nON [Transversal].[FACT_APORTES_SHR_DET] (FECHA_CONTABLE, NUM_CUENTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos APORTE y INTERES\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_APORTE_INTERES\nON [Transversal].[FACT_APORTES_SHR_DET] (APORTE, INTERES);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_ACTUALIZACION\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_FECHA_ACTUALIZACION\nON [Transversal].[FACT_APORTES_SHR_DET] (FECHA_ACTUALIZACION);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_convenios","title":"[FACT_CONVENIOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Acelera consultas basadas en fechas, especialmente aquellas relacionadas con la dimensi\u00f3n de tiempo.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza consultas que filtran por unidad, en relaci\u00f3n con la tabla de dimensi\u00f3n DIM_UNIDAD.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code></p> <ul> <li>Mejora la eficiencia de b\u00fasquedas relacionadas con programas espec\u00edficos, permitiendo una mejor integraci\u00f3n con las consultas de an\u00e1lisis.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code></p> <ul> <li>Facilita consultas que involucren rangos de fechas, comunes en an\u00e1lisis de duraci\u00f3n de convenios.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>VALOR_CONVENIO</code></p> <ul> <li>Acelera consultas que analizan valores monetarios de los convenios.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_CONVENIO</code> y <code>MUNICIPIO</code></p> <ul> <li>Permite consultas r\u00e1pidas que filtran por estado y ubicaci\u00f3n de los convenios.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_FECHA\nON [Transversal].[FACT_CONVENIOS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_UNIDAD\nON [Transversal].[FACT_CONVENIOS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_PROGRAMA\nON [Transversal].[FACT_CONVENIOS] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_FECHAS\nON [Transversal].[FACT_CONVENIOS] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo VALOR_CONVENIO\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_VALOR\nON [Transversal].[FACT_CONVENIOS] (VALOR_CONVENIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ESTADO_CONVENIO y MUNICIPIO\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_ESTADO_MUNICIPIO\nON [Transversal].[FACT_CONVENIOS] (ESTADO_CONVENIO, MUNICIPIO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_detalle_contable","title":"[FACT_DETALLE_CONTABLE]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CUENTA</code></p> <ul> <li>Facilita consultas y uniones relacionadas con cuentas contables en la dimensi\u00f3n DIM_CUENTA_CONTABLE.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora la eficiencia de consultas relacionadas con la dimensi\u00f3n de tiempo para an\u00e1lisis contable por per\u00edodos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CEBE</code></p> <ul> <li>Optimiza las b\u00fasquedas relacionadas con unidades organizativas en la dimensi\u00f3n DIM_UNIDADES_ORGANIZATIVAS.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_REGISTRO_SAP</code> y <code>FECHA_PROCESO</code></p> <ul> <li>Acelera las consultas que analizan registros por rangos de fechas o estados de proceso.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>IMPORTE</code> y <code>RESULTADO_EJERCICIO</code></p> <ul> <li>Mejora el rendimiento de an\u00e1lisis de resultados financieros y balances.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_CUENTA\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_ID_CUENTA\nON [Transversal].[FACT_DETALLE_CONTABLE] (ID_CUENTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_ID_FECHA\nON [Transversal].[FACT_DETALLE_CONTABLE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CEBE\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_ID_CEBE\nON [Transversal].[FACT_DETALLE_CONTABLE] (ID_CEBE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_REGISTRO_SAP y FECHA_PROCESO\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_FECHAS\nON [Transversal].[FACT_DETALLE_CONTABLE] (FECHA_REGISTRO_SAP, FECHA_PROCESO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos IMPORTE y RESULTADO_EJERCICIO\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_IMPORTE_RESULTADO\nON [Transversal].[FACT_DETALLE_CONTABLE] (IMPORTE, RESULTADO_EJERCICIO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_encuestas","title":"[FACT_ENCUESTAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora el rendimiento en consultas relacionadas con an\u00e1lisis temporales y de periodos de encuestas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza las consultas relacionadas con unidades y servicios prestados.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_AFILIADO</code>, <code>ID_EMPRESA</code>, <code>ID_BENEFICIARIO</code>, y <code>ID_APORTANTE</code></p> <ul> <li>Cada uno mejora las b\u00fasquedas en las relaciones con las respectivas dimensiones.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code></p> <ul> <li>Acelera consultas espec\u00edficas por identificaci\u00f3n de los encuestados.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SERVICIO</code> y <code>CALIFICACION</code></p> <ul> <li>Mejora el rendimiento en consultas anal\u00edticas sobre el servicio y su evaluaci\u00f3n.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_FECHA\nON [Transversal].[FACT_ENCUESTAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_UNIDAD\nON [Transversal].[FACT_ENCUESTAS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_AFILIADO\nON [Transversal].[FACT_ENCUESTAS] (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_EMPRESA\nON [Transversal].[FACT_ENCUESTAS] (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_BENEFICIARIO\nON [Transversal].[FACT_ENCUESTAS] (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_APORTANTE\nON [Transversal].[FACT_ENCUESTAS] (ID_APORTANTE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_TIPO_DOCUMENTO_DOCUMENTO\nON [Transversal].[FACT_ENCUESTAS] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_SERVICIO\nON [Transversal].[FACT_ENCUESTAS] (SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_CALIFICACION\nON [Transversal].[FACT_ENCUESTAS] (CALIFICACION);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_encuestas_psr","title":"[FACT_ENCUESTAS_PSR]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora el rendimiento de consultas por fechas y an\u00e1lisis temporales de encuestas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PROGRAMA</code> y <code>ACTIVIDAD_PREGUNTA</code></p> <ul> <li>Optimiza las b\u00fasquedas y an\u00e1lisis por tipo de programa y actividades asociadas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code></p> <ul> <li>Acelera consultas espec\u00edficas por identificaci\u00f3n de los encuestados.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CALIFICACION</code></p> <ul> <li>Mejora el rendimiento en consultas que analicen resultados por calificaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndices no cl\u00faster para <code>ID_AFILIADO</code>, <code>ID_BENEFICIARIO</code>, <code>ID_APORTANTE</code>, y <code>ID_EMPRESA</code></p> <ul> <li>Cada uno optimiza consultas que relacionen la tabla con sus dimensiones correspondientes.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_FECHA\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos PROGRAMA y ACTIVIDAD_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_PROGRAMA_ACTIVIDAD\nON [Transversal].[FACT_ENCUESTAS_PSR] (PROGRAMA, ACTIVIDAD_PREGUNTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_TIPO_DOCUMENTO_DOCUMENTO\nON [Transversal].[FACT_ENCUESTAS_PSR] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_CALIFICACION\nON [Transversal].[FACT_ENCUESTAS_PSR] (CALIFICACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_AFILIADO\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_BENEFICIARIO\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_APORTANTE\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_APORTANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_EMPRESA\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_EMPRESA);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_iniciativas","title":"[FACT_INICIATIVAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora las consultas basadas en tiempo, como filtrados por fechas de inicio o fin de iniciativas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza las b\u00fasquedas y relaciones con la dimensi\u00f3n de unidades organizativas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code></p> <ul> <li>Facilita las consultas basadas en rangos de fechas para iniciativas activas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_INICIATIVA</code></p> <ul> <li>Mejora el rendimiento de b\u00fasquedas basadas en el nombre de iniciativas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>OBSERVACIONES</code></p> <ul> <li>Optimiza las b\u00fasquedas por notas o comentarios asociados a las iniciativas.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_ID_FECHA\nON [Transversal].[FACT_INICIATIVAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_ID_UNIDAD\nON [Transversal].[FACT_INICIATIVAS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_FECHA_INICIO_FIN\nON [Transversal].[FACT_INICIATIVAS] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_INICIATIVA\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_NOMBRE_INICIATIVA\nON [Transversal].[FACT_INICIATIVAS] (NOMBRE_INICIATIVA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_OBSERVACIONES\nON [Transversal].[FACT_INICIATIVAS] (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_pqrs","title":"[FACT_PQRS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora las consultas basadas en tiempo, como filtros por fechas de creaci\u00f3n, resoluci\u00f3n o vencimiento.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza las b\u00fasquedas relacionadas con unidades espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_CREACION</code>, <code>FECHA_RESOLUCION</code> y <code>FECHA_VENCIMIENTO</code></p> <ul> <li>Acelera las consultas que involucran rangos de fechas para seguimiento de PQRS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO</code></p> <ul> <li>Incrementa la eficiencia en consultas relacionadas con el estado de las PQRS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_PQRS</code></p> <ul> <li>Facilita la b\u00fasqueda y clasificaci\u00f3n por tipo de PQRS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>ID_BENEFICIARIO</code>, <code>ID_APORTANTE</code></p> <ul> <li>Optimiza las relaciones con dimensiones relacionadas para an\u00e1lisis detallados.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_ID_FECHA\nON [Transversal].[FACT_PQRS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_ID_UNIDAD\nON [Transversal].[FACT_PQRS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos de fechas\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_FECHAS\nON [Transversal].[FACT_PQRS] (FECHA_CREACION, FECHA_RESOLUCION, FECHA_VENCIMIENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_ESTADO\nON [Transversal].[FACT_PQRS] (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_PQRS\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_TIPO_PQRS\nON [Transversal].[FACT_PQRS] (TIPO_PQRS);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos de dimensiones relacionadas\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_RELACIONES\nON [Transversal].[FACT_PQRS] (ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_presupuesto","title":"[FACT_PRESUPUESTO]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora la eficiencia en consultas que analizan presupuestos basados en periodos de tiempo.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CUENTA</code></p> <ul> <li>Optimiza la b\u00fasqueda y an\u00e1lisis de presupuestos asociados a cuentas contables espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CEBE</code></p> <ul> <li>Aumenta el rendimiento en consultas relacionadas con unidades organizativas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_TIPO_PRESUPUESTO</code> y <code>SEGMENT</code></p> <ul> <li>Facilita el an\u00e1lisis de presupuestos seg\u00fan el tipo y segmento.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para campos relacionados con valores (<code>INGRESOS</code>, <code>GASTOS</code>, <code>COSTOS</code>)</p> <ul> <li>Mejora el rendimiento de c\u00e1lculos financieros basados en estos campos.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_ID_FECHA\nON [Transversal].[FACT_PRESUPUESTO] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CUENTA\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_ID_CUENTA\nON [Transversal].[FACT_PRESUPUESTO] (ID_CUENTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CEBE\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_ID_CEBE\nON [Transversal].[FACT_PRESUPUESTO] (ID_CEBE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_TIPO_PRESUPUESTO y SEGMENT\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_TIPO_SEGMENT\nON [Transversal].[FACT_PRESUPUESTO] (ID_TIPO_PRESUPUESTO, SEGMENT);\nGO\n\n-- \u00cdndices no cl\u00faster para campos relacionados con valores\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_INGRESOS\nON [Transversal].[FACT_PRESUPUESTO] (INGRESOS, INGRESOS_OPERACIONALES);\nGO\n\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_GASTOS\nON [Transversal].[FACT_PRESUPUESTO] (GASTOS, GASTOS_OPERACIONALES, GASTOS_OPERACIONALES_ADMIN);\nGO\n\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_COSTOS\nON [Transversal].[FACT_PRESUPUESTO] (COSTOS);\nGO\n</code></pre>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/","title":"00. WEB SCRAPING","text":"<p>El contenido proporcionado documenta una amplia variedad de componentes y tareas en una soluci\u00f3n SSIS. Aqu\u00ed se integran scripts de Python como tareas externas para realizar operaciones espec\u00edficas. A continuaci\u00f3n, se detalla la actualizaci\u00f3n del modelo con base en este contenido.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#introduccion","title":"Introducci\u00f3n","text":"<p>El modelo de integraci\u00f3n documentado combina tareas de procesamiento de datos en SSIS con la ejecuci\u00f3n de scripts de Python externos. Estos scripts permiten realizar validaciones avanzadas, procesamiento din\u00e1mico y conexiones con sistemas externos como SharePoint. La soluci\u00f3n garantiza una ejecuci\u00f3n eficiente, flexible y configurable gracias al uso de expresiones del proyecto para adaptar rutas de trabajo y ejecutables a diferentes entornos.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#resumen-general","title":"Resumen General","text":"<p>Objetivos:</p> <ol> <li>Automatizaci\u00f3n: Integrar tareas repetitivas mediante scripts de Python.</li> <li>Estandarizaci\u00f3n: Establecer configuraciones din\u00e1micas para adaptabilidad en entornos variados.</li> <li>Escalabilidad: Dise\u00f1ar un modelo modular para incorporar nuevos flujos.</li> </ol> <p>Componentes Clave:</p> <ul> <li>Scripts Python:<ul> <li>Conexi\u00f3n y extracci\u00f3n desde SharePoint.</li> <li>Procesamiento de datos educativos, administrativos y financieros.</li> </ul> </li> <li>Tareas SSIS:<ul> <li>Ejecuci\u00f3n de scripts externos con configuraciones din\u00e1micas.</li> <li>Validaci\u00f3n y carga en el Data Warehouse.</li> </ul> </li> </ul> <p>Fuentes y Destinos:</p> <ul> <li>Fuentes:<ul> <li>Archivos planos, Excel y bases de datos relacionales.</li> <li>Sistemas externos a trav\u00e9s de scripts Python.</li> </ul> </li> <li>Destinos:<ul> <li>Tablas de hechos y dimensiones en el Data Warehouse <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as Python Executable\n    participant Script as Python Script\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; Python: Ejecuta script con configuraciones din\u00e1micas\n    Python -&gt;&gt; Script: Procesa datos o conecta con sistemas externos\n    Script -&gt;&gt; Python: Devuelve resultado\n    Python -&gt;&gt; SSIS: C\u00f3digo de retorno\n    SSIS -&gt;&gt; DWH: Carga datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#buenas-practicas","title":"Buenas Pr\u00e1cticas","text":"<ol> <li> <p>Configuraci\u00f3n Din\u00e1mica:</p> <ul> <li>Definir ejecutables y directorios mediante variables de proyecto.</li> <li>Adaptar las rutas seg\u00fan los entornos de desarrollo, pruebas y producci\u00f3n.</li> </ul> </li> <li> <p>Registro de Logs:</p> <ul> <li>Capturar la salida de los scripts Python para auditor\u00eda y resoluci\u00f3n de errores.</li> <li>Configurar registros detallados en SSIS.</li> </ul> </li> <li> <p>Compatibilidad:</p> <ul> <li>Validar la versi\u00f3n de Python y las dependencias necesarias para cada script.</li> <li>Probar la ejecuci\u00f3n en entornos similares al de producci\u00f3n.</li> </ul> </li> <li> <p>Ejecuci\u00f3n Segura:</p> <ul> <li>Establecer manejadores para c\u00f3digos de retorno inesperados.</li> <li>Asegurar la idempotencia de los scripts para evitar duplicidades.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-tecnicos","title":"Detalles T\u00e9cnicos","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componentes-principales","title":"Componentes Principales:","text":"<p>1. Ejecuci\u00f3n de Scripts Python:</p> <ul> <li>Propiedades Clave:<ul> <li>Ejecutable: Ruta del ejecutable de Python.</li> <li>Argumentos: Nombre del script y par\u00e1metros adicionales.</li> <li>Directorio de Trabajo: Ruta base configurada din\u00e1micamente.</li> </ul> </li> <li>C\u00f3digo de Retorno:<ul> <li>Configurado para no marcar fallos autom\u00e1ticamente.</li> </ul> </li> </ul> <p>2. Conexiones con Sistemas Externos:</p> <ul> <li>Scripts dedicados para conectar y extraer datos desde SharePoint.</li> <li>Generaci\u00f3n de registros detallados durante el proceso.</li> </ul> <p>3. Tareas de Procesamiento:</p> <ul> <li>Scripts que procesan datos educativos (docentes, matr\u00edculas, egresados).</li> <li>Scripts para consolidar datos operativos (ausencias, ingresos).</li> </ul>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#secuencia-de-operaciones","title":"Secuencia de Operaciones","text":"<ol> <li>Lee el valor de las expresiones del proyecto para determinar el ejecutable y el directorio de trabajo.</li> <li>Construye la instrucci\u00f3n de ejecuci\u00f3n del script.</li> <li>Ejecuta el script en el contexto del directorio especificado.</li> <li>Verifica el c\u00f3digo de retorno para determinar el estado de la tarea, pero no marca como fallo si no es un valor de \u00e9xito.</li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Executable\n    participant Script as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecutar `python.exe archivo_python.py`\n    Python -&gt;&gt; Script: Inicia ejecuci\u00f3n\n    Script -&gt;&gt; Python: Devuelve resultado\n    Python -&gt;&gt; SSIS: C\u00f3digo de retorno (no se fuerza fallo)</code></pre>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#consideraciones","title":"Consideraciones","text":"<ol> <li>Versiones de Python: El ejecutable especificado debe ser compatible con el script, asegurando que las bibliotecas y dependencias est\u00e9n instaladas.</li> <li>Errores en el Script: La tarea no fallar\u00e1 autom\u00e1ticamente si el c\u00f3digo de retorno no es exitoso. Si se requiere manejar este comportamiento, se debe incluir l\u00f3gica adicional en el flujo de trabajo.</li> <li>Configuraci\u00f3n Din\u00e1mica: Las expresiones del proyecto permiten adaptar el ejecutable y el directorio de trabajo seg\u00fan las configuraciones del entorno, facilitando portabilidad y mantenimiento.</li> <li>Control de Log: Configurar un registro adecuado para capturar la salida del script, especialmente si se omiten errores de retorno.</li> </ol> <p>Este componente es ideal para integrar scripts externos de Python en el flujo de ETL de SSIS, proporcionando flexibilidad para realizar tareas avanzadas o espec\u00edficas fuera del entorno nativo de SSIS.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#desarrollo-empresarial","title":"Desarrollo Empresarial","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01-docentes_desarrollo_empresarial","title":"Componente <code>Ejecutar Proceso: 01 Docentes_desarrollo_empresarial</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.Docentes_desarrollo_empresarial.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_docentes","title":"Componente <code>Ejecutar Proceso: emp_Docentes</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_1","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_01_Docentes.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-02preinscritospy","title":"Componente <code>Ejecutar Proceso: 02.Preinscritos.py</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_2","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>02.Preinscritos.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_03_preinscritos","title":"Componente <code>Ejecutar Proceso: emp_03_preinscritos</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_3","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_03_preinscritos.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-03listado_matriculas_emp","title":"Componente <code>Ejecutar Proceso: 03.Listado_matriculas_emp</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_4","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>03.Listado_matriculas_emp.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_02_listado_matriculas","title":"Componente <code>Ejecutar Proceso: emp_02_listado_matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_5","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_02_listado_matriculas.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04consolidado_inasistencias","title":"Componente <code>Ejecutar Proceso: 04.Consolidado_inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_6","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_06_consolidado_inasistencias","title":"Componente <code>Ejecutar Proceso: emp_06_consolidado_Inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_7","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_06_consolidado_Inasistencias.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-06egresados_graduados_empresarial","title":"Componente <code>Ejecutar Proceso: 06.Egresados_graduados_empresarial</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_8","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>06.Egresados_graduados_empresarial.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_04_egresados_graduados","title":"Componente <code>Ejecutar Proceso: emp_04_egresados_Graduados</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_9","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_04_egresados_Graduados.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-05estudiantes_inasistencias","title":"Componente <code>Ejecutar Proceso: 05.Estudiantes_inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_10","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>05.Estudiantes_inasistencias.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_05_estudiantes_inasistencias","title":"Componente <code>Ejecutar Proceso: emp_05_Estudiantes_inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_11","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_05_Estudiantes_inasistencias.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#desarrollo-empresarial-ejecucion-de-nodos-en-paralelo","title":"Desarrollo Empresarial <code>Ejecucion de nodos en paralelo</code>","text":"<p>Para optimizar los tiempos de procesamiento del scraping, los siguientes nodos del paquete se ejecutan en paralelo:</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-tarde-c-p","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Tarde \"c, p\"</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Tarde para el grupo identificado con el par\u00e1metro \"c, p\". La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python definido mediante variables de proyecto, lo que permite adaptar la configuraci\u00f3n a diferentes entornos.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_12","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py</code> con el par\u00e1metro <code>--alfabeto \"c, p\"</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py --alfabeto \"c, p\"</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no marca error si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, lo que permite centralizar y actualizar esta configuraci\u00f3n seg\u00fan el entorno.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts, la cual se concatena con la ruta relativa <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-tarde-lote-1","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Tarde Lote 1</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias del turno Tarde, espec\u00edficamente para el \u201cLote 1\u201d. Se utiliza un conjunto particular de par\u00e1metros para definir el alfabeto de procesamiento, que en este caso incluye caracteres especiales, d\u00edgitos y letras. La tarea se ejecuta desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python configurado a trav\u00e9s de variables de proyecto, lo que permite su adaptaci\u00f3n a distintos entornos.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_13","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py</code> con el par\u00e1metro <code>--alfabeto \"\u00bf, 1, 2, 3, 4, 5, a, b, d, e, f, g, h, i, j, k, l\"</code>     desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   La ruta del ejecutable se determina din\u00e1micamente a trav\u00e9s de la variable de proyecto <code>@[$Project::Python_Executable]</code>, que en tiempo de ejecuci\u00f3n corresponde a: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py --alfabeto \"\u00bf, 1, 2, 3, 4, 5, a, b, d, e, f, g, h, i, j, k, l\"</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no se marca como fallida si el c\u00f3digo de retorno no indica \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>):   Se utiliza un valor de 3, lo que sugiere que la tarea puede beneficiarse de mayor paralelismo en su ejecuci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python. Permite centralizar la configuraci\u00f3n del int\u00e9rprete, facilitando su actualizaci\u00f3n en distintos entornos (desarrollo, pruebas o producci\u00f3n).</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Esta variable se concatena con la ruta relativa <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-tarde-lote-3","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Tarde Lote 3</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias del turno Tarde para el \u201cLote 3\u201d. La tarea se ejecuta desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python definido mediante variables de proyecto, lo que facilita la configuraci\u00f3n adaptable a distintos entornos. Se configura para que, en caso de que el c\u00f3digo de retorno del proceso no indique \u00e9xito, el flujo ETL no se interrumpa.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_14","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py</code> con el par\u00e1metro <code>--alfabeto \"m, n, \u00f1, o, q, r, s, t, u, v, w, x, y, z\"</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Tarde_Alf.py --alfabeto \"m, n, \u00f1, o, q, r, s, t, u, v, w, x, y, z\"</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura mediante la expresi\u00f3n: <code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\01.Q10\\\\02.Educacion_Continua\"</code></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea contin\u00faa el flujo ETL aunque el proceso retorne un c\u00f3digo diferente al de \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>):   Se utiliza un valor de 1, lo que indica que la ejecuci\u00f3n se realizar\u00e1 en un \u00fanico hilo.</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python. Esta configuraci\u00f3n centralizada permite actualizar la ubicaci\u00f3n del int\u00e9rprete sin modificar la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se concatena con la ruta relativa <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-manana-c","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Ma\u00f1ana c</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Ma\u00f1ana para el grupo identificado con el par\u00e1metro \"c\". La tarea se ejecuta desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python definido a trav\u00e9s de variables de proyecto, permitiendo adaptar la configuraci\u00f3n a distintos entornos. Adem\u00e1s, se ha configurado para que, incluso si el proceso retorna un c\u00f3digo de error, el flujo ETL contin\u00fae sin marcar la tarea como fallida.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_15","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py</code> con el par\u00e1metro <code>--alfabeto c</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se establece mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>, la cual, en tiempo de ejecuci\u00f3n, corresponde a la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py --alfabeto c</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no se marca como fallida si el c\u00f3digo de retorno del proceso no indica \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>6</code> (sugiere que la tarea est\u00e1 optimizada para aprovechar hasta 6 hilos durante su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, permitiendo centralizar y actualizar esta configuraci\u00f3n sin modificar directamente la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se utiliza para establecer el contexto de ejecuci\u00f3n mediante la concatenaci\u00f3n con la ruta relativa <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-manana-p","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Ma\u00f1ana p</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Ma\u00f1ana para el grupo identificado con el par\u00e1metro \"p\". La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python configurado mediante variables de proyecto, lo que permite adaptar la tarea a diferentes entornos. Adem\u00e1s, se ha configurado para que, en caso de que el c\u00f3digo de retorno del proceso no indique \u00e9xito, el flujo ETL contin\u00fae sin marcar la tarea como fallida.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_16","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py</code> con el par\u00e1metro <code>--alfabeto p</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Definido a trav\u00e9s de la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py --alfabeto p</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Configurado din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea contin\u00faa el flujo ETL aunque el proceso retorne un c\u00f3digo diferente al de \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>7</code> (sugiere que la tarea puede beneficiarse de un mayor paralelismo durante su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, lo que permite centralizar y actualizar esta configuraci\u00f3n sin modificar la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se utiliza para establecer el contexto de ejecuci\u00f3n al concatenarse con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-manana-lote-1","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Ma\u00f1ana Lote 1</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Ma\u00f1ana para el \"Lote 1\". La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python configurado mediante variables de proyecto, permitiendo su adaptaci\u00f3n a distintos entornos. La tarea est\u00e1 dise\u00f1ada para continuar el flujo ETL incluso si el proceso retorna un c\u00f3digo de error.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_17","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py</code> con el par\u00e1metro <code>--alfabeto a, b, d, e, f, g, h, i, j, k, l</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>, que en tiempo de ejecuci\u00f3n corresponde a: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py --alfabeto a, b, d, e, f, g, h, i, j, k, l</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Configurado din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea contin\u00faa el flujo ETL aunque el proceso retorne un c\u00f3digo de error).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>8</code> (se sugiere que la tarea puede aprovechar el paralelismo utilizando hasta 8 hilos durante su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, centralizando la configuraci\u00f3n para facilitar su actualizaci\u00f3n y adaptaci\u00f3n a diferentes entornos (desarrollo, pruebas, producci\u00f3n).</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se concatena con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto adecuado de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-manana-lote-2","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Ma\u00f1ana Lote 2</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias del turno Ma\u00f1ana, espec\u00edficamente para el \"Lote 2\". La tarea se ejecuta desde un directorio de trabajo espec\u00edfico y utiliza el ejecutable de Python definido a trav\u00e9s de variables de proyecto, lo que permite adaptar la configuraci\u00f3n a distintos entornos. Adem\u00e1s, la tarea est\u00e1 configurada para que el flujo ETL contin\u00fae su ejecuci\u00f3n incluso si el proceso retorna un c\u00f3digo de error.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_18","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py</code> con el par\u00e1metro <code>--alfabeto m, n, \u00f1, o, q, r, s, t, u, v, w, x, y, z</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Ma\u00f1ana.py --alfabeto m, n, \u00f1, o, q, r, s, t, u, v, w, x, y, z</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura mediante la expresi\u00f3n: <code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\01.Q10\\\\02.Educacion_Continua\"</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no marca error si el proceso retorna un c\u00f3digo diferente al de \u00e9xito).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>9</code> (sugiere que la tarea puede aprovechar hasta 9 hilos para mejorar el procesamiento paralelo).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, permitiendo centralizar y actualizar esta configuraci\u00f3n seg\u00fan el entorno (desarrollo, pruebas, producci\u00f3n).</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts, la cual se concatena con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto adecuado de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-sabado","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Sabado</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondiente al d\u00eda S\u00e1bado. La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza un ejecutable de Python configurado a trav\u00e9s de variables de proyecto, lo que permite la adaptabilidad a distintos entornos. Adem\u00e1s, la tarea est\u00e1 dise\u00f1ada para continuar el flujo ETL incluso si el proceso retorna un c\u00f3digo de error.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_19","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Parametro.py</code> con el par\u00e1metro <code>--programa Sabado</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, la ruta del ejecutable es: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Parametro.py --programa Sabado</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Configurado din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no se marca como fallida si el proceso retorna un c\u00f3digo de error).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>5</code> (sugiere que la tarea puede aprovechar hasta 5 hilos durante su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, permitiendo centralizar y actualizar esta configuraci\u00f3n sin modificar directamente la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts, la cual se concatena con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code> para establecer el contexto adecuado de ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04-consolidado_inasistencias-noche","title":"Componente <code>Ejecutar Proceso: 04 Consolidado_inasistencias Noche</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias correspondientes al turno Noche. La ejecuci\u00f3n se realiza desde un directorio de trabajo espec\u00edfico y utiliza el ejecutable de Python definido mediante variables de proyecto, lo que permite adaptar la configuraci\u00f3n a distintos entornos. Adem\u00e1s, la tarea est\u00e1 configurada para que el flujo ETL contin\u00fae ejecut\u00e1ndose incluso si el proceso retorna un c\u00f3digo de error.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_20","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>04.Consolidado_inasistencias-emp_Parametro.py</code> con el par\u00e1metro <code>--programa Noche</code> desde el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Definido mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, se utiliza la ruta: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias-emp_Parametro.py --programa Noche</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Configurado din\u00e1micamente mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code></li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea no se marca como fallida si el proceso retorna un c\u00f3digo de error).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>4</code> (sugiere que la tarea est\u00e1 configurada para utilizar hasta 4 hilos en su ejecuci\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que define la ruta del ejecutable de Python, permitiendo centralizar y actualizar esta configuraci\u00f3n seg\u00fan el entorno (desarrollo, pruebas, producci\u00f3n).</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se utiliza para establecer el contexto de ejecuci\u00f3n mediante la concatenaci\u00f3n con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_consolidado_inasistencias","title":"Componente <code>Ejecutar Proceso: emp_consolidado_Inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que consolida la informaci\u00f3n de inasistencias a nivel empresarial. El proceso se ejecuta desde un directorio configurado para SharePoint, lo que indica que el script probablemente interact\u00faa con recursos o archivos alojados en un entorno SharePoint. La ejecuci\u00f3n se realiza utilizando un ejecutable de Python definido mediante variables de proyecto, lo que permite centralizar la configuraci\u00f3n y adaptarla a diferentes entornos sin modificaciones manuales.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_21","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n:     Ejecuta el script de Python <code>emp_06_consolidado_Inasistencias.py</code> desde el directorio configurado para SharePoint. Este script se encarga de consolidar y procesar datos de inasistencias en el \u00e1mbito empresarial.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>):   Se define mediante la variable de proyecto <code>@[$Project::Python_Executable]</code>. En tiempo de ejecuci\u00f3n, la ruta del ejecutable es: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>emp_06_consolidado_Inasistencias.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>):   Se configura mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con <code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint</code>, lo que establece el contexto de ejecuci\u00f3n en el entorno Sharepoint.</li> <li>C\u00f3digo de Retorno Esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (la tarea contin\u00faa el flujo ETL aunque el proceso retorne un c\u00f3digo de error).</li> <li>Hilos de Ejecuci\u00f3n (<code>ThreadHint</code>): <code>1</code> (la tarea se ejecuta de manera secuencial en un \u00fanico hilo).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>:     Variable que centraliza la ruta del ejecutable de Python, permitiendo actualizarla de manera global sin modificar la configuraci\u00f3n individual de la tarea.</li> <li><code>@[$Project::Working_Directory]</code>:     Variable que define la ruta base del directorio de trabajo para los scripts. Se utiliza para establecer el contexto de ejecuci\u00f3n, en este caso, apuntando al directorio SharePoint.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#cedesarrollo","title":"Cedesarrollo","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01docentes_cedesarrollo","title":"Componente <code>Ejecutar Proceso: 01.Docentes_Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_22","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.Docentes_Cedesarrollo.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_01_procesar_docentes","title":"Componente <code>Ejecutar Proceso: cede_01_procesar_docentes</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_23","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_01_procesar_docentes.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-02disenio_curricular","title":"Componente <code>Ejecutar Proceso:  02.Disenio_curricular</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_24","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_24","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>02.Disenio_curricular.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_02_procesar_diseno_curricular","title":"Componente <code>Ejecutar Proceso: cede_02_procesar_Dise\u00f1o_Curricular</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_25","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_25","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_02_procesar_Dise\u00f1o_Curricular.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-03listado_matriculas","title":"Componente <code>Ejecutar Proceso: 03.Listado_matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_26","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_26","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>03.Listado_matriculas.py --semestre True</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_03_procesar_listado_matriculas","title":"Componente <code>Ejecutar Proceso: cede_03_procesar_listado_matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_27","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_27","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_03_procesar_listado_matriculas.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04ingresos","title":"Componente <code>Ejecutar Proceso: 04.Ingresos</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_28","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_28","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Ingresos.py --semestre True</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_04_procesar_cede_ingresos","title":"Componente <code>Ejecutar Proceso: cede_04_procesar_cede_Ingresos</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_29","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_29","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_04_procesar_cede_Ingresos.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-05historico_notas_cedesarrollo","title":"Componente <code>Ejecutar Proceso: 05.Historico_notas_Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_30","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_30","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>05.Historico_notas_Cedesarrollo.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_05_cede_historico_notas","title":"Componente <code>Ejecutar Proceso:  cede_05_cede_Historico_Notas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_31","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_31","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_05_cede_Historico_Notas.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-06egresados_graduados_cedesarrollo","title":"Componente <code>Ejecutar Proceso: 06.Egresados_graduados_Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_32","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_32","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>06.Egresados_graduados_Cedesarrollo.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_06_cede_egresados_graduados","title":"Componente <code>Ejecutar Proceso: cede_06_cede_Egresados_Graduados</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_33","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_33","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_06_cede_Egresados_Graduados.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-07desertorespy","title":"Componente <code>Ejecutar Proceso: 07.Desertores.py</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_34","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_34","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>07.Desertores.py --semestre True</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_07_cancelados_desertores","title":"Componente <code>Ejecutar Proceso: cede_07_Cancelados_Desertores</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_35","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_35","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_07_Cancelados_Desertores.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#c4c","title":"C4C","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01c4c_webscraping_v4_actualizablepy","title":"Componente <code>Ejecutar Proceso: 01.C4C_webscraping_v4_Actualizable.py</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_36","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_36","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.C4C_webscraping_v4_Actualizable.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#archivos-manuales","title":"Archivos Manuales","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01sharepoint_connection_am-tra-08","title":"Componente <code>Ejecutar Proceso: 01.SharePoint_Connection_AM-TRA-08</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_37","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_37","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.SharePoint_Connection_AM-TRA-08.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-02sharepoint_connection_ep-tra-12","title":"Componente <code>Ejecutar Proceso: 02.SharePoint_Connection_EP-TRA-12</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_38","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_38","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>02.SharePoint_Connection_EP-TRA-12.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04sharepoint_connection_ep-tra-05","title":"Componente <code>Ejecutar Proceso: 04.SharePoint_Connection_EP-TRA-05</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_39","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_39","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.SharePoint_Connection_EP-TRA-05.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-sharepoint_connection_transversal","title":"Componente <code>Ejecutar Proceso: SharePoint_Connection_Transversal</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_40","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_40","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>SharePoint_Connection_Transversal.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-sharepoint_connection_proteccion","title":"Componente <code>Ejecutar Proceso: SharePoint_Connection_Proteccion</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_41","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_41","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>SharePoint_Connection_Proteccion.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01sharepoint_connection_am-edf-153","title":"Componente <code>Ejecutar Proceso: 01.SharePoint_Connection_AM-EDF-153</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_42","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_42","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.SharePoint_Connection_AM-EDF-153.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/","title":"Introduccion","text":"<p>La presente soluci\u00f3n SSIS constituye un conjunto integral de paquetes ETL cuidadosamente dise\u00f1ados para consolidar, transformar y cargar datos provenientes de fuentes heterog\u00e9neas hacia el Data Warehouse <code>DWH_COMFENALCO</code>. Cada paquete aborda dominios espec\u00edficos, como educaci\u00f3n, protecci\u00f3n social, finanzas y operaciones transversales, maximizando la calidad, consistencia y accesibilidad de los datos con el prop\u00f3sito de sustentar decisiones estrat\u00e9gicas.</p>"},{"location":"02.Paquetes_SSIS/00.params/#resumen-general","title":"Resumen General","text":"<p>Prop\u00f3sitos Estrat\u00e9gicos:</p> <ol> <li>Centralizar y estandarizar datos multisectoriales.</li> <li>Proveer informaci\u00f3n verificada y estructurada para an\u00e1lisis operativos y de inteligencia empresarial.</li> <li>Implementar transformaciones avanzadas que optimicen la confiabilidad y el valor de los datos.</li> </ol> <p>Componentes Fundamentales:</p> <ul> <li>Dimensiones:<ul> <li>Educativas: <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_LIBROS</code>, <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Administrativas: <code>DIM_CUENTA_CONTABLE</code>, <code>DIM_PERSONAL</code>, <code>DIM_INFRAESTRUCTURA_CCF</code>.</li> <li>Temporales: <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Hechos:<ul> <li>Operativos: <code>FACT_TRANSPORTE</code>, <code>FACT_PERMISO_ESTUDIANTE</code>, <code>FACT_DIAGNOSTICOS_EE_JEC</code>.</li> <li>Financieros: <code>FACT_DETALLE_CONTABLE</code>, <code>FACT_CONVENIOS</code>, <code>FACT_PRESUPUESTO</code>.</li> </ul> </li> <li>Automatizaci\u00f3n:<ul> <li>Scripts Python para descargas y validaciones din\u00e1micas.</li> </ul> </li> </ul> <p>Paquetes Principales y Tablas Asociadas:</p> <ol> <li> <p>01-TRANSVERSAL_DIMENSIONES:</p> <ul> <li>Tablas clave: <code>DIM_CUENTA_CONTABLE</code>, <code>DIM_PERSONAL</code>, <code>DIM_INFRAESTRUCTURA_CCF</code>.</li> <li>Fuentes: Archivos Excel y bases de datos SQL Server.</li> </ul> </li> <li> <p>02-TRANSVERSAL_FACT:</p> <ul> <li>Tablas clave: <code>FACT_DETALLE_CONTABLE</code>, <code>FACT_ENCUESTAS_PSR</code>, <code>FACT_INICIATIVAS</code>.</li> <li>Fuentes: Archivos CSV, bases de datos SAP.</li> </ul> </li> <li> <p>03-COLEGIO_DIMENSIONES y 03-COLEGIO_DIMENSIONES_AUXILIAR:</p> <ul> <li>Tablas clave: <code>DIM_CURSO</code>, <code>DIM_GRADO</code>, <code>DIM_PLAN_CURRICULAR</code>.</li> <li>Fuentes: Bases remotas y archivos Excel.</li> </ul> </li> <li> <p>04-COLEGIO_FACT:</p> <ul> <li>Tablas clave: <code>FACT_TRANSPORTE</code>, <code>FACT_CUPOS_NEGADOS</code>, <code>FACT_BIBLIOTECA</code>.</li> <li>Fuentes: Bases SAP y datos operativos.</li> </ul> </li> <li> <p>05-CEDESARROLLO_DIMENSIONES:</p> <ul> <li>Tablas clave: <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_JORNADA</code>.</li> <li>Fuentes: Archivos Excel y bases SQL Server.</li> </ul> </li> <li> <p>06-CEDESARROLLO_FACT:</p> <ul> <li>Tablas clave: <code>FACT_NOTAS</code>, <code>FACT_TRANSPORTE</code>, <code>FACT_PERMISO_ESTUDIANTE</code>.</li> <li>Fuentes: Bases de datos acad\u00e9micas.</li> </ul> </li> <li> <p>07-PROTECCION_DIMENSIONES y 08-PROTECCION_FACT:</p> <ul> <li>Tablas clave: <code>DIM_PREGUNTAS_EE_JEC</code>, <code>FACT_ENTREGA_MATERIAL</code>, <code>FACT_DESERCION</code>.</li> <li>Fuentes: Archivos planos y bases SQL Server.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#detalles-tecnicos-generales","title":"Detalles T\u00e9cnicos Generales","text":""},{"location":"02.Paquetes_SSIS/00.params/#extraccion-de-datos","title":"Extracci\u00f3n de Datos","text":"<ul> <li>Fuentes Primarias:<ul> <li>Bases SAP y SQL Server.</li> <li>Archivos CSV y Excel.</li> <li>Conexiones SharePoint para datos remotos.</li> </ul> </li> <li>Instrumentos:<ul> <li>ADO.NET para bases estructuradas.</li> <li>Scripts Python para descargas program\u00e1ticas.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#transformaciones","title":"Transformaciones","text":"<ul> <li>Validaciones:<ul> <li>Uso extensivo de <code>Lookup</code> para garantizar integridad referencial.</li> </ul> </li> <li>Transformaciones Especializadas:<ul> <li>Columnas derivadas para claves auxiliares y valores predeterminados.</li> <li>Clasificaci\u00f3n con <code>Conditional Split</code>.</li> <li>Conversi\u00f3n de tipos para alineaci\u00f3n de esquemas.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#carga-de-datos","title":"Carga de Datos","text":"<ul> <li>Tablas de Dimensiones:<ul> <li><code>DIM_CUENTA_CONTABLE</code>, <code>DIM_PROGRAMA</code>, <code>DIM_ESTUDIANTES</code>.</li> </ul> </li> <li>Tablas de Hechos:<ul> <li><code>FACT_TRANSPORTE</code>, <code>FACT_CONVENIOS</code>, <code>FACT_DIAGNOSTICOS_EE_JEC</code>.</li> </ul> </li> <li>Optimizaci\u00f3n:<ul> <li>Inserciones masivas (<code>Bulk Insert</code>) configuradas para alto rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#automatizacion","title":"Automatizaci\u00f3n","text":"<ul> <li>Scripts Python:<ul> <li>Validaciones din\u00e1micas en tiempo de ejecuci\u00f3n.</li> <li>Descarga de archivos con integraci\u00f3n SharePoint.</li> </ul> </li> <li>Procedimientos Almacenados:<ul> <li>Restauraci\u00f3n automatizada de reglas de integridad referencial.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#herramientas-y-tecnologias-utilizadas","title":"Herramientas y Tecnolog\u00edas Utilizadas","text":"<ul> <li>SSIS (SQL Server Integration Services):<ul> <li>Para dise\u00f1ar y ejecutar flujos de datos y procesos de control.</li> </ul> </li> <li>Python:<ul> <li>Automatizaci\u00f3n y validaci\u00f3n de datos mediante scripts personalizados.</li> </ul> </li> <li>ADO.NET:<ul> <li>Conexiones robustas a bases de datos relacionales.</li> </ul> </li> <li>OLE DB:<ul> <li>Lectura y transformaci\u00f3n de datos desde archivos Excel y CSV.</li> </ul> </li> <li>SQL Server:<ul> <li>Plataforma de destino para almacenar datos procesados.</li> </ul> </li> <li>Visual Studio:<ul> <li>Desarrollo y configuraci\u00f3n de paquetes SSIS.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#buenas-practicas","title":"Buenas Pr\u00e1cticas","text":"<ol> <li> <p>Estandarizaci\u00f3n:</p> <ul> <li>Nombrado uniforme para conexiones y componentes.</li> <li>Plantillas comunes en transformaciones y cargas.</li> </ul> </li> <li> <p>Optimizaci\u00f3n:</p> <ul> <li>Configuraci\u00f3n de cach\u00e9 para <code>Lookup</code>.</li> <li>Paralelizaci\u00f3n en flujos intensivos de datos.</li> </ul> </li> <li> <p>Automatizaci\u00f3n:</p> <ul> <li>Scripts Python para minimizar intervenciones manuales.</li> <li>Uso de variables din\u00e1micas para parametrizaci\u00f3n.</li> </ul> </li> <li> <p>Mantenimiento:</p> <ul> <li>Validaciones exhaustivas previas a la carga.</li> <li>Auditor\u00edas peri\u00f3dicas de consistencia.</li> </ul> </li> <li> <p>Seguridad:</p> <ul> <li>Eliminaci\u00f3n temporal de restricciones durante cargas masivas.</li> <li>Restauraci\u00f3n autom\u00e1tica tras completarse las operaciones.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#conclusion","title":"Conclusi\u00f3n","text":"<p>La soluci\u00f3n SSIS documentada constituye un pilar estrat\u00e9gico para la gesti\u00f3n y explotaci\u00f3n de datos organizacionales. Su dise\u00f1o modular y altamente automatizado no solo garantiza eficiencia operativa, sino que tambi\u00e9n habilita a la organizaci\u00f3n para responder \u00e1gilmente a desaf\u00edos futuros. La implementaci\u00f3n de buenas pr\u00e1cticas y recomendaciones adicionales potenciar\u00e1 su valor y sostenibilidad en el tiempo.</p> <p>A continuaci\u00f3n, se presentan diagramas en formato Mermaid que representan flujos de datos y relaciones entre tablas de la soluci\u00f3n SSIS:</p>"},{"location":"02.Paquetes_SSIS/00.params/#diagramas-ssis","title":"Diagramas SSIS","text":""},{"location":"02.Paquetes_SSIS/00.params/#diagrama-de-flujo-de-datos-general","title":"Diagrama de Flujo de Datos (General)","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel/CSV\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extrae datos desde fuentes remotas y locales\n    SSIS -&gt;&gt; Excel: Procesa datos adicionales desde archivos planos\n    SSIS -&gt;&gt; Python: Automatiza tareas de validaci\u00f3n y descarga\n    SSIS -&gt;&gt; DWH: Carga datos procesados en tablas destino</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#diagrama-de-transformaciones-ejemplo-para-dimensiones","title":"Diagrama de Transformaciones (Ejemplo para Dimensiones)","text":"<pre><code>graph TD\n    A1[Datos Crudos de Dimensiones] --&gt; T1[Validaci\u00f3n con Lookup]\n    T1 --&gt; T2[Conversi\u00f3n de Tipos]\n    T2 --&gt; T3[Columnas Derivadas]\n    T3 --&gt; T4[Filtrado con Conditional Split]\n    T4 --&gt; C1[Carga en Tablas de Dimensiones]</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#diagrama-er-para-tablas-de-dimensiones","title":"Diagrama ER para Tablas de Dimensiones","text":"<pre><code>erDiagram\n    DIM_CUENTA_CONTABLE {\n        int ID_CUENTA\n        string CUENTA_NUMERO\n        string DESCRIPCION\n    }\n    DIM_PERSONAL {\n        int ID_PERSONAL\n        string NOMBRE\n        string DIRECCION\n    }\n    DIM_INFRAESTRUCTURA_CCF {\n        int ID_INFRAESTRUCTURA\n        string DESCRIPCION\n    }\n    DIM_SEDES {\n        int ID_SEDE\n        string NOMBRE_SEDE\n    }\n    DIM_TIEMPO {\n        int ID_FECHA\n        date FECHA\n        string DESC_FECHA\n    }\n    DIM_CUENTA_CONTABLE ||--|| DIM_PERSONAL : \"Asociaci\u00f3n por Clave For\u00e1nea\"\n    DIM_INFRAESTRUCTURA_CCF ||--|| DIM_SEDES : \"Relaci\u00f3n Infraestructura-Sede\"\n    DIM_SEDES ||--|| DIM_TIEMPO : \"Relaci\u00f3n Temporal\"</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#diagrama-er-para-tablas-de-hechos-y-dimensiones","title":"Diagrama ER para Tablas de Hechos y Dimensiones","text":"<pre><code>erDiagram\n    FACT_TRANSPORTE {\n        string PARTNER_ESTUDIANTE\n        date FECHA_SERVICIO\n        int ANIO_ACADEMICO\n        string CATEGORIA_SERVICIO\n    }\n    FACT_CUPOS_NEGADOS {\n        string PARTNER_ESTUDIANTE\n        int ANIO_ACADEMICO\n        date FECHA_ESTADO\n    }\n    FACT_BIBLIOTECA {\n        string ITEM_LIBRO\n        date FECHA_PRESTAMO\n        string BP_ESTUDIANTE\n    }\n    FACT_PERMISO_ESTUDIANTE {\n        string BP_ESTUDIANTE\n        date FECHA_PERMISO\n        string MOTIVO\n    }\n    FACT_TRANSPORTE ||--|| FACT_CUPOS_NEGADOS : \"Relaci\u00f3n de estudiantes\"\n    FACT_BIBLIOTECA ||--|| FACT_PERMISO_ESTUDIANTE : \"Conexi\u00f3n por estudiantes\"\n    DIM_ESTUDIANTES ||--|| FACT_TRANSPORTE : \"Detalles de Estudiantes\"\n    DIM_LIBROS ||--|| FACT_BIBLIOTECA : \"Informaci\u00f3n de Libros\"</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#parametros-clave-en-la-solucion-ssis","title":"Par\u00e1metros Clave en la Soluci\u00f3n SSIS","text":""},{"location":"02.Paquetes_SSIS/00.params/#documentacion-del-archivo-projectparams","title":"Documentaci\u00f3n del Archivo <code>project.params</code>","text":"<p>El archivo <code>project.params</code> es un componente esencial en las soluciones de SQL Server Integration Services (SSIS), dise\u00f1ado para centralizar y administrar los par\u00e1metros utilizados globalmente en los paquetes de la soluci\u00f3n. Su prop\u00f3sito principal es facilitar la configuraci\u00f3n y gesti\u00f3n de variables cr\u00edticas, proporcionando un punto \u00fanico de control para ajustar valores clave sin necesidad de modificar cada paquete individualmente.</p> <p>Los par\u00e1metros definidos en este archivo son utilizados para:</p> <ol> <li> <p>Cadenas de conexi\u00f3n:</p> <ul> <li>Administrar el acceso a bases de datos y servicios externos.</li> <li>Establecer conexiones consistentes y seguras mediante cadenas configuradas que pueden ser reutilizadas en m\u00faltiples paquetes.</li> </ul> </li> <li> <p>Rutas de trabajo:</p> <ul> <li>Definir directorios y ubicaciones clave para archivos de entrada, salida o temporales.</li> <li>Estandarizar las rutas utilizadas en scripts y procesos, reduciendo la posibilidad de errores debido a inconsistencias.</li> </ul> </li> <li> <p>Configuraciones de tiempo de espera:</p> <ul> <li>Establecer valores predeterminados para manejar operaciones que requieren l\u00edmites temporales, como conexiones a bases de datos o transferencias de datos.</li> </ul> </li> <li> <p>Par\u00e1metros sensibles:</p> <ul> <li>Incluir contrase\u00f1as, claves de acceso y otras credenciales protegidas mediante la propiedad <code>Sensitive</code> que oculta estos valores en registros y exportaciones.</li> </ul> </li> <li> <p>Compatibilidad multi-entorno:</p> <ul> <li>Facilitar la portabilidad y configuraci\u00f3n de los paquetes SSIS en diferentes entornos (desarrollo, prueba, producci\u00f3n) mediante valores f\u00e1cilmente ajustables en un \u00fanico archivo.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#ventajas-del-uso-de-projectparams","title":"Ventajas del Uso de <code>project.params</code>","text":"<ol> <li>Centralizaci\u00f3n: Permite un punto \u00fanico de configuraci\u00f3n para par\u00e1metros globales, simplificando la administraci\u00f3n.</li> <li>Flexibilidad: Cambiar valores en el archivo afecta autom\u00e1ticamente todos los paquetes que dependen de estos par\u00e1metros, eliminando la necesidad de ediciones manuales en m\u00faltiples archivos.</li> <li>Estandarizaci\u00f3n: Garantiza consistencia en la configuraci\u00f3n entre paquetes, reduciendo errores y aumentando la mantenibilidad.</li> <li>Seguridad: Los par\u00e1metros sensibles pueden ser protegidos para evitar la exposici\u00f3n de informaci\u00f3n confidencial.</li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#estructura-del-archivo","title":"Estructura del Archivo","text":"<p>Cada par\u00e1metro en el archivo incluye: - Nombre: Identificador \u00fanico del par\u00e1metro. - Descripci\u00f3n: Informaci\u00f3n opcional que detalla el prop\u00f3sito del par\u00e1metro. - Propiedades clave:   - Sensitive: Indica si el par\u00e1metro contiene informaci\u00f3n sensible que debe ser protegida.   - DataType: Especifica el tipo de dato (e.g., cadena, n\u00famero).   - Valor: El valor asignado al par\u00e1metro, que puede ser una cadena de conexi\u00f3n, ruta, n\u00famero, entre otros.</p> <p>El dise\u00f1o del archivo <code>project.params</code> permite a los equipos de desarrollo y operaciones trabajar de manera eficiente y segura, garantizando que los procesos de integraci\u00f3n de datos sean robustos y escalables.</p>"},{"location":"02.Paquetes_SSIS/00.params/#1-dwh_comfenalco_connectionstring","title":"1. DWH_COMFENALCO_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para la base de datos principal <code>DWH_COMFENALCO</code>, utilizada para operaciones de carga y extracci\u00f3n de datos.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Initial Catalog=DWH_COMFENALCO;Persist Security Info=True;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code> (No contiene informaci\u00f3n sensible).</li> <li>DataType: <code>18</code> (Texto).</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#2-dwh_comfenalco_destino_connectionstring","title":"2. DWH_COMFENALCO_Destino_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para la base de datos de destino <code>DWH_COMFENALCO</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=QCSCONS19;Initial Catalog=DWH_COMFENALCO;Integrated Security=True;Encrypt=False;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#3-dwh_comfenalco_destino_oledb_connectionstring","title":"3. DWH_COMFENALCO_Destino_OLEDB_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n OLEDB para operaciones espec\u00edficas en la base de datos <code>DWH_COMFENALCO</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=QCSCONS19;Initial Catalog=DWH_COMFENALCO;Provider=MSOLEDBSQL.1;Integrated Security=SSPI;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#4-dwh_comfenalco_oledb_connectionstring","title":"4. DWH_COMFENALCO_OLEDB_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n OLEDB para la base de datos principal <code>DWH_COMFENALCO</code>, dise\u00f1ada para compatibilidad con aplicaciones que utilizan este proveedor.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Provider=MSOLEDBSQL.1;Persist Security Info=True;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#5-dwh_comfenalco_oledb_username","title":"5. DWH_COMFENALCO_OLEDB_UserName","text":"<ul> <li>Prop\u00f3sito: Nombre de usuario utilizado para la autenticaci\u00f3n en la conexi\u00f3n OLEDB de <code>DWH_COMFENALCO</code>.</li> <li>Ejemplo de Valor: <code>prov_quality1</code>.</li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#6-python_executable","title":"6. Python_Executable","text":"<ul> <li>Prop\u00f3sito: Ruta al ejecutable de Python que se utiliza en los scripts del proyecto.</li> <li>Ejemplo de Valor:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#7-sap_erp_connectionstring","title":"7. SAP_ERP_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para acceder al sistema SAP ERP.</li> <li>Ejemplo de Valor:   <pre><code>Server=10.5.4.51:30013;User ID=CONSULTAHANA;Database=HEQ;\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#8-stage_area_connectionstring","title":"8. STAGE_AREA_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para la base de datos <code>STAGE_AREA</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Initial Catalog=STAGE_AREA;Persist Security Info=True;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#9-stage_area_oledb_connectionstring","title":"9. STAGE_AREA_OLEDB_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n OLEDB para operaciones en <code>STAGE_AREA</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Initial Catalog=STAGE_AREA;Provider=SQLNCLI11.1;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#10-stage_area_oledb_username","title":"10. STAGE_AREA_OLEDB_UserName","text":"<ul> <li>Prop\u00f3sito: Nombre de usuario utilizado en la autenticaci\u00f3n para la conexi\u00f3n OLEDB de <code>STAGE_AREA</code>.</li> <li>Ejemplo de Valor: <code>prov_quality1</code>.</li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#11-tiempo_espera_segundos","title":"11. Tiempo_Espera_Segundos","text":"<ul> <li>Prop\u00f3sito: Configuraci\u00f3n del tiempo de espera (en segundos) para operaciones de conexi\u00f3n.</li> <li>Ejemplo de Valor: <code>600</code>.</li> <li>Propiedades Clave:</li> <li>DataType: <code>9</code> (Entero).</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#12-working_directory","title":"12. Working_Directory","text":"<ul> <li>Prop\u00f3sito: Directorio de trabajo utilizado para guardar archivos temporales y otros datos procesados por los paquetes de SSIS.</li> <li>Ejemplo de Valor:   <pre><code>\\\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/","title":"01. TRANSVERSAL_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#transversal_dimensiones","title":"TRANSVERSAL_DIMENSIONES","text":"<p>El paquete SSIS \"01-TRANSVERSAL_DIMENSIONES\" est\u00e1 dise\u00f1ado para gestionar flujos ETL enfocados en la consolidaci\u00f3n y estructuraci\u00f3n de datos de dimensiones transversales, como cuentas contables, infraestructura, sedes, poblaci\u00f3n educativa, y personal. Este paquete asegura la integraci\u00f3n eficiente de informaci\u00f3n desde m\u00faltiples fuentes en el Data Warehouse <code>DWH_COMFENALCO</code>, permitiendo an\u00e1lisis detallados y toma de decisiones estrat\u00e9gicas.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es centralizar, transformar y cargar datos relacionados con dimensiones transversales que impactan diferentes \u00e1reas operativas, asegurando su consistencia y calidad para an\u00e1lisis en plataformas de inteligencia de negocios.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes utilizadas:<ul> <li>Bases de Datos:<ul> <li><code>DIM_CUENTA_CONTABLE</code></li> <li><code>DIM_UNIDADES_ORGANIZATIVAS</code></li> <li><code>DIM_SEDES</code></li> </ul> </li> <li>Archivos Excel:<ul> <li>Informaci\u00f3n sobre poblaci\u00f3n educativa, infraestructura, y personal.</li> </ul> </li> </ul> </li> <li>Herramientas:<ul> <li>ADO.NET y OLE DB para conexiones eficientes.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Crea claves auxiliares y campos calculados.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Garantiza consistencia mediante b\u00fasquedas en tablas maestras.</li> </ul> </li> <li>Clasificaci\u00f3n (<code>Conditional Split</code>):<ul> <li>Segmentaci\u00f3n de datos seg\u00fan condiciones espec\u00edficas.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad entre columnas de entrada y destino.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_CUENTA_CONTABLE</code></li> <li><code>DIM_PERSONAL</code></li> <li><code>DIM_INFRAESTRUCTURA_CCF</code></li> <li><code>DIM_SEDES</code></li> </ul> </li> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python para integrar flujos de trabajo automatizados y procesar datos de SharePoint.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_CUENTA_CONTABLE:</p> <ul> <li><code>ID_CUENTA</code>: Identificador \u00fanico.</li> <li><code>CUENTA_NUMERO</code>: N\u00famero de cuenta.</li> <li><code>DESCRIPCION</code>: Descripci\u00f3n de la cuenta.</li> </ul> </li> <li> <p>DIM_PERSONAL:</p> <ul> <li><code>ID_PERSONAL</code>: Identificador \u00fanico.</li> <li><code>NOMBRE</code>: Nombre del personal.</li> <li><code>DIRECCION</code>: Direcci\u00f3n.</li> </ul> </li> <li> <p>DIM_INFRAESTRUCTURA_CCF:</p> <ul> <li><code>ID_INFRAESTRUCTURA</code>: Identificador \u00fanico.</li> <li><code>DESCRIPCION</code>: Descripci\u00f3n de la infraestructura.</li> </ul> </li> <li> <p>DIM_SEDES:</p> <ul> <li><code>ID_SEDE</code>: Identificador \u00fanico.</li> <li><code>NOMBRE_SEDE</code>: Nombre de la sede.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extrae datos de cuentas, personal, y sedes\n    SSIS -&gt;&gt; Excel: Procesa datos de infraestructura y poblaci\u00f3n\n    SSIS -&gt;&gt; Python: Ejecuta scripts para descargas\n    SSIS -&gt;&gt; DWH: Carga datos en tablas destino</code></pre> <ol> <li>Diagrama de Transformaciones y Validaciones</li> </ol> <pre><code>graph TD\n    A1[Datos de cuentas y sedes] --&gt; T1[Conversi\u00f3n de Datos]\n    A2[Datos de infraestructura y poblaci\u00f3n] --&gt; T2[Derived Column: Claves Auxiliares]\n    T1 --&gt; L1[Lookup en Tablas Maestras]\n    T2 --&gt; C1[Clasificaci\u00f3n por Condicional Split]\n    L1 --&gt; C2[Cargar datos transformados]</code></pre> <ol> <li>Diagrama ER para Tablas de Dimensiones</li> </ol> <pre><code>erDiagram\n    DIM_CUENTA_CONTABLE {\n        int ID_CUENTA\n        string CUENTA_NUMERO\n        string DESCRIPCION\n    }\n    DIM_PERSONAL {\n        int ID_PERSONAL\n        string NOMBRE\n        string DIRECCION\n    }\n    DIM_INFRAESTRUCTURA_CCF {\n        int ID_INFRAESTRUCTURA\n        string DESCRIPCION\n    }\n    DIM_SEDES {\n        int ID_SEDE\n        string NOMBRE_SEDE\n    }\n    DIM_CUENTA_CONTABLE ||--|| DIM_PERSONAL : \"Asociaci\u00f3n por Clave For\u00e1nea\"\n    DIM_INFRAESTRUCTURA_CCF ||--|| DIM_SEDES : \"Relaci\u00f3n Infraestructura-Sede\"</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-guardar-las-llaves-foraneas","title":"Componente: <code>Guardar las Llaves For\u00e1neas</code>","text":"<p>Prop\u00f3sito Esta tarea dentro de la soluci\u00f3n SSIS tiene como objetivo:</p> <ol> <li> <p>Crear tablas persistentes para almacenar definiciones de llaves for\u00e1neas en varios esquemas: <code>Transversal</code>, <code>Cedesarrollo</code>, <code>Proteccion</code> y <code>Colegio</code>.</p> </li> <li> <p>Insertar las definiciones de llaves for\u00e1neas en las tablas persistentes a partir de la metadata del sistema (<code>sys.foreign_keys</code> y tablas relacionadas).</p> </li> <li> <p>Eliminar restricciones de llaves for\u00e1neas existentes en los esquemas mencionados, prepar\u00e1ndose para un entorno donde no se necesiten dichas restricciones durante procesos espec\u00edficos (e.g., migraci\u00f3n o transformaci\u00f3n de datos).</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-tecnicos","title":"Detalles T\u00e9cnicos","text":"<ol> <li> <p>Tipo de Tarea: </p> <ul> <li><code>Microsoft.ExecuteSQLTask</code> (Tarea Ejecutar SQL).</li> </ul> </li> <li> <p>Descripci\u00f3n:</p> <ul> <li>La tarea ejecuta comandos SQL que realizan varias operaciones en los esquemas <code>Transversal</code>, <code>Cedesarrollo</code>, <code>Proteccion</code> y <code>Colegio</code>.</li> </ul> </li> <li> <p>Identificador de la Tarea:</p> <ul> <li>DTSID: <code>{86fe2b15-f28c-4064-b542-2d2ad2594a04}</code>.</li> </ul> </li> <li> <p>Nombre de la Tarea:</p> <ul> <li><code>Guardar las llaves foraneas</code>.</li> </ul> </li> <li> <p>Conexi\u00f3n Utilizada:</p> <ul> <li>Referenciada por el ID: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-codigo-sql","title":"Descripci\u00f3n del C\u00f3digo SQL","text":"<ol> <li> <p>Creaci\u00f3n de Tablas Persistentes:</p> <ul> <li>Para cada esquema (<code>Transversal</code>, <code>Cedesarrollo</code>, <code>Proteccion</code>, <code>Colegio</code>), se verifica la existencia previa de la tabla y se elimina si ya existe:  <pre><code>IF OBJECT_ID('dbo.ForeignKeys_&lt;Esquema&gt;', 'U') IS NOT NULL\n    DROP TABLE dbo.ForeignKeys_&lt;Esquema&gt;;\n</code></pre></li> <li>Posteriormente, se crea una nueva tabla con la estructura necesaria para almacenar las definiciones de las llaves for\u00e1neas:  <pre><code>CREATE TABLE dbo.ForeignKeys_&lt;Esquema&gt; (\n    TableName NVARCHAR(256),\n    ConstraintName NVARCHAR(256),\n    ColumnName NVARCHAR(256),\n    ReferencedTableName NVARCHAR(256),\n    ReferencedColumnName NVARCHAR(256)\n);\n</code></pre></li> </ul> </li> <li> <p>Inserci\u00f3n de Definiciones de Llaves For\u00e1neas:     .foreign_key_columns<code>,</code>sys.tables<code>,</code>sys.columns<code>,</code>sys.schemas`) y se insertan en las tablas persistentes:     <pre><code>INSERT INTO dbo.ForeignKeys_&lt;Esquema&gt; (TableName, ConstraintName, ColumnName, ReferencedTableName, ReferencedColumnName)\nSELECT \n    t.name AS TableName,\n    f.name AS ConstraintName,\n    c.name AS ColumnName,\n    rt.name AS ReferencedTableName,\n    rc.name AS ReferencedColumnName\nFROM sys.foreign_keys f\nINNER JOIN sys.foreign_key_columns fc ON f.object_id = fc.constraint_object_id\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\n...\nWHERE s.name = '&lt;Esquema&gt;';\n</code></pre></p> </li> <li> <p>Eliminaci\u00f3n de Restricciones de Llaves For\u00e1neas:     Se generan din\u00e1micamente comandos SQL para eliminar todas las restricciones de llaves for\u00e1neas en las tablas de cada esquema:         <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; '\nFROM sys.foreign_keys f\n...\nWHERE s.name = '&lt;Esquema&gt;';\nEXEC sp_executesql @sql;\n</code></pre></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#esquemas-procesados","title":"Esquemas Procesados","text":"<ol> <li>Transversal.</li> <li>Cedesarrollo.</li> <li>Proteccion.</li> <li>Colegio.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#ventajas-de-la-implementacion","title":"Ventajas de la Implementaci\u00f3n","text":"<ol> <li>Centralizaci\u00f3n de definiciones: Las tablas persistentes almacenan todas las llaves for\u00e1neas en un lugar accesible para auditor\u00edas o referencias futuras.</li> <li>Flexibilidad: Elimina restricciones en los esquemas, permitiendo procesos m\u00e1s \u00e1giles como migraciones de datos.</li> <li>Reutilizaci\u00f3n: La l\u00f3gica puede ser ajustada para nuevos esquemas simplemente actualizando el c\u00f3digo SQL y par\u00e1metros en el SSIS.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-de-datos","title":"Diagrama de flujo de proceso de datos","text":"<pre><code>sequenceDiagram\n    participant SQL_TASK\n    participant TRANSVERSAL_SCHEMA\n    participant CEDESARROLLO_SCHEMA\n    participant PROTECCION_SCHEMA\n    participant COLEGIO_SCHEMA\n\n    SQL_TASK-&gt;&gt;TRANSVERSAL_SCHEMA: Crear tablas y definir llaves for\u00e1neas\n    SQL_TASK-&gt;&gt;CEDESARROLLO_SCHEMA: Crear tablas y definir llaves for\u00e1neas\n    SQL_TASK-&gt;&gt;PROTECCION_SCHEMA: Crear tablas y definir llaves for\u00e1neas\n    SQL_TASK-&gt;&gt;COLEGIO_SCHEMA: Crear tablas y definir llaves for\u00e1neas</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_cuenta_contable","title":"Componente <code>Cargar_DIM_CUENTA_CONTABLE</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Cargar_DIM_CUENTA_CONTABLE</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de cargar datos en la dimensi\u00f3n <code>DIM_CUENTA_CONTABLE</code>. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-y-funcionalidades","title":"Componentes y Funcionalidades","text":"<ol> <li> <p>Variables y Opciones de Registro</p> <ul> <li>No se definen variables espec\u00edficas.</li> <li>Opciones de registro configuradas con <code>DTS:FilterKind=\"0\"</code>.</li> </ul> </li> <li> <p>Pipeline</p> <ul> <li>Versi\u00f3n: 1</li> </ul> </li> <li> <p>Componentes del Pipeline</p> <ul> <li> <p>Conditional Split</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos utilizando expresiones SSIS.</li> <li>Entradas: <ul> <li>Columnas de entrada incluyen <code>CUENTA_NUMERO</code>, <code>CUENTA</code>, <code>CUENTA_HOMOLOGA</code>, <code>DESCRIPCION</code>, <code>TIPO_CUENTA</code>, <code>TIPO_OPERACION</code>, <code>GRUPO_CUENTA</code>, <code>SUBGRUPO_CUENTA</code>, <code>GRUPO_OPERACION</code>, <code>FEC_PROCESO</code>, <code>UDATE</code>, <code>CUENTA_SSF</code>, <code>DESCRIPCION_SSF</code>, <code>NUMERO_PROCESO_SQL</code>, <code>CLASIFICACION</code>, <code>USUARIO_PROCESO</code>, <code>ESTADO_REGISTRO</code>, <code>ID_CUENTA</code>.</li> </ul> </li> <li>Salidas:<ul> <li><code>Agregar</code>: Filtra filas donde <code>ID_CUENTA</code> es nulo.</li> <li><code>Modificar</code>: Filtra filas donde hay diferencias entre las columnas de origen y las columnas de b\u00fasqueda.</li> <li><code>Sin Cambios</code>: Salida por defecto para filas sin cambios.</li> <li><code>Conditional Split Error Output</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Carga datos en una base de datos compatible con ADO.NET.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_CUENTA_CONTABLE\"</code></li> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> <li>Entradas: Columnas de entrada incluyen <code>ID_CUENTA</code>, <code>CUENTA_NUMERO</code>, <code>CUENTA</code>, <code>CUENTA_HOMOLOGA</code>, <code>DESCRIPCION</code>, <code>TIPO_CUENTA</code>, <code>TIPO_OPERACION</code>, <code>GRUPO_CUENTA</code>, <code>SUBGRUPO_CUENTA</code>, <code>GRUPO_OPERACION</code>, <code>FEC_PROCESO</code>, <code>UDATE</code>, <code>CUENTA_SSF</code>, <code>DESCRIPCION_SSF</code>, <code>NUMERO_PROCESO_SQL</code>, <code>CLASIFICACION</code>, <code>USUARIO_PROCESO</code>, <code>ESTADO_REGISTRO</code>.</li> <li>Salidas:<ul> <li><code>Salida de error de destino de ADO NET</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>DIM_CUENTA_CONTABLE_ORIG</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server utilizando una instrucci\u00f3n Transact-SQL.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>SELECT [ID_CUENTA], [CUENTA_NUMERO], [CUENTA], [CUENTA_HOMOLOGA], [DESCRIPCION], [TIPO_CUENTA], [TIPO_OPERACION], [GRUPO_CUENTA], [SUBGRUPO_CUENTA], [GRUPO_OPERACION], [FEC_PROCESO], [UDATE], [CUENTA_SSF], [DESCRIPCION_SSF], [NUMERO_PROCESO_SQL], [CLASIFICACION], [USUARIO_PROCESO], [ESTADO_REGISTRO] FROM [DWH_COMFENALCO].[Financiera].[DIM_CUENTA_CONTABLE]</code></li> <li><code>CommandTimeout</code>: 30</li> <li><code>AllowImplicitStringConversion</code>: true</li> <li><code>TableOrViewName</code>: <code>\"Financiera\".\"DIM_CUENTA_CONTABLE\"</code></li> <li><code>AccessMode</code>: 2</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code></li> <li>Salidas:<ul> <li><code>Salida de origen de ADO NET</code>: Salida principal.</li> <li><code>Salida de error de origen de ADO NET</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda de valores en una tabla para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>SELECT [ID_CUENTA], [CUENTA_NUMERO], [CUENTA], [CUENTA_HOMOLOGA], [DESCRIPCION], [TIPO_CUENTA], [TIPO_OPERACION], [GRUPO_CUENTA], [SUBGRUPO_CUENTA], [GRUPO_OPERACION], [FEC_PROCESO], [UDATE], [CUENTA_SSF], [DESCRIPCION_SSF], [NUMERO_PROCESO_SQL], [CLASIFICACION], [USUARIO_PROCESO], [ESTADO_REGISTRO] FROM [Transversal].[DIM_CUENTA_CONTABLE]</code></li> <li><code>SqlCommandParam</code>: <code>select * from (SELECT [ID_CUENTA], [CUENTA_NUMERO], [CUENTA], [CUENTA_HOMOLOGA], [DESCRIPCION], [TIPO_CUENTA], [TIPO_OPERACION], [GRUPO_CUENTA], [SUBGRUPO_CUENTA], [GRUPO_OPERACION], [FEC_PROCESO], [UDATE], [CUENTA_SSF], [DESCRIPCION_SSF], [NUMERO_PROCESO_SQL], [CLASIFICACION], [USUARIO_PROCESO], [ESTADO_REGISTRO] FROM [Transversal].[DIM_CUENTA_CONTABLE]) [refTable] where [refTable].[ID_CUENTA] = ?</code></li> <li><code>ConnectionType</code>: 0</li> <li><code>CacheType</code>: 0</li> <li><code>NoMatchBehavior</code>: 0</li> <li><code>NoMatchCachePercentage</code>: 0</li> <li><code>MaxMemoryUsage</code>: 25</li> <li><code>MaxMemoryUsage64</code>: 25</li> <li><code>ReferenceMetadataXml</code>: <code>&lt;referenceMetadata&gt;...&lt;/referenceMetadata&gt;</code></li> <li><code>ParameterMap</code>: <code>#{Package\\Cargar_DIM_CUENTA_CONTABLE\\DIM_CUENTA_CONTABLE_ORIG.Outputs[Salida de origen de ADO NET].Columns[ID_CUENTA]};</code></li> <li><code>DefaultCodePage</code>: 1252</li> <li><code>TreatDuplicateKeysAsError</code>: false</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code></li> <li>Entradas: <code>ID_CUENTA</code></li> <li>Salidas:<ul> <li><code>Lookup Match Output</code>: Salida para filas con coincidencias.</li> <li><code>Lookup No Match Output</code>: Salida para filas sin coincidencias.</li> <li><code>Lookup Error Output</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>OLE DB Command</p> <ul> <li>Descripci\u00f3n: Ejecuta una instrucci\u00f3n SQL para cada fila en un flujo de datos.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>SqlCommand</code>: <code>UPDATE [Transversal].[DIM_CUENTA_CONTABLE] SET [CUENTA_NUMERO] = ?, [CUENTA] = ?, [CUENTA_HOMOLOGA] = ?, [DESCRIPCION] = ?, [TIPO_CUENTA] = ?, [TIPO_OPERACION] = ?, [GRUPO_CUENTA] = ?, [SUBGRUPO_CUENTA] = ?, [GRUPO_OPERACION] = ?, [FEC_PROCESO] = ?, [UDATE] = ?, [CUENTA_SSF] = ?, [DESCRIPCION_SSF] = ?, [NUMERO_PROCESO_SQL] = ?, [CLASIFICACION] = ?, [USUARIO_PROCESO] = ?, [ESTADO_REGISTRO] = ? WHERE [ID_CUENTA] = ?</code></li> <li><code>DefaultCodePage</code>: 1252</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code></li> <li>Entradas: Columnas de entrada incluyen <code>CUENTA_NUMERO</code>, <code>CUENTA</code>, <code>CUENTA_HOMOLOGA</code>,      <code>DESCRIPCION</code>, <code>TIPO_CUENTA</code>, <code>TIPO_OPERACION</code>, <code>GRUPO_CUENTA</code>, <code>SUBGRUPO_CUENTA</code>, <code>GRUPO_OPERACION</code>, <code>FEC_PROCESO</code>, <code>UDATE</code>, <code>CUENTA_SSF</code>, <code>DESCRIPCION_SSF</code>, <code>NUMERO_PROCESO_SQL</code>, <code>CLASIFICACION</code>, <code>USUARIO_PROCESO</code>, <code>ESTADO_REGISTRO</code>, <code>ID_CUENTA</code>.</li> <li>Salidas:<ul> <li><code>OLE DB Command Output</code>: Salida principal.</li> <li><code>OLE DB Command Error Output</code>: Salida de error.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Rutas del Pipeline</p> <ul> <li><code>Agregar</code>: Desde <code>Conditional Split.Outputs[Agregar]</code> hasta <code>Destino de ADO NET.Inputs[Entrada de destino de ADO NET]</code>.</li> <li><code>Lookup Match Output</code>: Desde <code>Lookup.Outputs[Lookup Match Output]</code> hasta <code>Conditional Split.Inputs[Conditional Split Input]</code>.</li> <li><code>Modificar</code>: Desde <code>Conditional Split.Outputs[Modificar]</code> hasta <code>OLE DB Command.Inputs[OLE DB Command Input]</code>.</li> <li><code>Salida de origen de ADO NET</code>: Desde <code>DIM_CUENTA_CONTABLE_ORIG.Outputs[Salida de origen de ADO NET]</code> hasta <code>Lookup.Inputs[Lookup Input]</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-de-datos_1","title":"Diagrama de flujo de proceso de datos","text":"<pre><code>sequenceDiagram\n    participant DIM_CUENTA_CONTABLE_ORIG\n    participant Lookup\n    participant Conditional_Split\n    participant Destino_de_ADO_NET\n    participant OLE_DB_Command\n\n    DIM_CUENTA_CONTABLE_ORIG-&gt;&gt;Lookup: Salida de origen de ADO NET\n    Lookup-&gt;&gt;Conditional_Split: Lookup Match Output\n    Conditional_Split-&gt;&gt;Destino_de_ADO_NET: Agregar\n    Conditional_Split-&gt;&gt;OLE_DB_Command: Modificar</code></pre> <p>&lt;!-- ### Componente <code>Cargar_DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIAS</code></p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Cargar_DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIAS</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de cargar datos en las dimensiones <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code> y <code>DIM_CATEGORIAS</code>. Esta tarea realiza operaciones de eliminaci\u00f3n, truncado e inserci\u00f3n de datos en las tablas correspondientes del Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{117A40D1-E1F3-4DF6-9457-B49F2D971A3B}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Descripci\u00f3n: Tarea Ejecutar SQL</li> <li>Conexi\u00f3n: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code></li> <li>Declaraciones SQL:<ul> <li>Eliminar restricciones de clave for\u00e1nea en el esquema <code>Transversal</code>.</li> <li>Truncar las tablas <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code> y <code>DIM_CATEGORIAS</code>.</li> <li>Insertar registros en las tablas <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code> y <code>DIM_CATEGORIAS</code>.</li> <li>Insertar un registro para el personal sin datos en la tabla <code>DIM_PERSONAL</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Cargar_DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIAS\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant SQL as Script SQL\n  participant DWH as Data Warehouse\n\n  SSIS-&gt;&gt;SQL: Ejecutar eliminaci\u00f3n de restricciones de clave for\u00e1nea\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de eliminaci\u00f3n\n  SSIS-&gt;&gt;SQL: Ejecutar truncado de tablas\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registros en DIM_UNIDAD\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_UNIDAD\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registros en DIM_INFRAESTRUCTURA_CCF\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_INFRAESTRUCTURA_CCF\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registros en DIM_CATEGORIAS\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_CATEGORIAS\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registro en DIM_PERSONAL\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_PERSONAL</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo","title":"C\u00f3digo","text":"<pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON; -- Configura el manejo est\u00e1ndar de valores nulos.\nGO\nSET QUOTED_IDENTIFIER ON; -- Permite usar comillas dobles para nombres de objetos.\nGO\n\n-- Eliminar restricciones de clave for\u00e1nea del esquema 'Transversal'.\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n\n-- Limpiar las tablas mediante truncado para eliminar datos existentes.\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDAD]; -- Tabla de unidades.\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_INFRAESTRUCTURA_CCF]; -- Infraestructura CCF.\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CATEGORIA]; -- Categor\u00edas.\n\n-- Insertar registros iniciales en la tabla DIM_UNIDAD.\nINSERT INTO [Transversal].[DIM_UNIDAD] (UNIDAD)\nVALUES ('EDUCACI\u00d3N FORMAL'), -- Representa Educaci\u00f3n Formal.\n       ('EDUCACI\u00d3N T\u00c9CNICA'), -- Representa Educaci\u00f3n T\u00e9cnica.\n       ('EDUCACI\u00d3N CONTINUA'), -- Representa Educaci\u00f3n Continua.\n       ('PROTECCI\u00d3N SOCIAL'), -- Representa Protecci\u00f3n Social.\n       ('SIN UNIDAD'); -- Valor predeterminado para datos sin unidad.\n\n-- Insertar registros en DIM_INFRAESTRUCTURA_CCF con valores asociados a unidades espec\u00edficas.\nINSERT INTO [Transversal].[DIM_INFRAESTRUCTURA_CCF] ([COD_INFRAESTRUCTURA_CCF], [DESCRIPCION], [ID_UNIDAD]) VALUES\n('CCF008-12-00001', 'Educaci\u00f3n formal', 1), -- Educaci\u00f3n formal asociada a ID 1.\n('CCF008-13-00001', 'Educaci\u00f3n para el trabajo', 2), -- Educaci\u00f3n t\u00e9cnica asociada a ID 2.\n('CCF008-15-00001', 'Desarrollo empresarial', 3), -- Desarrollo empresarial asociado a ID 3.\n('CCF008-26-00001', 'Protecci\u00f3n social', 4); -- Protecci\u00f3n social asociada a ID 4.\n\n-- Insertar registros en DIM_CATEGORIA con las categor\u00edas disponibles.\nINSERT INTO [Transversal].[DIM_CATEGORIA] ([COD_CATEGORIA], [DESCRIPCION]) VALUES\n('1', 'Categor\u00eda A'), -- Categor\u00eda A.\n('2', 'Categor\u00eda B'), -- Categor\u00eda B.\n('3', 'Categor\u00eda C'), -- Categor\u00eda C.\n('4', 'Categor\u00eda D'), -- Categor\u00eda D.\n('5', 'Empresas'), -- Categor\u00eda para empresas.\n('6', 'Fondos de Ley'), -- Fondos de ley.\n('10', 'Convenios y Facultativos'), -- Convenios.\n('12', 'Empresa no afiliada'); -- Empresas no afiliadas.\n\n-- Insertar un registro en la tabla DIM_PERSONAL para representar datos gen\u00e9ricos o no disponibles.\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] ON; -- Permite insertar valores en la columna IDENTITY.\nINSERT INTO [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL], \n    [COD_PERSONA_UNIDAD], \n    [ID_UNIDAD], \n    [SERVICIO], \n    [NOMBRE], \n    [TELEFONO], \n    [CELULAR], \n    [CORREO], \n    [DIRECCION], \n    [CIUDAD], \n    [TIPO_DOCUMENTO], \n    [DOCUMENTO], \n    [FECHA_NACIMIENTO], \n    [GENERO], \n    [HORAS_CONTRATADAS_MENSUAL], \n    [HORAS_CONTRATADAS_TOTALES], \n    [VALOR_TOTAL], \n    [TIPO_CONTRATACION], \n    [FECHA_INICIO_CONTRATACION], \n    [FECHA_FIN_CONTRATACION], \n    [CAUSA_TERMINACION_CONTRATO], \n    [PREGRADO], \n    [POSGRADO_ESPECIALIDAD], \n    [POSGRADO_MAESTRIA], \n    [POSGRADO_DOCTORADO], \n    [NIVEL_INGLES], \n    [AREA]\n) \nVALUES (\n    -1, -- ID predeterminado para datos gen\u00e9ricos.\n    -1, -- C\u00f3digo gen\u00e9rico.\n    5, -- Unidad asociada a \"SIN UNIDAD\".\n    NULL, NULL, NULL, NULL, NULL, NULL, NULL, -- Datos personales no disponibles.\n    'CC', '-1', NULL, NULL, NULL, NULL, NULL, -- Documento y tipo predeterminado.\n    NULL, '1900-01-01', '1900-01-01', NULL, NULL, NULL, NULL, NULL, NULL, NULL\n);\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] OFF; -- Finaliza la inserci\u00f3n de IDENTITY.\nGO\n``` --&gt;\n\n### Componente **`Limpiar_DIM_UNIDADES_ORGANIZATIVAS`**\n\n#### Descripci\u00f3n General\n\nLa tarea `Limpiar_DIM_UNIDADES_ORGANIZATIVAS` es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de limpiar la tabla `DIM_UNIDADES_ORGANIZATIVAS` en el Data Warehouse. Esta tarea realiza operaciones de eliminaci\u00f3n de restricciones de clave for\u00e1nea y truncado de la tabla correspondiente.\n\n#### Detalles de la Tarea\n\n- **ID de la Tarea**: `{047c1578-c938-442e-8b96-1f6a3417d0a2}`\n- **Tipo de Tarea**: `Microsoft.ExecuteSQLTask`\n- **Descripci\u00f3n**: Tarea Ejecutar SQL\n- **Conexi\u00f3n**: `{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}`\n- **Declaraciones SQL**:\n    - Eliminar restricciones de clave for\u00e1nea en el esquema `Transversal`.\n    - Truncar la tabla `DIM_UNIDADES_ORGANIZATIVAS`.\n\n#### Diagrama de Secuencia del Proceso ETL\n\n```mermaid\nsequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Limpiar_DIM_UNIDADES_ORGANIZATIVAS\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant SQL as Script SQL\n  participant DWH as Data Warehouse\n\n  SSIS-&gt;&gt;SQL: Ejecutar eliminaci\u00f3n de restricciones de clave for\u00e1nea\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de eliminaci\u00f3n\n  SSIS-&gt;&gt;SQL: Ejecutar truncado de tabla DIM_UNIDADES_ORGANIZATIVAS\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql","title":"C\u00f3digo SQL","text":"<pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n\n-- Eliminar restricciones de clave for\u00e1nea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n\n-- Truncar tabla DIM_UNIDADES_ORGANIZATIVAS\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDADES_ORGANIZATIVAS];\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar-valores-nulos-por-defecto-para-todos-los-esquemas","title":"Componente <code>Cargar Valores nulos por defecto para todos los esquemas</code>","text":"<p>El paquete SSIS \"Cargar Valores nulos por defecto para todos los esquemas\" se encarga de inicializar y estandarizar los datos en m\u00faltiples esquemas del Data Warehouse <code>DWH_COMFENALCO</code> mediante la ejecuci\u00f3n de un proceso SQL. Este componente se encarga de eliminar restricciones, truncar tablas y cargar registros predeterminados (con valores nulos o -1) en diversas tablas de las \u00e1reas Transversal, Cedesarrollo, Protecci\u00f3n y Colegio. La implementaci\u00f3n de esta tarea garantiza que, en ausencia de datos v\u00e1lidos, se disponga de registros por defecto que faciliten las consultas y an\u00e1lisis posteriores en plataformas de inteligencia de negocios.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete_1","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del componente es:</p> <ol> <li>Eliminar restricciones de clave for\u00e1nea en el esquema <code>Transversal</code> para permitir la carga de datos sin conflictos.</li> <li>Truncar tablas en las \u00e1reas correspondientes para limpiar datos obsoletos o inconsistentes.</li> <li>Insertar registros por defecto en las dimensiones clave, utilizando valores nulos o identificadores especiales (como -1) para representar datos no disponibles o gen\u00e9ricos.</li> <li>Estandarizar la carga de informaci\u00f3n en las \u00e1reas Transversal, Cedesarrollo, Protecci\u00f3n y Colegio, asegurando la integridad y consistencia de los datos en el Data Warehouse.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-paquete_1","title":"Descripci\u00f3n del Paquete","text":"<p>La tarea se realiza a trav\u00e9s de una Tarea Ejecutar SQL (Execute SQL Task) que contiene un bloque de c\u00f3digo SQL con las siguientes operaciones:</p> <ol> <li> <p>Eliminaci\u00f3n de restricciones de clave for\u00e1nea:  </p> <ul> <li>Se genera y ejecuta un comando din\u00e1mico que elimina todas las restricciones de llave for\u00e1nea en el esquema <code>Transversal</code>.</li> </ul> </li> <li> <p>Truncado e inserci\u00f3n en la dimensi\u00f3n de Unidades:  </p> <ul> <li>Se trunca la tabla <code>DIM_UNIDAD</code> y se insertan registros que representan las diferentes unidades operativas: Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua, Protecci\u00f3n Social y un valor por defecto (\"SIN UNIDAD\").</li> </ul> </li> <li> <p>Cargar datos en DIM_INFRAESTRUCTURA_CCF:  </p> <ul> <li>Se trunca la tabla y se insertan registros que incluyen un valor por defecto (con c\u00f3digo -1 y descripci\u00f3n 'SinDato') y registros reales asociados a cada unidad.</li> </ul> </li> <li> <p>Cargar registros en DIM_CATEGORIA:  </p> <ul> <li>Se trunca la tabla <code>DIM_CATEGORIA</code> y se insertan categor\u00edas predefinidas, abarcando desde categor\u00edas est\u00e1ndar hasta aquellas para empresas y convenios.</li> </ul> </li> <li> <p>Inicializaci\u00f3n de la tabla DIM_PERSONAL:  </p> <ul> <li>Se trunca la tabla y se inserta un registro para el personal sin datos (con ID -1), permitiendo que exista un valor por defecto en situaciones donde no se disponga de informaci\u00f3n personal.</li> </ul> </li> <li> <p>Carga de registros por defecto en DIM_TARIFAS_SERVICIOS:  </p> <ul> <li>Se trunca la tabla y se inserta un registro con ID_TARIFA -1, utilizando valores de ejemplo para los campos que definen el servicio, objeto, costo, tarifa, categor\u00eda, a\u00f1o y c\u00f3digo de infraestructura.</li> </ul> </li> <li> <p>Carga de registros en el esquema Cedesarrollo:  </p> <ul> <li>Se truncan las tablas DIM_PROGRAMA y DIM_PERIODO_ACADEMICO, insert\u00e1ndose un registro por defecto en cada una (con ID -1) para representar programas y periodos sin datos.</li> </ul> </li> <li> <p>Carga de registros en el esquema Protecci\u00f3n:  </p> <ul> <li>Se actualizan las tablas DIM_PROGRAMA, DIM_PREGUNTAS_EE_JEC, DIM_RESPUESTAS_EE_JEC, DIM_PREGUNTAS_EE_AIPI y DIM_RESPUESTAS_EE_AIPI, insertando registros predeterminados (con valores -1 y descripciones como 'PREGUNTA_ABIERTA' o 'RESPUESTA_PREGUNTA_ABIERTA') para manejar datos no disponibles.</li> </ul> </li> <li> <p>Verificaci\u00f3n e inserci\u00f3n en el esquema Colegio:  </p> <ul> <li>Se verifica la existencia de un registro por defecto en la tabla <code>DIM_POBLACION_MATRICULA</code>. Si no existe, se trunca la tabla y se inserta un registro con ID -1, que utiliza valores \"N/A\" y un mensaje descriptivo para representar a estudiantes sin cruce de datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#tablas-y-columnas-clave_1","title":"Tablas y Columnas Clave","text":"<p>A continuaci\u00f3n se enumeran algunas de las tablas afectadas y el prop\u00f3sito de los valores por defecto:</p> <ol> <li> <p>DIM_UNIDAD:</p> <ul> <li>Columna: <code>UNIDAD</code></li> <li>Valores Insertados: 'EDUCACI\u00d3N FORMAL', 'EDUCACI\u00d3N T\u00c9CNICA', 'EDUCACI\u00d3N CONTINUA', 'PROTECCI\u00d3N SOCIAL', 'SIN UNIDAD'</li> </ul> </li> <li> <p>DIM_INFRAESTRUCTURA_CCF:</p> <ul> <li>Columnas: <code>COD_INFRAESTRUCTURA_CCF</code>, <code>DESCRIPCION</code>, <code>ID_UNIDAD</code></li> <li>Valores Insertados: Incluye un registro por defecto con <code>'-1'</code>, 'SinDato', y 5, adem\u00e1s de registros reales asociados a cada unidad.</li> </ul> </li> <li> <p>DIM_CATEGORIA:</p> <ul> <li>Columnas: <code>COD_CATEGORIA</code>, <code>DESCRIPCION</code></li> <li>Valores Insertados: '1' a '12' con descripciones como 'Categor\u00eda A', 'Categor\u00eda B', etc.</li> </ul> </li> <li> <p>DIM_PERSONAL:</p> <ul> <li>Columnas: Incluye <code>ID_PERSONAL</code>, <code>COD_PERSONA_UNIDAD</code>, <code>ID_UNIDAD</code>, entre otras.</li> <li>Valores Insertados: Un registro con <code>ID_PERSONAL = -1</code> para representar datos gen\u00e9ricos.</li> </ul> </li> <li> <p>DIM_TARIFAS_SERVICIOS:</p> <ul> <li>Columnas: Incluye <code>ID_TARIFA</code>, <code>COD_SERVICIO</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>VAL_TARIFA</code>, <code>COD_CATEGORIA</code>, <code>ANIO_TARIFA</code>, <code>COD_INFRAESTRUCTURA_CCF</code></li> <li>Valores Insertados: Un registro con <code>ID_TARIFA = -1</code> que establece valores predeterminados para definir un servicio sin datos.</li> </ul> </li> <li> <p>DIM_PROGRAMA (Cedesarrollo) y DIM_PERIODO_ACADEMICO (Cedesarrollo):</p> <ul> <li>Valores Insertados: Se insertan registros con <code>ID_PROGRAMA = -1</code> y <code>ID_PERIODO = -1</code> respectivamente, indicando ausencia de datos.</li> </ul> </li> <li> <p>Tablas en Protecci\u00f3n (DIM_PROGRAMA, DIM_PREGUNTAS_EE_JEC, DIM_RESPUESTAS_EE_JEC, DIM_PREGUNTAS_EE_AIPI, DIM_RESPUESTAS_EE_AIPI):</p> <ul> <li>Valores Insertados: Se insertan registros que utilizan el valor -1 para representar preguntas y respuestas predeterminadas.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA (Colegio):</p> <ul> <li>Valores Insertados: Se inserta un registro con <code>ID_POBLACION_MATRICULA = -1</code> en caso de que no exista, utilizando valores \"N/A\" y una descripci\u00f3n para estudiantes sin cruce.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas_1","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-de-carga-de-valores-nulos-por-defecto","title":"Diagrama de Flujo de Proceso de Carga de Valores Nulos por Defecto","text":"<pre><code>sequenceDiagram\n    participant SQL_TASK as Tarea Ejecutar SQL\n    participant Transversal as Esquema Transversal\n    participant Cedesarrollo as Esquema Cedesarrollo\n    participant Proteccion as Esquema Proteccion\n    participant Colegio as Esquema Colegio\n\n    SQL_TASK-&gt;&gt;Transversal: Eliminar restricciones y truncar tablas DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF, DIM_CATEGORIA y DIM_PERSONAL\n    Transversal--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de eliminaci\u00f3n y truncado\n    SQL_TASK-&gt;&gt;Transversal: Insertar registros por defecto en DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIA\n    Transversal--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Transversal: Insertar registro por defecto en DIM_PERSONAL\n    Transversal--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Transversal: Insertar registro por defecto en DIM_TARIFAS_SERVICIOS\n    Transversal--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Cedesarrollo: Truncar e insertar registro por defecto en DIM_PROGRAMA y DIM_PERIODO_ACADEMICO\n    Cedesarrollo--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Proteccion: Truncar e insertar registros predeterminados en DIM_PROGRAMA, DIM_PREGUNTAS_EE_JEC, DIM_RESPUESTAS_EE_JEC, DIM_PREGUNTAS_EE_AIPI y DIM_RESPUESTAS_EE_AIPI\n    Proteccion--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n\n    SQL_TASK-&gt;&gt;Colegio: Verificar e insertar registro por defecto en DIM_POBLACION_MATRICULA\n    Colegio--&gt;&gt;SQL_TASK: Confirmaci\u00f3n de inserci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito","title":"Prop\u00f3sito:","text":"<p>Este componente tiene como objetivo inicializar y estandarizar los datos en m\u00faltiples esquemas del Data Warehouse mediante la carga de valores predeterminados en caso de ausencia de informaci\u00f3n. Esto facilita la integraci\u00f3n de datos y evita problemas en las consultas y an\u00e1lisis posteriores.</p> <p>Operaciones Principales:</p> <ol> <li> <p>Eliminaci\u00f3n de Restricciones:  </p> <ul> <li>Genera y ejecuta un script din\u00e1mico para eliminar todas las restricciones de clave for\u00e1nea en el esquema <code>Transversal</code>, permitiendo la inserci\u00f3n de datos sin conflictos.</li> </ul> </li> <li> <p>Limpieza de Tablas:  </p> <ul> <li>Se truncan las tablas cr\u00edticas en los esquemas involucrados (por ejemplo, <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code>, <code>DIM_CATEGORIA</code>, <code>DIM_PERSONAL</code>, <code>DIM_TARIFAS_SERVICIOS</code>, entre otras) para asegurar que no existan datos obsoletos o inconsistentes.</li> </ul> </li> <li> <p>Carga de Registros Predeterminados:  </p> <ul> <li>Inserta registros con valores especiales (usualmente -1 o 'N/A') en cada tabla para representar datos no disponibles.  </li> <li>Se incluyen registros para \u00e1reas operativas como Transversal, Cedesarrollo, Protecci\u00f3n y Colegio, garantizando que cada \u00e1rea disponga de un registro por defecto.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_1","title":"C\u00f3digo SQL","text":"<pre><code>USE DWH_COMFENALCO\nGO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- Eliminar restricciones de clave for\u00e1nea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDAD];\nINSERT INTO [Transversal].[DIM_UNIDAD] (UNIDAD)\nVALUES ('EDUCACI\u00d3N FORMAL'), ('EDUCACI\u00d3N T\u00c9CNICA'), ('EDUCACI\u00d3N CONTINUA'), ('PROTECCI\u00d3N SOCIAL'), ('SIN UNIDAD');\n-- Insertar registros en DIM_INFRAESTRUCTURA\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_INFRAESTRUCTURA_CCF];\nINSERT INTO [Transversal].[DIM_INFRAESTRUCTURA_CCF] ([COD_INFRAESTRUCTURA_CCF], [DESCRIPCION], [ID_UNIDAD]) VALUES\n('-1', 'SinDato', 5),\n('CCF008-12-00001', 'Educaci\u00f3n formal', 1),\n('CCF008-13-00001', 'Educaci\u00f3n para el trabajo', 2),\n('CCF008-15-00001', 'Desarrollo empresarial', 3),\n('CCF008-26-00001', 'Protecci\u00f3n social', 4);\n-- Insertar registros DIM_CATEGORIA\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CATEGORIA];\nINSERT INTO [Transversal].[DIM_CATEGORIA] ([COD_CATEGORIA], [DESCRIPCION]) VALUES\n('1', 'Categor\u00eda A'),\n('2', 'Categor\u00eda B'),\n('3', 'Categor\u00eda C'),\n('4', 'Categor\u00eda D'),\n('5', 'Empresas'),\n('6', 'Fondos de Ley'),\n('10', 'Convenios y Facultativos'),\n('12', 'Empresa no afiliada');\n\n-- Insertar un registro para el personal sin datos\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL];\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] ON;\nINSERT INTO [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL], \n    [COD_PERSONA_UNIDAD], \n    [ID_UNIDAD], \n    [SERVICIO], \n    [NOMBRE], \n    [TELEFONO], \n    [CELULAR], \n    [CORREO], \n    [DIRECCION], \n    [CIUDAD], \n    [TIPO_DOCUMENTO], \n    [DOCUMENTO], \n    [FECHA_NACIMIENTO], \n    [GENERO], \n    [HORAS_CONTRATADAS_MENSUAL], \n    [HORAS_CONTRATADAS_TOTALES], \n    [VALOR_TOTAL], \n    [TIPO_CONTRATACION], \n    [FECHA_INICIO_CONTRATACION], \n    [FECHA_FIN_CONTRATACION], \n    [CAUSA_TERMINACION_CONTRATO], \n    [PREGRADO], \n    [POSGRADO_ESPECIALIDAD], \n    [POSGRADO_MAESTRIA], \n    [POSGRADO_DOCTORADO], \n    [NIVEL_INGLES], \n    [AREA]\n) \nVALUES (\n    -1, \n    -1, \n    5,\n    NULL, NULL, NULL, NULL, NULL, NULL, NULL, \n    'CC', '-1', NULL, NULL, NULL, NULL, NULL, \n    NULL, '1900-01-01', '1900-01-01', NULL, NULL, NULL, NULL, NULL, NULL, NULL\n);\n\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] OFF;\nGO\n\n-- Insertar registro con ID_TARIFA -1\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_TARIFAS_SERVICIOS]\nSET IDENTITY_INSERT [Transversal].[DIM_TARIFAS_SERVICIOS] ON;\nINSERT INTO [Transversal].[DIM_TARIFAS_SERVICIOS] (\n    [ID_TARIFA],\n    [COD_SERVICIO],\n    [CON_OBJETO_TARIFA],\n    [COS_UNITARIO_CONCEPTO],\n    [VAL_TARIFA],\n    [COD_CATEGORIA],\n    [ANIO_TARIFA],\n    [COD_INFRAESTRUCTURA_CCF]\n)\nVALUES (\n    -1,\n    0, -- Ejemplo de servicio\n    'default object', -- Ejemplo de objeto\n    0, -- Ejemplo de costo unitario\n    0, -- Ejemplo de valor de tarifa\n    '3', -- Debe coincidir con el valor en DIM_CATEGORIA\n    '2024', -- Ejemplo de a\u00f1o de tarifa\n    '-1' -- Debe coincidir con el valor en DIM_INFRAESTRUCTURA_CCF\n);\n\nSET IDENTITY_INSERT [Transversal].[DIM_TARIFAS_SERVICIOS] OFF;\n\n-- Insertar registro con ID_PROGRAMA -1\nTRUNCATE TABLE [DWH_COMFENALCO].[Cedesarrollo].[DIM_PROGRAMA] \nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PROGRAMA] ON;\nINSERT INTO [Cedesarrollo].[DIM_PROGRAMA] (\n    [ID_PROGRAMA],\n    [PROGRAMA]\n)\nVALUES (\n    -1,\n    'Sin Programa' -- Ejemplo de nombre de programa\n);\n\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PROGRAMA] OFF;\n\n-- Insertar un registro para el periodo sin datos\nTRUNCATE TABLE [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO];\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] ON;\n\nINSERT INTO [Cedesarrollo].[DIM_PERIODO_ACADEMICO] (\n    [ID_PERIODO], \n    [ID_UNIDAD], \n    [PERIODO_ACADEMICO], \n    [FECHA_INICIO], \n    [FECHA_FIN]\n) \nVALUES (\n    -1, \n    5, \n    'Sin datos', \n    NULL, \n    NULL\n);\n\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] OFF;\nGO\n\n-- Insertar registros de programas Proteccion\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] ON\nINSERT INTO [Proteccion].[DIM_PROGRAMA] (ID_PROGRAMA,PROGRAMA)\nVALUES (1,'ADULTO_MAYOR'),\n(2,'DISCAPACIDAD'),\n(3,'JEC'),\n(4,'AIPI');\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] OFF;\n\n\n-- Insertar -1 para preguntas proteccion JEC\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC] ON\nINSERT INTO [Proteccion].[DIM_PREGUNTAS_EE_JEC] (ID_PREGUNTA,PREGUNTA,ID_PROGRAMA)\nVALUES (-1,'PREGUNTA_ABIERTA',3);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC] OFF;\n\n-- Insertar -1 para respuestas proteccion JEC\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] ON\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_JEC] (ID_RESPUESTA,RESPUESTA,ID_PREGUNTA)\nVALUES (-1,'RESPUESTA_PREGUNTA_ABIERTA',-1);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] OFF;\n\n\n-- Insertar -1 para preguntas proteccion AIPI\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI] ON\nINSERT INTO [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (ID_PREGUNTA,PREGUNTA,ID_PROGRAMA)\nVALUES (-1,'PREGUNTA_ABIERTA',4);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI] OFF;\n\n\n-- Insertar -1 para respuestas proteccion AIPI\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] ON\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (ID_RESPUESTA,RESPUESTA,ID_PREGUNTA)\nVALUES (-1,'RESPUESTA_PREGUNTA_ABIERTA',-1);\n\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] OFF; \n\n\n\n-- Verificar si el registro ya existe\nIF NOT EXISTS (\n    SELECT 1\n    FROM [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA]\n    WHERE [ID_POBLACION_MATRICULA] = -1\n)\nBEGIN\n    -- Activar IDENTITY_INSERT para la tabla\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] ON;\n\n-- Insertar el registro con ID_POBLACION_MATRICULA = -1 para colegio\n    INSERT INTO [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] \n    (\n        [ID_POBLACION_MATRICULA],\n        [PARTNER],\n        [TIPO_DOCUMENTO],\n        [DOCUMENTO],\n        [NOMBRE_COMPLETO],\n        [GENERO],\n        [DIRECCION],\n        [TELEFONO],\n        [CORREO],\n        [FECHA_NACIMIENTO]\n    )\n    VALUES \n    (\n        -1,\n        'N/A', -- PARTNER\n        'N/A', -- TIPO_DOCUMENTO\n        'N/A', -- DOCUMENTO\n        'Estudiantes sin cruce', -- NOMBRE_COMPLETO\n        'N/A', -- GENERO\n        'N/A', -- DIRECCION\n        'N/A', -- TELEFONO\n        'N/A', -- CORREO\n        NULL -- FECHA_NACIMIENTO\n    );\n\n    -- Desactivar IDENTITY_INSERT para la tabla\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] OFF;\nEND\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_unidades_organizativas","title":"Componente <code>Cargar_DIM_UNIDADES_ORGANIZATIVAS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente <code>Cargar_DIM_UNIDADES_ORGANIZATIVAS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de cargar datos en la tabla <code>DIM_UNIDADES_ORGANIZATIVAS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Cargar_DIM_UNIDADES_ORGANIZATIVAS</code></li> <li>DTSID: <code>{2b52324e-63da-4f09-aadd-80b248ece527}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen de Datos ADO.NET (<code>DIM_UNIDADES_ORGANIZATIVAS_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server, OLE DB, ODBC u Oracle mediante el correspondiente proveedor de datos de .NET Framework.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_CEBE], [CEBE], [DESCRIPCION_BREVE], [DESCRIPCION_COMPLETA], [DEPARTAMENTO], [AREA], [SUBAREA], [SEGMENTO], [DESCRIPCION_SEGMENTO], [CODIGO_SSF], [NOMBRE_SSF], [UDATE], [NUMERO_PROCESO_SQL], [FEC_PROCESO], [USUARIO_PROCESO], [GRUPO_CEBE], \nCASE \n    WHEN [DEPARTAMENTO] = 'EDUCACION FORMAL' THEN 1\n    WHEN [DEPARTAMENTO] = 'EDUCACION PARA EL TRABAJO' THEN 2\n    WHEN [DEPARTAMENTO] = 'DESARROLLO EMPRESARIAL' THEN 3\n    WHEN [DEPARTAMENTO] = 'PROGRAMAS Y CONVENIOS ESPECIALES' AND [AREA] IN ('Adulto Mayor', 'Discapacidad', 'Atencion integral a la Ninez', 'Jornada Escolar Complementaria') THEN 4\n    ELSE 5\nEND AS [ID_UNIDAD]\nFROM [DWH_COMFENALCO].[Financiera].[DIM_UNIDADES_ORGANIZATIVAS]\nWHERE DEPARTAMENTO IN ('EDUCACION FORMAL', 'EDUCACION PARA EL TRABAJO', 'DESARROLLO EMPRESARIAL')\nOR (DEPARTAMENTO IN ('PROGRAMAS Y CONVENIOS ESPECIALES') AND AREA IN ('Adulto Mayor', 'Discapacidad','Atencion integral a la Ninez','Jornada Escolar Complementaria'))\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>AllowImplicitStringConversion</code>: <code>true</code></li> <li><code>TableOrViewName</code>: <code>\"Financiera\".\"DIM_CUENTA_CONTABLE\"</code></li> <li><code>AccessMode</code>: <code>2</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_CEBE</code>, <code>CEBE</code>, <code>DESCRIPCION_BREVE</code>, <code>DESCRIPCION_COMPLETA</code>, <code>DEPARTAMENTO</code>, <code>AREA</code>, <code>SUBAREA</code>, <code>SEGMENTO</code>, <code>DESCRIPCION_SEGMENTO</code>, <code>CODIGO_SSF</code>, <code>NOMBRE_SSF</code>, <code>UDATE</code>, <code>NUMERO_PROCESO_SQL</code>, <code>FEC_PROCESO</code>, <code>USUARIO_PROCESO</code>, <code>GRUPO_CEBE</code></li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_UNIDADES_ORGANIZATIVAS_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en una base de datos compatible con ADO.NET que use una vista o tabla de base de datos.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_UNIDADES_ORGANIZATIVAS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_CEBE</code>, <code>CEBE</code>, <code>DESCRIPCION_BREVE</code>, <code>DESCRIPCION_COMPLETA</code>, <code>DEPARTAMENTO</code>, <code>AREA</code>, <code>SUBAREA</code>, <code>SEGMENTO</code>, <code>DESCRIPCION_SEGMENTO</code>, <code>CODIGO_SSF</code>, <code>NOMBRE_SSF</code>, <code>UDATE</code>, <code>NUMERO_PROCESO_SQL</code>, <code>FEC_PROCESO</code>, <code>USUARIO_PROCESO</code>, <code>GRUPO_CEBE</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-descargar_am-tra-08","title":"Componente <code>Descargar_AM-TRA-08</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_AM-TRA-08</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para la conexi\u00f3n a SharePoint y la descarga de archivos manuales.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_1","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_1","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Descargar_AM-TRA-08</code></li> <li>DTSID: <code>{16C2FBC1-E5C9-472A-BE1E-3575DAEF56C3}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar proceso</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteProcess</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Executable: <code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>01.SharePoint_Connection_AM-TRA-08.py</code></li> <li>WorkingDirectory: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_1","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Descargar_AM-TRA-08\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Script as Script Python\n    participant SharePoint as SharePoint\n\n    SSIS-&gt;&gt;Script: Ejecutar 01.SharePoint_Connection_AM-TRA-08.py\n    Script-&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de conexi\u00f3n\n    Script-&gt;&gt;SharePoint: Descargar archivos manuales\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de descarga\n    Script--&gt;&gt;SSIS: Proceso completado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_servicios","title":"Componente <code>Procesar_DIM_SERVICIOS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_SERVICIOS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_TARIFAS_SERVICIOS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_2","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_2","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_SERVICIOS</code></li> <li>DTSID: <code>{0EC61E46-C061-4440-8E8D-2704CC9AD0D4}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>AM-TRA-08_Manual_Tarifario</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: <code>0</code></li> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[Excel_Connection_Dim_Servicios]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ANIO_TARIFA</code>, <code>COD_INFRAESTRUCTURA_CCF</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>COD_CATEGORIA</code>, <code>VAL_TARIFA</code>, <code>COD_SERVICIO</code></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Verificar Tipos de Datos</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> <li>Columnas de Entrada:     <code>ANIO_TARIFA</code>, <code>COD_INFRAESTRUCTURA_CCF</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>COD_CATEGORIA</code>, <code>VAL_TARIFA</code>, <code>COD_SERVICIO</code></li> <li>Columnas de Salida:     <code>ANIO_TARIFA_v</code>, <code>COD_INFRAESTRUCTURA_CCF_v</code>, <code>CON_OBJETO_TARIFA_v</code>, <code>COS_UNITARIO_CONCEPTO_v</code>, <code>COD_CATEGORIA_v</code>, <code>VAL_TARIFA_v</code>, <code>COD_SERVICIO_v</code></li> </ul> </li> <li> <p>Columna Derivada (<code>Crear ID_SERVICIO_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_TARIFA_AUXILIAR</code> concatenando varias columnas de entrada.</li> <li>Columnas de Entrada:<ul> <li><code>ANIO_TARIFA_v</code></li> <li><code>COD_INFRAESTRUCTURA_CCF_v</code></li> <li><code>COD_SERVICIO_v</code></li> <li><code>COD_CATEGORIA_v</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_TARIFAS_SERVICIOS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>select * from [Transversal].[DIM_TARIFAS_SERVICIOS]</code></li> <li><code>SqlCommandParam</code>: <code>select * from (select * from [Transversal].[DIM_TARIFAS_SERVICIOS]) [refTable] where [refTable].[ID_TARIFA_AUXILIAR] = ?</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>COD_SERVICIO</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>VAL_TARIFA</code>, <code>COD_CATEGORIA</code></li> <li><code>ANIO_TARIFA</code>,  <code>COD_INFRAESTRUCTURA_CCF</code>, <code>ID_TARIFA</code>, <code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> <li>Salidas:<ul> <li><code>Agregar</code>: Filas donde <code>ID_TARIFA_AUXILIAR</code> es nulo.</li> <li><code>Sin Cambios</code>: Filas donde <code>ID_TARIFA_AUXILIAR</code> no es nulo.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_SERVICIOS_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_TARIFAS_SERVICIOS</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_TARIFAS_SERVICIOS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>COD_SERVICIO_v</code>, <code>CON_OBJETO_TARIFA_v</code>, <code>COS_UNITARIO_CONCEPTO_v</code>, <code>VAL_TARIFA_v</code>, <code>COD_CATEGORIA_v</code>, <code>ANIO_TARIFA_v</code>, <code>COD_INFRAESTRUCTURA_CCF_v</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_sedes","title":"Componente <code>Cargar_DIM_SEDES</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente <code>Cargar_DIM_SEDES</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de truncar y cargar datos en la tabla <code>DIM_SEDES</code> en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_3","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_3","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Cargar_DIM_SEDES</code></li> <li>DTSID: <code>{fbd7f70d-08d3-4da5-a641-f28f431909b7}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar SQL</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteSQLTask</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_1","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Connection: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_1","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>SQL Statement:   <pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_SEDES];\nINSERT INTO [Transversal].[DIM_SEDES] (SEDE)\nVALUES ('CEC'), ('CEDESARROLLO');\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_2","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Cargar_DIM_SEDES\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant SQL as Base de Datos SQL\n\n    SSIS-&gt;&gt;SQL: TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_SEDES]\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n    SSIS-&gt;&gt;SQL: INSERT INTO [Transversal].[DIM_SEDES] (SEDE) VALUES ('CEC'), ('CEDESARROLLO')\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso","title":"Descripci\u00f3n del Proceso","text":"<ol> <li>Truncar Tabla: La tarea ejecuta una instrucci\u00f3n SQL para truncar la tabla <code>DIM_SEDES</code>, eliminando todos los registros existentes.</li> <li>Insertar Datos: La tarea ejecuta una instrucci\u00f3n SQL para insertar nuevos registros en la tabla <code>DIM_SEDES</code> con los valores <code>'CEC'</code> y <code>'CEDESARROLLO'</code>.</li> </ol> <p>Este proceso asegura que la tabla <code>DIM_SEDES</code> se actualice con los datos m\u00e1s recientes, eliminando cualquier dato anterior y cargando los nuevos valores especificados.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-descargar_ep-tra-12","title":"Componente <code>Descargar_EP-TRA-12</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_EP-TRA-12</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para la conexi\u00f3n a SharePoint y la descarga de archivos manuales.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_4","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_4","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Descargar_EP-TRA-12</code></li> <li>DTSID: <code>{56e49c08-d0c9-4678-8e9c-27288db94c3b}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar proceso</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteProcess</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_2","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Executable: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_2","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>02.SharePoint_Connection_EP-TRA-12.py</code></li> <li>WorkingDirectory: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_3","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Descargar_EP-TRA-12\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Script as Script Python\n    participant SharePoint as SharePoint\n\n    SSIS-&gt;&gt;Script: Ejecutar 02.SharePoint_Connection_EP-TRA-12.py\n    Script-&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de conexi\u00f3n\n    Script-&gt;&gt;SharePoint: Descargar archivos manuales\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de descarga\n    Script--&gt;&gt;SSIS: Proceso completado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso_1","title":"Descripci\u00f3n del Proceso","text":"<ol> <li>Ejecutar Script Python: La tarea ejecuta el script <code>02.SharePoint_Connection_EP-TRA-12.py</code> utilizando el int\u00e9rprete de Python especificado.</li> <li>Conectar a SharePoint: El script se conecta a SharePoint para acceder a los archivos manuales.</li> <li>Descargar Archivos: El script descarga los archivos manuales desde SharePoint al directorio de trabajo especificado.</li> <li>Confirmaci\u00f3n de Descarga: El script confirma la descarga exitosa de los archivos y finaliza el proceso.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_capacidad_fisica","title":"Componente <code>Procesar_DIM_CAPACIDAD_FISICA</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_CAPACIDAD_FISICA</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_CAPACIDAD_FISICA</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_5","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_5","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_CAPACIDAD_FISICA</code></li> <li>DTSID: <code>{592bbecc-5b7f-44ef-b177-462c29ca7233}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>EP-TRA-12_Capacidad Fisica</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: <code>0</code></li> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[Excel_Connection_Dim_Capacidad]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>JORNADA</code>, <code>DESCRIPCION_ESPACIO</code>, <code>ID_UNIDAD</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> <li> <p>Columnas de Entrada:     <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>JORNADA</code>, <code>DESCRIPCION_ESPACIO</code>, <code>ID_UNIDAD</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code></p> </li> <li> <p>Columnas de Salida:     <code>Copy of ID_SALON</code>, <code>Copy of CAPACIDAD</code>, <code>Copy of JORNADA</code>, <code>Copy of DESCRIPCION_ESPACIO</code>, <code>Copy of ID_UNIDAD</code>, <code>Copy of BLOQUE</code>, <code>Copy of GRUPO</code>, <code>Copy of ID_SEDE</code>, <code>Copy of SEDE</code>, <code>Copy of ESTADO</code>, <code>Copy of FECHA_ESTADO</code></p> </li> </ul> </li> <li> <p>Columna Derivada (<code>Crear_ID_CAPACIDAD_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_CAPACIDAD_AUXILIAR</code> concatenando varias columnas de entrada.</li> <li>Columnas de Entrada:     <code>Copy of ID_SALON</code>,  <code>Copy of JORNADA</code>, <code>Copy of ID_UNIDAD</code></li> <li>Columnas de Salida:     <code>ID_CAPACIDAD_AUXILIAR</code></li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_CAPACIDAD_FISICA</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>select * from [Transversal].[DIM_CAPACIDAD_FISICA]</code></li> <li><code>SqlCommandParam</code>: <code>select * from (select * from [Transversal].[DIM_CAPACIDAD_FISICA]) [refTable] where [refTable].[ID_CAPACIDAD_AUXILIAR] = ?</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_CAPACIDAD_AUXILIAR</code></li> <li>Columnas de Salida:     <code>ID_CAPACIDAD</code>, <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>DESCRIPCION_ESPACIO</code>, <code>JORNADA</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_UNIDAD</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code>, <code>ID_CAPACIDAD_AUXILIAR</code></li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li> <p>Columnas de Entrada:     <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>JORNADA</code>, <code>DESCRIPCION_ESPACIO</code>, <code>ID_UNIDAD</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code>, <code>ID_CAPACIDAD</code></p> </li> <li> <p>Salidas:</p> <ul> <li><code>Agregar</code>: Filas donde <code>ID_CAPACIDAD</code> es nulo.</li> <li><code>Modificar</code>: Filas donde hay diferencias entre las columnas de entrada y las columnas de b\u00fasqueda.</li> <li><code>Sin Cambios</code>: Filas donde no hay diferencias.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_CAPACIDAD_FISICA_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_CAPACIDAD_FISICA</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_CAPACIDAD_FISICA\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>Copy of ID_SALON</code>, <code>Copy of CAPACIDAD</code>, <code>Copy of DESCRIPCION_ESPACIO</code>, <code>Copy of JORNADA</code>, <code>Copy of BLOQUE</code>, <code>Copy of GRUPO</code>, <code>Copy of ID_UNIDAD</code>, <code>Copy of ID_SEDE</code>, <code>Copy of SEDE</code>, <code>Copy of ESTADO</code>, <code>Copy of FECHA_ESTADO</code></li> </ul> </li> <li> <p>Comando OLE DB (<code>OLE DB Command 1</code>)</p> <ul> <li>Descripci\u00f3n: Ejecuta una instrucci\u00f3n SQL para cada fila en el flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>UPDATE [Transversal].[DIM_CAPACIDAD_FISICA]\n   SET [ID_SALON] = ?\n      ,[CAPACIDAD] = ?\n      ,[DESCRIPCION_ESPACIO] = ?\n      ,[JORNADA] = ?\n      ,[BLOQUE] = ?\n      ,[GRUPO] = ?\n      ,[ID_UNIDAD] = ?\n      ,[ID_SEDE] = ?\n      ,[SEDE] = ?\n      ,[ESTADO] = ?\n      ,[FECHA_ESTADO] = ?\n WHERE [ID_CAPACIDAD] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>DESCRIPCION_ESPACIO</code>, <code>JORNADA</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_UNIDAD</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code>, <code>ID_CAPACIDAD</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as EP-TRA-12_Capacidad Fisica\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Crear_ID_CAPACIDAD_AUXILIAR\n    participant Lookup as Lookup\n    participant ConditionalSplit as Conditional Split\n    participant AdoNetDestination as DIM_CAPACIDAD_FISICA_DEST\n    participant OleDbCommand as OLE DB Command 1\n\n    ExcelSource -&gt;&gt; DataConversion: Excel Source Output\n    DataConversion -&gt;&gt; DerivedColumn: Data Conversion Output\n    DerivedColumn -&gt;&gt; Lookup: Derived Column Output\n    Lookup -&gt;&gt; ConditionalSplit: Lookup Match Output\n    ConditionalSplit -&gt;&gt; AdoNetDestination: Agregar\n    ConditionalSplit -&gt;&gt; OleDbCommand: Modificar</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-tabla-temporal-dim_estudiantes-educacion-continua-y-tecnica","title":"Componente <code>Tabla Temporal DIM_ESTUDIANTES Educaci\u00f3n Continua y T\u00e9cnica</code>","text":"<p>El paquete SSIS \"Tabla Temporal DIM_ESTUDIANTES Educaci\u00f3n Continua y T\u00e9cnica\" se encarga de gestionar flujos ETL que permiten consolidar, transformar y cargar datos temporales relacionados con los estudiantes de Educaci\u00f3n Continua y T\u00e9cnica. Este paquete se utiliza para integrar, depurar y unificar informaci\u00f3n proveniente de diversas fuentes (Excel, bases de datos, etc.) en una tabla temporal que sirve de staging para procesos posteriores en el Data Warehouse. La soluci\u00f3n abarca desde la actualizaci\u00f3n de datos de egresados, inasistencias, matr\u00edculas y registros de estudiantes hasta la ejecuci\u00f3n de procesos adicionales para descargar informaci\u00f3n complementaria.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete_2","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es:</p> <ul> <li>Consolidar y Unificar Datos Temporales: Recopilar informaci\u00f3n de estudiantes procedente de diversas fuentes (Excel, bases de datos, etc.) y depositarla en una tabla temporal para facilitar su procesamiento posterior.</li> <li>Depurar y Transformar Datos: Aplicar conversiones, derivaciones y validaciones sobre los datos le\u00eddos para garantizar su integridad y calidad.</li> <li>Integrar Fuentes Adicionales: Ejecutar procesos externos (scripts en Python) para descargar informaci\u00f3n complementaria (egresados, matr\u00edculas, preinscritos, etc.) que permita actualizar y enriquecer la tabla temporal.</li> <li>Limpiar el Staging Area: Truncar la tabla temporal al inicio del proceso para evitar la acumulaci\u00f3n de registros obsoletos.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-paquete_2","title":"Descripci\u00f3n del Paquete","text":"<p>El paquete se compone de varios componentes que realizan operaciones ETL espec\u00edficas:</p> <ol> <li> <p>Actualizar Tabla Temporal Egresados </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Extrae datos desde una hoja de Excel (Fuente: \"Egresados\") para actualizar la informaci\u00f3n de egresados en la tabla temporal.  </li> <li>Conexi\u00f3n: Utiliza un administrador de conexiones para Excel.</li> </ul> </li> <li> <p>Actualizar Tabla Temporal Inasistencias </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Procesa informaci\u00f3n de inasistencias extra\u00edda desde Excel, aplicando transformaciones y derivaciones para adecuar los campos (como DOCUMENTO, TIPO_DOCUMENTO, ESTUDIANTE) y luego carga los datos en la tabla temporal.  </li> <li>Componentes clave: Excel Source, Transformaci\u00f3n de Columnas (Derived Column) y ADO.NET Destination.</li> </ul> </li> <li> <p>Actualizar Tabla Temporal Matr\u00edculas </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Extrae datos de matr\u00edculas desde Excel para actualizar la informaci\u00f3n en la tabla temporal, incluyendo campos como TIPO_DOCUMENTO, DOCUMENTO_ESTUDIANTE y NOMBRE_ESTUDIANTE.  </li> <li>Conexi\u00f3n: Se conecta a Excel mediante un administrador de conexiones espec\u00edfico.</li> </ul> </li> <li> <p>Actualizar Tabla Temporal Matr\u00edculas Emp </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Similar al componente anterior, pero orientado a consolidar datos de matr\u00edculas empresariales (Emp), utilizando informaci\u00f3n de una fuente Excel y cargando la informaci\u00f3n en la tabla temporal.</li> </ul> </li> <li> <p>dim_Estudiantes py </p> <ul> <li>Tipo: Execute Process Task  </li> <li>Funcionalidad: Ejecuta un script de Python (<code>dim_Estudiantes.py</code>) que procesa y consolida los datos de estudiantes a nivel general, utilizando un ejecutable de Python configurado mediante variables de proyecto.  </li> <li>Directorio de trabajo: Se configura para ejecutarse en la carpeta de utilidades.</li> </ul> </li> <li> <p>Fuentes Adicionales de Estudiantes </p> <ul> <li>Tipo: Contenedor de secuencias (Sequence)  </li> <li>Funcionalidad: Agrupa varios procesos externos para complementar la informaci\u00f3n de estudiantes. Entre ellos se encuentran:  </li> <li>Tarea cede_Egresados_Graduados: Ejecuta un script de Python para descargar informaci\u00f3n de egresados y graduados desde una fuente definida (probablemente SharePoint o similar).  </li> <li>Tarea cede_Listado_Matriculas: Ejecuta un script de Python para descargar un listado de matr\u00edculas.  </li> <li>Tarea emp_Consolidado_inasistencias: Ejecuta un script de Python para consolidar inasistencias a nivel empresarial.  </li> <li>Tarea emp_Egresados_Graduados: Ejecuta un script para procesar datos de egresados en el \u00e1mbito empresarial.  </li> <li>Tarea emp_Listado_Matriculas: Ejecuta un script para descargar informaci\u00f3n del listado de matr\u00edculas empresariales.  </li> <li>Tarea emp_Preinscritos: Ejecuta un script para procesar los  preinscritos.  </li> <li>Tarea fact_graduados py: Ejecuta un script que procesa la informaci\u00f3n de graduados.</li> </ul> </li> <li> <p>Actualizar Tabla Temporal Inscripciones </p> <ul> <li>Tipo: Data Flow Task  </li> <li>Funcionalidad: Procesa y consolida los datos de inscripciones, extray\u00e9ndolos de Excel, aplicando transformaciones y carg\u00e1ndolos en la tabla temporal.</li> </ul> </li> <li> <p>Limpiar Tabla Temporal </p> <ul> <li>Tipo: Execute SQL Task  </li> <li>Funcionalidad: Ejecuta una instrucci\u00f3n SQL para truncar la tabla temporal <code>TMP_ESTUDIANTES_CEDESARROLLO</code>, asegurando que el proceso ETL comience sin datos previos y evite la duplicidad de registros.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas_2","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-etl","title":"Diagrama de Flujo de Proceso ETL","text":"<pre><code>sequenceDiagram\n    participant Egresados as Actualizar Tabla Temporal Egresados\n    participant Inasistencias as Actualizar Tabla Temporal Inasistencias\n    participant Matriculas as Actualizar Tabla Temporal Matr\u00edculas\n    participant MatriculasEmp as Actualizar Tabla Temporal Matr\u00edculas Emp\n    participant DimEstudiantes as dim_Estudiantes py\n    participant FuentesAdic as Fuentes adicionales de Estudiantes\n    participant Inscripciones as Actualizar Tabla Temporal Inscripciones\n    participant Limpiar as Limpiar Tabla Temporal\n\n    Egresados-&gt;&gt;Inasistencias: Proceso de consolidado de egresados y inasistencias\n    Inasistencias-&gt;&gt;Matriculas: Integraci\u00f3n de datos de inasistencias y matr\u00edculas\n    Matriculas-&gt;&gt;MatriculasEmp: Consolidaci\u00f3n de matr\u00edculas empresariales\n    MatriculasEmp-&gt;&gt;DimEstudiantes: Complemento de datos de estudiantes\n    DimEstudiantes-&gt;&gt;FuentesAdic: Ejecuci\u00f3n de procesos adicionales\n    FuentesAdic-&gt;&gt;Inscripciones: Unificaci\u00f3n de datos de inscripciones\n    Inscripciones-&gt;&gt;Limpiar: Truncado y limpieza de la tabla temporal</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-precedencia","title":"Diagrama de Precedencia","text":"<pre><code>sequenceDiagram\n    participant DimEst as dim_Estudiantes py\n    participant Fuentes as Fuentes adicionales de Estudiantes\n    participant Matriculas as Actualizar Tabla Temporal Matr\u00edculas\n    participant Inscripciones as Actualizar Tabla Temporal Inscripciones\n    participant Limpiar as Limpiar Tabla Temporal\n\n    DimEst-&gt;&gt;Fuentes: Ejecutar procesos adicionales (egresados, preinscritos, etc.)\n    Fuentes-&gt;&gt;Matriculas: Consolidar listado de matr\u00edculas\n    Matriculas-&gt;&gt;Inscripciones: Actualizar inscripciones\n    Inscripciones-&gt;&gt;Limpiar: Finalizar proceso con limpieza de la tabla temporal</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave-del-proceso","title":"Componentes Clave del Proceso","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-consolidacion-y-actualizacion-de-datos-temporales","title":"1. Consolidaci\u00f3n y Actualizaci\u00f3n de Datos Temporales","text":"<ul> <li> <p>Actualizaci\u00f3n de Datos de Egresados e Inasistencias:   Se extraen datos de fuentes Excel y se transforman para consolidar la informaci\u00f3n de egresados e inasistencias. Estos datos se integran en la tabla temporal para su posterior an\u00e1lisis.</p> </li> <li> <p>Actualizaci\u00f3n de Matr\u00edculas e Inscripciones:   Se procesan registros de matr\u00edculas e inscripciones a trav\u00e9s de m\u00faltiples Data Flow Tasks, que incluyen conversiones de datos y transformaciones derivadas para unificar la informaci\u00f3n.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-ejecucion-de-procesos-externos-con-python","title":"2. Ejecuci\u00f3n de Procesos Externos con Python","text":"<ul> <li> <p>dim_Estudiantes py:   Ejecuta un script de Python para procesar datos generales de estudiantes, sirviendo como punto de partida para la consolidaci\u00f3n.</p> </li> <li> <p>Fuentes Adicionales de Estudiantes:   Contiene m\u00faltiples tareas de proceso que descargan y actualizan informaci\u00f3n complementaria, como egresados, listado de matr\u00edculas, preinscritos y datos consolidados empresariales.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-limpieza-del-area-de-staging","title":"3. Limpieza del \u00c1rea de Staging","text":"<ul> <li>Limpiar Tabla Temporal:   Una tarea de SQL se encarga de truncar la tabla temporal <code>TMP_ESTUDIANTES_CEDESARROLLO</code>, garantizando un entorno limpio para cada ejecuci\u00f3n del proceso ETL.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_2","title":"C\u00f3digo SQL","text":"<p>El siguiente c\u00f3digo SQL se utiliza en la tarea de \"Cargar Valores nulos por defecto para todos los esquemas\" para inicializar las dimensiones con registros predeterminados:</p> <pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n\n-- Eliminar restricciones de clave for\u00e1nea en el esquema Transversal\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n\n-- Truncar y cargar datos en DIM_UNIDAD\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDAD];\nINSERT INTO [Transversal].[DIM_UNIDAD] (UNIDAD)\nVALUES ('EDUCACI\u00d3N FORMAL'), ('EDUCACI\u00d3N T\u00c9CNICA'), ('EDUCACI\u00d3N CONTINUA'), ('PROTECCI\u00d3N SOCIAL'), ('SIN UNIDAD');\n\n-- Truncar y cargar datos en DIM_INFRAESTRUCTURA_CCF\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_INFRAESTRUCTURA_CCF];\nINSERT INTO [Transversal].[DIM_INFRAESTRUCTURA_CCF] ([COD_INFRAESTRUCTURA_CCF], [DESCRIPCION], [ID_UNIDAD]) VALUES\n('-1', 'SinDato', 5),\n('CCF008-12-00001', 'Educaci\u00f3n formal', 1),\n('CCF008-13-00001', 'Educaci\u00f3n para el trabajo', 2),\n('CCF008-15-00001', 'Desarrollo empresarial', 3),\n('CCF008-26-00001', 'Protecci\u00f3n social', 4);\n\n-- Truncar y cargar datos en DIM_CATEGORIA\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CATEGORIA];\nINSERT INTO [Transversal].[DIM_CATEGORIA] ([COD_CATEGORIA], [DESCRIPCION]) VALUES\n('1', 'Categor\u00eda A'),\n('2', 'Categor\u00eda B'),\n('3', 'Categor\u00eda C'),\n('4', 'Categor\u00eda D'),\n('5', 'Empresas'),\n('6', 'Fondos de Ley'),\n('10', 'Convenios y Facultativos'),\n('12', 'Empresa no afiliada');\n\n-- Truncar y cargar datos en DIM_PERSONAL\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL];\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] ON;\nINSERT INTO [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL], \n    [COD_PERSONA_UNIDAD], \n    [ID_UNIDAD], \n    [SERVICIO], \n    [NOMBRE], \n    [TELEFONO], \n    [CELULAR], \n    [CORREO], \n    [DIRECCION], \n    [CIUDAD], \n    [TIPO_DOCUMENTO], \n    [DOCUMENTO], \n    [FECHA_NACIMIENTO], \n    [GENERO], \n    [HORAS_CONTRATADAS_MENSUAL], \n    [HORAS_CONTRATADAS_TOTALES], \n    [VALOR_TOTAL], \n    [TIPO_CONTRATACION], \n    [FECHA_INICIO_CONTRATACION], \n    [FECHA_FIN_CONTRATACION], \n    [CAUSA_TERMINACION_CONTRATO], \n    [PREGRADO], \n    [POSGRADO_ESPECIALIDAD], \n    [POSGRADO_MAESTRIA], \n    [POSGRADO_DOCTORADO], \n    [NIVEL_INGLES], \n    [AREA]\n) \nVALUES (\n    -1, -1, 5, NULL, NULL, NULL, NULL, NULL, NULL, NULL, \n    'CC', '-1', NULL, NULL, NULL, NULL, NULL, NULL, '1900-01-01', '1900-01-01', \n    NULL, NULL, NULL, NULL, NULL, NULL, NULL\n);\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] OFF;\n\n-- Truncar y cargar datos en DIM_TARIFAS_SERVICIOS\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_TARIFAS_SERVICIOS];\nSET IDENTITY_INSERT [Transversal].[DIM_TARIFAS_SERVICIOS] ON;\nINSERT INTO [Transversal].[DIM_TARIFAS_SERVICIOS] (\n    [ID_TARIFA], [COD_SERVICIO], [CON_OBJETO_TARIFA], [COS_UNITARIO_CONCEPTO],\n    [VAL_TARIFA], [COD_CATEGORIA], [ANIO_TARIFA], [COD_INFRAESTRUCTURA_CCF]\n)\nVALUES (\n    -1, 0, 'default object', 0, 0, '3', '2024', '-1'\n);\nSET IDENTITY_INSERT [Transversal].[DIM_TARIFAS_SERVICIOS] OFF;\n\n-- Truncar y cargar datos en DIM_PROGRAMA (Cedesarrollo)\nTRUNCATE TABLE [DWH_COMFENALCO].[Cedesarrollo].[DIM_PROGRAMA];\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PROGRAMA] ON;\nINSERT INTO [Cedesarrollo].[DIM_PROGRAMA] ([ID_PROGRAMA], [PROGRAMA])\nVALUES (-1, 'Sin Programa');\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PROGRAMA] OFF;\n\n-- Truncar y cargar datos en DIM_PERIODO_ACADEMICO (Cedesarrollo)\nTRUNCATE TABLE [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO];\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] ON;\nINSERT INTO [Cedesarrollo].[DIM_PERIODO_ACADEMICO] (\n    [ID_PERIODO], [ID_UNIDAD], [PERIODO_ACADEMICO], [FECHA_INICIO], [FECHA_FIN]\n)\nVALUES (\n    -1, 5, 'Sin datos', NULL, NULL\n);\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] OFF;\n\n-- Truncar e insertar registros en las tablas de Protecci\u00f3n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] ON;\nINSERT INTO [Proteccion].[DIM_PROGRAMA] (ID_PROGRAMA, PROGRAMA)\nVALUES (1, 'ADULTO_MAYOR'), (2, 'DISCAPACIDAD'), (3, 'JEC'), (4, 'AIPI');\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PROGRAMA] OFF;\n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC] ON;\nINSERT INTO [Proteccion].[DIM_PREGUNTAS_EE_JEC] (ID_PREGUNTA, PREGUNTA, ID_PROGRAMA)\nVALUES (-1, 'PREGUNTA_ABIERTA', 3);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_JEC] OFF;\n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] ON;\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_JEC] (ID_RESPUESTA, RESPUESTA, ID_PREGUNTA)\nVALUES (-1, 'RESPUESTA_PREGUNTA_ABIERTA', -1);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_JEC] OFF;\n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI] ON;\nINSERT INTO [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (ID_PREGUNTA, PREGUNTA, ID_PROGRAMA)\nVALUES (-1, 'PREGUNTA_ABIERTA', 4);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_PREGUNTAS_EE_AIPI] OFF;\n\nTRUNCATE TABLE [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI];\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] ON;\nINSERT INTO [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (ID_RESPUESTA, RESPUESTA, ID_PREGUNTA)\nVALUES (-1, 'RESPUESTA_PREGUNTA_ABIERTA', -1);\nSET IDENTITY_INSERT [DWH_COMFENALCO].[Proteccion].[DIM_RESPUESTAS_EE_AIPI] OFF;\n\n-- Verificar e insertar registro en DIM_POBLACION_MATRICULA (Colegio)\nIF NOT EXISTS (\n    SELECT 1\n    FROM [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA]\n    WHERE [ID_POBLACION_MATRICULA] = -1\n)\nBEGIN\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] ON;\n    INSERT INTO [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] (\n        [ID_POBLACION_MATRICULA], [PARTNER], [TIPO_DOCUMENTO], [DOCUMENTO],\n        [NOMBRE_COMPLETO], [GENERO], [DIRECCION], [TELEFONO], [CORREO], [FECHA_NACIMIENTO]\n    )\n    VALUES (\n        -1, 'N/A', 'N/A', 'N/A', 'Estudiantes sin cruce', 'N/A', 'N/A', 'N/A', 'N/A', NULL\n    );\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] OFF;\nEND;\nGO\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componende-agregar-registros-con-id-1-para-tablas-de-poblacion","title":"Componende <code>Agregar registros con ID -1 para tablas de poblaci\u00f3n</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion","title":"Descripci\u00f3n","text":"<p>Este proceso en la soluci\u00f3n SSIS se encarga de agregar registros con el ID <code>-1</code> en las tablas de poblaci\u00f3n. Este ID se utiliza para representar datos gen\u00e9ricos o no disponibles en las tablas de destino.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-proceso","title":"Detalles del Proceso","text":"<ol> <li>Truncar Tabla: Se ejecuta una instrucci\u00f3n SQL para truncar las tablas de poblaci\u00f3n, eliminando todos los registros existentes.</li> <li>Insertar Datos: Se ejecuta una instrucci\u00f3n SQL para insertar nuevos registros en las tablas de poblaci\u00f3n con el ID <code>-1</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_4","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Agregar registros con ID -1 para tablas de poblaci\u00f3n\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant SQL as Script SQL\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;SQL: Ejecutar truncado de tablas de poblaci\u00f3n\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n    SSIS-&gt;&gt;SQL: Insertar registros con ID -1 en tablas de poblaci\u00f3n\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_3","title":"C\u00f3digo SQL","text":"<pre><code>-- Truncar tablas de poblaci\u00f3n\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_POBLACION];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_ESTABLECIMIENTO_EDUCATIVO];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_PROGRAMA];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CAMPOS_CARACT];\n\n-- Insertar registros con ID -1\nINSERT INTO [Transversal].[DIM_POBLACION] (ID_POBLACION, TIPO_DOCUMENTO, DOCUMENTO)\nVALUES (-1, 'N/A', 'N/A');\n\nINSERT INTO [Transversal].[DIM_ESTABLECIMIENTO_EDUCATIVO] (ID_ESTABLECIMIENTO_EDUCATIVO, NOMBRE_ESTABLECIMIENTO)\nVALUES (-1, 'N/A');\n\nINSERT INTO [Transversal].[DIM_PROGRAMA] (ID_PROGRAMA, PROGRAMA)\nVALUES (-1, 'N/A');\n\nINSERT INTO [Transversal].[DIM_CAMPOS_CARACT] (ID_PREGUNTA, PREGUNTA)\nVALUES (-1, 'N/A');\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-vaciar-tabla-temporal-de-poblacion-educacion","title":"Componente <code>Vaciar tabla temporal de Poblacion Educacion</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Vaciar tabla temporal de Poblacion Educacion</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de vaciar la tabla temporal <code>TMP_POBLACION_EDUCACION</code> en el Data Warehouse. Esta tarea realiza una operaci\u00f3n de truncado en la tabla correspondiente.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea_1","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{C1C8514E-6B9D-448B-B2C4-085047066756}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Descripci\u00f3n: Tarea Ejecutar SQL</li> <li>Conexi\u00f3n: <code>{878C9AA8-681C-4799-9C30-34C49CD01857}</code></li> <li>Declaraci\u00f3n SQL:<ul> <li>Truncar la tabla <code>TMP_POBLACION_EDUCACION</code> en el esquema <code>Transversal</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_5","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Vaciar tabla temporal de Poblacion Educacion\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant SQL as Script SQL\n  participant DWH as Data Warehouse\n\n  SSIS-&gt;&gt;SQL: Ejecutar truncado de tabla TMP_POBLACION_EDUCACION\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_4","title":"C\u00f3digo SQL","text":"<pre><code>TRUNCATE TABLE [Transversal].[TMP_POBLACION_EDUCACION];\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-poblacion-prs","title":"Componente <code>Procesar Poblacion PRS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Procesar Poblacion PRS</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para procesar la poblaci\u00f3n PRS. Esta tarea utiliza el ejecutable de Python y un script espec\u00edfico para realizar el procesamiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea_2","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{7f11d36d-f826-44f0-8b89-e04825763509}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteProcess</code></li> <li>Descripci\u00f3n: Tarea Ejecutar proceso</li> <li>Conexi\u00f3n: No aplica (ejecuci\u00f3n de proceso)</li> <li>Propiedades del Componente:<ul> <li>Executable: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_3","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>03.PoblacionProteccion.py</code></li> <li>WorkingDirectory: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_6","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Procesar Poblacion PRS\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant Python as Script Python\n  participant FileSystem as Sistema de Archivos\n\n  SSIS-&gt;&gt;Python: Ejecutar script 03.PoblacionProteccion.py\n  Python--&gt;&gt;FileSystem: Leer y procesar datos\n  FileSystem--&gt;&gt;Python: Datos procesados\n  Python--&gt;&gt;SSIS: Confirmaci\u00f3n de ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-identificar-poblacion-educacion","title":"Componente <code>Identificar Poblacion Educaci\u00f3n</code>","text":"<p>El paquete SSIS \"Identificar Poblaci\u00f3n Educaci\u00f3n\" est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con la poblaci\u00f3n educativa. Este proceso ETL consolida informaci\u00f3n proveniente de diversas fuentes, como bases de datos y archivos Excel, para generar un conjunto de datos limpio y estandarizado en el \u00e1rea de staging. La soluci\u00f3n permite identificar y unir registros de estudiantes utilizando transformaciones, conversiones y b\u00fasquedas, facilitando la integraci\u00f3n y an\u00e1lisis de la informaci\u00f3n en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete_3","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es:</p> <ul> <li>Extraer y Unificar Datos: Recopilar informaci\u00f3n sobre la poblaci\u00f3n educativa desde distintas fuentes (por ejemplo, registros de inscripciones en el colegio y datos adicionales en archivos Excel).</li> <li>Transformar y Estandarizar Informaci\u00f3n: Aplicar conversiones de datos y crear columnas derivadas para asegurar la consistencia y calidad de la informaci\u00f3n.</li> <li>Realizar B\u00fasquedas y Combinar Datos: Utilizar transformaciones de Lookup y Merge para integrar y asociar datos provenientes de diferentes or\u00edgenes.</li> <li>Cargar la Informaci\u00f3n en el \u00c1rea de Staging: Depositar los datos consolidados en la tabla temporal <code>TMP_POBLACION_EDUCACION</code> para su uso posterior en el Data Warehouse.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-paquete_3","title":"Descripci\u00f3n del Paquete","text":"<p>El proceso ETL de \"Identificar Poblaci\u00f3n Educaci\u00f3n\" se compone de varios pasos:</p> <ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Se obtienen datos de dos fuentes principales:</li> <li>Origen de ADO NET: Extrae datos de la tabla <code>DIM_POBLACION_MATRICULA</code> del colegio, obteniendo columnas como <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> <li>Poblaci\u00f3n PRS: Extrae informaci\u00f3n desde un archivo Excel para complementar los datos de poblaci\u00f3n.</li> </ul> </li> <li> <p>Transformaci\u00f3n y Conversi\u00f3n:</p> <ul> <li>Data Conversion: Se aplican dos transformaciones de datos para convertir los tipos de datos de las columnas de entrada (por ejemplo, <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>) y generar versiones copiadas con longitudes y formatos requeridos.</li> <li>Derived Column: Se utiliza para crear una nueva columna (como la conversi\u00f3n o ajuste de valores nulos) mediante expresiones que aplican funciones como REPLACENULL.</li> </ul> </li> <li> <p>Uni\u00f3n y Combinaci\u00f3n de Datos:</p> <ul> <li>Lookup: Se utiliza para buscar y unir informaci\u00f3n adicional de la tabla de referencia <code>DIM_TIPO_DOCUMENTO</code>, asignando identificadores como <code>ID_TIPODOC_AFILIADO</code> y las siglas correspondientes.</li> <li>Merge: Se combinan los datos provenientes de la fuente de ADO NET y de la fuente Excel (Poblaci\u00f3n PRS) para unificar la informaci\u00f3n en un flujo ordenado.</li> <li>Sort: Se aplican transformaciones de ordenaci\u00f3n para asegurar que los flujos de datos est\u00e9n correctamente ordenados antes de ser combinados.</li> </ul> </li> <li> <p>Carga en el \u00c1rea de Staging:</p> <ul> <li>Los datos resultantes se cargan en la tabla temporal <code>TMP_POBLACION_EDUCACION</code> del esquema Transversal, utilizando un destino ADO NET.</li> <li>Adem\u00e1s, se env\u00edan registros err\u00f3neos a un archivo plano para su revisi\u00f3n y  depuraci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave-del-proceso_1","title":"Componentes Clave del Proceso","text":"<ol> <li> <p>Data Conversion y Data Conversion 1:    Se utilizan para convertir y formatear las columnas <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code> de las fuentes de datos. La primera transformaci\u00f3n opera sobre datos provenientes de un flujo combinado (Merge Output), y la segunda se encarga de convertir datos extra\u00eddos directamente del origen ADO NET.</p> </li> <li> <p>Derived Column:    Crea nuevas columnas a partir de las existentes, aplicando funciones que aseguran que los valores nulos se reemplacen por valores por defecto (por ejemplo, utilizando la funci\u00f3n REPLACENULL).</p> </li> <li> <p>Lookup:    Realiza una b\u00fasqueda en la tabla de referencia <code>DIM_TIPO_DOCUMENTO</code> para asociar a cada registro el <code>ID_TIPODOC_AFILIADO</code> correspondiente, bas\u00e1ndose en el valor convertido de <code>TIPO_DOCUMENTO</code>.</p> </li> <li> <p>Merge y Sort:    Se utilizan transformaciones de ordenaci\u00f3n y fusi\u00f3n para combinar los datos de las diferentes fuentes (origen ADO NET y Excel) en un flujo \u00fanico, asegurando la integridad del ordenamiento para la posterior uni\u00f3n.</p> </li> <li> <p>Origen de ADO NET (Estudiantes Colegio):    Extrae los datos clave de la poblaci\u00f3n educativa directamente de la base de datos del colegio, sirviendo de referencia principal para la identificaci\u00f3n de registros.</p> </li> <li> <p>Flat File Destination:    Permite la escritura de los registros que generen errores durante las transformaciones, facilitando la auditor\u00eda y depuraci\u00f3n de la informaci\u00f3n.</p> </li> <li> <p>Poblaci\u00f3n Educaci\u00f3n (Stage Area):    Carga el flujo de datos resultante en la tabla temporal <code>TMP_POBLACION_EDUCACION</code>, que servir\u00e1 de base para los procesos posteriores de integraci\u00f3n en el Data Warehouse.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas_3","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos_1","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant ADO as Origen de ADO NET\n    participant Excel as Poblaci\u00f3n PRS\n    participant DC as Data Conversion\n    participant DC1 as Data Conversion 1\n    participant DerCol as Derived Column\n    participant Lookup as Lookup\n    participant Sort as Sort\n    participant Sort1 as Sort 1\n    participant Sort2 as Sort 2\n    participant Merge as Merge\n    participant Merge1 as Merge 1\n    participant Stage as Poblacion Educacion (Stage Area)\n    participant Flat as Flat File Destination\n\n    ADO-&gt;&gt;DC1: Extraer datos de DIM_POBLACION_MATRICULA\n    Excel-&gt;&gt;Sort2: Extraer datos desde Excel\n    DC-&gt;&gt;Lookup: Convertir y formatear columnas (TIPO_DOCUMENTO, DOCUMENTO)\n    DC1-&gt;&gt;Sort1: Convertir datos del origen ADO NET\n    Sort1-&gt;&gt;Merge: Ordenar datos del origen ADO NET\n    Sort2-&gt;&gt;Merge1: Ordenar datos de Excel\n    Merge-&gt;&gt;Merge1: Fusionar flujos ordenados\n    Merge1-&gt;&gt;DerCol: Aplicar columna derivada para reemplazar nulos\n    DerCol-&gt;&gt;Stage: Cargar datos en TMP_POBLACION_EDUCACION\n    DC-&gt;&gt;Flat: Enviar filas con error a archivo plano</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-precedencia_1","title":"Diagrama de Precedencia","text":"<pre><code>sequenceDiagram\n    participant ADO as Estudiantes Colegio (Origen ADO NET)\n    participant Excel as Poblaci\u00f3n PRS (Excel)\n    participant Conv as Data Conversion\n    participant Conv1 as Data Conversion 1\n    participant Look as Lookup\n    participant M1 as Merge 1\n    participant Flat as Flat File Destination\n    participant Stage as Poblacion Educacion (Stage Area)\n\n    ADO-&gt;&gt;Conv1: Extraer y convertir datos del origen ADO NET\n    Excel-&gt;&gt;Conv: Extraer y convertir datos de Excel\n    Conv-&gt;&gt;Look: Enviar datos convertidos al Lookup\n    Look-&gt;&gt;M1: Combinar datos mediante Merge\n    M1-&gt;&gt;Stage: Cargar datos consolidados en el \u00e1rea de staging\n    Conv-&gt;&gt;Flat: Redirigir registros con error a archivo plano</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_beneficiarios","title":"Componente <code>Procesar DIM_BENEFICIARIOS</code>","text":"<p>El paquete SSIS \"Procesar DIM_BENEFICIARIOS\" se encarga de la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con los beneficiarios en el Data Warehouse. Este proceso se centra en consolidar y actualizar la dimensi\u00f3n de beneficiarios en el esquema Transversal, asegurando que la informaci\u00f3n sea precisa y est\u00e9 estandarizada para su an\u00e1lisis y toma de decisiones.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete_4","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del proceso es:</p> <ul> <li>Extraer y Unificar Datos: Recopilar informaci\u00f3n sobre beneficiarios desde diversas fuentes, incluyendo datos provenientes del \u00e1rea de staging donde se almacenan los registros temporales.</li> <li>Transformar y Estandarizar la Informaci\u00f3n: Aplicar conversiones de datos y transformar los valores para garantizar la consistencia de la dimensi\u00f3n, incluyendo el formateo de tipos de datos y la integraci\u00f3n de identificadores clave.</li> <li>Cargar la Informaci\u00f3n en la Dimensi\u00f3n: Insertar o actualizar los registros en la tabla <code>DIM_BENEFICIARIOS</code> dentro del esquema Transversal, asegurando la integridad y calidad de los datos.</li> <li>Manejar Errores: Redirigir cualquier fila que genere error durante la transformaci\u00f3n a un destino de error para su posterior an\u00e1lisis y depuraci\u00f3n.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso_2","title":"Descripci\u00f3n del Proceso","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Origen de Datos Temporal: Se extraen datos desde la tabla temporal en el \u00e1rea de staging (<code>TMP POBLACION EDUCACION</code>), la cual contiene registros de beneficiarios identificados a partir de procesos previos.</li> <li>Origen de Datos Adicional: Se utiliza el componente \"Estudiantes Colegio\" para obtener informaci\u00f3n complementaria desde la base de datos del colegio, la cual incluye columnas clave como <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Conversi\u00f3n de Datos:  Se aplican dos transformaciones de Data Conversion para convertir los valores de columnas cr\u00edticas (por ejemplo, <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>) al formato y longitud requeridos.  </li> <li>La primera transformaci\u00f3n crea copias de las columnas con la longitud adecuada para facilitar las operaciones de Lookup y Merge.</li> <li> <p>La segunda transformaci\u00f3n, aplicada directamente sobre el flujo de datos extra\u00eddo, garantiza que los datos sean consistentes.</p> </li> <li> <p>Lookup:  Se utiliza una transformaci\u00f3n Lookup para unir los datos del flujo con la tabla de referencia <code>DIM_TIPO_DOCUMENTO</code>. Esta uni\u00f3n permite asignar a cada registro el <code>ID_TIPODOC_AFILIADO</code> y las siglas correspondientes a partir de la columna <code>COD_TIPO_DOCUMENTO</code>, facilitando la identificaci\u00f3n y categorizaci\u00f3n de los beneficiarios.</p> </li> <li> <p>Fusi\u00f3n (Merge):  Las transformaciones Sort y Merge se utilizan para combinar y ordenar los registros provenientes de las diversas fuentes. Este paso asegura que el flujo final de datos est\u00e9 correctamente ordenado y listo para la carga.</p> </li> </ul> </li> <li> <p>Carga de Datos en la Dimensi\u00f3n:</p> <ul> <li> <p>Destino ADO.NET:  Los datos transformados se cargan en la tabla <code>DIM_BENEFICIARIOS</code> ubicada en el esquema Transversal del Data Warehouse. La configuraci\u00f3n del destino ADO.NET permite la inserci\u00f3n masiva, optimizando el rendimiento del proceso.</p> </li> <li> <p>Manejo de Errores:  Se definen salidas de error que capturan cualquier fila que no cumpla con las conversiones o validaciones establecidas, permitiendo que los errores sean redirigidos a un destino espec\u00edfico para su an\u00e1lisis.</p> </li> </ul> </li> <li> <p>Integraci\u00f3n Final:</p> <ul> <li>Los registros actualizados y/o nuevos se integran en la dimensi\u00f3n <code>DIM_BENEFICIARIOS</code>, lo cual facilita la realizaci\u00f3n de an\u00e1lisis sobre la poblaci\u00f3n de beneficiarios y su impacto en las operaciones de la organizaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave-del-proceso_2","title":"Componentes Clave del Proceso","text":"<ol> <li> <p>Destino de ADO NET:    Utiliza un componente ADO.NET para cargar los datos finales en la tabla <code>\"Transversal\".\"DIM_BENEFICIARIOS\"</code>, configurado con propiedades que optimizan la inserci\u00f3n masiva (BatchSize = 0, CommandTimeout = 30, UseBulkInsertWhenPossible = true).</p> </li> <li> <p>Transformaciones de Data Conversion:    Dos transformaciones de Data Conversion se aplican para asegurar que las columnas <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code> tengan el formato correcto para su posterior procesamiento. La primera transformaci\u00f3n trabaja sobre datos combinados, mientras que la segunda opera sobre datos provenientes directamente del origen.</p> </li> <li> <p>Transformaci\u00f3n Lookup:    Realiza la uni\u00f3n entre el flujo de datos y la tabla de referencia <code>DIM_TIPO_DOCUMENTO</code>, permitiendo obtener el <code>ID_TIPODOC_AFILIADO</code> y las siglas de tipo de documento para cada registro.</p> </li> <li> <p>Componentes de Sort y Merge:    Se utilizan para ordenar y combinar registros provenientes de diferentes or\u00edgenes, asegurando que la fusi\u00f3n de datos se realice de forma coherente y ordenada.</p> </li> <li> <p>Origen de ADO NET (TMP POBLACION EDUCACION):    Extrae los datos de la tabla temporal donde se consolidaron previamente los registros de beneficiarios, sirviendo de base para identificar los registros nuevos o faltantes en la dimensi\u00f3n.</p> </li> <li> <p>Destino de Error:    Los errores detectados durante la conversi\u00f3n y transformaci\u00f3n se redirigen a una salida de error, permitiendo su revisi\u00f3n y correcci\u00f3n sin interrumpir el proceso principal.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas_4","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos_2","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant TMP as TMP POBLACION EDUCACION (Origen)\n    participant ADO as Estudiantes Colegio (Origen ADO NET)\n    participant DC as Data Conversion\n    participant DC1 as Data Conversion 1\n    participant Lookup as Lookup\n    participant Sort as Sort\n    participant Sort1 as Sort 1\n    participant Sort2 as Sort 2\n    participant Merge as Merge\n    participant Stage as Destino de ADO NET (DIM_BENEFICIARIOS)\n    participant Error as Salida de error de destino de ADO NET\n\n    TMP-&gt;&gt;DC1: Extrae datos de TMP POBLACION EDUCACION\n    ADO-&gt;&gt;DC: Extrae datos de Estudiantes Colegio\n    DC-&gt;&gt;Lookup: Convierte y formatea columnas (TIPO_DOCUMENTO, DOCUMENTO)\n    DC1-&gt;&gt;Sort1: Convierte datos del origen TMP\n    Sort1-&gt;&gt;Merge: Ordena datos del origen TMP\n    Sort2-&gt;&gt;Merge: Ordena datos de Excel (Poblaci\u00f3n PRS)\n    Merge-&gt;&gt;Lookup: Combina flujos de datos para Lookup\n    Lookup-&gt;&gt;Stage: Carga datos en DIM_BENEFICIARIOS\n    DC-&gt;&gt;Error: Redirige filas con errores</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-precedencia_2","title":"Diagrama de Precedencia","text":"<pre><code>sequenceDiagram\n    participant Origen as TMP POBLACION EDUCACION\n    participant ADO as Estudiantes Colegio\n    participant Conv as Data Conversion\n    participant Look as Lookup\n    participant Merge as Merge\n    participant Destino as Destino de ADO NET (DIM_BENEFICIARIOS)\n\n    Origen-&gt;&gt;Conv: Extraer y convertir datos desde TMP\n    ADO-&gt;&gt;Conv: Extraer datos complementarios desde ADO NET\n    Conv-&gt;&gt;Look: Enviar datos convertidos al Lookup\n    Look-&gt;&gt;Merge: Unir datos con referencia de DIM_TIPO_DOCUMENTO\n    Merge-&gt;&gt;Destino: Cargar registros consolidados en DIM_BENEFICIARIOS</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_beneficiarios-por-bp","title":"Componente <code>Procesar DIM_BENEFICIARIOS por BP</code>","text":"<p>Este flujo de datos de SSIS se encarga de extraer y procesar informaci\u00f3n de la poblaci\u00f3n de matr\u00edcula del Colegio para identificar beneficiarios asociados a un determinado \u201cBP\u201d (Business Partner). El objetivo es detectar registros nuevos que no se encuentren en la dimensi\u00f3n de beneficiarios transversal y, a partir de esa comparaci\u00f3n, enriquecer la informaci\u00f3n utilizando datos de las \u00e1reas de Aportes y Afiliados.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-flujo","title":"Prop\u00f3sito del Flujo","text":"<ul> <li> <p>Identificar Beneficiarios Nuevos:   Se extraen los registros de la poblaci\u00f3n de matr\u00edcula del Colegio y se comparan con la dimensi\u00f3n de beneficiarios existente. Se identifican aquellos registros que a\u00fan no han sido cargados en la dimensi\u00f3n.</p> </li> <li> <p>Integrar Informaci\u00f3n de Aportes:   Se realiza una uni\u00f3n con los datos provenientes de la dimensi\u00f3n de beneficiarios del \u00e1rea de Aportes (DIM_BENEFICIARIOS de Aportes) y la informaci\u00f3n de afiliados para complementar la informaci\u00f3n del beneficiario.</p> </li> <li> <p>Cargar la Dimensi\u00f3n Transversal:   Finalmente, se cargan los registros resultantes en la dimensi\u00f3n de beneficiarios del esquema Transversal, asegurando la actualizaci\u00f3n y consistencia de la informaci\u00f3n.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso_3","title":"Descripci\u00f3n del Proceso","text":"<ol> <li>Extracci\u00f3n de Datos \u2013 Origen DIM POBLACION MATRICULA Colegio:    Se utiliza un componente de origen ADO.NET que ejecuta una consulta SQL con m\u00faltiples CTEs (Common Table Expressions).  <ul> <li>CTE PobMatricula: Extrae la columna <code>PARTNER</code> desde la tabla <code>[DIM_POBLACION_MATRICULA]</code> del Colegio.  </li> <li>CTE Beneficiarios: Extrae todos los registros existentes en la dimensi\u00f3n de beneficiarios transversal.  </li> <li>CTE BenNuevos: Selecciona los registros de la poblaci\u00f3n de matr\u00edcula que no tienen correspondencia en la dimensi\u00f3n de beneficiarios.  </li> <li>CTEs BENEFICIARIOS2 y AFILIADOS: Extraen informaci\u00f3n desde las dimensiones de Aportes y Afiliados, respectivamente, considerando \u00fanicamente registros activos (con <code>ESTADOREGISTRO = 'CURRENT'</code> y condiciones espec\u00edficas en <code>TIPO_APORTANTE</code> y <code>EMPRESA_PRINCIPAL</code>).  </li> <li>CTE LastLookUp: Realiza la uni\u00f3n entre la informaci\u00f3n de Aportes y Afiliados para obtener los registros completos de beneficiarios.</li> </ul> </li> </ol> <p>La consulta final realiza una uni\u00f3n (LEFT JOIN) entre los registros identificados como nuevos y la informaci\u00f3n consolidada en LastLookUp, filtrando aquellos que tengan un <code>ID_BENEFICIARIO</code> v\u00e1lido.</p> <ol> <li> <p>Salida del Origen:    Los datos extra\u00eddos contienen columnas clave como:</p> <ul> <li><code>ID_BENEFICIARIO</code></li> <li><code>PARTNER</code></li> <li><code>TITULAR</code></li> <li><code>ID_TIPO_DOCUMENTO</code></li> <li><code>COD_TIPO_DOCUMENTO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NUMERO_DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>PRIMER_APELLIDO</code></li> <li><code>SEGUNDO_APELLIDO</code></li> <li><code>PRIMER_NOMBRE</code></li> <li><code>SEGUNDO_NOMBRE</code></li> <li><code>ID_PARENTESCO</code></li> <li><code>PARENTESCO</code></li> <li><code>FECHA_AFILIACION</code></li> <li><code>FECHA_RETIRO</code></li> <li><code>ID_GENERO</code></li> <li><code>GENERO</code></li> <li><code>ID_NIVEL_EDUCATIVO</code></li> <li><code>NIVEL_EDUCATIVO</code></li> <li><code>ID_ESTADO_CIVIL</code></li> <li><code>ESTADO_CIVIL</code></li> <li><code>DISCAPACIDAD</code></li> <li><code>FECHA_NACIMIENTO</code></li> <li><code>DIRECCION</code></li> <li><code>TELEFONO</code></li> <li><code>BARRIO</code></li> <li><code>ESTRATO</code></li> <li><code>ID_CIUDAD</code></li> <li><code>ID_AREA_GEOGRAFICA</code></li> <li><code>AREA_GEOGRAFICA</code></li> <li><code>FEC_CREACION</code></li> <li><code>USUARIO_PROCESO</code></li> <li><code>FEC_ACTUALIZACION</code></li> </ul> </li> <li> <p>Carga en la Dimensi\u00f3n \u2013 DIM_BENEFICIARIOS Transversal:    Los datos procesados se env\u00edan al destino ADO.NET configurado para insertar (o actualizar) los registros en la tabla <code>\"Transversal\".\"DIM_BENEFICIARIOS\"</code>. Se utilizan configuraciones que optimizan la inserci\u00f3n masiva (BatchSize = 0, CommandTimeout = 30, UseBulkInsertWhenPossible = true).</p> </li> <li> <p>Manejo de Errores:    Cualquier fila que genere error en el proceso de carga se redirige a una salida de error para su posterior an\u00e1lisis, asegurando que el flujo principal no se detenga por datos inv\u00e1lidos.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos_3","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant Origen as DIM POBLACION MATRICULA Colegio (Origen ADO.NET)\n    participant Transform as Proceso SQL con CTEs (BenNuevos, LastLookUp)\n    participant Salida as Salida de Origen de ADO.NET\n    participant Destino as DIM_BENEFICIARIOS Transversal (Destino ADO.NET)\n    participant Error as Salida de Error de Origen de ADO.NET\n\n    Origen-&gt;&gt;Transform: Ejecuta consulta SQL con CTEs\n    Transform-&gt;&gt;Salida: Devuelve registros nuevos identificados\n    Salida-&gt;&gt;Destino: Carga registros en DIM_BENEFICIARIOS Transversal\n    Salida-&gt;&gt;Error: Redirige filas con errores</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_afiliados","title":"Componente <code>Procesar_DIM_AFILIADOS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_AFILIADOS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_AFILIADOS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_6","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_6","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_AFILIADOS</code></li> <li>DTSID: <code>{UNIQUE-DTSID}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_3","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Afiliados</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_AFILIADOS\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#columnas-de-entrada","title":"Columnas de Entrada","text":"<ul> <li><code>ID_AFILIADO</code></li> <li><code>NOMBRE</code></li> <li><code>APELLIDO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NUMERO_DOCUMENTO</code></li> <li><code>FECHA_NACIMIENTO</code></li> <li><code>GENERO</code></li> <li><code>ESTADO_CIVIL</code></li> <li><code>DIRECCION</code></li> <li><code>CIUDAD</code></li> <li><code>TELEFONO</code></li> <li><code>EMAIL</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_7","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_AFILIADOS\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Convertir datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_AFILIADO_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_AFILIADOS`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Modificar`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_AFILIADOS`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Sheet1$</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>CommandTimeout</code>: <code>0</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Verifica y convierte los tipos de datos de las columnas de entrada.</li> </ul> </li> <li> <p>Columna Derivada (<code>Crear ID_AFILIADO_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_AFILIADO_AUXILIAR</code> concatenando varias columnas de entrada.</li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_AFILIADOS</code> para unir columnas adicionales al flujo de datos.</li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> </ul> </li> <li> <p>Destino ADO.NET (<code>DIM_AFILIADOS_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_AFILIADOS</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_AFILIADOS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_afiliados","title":"Componente <code>Procesar DIM_AFILIADOS</code>","text":"<p>Corresponde a un flujo de datos dentro del paquete SSIS dise\u00f1ado para procesar la dimensi\u00f3n de afiliados. El flujo extrae informaci\u00f3n relevante desde una fuente de datos en la zona de staging (TMP POBLACION EDUCACION) y la transforma para finalmente cargarla en la tabla destino <code>\"Transversal\".\"DIM_AFILIADOS\"</code> en el Data Warehouse de destino.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-principales","title":"Componentes Principales","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-componente-origen-tmp-poblacion-educacion","title":"1. Componente Origen: TMP POBLACION EDUCACION","text":"<ul> <li>Funci\u00f3n:   Utiliza un adaptador DataReader para conectarse a la base de datos de staging (STAGE_AREA) y ejecutar una consulta SQL compleja que utiliza m\u00faltiples CTEs (Common Table Expressions).  </li> <li> <p>Proceso de la Consulta: </p> <ul> <li>PobEducacion: Extrae datos de la tabla temporal <code>[TMP_POBLACION_EDUCACION]</code>, seleccionando columnas como <code>TIPO_DOCUMENTO_SIGLAS</code>, <code>DOCUMENTO</code> y <code>ID_TIPO_DOCUMENTO</code>.  </li> <li>AFILIADOS: Obtiene la informaci\u00f3n actual de afiliados desde la dimensi\u00f3n <code>[DIM_AFILIADOS]</code> del esquema Transversal, filtrando por registros con <code>ESTADOREGISTRO = 'CURRENT'</code> y que tengan <code>EMPRESA_PRINCIPAL = 'X'</code>.  </li> <li>afiliadoNuevos: Identifica registros nuevos comparando la informaci\u00f3n extra\u00edda de la zona de staging con la existente en <code>[DIM_AFILIADOS]</code>, utilizando una operaci\u00f3n LEFT JOIN.  </li> <li>EMPRESASCaja y AFILIADOSCaja: Se extrae informaci\u00f3n desde las dimensiones de Aportes para relacionar a los afiliados con las empresas correspondientes.  </li> <li>AFILIADOS_CON_EMPRESA y AfiliadosCajaIdEmpresa: Se realiza una uni\u00f3n y se selecciona la \u00faltima coincidencia (utilizando ROW_NUMBER) para garantizar que cada afiliado quede asociado a un \u00fanico <code>ID_EMPRESA</code>.</li> <li>Consulta Final:   Se efect\u00faa un LEFT JOIN entre los registros nuevos (<code>afiliadoNuevos</code>) y la informaci\u00f3n consolidada de afiliados con empresa (<code>AfiliadosCajaIdEmpresa</code>), filtrando aquellos registros que tienen un <code>ID_AFILIADO</code> v\u00e1lido.</li> </ul> </li> <li> <p>Conexi\u00f3n:   Se utiliza un administrador de conexiones externo apuntando al ambiente <code>STAGE_AREA</code>.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-componente-destino-destino-de-ado-net","title":"2. Componente Destino: Destino de ADO NET","text":"<ul> <li>Funci\u00f3n:   Este componente carga los datos procesados en la tabla destino <code>\"Transversal\".\"DIM_AFILIADOS\"</code> del Data Warehouse.</li> <li>Configuraci\u00f3n Clave: <ul> <li>TableOrViewName: <code>\"Transversal\".\"DIM_AFILIADOS\"</code> </li> <li>BatchSize: 0 (utiliza el tama\u00f1o del b\u00fafer interno de SSIS)  </li> <li>CommandTimeout: 30 segundos  </li> <li>UseBulkInsertWhenPossible: true (mejora el rendimiento al usar inserci\u00f3n masiva)</li> </ul> </li> <li>Conexi\u00f3n:   Se conecta a trav\u00e9s de un administrador de conexiones configurado con <code>DWH_COMFENALCO_Destino</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-flujo-de-conexion","title":"3. Flujo de Conexi\u00f3n","text":"<p>El flujo conecta el origen (TMP POBLACION EDUCACION) con el destino (DIM_AFILIADOS Transversal) mediante una ruta de datos:</p> <pre><code>sequenceDiagram\n    participant Origen as TMP POBLACION EDUCACION (Origen ADO.NET)\n    participant Destino as DIM_AFILIADOS Transversal (Destino ADO.NET)\n\n    Origen -&gt;&gt; Destino: Transfiere datos procesados para cargar en la dimensi\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proceso-general","title":"Proceso General","text":"<ol> <li> <p>Extracci\u00f3n de Datos:    La consulta SQL del componente origen ejecuta m\u00faltiples CTEs para:</p> <ul> <li>Extraer datos de la zona de staging.</li> <li>Comparar y detectar registros nuevos de afiliados.</li> <li>Relacionar la informaci\u00f3n con datos de empresas y afiliados desde \u00e1reas de aportes.</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:     Los registros nuevos son identificados a partir de la ausencia de coincidencias en la dimensi\u00f3n actual. Se aplican transformaciones y validaciones impl\u00edcitas para asegurar la calidad de los datos.</p> </li> <li> <p>Carga de Datos:     Los datos resultantes se env\u00edan al componente destino, que inserta la informaci\u00f3n en la tabla <code>\"Transversal\".\"DIM_AFILIADOS\"</code>, utilizando configuraciones optimizadas para cargas masivas.</p> </li> <li> <p>Manejo de Errores:     Cualquier fila que genere error en la extracci\u00f3n o transformaci\u00f3n se redirige a una salida de error, permitiendo el an\u00e1lisis y correcci\u00f3n sin detener el flujo principal.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#procesar-dim-afiliados-desde-beneficiarios","title":"Procesar <code>DIM AFILIADOS desde BENEFICIARIOS</code>","text":"<p>Este nodo un Data Flow Task dentro del paquete SSIS, cuyo objetivo es procesar y actualizar la dimensi\u00f3n de afiliados a partir de datos provenientes de beneficiarios. Los datos se extraen a trav\u00e9s de una consulta SQL compleja que utiliza varias CTEs para identificar los registros de beneficiarios que a\u00fan no se encuentran en la dimensi\u00f3n de afiliados y, posteriormente, se cargan en la tabla destino <code>\"Transversal\".\"DIM_AFILIADOS\"</code>.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave","title":"Componentes Clave","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-origen-transversal_dim_beneficiarios","title":"1. Origen: TRANSVERSAL_DIM_BENEFICIARIOS","text":"<ul> <li>Funci\u00f3n:   Este componente extrae datos usando un adaptador ADO.NET (DataReaderSource) que ejecuta una consulta SQL.  </li> <li> <p>Consulta SQL:     La consulta utiliza varias CTEs para:</p> <ul> <li>Seleccionar los <code>ID_AFILIADO</code> \u00fanicos de la tabla <code>[DIM_BENEFICIARIOS]</code> en el esquema Transversal.</li> <li>Compararlos con los <code>ID_AFILIADO</code> ya presentes en la tabla <code>[DIM_AFILIADOS]</code> del mismo esquema.</li> <li>Identificar los registros que est\u00e1n en beneficiarios pero faltan en la dimensi\u00f3n de afiliados.</li> <li>Adem\u00e1s, se unen con las dimensiones de empresas y se filtran por registros actuales (por ejemplo, donde <code>[ESTADOREGISTRO] = 'CURRENT'</code>) y por la condici\u00f3n de empresa principal.</li> <li>Se asigna un n\u00famero de fila (rn) para seleccionar el registro final por cada afiliado.</li> </ul> </li> <li> <p>Conexi\u00f3n:   Utiliza el administrador de conexiones configurado con <code>DWH_COMFENALCO_Destino</code>.</p> </li> <li> <p>Salida:   La salida (Salida de origen de ADO NET) expone columnas relevantes, incluyendo:</p> <ul> <li><code>ID_AFILIADO</code></li> <li><code>PARTNER</code></li> <li><code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code></li> <li><code>NUMERO_DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code></li> <li>Y otros campos relacionados con la afiliaci\u00f3n, caracter\u00edsticas demogr\u00e1ficas, estado civil, ocupaci\u00f3n, entre otros.</li> </ul> </li> </ul> <p>Adem\u00e1s, se genera la columna <code>rn</code> para identificar el registro principal en caso de m\u00faltiples coincidencias.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-destino-destino-de-ado-net","title":"2. Destino: Destino de ADO NET","text":"<ul> <li>Funci\u00f3n:   Este componente se encarga de cargar los datos procesados en la tabla destino <code>\"Transversal\".\"DIM_AFILIADOS\"</code>.</li> <li>Configuraci\u00f3n Importante: <ul> <li>TableOrViewName: <code>\"Transversal\".\"DIM_AFILIADOS\"</code></li> <li>BatchSize: 0 (lo que indica que se usar\u00e1 el tama\u00f1o del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true (habilita la inserci\u00f3n masiva para mejorar el rendimiento)</li> </ul> </li> <li>Conexi\u00f3n:   Se conecta a trav\u00e9s del administrador de conexiones <code>DWH_COMFENALCO_Destino</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-flujo-de-datos","title":"3. Flujo de Datos","text":"<p>El flujo de datos conecta la salida del componente de origen (TRANSVERSAL_DIM_BENEFICIARIOS) con la entrada del componente destino (Destino de ADO NET). Esto garantiza que los registros identificados se transfieran y se inserten en la tabla de afiliados.</p> <pre><code>sequenceDiagram\n    participant Origen as TRANSVERSAL_DIM_BENEFICIARIOS (Salida de origen de ADO NET)\n    participant Destino as Destino de ADO NET (Entrada de destino de ADO NET)\n\n    Origen -&gt;&gt; Destino: Transfiere los datos para actualizar DIM_AFILIADOS</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proceso-general_1","title":"Proceso General","text":"<ol> <li> <p>Extracci\u00f3n: </p> <ul> <li>La consulta SQL del componente origen extrae los <code>ID_AFILIADO</code> de la dimensi\u00f3n de beneficiarios que no se encuentran en la dimensi\u00f3n de afiliados.</li> <li>Se realizan uniones y se filtra la informaci\u00f3n para garantizar la calidad de los datos (por ejemplo, considerando solo registros actuales y los de empresa principal).</li> </ul> </li> <li> <p>Transformaci\u00f3n: </p> <ul> <li>Se realiza la asignaci\u00f3n de un n\u00famero de fila (<code>rn</code>) para seleccionar el registro final en caso de m\u00faltiples coincidencias para un mismo afiliado.</li> <li>La consulta prepara los datos para ser consistentes con el esquema de la tabla destino, convirtiendo tipos de datos y asegurando la integridad de la informaci\u00f3n.</li> </ul> </li> <li> <p>Carga: </p> <ul> <li>El componente destino recibe los datos y los inserta en la tabla <code>\"Transversal\".\"DIM_AFILIADOS\"</code>, utilizando Bulk Insert cuando sea posible para mejorar el rendimiento.</li> <li>En caso de errores, los registros problem\u00e1ticos se redirigen a una salida de  error, permitiendo el an\u00e1lisis posterior sin detener el flujo completo.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_empresas","title":"Componente <code>Procesar DIM_EMPRESAS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_EMPRESAS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_EMPRESAS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_7","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_7","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_EMPRESAS</code></li> <li>DTSID: <code>{DTSID_DEL_COMPONENTE}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_4","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Empresas</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino_1","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_EMPRESAS\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_8","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_EMPRESAS\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Verificar tipos de datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_EMPRESA_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_EMPRESAS`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Modificar`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_EMPRESAS`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_empresas-desde-afiliados","title":"Componente <code>Procesar DIM_EMPRESAS desde AFILIADOS</code>","text":"<p>Flujo de datos (Data Flow Task) dentro del paquete SSIS cuyo objetivo es procesar informaci\u00f3n relacionada con empresas a partir de datos provenientes de afiliados. La informaci\u00f3n se extrae de una fuente (un componente de origen basado en ADO.NET que ejecuta una consulta SQL) y se carga en la tabla destino <code>\"Transversal\".\"DIM_EMPRESAS\"</code> en el Data Warehouse de destino.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave_1","title":"Componentes Clave","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-origen-transversal-dim-afiliados","title":"1. Origen: TRANSVERSAL DIM AFILIADOS","text":"<ul> <li>Funci\u00f3n:   Este componente extrae datos utilizando un adaptador ADO.NET (DataReaderSource) que ejecuta una consulta SQL.  </li> <li> <p>Consulta SQL:     La consulta utiliza CTEs (Common Table Expressions) para:</p> <ul> <li>Seleccionar de la dimensi\u00f3n de afiliados (<code>[DIM_AFILIADOS]</code>) del esquema Transversal.</li> <li>Identificar los <code>ID_EMPRESA</code> que est\u00e1n presentes en la dimensi\u00f3n de afiliados pero que no se encuentran en la dimensi\u00f3n de empresas actual (<code>[DIM_EMPRESAS]</code>).</li> <li>Luego, se hace un LEFT JOIN con la tabla <code>[DIM_EMPRESAS]</code> del esquema Aportes, filtrando registros actuales (<code>ESTADOREGISTRO = 'CURRENT'</code>).</li> </ul> </li> <li> <p>Conexi\u00f3n:   Se utiliza un administrador de conexiones configurado con <code>DWH_COMFENALCO_Destino</code>.</p> </li> <li> <p>Salida:   El componente expone una salida de datos (Salida de origen de ADO NET) con columnas relevantes como <code>ID_EMPRESA</code>, <code>PARTNER</code>, <code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>RAZON_SOCIAL</code>, <code>ID_ESTADO</code>, <code>ESTADO</code>, entre otras, que se utilizar\u00e1n en la carga final.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-destino-destino-de-ado-net_1","title":"2. Destino: Destino de ADO NET","text":"<ul> <li>Funci\u00f3n:   Este componente carga los datos procesados en la tabla destino <code>\"Transversal\".\"DIM_EMPRESAS\"</code>.  </li> <li> <p>Configuraci\u00f3n Importante: </p> <ul> <li>TableOrViewName: <code>\"Transversal\".\"DIM_EMPRESAS\"</code></li> <li>BatchSize: 0 (utiliza el tama\u00f1o del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true (habilita la inserci\u00f3n masiva para mejorar el rendimiento)</li> </ul> </li> <li> <p>Conexi\u00f3n:   Utiliza el administrador de conexiones <code>DWH_COMFENALCO_Destino</code>.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-flujo-de-datos_1","title":"3. Flujo de Datos","text":"<p>El flujo de datos conecta la salida del componente de origen (TRANSVERSAL DIM AFILIADOS) con la entrada del componente destino (Destino de ADO NET), de manera que los datos extra\u00eddos y transformados se inserten en la tabla <code>\"Transversal\".\"DIM_EMPRESAS\"</code>.</p> <pre><code>sequenceDiagram\n    participant Origen as TRANSVERSAL DIM AFILIADOS (Salida de origen de ADO NET)\n    participant Destino as Destino de ADO NET (Entrada de destino de ADO NET)\n\n    Origen -&gt;&gt; Destino: Transfiere los datos para cargar en DIM_EMPRESAS</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proceso-general_2","title":"Proceso General","text":"<ol> <li> <p>Extracci\u00f3n: </p> <ul> <li>Se ejecuta la consulta SQL del componente origen que identifica los <code>ID_EMPRESA</code> presentes en la dimensi\u00f3n de afiliados y que a\u00fan no existen en la dimensi\u00f3n de empresas.  </li> <li>La consulta se apoya en CTEs para estructurar y filtrar los datos, garantizando que s\u00f3lo se seleccionen empresas relevantes que deben ser cargadas.</li> </ul> </li> <li> <p>Transformaci\u00f3n: </p> <ul> <li>Los datos extra\u00eddos se transforman impl\u00edcitamente a trav\u00e9s de la configuraci\u00f3n del flujo, garantizando la correcta conversi\u00f3n de tipos (por ejemplo, cadenas, enteros y marcas de tiempo).</li> </ul> </li> <li> <p>Carga: </p> <ul> <li>El componente destino recibe los datos y los inserta en la tabla <code>\"Transversal\".\"DIM_EMPRESAS\"</code>.  </li> <li>La opci\u00f3n de Bulk Insert est\u00e1 activada para optimizar el rendimiento de la carga masiva.</li> </ul> </li> <li> <p>Manejo de Errores: </p> <ul> <li>Cualquier error durante la carga se redirige a una salida de error (Salida de error de destino de ADO NET), lo que permite analizar y corregir problemas sin detener el flujo completo.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_aportante_no_afiliado","title":"Componente <code>Procesar_DIM_APORTANTE_NO_AFILIADO</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_APORTANTE_NO_AFILIADO</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_APORTANTE_NO_AFILIADO</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_8","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_8","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_APORTANTE_NO_AFILIADO</code></li> <li>DTSID: <code>{DTSID_DEL_COMPONENTE}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_5","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Aportante</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino_2","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_APORTANTE_NO_AFILIADO\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#columnas-de-entrada_1","title":"Columnas de Entrada","text":"<ul> <li><code>ID_APORTANTE</code></li> <li><code>NOMBRE_APORTANTE</code></li> <li><code>TIPO_APORTANTE</code></li> <li><code>FECHA_REGISTRO</code></li> <li><code>ESTADO</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_9","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_APORTANTE_NO_AFILIADO\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Convertir datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_APORTANTE_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_APORTANTE_NO_AFILIADO`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Modificar`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_APORTANTE_NO_AFILIADO`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Sheet1$</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>CommandTimeout</code>: <code>0</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> </ul> </li> <li> <p>Columna Derivada (<code>Crear_ID_APORTANTE_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_APORTANTE_AUXILIAR</code> concatenando varias columnas de entrada.</li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_APORTANTE_NO_AFILIADO</code> para unir columnas adicionales al flujo de datos.</li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> </ul> </li> <li> <p>Destino ADO.NET (<code>DIM_APORTANTE_NO_AFILIADO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_APORTANTE_NO_AFILIADO</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_APORTANTE_NO_AFILIADO\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-descargar_ep-tra-05","title":"Componente <code>Descargar_EP-TRA-05</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_EP-TRA-05</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script de Python para descargar archivos desde SharePoint. Este componente utiliza la tarea <code>Execute Process</code> para ejecutar el script.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_9","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_9","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Descargar_EP-TRA-05</code></li> <li>DTSID: <code>{769c3094-28c7-44e9-9e36-9e9bc371b279}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar proceso</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteProcess</code></li> <li>TaskContact: <code>Execute Process Task;Microsoft Corporation; SQL Server 2022; \u00a9 2022 Microsoft Corporation; All Rights Reserved;http://www.microsoft.com/sql/support/default.asp;1</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-proceso","title":"Propiedades del Proceso","text":"<ul> <li>Executable: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> <li>Arguments: <code>04.SharePoint_Connection_EP-TRA-05.py</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso","title":"Diagrama de Secuencia del Proceso","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso - Descargar_EP-TRA-05\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Python as Script de Python\n    participant SharePoint as Servidor SharePoint\n\n    SSIS-&gt;&gt;Python: Ejecutar script `04.SharePoint_Connection_EP-TRA-05.py`\n    Python--&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Python: Confirmar conexi\u00f3n\n    Python-&gt;&gt;SharePoint: Descargar archivos\n    SharePoint--&gt;&gt;Python: Retornar archivos descargados\n    Python--&gt;&gt;SSIS: Confirmar finalizaci\u00f3n del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-proceso","title":"Componentes del Proceso","text":"<ol> <li> <p>Tarea Ejecutar Proceso (<code>Descargar_EP-TRA-05</code>)</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python para descargar archivos desde SharePoint.</li> <li>Propiedades:<ul> <li><code>Executable</code>: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li><code>WorkingDirectory</code>: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> <li><code>Arguments</code>: <code>04.SharePoint_Connection_EP-TRA-05.py</code></li> </ul> </li> </ul> </li> <li> <p>Script de Python (<code>04.SharePoint_Connection_EP-TRA-05.py</code>)</p> <ul> <li>Descripci\u00f3n: Script que se conecta a SharePoint y descarga los archivos necesarios.</li> </ul> </li> <li> <p>Servidor SharePoint</p> <ul> <li>Descripci\u00f3n: Servidor desde el cual se descargan los archivos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_personal","title":"Componente <code>Procesar_DIM_PERSONAL</code>","text":"<p>Este Data Flow Task dentro del paquete SSIS est\u00e1 dise\u00f1ado para procesar la dimensi\u00f3n del personal. El flujo de datos extrae informaci\u00f3n de una fuente Excel, la transforma a trav\u00e9s de conversiones y derivaciones, y la enriquece mediante una operaci\u00f3n de b\u00fasqueda (Lookup), para finalmente cargar los datos transformados en la tabla destino <code>\"Transversal\".\"DIM_PERSONAL\"</code>.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-principales_1","title":"Componentes Principales","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#1-excel-source-leer-ep-tra-05","title":"1. Excel Source \u2013 Leer EP-TRA-05","text":"<ul> <li>Funci\u00f3n:   Extrae datos desde un archivo Excel (hoja \"Sheet1$\").  </li> <li>Columnas Extra\u00eddas:   Incluye columnas como <code>COD_PERSONA_UNIDAD</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>NOMBRE</code>, <code>TELEFONO</code>, <code>CELULAR</code>, <code>CORREO</code>, <code>DIRECCION</code>, <code>CIUDAD</code>, <code>FECHA_NACIMIENTO</code>, <code>GENERO</code>, <code>ID_UNIDAD</code>, <code>SERVICIO</code>, <code>AREA</code>, <code>TIPO_CONTRATACION</code>, <code>FECHA_INICIO_CONTRATACION</code>, <code>FECHA_FIN_CONTRATACION</code>, entre otras.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#2-data-conversion","title":"2. Data Conversion","text":"<ul> <li>Funci\u00f3n:   Convierte los datos extra\u00eddos del Excel a los tipos requeridos para las siguientes transformaciones.  </li> <li>Ejemplos de Conversiones: </li> <li>Convierte cadenas de texto a cadenas con longitudes ajustadas (por ejemplo, <code>COD_PERSONA_UNIDAD</code> a 40 caracteres).  </li> <li>Convierte fechas almacenadas como cadenas a tipo <code>date</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#3-crear-id_personal_auxiliar-derived-column","title":"3. Crear ID_PERSONAL_AUXILIAR (Derived Column)","text":"<ul> <li>Funci\u00f3n:   Crea una columna derivada denominada <code>ID_PERSONAL_AUXILIAR</code>.  </li> <li>L\u00f3gica de la Expresi\u00f3n:   Concatena la columna <code>COD_PERSONA_UNIDAD</code> y <code>ID_UNIDAD</code>, separadas por un guion bajo, para formar un identificador \u00fanico que se utilizar\u00e1 en la comparaci\u00f3n y enriquecimiento posterior.</li> </ul> <p>Expresi\u00f3n: <code>COD_PERSONA_UNIDAD + \"_\" + (DT_WSTR,10)ID_UNIDAD</code></p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#4-lookup","title":"4. Lookup","text":"<ul> <li>Funci\u00f3n:   Realiza una b\u00fasqueda en la tabla de referencia <code>[Transversal].[DIM_PERSONAL]</code> para obtener columnas adicionales, en este caso, para obtener el campo <code>ID_PERSONAL_AUXILIAR</code>.  </li> <li>Consulta SQL de Referencia: <pre><code>SELECT \n    [COD_PERSONA_UNIDAD],\n    [ID_UNIDAD],\n    [COD_PERSONA_UNIDAD] + '_' + CAST([ID_UNIDAD] AS NVARCHAR(10)) AS [ID_PERSONAL_AUXILIAR]\nFROM \n    [Transversal].[DIM_PERSONAL];\n</code></pre></li> <li>Par\u00e1metro de Uni\u00f3n:   Se utiliza el resultado generado en el componente derivado (<code>ID_PERSONAL_AUXILIAR</code>) para comparar con la columna correspondiente del conjunto de referencia.  </li> <li>Salidas del Lookup: </li> <li>Lookup Match Output: Registros donde se encuentra la coincidencia en la referencia.  </li> <li>Lookup No Match Output: Registros sin coincidencia (en este flujo, estos datos se redirigen para la evaluaci\u00f3n en el Conditional Split).</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#5-conditional-split","title":"5. Conditional Split","text":"<ul> <li>Funci\u00f3n:   Divide el flujo de datos en dos rutas bas\u00e1ndose en una condici\u00f3n.</li> <li>Condici\u00f3n Especificada (\"Agregar\"):   La condici\u00f3n eval\u00faa si el valor de <code>ID_PERSONAL_AUXILIAR</code> obtenido del Lookup es nulo y si el campo <code>Copy of DOCUMENTO</code> (resultado del Data Conversion) no es nulo: <p>Expresi\u00f3n (versi\u00f3n con nombres de columna): <code>ISNULL(Lookup.ID_PERSONAL_AUXILIAR) &amp;&amp; !ISNULL([Copy of DOCUMENTO])</code></p> </li> <li>Salidas: </li> <li>Agregar: Registros que cumplen la condici\u00f3n y que, por lo tanto, deben ser tratados como nuevos registros para agregarlos a la dimensi\u00f3n.</li> <li>Sin Cambios (Default): Registros que no cumplen la condici\u00f3n de agregaci\u00f3n.</li> <li>Conditional Split Error Output: Manejo de errores.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#6-destino-de-ado-net","title":"6. Destino de ADO NET","text":"<ul> <li>Funci\u00f3n:   Carga los datos transformados y filtrados en la tabla destino <code>\"Transversal\".\"DIM_PERSONAL\"</code>.</li> <li>Configuraci\u00f3n Clave: </li> <li>TableOrViewName: <code>\"Transversal\".\"DIM_PERSONAL\"</code> </li> <li>BatchSize: 0 (usa el tama\u00f1o del b\u00fafer interno de SSIS)  </li> <li>CommandTimeout: 30 segundos  </li> <li>UseBulkInsertWhenPossible: true (para mejorar el rendimiento en inserciones masivas)  </li> <li>Conexi\u00f3n:   Utiliza un administrador de conexiones configurado (<code>DWH_COMFENALCO_Destino</code>).</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#flujo-general-del-proceso","title":"Flujo General del Proceso","text":"<ol> <li> <p>Extracci\u00f3n de Datos:    Los datos se leen desde un archivo Excel mediante el componente Excel Source.</p> </li> <li> <p>Conversi\u00f3n y Transformaci\u00f3n:    Se aplican conversiones de datos (Data Conversion) y se crea un identificador \u00fanico (<code>ID_PERSONAL_AUXILIAR</code>) mediante el componente Derived Column.</p> </li> <li> <p>Enriquecimiento con Lookup:    El componente Lookup compara el <code>ID_PERSONAL_AUXILIAR</code> generado con la referencia de la dimensi\u00f3n existente para identificar registros nuevos o sin cambios.</p> </li> <li> <p>Divisi\u00f3n Condicional:    Mediante el Conditional Split, se enrutan los registros a la salida \"Agregar\" para aquellos registros nuevos (donde no se encontr\u00f3 coincidencia en la tabla de referencia) y \"Sin Cambios\" para los registros ya existentes.</p> </li> <li> <p>Carga de Datos:    Finalmente, los registros identificados para agregaci\u00f3n se cargan en la tabla <code>\"Transversal\".\"DIM_PERSONAL\"</code> a trav\u00e9s del componente de destino ADO.NET.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/","title":"02. TRANSVERSAL_FACT","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#transversal_fact","title":"TRANSVERSAL_FACT","text":"<p>El paquete SSIS \"02-TRANSVERSAL_FACT\" est\u00e1 dise\u00f1ado para procesar y consolidar datos financieros, educativos y operativos relacionados con diversas \u00e1reas estrat\u00e9gicas. Este paquete facilita la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos, asegurando que se integren de manera efectiva en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es gestionar datos transversales cr\u00edticos, desde detalles contables y presupuestarios hasta encuestas y convenios. Este paquete asegura que los datos cargados en el Data Warehouse est\u00e9n preparados para an\u00e1lisis estrat\u00e9gicos, garantizando calidad, consistencia y precisi\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>FACT_DETALLE_CONTABLE</code></li> <li><code>FACT_PRESUPUESTO</code></li> <li><code>FACT_ENCUESTAS_PSR</code></li> <li><code>FACT_CONVENIOS</code></li> <li><code>FACT_INICIATIVAS</code></li> <li>Archivos Excel y CSV:</li> <li>Encuestas, PQRS, y otros registros de entrada.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB para acceso eficiente.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaciones (<code>Lookup</code>):<ul> <li>Garantiza la consistencia comparando con tablas maestras (<code>DIM_TIEMPO</code>, <code>DIM_AFILIADOS</code>, <code>DIM_EMPRESAS</code>).</li> </ul> </li> <li>Divisi\u00f3n Condicional (<code>Conditional Split</code>):<ul> <li>Clasifica registros en v\u00e1lidos y no v\u00e1lidos seg\u00fan criterios espec\u00edficos.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con el destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Genera claves auxiliares y valores predeterminados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas destino:<ul> <li><code>FACT_DETALLE_CONTABLE</code></li> <li><code>FACT_PRESUPUESTO</code></li> <li><code>FACT_ENCUESTAS_PSR</code></li> <li><code>FACT_CONVENIOS</code></li> <li><code>FACT_INICIATIVAS</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python para automatizar tareas relacionadas con conexiones a SharePoint y procesamiento din\u00e1mico de datos.</li> </ul> </li> <li> <p>Mantenimiento de Restricciones:</p> <ul> <li>Restauraci\u00f3n din\u00e1mica de llaves for\u00e1neas utilizando SQL din\u00e1mico para mantener integridad referencial.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>FACT_DETALLE_CONTABLE:</p> <ul> <li><code>ID_CEBE</code>, <code>ID_CUENTA</code>, <code>ID_FECHA</code>, <code>IMPORTE</code>, <code>GASTOS</code>, <code>ACTIVO</code>, <code>PASIVO</code>, entre otros.</li> </ul> </li> <li> <p>FACT_PRESUPUESTO:</p> <ul> <li><code>ID_CEBE</code>, <code>ID_FECHA</code>, <code>ID_TIPO_PRESUPUESTO</code>, <code>SEGMENT</code>, <code>VALOR</code>, <code>GASTOS</code>, <code>COSTOS</code>.</li> </ul> </li> <li> <p>FACT_ENCUESTAS_PSR:</p> <ul> <li><code>ID_FECHA</code>, <code>ID_EMPRESA</code>, <code>ID_BENEFICIARIO</code>, <code>DOCUMENTO</code>, <code>CALIFICACION</code>.</li> </ul> </li> <li> <p>FACT_CONVENIOS:</p> <ul> <li><code>ID_FECHA</code>, <code>NOMBRE_CONVENIO</code>, <code>VALOR_CONVENIO</code>, <code>ID_PROGRAMA</code>, <code>ID_UNIDAD</code>.</li> </ul> </li> <li> <p>FACT_INICIATIVAS:</p> <ul> <li><code>ID_INICIATIVA</code>, <code>ID_FECHA</code>, <code>NOMBRE_INICIATIVA</code>, <code>DESCRIPCION_INICIATIVA</code>, <code>OBSERVACIONES</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel y CSV\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de tablas maestras y transaccionales\n    SSIS -&gt;&gt; Excel: Leer datos de encuestas y PQRS\n    SSIS -&gt;&gt; Python: Ejecutar scripts de automatizaci\u00f3n\n    SSIS -&gt;&gt; DWH: Cargar datos procesados en tablas destino</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#2-diagrama-de-transformaciones-y-validaciones","title":"2. Diagrama de Transformaciones y Validaciones","text":"<pre><code>graph TD\n    A1[Fuente de Datos] --&gt; T1[Conversi\u00f3n de Datos]\n    A2[Tablas Maestras] --&gt; T2[Validaci\u00f3n mediante Lookup]\n    T1 --&gt; C1[Divisi\u00f3n por Condicional Split]\n    T2 --&gt; L1[Agregar Columnas Derivadas]\n    C1 --&gt; C2[Cargar datos transformados]</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#3-diagrama-er-para-tablas-de-hechos","title":"3. Diagrama ER para Tablas de Hechos","text":"<pre><code>erDiagram\n    FACT_DETALLE_CONTABLE {\n        int ID_CEBE\n        int ID_CUENTA\n        int ID_FECHA\n        float IMPORTE\n    }\n    FACT_PRESUPUESTO {\n        int ID_CEBE\n        int ID_FECHA\n        int ID_TIPO_PRESUPUESTO\n        float VALOR\n    }\n    FACT_ENCUESTAS_PSR {\n        int ID_FECHA\n        int ID_EMPRESA\n        int ID_BENEFICIARIO\n        string DOCUMENTO\n    }\n    FACT_CONVENIOS {\n        int ID_FECHA\n        string NOMBRE_CONVENIO\n        float VALOR_CONVENIO\n    }\n    FACT_INICIATIVAS {\n        int ID_INICIATIVA\n        int ID_FECHA\n        string NOMBRE_INICIATIVA\n    }\n    FACT_DETALLE_CONTABLE ||--|| FACT_PRESUPUESTO : \"Relaci\u00f3n Financiera\"\n    FACT_PRESUPUESTO ||--|| FACT_CONVENIOS : \"Conexi\u00f3n por Programas\"\n    FACT_ENCUESTAS_PSR ||--|| FACT_INICIATIVAS : \"An\u00e1lisis de Impacto\"</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-ejecucion-etl-c4c_sharepoint","title":"Componente <code>Ejecuci\u00f3n ETL C4C_SharePoint</code>","text":"<p>Este componente es una tarea de proceso (Execute Process Task) dentro del paquete SSIS, dise\u00f1ado para automatizar la ejecuci\u00f3n de un script Python que extrae y procesa datos desde SharePoint, espec\u00edficamente para la integraci\u00f3n con la soluci\u00f3n C4C. La tarea se configura din\u00e1micamente mediante expresiones de proyecto, lo que permite adaptar el ejecutable y el directorio de trabajo a diferentes entornos (por ejemplo, desarrollo, pruebas y producci\u00f3n).</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>c4c_from_sharepoint.py</code> que se encarga de conectarse a SharePoint para descargar y procesar datos relacionados con la soluci\u00f3n C4C.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar de manera automatizada la extracci\u00f3n de datos de SharePoint dentro del flujo de trabajo ETL de la soluci\u00f3n SSIS, facilitando la consolidaci\u00f3n y actualizaci\u00f3n de la informaci\u00f3n en el Data Warehouse.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute Process Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>Executable:   Se utiliza una expresi\u00f3n de propiedad para definir din\u00e1micamente la ruta del ejecutable de Python:   <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory:   La ruta de trabajo se define tambi\u00e9n de forma din\u00e1mica, estableciendo el directorio base donde se encuentra el script:   <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments:   El script a ejecutar es:   <pre><code>c4c_from_sharepoint.py\n</code></pre></li> </ul> </li> <li> <p>Datos del Objeto:</p> </li> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso sigue los siguientes pasos:</p> <ol> <li> <p>Inicio de la Tarea:    El paquete SSIS inicia la tarea de ejecuci\u00f3n de proceso.</p> </li> <li> <p>Ejecuci\u00f3n del Script Python:    Se ejecuta el ejecutable de Python con el argumento <code>c4c_from_sharepoint.py</code> en el directorio especificado. El script se conecta a SharePoint para realizar las operaciones de extracci\u00f3n y procesamiento de datos.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Una vez finalizada la ejecuci\u00f3n del script, la tarea devuelve el c\u00f3digo de retorno y el flujo ETL contin\u00faa con las siguientes operaciones definidas en el paquete.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant PythonScript as c4c_from_sharepoint.py\n\n    SSIS -&gt;&gt; ExecProcess: Inicia Ejecuci\u00f3n ETL C4C_SharePoint\n    ExecProcess -&gt;&gt; PythonScript: Ejecuta script de Python\n    PythonScript --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza la tarea ETL</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-ejecucion-etls","title":"Componente <code>Ejecuci\u00f3n ETLs</code>","text":"<p>Tarea de proceso (Execute Process Task) dentro del paquete SSIS, dise\u00f1ada para ejecutar un script Python que se encarga de establecer la conexi\u00f3n con SharePoint desde el entorno Transversal. El prop\u00f3sito es automatizar la extracci\u00f3n y el procesamiento de datos desde SharePoint, integr\u00e1ndolos en el flujo ETL global del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_1","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Conexi\u00f3n y Extracci\u00f3n de Datos desde SharePoint:   Ejecutar el script <code>05.SharePoint_Connection_Transversal.py</code> que establece la conexi\u00f3n a SharePoint para extraer y procesar datos espec\u00edficos del entorno Transversal.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar de forma automatizada la conexi\u00f3n y extracci\u00f3n de datos en el flujo ETL, asegurando la consolidaci\u00f3n y actualizaci\u00f3n continua de la informaci\u00f3n en el Data Warehouse.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_1","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute Process Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>Executable:   Se utiliza una expresi\u00f3n de propiedad para definir din\u00e1micamente la ruta del ejecutable de Python:   <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory:   La ruta de trabajo se define din\u00e1micamente con la siguiente expresi\u00f3n:   <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"\n</code></pre></li> <li>Arguments:   El script a ejecutar es:   <pre><code>05.SharePoint_Connection_Transversal.py\n</code></pre></li> </ul> </li> <li> <p>Datos del Objeto:</p> <ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_1","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso sigue estos pasos:</p> <ol> <li> <p>Inicio de la Tarea:    El paquete SSIS inicia la tarea de proceso que ejecuta el script.</p> </li> <li> <p>Ejecuci\u00f3n del Script Python:    Se invoca el ejecutable de Python con el argumento <code>05.SharePoint_Connection_Transversal.py</code> en el directorio de trabajo especificado. El script se encarga de conectarse a SharePoint, extraer y procesar los datos requeridos para el entorno Transversal.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Tras la ejecuci\u00f3n del script, la tarea finaliza y retorna el c\u00f3digo de retorno, permitiendo que el flujo ETL contin\u00fae con las siguientes operaciones.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Ejecuci\u00f3n ETLs\n    participant PythonScript as 05.SharePoint_Connection_Transversal.py\n\n    SSIS -&gt;&gt; ExecProcess: Inicia tarea de proceso\n    ExecProcess -&gt;&gt; PythonScript: Ejecuta script de Python\n    PythonScript --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_aportes_shr_det","title":"Componente <code>FACT_APORTES_SHR_DET</code>","text":"<p>El componente FACT_APORTES_SHR_DET es una tarea de flujo de datos (Data Flow Task) en el paquete SSIS dise\u00f1ada para procesar y consolidar datos relacionados con los aportes. Este flujo de datos forma parte de la soluci\u00f3n de integraci\u00f3n ETL del Data Warehouse <code>DWH_COMFENALCO</code> y se encarga de extraer datos desde la fuente de aportes, aplicar transformaciones y validaciones, y cargar la informaci\u00f3n final en la tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_2","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n y Consolidaci\u00f3n de Datos de Aportes:   Obtiene informaci\u00f3n financiera y operativa de aportes, considerando aportes, intereses y otros campos relevantes, para garantizar que los datos financieros est\u00e9n correctamente integrados en el Data Warehouse.</p> </li> <li> <p>Transformaci\u00f3n y Validaci\u00f3n de Datos:   Realiza conversiones de tipos de datos y cruces (lookups) para verificar la existencia y consistencia de registros en tablas relacionadas (por ejemplo, validaci\u00f3n de datos de afiliados y empresas). Adem\u00e1s, se asegura que solo se inserten nuevos registros mediante la comparaci\u00f3n con datos ya existentes.</p> </li> <li> <p>Carga de Datos con Rendimiento Optimizado:   Utiliza inserciones masivas (bulk insert) para la carga en la tabla <code>\"Transversal\".\"FACT_APORTES_SHR_DET\"</code>, garantizando una alta performance durante el proceso de ETL.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_2","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos del componente FACT_APORTES_SHR_DET se estructura en dos grandes grupos de componentes:</p> <ol> <li> <p>Fuente y Transformaci\u00f3n de Datos:</p> <ul> <li>Fuente de Datos ADO.NET:     Se extrae la informaci\u00f3n de aportes mediante una consulta SQL definida en el componente. La consulta obtiene campos como <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code>, <code>APORTE</code>, <code>INTERES</code>, <code>ESTADOREGISTRO</code>, <code>FECHA_ACTUALIZACION</code>, <code>DESDE</code>, <code>HASTA</code>, <code>PROCESO</code>, <code>BP_EMPRESA</code>, <code>BP_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>SW_AJUSTE</code> y <code>APORTE_NUEVO</code> de la tabla <code>[Aportes].[FACT_APORTES_SHR_DET]</code> para registros a partir del a\u00f1o 2022.</li> <li>Transformaciones y Cruces:     Se realizan conversiones de datos (por ejemplo, el campo <code>FECHA_CONTABLE</code> se utiliza en su formato num\u00e9rico) y se aplican lookups adicionales en tablas relacionadas para:<ul> <li>Validar y enriquecer la informaci\u00f3n con datos de afiliados y empresas.</li> <li>Comparar los datos extra\u00eddos con los registros existentes en el esquema transversal para evitar duplicidades. El uso de condiciones en los lookups permite identificar registros nuevos (aquellos que no se encuentran en el destino) que ser\u00e1n insertados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Destino de Datos ADO.NET:     La informaci\u00f3n procesada se carga en la tabla destino <code>\"Transversal\".\"FACT_APORTES_SHR_DET\"</code>. Se configura el destino para usar inserciones masivas (bulk insert) y se establecen par\u00e1metros como el tama\u00f1o del lote (BatchSize=0) y el tiempo de espera (CommandTimeout=600 segundos) para optimizar el rendimiento.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_2","title":"Flujo de Ejecuci\u00f3n","text":"<p>El flujo de datos del componente FACT_APORTES_SHR_DET se describe a continuaci\u00f3n:</p> <ol> <li> <p>Extracci\u00f3n de Datos:    El componente de origen ADO.NET ejecuta la consulta SQL para extraer los registros de aportes desde la base de datos <code>DWH_COMFENALCO</code>.</p> </li> <li> <p>Transformaci\u00f3n y Enriquecimiento: </p> </li> <li>Se aplican conversiones de datos para asegurar la correcta tipificaci\u00f3n (por ejemplo, conversi\u00f3n de <code>FECHA_CONTABLE</code>).</li> <li>Se realizan b\u00fasquedas (lookups) en las tablas DIM_AFILIADOS y DIM_EMPRESAS para validar que los registros de afiliados y empresas existan.  </li> <li> <p>Se efect\u00faa una comparaci\u00f3n (mediante un lookup con par\u00e1metros m\u00faltiples) contra la tabla ya cargada en el esquema Transversal para identificar registros nuevos.</p> </li> <li> <p>Carga de Datos:    Los registros que no coinciden con los existentes en el destino se cargan en la tabla <code>\"Transversal\".\"FACT_APORTES_SHR_DET\"</code> utilizando la configuraci\u00f3n de inserci\u00f3n masiva, asegurando una transferencia eficiente y confiable.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as Fuente de ADO.NET (FACT_APORTES_SHR_DET)\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup en DIM_AFILIADOS\n    participant ConditionalSplit as Divisi\u00f3n Condicional\n    participant Lookup2 as Lookup en DIM_EMPRESAS\n    participant ConditionalSplit1 as Segunda Divisi\u00f3n Condicional\n    participant Lookup as Lookup en FACT_APORTES_SHR_DET Transversal\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; DataConversion: Extrae datos de aportes\n    DataConversion -&gt;&gt; Lookup1: Aplica conversi\u00f3n de datos\n    Lookup1 -&gt;&gt; ConditionalSplit: Cruza con DIM_AFILIADOS\n    ConditionalSplit -&gt;&gt; Lookup2: Filtra registros v\u00e1lidos (ID_AFILIADO existe)\n    Lookup2 -&gt;&gt; ConditionalSplit1: Cruza con DIM_EMPRESAS\n    ConditionalSplit1 -&gt;&gt; Lookup: Compara con registros existentes en Transversal\n    Lookup -&gt;&gt; AdoNetDestination: Inserta registros nuevos</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_detalle_contable","title":"Componente <code>FACT_DETALLE_CONTABLE</code>","text":"<p>El componente FACT_DETALLE_CONTABLE es una tarea de flujo de datos (Data Flow Task) del paquete SSIS dise\u00f1ada para extraer, transformar y cargar datos financieros provenientes de la tabla <code>FACT_DETALLE_CONTABLE</code> ubicada en el esquema <code>Financiera</code> del Data Warehouse <code>DWH_COMFENALCO</code>. Este proceso forma parte del conjunto de operaciones ETL que alimentan la capa transversal del Data Warehouse, asegurando que los datos financieros se integren de manera precisa y sin duplicidades.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_3","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos Financieros:   Recuperar informaci\u00f3n detallada relacionada con cuentas, fechas, importes, ingresos, gastos, activos, pasivos y otros indicadores financieros de la tabla <code>FACT_DETALLE_CONTABLE</code>.</p> </li> <li> <p>Transformaci\u00f3n y Validaci\u00f3n:   Aplicar conversiones de tipos de datos, especialmente para fechas (por ejemplo, <code>FECHA_REGISTRO_SAP</code> y <code>FECHA_PROCESO</code>), y validar que la informaci\u00f3n extra\u00edda no se encuentre duplicada en el esquema transversal. Esto se logra mediante un cruce (lookup) con la tabla <code>[Transversal].[FACT_DETALLE_CONTABLE]</code>.</p> </li> <li> <p>Carga de Datos con Alta Performance:   Insertar \u00fanicamente los registros nuevos (aquellos que no existen en la tabla de destino) en la tabla <code>\"Transversal\".\"FACT_DETALLE_CONTABLE\"</code>, utilizando inserciones masivas (bulk insert) para optimizar el rendimiento del proceso.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_3","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos de FACT_DETALLE_CONTABLE se compone de los siguientes pasos:</p> <ol> <li> <p>Fuente de Datos ADO.NET: </p> <ul> <li>Se ejecuta una consulta SQL que extrae las columnas relevantes de la tabla <code>[Financiera].[FACT_DETALLE_CONTABLE]</code>.  </li> <li>La consulta incluye la conversi\u00f3n de los campos <code>FECHA_REGISTRO_SAP</code> y <code>FECHA_PROCESO</code> al tipo <code>smalldatetime</code> para facilitar su procesamiento.</li> </ul> </li> <li> <p>Conversi\u00f3n de Datos: </p> <ul> <li>Se utilizan componentes de Data Conversion para generar copias de las columnas de fecha (<code>Copy of FECHA_REGISTRO_SAP</code> y <code>Copy of FECHA_PROCESO</code>), asegurando que el formato y tipo de datos sean compatibles con los componentes de destino.</li> </ul> </li> <li> <p>Lookup para Validaci\u00f3n de Duplicidad: </p> <ul> <li>Se realiza un cruce (lookup) con la tabla <code>[Transversal].[FACT_DETALLE_CONTABLE]</code> para comparar los registros extra\u00eddos.  </li> <li>La uni\u00f3n se efect\u00faa mediante las claves: <code>ID_CEBE</code>, <code>ID_CUENTA</code>, <code>ID_FECHA</code>, <code>SEGMENT</code>, <code>IMPORTE</code> y <code>FECHA_REGISTRO_SAP</code>.  </li> <li>Solo se consideran los registros que no encuentran coincidencia en el destino (es decir, aquellos para los cuales el lookup devuelve un valor nulo).</li> </ul> </li> <li> <p>Destino de Datos ADO.NET: </p> <ul> <li>Los registros resultantes, considerados nuevos, se cargan en la tabla <code>\"Transversal\".\"FACT_DETALLE_CONTABLE\"</code>.  </li> <li>Se configuran par\u00e1metros de inserci\u00f3n masiva (Bulk Insert) con un tama\u00f1o de lote predeterminado (BatchSize=0) y un CommandTimeout de 300 segundos para optimizar la operaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_3","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso ETL se puede resumir en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    La fuente ADO.NET ejecuta la consulta para recuperar los datos financieros desde la tabla origen en el esquema <code>Financiera</code>.</p> </li> <li> <p>Transformaci\u00f3n: </p> <ul> <li>Se convierten los campos de fecha a un formato adecuado.  </li> <li>Se realiza un cruce (lookup) para verificar la existencia de cada registro en la tabla destino del esquema <code>Transversal</code>.</li> </ul> </li> <li> <p>Carga:    Los registros que no est\u00e1n presentes en la tabla de destino se insertan en <code>\"Transversal\".\"FACT_DETALLE_CONTABLE\"</code>, garantizando la integraci\u00f3n de solo datos nuevos y evitando duplicidades.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as Fuente de ADO.NET (FACT_DETALLE_CONTABLE)\n    participant DataConversion as Componente Data Conversion\n    participant Lookup as Componente Lookup (Validaci\u00f3n en Transversal)\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; DataConversion: Extrae datos financieros\n    DataConversion -&gt;&gt; Lookup: Aplica conversi\u00f3n de fechas\n    Lookup -&gt;&gt; AdoNetDestination: Filtra registros nuevos (Lookup sin coincidencias)</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_convenios","title":"Componente <code>FACT_CONVENIOS</code>","text":"<p>El componente FACT_CONVENIOS es una tarea de flujo de datos (Data Flow Task) del paquete SSIS que se encarga de procesar y cargar datos de convenios extra\u00eddos de archivos Excel hacia el Data Warehouse <code>DWH_COMFENALCO</code>. Este proceso forma parte de la integraci\u00f3n transversal y se encarga de transformar la informaci\u00f3n para enriquecer la capa anal\u00edtica con datos de convenios, sus entidades y condiciones asociadas.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_4","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos desde Excel:   Se leen datos de convenios provenientes de un archivo Excel. Entre la informaci\u00f3n extra\u00edda se encuentran los nombres de convenios, la identificaci\u00f3n del acto del convenio, la entidad responsable, el c\u00f3digo del municipio, el valor del convenio, el aporte de Comfenalco, el estado del convenio, las fechas de inicio y fin, y los identificadores relacionados con el programa y la unidad.</p> </li> <li> <p>Transformaci\u00f3n y Conversi\u00f3n de Datos:   Se aplican conversiones de datos para adecuar los tipos de datos a los requeridos por el destino. Por ejemplo, se convierten las fechas de inicio y fin a un tipo de fecha (timestamp) y se transforma el identificador del programa y la unidad a tipos num\u00e9ricos compatibles.</p> </li> <li> <p>Carga de Datos con Alta Performance:   Los datos transformados se insertan en la tabla <code>\"Transversal\".\"FACT_CONVENIOS\"</code> utilizando inserciones masivas (Bulk Insert) para optimizar el rendimiento del proceso.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_4","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos del componente FACT_CONVENIOS se estructura en los siguientes pasos:</p> <ol> <li> <p>Fuente de Datos Excel: </p> <ul> <li>Objetivo: Leer la informaci\u00f3n de convenios desde una hoja de Excel (por ejemplo, <code>Sheet1$</code>).  </li> <li>Columnas Extra\u00eddas: <ul> <li><code>NOMBRE_CONVENIO</code>,  </li> <li><code>IDENTIFICACION_ACTO_CONVENIO</code>,  </li> <li><code>ENTIDAD_CONVENIO</code>,  </li> <li><code>COD_MUNICIPIO</code>,  </li> <li><code>VALOR_CONVENIO</code>,  </li> <li><code>APORTE_COMFENALCO</code>,  </li> <li><code>ESTADO_CONVENIO</code>,  </li> <li><code>FECHA_INICIO</code>,  </li> <li><code>FECHA_FIN</code>,  </li> <li><code>PROGRAMA</code>,  </li> <li><code>ID_PROGRAMA</code>,  </li> <li><code>ID_UNIDAD</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos: </p> <ul> <li>Objetivo: Transformar y ajustar los tipos de datos de las columnas extra\u00eddas para que sean compatibles con los procesos posteriores.  </li> <li>Conversiones Espec\u00edficas: <ul> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code> se convierten a un formato de fecha/hora (timestamp) y se renombran como <code>Copy of FECHA_INICIO</code> y <code>Copy of FECHA_FIN</code>.  </li> <li><code>ID_PROGRAMA</code> se transforma a formato num\u00e9rico y se guarda en <code>Copy of ID_PROGRAMA</code>.  </li> <li>Se crea una versi\u00f3n reducida (por ejemplo, de 40 caracteres) de la columna <code>PROGRAMA</code> denominada <code>Copy of PROGRAMA</code>.  </li> <li>De igual manera se generan copias de <code>NOMBRE_CONVENIO</code>, <code>ENTIDAD_CONVENIO</code> y <code>IDENTIFICACION_ACTO_CONVENIO</code> con el tama\u00f1o adecuado.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET: </p> <ul> <li>Objetivo: Cargar la informaci\u00f3n transformada en la tabla de destino <code>\"Transversal\".\"FACT_CONVENIOS\"</code>.  </li> <li>Configuraci\u00f3n: <ul> <li>Se utiliza inserci\u00f3n masiva (Bulk Insert) para optimizar el rendimiento.  </li> <li>El componente se conecta a la base de datos destino mediante el administrador de conexiones <code>DWH_COMFENALCO_Destino</code>.</li> </ul> </li> <li>Columnas Cargadas: <ul> <li>Se incluyen tanto las columnas transformadas (por ejemplo, <code>Copy of FECHA_INICIO</code>, <code>Copy of FECHA_FIN</code>, <code>Copy of ID_PROGRAMA</code>, <code>Copy of PROGRAMA</code>, <code>Copy of NOMBRE_CONVENIO</code>, <code>Copy of ENTIDAD_CONVENIO</code>, <code>Copy of IDENTIFICACION_ACTO_CONVENIO</code>) como aquellas que provienen directamente de la fuente (por ejemplo, <code>COD_MUNICIPIO</code>, <code>VALOR_CONVENIO</code>, <code>APORTE_COMFENALCO</code>, <code>ESTADO_CONVENIO</code>).</li> </ul> </li> </ul> </li> <li> <p>Integraci\u00f3n con el Proceso ETL: </p> <ul> <li>La salida del componente Excel se une a la transformaci\u00f3n (Data Conversion) y, posteriormente, el flujo se conecta directamente al destino de ADO.NET.  </li> <li>Se garantiza que la informaci\u00f3n cargada en la tabla de destino est\u00e9 normalizada y lista para su an\u00e1lisis en el contexto transversal.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_4","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso ETL en FACT_CONVENIOS se puede resumir en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    La fuente de datos Excel extrae los registros de convenios de la hoja configurada.</p> </li> <li> <p>Transformaci\u00f3n:    Los datos se pasan a trav\u00e9s de un componente de Data Conversion, donde se aplican las conversiones necesarias (fechas, identificadores y textos) para normalizar la informaci\u00f3n.</p> </li> <li> <p>Carga:    Los registros transformados se insertan en la tabla <code>\"Transversal\".\"FACT_CONVENIOS\"</code> utilizando un destino ADO.NET configurado para inserciones masivas.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Fuente de Excel (FACT_CONVENIOS)\n    participant DataConversion as Componente Data Conversion\n    participant AdoNetDestination as Destino de ADO NET\n\n    ExcelSource -&gt;&gt; DataConversion: Extrae datos desde Excel\n    DataConversion -&gt;&gt; AdoNetDestination: Transforma y pasa datos\n    AdoNetDestination -&gt;&gt; AdoNetDestination: Inserta registros en \"Transversal\".\"FACT_CONVENIOS\"</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_presupuesto","title":"Componente <code>FACT_PRESUPUESTO</code>","text":"<p>El componente FACT_PRESUPUESTO es una tarea de flujo de datos (Data Flow Task) del paquete SSIS dise\u00f1ado para extraer, transformar y cargar datos financieros del presupuesto. Este componente extrae registros de la tabla <code>FACT_PRESUPUESTO</code> del esquema <code>Financiera</code> en el Data Warehouse <code>DWH_COMFENALCO</code>, y posteriormente inserta los registros nuevos en la tabla de destino <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code>. El proceso garantiza que la informaci\u00f3n presupuestal se integre de forma precisa y sin duplicidades en la capa transversal.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_5","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos Financieros:   Se obtienen los registros de la tabla <code>[DWH_COMFENALCO].[Financiera].[FACT_PRESUPUESTO]</code>, que contienen indicadores como valor, ingresos, gastos y otros datos relevantes para el an\u00e1lisis presupuestal.</p> </li> <li> <p>Transformaci\u00f3n y Validaci\u00f3n: </p> <ul> <li>Se realiza la conversi\u00f3n de los datos extra\u00eddos para asegurar la compatibilidad de tipos, especialmente en campos num\u00e9ricos y de fecha.</li> <li>Se efect\u00faa una validaci\u00f3n mediante un cruce (lookup) para verificar que los registros a cargar sean nuevos, comparando la informaci\u00f3n existente en la tabla de destino del esquema <code>Transversal</code>.</li> </ul> </li> <li> <p>Carga de Datos con Alta Performance:   Se insertan los registros nuevos en la tabla <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code> utilizando inserciones masivas (bulk insert) para maximizar el rendimiento del proceso ETL.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_5","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos del componente FACT_PRESUPUESTO se compone de los siguientes pasos:</p> <ol> <li> <p>Fuente de Datos ADO.NET: </p> <ul> <li> <p>Consulta SQL:     Se ejecuta una instrucci\u00f3n que extrae los datos de la tabla <code>[DWH_COMFENALCO].[Financiera].[FACT_PRESUPUESTO]</code> y que filtra los registros mediante una uni\u00f3n con la tabla <code>[Transversal].[DIM_UNIDADES_ORGANIZATIVAS]</code> para asegurar que se consideren solo aquellos registros que correspondan a unidades organizativas v\u00e1lidas.</p> <p>La consulta utiliza la cl\u00e1usula <code>WITH</code> para definir un conjunto intermedio de datos (fact presupuestario) y, posteriormente, se realiza un cruce con la tabla destino para seleccionar \u00fanicamente los registros nuevos (aquellos para los que no existe coincidencia en <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code>).</p> </li> </ul> </li> <li> <p>Transformaci\u00f3n y Conversi\u00f3n de Datos: </p> <ul> <li>Se garantiza que los tipos de datos sean compatibles con el destino, incluyendo conversiones necesarias para campos num\u00e9ricos y fechas.</li> <li>La transformaci\u00f3n asegura que los datos sean limpios y listos para su integraci\u00f3n en la capa transversal.</li> </ul> </li> <li> <p>Destino de Datos ADO.NET: </p> <ul> <li>Configuraci\u00f3n: <ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code>.</li> <li>Par\u00e1metros: </li> <li><code>BatchSize</code> se configura a 0 para utilizar el tama\u00f1o de b\u00fafer interno de SSIS.</li> <li><code>CommandTimeout</code> se establece en 600 segundos para procesos de alta carga.</li> <li>Se utiliza la opci\u00f3n de Bulk Insert para optimizar la inserci\u00f3n de grandes vol\u00famenes de datos.</li> </ul> </li> <li>Carga de Registros Nuevos:     Solo se insertan aquellos registros que no han sido previamente cargados en el destino, de acuerdo al cruce (lookup) realizado en la consulta SQL.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_5","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso ETL del componente FACT_PRESUPUESTO se resume en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    Se ejecuta la consulta SQL en la fuente ADO.NET para recuperar los datos financieros del presupuesto desde la tabla en el esquema <code>Financiera</code>.</p> </li> <li> <p>Transformaci\u00f3n:    Se aplican conversiones y validaciones para asegurar que los datos cumplan con los requisitos de la capa transversal.</p> </li> <li> <p>Carga:    Los registros validados y que no existen en la tabla destino se insertan en <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code>, integr\u00e1ndose al Data Warehouse para an\u00e1lisis y reportes estrat\u00e9gicos.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as Fuente de ADO.NET (FACT_PRESUPUESTO)\n    participant Lookup as Componente Lookup (Validaci\u00f3n y filtrado)\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; Lookup: Extrae datos de FACT_PRESUPUESTO\n    Lookup -&gt;&gt; AdoNetDestination: Filtra e inserta registros nuevos</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_iniciativas","title":"Componente <code>FACT_INICIATIVAS</code>","text":"<p>El componente FACT_INICIATIVAS es una tarea de flujo de datos (Data Flow Task) del paquete SSIS que se encarga de extraer, transformar y cargar informaci\u00f3n relacionada con iniciativas. Esta informaci\u00f3n se obtiene principalmente desde un archivo Excel y, mediante una transformaci\u00f3n de datos y b\u00fasquedas (lookup), se enriquece con informaci\u00f3n adicional de la dimensi\u00f3n de tiempo para asignar el identificador de fecha correspondiente. Finalmente, los datos transformados se insertan en la tabla <code>\"Transversal\".\"FACT_INICIATIVAS\"</code> del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_6","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos:   Se leen los registros de iniciativas desde un archivo Excel. Entre los datos extra\u00eddos se encuentran los identificadores de la iniciativa, la unidad, la fecha de inicio, la fecha de fin, el nombre de la iniciativa, la descripci\u00f3n y observaciones.</p> </li> <li> <p>Transformaci\u00f3n y Conversi\u00f3n: </p> <ul> <li>Se aplican conversiones de datos para asegurar la correcta transformaci\u00f3n de los campos de fecha (de texto a timestamp) y la normalizaci\u00f3n de los campos de texto.</li> <li>Estas conversiones permiten trabajar con formatos adecuados para la integraci\u00f3n en la base de datos.</li> </ul> </li> <li> <p>Enriquecimiento mediante Lookup:   Se realiza una b\u00fasqueda (lookup) en la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO</code>) para obtener el valor de <code>ID_FECHA</code> correspondiente a la fecha de inicio de la iniciativa, lo que facilita la integraci\u00f3n de la informaci\u00f3n temporal en el proceso ETL.</p> </li> <li> <p>Carga de Datos:   Los datos transformados y enriquecidos se insertan en la tabla destino <code>\"Transversal\".\"FACT_INICIATIVAS\"</code>, garantizando la integraci\u00f3n de la informaci\u00f3n de iniciativas en la capa transversal del Data Warehouse para posteriores an\u00e1lisis estrat\u00e9gicos.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_6","title":"Descripci\u00f3n T\u00e9cnica","text":"<p>El flujo de datos del componente FACT_INICIATIVAS se compone de los siguientes pasos:</p> <ol> <li> <p>Excel Source: </p> <ul> <li>Funci\u00f3n: Extraer los datos de iniciativas desde un archivo Excel.</li> <li>Datos Extra\u00eddos: <ul> <li><code>ID_INICIATIVA</code></li> <li><code>ID_UNIDAD</code></li> <li><code>FECHA_INICIO</code></li> <li><code>FECHA_FIN</code></li> <li><code>NOMBRE_INICIATIVA</code></li> <li><code>DESCRIPCION_INICIATIVA</code></li> <li><code>OBSERVACIONES</code></li> </ul> </li> <li>Conexi\u00f3n: Se utiliza el administrador de conexiones configurado para Excel.</li> </ul> </li> <li> <p>Data Conversion: </p> <ul> <li>Funci\u00f3n: Convertir los datos extra\u00eddos a tipos compatibles con el procesamiento posterior.</li> <li>Conversiones Realizadas: <ul> <li>Se convierten los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code> de texto a tipo dbTimeStamp.</li> <li>Se realizan copias de los campos <code>NOMBRE_INICIATIVA</code>, <code>DESCRIPCION_INICIATIVA</code> y <code>OBSERVACIONES</code> para mantener la integridad de la informaci\u00f3n durante la transformaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_TIEMPO): </p> <ul> <li>Funci\u00f3n: Enriquecer los datos del flujo mediante una b\u00fasqueda en la tabla <code>DIM_TIEMPO</code> para obtener el valor de <code>ID_FECHA</code>.</li> <li>Par\u00e1metros: <ul> <li>Se utiliza el campo convertido <code>Copy of FECHA_INICIO</code> para unir con la columna <code>FECHA</code> de la tabla <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Resultado: <ul> <li>Se obtiene el <code>ID_FECHA</code> que se agregar\u00e1 al flujo de datos para relacionar la iniciativa con la dimensi\u00f3n de tiempo.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET: </p> <ul> <li>Funci\u00f3n: Insertar los datos transformados y enriquecidos en la tabla de destino.</li> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_INICIATIVAS\"</code>.</li> <li>Configuraci\u00f3n: <ul> <li>Se emplea Bulk Insert para mejorar el rendimiento.</li> <li>Los par\u00e1metros de lote (BatchSize) y tiempo de espera (CommandTimeout) se configuran para optimizar la inserci\u00f3n de grandes vol\u00famenes de datos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_6","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso ETL del componente FACT_INICIATIVAS se resume en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    Los datos se leen desde un archivo Excel mediante el componente Excel Source.</p> </li> <li> <p>Transformaci\u00f3n:    Se aplican conversiones a los campos de fecha y texto usando el componente Data Conversion.</p> </li> <li> <p>Enriquecimiento:    El componente Lookup consulta la tabla <code>DIM_TIEMPO</code> para asignar a cada registro el valor correspondiente de <code>ID_FECHA</code> bas\u00e1ndose en la fecha de inicio.</p> </li> <li> <p>Carga:    Los registros resultantes se insertan en la tabla <code>\"Transversal\".\"FACT_INICIATIVAS\"</code> utilizando el destino ADO.NET.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup (DIM_TIEMPO)\n    participant AdoNetDestination as Destino de ADO NET\n\n    ExcelSource -&gt;&gt; DataConversion: Extrae datos desde Excel\n    DataConversion -&gt;&gt; Lookup: Convierte y env\u00eda datos (p.ej., Copy of FECHA_INICIO)\n    Lookup -&gt;&gt; AdoNetDestination: Enrich &amp; Filtra datos (asigna ID_FECHA) y carga registros nuevos</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-truncar-tmp_encuestas","title":"Componente <code>Truncar TMP_ENCUESTAS</code>","text":"<p>El componente Truncar TMP_ENCUESTAS es una tarea de ejecuci\u00f3n de SQL (Execute SQL Task) en un paquete SSIS. Su funci\u00f3n principal es limpiar la tabla temporal <code>[STAGE_AREA].[Transversal].[TMP_ENCUESTAS]</code> antes de cargar nuevos datos durante el proceso ETL. Esta acci\u00f3n es fundamental para garantizar que la tabla no contenga datos residuales de ejecuciones anteriores, asegurando as\u00ed la calidad y consistencia de la informaci\u00f3n que se insertar\u00e1 posteriormente.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-componente_7","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Limpieza de Datos:   El objetivo principal es truncar (vaciar) la tabla <code>[STAGE_AREA].[Transversal].[TMP_ENCUESTAS]</code> para eliminar todos los registros existentes, preparando la tabla para una nueva carga de datos.</p> </li> <li> <p>Garantizar Integridad:   Al vaciar la tabla temporal, se evita la mezcla de datos antiguos y nuevos, lo que contribuye a la precisi\u00f3n del proceso ETL y facilita el manejo de la informaci\u00f3n en etapas posteriores.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_7","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea: Execute SQL Task \u2013 Permite la ejecuci\u00f3n de sentencias SQL directamente desde el paquete SSIS.</p> </li> <li> <p>Instrucci\u00f3n SQL:   La tarea ejecuta la siguiente sentencia:   <pre><code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ENCUESTAS]\n</code></pre>   Esta sentencia elimina de forma r\u00e1pida y eficiente todos los registros de la tabla, sin registrar cada eliminaci\u00f3n individualmente (a diferencia de una sentencia DELETE).</p> </li> <li> <p>Conexi\u00f3n:   Se utiliza una conexi\u00f3n preconfigurada (identificada mediante el GUID <code>{5972EC76-2533-4771-BB68-A92E1CDD645D}</code>) que apunta a la base de datos de destino, asegurando que la operaci\u00f3n se realice sobre el entorno correcto.</p> </li> <li> <p>Tiempo de Espera:   La configuraci\u00f3n predeterminada de tiempo de espera se aplica, aunque este par\u00e1metro puede ajustarse seg\u00fan las necesidades del entorno.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#flujo-de-ejecucion_7","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    Al ejecutar el paquete SSIS, se inicia la tarea de SQL que contiene la sentencia de truncamiento.</p> </li> <li> <p>Ejecuci\u00f3n de la Sentencia SQL:    La sentencia <code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ENCUESTAS]</code> se env\u00eda a la base de datos a trav\u00e9s del administrador de conexiones configurado.</p> </li> <li> <p>Limpieza de la Tabla:    Todos los registros en la tabla temporal se eliminan, dej\u00e1ndola vac\u00eda y lista para la nueva carga de datos.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Una vez completada la operaci\u00f3n, la tarea finaliza y el proceso ETL puede continuar con las siguientes etapas de carga y transformaci\u00f3n.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SQLTask as Truncar TMP_ENCUESTAS\n    participant DB as Base de Datos\n\n    SQLTask -&gt;&gt; DB: Ejecuta \"TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ENCUESTAS]\"\n    DB --&gt;&gt; SQLTask: Confirmaci\u00f3n de limpieza</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-tmp_encuestas","title":"Componente <code>TMP_ENCUESTAS</code>","text":"<p>El paquete SSIS \"TMP_ENCUESTAS\" es un flujo de datos (Data Flow Task) dise\u00f1ado para extraer, transformar y cargar informaci\u00f3n proveniente de un archivo plano (CSV) hacia la tabla <code>[Transversal].[TMP_ENCUESTAS]</code> en la base de datos de staging. Este flujo se encarga de convertir datos de entrada, aplicar expresiones para derivar nuevos valores (por ejemplo, el identificador de unidad basado en el servicio) y, finalmente, cargar la informaci\u00f3n limpia y transformada en el destino.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-paquete_1","title":"Prop\u00f3sito del Paquete","text":"<ul> <li> <p>Extracci\u00f3n de Datos:   Se leen los registros de un archivo CSV que contiene informaci\u00f3n de encuestas, incluyendo columnas como FECHA_ENCUESTA, DOCUMENTO, TIPO_DOCUMENTO, CALIFICACION, SERVICIO, PREGUNTA y NPS.</p> </li> <li> <p>Transformaci\u00f3n de Datos:     El proceso incluye:</p> <ul> <li>Conversi\u00f3n de Datos: Se transforma la informaci\u00f3n extra\u00edda (por ejemplo, se convierte la fecha de encuesta a formato de fecha/hora compatible con la base de datos).</li> <li>Derivaci\u00f3n de Columnas: Se utiliza una transformaci\u00f3n Derivada para calcular la columna ID_UNIDAD a partir del valor de la columna SERVICIO. La expresi\u00f3n asigna diferentes valores num\u00e9ricos seg\u00fan el contenido de SERVICIO (por ejemplo, \u201cConsultorias\u201d \u2192 3, \u201cEgresados\u201d \u2192 2, etc.).</li> </ul> </li> <li> <p>Carga de Datos:   La informaci\u00f3n transformada se carga en la tabla <code>[Transversal].[TMP_ENCUESTAS]</code> del \u00e1rea de staging, utilizando un destino ADO.NET optimizado para inserciones masivas.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_8","title":"Descripci\u00f3n T\u00e9cnica","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-principales","title":"Componentes Principales:","text":"<ol> <li> <p>Flat File Source: </p> <ul> <li>Funci\u00f3n: Extrae los datos del archivo CSV.</li> <li>Columnas de Origen: <ul> <li>FECHA_ENCUESTA  </li> <li>DOCUMENTO  </li> <li>PREGUNTA  </li> <li>CALIFICACION  </li> <li>SERVICIO  </li> <li>TIPO_DOCUMENTO  </li> <li>NPS  </li> </ul> </li> <li>Configuraci\u00f3n: Se utiliza una conexi\u00f3n definida (Csv_Connection_Fact_Encuestas) y se lee la hoja o secci\u00f3n definida en el archivo.</li> </ul> </li> <li> <p>Data Conversion: </p> <ul> <li>Funci\u00f3n: Convierte las columnas de datos extra\u00eddos a tipos de datos compatibles para operaciones posteriores.</li> <li>Conversiones Realizadas: <ul> <li>FECHA_ENCUESTA se convierte a tipo dbTimeStamp (formato fecha/hora).  </li> <li>DOCUMENTO, TIPO_DOCUMENTO, CALIFICACION, SERVICIO, PREGUNTA y NPS se convierten a cadenas de caracteres (wstr) con longitudes espec\u00edficas.</li> </ul> </li> </ul> </li> <li> <p>Derived Column (ID_UNIDAD): </p> <ul> <li>Funci\u00f3n: Genera la columna ID_UNIDAD mediante una expresi\u00f3n derivada que asigna un valor num\u00e9rico seg\u00fan el valor de la columna SERVICIO.  </li> <li>Expresi\u00f3n Utilizada: <pre><code>(DT_I4)(SERVICIO == \"Consultorias\" ? 3 :\n        SERVICIO == \"Egresados\" ? 2 :\n        SERVICIO == \"Proteccion social\" ? 4 :\n        SERVICIO == \"Cedesarrollo convenios\" ? 2 :\n        SERVICIO == \"CEC\" ? 1 :\n        SERVICIO == \"Estudiantes Activos\" ? 2 :\n        SERVICIO == \"Cursos y diplomados\" ? 3 : 5)\n</code></pre>     Esta l\u00f3gica clasifica el servicio en diferentes categor\u00edas y asigna un identificador num\u00e9rico que se utilizar\u00e1 en el sistema.</li> </ul> </li> <li> <p>Destino de ADO.NET: </p> <ul> <li>Funci\u00f3n: Carga los datos finales transformados en la tabla <code>[Transversal].[TMP_ENCUESTAS]</code>.  </li> <li>Configuraci\u00f3n: <ul> <li>Tabla de Destino: <code>\"Transversal\".\"TMP_ENCUESTAS\"</code> </li> <li>BatchSize: 0 (usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS)  </li> <li>CommandTimeout: 30 segundos  </li> <li>Uso de Bulk Insert: Activado para mejorar el rendimiento en la carga de datos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant FlatFile as Flat File Source\n    participant DataConv as Data Conversion\n    participant Derived as Derived Column (ID_UNIDAD)\n    participant Destination as Destino ADO.NET\n\n    FlatFile -&gt;&gt; DataConv: Extrae y convierte datos del CSV\n    DataConv -&gt;&gt; Derived: Env\u00eda datos convertidos\n    Derived -&gt;&gt; Destination: Carga datos transformados en la tabla TMP_ENCUESTAS</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-actualizacion-fact_encuestas","title":"Componente <code>Actualizacion FACT_ENCUESTAS</code>","text":"<p>El paquete SSIS \"Actualizacion FACT_ENCUESTAS\" es un flujo de datos (Data Flow Task) dise\u00f1ado para actualizar la tabla de encuestas en el entorno transversal. Su funci\u00f3n es comparar y actualizar los registros de encuestas en la tabla de destino <code>[Transversal].[FACT_ENCUESTAS]</code> con la informaci\u00f3n procesada proveniente de la etapa de staging. El proceso se centra en identificar registros nuevos o modificados que a\u00fan no existan en el sistema y actualizarlos, garantizando la integridad y consistencia de los datos.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-paquete_2","title":"Prop\u00f3sito del Paquete","text":"<ul> <li> <p>Extracci\u00f3n de Datos:   Se consumen datos de la etapa de staging, previamente cargados en la tabla temporal, que contienen informaci\u00f3n consolidada de encuestas. Las columnas extra\u00eddas incluyen FECHA_ENCUESTA, ID_FECHA, DOCUMENTO, PREGUNTA, CALIFICACION, SERVICIO, TIPO_DOCUMENTO, NPS, ID_UNIDAD, ID_AFILIADO, ID_BENEFICIARIO e ID_APORTANTE.</p> </li> <li> <p>Transformaci\u00f3n de Datos:     El paquete se basa en una consulta SQL que utiliza expresiones comunes y t\u00e9cnicas de uni\u00f3n para:</p> <ul> <li>Transformar y normalizar la informaci\u00f3n.</li> <li>Realizar joins con tablas de referencia (como DIM_TIEMPO, DIM_EMPRESAS, DIM_AFILIADOS, DIM_BENEFICIARIOS y DIM_APORTANTE_NOAFILIADO) para enriquecer el dataset.</li> <li>Filtrar registros que ya existen en la tabla final, de modo que s\u00f3lo se inserten aquellos que son nuevos (es decir, aquellos cuya clave primaria o identificador no se encuentra en <code>[Transversal].[FACT_ENCUESTAS]</code>).</li> </ul> </li> <li> <p>Carga de Datos:   La informaci\u00f3n resultante se inserta en la tabla <code>[Transversal].[FACT_ENCUESTAS]</code> usando un destino ADO.NET optimizado para cargas masivas. Esto permite actualizar el repositorio de encuestas de forma eficiente y con alta performance.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-tecnica_9","title":"Descripci\u00f3n T\u00e9cnica","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-principales_1","title":"Componentes Principales:","text":"<ol> <li> <p>Consulta de Origen (Consulta): </p> <ul> <li>Funci\u00f3n:     Consume datos de la tabla temporal en el \u00e1rea de staging (<code>[STAGE_AREA].[Transversal].[TMP_ENCUESTAS]</code>), aplicando una serie de transformaciones y agregaciones para obtener un conjunto de resultados limpio y consolidado.  </li> <li>Detalles:     La consulta utiliza Common Table Expressions (CTE) para:<ul> <li>Definir la subconsulta Encuestas que selecciona columnas transformadas (incluyendo la conversi\u00f3n de FECHA_ENCUESTA a un formato num\u00e9rico para obtener el ID_FECHA).</li> <li>Calcular la informaci\u00f3n de poblaci\u00f3n (IdPoblacion) mediante joins con las dimensiones de empresas, afiliados, beneficiarios y aportantes.</li> <li>Filtrar aquellos registros que a\u00fan no existen en la tabla <code>[Transversal].[FACT_ENCUESTAS]</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET (Actualizacion): </p> <ul> <li>Funci\u00f3n:     Inserta los registros nuevos obtenidos de la consulta en la tabla de destino <code>[Transversal].[FACT_ENCUESTAS]</code>.</li> <li>Configuraci\u00f3n: <ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_ENCUESTAS\"</code></li> <li>BatchSize: 0 (utiliza el tama\u00f1o predeterminado del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>Uso de Bulk Insert: Activado para mejorar el rendimiento en la carga de grandes vol\u00famenes de datos.</li> </ul> </li> </ul> </li> <li> <p>Flujo de Datos y Conexiones: </p> <ul> <li>Origen:     La salida de la consulta SQL (definida en el componente \"Consulta\") provee las columnas transformadas:<ul> <li>FECHA_ENCUESTA</li> <li>ID_FECHA</li> <li>DOCUMENTO</li> <li>PREGUNTA</li> <li>CALIFICACION</li> <li>SERVICIO</li> <li>TIPO_DOCUMENTO</li> <li>NPS</li> <li>ID_UNIDAD</li> <li>ID_AFILIADO</li> <li>ID_BENEFICIARIO</li> <li>ID_APORTANTE</li> </ul> </li> <li>Destino:     La informaci\u00f3n se canaliza hacia el componente de destino ADO.NET, que actualiza la tabla de encuestas, asegurando que s\u00f3lo se inserten los registros que no tengan coincidencias en la tabla de destino.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Consulta as Componente \"Consulta\"\n    participant Destination as Componente \"Actualizacion\" (Destino ADO.NET)\n\n    Consulta -&gt;&gt; Destination: Env\u00eda registros nuevos (sin coincidencias)\n    Destination -&gt;&gt; Destination: Inserta datos en [Transversal].[FACT_ENCUESTAS]</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_encuestas_psr","title":"Componente <code>FACT_ENCUESTAS_PSR</code>,","text":"<p>Forma parte del proceso ETL para la consolidaci\u00f3n de datos de encuestas del \u00e1rea transversal. Este flujo de datos extrae informaci\u00f3n de archivos planos, la transforma y la enriquece mediante diversas conversiones y b\u00fasquedas (Lookups) para, finalmente, cargar los registros resultantes en la tabla destino <code>[Transversal].[FACT_ENCUESTAS_PSR]</code>.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-paquete_3","title":"Prop\u00f3sito del Paquete","text":"<ul> <li> <p>Extracci\u00f3n:   Se utiliza un origen de archivo plano (Flat File Source) que lee datos de encuestas, obteniendo columnas como FECHA_ENCUESTA, DOCUMENTO, TIPO_DOCUMENTO, CALIFICACION, PROGRAMA, ACTIVIDAD_PREGUNTA, NPS, entre otras.</p> </li> <li> <p>Transformaci\u00f3n: </p> <ul> <li>Data Conversion: Convierte los valores de texto (por ejemplo, FECHA_ENCUESTA) a tipos de datos nativos, como <code>dbTimeStamp</code> para fechas, y ajusta la longitud de columnas num\u00e9ricas y de texto.  </li> <li>Lookup:   Se implementan varios componentes de Lookup para enriquecer los datos:</li> <li>Lookup: Consulta la tabla de referencia DIM_TIEMPO para obtener el ID_FECHA bas\u00e1ndose en la FECHA.</li> <li>Lookup 1: Busca en la dimensi\u00f3n de empresas para obtener el ID_EMPRESA, utilizando los campos TIPO_DOCUMENTO y DOCUMENTO.</li> <li>Lookup 2: Une con la dimensi\u00f3n de beneficiarios para extraer el ID_BENEFICIARIO, comparando DOCUMENTO y TIPO_DOCUMENTO.</li> <li>Lookup 3: Se conecta a la dimensi\u00f3n de afiliados para obtener el ID_AFILIADO.</li> <li>Lookup 4: Realiza la b\u00fasqueda en la dimensi\u00f3n de aportantes no afiliados para obtener el ID_APORTANTE, utilizando tambi\u00e9n DOCUMENTO y TIPO_DOCUMENTO.</li> </ul> <p>Cada Lookup compara los registros del flujo de datos con las tablas de referencia y, seg\u00fan la configuraci\u00f3n, env\u00eda las filas sin coincidencias (No Match) a la salida para que puedan ser procesadas o insertadas.</p> </li> <li> <p>Carga:   Los datos transformados y enriquecidos se env\u00edan a un destino ADO.NET, que inserta los registros en la tabla <code>[Transversal].[FACT_ENCUESTAS_PSR]</code>. Este componente utiliza la carga masiva (Bulk Insert) para optimizar el rendimiento, con un CommandTimeout configurado a 30 segundos y sin l\u00edmites en el tama\u00f1o del lote.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant FlatFile as Flat File Source\n    participant Convert as Data Conversion\n    participant Lookup as Varios Lookups\n    participant Destination as Destino ADO.NET\n\n    FlatFile -&gt;&gt; Convert: Lee y convierte datos (FECHA_ENCUESTA, DOCUMENTO, etc.)\n    Convert -&gt;&gt; Lookup: Env\u00eda datos para enriquecimiento mediante Lookups\n    Lookup -&gt;&gt; Destination: Env\u00eda registros enriquecidos (con ID_FECHA, ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE)\n    Destination -&gt;&gt; Destination: Inserta datos en [Transversal].[FACT_ENCUESTAS_PSR]</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/","title":"03. COLEGIO_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#colegio_dimensiones","title":"COLEGIO_DIMENSIONES","text":"<p>El paquete SSIS \"03-COLEGIO_DIMENSIONES\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar informaci\u00f3n relacionada con dimensiones clave del \u00e1mbito educativo, tales como a\u00f1os acad\u00e9micos, planes curriculares, poblaci\u00f3n matriculada y libros. Este paquete asegura un flujo de trabajo robusto y automatizado que consolida datos provenientes de m\u00faltiples fuentes, garantizando su calidad e integridad en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El prop\u00f3sito principal del paquete es estructurar y centralizar datos educativos cr\u00edticos, asegurando su disponibilidad y consistencia para an\u00e1lisis estrat\u00e9gicos y toma de decisiones operativas.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>FACT_ESTADO_MATRICULAS</code>, <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_LIBROS</code>, <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Archivos Excel:</li> <li>Informaci\u00f3n sobre libros (<code>AM-EDF-153</code>).</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB para extracci\u00f3n y carga.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>B\u00fasquedas (<code>Lookup</code>):<ul> <li>Garantiza la consistencia mediante validaciones en tablas maestras como <code>DIM_PLAN_CURRICULAR</code> y <code>DIM_LIBROS</code>.</li> </ul> </li> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Genera claves auxiliares y valores predeterminados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_ANIO_ACADEMICO</code></li> <li><code>DIM_PLAN_CURRICULAR</code></li> <li><code>DIM_LIBROS</code></li> <li><code>DIM_POBLACION_MATRICULA</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Uso de scripts Python para automatizar tareas de descarga y validaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_ANIO_ACADEMICO:</p> <ul> <li><code>ANIO_ACADEMICO</code>: A\u00f1os acad\u00e9micos \u00fanicos extra\u00eddos de <code>FACT_ESTADO_MATRICULAS</code>.</li> </ul> </li> <li> <p>DIM_PLAN_CURRICULAR:</p> <ul> <li><code>COD_ASIGNATURA_SAP</code>, <code>ANIO_ACADEMICO</code>, <code>ASIGNATURA</code>, <code>PLAN_ESTUDIOS</code>.</li> </ul> </li> <li> <p>DIM_LIBROS:</p> <ul> <li><code>CODIGO_BARRAS</code>, <code>ITEM</code>, <code>TITULO</code>, <code>AUTOR</code>.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA:</p> <ul> <li><code>ID_POBLACION_MATRICULA</code>, <code>PARTNER</code>, <code>DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant FACT as FACT_ESTADO_MATRICULAS\n    participant PLAN as DIM_PLAN_CURRICULAR\n    participant LIBROS as DIM_LIBROS\n    participant POBLACION as DIM_POBLACION_MATRICULA\n\n    FACT -&gt;&gt; PLAN: Validaci\u00f3n de a\u00f1os acad\u00e9micos\n    PLAN -&gt;&gt; DIM_PLAN_CURRICULAR: Transformaci\u00f3n y carga\n    LIBROS -&gt;&gt; DIM_LIBROS: Datos transformados\n    POBLACION -&gt;&gt; DIM_POBLACION_MATRICULA: Inserci\u00f3n de datos</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#2-diagrama-er-para-tablas-de-dimensiones","title":"2. Diagrama ER para Tablas de Dimensiones","text":"<pre><code>erDiagram\n    DIM_ANIO_ACADEMICO {\n        int ANIO_ACADEMICO\n    }\n    DIM_PLAN_CURRICULAR {\n        string COD_ASIGNATURA_SAP\n        int ANIO_ACADEMICO\n        string ASIGNATURA\n        string PLAN_ESTUDIOS\n    }\n    DIM_LIBROS {\n        string CODIGO_BARRAS\n        string ITEM\n        string TITULO\n        string AUTOR\n    }\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION_MATRICULA\n        string PARTNER\n        string DOCUMENTO\n        string NOMBRE_COMPLETO\n    }\n    DIM_ANIO_ACADEMICO ||--|| DIM_PLAN_CURRICULAR : \"Relaciona a\u00f1os acad\u00e9micos\"\n    DIM_PLAN_CURRICULAR ||--|| DIM_LIBROS : \"Relaci\u00f3n con libros\"\n    DIM_LIBROS ||--|| DIM_POBLACION_MATRICULA : \"Asociaci\u00f3n de datos\"</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-poblar-dim_anio_academico","title":"Componente <code>Poblar DIM_ANIO_ACADEMICO</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Poblar DIM_ANIO_ACADEMICO</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_ANIO_ACADEMICO</code>. Este flujo incluye procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL) para garantizar datos limpios y estructurados en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>FACT_ESTADO_MATRICULAS</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde la tabla <code>FACT_ESTADO_MATRICULAS</code> en el esquema <code>Colegio</code> para generar un conjunto de a\u00f1os acad\u00e9micos \u00fanicos.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT DISTINCT [CA20_ANO_ACADEMICO] AS ANIO_ACADEMICO \nFROM [DWH_COMFENALCO].[Colegio].[FACT_ESTADO_MATRICULAS]\nORDER BY [CA20_ANO_ACADEMICO] ASC\n</code></pre></li> <li>Tiempo de espera: <code>30 segundos</code>.</li> <li>Permitir conversi\u00f3n impl\u00edcita de cadenas: <code>true</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code> (Tipo: Numeric, Precisi\u00f3n: 4).</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_ANIO_ACADEMICO</code> para determinar si un registro ya existe.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Colegio].[DIM_ANIO_ACADEMICO]\n</code></pre></li> <li>Comportamiento para filas sin coincidencias: Enviar filas a la salida sin coincidencias.</li> <li>Porcentaje de cach\u00e9 para filas sin coincidencias: <code>0%</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>ANIO_ACADEMICO</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code> (Coincidencias y sin coincidencias).</li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Separa los registros en diferentes flujos de datos seg\u00fan la existencia de coincidencias en el paso de b\u00fasqueda.</li> <li>Condiciones:<ul> <li><code>Agregar</code>: Filas donde <code>ANIO_ACADEMICO</code> es nulo (filas nuevas).</li> <li><code>Ya incluido</code>: Filas donde <code>ANIO_ACADEMICO</code> ya existe.</li> <li><code>Conditional Split Error Output</code>: Filas con errores o problemas.</li> </ul> </li> <li>Expresi\u00f3n de condici\u00f3n:     <pre><code>ISNULL(Lookup.ANIO_ACADEMICO)\n</code></pre></li> </ul> </li> <li>Destino de Datos ADO.NET (<code>DIM_ANIO_ACADEMICO</code>)<ul> <li>Descripci\u00f3n: Carga los registros nuevos en la tabla <code>DIM_ANIO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Colegio\".\"DIM_ANIO_ACADEMICO\"</code>.</li> <li>Tama\u00f1o del lote: <code>0</code> (por defecto).</li> <li>Tiempo de espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n masiva: Activada.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>ANIO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-procesar-dim_plan_curricular","title":"Componente <code>Procesar DIM_PLAN_CURRICULAR</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente <code>DIM_PLAN_CURRICULAR</code> es una tarea de flujo de datos en un paquete SSIS que procesa informaci\u00f3n relacionada con el plan curricular de asignaturas. Este flujo realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) para consolidar los datos desde un sistema fuente hacia una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>PLAN_CURRICULAR SAP</code>)</p> <ul> <li>Descripci\u00f3n: Este componente extrae datos desde el sistema SAP ERP, relacionado con asignaturas y planes de estudio.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>WITH Curriculum AS (\nSELECT\n    objid AS ID_PLAN_ESTUDIOS,\n    CASE\n        WHEN objid = '02000000' THEN 'PREESCOLAR'\n        WHEN objid = '02000001' THEN 'PRIMARIA'\n        WHEN objid = '02000003' THEN 'BASICA/MEDIA SECUNDARIA'\n        ELSE 'OTROS'\n    END AS PLAN_ESTUDIOS\nFROM SAPABAP1.HRP1000\nWHERE plvar = '01' -- Plan activos\n    AND Otype = 'SC' -- Plan de estudios\n    AND langu = 'S' -- Espa\u00f1ol\n),\nSubjects as(\nSELECT\n  a.objid AS OBJETO_SAP_ASIGNATURA,\n  a.sobid AS ID_PLAN_ESTUDIOS,\n  b.peryr AS ANIO_ACADEMICO\n FROM SAPABAP1.HRP1001 as a\n INNER join\n  SAPABAP1.HRP1739 as b On a.otype = b.otype AND  A.objid = b.objid\n WHERE a.plvar = '01' and --\u201cPlan activo\n  A.otype = 'SM' and --\u201cEstudios\n  a.sclas = 'SC' and\n  --a.sobid = PE and --(Par\u00e1metros)\n  b.peryr &gt;= 2021 and --(Par\u00e1metro\n  b.perid = '001'-- \u201cPer. Comfenalco\n),\nCurriculumDetails AS (\nSelect\n  aclevelvar AS PROGRAMA_PLAN_ESTUDIOS\n From SAPABAP1.HRP1730\n Where plvar = '01'\n),\nSubjectDetails AS (\n SELECT\n  objid AS OBJETO_SAP_ASIGNATURA,\n  short,\n  stext,\n  --*,\n  CASE\n    WHEN SUBSTRING(SHORT, 1, 2) IN ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11','JD','PJ','TR') THEN\n        CASE SUBSTRING(SHORT, 1, 2)\n            WHEN '01' THEN 1\n            WHEN '02' THEN 2\n            WHEN '03' THEN 3\n            WHEN '04' THEN 4\n            WHEN '05' THEN 5\n            WHEN '06' THEN 6\n            WHEN '07' THEN 10\n            WHEN '08' THEN 11\n            WHEN '09' THEN 12\n            WHEN '10' THEN 13\n            WHEN '11' THEN 14\n            WHEN 'JD' THEN 7\n            WHEN 'PJ' THEN 8\n            WHEN 'TR' THEN 9\n        END\n    ELSE '-1'\nEND AS ID_CURSO,\nCASE\n    WHEN SUBSTRING(SHORT, 1, 2) IN ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11','JD','PJ','TR') THEN\n        CASE SUBSTRING(SHORT, 1, 2)\n            WHEN '01' THEN 'PRIMERO'\n            WHEN '02' THEN 'SEGUNDO'\n            WHEN '03' THEN 'TERCERO'\n            WHEN '04' THEN 'CUARTO'\n            WHEN '05' THEN 'QUINTO'\n            WHEN '06' THEN 'SEXTO'\n            WHEN '07' THEN 'SEPTIMO'\n            WHEN '08' THEN 'OCTAVO'\n            WHEN '09' THEN 'NOVENO'\n            WHEN '10' THEN 'DECIMO'\n            WHEN '11' THEN 'ONCE'\n            WHEN 'JD' THEN 'PREJARD\u00cdN'\n            WHEN 'PJ' THEN 'JARD\u00cdN'\n            WHEN 'TR' THEN 'TRANSICI\u00d3N'\n        END\n    ELSE 'TRANSVERSAL'\nEND AS CURSO\n FROM SAPABAP1.hrp1000\n WHERE otype = 'SM'\n AND plvar = '01'\n)\nSELECT\nsd.short AS COD_ASIGNATURA_SAP,\ns.ANIO_ACADEMICO,\ns.OBJETO_SAP_ASIGNATURA,\nsd.stext AS ASIGNATURA,\nsd.ID_CURSO,\n--sd.CURSO,\ns.ID_PLAN_ESTUDIOS,\nc.PLAN_ESTUDIOS,\nsd.short || '_' || s.ANIO_ACADEMICO AS ID_ASIGNATURA_AUXILIAR\nFROM Subjects AS s\nINNER JOIN Curriculum AS c ON s.ID_PLAN_ESTUDIOS = c.ID_PLAN_ESTUDIOS\nINNER JOIN SubjectDetails AS sd ON s.OBJETO_SAP_ASIGNATURA = sd.OBJETO_SAP_ASIGNATURA\nORDER BY s.ANIO_ACADEMICO,sd.short\n</code></pre></li> <li>Tiempo de espera: <code>30 segundos</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[SAP_ERP]</code>.</li> <li>Columnas de Salida:<ul> <li><code>COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>OBJETO_SAP_ASIGNATURA</code></li> <li><code>ASIGNATURA</code></li> <li><code>ID_CURSO</code></li> <li><code>ID_PLAN_ESTUDIOS</code></li> <li><code>PLAN_ESTUDIOS</code></li> <li><code>ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada para garantizar la compatibilidad con las transformaciones posteriores.</li> <li>Columnas Convertidas:<ul> <li><code>COD_ASIGNATURA_SAP</code> \u2192 <code>Copy of COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code> \u2192 <code>Copy of ANIO_ACADEMICO</code></li> <li><code>OBJETO_SAP_ASIGNATURA</code> \u2192 <code>Copy of OBJETO_SAP_ASIGNATURA</code></li> <li><code>ASIGNATURA</code> \u2192 <code>Copy of ASIGNATURA</code></li> <li><code>ID_CURSO</code> \u2192 <code>Copy of ID_CURSO</code></li> <li><code>ID_PLAN_ESTUDIOS</code> \u2192 <code>Copy of ID_PLAN_ESTUDIOS</code></li> <li><code>PLAN_ESTUDIOS</code> \u2192 <code>Copy of PLAN_ESTUDIOS</code></li> <li><code>ID_ASIGNATURA_AUXILIAR</code> \u2192 <code>Copy of ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una comparaci\u00f3n de los datos con la tabla <code>DIM_PLAN_CURRICULAR</code> para enriquecer los datos en el flujo de trabajo.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT\n    [ID_ASIGNATURA],\n    [COD_ASIGNATURA_SAP],\n    [ANIO_ACADEMICO],\n    [COD_ASIGNATURA_SAP] + '_' + CAST([ANIO_ACADEMICO] AS NVARCHAR) AS ID_ASIGNATURA_AUXILIAR\nFROM [DWH_COMFENALCO].[Colegio].[DIM_PLAN_CURRICULAR]\n</code></pre></li> <li>Comportamiento para filas sin coincidencias: Enviar a la salida \"No Match Output\".</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>Copy of ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_ASIGNATURA</code></li> <li><code>COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_PLAN_CURRICULAR</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>DIM_PLAN_CURRICULAR</code> dentro del esquema <code>Colegio</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>\"Colegio\".\"DIM_PLAN_CURRICULAR\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code>.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activado (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>OBJETO_SAP_ASIGNATURA</code></li> <li><code>ASIGNATURA</code></li> <li><code>ID_CURSO</code></li> <li><code>ID_PLAN_ESTUDIOS</code></li> <li><code>PLAN_ESTUDIOS</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as PLAN_CURRICULAR SAP\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup\n    participant AdoNetDestination as DIM_PLAN_CURRICULAR\n\n    AdoNetSource -&gt;&gt; DataConversion: Salida de origen de ADO NET\n    DataConversion -&gt;&gt; Lookup: Data Conversion Output\n    Lookup -&gt;&gt; AdoNetDestination: Lookup No Match Output</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-truncar-tabla-temporal","title":"Componente <code>Truncar Tabla Temporal</code>","text":"<p>Este componente es una tarea de ejecuci\u00f3n de SQL (Execute SQL Task) en el paquete SSIS, dise\u00f1ada para limpiar la tabla temporal utilizada en el proceso ETL del m\u00f3dulo de Acudientes. Su funci\u00f3n principal es eliminar todos los registros de la tabla <code>[STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]</code> antes de iniciar la carga de nuevos datos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Limpieza de Datos:   El objetivo principal es vaciar la tabla temporal para eliminar registros residuales de ejecuciones anteriores, garantizando que la nueva carga de datos se realice sobre una tabla limpia.</p> </li> <li> <p>Garantizar la Integridad:   Al eliminar todos los datos anteriores, se evita la mezcla de informaci\u00f3n vieja y nueva, lo que contribuye a mantener la precisi\u00f3n y consistencia en el proceso ETL.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute SQL Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>SQL Statement: <pre><code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]\n</code></pre></li> <li>Conexi\u00f3n:   Se utiliza una conexi\u00f3n preconfigurada identificada por el GUID <code>{5972EC76-2533-4771-BB68-A92E1CDD645D}</code>, que apunta a la base de datos de destino.</li> </ul> </li> <li> <p>Datos del Objeto:</p> </li> <li>Conexi\u00f3n Utilizada: <code>{5972EC76-2533-4771-BB68-A92E1CDD645D}</code></li> <li>Sentencia SQL (c\u00f3digo): <pre><code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    Al iniciar el paquete SSIS, se ejecuta la tarea de SQL correspondiente.</p> </li> <li> <p>Ejecuci\u00f3n de la Sentencia SQL:    La sentencia <code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]</code> se env\u00eda a la base de datos mediante el administrador de conexiones configurado.</p> </li> <li> <p>Limpieza de la Tabla:    La tabla temporal se vac\u00eda de forma r\u00e1pida y eficiente, sin registrar individualmente cada eliminaci\u00f3n, lo que mejora el rendimiento.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Una vez completada la operaci\u00f3n, la tarea finaliza, permitiendo que el proceso ETL contin\u00fae con las etapas siguientes de carga y transformaci\u00f3n.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SQLTask as Truncar Tabla Temporal\n    participant DB as Base de Datos\n\n    SQLTask -&gt;&gt; DB: Ejecuta \"TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]\"\n    DB --&gt;&gt; SQLTask: Confirmaci\u00f3n de limpieza</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-consulta-sap","title":"Componente <code>Consulta SAP</code>","text":"<p>Este componente es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS, dise\u00f1ada para extraer y consolidar datos provenientes del sistema SAP. Utiliza una consulta SQL compleja (con m\u00faltiples CTE) para obtener informaci\u00f3n detallada de los acudientes y estudiantes, integrando datos de diversas tablas de SAP y enriqueciendo la informaci\u00f3n mediante c\u00e1lculos y conversiones. La salida de este componente se utiliza para alimentar procesos de integraci\u00f3n posteriores en el flujo ETL.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente_1","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n de Datos desde SAP:   Recuperar informaci\u00f3n relevante de acudientes y estudiantes a partir de m\u00faltiples fuentes de datos en el sistema SAP. Esto incluye datos personales, detalles de contactos (tel\u00e9fonos, direcciones y correos electr\u00f3nicos) y claves de identificaci\u00f3n para su posterior vinculaci\u00f3n en el proceso ETL.</p> </li> <li> <p>Consolidaci\u00f3n y Enriquecimiento:   Unir y transformar datos mediante CTEs para combinar informaci\u00f3n de tablas como HRP1001, BUT000, y otras, integrando adem\u00e1s datos de contactos recientes (tel\u00e9fonos, direcciones y emails) y claves de estudiantes. Esto permite obtener un dataset completo que relaciona la informaci\u00f3n de acudientes con la de estudiantes y sus datos asociados.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica_1","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Data Flow Task (Pipeline).</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>SQL Command:   Se utiliza una instrucci\u00f3n SQL avanzada que emplea Common Table Expressions (CTE) para:</li> <li>PartnerDetails: Extraer detalles del acudiente, incluyendo datos personales, estado civil, profesi\u00f3n y fecha de nacimiento.  </li> <li>RecentPhones, RecentAddresses y RecentEmails: Obtener la informaci\u00f3n de contacto m\u00e1s reciente para cada acudiente.  </li> <li>StudentKeys: Relacionar el acudiente con el estudiante mediante claves SAP.</li> </ul> <p>La consulta finaliza uniendo estos conjuntos de datos para producir un resultado consolidado con campos tales como:   - <code>BP_ACUDIENTE</code>, <code>OBJETO_SAP_ESTUDIANTE</code>, <code>BP_ESTUDIANTE</code>, <code>NUMERO_MATRICULA</code>   - <code>TIPO_DOCUMENTO</code>, <code>NUMERO_DOCUMENTO</code>   - <code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code>   - <code>GENERO</code>, <code>ESTADO_CIVIL</code>, <code>PROFESION</code>, <code>FECHA_NACIMIENTO</code>   - <code>PARENTESCO</code>, <code>RESPONSABLE_JURIDICO</code>   - <code>TELEFONO</code>, <code>PAIS</code>, <code>CIUDAD</code>, <code>DIRECCION</code>, <code>CORREO</code></p> </li> <li> <p>Datos del Objeto:</p> <ul> <li>Conexi\u00f3n Utilizada:   Se conecta al sistema SAP a trav\u00e9s del administrador de conexiones configurado con el identificador de conexi\u00f3n <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code> y el nombre de conexi\u00f3n <code>SAP_ERP</code>.</li> <li>Modo de Acceso:   Utiliza el proveedor de datos .NET (DataReaderSourceAdapter) para ejecutar la consulta y extraer el conjunto de resultados.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion_1","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    El componente inicia la ejecuci\u00f3n de la consulta SQL definida en la propiedad <code>SqlCommand</code>.</p> </li> <li> <p>Extracci\u00f3n y Transformaci\u00f3n:    La consulta se ejecuta contra el sistema SAP y, mediante el uso de CTEs, extrae y transforma los datos, uniendo informaci\u00f3n de diferentes or\u00edgenes (detalles del acudiente, datos de contacto y claves de estudiante).</p> </li> <li> <p>Salida de Datos:    El conjunto de resultados, con las columnas transformadas y consolidadas, se expone en la salida del componente (\"Salida de origen de ADO NET\"), que posteriormente alimenta otros procesos o destinos dentro del flujo ETL.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SAPData as Componente ACUDIENTES SAP\n    participant SAP as Sistema SAP (ERP)\n    participant Dest as Destino de datos (TMP_ACUDIENTES_SAP)\n\n    SAPData -&gt;&gt; SAP: Ejecuta consulta SQL consolidada\n    SAP --&gt;&gt; SAPData: Retorna conjunto de resultados con datos de acudientes y estudiantes\n    SAPData -&gt;&gt; Dest: Transfiere datos transformados para carga posterior</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-actualizar-dim_acudientes","title":"Componente <code>Actualizar DIM_ACUDIENTES</code>","text":"<p>Este componente es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS, dise\u00f1ada para actualizar la dimensi\u00f3n de acudientes en el \u00e1mbito Colegio. Su funci\u00f3n principal es leer los datos consolidados en la tabla temporal de staging (<code>TMP_ACUDIENTES_SAP</code>), compararlos con la dimensi\u00f3n existente (<code>DIM_ACUDIENTES</code>) y cargar \u00fanicamente los registros nuevos o actualizados en la tabla de destino. Esto garantiza la integridad y actualizaci\u00f3n de la informaci\u00f3n de acudientes en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente_2","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Integraci\u00f3n de Datos de Acudientes:   Actualizar la dimensi\u00f3n <code>DIM_ACUDIENTES</code> en el esquema Colegio, asegur\u00e1ndose de que s\u00f3lo se inserten los registros nuevos o modificados que no est\u00e9n ya presentes en la dimensi\u00f3n. Esto permite mantener una base de datos actualizada y libre de duplicidades.</p> </li> <li> <p>Validaci\u00f3n y Consolidaci\u00f3n de la Informaci\u00f3n:   El proceso realiza una comparaci\u00f3n entre los datos provenientes de la tabla temporal en staging y la dimensi\u00f3n existente para filtrar registros ya cargados, permitiendo la actualizaci\u00f3n s\u00f3lo de la informaci\u00f3n faltante o modificada.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica_2","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Data Flow Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>Destino de ADO NET:   Se utiliza un componente de destino ADO.NET para cargar los registros en la tabla de destino.</li> <li>TableOrViewName:     La tabla destino se define mediante la expresi\u00f3n:     <pre><code>\"Colegio\".\"DIM_ACUDIENTES\"\n</code></pre></li> <li>BatchSize:     Se configura a <code>0</code>, utilizando el tama\u00f1o del b\u00fafer interno de SSIS.</li> <li>CommandTimeout:     Establecido en <code>30</code> segundos.</li> <li>UseBulkInsertWhenPossible:     Activado para mejorar el rendimiento durante la inserci\u00f3n masiva de datos.</li> </ul> </li> <li> <p>Conexi\u00f3n:     La tarea se conecta a la base de datos destino mediante el administrador de conexiones configurado con el identificador <code>{C2A27DDB-56C2-4889-8A4B-7AA7124DFFD7}</code> y el nombre de conexi\u00f3n <code>DWH_COMFENALCO_Destino</code>.</p> </li> <li> <p>Origen de Datos:     El componente extrae los datos desde la tabla temporal <code>[STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]</code> mediante un origen ADO.NET. La consulta de origen realiza un LEFT JOIN con la dimensi\u00f3n existente <code>[Colegio].[DIM_ACUDIENTES]</code> y un INNER JOIN con <code>[DIM_POBLACION_MATRICULA]</code> para asegurar que:</p> <ul> <li>Se seleccionen \u00fanicamente los registros en los que no existe coincidencia en <code>DIM_ACUDIENTES</code> (es decir, los registros nuevos).</li> <li>Se asegure que el campo <code>ID_POBLACION_MATRICULA</code> tenga un valor v\u00e1lido.</li> </ul> </li> <li> <p>Flujo de Datos:   Los datos fluyen desde el origen (la consulta en la tabla temporal) hacia el destino de ADO.NET, garantizando que s\u00f3lo se carguen los registros que a\u00fan no han sido incorporados en la dimensi\u00f3n.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion_2","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Extracci\u00f3n de Datos:    El componente de origen ADO.NET ejecuta la consulta SQL para leer los datos desde <code>[STAGE_AREA].[Transversal].[TMP_ACUDIENTES_SAP]</code> que cumplen las condiciones de actualizaci\u00f3n.</p> </li> <li> <p>Validaci\u00f3n de Registros:    Se realiza un cruce impl\u00edcito (mediante la consulta SQL) que descarta los registros cuyo <code>BP_ESTUDIANTE</code> ya existe en la dimensi\u00f3n <code>[Colegio].[DIM_ACUDIENTES]</code> y que garantiza que <code>ID_POBLACION_MATRICULA</code> sea v\u00e1lido.</p> </li> <li> <p>Carga de Datos:    Los registros que cumplen con las condiciones (nuevos o no encontrados en la dimensi\u00f3n) se cargan en la tabla <code>\"Colegio\".\"DIM_ACUDIENTES\"</code> utilizando la opci\u00f3n de Bulk Insert para optimizar el rendimiento.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen de ADO NET (TMP_ACUDIENTES_SAP)\n    participant Transform as Proceso de Validaci\u00f3n y Filtrado\n    participant Dest as Destino de ADO NET (DIM_ACUDIENTES)\n\n    Origen -&gt;&gt; Transform: Extrae datos desde TMP_ACUDIENTES_SAP\n    Transform -&gt;&gt; Transform: Compara registros con DIM_ACUDIENTES y DIM_POBLACION_MATRICULA\n    Transform -&gt;&gt; Dest: Env\u00eda registros nuevos para inserci\u00f3n\n    Dest -&gt;&gt; Dest: Inserta datos en \"Colegio\".\"DIM_ACUDIENTES\"</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-descargar_am-edf-153","title":"Componente <code>Descargar_AM-EDF-153</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_AM-EDF-153</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para conectar a SharePoint y descargar archivos manuales relacionados con el proyecto. Esta tarea utiliza la funcionalidad <code>Execute Process</code> de SSIS para garantizar una integraci\u00f3n fluida con sistemas externos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#detalles-del-componente","title":"Detalles del Componente","text":"<ol> <li> <p>Identificador del Componente:</p> <ul> <li>DTSID: <code>{dc092a95-1b4b-442c-9f34-b34054bbb72d}</code></li> </ul> </li> <li> <p>Tipo de Componente:</p> <ul> <li><code>Microsoft.ExecuteProcess</code></li> </ul> </li> <li> <p>Descripci\u00f3n:</p> <ul> <li>Tarea dise\u00f1ada para ejecutar un proceso externo, en este caso, un script Python que se conecta a SharePoint y descarga los archivos requeridos.</li> </ul> </li> <li> <p>Propiedades:</p> <ul> <li>Executable:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>WorkingDirectory:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\04.Colegio\n</code></pre></li> <li>Arguments:      <pre><code>01.SharePoint_Connection_AM-EDF-153.py\n</code></pre></li> </ul> </li> </ol> <p>Propiedades Avanzadas</p> <ol> <li> <p>Configuraciones de Expresi\u00f3n:</p> <ul> <li>Executable:      <pre><code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"\n</code></pre></li> <li>WorkingDirectory:      <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\04.Colegio\"\n</code></pre></li> </ul> </li> <li> <p>Detalles del Proceso:</p> <ul> <li>Ejecutable:<ul> <li>Ubicaci\u00f3n del script de Python a ejecutar.</li> </ul> </li> <li>Argumentos:<ul> <li>Nombre del archivo de script: <code>01.SharePoint_Connection_AM-EDF-153.py</code>.</li> </ul> </li> <li>Directorio de Trabajo:<ul> <li>Ruta donde se encuentra el script y los archivos necesarios para su ejecuci\u00f3n.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as Script de Python\n    participant SharePoint as Servidor SharePoint\n\n    SSIS-&gt;&gt;Python: Ejecutar `01.SharePoint_Connection_AM-EDF-153.py`\n    Python-&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Python: Confirmar conexi\u00f3n\n    Python-&gt;&gt;SharePoint: Descargar archivos\n    SharePoint--&gt;&gt;Python: Retornar archivos descargados\n    Python--&gt;&gt;SSIS: Confirmar finalizaci\u00f3n del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-procesar-dim_libros","title":"Componente <code>Procesar DIM_LIBROS</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar DIM_LIBROS</code> es una tarea de flujo de datos en un paquete SSIS que realiza operaciones ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) sobre informaci\u00f3n de libros. Los datos son extra\u00eddos desde un archivo de Excel, transformados mediante conversiones y columnas derivadas, y finalmente cargados en una base de datos destino. Adicionalmente, el flujo incluye una operaci\u00f3n de b\u00fasqueda (<code>Lookup</code>) para enriquecer los datos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>AM-EDF-153</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde una hoja de c\u00e1lculo Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code> (Modo de acceso directo)</li> <li><code>CommandTimeout</code>: <code>0</code> (Sin l\u00edmite de tiempo)</li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: Conexi\u00f3n a Excel referenciada por el administrador de conexiones <code>Excel_Connection_Dim_Libros</code>.</li> </ul> </li> <li>Columnas de Salida:     <code>CODIGO_BARRAS</code>, <code>ITEM</code>, <code>AUTOR</code>, <code>TITULO</code>.</li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte las columnas de datos para garantizar compatibilidad con los componentes posteriores.</li> <li>Columnas de Entrada:     <code>CODIGO_BARRAS</code>, <code>ITEM</code>, <code>AUTOR</code>, <code>TITULO</code>.</li> <li>Columnas de Salida:     <code>Copy of CODIGO_BARRAS</code>, <code>Copy of ITEM</code>, <code>Copy of AUTOR</code>, <code>Copy of TITULO</code>.</li> </ul> </li> <li> <p>Columna Derivada (<code>ID_LIBRO_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_LIBRO_AUXILIAR</code> combinando <code>CODIGO_BARRAS</code> e <code>ITEM</code>.</li> <li>Expresi\u00f3n Derivada:      <pre><code>CODIGO_BARRAS + \"_\" + ITEM\n</code></pre></li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_LIBROS</code> para enriquecer los datos con informaci\u00f3n adicional.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_LIBRO], [CODIGO_BARRAS]+'_'+[ITEM] AS ID_LIBRO_AUXILIAR\nFROM [DWH_COMFENALCO].[Colegio].[DIM_LIBROS]\n</code></pre></li> </ul> </li> <li>Columnas de Salida:     <code>ID_LIBRO</code>, <code>ID_LIBRO_AUXILIAR</code>.</li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_LIBROS</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>DIM_LIBROS</code> en la base de datos destino.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"DIM_LIBROS\"</code></li> <li><code>BatchSize</code>: <code>0</code> (Predeterminado)</li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Columnas de Entrada:     <code>Copy of CODIGO_BARRAS</code>, <code>Copy of ITEM</code>, <code>Copy of AUTOR</code>, <code>Copy of TITULO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as AM-EDF-153 (Fuente Excel)\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as ID_LIBRO_AUXILIAR\n    participant Lookup as Lookup\n    participant AdoNetDestination as DIM_LIBROS (Destino)\n\n    ExcelSource-&gt;&gt;DataConversion: Salida de datos Excel\n    DataConversion-&gt;&gt;DerivedColumn: Salida de datos convertidos\n    DerivedColumn-&gt;&gt;Lookup: Salida de columna derivada\n    Lookup-&gt;&gt;AdoNetDestination: Salida de b\u00fasqueda no coincidente</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-validar-si-existe-tabla-para-guardar","title":"Componente <code>Validar si existe tabla para guardar</code>","text":"<p>Este componente es una tarea de ejecuci\u00f3n de SQL (Execute SQL Task) dentro del paquete SSIS \"Procedimiento y Tabla para FACT_RETIROS\". Su funci\u00f3n es verificar si existe una tabla denominada RESULTS en el esquema actual y, en caso de que no exista, crearla. Esto asegura que, antes de iniciar el proceso de carga de datos para FACT_RETIROS, exista la estructura necesaria para almacenar los resultados.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente_3","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Verificaci\u00f3n y Creaci\u00f3n de Estructura:   Asegurarse de que la tabla RESULTS est\u00e9 presente en el entorno, creando la tabla si no existe, para evitar errores en fases posteriores del proceso ETL.</p> </li> <li> <p>Preparaci\u00f3n del Entorno de Carga:   Automatizar la validaci\u00f3n y provisi\u00f3n de la infraestructura de datos necesaria para la integraci\u00f3n y almacenamiento de la informaci\u00f3n de FACT_RETIROS.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica_3","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute SQL Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>SqlStatementSource:   El componente ejecuta la siguiente sentencia SQL para validar y crear la tabla en caso de ausencia:   <pre><code>-- Verificar si la tabla 'RESULTS' existe y crearla si no es as\u00ed\nDO\nBEGIN\n    DECLARE table_count INT;\n\n    SELECT COUNT(*) INTO table_count\n    FROM TABLES\n    WHERE TABLE_NAME = 'RESULTS' AND SCHEMA_NAME = CURRENT_SCHEMA;\n\n    IF table_count = 0 THEN\n        EXEC 'CREATE TABLE RESULTS (\n                OBJETO_SAP_ESTUDIANTE VARCHAR(20),\n                NUMERO_MATRICULA VARCHAR(20),\n                PARTNER_ESTUDIANTE VARCHAR(20),\n                ANIO_ACADEMICO VARCHAR(20),\n                APELLIDOS VARCHAR(50),\n                NOMBRES VARCHAR(50),\n                CURSO VARCHAR(20),\n                GRADO VARCHAR(20),\n                FECHA_RETIRO_SAP DATE,\n                FECHA_VALIDO_DESDE DATE,\n                FECHA_VALIDO_HASTA DATE\n              );';\n    END IF;\nEND;\n</code></pre></li> <li>Conexi\u00f3n:   Utiliza una conexi\u00f3n preconfigurada (identificada mediante el GUID <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>) que apunta al servidor de base de datos adecuado para ejecutar la sentencia SQL.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion_3","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    Al iniciar el paquete, se ejecuta la tarea de SQL para validar la existencia de la tabla RESULTS.</p> </li> <li> <p>Verificaci\u00f3n en la Base de Datos:    La tarea consulta el sistema de tablas para contar cu\u00e1ntas tablas con el nombre RESULTS existen en el esquema actual.</p> </li> <li> <p>Creaci\u00f3n Condicional:    Si el resultado es 0 (es decir, la tabla no existe), se ejecuta el comando SQL para crear la tabla con las columnas especificadas.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Tras la verificaci\u00f3n (y creaci\u00f3n, de ser necesaria), la tarea finaliza, permitiendo que el flujo ETL contin\u00fae con los siguientes pasos.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQLTask as Execute SQL Task\n    participant DB as Base de Datos\n\n    SSIS -&gt;&gt; SQLTask: Inicia \"Validar si existe tabla para guardar\"\n    SQLTask -&gt;&gt; DB: Ejecuta SQL para verificar existencia de \"RESULTS\"\n    DB --&gt;&gt; SQLTask: Devuelve el conteo de tablas\n    SQLTask -&gt;&gt; DB: Si no existe, ejecuta comando CREATE TABLE\n    DB --&gt;&gt; SQLTask: Confirma creaci\u00f3n (o existencia) de la tabla\n    SQLTask -&gt;&gt; SSIS: Finaliza la tarea</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-crear-procedimiento-anual","title":"Componente <code>Crear procedimiento anual</code>","text":"<p>Este componente es una tarea de ejecuci\u00f3n de SQL (Execute SQL Task) dentro del paquete SSIS \"Procedimiento y Tabla para FACT_RETIROS\". Su funci\u00f3n es verificar si existe el procedimiento almacenado GetRetirosByYear en el esquema actual y, de no existir, crearlo. Este procedimiento se utiliza para obtener los retiros filtrados por a\u00f1o, lo cual es fundamental para el proceso ETL relacionado con FACT_RETIROS.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-componente_4","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Verificaci\u00f3n y Creaci\u00f3n de Procedimiento:   Se asegura que el procedimiento GetRetirosByYear est\u00e9 definido en la base de datos antes de proceder con las operaciones de carga y procesamiento de datos de retiros.</p> </li> <li> <p>Preparaci\u00f3n del Entorno ETL:   Automatiza la creaci\u00f3n del procedimiento almacenado en caso de ausencia, lo que evita fallos en etapas posteriores del flujo ETL.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-tecnica_4","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute SQL Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>SqlStatementSource:   El componente ejecuta la siguiente sentencia SQL para verificar y crear el procedimiento:   <pre><code>-- Verificar si el procedimiento 'GetRetirosByYear' existe y crearlo si no es as\u00ed\nDO\nBEGIN\n    DECLARE proc_count INT;\n\n    SELECT COUNT(*) INTO proc_count\n    FROM PROCEDURES\n    WHERE PROCEDURE_NAME = 'GETRETIROSBYYEAR' AND SCHEMA_NAME = CURRENT_SCHEMA;\n\n    IF proc_count = 0 THEN\n        EXEC 'CREATE PROCEDURE GetRetirosByYear (IN P_YEAR INT)\n               LANGUAGE SQLSCRIPT\n               AS\n               BEGIN\n                   DECLARE valid_from_date NVARCHAR(8); \n                   valid_from_date := CONCAT(P_YEAR, ''0101'');\n                   INSERT INTO RESULTS\n                   SELECT \n                       DISTINCT \n                       h.objid AS OBJETO_SAP_ESTUDIANTE,\n                       p.short AS NUMERO_MATRICULA,\n                       b.PARTNER AS PARTNER_ESTUDIANTE,\n                       o.ayear AS ANIO_ACADEMICO,\n                       h.nachn AS APELLIDOS,\n                       h.vorna AS NOMBRES,\n                       i.prcl AS ID_CURSO,\n                       j.matrikel AS GRADO,\n                       m.END_KEY_DATE AS FECHA_RETIRO_SAP,\n                       i.mc_valid_from AS FECHA_VALIDO_DESDE,\n                       i.mc_valid_to AS FECHA_VALIDO_HASTA\n                   FROM SAPABAP1.hrp1702 AS h\n                   INNER JOIN SAPABAP1.hrp1000 AS p ON h.plvar = p.plvar AND h.otype = p.otype AND h.objid = p.objid AND h.endda = p.endda\n                   INNER JOIN SAPABAP1.hrp1705 AS j ON h.plvar = j.plvar AND h.otype = j.otype AND h.objid = j.objid AND h.endda = j.endda\n                   INNER JOIN SAPABAP1.hrp1737 AS k ON j.plvar = k.plvar AND j.otype = k.otype AND j.objid = k.objid AND j.endda = k.endda\n                   INNER JOIN SAPABAP1.hrt1737 AS i ON k.tabnr = i.tabnr\n                   INNER JOIN SAPABAP1.hrp1001 AS l ON l.plvar = h.plvar AND l.otype = h.otype AND l.objid = h.objid AND l.endda = h.endda\n                   INNER JOIN SAPABAP1.hrp1001 AS n ON n.plvar = l.plvar AND n.otype = l.sclas AND n.objid = l.sobid AND n.endda = l.endda\n                   INNER JOIN SAPABAP1.hrp1769 AS m ON m.plvar = n.plvar AND m.otype = n.otype AND m.objid = n.objid\n                   INNER JOIN SAPABAP1.hrp1771 AS o ON o.plvar = n.plvar AND o.otype = n.otype AND o.objid = n.objid\n                   INNER JOIN SAPABAP1.CMACBPST as b On p.objid = b.stobjid\n                   WHERE\n                       l.sclas = ''CS'' AND\n                       n.sclas = ''SC'' AND\n                       p.otype = ''ST'' AND\n                       p.plvar = ''01'' AND\n                       i.mc_valid_to &gt;= CURDATE() AND\n                       i.prog_type = ''4'' AND\n                       i.valid_from = valid_from_date AND\n                       m.begda &lt;= CURDATE() AND\n                       m.endda &lt;= CURDATE() AND\n                       o.prs_state = ''A'' AND\n                       o.ayear = P_YEAR AND\n                       m.END_PROCESS = ''RW01'' AND\n                       m.END_KEY_DATE &gt;= i.valid_from;\n               END;';\n    END IF;\nEND;\n</code></pre></li> <li>Conexi\u00f3n:   Se utiliza una conexi\u00f3n preconfigurada (identificada mediante el GUID <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>) que apunta al servidor de base de datos donde se encuentra el procedimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#flujo-de-ejecucion_4","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Inicio de la Tarea:    El paquete SSIS inicia la tarea de SQL \"Crear procedimiento anual\".</p> </li> <li> <p>Verificaci\u00f3n del Procedimiento:    La tarea consulta el cat\u00e1logo de procedimientos para determinar si GETRETIROSBYYEAR ya existe en el esquema actual.</p> </li> <li> <p>Creaci\u00f3n Condicional: </p> <ul> <li>Si el procedimiento no existe (conteo igual a 0), se ejecuta el comando SQL para crear el procedimiento almacenado con la definici\u00f3n especificada.</li> <li>Si ya existe, no se realiza ninguna acci\u00f3n adicional.</li> </ul> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    La tarea finaliza y el proceso ETL puede continuar con las siguientes etapas, sabiendo que la estructura necesaria para procesar los retiros est\u00e1 en su lugar.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQLTask as Execute SQL Task\n    participant DB as Base de Datos\n\n    SSIS -&gt;&gt; SQLTask: Inicia \"Crear procedimiento anual\"\n    SQLTask -&gt;&gt; DB: Ejecuta SQL para verificar existencia de 'GETRETIROSBYYEAR'\n    DB --&gt;&gt; SQLTask: Devuelve conteo de procedimientos\n    SQLTask -&gt;&gt; DB: Si no existe, ejecuta comando CREATE PROCEDURE\n    DB --&gt;&gt; SQLTask: Confirma creaci\u00f3n (o existencia) del procedimiento\n    SQLTask -&gt;&gt; SSIS: Finaliza la tarea</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/","title":"03 COLEGIO DIMENSIONES AUXILIAR","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#colegio_dimensiones_auxiliar","title":"COLEGIO_DIMENSIONES_AUXILIAR","text":"<p>El paquete SSIS \"03-COLEGIO_DIMENSIONES_AUXILIAR\" est\u00e1 dise\u00f1ado para gestionar la transferencia, transformaci\u00f3n y carga (ETL) de datos educativos relacionados con cursos, grados, poblaciones matriculadas y dimensiones de tiempo. Este paquete asegura que los datos provenientes de ambientes remotos se integren eficientemente en el Data Warehouse <code>DWH_COMFENALCO</code>, garantizando su calidad y disponibilidad para an\u00e1lisis.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es sincronizar y centralizar datos de dimensiones educativas clave, asegurando la consistencia y calidad de la informaci\u00f3n en el Data Warehouse. Esto facilita la toma de decisiones basada en datos para an\u00e1lisis operativos y estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos Remotas:</li> <li><code>DIM_CURSO</code>, <code>DIM_GRADO</code>, <code>DIM_POBLACION_MATRICULA</code>, <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET para lectura de datos remotos.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaci\u00f3n de Registros:<ul> <li>Se asegura que los datos est\u00e9n completos antes de cargarlos.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con las tablas destino.</li> </ul> </li> <li>Inserciones Masivas (<code>Bulk Insert</code>):<ul> <li>Habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_CURSO</code></li> <li><code>DIM_GRADO</code></li> <li><code>DIM_POBLACION_MATRICULA</code></li> <li><code>DIM_TIEMPO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_CURSO:</p> <ul> <li><code>ID_CURSO</code>, <code>DESC_CURSO</code>, <code>FECHA_CREACION</code>, <code>ESTADO_REGISTRO</code>.</li> </ul> </li> <li> <p>DIM_GRADO:</p> <ul> <li><code>ID_GRADO</code>, <code>DESC_GRADO</code>, <code>FECHA_CREACION</code>, <code>ESTADO_REGISTRO</code>.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA:</p> <ul> <li><code>ID_POBLACION_MATRICULA</code>, <code>PARTNER</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>, <code>GENERO</code>, <code>DIRECCION</code>, <code>TELEFONO</code>, <code>CORREO</code>, <code>FECHA_NACIMIENTO</code>.</li> </ul> </li> <li> <p>DIM_TIEMPO:</p> <ul> <li><code>ID_FECHA</code>, <code>FECHA</code>, <code>DESC_FECHA</code>, <code>ID_SEMANA</code>, <code>DESC_SEMANA</code>, <code>ID_MES</code>, <code>DESC_MES</code>, <code>ID_ANIO</code>, <code>FESTIVO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant CURSO_ORIG as DIM_CURSO_ORIG\n    participant CURSO_DEST as DIM_CURSO_DEST\n    participant GRADO_ORIG as DIM_GRADO_ORIG\n    participant GRADO_DEST as DIM_GRADO_DEST\n    participant POB_ORIG as DIM_POBLACION_MATRICULA_ORIG\n    participant POB_DEST as DIM_POBLACION_MATRICULA_DEST\n    participant TIEMPO_ORIG as DIM_TIEMPO_ORIG\n    participant TIEMPO_DEST as DIM_TIEMPO_DEST\n\n    CURSO_ORIG -&gt;&gt; CURSO_DEST: Transferir datos de DIM_CURSO\n    GRADO_ORIG -&gt;&gt; GRADO_DEST: Transferir datos de DIM_GRADO\n    POB_ORIG -&gt;&gt; POB_DEST: Transferir datos de DIM_POBLACION_MATRICULA\n    TIEMPO_ORIG -&gt;&gt; TIEMPO_DEST: Transferir datos de DIM_TIEMPO</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#2-diagrama-er-para-tablas-de-dimensiones","title":"2. Diagrama ER para Tablas de Dimensiones","text":"<pre><code>erDiagram\n    DIM_CURSO {\n        int ID_CURSO\n        string DESC_CURSO\n        date FECHA_CREACION\n        string ESTADO_REGISTRO\n    }\n    DIM_GRADO {\n        int ID_GRADO\n        string DESC_GRADO\n        date FECHA_CREACION\n        string ESTADO_REGISTRO\n    }\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION_MATRICULA\n        string PARTNER\n        string TIPO_DOCUMENTO\n        string DOCUMENTO\n        string NOMBRE_COMPLETO\n        string GENERO\n        string DIRECCION\n        string TELEFONO\n        string CORREO\n        date FECHA_NACIMIENTO\n    }\n    DIM_TIEMPO {\n        int ID_FECHA\n        date FECHA\n        string DESC_FECHA\n        int ID_SEMANA\n        string DESC_SEMANA\n        int ID_MES\n        string DESC_MES\n        int ID_ANIO\n        boolean FESTIVO\n    }</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componente-traer-a-local-tablas-disponibles-en-ambiente-comfenalco","title":"Componente <code>Traer a local tablas disponibles en ambiente Comfenalco</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Traer a local tablas disponibles en ambiente Comfenalco</code> es una tarea de flujo de datos en un paquete SSIS que transfiere datos desde un origen en un ambiente remoto hacia tablas de destino en un ambiente local. Est\u00e1 dise\u00f1ado para extraer, transformar y cargar (ETL) datos de m\u00faltiples tablas relacionadas con cursos, grados y poblaciones matriculadas.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>DIM_CURSO_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de la tabla <code>[Colegio].[DIM_CURSO]</code> en un origen remoto utilizando ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Colegio].[DIM_CURSO]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_CURSO</code></li> <li><code>DESC_CURSO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_CURSO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos transformados en la tabla <code>[Colegio].[DIM_CURSO]</code> del ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Colegio\".\"DIM_CURSO\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_CURSO</code></li> <li><code>DESC_CURSO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos ADO.NET (<code>DIM_GRADO_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de la tabla <code>[Colegio].[DIM_GRADO]</code> en un origen remoto utilizando ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Colegio].[DIM_GRADO]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_GRADO</code></li> <li><code>DESC_GRADO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_GRADO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos transformados en la tabla <code>[Colegio].[DIM_GRADO]</code> del ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Colegio\".\"DIM_GRADO\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_GRADO</code></li> <li><code>DESC_GRADO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos ADO.NET (<code>DIM_POBLACION_MATRICULA_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code> en un origen remoto utilizando ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_POBLACION_MATRICULA</code></li> <li><code>PARTNER</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>GENERO</code></li> <li><code>DIRECCION</code></li> <li><code>TELEFONO</code></li> <li><code>CORREO</code></li> <li><code>FECHA_NACIMIENTO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_POBLACION_MATRICULA_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos transformados en la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code> del ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Colegio\".\"DIM_POBLACION_MATRICULA\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_POBLACION_MATRICULA</code></li> <li><code>PARTNER</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>GENERO</code></li> <li><code>DIRECCION</code></li> <li><code>TELEFONO</code></li> <li><code>CORREO</code></li> <li><code>FECHA_NACIMIENTO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#conexiones-entre-componentes","title":"Conexiones entre Componentes","text":"<ol> <li>DIM_CURSO_ORIG \u2192 DIM_CURSO_DEST </li> <li>DIM_GRADO_ORIG \u2192 DIM_GRADO_DEST </li> <li>DIM_POBLACION_MATRICULA_ORIG \u2192 DIM_POBLACION_MATRICULA_DEST</li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant CURSO_ORIG as DIM_CURSO_ORIG\n    participant CURSO_DEST as DIM_CURSO_DEST\n    participant GRADO_ORIG as DIM_GRADO_ORIG\n    participant GRADO_DEST as DIM_GRADO_DEST\n    participant POB_ORIG as DIM_POBLACION_MATRICULA_ORIG\n    participant POB_DEST as DIM_POBLACION_MATRICULA_DEST\n\n    CURSO_ORIG -&gt;&gt; CURSO_DEST: Transferencia de datos DIM_CURSO\n    GRADO_ORIG -&gt;&gt; GRADO_DEST: Transferencia de datos DIM_GRADO\n    POB_ORIG -&gt;&gt; POB_DEST: Transferencia de datos DIM_POBLACION_MATRICULA</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componente-traer-dim-tiempo-a-local","title":"Componente <code>Traer Dim Tiempo a Local</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente <code>Traer Dim Tiempo a Local</code> es un flujo de datos en SSIS dise\u00f1ado para transferir y cargar datos de la dimensi\u00f3n <code>DIM_TIEMPO</code> desde un ambiente remoto hacia un ambiente local. Este flujo est\u00e1 deshabilitado por defecto (<code>Disabled=\"True\"</code>), y su objetivo principal es mantener sincronizados los datos de tiempo.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>DIM_TIEMPO_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos de la tabla <code>[Dwh].[DIM_TIEMPO]</code> en un origen remoto utilizando una conexi\u00f3n ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Dwh].[DIM_TIEMPO]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:  <code>ID_FECHA</code>, <code>FECHA</code>, <code>DESC_FECHA</code>, <code>ID_SEMANA</code>, <code>DESC_SEMANA</code>, <code>ID_NO_MES</code>, <code>DESC_NO_MES</code>, <code>ID_MES</code>, <code>DESC_MES</code>, <code>DESC_MES_CORTA</code>, <code>ID_BIMESTRE</code>, <code>DESC_BIMESTRE</code>, <code>ID_TRIMESTRE</code>, <code>DESC_TRIMESTRE</code>, <code>ID_CUATRIMESTRE</code>, <code>DESC_CUATRIMESTRE</code>, <code>ID_SEMESTRE</code>, <code>DESC_SEMESTRE</code>, <code>ID_ANIO</code>, <code>ID_ANIO_ANT</code>, <code>NUM_DIA_SEMANA</code>, <code>FESTIVO</code>, <code>FECHA_CORTA</code></li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_TIEMPO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos extra\u00eddos y transformados en la tabla <code>[Dwh].[DIM_TIEMPO]</code> en el ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Dwh\".\"DIM_TIEMPO\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada: <code>ID_FECHA</code>, <code>FECHA</code>, <code>DESC_FECHA</code>, <code>ID_SEMANA</code>, <code>DESC_SEMANA</code>, <code>ID_NO_MES</code>, <code>DESC_NO_MES</code>, <code>ID_MES</code>, <code>DESC_MES</code>, <code>DESC_MES_CORTA</code>, <code>ID_BIMESTRE</code>, <code>DESC_BIMESTRE</code>, <code>ID_TRIMESTRE</code>, <code>DESC_TRIMESTRE</code>, <code>ID_CUATRIMESTRE</code>, <code>DESC_CUATRIMESTRE</code>, <code>ID_SEMESTRE</code>, <code>DESC_SEMESTRE</code>, <code>ID_ANIO</code>, <code>ID_ANIO_ANT</code>, <code>NUM_DIA_SEMANA</code>, <code>FESTIVO</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#conexiones-entre-componentes_1","title":"Conexiones entre Componentes","text":"<ol> <li>DIM_TIEMPO_ORIG \u2192 DIM_TIEMPO_DEST</li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant TIEMPO_ORIG as DIM_TIEMPO_ORIG\n    participant TIEMPO_DEST as DIM_TIEMPO_DEST\n\n    TIEMPO_ORIG -&gt;&gt; TIEMPO_DEST: Transferencia de datos DIM_TIEMPO</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/","title":"04. COLEGIO_FACT","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#colegio_fact","title":"COLEGIO_FACT","text":"<p>El paquete SSIS \"04-COLEGIO_FACT\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar datos cr\u00edticos relacionados con operaciones educativas en diversas \u00e1reas como matr\u00edculas, transporte, biblioteca y evaluaciones. Este paquete asegura la integraci\u00f3n efectiva de datos en el Data Warehouse <code>DWH_COMFENALCO</code>, garantizando su calidad y disponibilidad para an\u00e1lisis y reportes estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es consolidar informaci\u00f3n operativa y educativa para apoyar la toma de decisiones basada en datos. Esto incluye la transformaci\u00f3n de datos de diversas fuentes, su validaci\u00f3n y enriquecimiento antes de su carga en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos SAP y SQL Server:</li> <li><code>FACT_TRANSPORTE</code>, <code>FACT_CUPOS_NEGADOS</code>, <code>FACT_AUSENTISMO_DOCENTE</code>, <code>FACT_BIBLIOTECA</code>.</li> <li>Archivos Excel:</li> <li>Informaci\u00f3n de permisos, ausentismo, y evaluaciones.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB para extracci\u00f3n y carga.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaci\u00f3n de Datos (<code>Lookup</code>):<ul> <li>Comprobaci\u00f3n en tablas maestras como <code>DIM_POBLACION_MATRICULA</code>, <code>DIM_CURSO</code>, y <code>DIM_LIBROS</code>.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>C\u00e1lculo de identificadores \u00fanicos y asignaciones condicionales.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>FACT_TRANSPORTE</code></li> <li><code>FACT_CUPOS_NEGADOS</code></li> <li><code>FACT_BIBLIOTECA</code></li> <li><code>FACT_PERMISO_ESTUDIANTE</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Uso de scripts Python para automatizaci\u00f3n de descargas y validaci\u00f3n de datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>FACT_TRANSPORTE:</p> <ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ID_FECHA</code>, <code>ANIO_ACADEMICO</code>, <code>CATEGORIA_SERVICIO</code>.</li> </ul> </li> <li> <p>FACT_CUPOS_NEGADOS:</p> <ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_ESTADO</code>.</li> </ul> </li> <li> <p>FACT_BIBLIOTECA:</p> <ul> <li><code>ITEM_LIBRO</code>, <code>FECHA_PRESTAMO</code>, <code>FECHA_DEVOLUCION</code>, <code>BP_ESTUDIANTE</code>.</li> </ul> </li> <li> <p>FACT_PERMISO_ESTUDIANTE:</p> <ul> <li><code>BP_ESTUDIANTE</code>, <code>FECHA_PERMISO</code>, <code>MOTIVO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de SAP y SQL Server\n    SSIS -&gt;&gt; Excel: Leer informaci\u00f3n operativa y educativa\n    SSIS -&gt;&gt; Python: Automatizar descargas\n    SSIS -&gt;&gt; DWH: Cargar datos procesados</code></pre> <ol> <li>Diagrama ER para Tablas de Hechos</li> </ol> <pre><code>erDiagram\n    FACT_TRANSPORTE {\n        string PARTNER_ESTUDIANTE\n        date FECHA_INICIO_SERVICIO\n        int ANIO_ACADEMICO\n        string CATEGORIA_SERVICIO\n    }\n    FACT_CUPOS_NEGADOS {\n        string PARTNER_ESTUDIANTE\n        int ANIO_ACADEMICO\n        date FECHA_ESTADO\n    }\n    FACT_BIBLIOTECA {\n        string ITEM_LIBRO\n        date FECHA_PRESTAMO\n        string BP_ESTUDIANTE\n    }\n    FACT_PERMISO_ESTUDIANTE {\n        string BP_ESTUDIANTE\n        date FECHA_PERMISO\n        string MOTIVO\n    }\n    FACT_TRANSPORTE ||--|| FACT_CUPOS_NEGADOS : \"Relaci\u00f3n de estudiantes\"\n    FACT_BIBLIOTECA ||--|| FACT_PERMISO_ESTUDIANTE : \"Conexi\u00f3n por estudiantes\"</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-01-fact_enfermeria","title":"Componente <code>EP-EDF-01 FACT_ENFERMERIA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-01 FACT_ENFERMERIA</code> es un proceso de ejecuci\u00f3n en un paquete SSIS dise\u00f1ado para correr un script de Python que realiza tareas relacionadas con la descarga de informaci\u00f3n para la facturaci\u00f3n de enfermer\u00eda. El componente utiliza una ruta espec\u00edfica y argumentos para ejecutar el script.</p> <p>Detalles del Componente</p> <ul> <li>Nombre del Componente: EP-EDF-01 FACT_ENFERMERIA</li> <li>Tipo: Execute Process Task</li> <li>Descripci\u00f3n: Ejecuta un script de Python encargado de descargar datos espec\u00edficos relacionados con el proceso <code>EP-EDF-01</code>.</li> <li>ID del Componente: <code>{4412de09-7ca0-4c06-ab1a-20e07c589832}</code></li> </ul> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-01</code> Tiempo de Espera No especificado (valor predeterminado) ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-01</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-01`\n    Python -&gt;&gt; Python: Descarga datos de `EP-EDF-01`\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-02-fact_ausentismo_docente","title":"Componente <code>EP-EDF-02 FACT_AUSENTISMO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-02 FACT_AUSENTISMO_DOCENTE</code> es un proceso dise\u00f1ado para ejecutar un script de Python que gestiona la descarga de informaci\u00f3n relacionada con el ausentismo docente. El componente utiliza configuraciones din\u00e1micas para el ejecutable y el directorio de trabajo, maximizando la flexibilidad y portabilidad dentro del entorno del proyecto.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-02 FACT_AUSENTISMO_DOCENTE Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python que descarga datos relacionados con el ausentismo docente. ID del Componente <code>{34225bf4-f1be-4808-9dfa-a648f4e220fc}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-02</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_1","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-02</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-02`\n    Python -&gt;&gt; Python: Descarga datos relacionados con ausentismo docente\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-03-fact_reemplazo_docente","title":"Componente <code>EP-EDF-03 FACT_REEMPLAZO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-03 FACT_REEMPLAZO_DOCENTE</code> es un componente dise\u00f1ado para ejecutar un script de Python. Su prop\u00f3sito es gestionar la descarga de informaci\u00f3n relacionada con el reemplazo docente. Utiliza configuraciones din\u00e1micas a trav\u00e9s de variables de proyecto, lo que garantiza flexibilidad y adaptabilidad dentro del entorno de desarrollo.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-03 FACT_REEMPLAZO_DOCENTE Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python que descarga datos relacionados con el reemplazo docente. ID del Componente <code>{df155a7f-6a3b-4e31-af0d-7b07113807e9}</code> <p>Propiedades Principales Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-03</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_2","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-03</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-03`\n    Python -&gt;&gt; Python: Descarga datos relacionados con reemplazo docente\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-04-fact_permiso_estudiante","title":"Componente <code>EP-EDF-04 FACT_PERMISO_ESTUDIANTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-04 FACT_PERMISO_ESTUDIANTE</code> es un componente que ejecuta un script de Python para descargar datos relacionados con permisos estudiantiles. Este componente utiliza variables din\u00e1micas de proyecto para definir tanto el ejecutable como el directorio de trabajo, asegurando flexibilidad y adaptabilidad al entorno.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-04 FACT_PERMISO_ESTUDIANTE Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python que descarga datos relacionados con permisos estudiantiles. ID del Componente <code>{2c32b9c0-798a-4bd5-a1e9-8b0351f2e222}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-04</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_3","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-04</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-04`\n    Python -&gt;&gt; Python: Descarga datos relacionados con permisos estudiantiles\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-05-fact_biblioteca","title":"Componente <code>EP-EDF-05 FACT_BIBLIOTECA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-05 FACT_BIBLIOTECA</code> es un componente que ejecuta un script de Python dise\u00f1ado para gestionar datos relacionados con la biblioteca del sistema. Este componente utiliza variables din\u00e1micas de proyecto para configurar el ejecutable y el directorio de trabajo, proporcionando flexibilidad en diferentes entornos.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-05 FACT_BIBLIOTECA Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python para gestionar datos de la biblioteca. ID del Componente <code>{93de8c31-f735-482b-9d44-ae33924b8a70}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-05</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_4","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-05</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-05`\n    Python -&gt;&gt; Python: Descarga datos de la biblioteca\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-06-fact_biblioteca_virtual","title":"Componente <code>EP-EDF-06 FACT_BIBLIOTECA_VIRTUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente <code>EP-EDF-06 FACT_BIBLIOTECA_VIRTUAL</code> est\u00e1 dise\u00f1ado para ejecutar un script de Python que gestiona la descarga de datos relacionados con la biblioteca virtual en el sistema. Este componente utiliza propiedades din\u00e1micas configuradas a nivel de proyecto, lo que permite flexibilidad en su uso en diferentes entornos.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-06 FACT_BIBLIOTECA_VIRTUAL Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python para gestionar datos de la biblioteca virtual. ID del Componente <code>{d22a6787-565a-4722-8ab0-acea586c4bfd}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-06</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_5","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-06</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-06`\n    Python -&gt;&gt; Python: Descarga datos de la biblioteca virtual\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-07-fact_saber11_individual","title":"Componente <code>EP-EDF-07 FACT_SABER11_INDIVIDUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente <code>EP-EDF-07 FACT_SABER11_INDIVIDUAL</code> ejecuta un script de Python que gestiona la descarga y procesamiento de informaci\u00f3n relacionada con las evaluaciones Saber 11 individuales. Este componente utiliza variables de proyecto para configurar el ejecutable y el directorio de trabajo, lo que garantiza flexibilidad en diferentes entornos.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-07 FACT_SABER11_INDIVIDUAL Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python para gestionar datos de evaluaciones Saber 11 individuales. ID del Componente <code>{47f926b0-8b2b-497d-bed6-90dc0e6f9d7c}</code> <p>Propiedades Principales</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-07</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_6","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-07</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-07`\n    Python -&gt;&gt; Python: Descarga y procesa datos de evaluaciones Saber 11\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-08-fact_saber11_colegios","title":"Componente <code>EP-EDF-08 FACT_SABER11_COLEGIOS</code>","text":"<p>Este componente es una tarea de proceso (Execute Process Task) dentro del paquete SSIS, dise\u00f1ado para ejecutar un script de Python que gestiona la descarga y procesamiento de datos relacionados con las evaluaciones SABER 11 a nivel de colegios. La tarea se configura din\u00e1micamente mediante expresiones de proyecto, lo que permite adaptar la ruta del ejecutable y el directorio de trabajo a diferentes entornos (por ejemplo, desarrollo, pruebas y producci\u00f3n).</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-08</code> que se encarga de conectarse a la fuente de datos (por ejemplo, un servicio o archivo remoto) para extraer informaci\u00f3n de evaluaciones SABER 11 de colegios.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar de manera automatizada la extracci\u00f3n y transformaci\u00f3n de datos en el flujo ETL de la soluci\u00f3n SSIS, facilitando la consolidaci\u00f3n y actualizaci\u00f3n de la informaci\u00f3n en el Data Warehouse.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-tecnica","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Execute Process Task.</p> </li> <li> <p>Propiedades Clave:</p> <ul> <li>Executable:   Se define din\u00e1micamente la ruta del ejecutable de Python mediante la siguiente expresi\u00f3n:   <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory:   Se establece la ruta de trabajo din\u00e1mica para el script, concatenando la variable de proyecto correspondiente:   <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments:   El script a ejecutar es:   <pre><code>download.py --key EP-EDF-08\n</code></pre></li> </ul> </li> <li> <p>Datos del Objeto:</p> <ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#flujo-de-ejecucion","title":"Flujo de Ejecuci\u00f3n","text":"<p>El proceso sigue los siguientes pasos:</p> <ol> <li> <p>Inicio de la Tarea:    El paquete SSIS inicia la tarea de proceso configurada para ejecutar el script.</p> </li> <li> <p>Ejecuci\u00f3n del Script Python:    Se invoca el ejecutable de Python con el argumento <code>download.py --key EP-EDF-08</code> en el directorio de trabajo especificado. El script se encarga de conectarse al sistema de origen, extraer y procesar los datos de evaluaciones SABER 11 para colegios.</p> </li> <li> <p>Finalizaci\u00f3n de la Tarea:    Una vez finalizada la ejecuci\u00f3n del script, la tarea devuelve el c\u00f3digo de retorno y el flujo ETL contin\u00faa con las siguientes operaciones definidas en el paquete.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant PythonScript as download.py --key EP-EDF-08\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-08 FACT_SABER11_COLEGIOS\n    ExecProcess -&gt;&gt; PythonScript: Ejecuta script de Python\n    PythonScript --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-09-fact_desempenho_docente","title":"Componente <code>EP-EDF-09 FACT_DESEMPENHO_DOCENTE</code>","text":"<p>Este componente ejecuta un script de Python encargado de descargar y procesar datos relacionados con el desempe\u00f1o docente. El script se invoca mediante la tarea de proceso, facilitando la integraci\u00f3n de la informaci\u00f3n de evaluaciones docentes en el flujo ETL.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-09</code> para obtener informaci\u00f3n sobre el desempe\u00f1o docente desde la fuente de datos, facilitando su an\u00e1lisis en el Data Warehouse.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar de manera automatizada la extracci\u00f3n de datos sobre desempe\u00f1o docente dentro del proceso ETL global, garantizando la actualizaci\u00f3n continua de la informaci\u00f3n.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <pre><code>download.py --key EP-EDF-09\n</code></pre></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-09\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-09 FACT_DESEMPENHO_DOCENTE\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-10-fact_legalizacion","title":"Componente <code>EP-EDF-10 FACT_LEGALIZACION</code>","text":"<p>Este componente ejecuta un script de Python que gestiona la descarga y procesamiento de datos relacionados con la legalizaci\u00f3n. Es parte de la consolidaci\u00f3n de informaci\u00f3n que alimenta el Data Warehouse, permitiendo la verificaci\u00f3n y validaci\u00f3n de registros legales.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-10</code> para obtener informaci\u00f3n legal desde la fuente, asegurando su preparaci\u00f3n para la integraci\u00f3n en el Data Warehouse.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Facilitar la actualizaci\u00f3n y consolidaci\u00f3n de datos de legalizaci\u00f3n mediante la automatizaci\u00f3n del proceso de extracci\u00f3n.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <code>plaintext   download.py --key EP-EDF-10</code></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-10\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-10 FACT_LEGALIZACION\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-11-fact_psiorientacion","title":"Componente <code>EP-EDF-11 FACT_PSIORIENTACION</code>","text":"<p>Este componente ejecuta un script de Python destinado a procesar datos de orientaci\u00f3n psicol\u00f3gica. Permite la extracci\u00f3n y transformaci\u00f3n de informaci\u00f3n que posteriormente se integrar\u00e1 en el Data Warehouse para el an\u00e1lisis de atenci\u00f3n psicol\u00f3gica.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-11</code> para extraer datos de orientaci\u00f3n psicol\u00f3gica, facilitando su posterior an\u00e1lisis y reporte.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Asegurar la actualizaci\u00f3n peri\u00f3dica de los datos de orientaci\u00f3n psicol\u00f3gica dentro del flujo ETL.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <pre><code>download.py --key EP-EDF-11\n</code></pre></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-11\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-11 FACT_PSIORIENTACION\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-12-fact_reserva_espacios","title":"Componente <code>EP-EDF-12 FACT_RESERVA_ESPACIOS</code>","text":"<p>Este componente ejecuta un script de Python que se encarga de la descarga y procesamiento de datos relacionados con la reserva de espacios educativos. El script facilita la consolidaci\u00f3n de la informaci\u00f3n de reservas para su posterior an\u00e1lisis y reporte.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-12</code> para obtener informaci\u00f3n de reservas de espacios, asegurando que los datos sean precisos y est\u00e9n listos para ser cargados en el Data Warehouse.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Integrar autom\u00e1ticamente la extracci\u00f3n y transformaci\u00f3n de datos de reservas dentro del flujo ETL.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <pre><code>download.py --key EP-EDF-12\n</code></pre></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-12\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-12 FACT_RESERVA_ESPACIOS\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-13-fact_servicio_social","title":"Componente <code>EP-EDF-13 FACT_SERVICIO_SOCIAL</code>","text":"<p>Este componente ejecuta un script de Python encargado de descargar y procesar datos relacionados con el servicio social de los estudiantes. La tarea automatiza la integraci\u00f3n de estos datos en el flujo ETL, permitiendo su an\u00e1lisis y reporte en el Data Warehouse.</p> <p>Prop\u00f3sito del Componente</p> <ul> <li> <p>Extracci\u00f3n y Procesamiento de Datos:   Ejecutar el script <code>download.py --key EP-EDF-13</code> para extraer informaci\u00f3n sobre el servicio social, transformarla y prepararla para su carga en el sistema.</p> </li> <li> <p>Automatizaci\u00f3n del Proceso ETL:   Asegurar que la extracci\u00f3n de datos de servicio social se ejecute de forma autom\u00e1tica y peri\u00f3dica, integr\u00e1ndose en el proceso ETL global.</p> </li> </ul> <p>Descripci\u00f3n T\u00e9cnica</p> <ul> <li>Tipo de Tarea: Execute Process Task.</li> <li>Propiedades Clave:<ul> <li>Executable: <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>WorkingDirectory: <pre><code>@[$Project::Working_Directory] + \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> <li>Arguments: <pre><code>download.py --key EP-EDF-13\n</code></pre></li> </ul> </li> <li>Datos F\u00edsicos:<ul> <li>Executable (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>WorkingDirectory (ruta f\u00edsica): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> <p>Diagrama de Secuencia</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecProcess as Tarea Ejecutar Proceso\n    participant Python as download.py --key EP-EDF-13\n\n    SSIS -&gt;&gt; ExecProcess: Inicia ejecuci\u00f3n de EP-EDF-13 FACT_SERVICIO_SOCIAL\n    ExecProcess -&gt;&gt; Python: Ejecuta script de Python\n    Python --&gt;&gt; ExecProcess: Devuelve c\u00f3digo de retorno\n    ExecProcess -&gt;&gt; SSIS: Finaliza tarea de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_transporte","title":"Componente <code>Procesar FACT_TRANSPORTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_TRANSPORTE</code> es una tarea de flujo de datos en un paquete SSIS que realiza procesos ETL para gestionar informaci\u00f3n de transporte. Este flujo extrae datos de SAP, realiza transformaciones mediante conversiones, divisiones condicionales y b\u00fasquedas, y finalmente carga los datos procesados en una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li>Fuente de Datos ADO.NET (<code>FACT_TRANSPORTE SAP</code>)<ul> <li>Descripci\u00f3n: Extrae datos de SAP mediante una consulta SQL.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>WITH TransportDetails AS (\n    SELECT OBJID AS OBJETO_SAP_ESTUDIANTE, BEGDA AS FECHA_INICIO_SERVICIO, \n           ENDDA AS FECHA_FIN_SERVICIO, BENCAT AS CATEGORIA_SERVICIO\n    FROM SAPABAP1.hrp1706 hh\n    WHERE PLVAR = '01' AND otype = 'ST' AND PDISCT2 = 'TRAN'\n), \nStudentKeys AS (\n    SELECT a.objid AS OBJETO_SAP_ESTUDIANTE, a.short AS NUMERO_MATRICULA,\n           b.PARTNER AS PARTNER_ESTUDIANTE\n    FROM SAPABAP1.HRP1000 AS a\n    INNER JOIN SAPABAP1.CMACBPST AS b ON a.objid = b.stobjid\n    WHERE a.plvar = 01 AND a.otype = 'ST' AND a.endda &gt;= CURDATE()\n)\nSELECT s.PARTNER_ESTUDIANTE, t.FECHA_INICIO_SERVICIO AS ID_FECHA,\n       YEAR(TO_DATE(t.FECHA_INICIO_SERVICIO, 'YYYYMMDD')) AS ANIO_ACADEMICO,\n       TO_DATE(t.FECHA_INICIO_SERVICIO, 'YYYYMMDD') AS FECHA_INICIO_SERVICIO,\n       TO_DATE(t.FECHA_FIN_SERVICIO, 'YYYYMMDD') AS FECHA_FIN_SERVICIO,\n       t.CATEGORIA_SERVICIO, 'SI' AS SERVICIO_TRANSPORTE,\n       s.PARTNER_ESTUDIANTE || '_' || TO_CHAR(t.FECHA_INICIO_SERVICIO, 'YYYYMMDD') AS ID_REGISTRO_AUXILIAR\nFROM TransportDetails AS t\nINNER JOIN StudentKeys AS S ON t.OBJETO_SAP_ESTUDIANTE = s.OBJETO_SAP_ESTUDIANTE\nWHERE t.FECHA_INICIO_SERVICIO &gt;= '20230101'\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: Conexi\u00f3n a SAP referenciada por <code>SAP_ERP</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ID_FECHA</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_INICIO_SERVICIO</code>, <code>FECHA_FIN_SERVICIO</code>, <code>CATEGORIA_SERVICIO</code>, <code>SERVICIO_TRANSPORTE</code>, <code>ID_REGISTRO_AUXILIAR</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>)<ul> <li>Descripci\u00f3n: Convierte columnas de entrada para garantizar compatibilidad con componentes posteriores.</li> <li>Columnas de Entrada:<ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ID_FECHA</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_INICIO_SERVICIO</code>, <code>FECHA_FIN_SERVICIO</code>, <code>SERVICIO_TRANSPORTE</code>, <code>ID_REGISTRO_AUXILIAR</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_INICIO_SERVICIO</code>, <code>Copy of FECHA_FIN_SERVICIO</code>, <code>Copy of SERVICIO_TRANSPORTE</code>, <code>Copy of ID_REGISTRO_AUXILIAR</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>B\u00fasquedas (<code>Lookup</code>)<ul> <li>Lookup <code>1</code>:<ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_TARIFAS_SERVICIOS</code>.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:   <pre><code>SELECT [ID_TARIFA], [CON_OBJETO_TARIFA], CAST([ANIO_TARIFA] AS INT) AS [ANIO_TARIFA]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_TARIFAS_SERVICIOS]\nWHERE [COD_INFRAESTRUCTURA_CCF] = 'CCF008-12-00001' AND UPPER([CON_OBJETO_TARIFA]) LIKE '%TRANSPORTE%'\n</code></pre></li> </ul> </li> </ul> </li> <li>Lookup <code>2</code>:<ul> <li>Descripci\u00f3n: Busca en <code>FACT_TRANSPORTE</code> utilizando la columna <code>ID_REGISTRO_AUXILIAR</code>.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:   <pre><code>SELECT [ID_REGISTRO], [BP_ESTUDIANTE], [ID_FECHA], [BP_ESTUDIANTE] + '_' + CONVERT(VARCHAR, [ID_FECHA], 112) AS [ID_REGISTRO_AUXILIAR]\nFROM [DWH_COMFENALCO].[Colegio].[FACT_TRANSPORTE]\n</code></pre></li> </ul> </li> </ul> </li> </ul> </li> </ol> <ol> <li>Divisi\u00f3n Condicional (<code>Conditional Split</code>)<ul> <li>Descripci\u00f3n: Separa filas en salidas distintas seg\u00fan condiciones espec\u00edficas.</li> <li>Condiciones:<ul> <li>Agregar: <code>!ISNULL(ID_TARIFA)</code></li> <li>No Agregar: Filas que no cumplen con la condici\u00f3n anterior.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Destino de Datos ADO.NET (<code>FACT_TRANSPORTE_DEST</code>)<ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_TRANSPORTE</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"FACT_TRANSPORTE\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_INICIO_SERVICIO</code>, <code>Copy of FECHA_FIN_SERVICIO</code>, <code>Copy of SERVICIO_TRANSPORTE</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Source as FACT_TRANSPORTE SAP (Fuente)\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup 1\n    participant ConditionalSplit as Conditional Split\n    participant Lookup2 as Lookup 2\n    participant Destination as FACT_TRANSPORTE_DEST (Destino)\n\n    Source -&gt;&gt; DataConversion: Datos extra\u00eddos\n    DataConversion -&gt;&gt; Lookup1: Datos convertidos\n    Lookup1 -&gt;&gt; ConditionalSplit: Datos enriquecidos\n    ConditionalSplit -&gt;&gt; Lookup2: Filas seleccionadas\n    Lookup2 -&gt;&gt; Destination: Datos finales</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_cupos_negados","title":"Componente <code>Procesar FACT_CUPOS_NEGADOS</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_CUPOS_NEGADOS</code> es un flujo de datos en un paquete SSIS que gestiona el procesamiento de informaci\u00f3n relacionada con cupos negados para estudiantes. Este flujo incluye extracci\u00f3n de datos desde SAP, transformaciones mediante conversiones, b\u00fasquedas y derivaci\u00f3n de columnas, finalizando con la carga de datos en una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li>Fuente de Datos ADO.NET (<code>FACT_CUPOS NEGADOS SAP</code>)<ul> <li>Descripci\u00f3n: Extrae datos desde SAP utilizando una consulta SQL.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>WITH StudentKeys AS (\n    SELECT a.objid AS OBJETO_SAP_ESTUDIANTE, \n           a.short AS NUMERO_MATRICULA,\n           b.PARTNER AS PARTNER_ESTUDIANTE,\n           a.STEXT AS NOMBRE_ESTUDIANTE\n    FROM SAPABAP1.HRP1000 AS a\n    INNER JOIN SAPABAP1.CMACBPST AS b ON a.objid = b.stobjid\n    WHERE a.plvar = 01 AND a.otype = 'ST' AND a.endda &gt;= CURDATE()\n),\nDeniedStudents AS (\n    SELECT OBJID AS OBJETO_SAP_ESTUDIANTE, \n           HS_PERYR AS ANIO_ACADEMICO, \n           AEDTM AS FECHA_ESTADO\n    FROM SAPABAP1.HRP1728 AS h\n    WHERE plvar = '01' AND otype = 'ST' AND SUBTY = '9060' AND HS_STATE = 'A'\n)\nSELECT sk.NUMERO_MATRICULA, sk.PARTNER_ESTUDIANTE, sk.OBJETO_SAP_ESTUDIANTE, \n       sk.NOMBRE_ESTUDIANTE, d.ANIO_ACADEMICO, \n       TO_DATE(d.FECHA_ESTADO, 'YYYYMMDD') AS FECHA_ESTADO, d.FECHA_ESTADO AS ID_FECHA\nFROM DeniedStudents AS d\nINNER JOIN StudentKeys AS sk ON d.OBJETO_SAP_ESTUDIANTE = sk.OBJETO_SAP_ESTUDIANTE\n</code></pre></li> <li>Conexi\u00f3n: Referencia a <code>SAP_ERP</code>.</li> <li>Tiempo de espera: <code>30</code> segundos.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>NUMERO_MATRICULA</code>, <code>PARTNER_ESTUDIANTE</code>, <code>OBJETO_SAP_ESTUDIANTE</code>, <code>NOMBRE_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_ESTADO</code>, <code>ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>)<ul> <li>Descripci\u00f3n: Convierte columnas de entrada a tipos y longitudes compatibles con otros componentes.</li> <li>Columnas de Entrada:<ul> <li><code>NUMERO_MATRICULA</code>, <code>PARTNER_ESTUDIANTE</code>, <code>OBJETO_SAP_ESTUDIANTE</code>, <code>NOMBRE_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_ESTADO</code>, <code>ID_FECHA</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Copy of NUMERO_MATRICULA</code>, <code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of OBJETO_SAP_ESTUDIANTE</code>, <code>Copy of NOMBRE_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_ESTADO</code>, <code>Copy of ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>B\u00fasqueda (<code>Lookup</code>)<ul> <li>Descripci\u00f3n: Busca datos adicionales en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li>Columna de Uni\u00f3n: <code>PARTNER</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_POBLACION_MATRICULA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Columna Derivada (<code>Derived Column</code>)<ul> <li>Descripci\u00f3n: Calcula o asigna valores a columnas existentes o nuevas bas\u00e1ndose en condiciones.</li> <li>Expresi\u00f3n:   <pre><code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA\n</code></pre></li> <li>Columna Derivada:<ul> <li><code>ID_POBLACION_MATRICULA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)<ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_CUPOS_NEGADOS</code>.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Colegio\".\"FACT_CUPOS_NEGADOS\"</code>.</li> <li>BatchSize: <code>0</code> (tama\u00f1o predeterminado del b\u00fafer interno).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of NUMERO_MATRICULA</code>, <code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of OBJETO_SAP_ESTUDIANTE</code>, <code>Copy of NOMBRE_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_ESTADO</code>, <code>Copy of ID_FECHA</code>, <code>ID_POBLACION_MATRICULA</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia-del-flujo","title":"Diagrama de Secuencia del Flujo","text":"<pre><code>sequenceDiagram\n    participant Source as FACT_CUPOS NEGADOS SAP (Fuente)\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup (DIM_POBLACION_MATRICULA)\n    participant DerivedColumn as Derived Column\n    participant Destination as FACT_CUPOS_NEGADOS (Destino)\n\n    Source -&gt;&gt; DataConversion: Extrae datos y los convierte\n    DataConversion -&gt;&gt; Lookup: Enriquecimiento con b\u00fasqueda\n    Lookup -&gt;&gt; DerivedColumn: Asigna valores derivados\n    DerivedColumn -&gt;&gt; Destination: Carga datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-truncar-tabla","title":"Componente: <code>Truncar tabla</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>El componente \"Truncar tabla\" es una tarea de ejecuci\u00f3n de SQL que elimina todos los datos de la tabla <code>RESULTS</code> antes de ejecutar cualquier procedimiento o carga posterior, asegurando que la tabla est\u00e9 vac\u00eda y preparada para nuevos datos. Utiliza el comando <code>TRUNCATE TABLE</code> para eliminar de forma eficiente los registros, sin generar registros de transacci\u00f3n para cada fila eliminada.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-detallados","title":"Componentes Detallados","text":"<p>Descripci\u00f3n - Nombre del componente: Truncar tabla - Tipo: Tarea Ejecutar SQL - Descripci\u00f3n: Limpia la tabla <code>RESULTS</code> para evitar conflictos o duplicados en cargas posteriores.</p> <p>Propiedades</p> Propiedad Valor Connection <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code> SqlStatementSource <code>TRUNCATE TABLE RESULTS;</code> LocaleID <code>-1</code> CreationName <code>Microsoft.ExecuteSQLTask</code> TaskContact <code>Execute SQL Task; Microsoft Corporation; SQL Server 2022; \u00a9 2022 Microsoft Corporation</code> <p>Script SQL <pre><code>-- Limpiar la tabla antes de ejecutar el procedimiento\nTRUNCATE TABLE RESULTS;\n</code></pre></p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-calcular-retiros","title":"Componente <code>Calcular retiros</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente \"Calcular retiros\" es una tarea de flujo de datos en SSIS dise\u00f1ada para procesar, transformar y almacenar informaci\u00f3n relacionada con retiros de estudiantes. Este flujo extrae datos de una fuente SAP, realiza conversiones de datos, derivaciones de columnas, y finalmente almacena los resultados en la tabla de destino <code>FACT_RETIROS</code>.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>FACT_RETIROS SAP (Origen de datos)</p> <ul> <li>Descripci\u00f3n: Extrae informaci\u00f3n de estudiantes y retiros desde SAP usando un bloque SQL que recorre a\u00f1os desde 2023 hasta el a\u00f1o actual.</li> <li>Propiedades principales:<ul> <li>Consulta SQL: <pre><code>DO\nBEGIN\n    DECLARE year INT := 2023;\n    DECLARE current_year INT := YEAR(CURRENT_DATE);\n    WHILE year &lt;= current_year DO\n        CALL GetRetirosByYear(year);\n        year := year + 1;\n    END WHILE;\n    SELECT * FROM RESULTS;\nEND\n</code></pre></li> <li>Conexi\u00f3n: <code>SAP_ERP</code></li> <li>Timeout: 30 segundos.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos extra\u00eddos a los tipos requeridos para las siguientes transformaciones y el destino.</li> <li>Entrada:<ul> <li>Columnas: <code>OBJETO_SAP_ESTUDIANTE</code>, <code>NUMERO_MATRICULA</code>, <code>PARTNER_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>APELLIDOS</code>, <code>NOMBRES</code>, <code>CURSO</code>, <code>GRADO</code>, <code>FECHA_RETIRO_SAP</code>, <code>FECHA_VALIDO_DESDE</code>, <code>FECHA_VALIDO_HASTA</code>.</li> </ul> </li> <li>Salida:<ul> <li>Columnas convertidas como <code>Copy of &lt;nombre original&gt;</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Enlaza informaci\u00f3n adicional de la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Propiedades principales:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li>Comportamiento de no coincidencia: Ignorar filas sin coincidencias.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code>.</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas a partir de las existentes. Por ejemplo, se genera la columna <code>ID_FECHA</code> utilizando <code>FECHA_RETIRO_SAP</code>.</li> <li>Expresi\u00f3n derivada: <pre><code>(DT_I4)(YEAR([Copy of FECHA_RETIRO_SAP]) * 10000 + MONTH([Copy of FECHA_RETIRO_SAP]) * 100 + DAY([Copy of FECHA_RETIRO_SAP]))\n</code></pre></li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Almacena los resultados procesados en la tabla <code>FACT_RETIROS</code> en la base de datos de destino.</li> <li>Propiedades principales:<ul> <li>Tabla de destino: <code>Colegio.FACT_RETIROS</code></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#flujo-del-proceso","title":"Flujo del Proceso","text":"<ol> <li>Extraer datos desde SAP mediante <code>FACT_RETIROS SAP</code>.</li> <li>Convertir datos en el componente <code>Data Conversion</code>.</li> <li>Realizar un lookup para enriquecer datos desde <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Derivar nuevas columnas usando <code>Derived Column</code>.</li> <li>Almacenar los datos procesados en la tabla <code>FACT_RETIROS</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia-del-flujo_1","title":"Diagrama de Secuencia del Flujo","text":"<pre><code>sequenceDiagram\n    participant SAP as FACT_RETIROS SAP\n    participant DC as Data Conversion\n    participant LKP as Lookup\n    participant DCOL as Derived Column\n    participant DEST as Destino de ADO NET\n\n    SAP-&gt;&gt;DC: Extraer datos desde SAP\n    DC-&gt;&gt;LKP: Convertir datos y realizar Lookup\n    LKP-&gt;&gt;DCOL: Enviar datos enriquecidos\n    DCOL-&gt;&gt;DEST: Derivar columnas y guardar en destino\n    DEST--&gt;&gt;SAP: Fin del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_ausentismo_docente","title":"Componente <code>Procesar FACT_AUSENTISMO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>El componente \"Procesar FACT_AUSENTISMO_DOCENTE\" es una tarea de flujo de datos en SSIS destinada a procesar, transformar y almacenar informaci\u00f3n relacionada con el ausentismo docente. El flujo de datos incluye una fuente de datos Excel, transformaciones como conversi\u00f3n de datos y derivaci\u00f3n de columnas, enriquecimiento con datos adicionales mediante <code>Lookup</code>, y finalmente el almacenamiento en la tabla <code>FACT_AUSENTISMO_DOCENTE</code>.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Leer EP-EDF-02 (Excel Source)</p> <ul> <li>Descripci\u00f3n: Lee los datos desde un archivo Excel ubicado en la conexi\u00f3n <code>Excel_Connection_Fact_Ausentismo_Docente</code>.</li> <li>Propiedades principales:<ul> <li>Nombre de la hoja: <code>Hoja1$</code>.</li> <li>Columnas: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_REGISTRO</code>, <code>NOMBRE_DOCENTE</code>, <code>CARGO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>, <code>AUSENCIA_HORAS</code>, <code>AUSENCIA_DIAS</code>, <code>TIPO_AUSENCIA</code>, <code>PERMISO</code>, <code>MOTIVO_AUSENCIA</code>.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos extra\u00eddos a los tipos requeridos para las siguientes transformaciones y el destino.</li> <li>Entrada:<ul> <li>Columnas del archivo Excel.</li> </ul> </li> <li>Salida:<ul> <li>Columnas convertidas, con prefijo <code>Copy of</code>.</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas basadas en c\u00e1lculos sobre las columnas existentes. Por ejemplo, se genera <code>ID_FECHA</code> utilizando <code>FECHA_REGISTRO</code>.</li> <li>Expresi\u00f3n derivada: <pre><code>(DT_I4)(YEAR([Copy of FECHA_REGISTRO]) * 10000 + MONTH([Copy of FECHA_REGISTRO]) * 100 + DAY([Copy of FECHA_REGISTRO]))\n</code></pre></li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Enlaza informaci\u00f3n adicional desde la tabla <code>DIM_PERSONAL</code> en la base de datos <code>DWH_COMFENALCO</code>.</li> <li>Propiedades principales:<ul> <li>Consulta SQL: <pre><code>SELECT [ID_PERSONAL], CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO, [ID_UNIDAD], [TIPO_DOCUMENTO], [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1\n</code></pre></li> <li>Claves de uni\u00f3n: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ANIO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Almacena los datos procesados en la tabla <code>FACT_AUSENTISMO_DOCENTE</code>.</li> <li>Propiedades principales:<ul> <li>Tabla de destino: <code>Colegio.FACT_AUSENTISMO_DOCENTE</code>.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Leer EP-EDF-02 (Excel Source)\n    participant DC as Data Conversion\n    participant LKP as Lookup\n    participant DCOL as Derived Column\n    participant DEST as Destino de ADO NET\n\n    Excel-&gt;&gt;DC: Leer datos desde Excel\n    DC-&gt;&gt;DCOL: Convertir datos y derivar columnas\n    DCOL-&gt;&gt;LKP: Enviar datos para enriquecimiento\n    LKP-&gt;&gt;DEST: Guardar en base de datos\n    DEST--&gt;&gt;Excel: Fin del proceso</code></pre> <p>Flujo del Proceso</p> <ol> <li>Leer datos desde el archivo Excel (<code>Leer EP-EDF-02</code>).</li> <li>Convertir tipos de datos con el componente <code>Data Conversion</code>.</li> <li>Derivar nuevas columnas usando <code>Derived Column</code>.</li> <li>Enriquecer datos con informaci\u00f3n adicional mediante <code>Lookup</code>.</li> <li>Almacenar los datos procesados en la tabla <code>FACT_AUSENTISMO_DOCENTE</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_biblioteca","title":"Componente <code>Procesar FACT_BIBLIOTECA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos procesa la informaci\u00f3n de pr\u00e9stamos de biblioteca desde un archivo Excel hasta un destino en la base de datos relacional mediante transformaciones como conversiones de datos, columnas derivadas y b\u00fasquedas para enriquecer los datos con informaci\u00f3n adicional.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<p>1. Fuente: Leer EP-EDF-05</p> <ul> <li>Descripci\u00f3n: Extrae datos de un archivo Excel que contiene registros de pr\u00e9stamos de biblioteca.</li> <li>Propiedades:<ul> <li>Nombre de la hoja: <code>Hoja1$</code>.</li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Biblioteca</code>.</li> <li>Tiempo de espera del comando: <code>0</code> (sin l\u00edmite).</li> </ul> </li> <li>Columnas extra\u00eddas:<ul> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>BP_ESTUDIANTE</code>, <code>TIPO_USUARIO</code>, <code>FECHA_PRESTAMO</code>, <code>FECHA_VENCIMIENTO</code>, <code>FECHA_ENTREGA</code>, <code>BIBLIOTECA</code>, <code>ITEM_LIBRO</code>, <code>NO_PRESTAMOS</code>.</li> </ul> </li> </ul> <p>2. Transformaci\u00f3n: Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte las columnas extra\u00eddas en tipos compatibles con los destinos y procesos posteriores.</li> <li>Propiedades:<ul> <li>Conversi\u00f3n de tipos: <code>wstr</code> a tipos espec\u00edficos como <code>date</code> e <code>i4</code>.</li> <li>Columnas convertidas: <ul> <li>Ejemplo: <code>FECHA_PRESTAMO</code> a tipo <code>date</code>, <code>ITEM_LIBRO</code> a tipo <code>wstr</code> con longitud espec\u00edfica.</li> </ul> </li> <li>Disposici\u00f3n en caso de error: <code>FailComponent</code>.</li> </ul> </li> </ul> <p>3. Transformaci\u00f3n: Derived Column</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas de las existentes, como <code>ID_FECHA</code> y <code>ANIO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Expresiones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)(YEAR([FECHA_PRESTAMO])*10000 + MONTH([FECHA_PRESTAMO])*100 + DAY([FECHA_PRESTAMO]))</code>.</li> <li><code>ANIO_ACADEMICO</code>: <code>(DT_I4)(YEAR([FECHA_PRESTAMO]))</code>.</li> </ul> </li> <li>Manejo de errores: <code>FailComponent</code>.</li> </ul> </li> </ul> <p>4. Transformaci\u00f3n: Lookup</p> <ul> <li> <p>Lookup 1: Datos de matr\u00edcula (<code>DIM_POBLACION_MATRICULA</code>)</p> <ul> <li>Descripci\u00f3n: Asocia datos de estudiantes a partir de la columna <code>BP_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA];\n</code></pre></li> <li>Mapeo de par\u00e1metros: <code>BP_ESTUDIANTE \u2192 PARTNER</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup 2: Datos de libros (<code>DIM_LIBROS</code>)</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_LIBRO</code> usando el c\u00f3digo de barras o \u00edtem del libro.</li> <li>Propiedades:<ul> <li>Consulta SQL (con CTE para manejar duplicados): <pre><code>WITH CTE AS (\n    SELECT [ID_LIBRO], [ITEM],\n            ROW_NUMBER() OVER (PARTITION BY [ITEM] ORDER BY [ID_LIBRO]) AS rn\n    FROM [DWH_COMFENALCO].[Colegio].[DIM_LIBROS]\n)\nSELECT [ID_LIBRO], [ITEM] FROM CTE WHERE rn = 1;\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Lookup 3: Verificaci\u00f3n de registros existentes (<code>FACT_BIBLIOTECA</code>)</p> <ul> <li>Descripci\u00f3n: Verifica si ya existe un registro similar en la tabla destino.</li> <li>Propiedades:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[FACT_BIBLIOTECA];\n</code></pre></li> </ul> </li> </ul> </li> </ul> <p>5. Destino: Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados en la tabla <code>FACT_BIBLIOTECA</code> del esquema <code>Colegio</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Colegio\".\"FACT_BIBLIOTECA\"</code>.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code>.</li> <li>Tama\u00f1o de lotes: <code>0</code> (uso del tama\u00f1o de buffer interno).</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-05\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupMatricula as Lookup: DIM_POBLACION_MATRICULA\n    participant LookupLibros as Lookup: DIM_LIBROS\n    participant LookupFact as Lookup: FACT_BIBLIOTECA\n    participant Destino as ADO.NET Destination\n\n    ExcelSource -&gt;&gt; DataConversion: Extraer columnas y convertir tipos\n    DataConversion -&gt;&gt; DerivedColumn: Generar columnas derivadas\n    DerivedColumn -&gt;&gt; LookupMatricula: Buscar ID de matr\u00edcula\n    LookupMatricula -&gt;&gt; LookupLibros: Buscar ID de libro\n    LookupLibros -&gt;&gt; LookupFact: Verificar duplicados\n    LookupFact -&gt;&gt; Destino: Insertar registros finales</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_biblioteca_virtual","title":"Componente <code>Procesar FACT_BIBLIOTECA_VIRTUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) para los registros de la biblioteca virtual. Incluye conversiones de datos, derivaci\u00f3n de columnas, b\u00fasquedas y carga en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<p>1. Componente <code>Leer EP-EDF-06</code></p> <ul> <li>Descripci\u00f3n: Fuente de datos Excel que extrae informaci\u00f3n de la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0 (infinito).</li> <li><code>AccessMode</code>: 0 (tabla directa).</li> <li><code>OpenRowset</code>: <code>Hoja1$</code>.</li> </ul> </li> </ul> <p>2. Componente <code>Data Conversion</code></p> <ul> <li>Descripci\u00f3n: Convierte las columnas de entrada para ajustarlas a los tipos requeridos.</li> <li>Columnas Convertidas:<ul> <li><code>TIPO_DOCUMENTO</code>: <code>wstr</code> (40).</li> <li><code>DOCUMENTO</code>: <code>wstr</code> (20).</li> <li><code>FECHA_INICIO</code>: <code>date</code>.</li> </ul> </li> <li>Propiedades Adicionales:<ul> <li><code>FastParse</code>: <code>false</code> en todas las columnas.</li> </ul> </li> </ul> <p>3. Componente <code>Derived Column</code></p> <ul> <li>Descripci\u00f3n: Deriva columnas calculadas como <code>ID_FECHA</code> y <code>ANIO_ACADEMICO</code>.</li> <li>Columnas Derivadas:<ul> <li><code>ID_FECHA</code>: Combina a\u00f1o, mes y d\u00eda de <code>FECHA_INICIO</code>.</li> <li><code>ANIO_ACADEMICO</code>: Extrae solo el a\u00f1o.</li> </ul> </li> </ul> <p>4. Componente <code>Lookup</code></p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_POBLACION_MATRICULA</code> para obtener <code>ID_POBLACION_MATRICULA</code>.</li> <li>SQL de B\u00fasqueda: <pre><code>SELECT * FROM Colegio.DIM_POBLACION_MATRICULA WHERE TIPO_DOCUMENTO = ? AND DOCUMENTO = ?\n</code></pre></li> <li>Propiedades:<ul> <li><code>CacheType</code>: Completo.</li> <li><code>NoMatchBehavior</code>: Ignorar filas sin coincidencia.</li> </ul> </li> </ul> <p>5. Componente <code>Destino de ADO NET</code></p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>Colegio.FACT_BIBLIOTECA</code>.</li> <li>Propiedades:<ul> <li><code>BatchSize</code>: 0 (usa tama\u00f1o de b\u00fafer).</li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code>.</li> <li><code>CommandTimeout</code>: 30 segundos.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_11","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    Leer EP-EDF-06 -&gt;&gt; Data Conversion: Exporta datos Excel\n    Data Conversion -&gt;&gt; Derived Column: Convierte columnas\n    Derived Column -&gt;&gt; Lookup: Realiza b\u00fasquedas\n    Lookup -&gt;&gt; Derived Column 1: Agrega nuevas columnas derivadas\n    Derived Column 1 -&gt;&gt; Destino de ADO NET: Carga datos en la tabla FACT_BIBLIOTECA</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_desempenho_docente","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_DESEMPENHO_DOCENTE</code> es un flujo de datos dise\u00f1ado para extraer informaci\u00f3n desde un archivo Excel, realizar transformaciones y cargar los datos procesados en una base de datos. Este flujo incluye transformaciones clave como conversi\u00f3n de datos, derivaci\u00f3n de columnas, y consultas de b\u00fasqueda para enriquecer la informaci\u00f3n antes de almacenarla en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos:","text":"<ol> <li> <p>Leer EP-EDF-09 (Excel Source):</p> <ul> <li>Descripci\u00f3n: Fuente de datos que extrae informaci\u00f3n desde un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja: <code>Hoja1$</code></li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Desempenho_Colegio</code></li> <li>Columnas: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ANIO_ACADEMICO</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion:</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipos de datos de las columnas extra\u00eddas.</li> <li>Columnas Convertidas:<ul> <li><code>TIPO_DOCUMENTO</code> a <code>wstr(40)</code></li> <li><code>FECHA</code> a <code>date</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column:</p> <ul> <li>Descripci\u00f3n: Genera la columna <code>ID_FECHA</code> basada en la fecha en formato <code>YYYYMMDD</code>.</li> <li>Expresi\u00f3n: <code>(DT_I4)(YEAR([Copy of FECHA]) * 10000 + MONTH([Copy of FECHA]) * 100 + DAY([Copy of FECHA]))</code></li> </ul> </li> <li> <p>Lookup:</p> <ul> <li>Descripci\u00f3n: Enlaza los datos con la tabla <code>DIM_PERSONAL</code> para obtener el <code>ID_PERSONAL</code>.</li> <li>Consulta SQL: <pre><code>SELECT [ID_PERSONAL], CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1\n</code></pre></li> </ul> </li> <li> <p>Derived Column 1:</p> <ul> <li>Descripci\u00f3n: Asigna <code>-1</code> al <code>ID_PERSONAL</code> si no se encuentra un valor correspondiente.</li> <li>Expresi\u00f3n: <code>ISNULL(ID_PERSONAL) ? -1 : ID_PERSONAL</code></li> </ul> </li> <li> <p>Lookup 1:</p> <ul> <li>Descripci\u00f3n: Verifica duplicados en la tabla <code>FACT_DESEMPENHO_DOCENTE</code> para evitar registros repetidos.</li> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[FACT_DESEMPENHO_DOCENTE]\nWHERE [ID_FECHA] = ? AND [ID_PERSONAL] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de ADO NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_DESEMPENHO_DOCENTE</code>.</li> <li>Tabla Destino: <code>\"Colegio\".\"FACT_DESEMPENHO_DOCENTE\"</code></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_12","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel_Source as Leer EP-EDF-09 (Excel Source)\n    participant Data_Conversion as Data Conversion\n    participant Derived_Column as Derived Column\n    participant Lookup as Lookup\n    participant Lookup_1 as Lookup 1\n    participant Derived_Column_1 as Derived Column 1\n    participant ADO_NET as Destino de ADO NET\n\n    Excel_Source -&gt;&gt; Data_Conversion: Env\u00edo de datos\n    Data_Conversion -&gt;&gt; Derived_Column: Conversi\u00f3n de tipos\n    Derived_Column -&gt;&gt; Lookup: Relaciona datos con DIM_PERSONAL\n    Lookup -&gt;&gt; Derived_Column_1: Combina resultados\n    Derived_Column_1 -&gt;&gt; Lookup_1: Valida duplicados en FACT_DESEMPENHO_DOCENTE\n    Lookup_1 -&gt;&gt; ADO_NET: Inserta datos \u00fanicos\n    Note right of ADO_NET: Datos procesados y almacenados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_enfermeria","title":"Componente <code>Procesar FACT_ENFERMERIA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_ENFERMERIA</code> gestiona el flujo de datos para transformar, enriquecer y almacenar informaci\u00f3n relacionada con casos de atenci\u00f3n en enfermer\u00eda. Este flujo extrae datos de un archivo Excel, realiza conversiones y c\u00e1lculos, enriquece los datos con informaci\u00f3n adicional, y los carga en una tabla de base de datos mediante un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos:","text":"<ol> <li> <p>Leer EP-EDF-01 (Excel Source):</p> <ul> <li>Descripci\u00f3n: Fuente de datos que extrae informaci\u00f3n desde un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja: <code>Hoja1$</code></li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Enfermeria</code></li> <li>Columnas: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>IDCASO</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion:</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipos de datos de las columnas extra\u00eddas.</li> <li>Columnas Convertidas:<ul> <li><code>TIPO_DOCUMENTO</code> a <code>wstr(40)</code></li> <li><code>FECHA_ATENCION</code> a <code>date</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column:</p> <ul> <li>Descripci\u00f3n: Genera la columna <code>ID_FECHA</code> basada en la fecha de atenci\u00f3n en formato <code>YYYYMMDD</code>.</li> <li>Expresi\u00f3n: <code>(DT_I4)(YEAR([Copy of FECHA_ATENCION]) * 10000 + MONTH([Copy of FECHA_ATENCION]) * 100 + DAY([Copy of FECHA_ATENCION]))</code></li> </ul> </li> <li> <p>Lookup:</p> <ul> <li>Descripci\u00f3n: Enlaza los datos con la tabla <code>DIM_POBLACION_MATRICULA</code> para obtener el <code>ID_POBLACION_MATRICULA</code>.</li> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]\nWHERE [TIPO_DOCUMENTO] = ? AND [DOCUMENTO] = ?\n</code></pre></li> </ul> </li> <li> <p>Derived Column 1:</p> <ul> <li>Descripci\u00f3n: Asigna <code>-1</code> al <code>ID_POBLACION_MATRICULA</code> si no se encuentra un valor correspondiente.</li> <li>Expresi\u00f3n: <code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA</code></li> </ul> </li> <li> <p>Lookup 1:</p> <ul> <li>Descripci\u00f3n: Verifica duplicados en la tabla <code>FACT_ENFERMERIA</code> para evitar registros repetidos.</li> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[FACT_ENFERMERIA]\nWHERE [ID_CASO] = ? AND [ID_FECHA] = ? AND [ID_POBLACION_MATRICULA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de ADO NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_ENFERMERIA</code>.</li> <li>Tabla Destino: <code>\"Colegio\".\"FACT_ENFERMERIA\"</code></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_13","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel_Source as Leer EP-EDF-01 (Excel Source)\n    participant Data_Conversion as Data Conversion\n    participant Derived_Column as Derived Column\n    participant Lookup as Lookup\n    participant Lookup_1 as Lookup 1\n    participant Derived_Column_1 as Derived Column 1\n    participant ADO_NET as Destino de ADO NET\n\n    Excel_Source -&gt;&gt; Data_Conversion: Env\u00edo de datos\n    Data_Conversion -&gt;&gt; Derived_Column: Conversi\u00f3n de tipos\n    Derived_Column -&gt;&gt; Lookup: Relaciona datos con DIM_POBLACION_MATRICULA\n    Lookup -&gt;&gt; Derived_Column_1: Combina resultados\n    Derived_Column_1 -&gt;&gt; Lookup_1: Verifica duplicados en FACT_ENFERMERIA\n    Lookup_1 -&gt;&gt; ADO_NET: Inserta datos \u00fanicos\n    Note right of ADO_NET: Almacena datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_legalizacion","title":"Componente <code>Procesar FACT_LEGALIZACION</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos del paquete SSIS tiene como objetivo procesar y cargar datos relacionados con FACT_LEGALIZACION desde una fuente de datos Excel hacia una base de datos compatible con ADO.NET. Los datos se someten a diversas transformaciones antes de ser insertados en la tabla destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<p>1. Leer EP-EDF-10</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel llamada <code>Sheet1$</code> usando un origen de datos Excel.</li> <li>Propiedades:<ul> <li>Tiempo de espera: <code>0</code> (sin l\u00edmite).</li> <li>Modo de acceso: <code>0</code> (por defecto).</li> </ul> </li> <li>Columnas de salida:<ul> <li><code>RAZON_SOCIAL</code>: Ancho de 255 caracteres.</li> <li><code>FECHA</code>: Tipo de dato <code>date</code>.</li> <li><code>CODIGO_DANE</code>, <code>CODIGO_ICFES</code>: Tipo de dato <code>r8</code>.</li> <li>Otras columnas incluyen detalles como <code>CALENDARIO</code>, <code>NATURALEZA</code>, <code>CARACTER</code>, <code>TOTAL_ESTUDIANTES</code>, entre otros.</li> </ul> </li> </ul> <p>2. Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos y realiza ajustes necesarios en las columnas del flujo de datos para asegurar la compatibilidad con el destino.</li> <li>Propiedades:<ul> <li>Utiliza la opci\u00f3n <code>FailComponent</code> para manejar errores.</li> <li>Genera copias de las columnas le\u00eddas con ajustes de longitud y tipo de datos.</li> </ul> </li> <li>Columnas procesadas:<ul> <li>Ejemplo: <code>Copy of RAZON_SOCIAL</code> (tipo <code>wstr</code>, longitud: 40), <code>Copy of FECHA</code> (tipo <code>date</code>).</li> </ul> </li> </ul> <p>3. Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas a partir de transformaciones sobre las columnas existentes.</li> <li>Propiedades:<ul> <li>Calcula el campo <code>ID_FECHA</code> combinando valores de <code>A\u00f1o</code>, <code>Mes</code> y <code>D\u00eda</code> provenientes de <code>Copy of FECHA</code>.</li> <li>Ejemplo de expresi\u00f3n: <code>(DT_I4)(YEAR([Copy of FECHA]) * 10000 + MONTH([Copy of FECHA]) * 100 + DAY([Copy of FECHA]))</code>.</li> </ul> </li> </ul> <p>4. Lookup</p> <ul> <li>Descripci\u00f3n: Realiza b\u00fasquedas en la tabla de destino para verificar si los registros ya existen.</li> <li>Propiedades:<ul> <li>Usa la consulta SQL: <code>SELECT * FROM [Colegio].[FACT_LEGALIZACION]</code>.</li> <li>Maneja filas sin coincidencias envi\u00e1ndolas al flujo de datos.</li> <li>Coincidencias basadas en <code>RAZON_SOCIAL</code>, <code>CODIGO_DANE</code> y <code>ID_FECHA</code>.</li> </ul> </li> </ul> <p>5. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados en la tabla destino <code>FACT_LEGALIZACION</code> dentro de la base de datos del Colegio.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Colegio\".\"FACT_LEGALIZACION\"</code>.</li> <li>Tama\u00f1o del lote: <code>0</code> (uso de tama\u00f1o predeterminado).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Usa <code>SqlBulkCopy</code> para mejorar el rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_14","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-10\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant Lookup as Lookup\n    participant ADODestination as Destino de ADO.NET\n\n    ExcelSource-&gt;&gt;DataConversion: Flujo de datos\n    DataConversion-&gt;&gt;DerivedColumn: Datos convertidos\n    DerivedColumn-&gt;&gt;Lookup: Datos transformados\n    Lookup-&gt;&gt;ADODestination: Datos validados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_permiso_estudiante","title":"Componente <code>Procesar FACT_PERMISO_ESTUDIANTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>El flujo de datos del paquete SSIS procesa y carga informaci\u00f3n relacionada con permisos de estudiantes desde un archivo Excel hacia la base de datos del Colegio en la tabla <code>FACT_PERMISO_ESTUDIANTE</code>. El proceso incluye la validaci\u00f3n, transformaci\u00f3n y enriquecimiento de los datos.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_9","title":"Componentes del Flujo de Datos","text":"<p>1. Leer EP-EDF-04</p> <ul> <li>Descripci\u00f3n: Origen de datos Excel que lee los registros desde la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li>Tiempo de espera: <code>0</code> (sin l\u00edmite).</li> <li>Modo de acceso: <code>0</code> (predeterminado).</li> </ul> </li> <li>Columnas de salida: Incluye datos como <code>FECHA</code>, <code>BP_ESTUDIANTE</code>, <code>NOMBRE_ESTUDIANTE</code>, <code>GRADO</code>, <code>CURSO</code>, entre otros.</li> </ul> <p>2. Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos y ajusta las columnas para la compatibilidad con los pasos posteriores.</li> <li>Propiedades:<ul> <li>Asigna un prefijo <code>Copy of</code> a las columnas convertidas.</li> <li>Convierte columnas como <code>BP_ESTUDIANTE</code> (tipo <code>wstr</code>) y <code>FECHA</code> (tipo <code>date</code>).</li> </ul> </li> <li>Manejo de errores: Disposici\u00f3n <code>FailComponent</code>.</li> </ul> <p>3. Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas utilizando expresiones matem\u00e1ticas y l\u00f3gicas.</li> <li>Columnas generadas:<ul> <li><code>ID_FECHA</code>: Calculada como una combinaci\u00f3n de <code>A\u00f1o</code>, <code>Mes</code> y <code>D\u00eda</code>.</li> <li><code>ANIO_ACADEMICO</code>: Extra\u00eddo del a\u00f1o de la columna <code>Copy of FECHA</code>.</li> </ul> </li> </ul> <p>4. Lookup</p> <ul> <li>Descripci\u00f3n: Busca informaci\u00f3n adicional en la tabla de dimensiones <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> <li>Filtra filas bas\u00e1ndose en la columna <code>BP_ESTUDIANTE</code>.</li> </ul> </li> </ul> <p>5. Lookup 1 y Lookup 2</p> <ul> <li>Descripci\u00f3n: <ul> <li><code>Lookup 1</code>: Busca en <code>DIM_CURSO</code> para obtener el <code>ID_CURSO</code>.</li> <li><code>Lookup 2</code>: Busca en <code>DIM_GRADO</code> para obtener el <code>ID_GRADO</code>.</li> </ul> </li> <li>Propiedades:<ul> <li>Ambas operaciones utilizan columnas como <code>CURSO</code> y <code>GRADO</code> para realizar las coincidencias.</li> </ul> </li> </ul> <p>6. Lookup 3</p> <ul> <li>Descripci\u00f3n: Verifica si ya existen registros en la tabla destino <code>FACT_PERMISO_ESTUDIANTE</code> bas\u00e1ndose en las columnas <code>HORA</code>, <code>ID_FECHA</code> e <code>ID_POBLACION_MATRICULA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Colegio].[FACT_PERMISO_ESTUDIANTE]</code>.</li> </ul> </li> </ul> <p>7. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>FACT_PERMISO_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Colegio\".\"FACT_PERMISO_ESTUDIANTE\"</code>.</li> <li>Inserci\u00f3n masiva habilitada con <code>SqlBulkCopy</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_15","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-04\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant Lookup1 as Lookup DIM_POBLACION_MATRICULA\n    participant Lookup2 as Lookup DIM_CURSO\n    participant Lookup3 as Lookup DIM_GRADO\n    participant LookupFinal as Lookup FACT_PERMISO_ESTUDIANTE\n    participant Destination as Destino ADO.NET\n\n    ExcelSource-&gt;&gt;DataConversion: Datos le\u00eddos\n    DataConversion-&gt;&gt;DerivedColumn: Datos convertidos\n    DerivedColumn-&gt;&gt;Lookup1: Validaci\u00f3n de BP_ESTUDIANTE\n    Lookup1-&gt;&gt;Lookup2: Validaci\u00f3n de CURSO\n    Lookup2-&gt;&gt;Lookup3: Validaci\u00f3n de GRADO\n    Lookup3-&gt;&gt;Destination: Inserci\u00f3n en tabla destino</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_psiorientacion","title":"Componente <code>Procesar FACT_PSIORIENTACION</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>El flujo de datos del paquete SSIS procesa y carga informaci\u00f3n de orientaci\u00f3n psicol\u00f3gica de estudiantes desde un archivo Excel hacia la tabla de destino <code>FACT_PSICORIENTACION</code> en la base de datos. Incluye transformaciones de datos, validaciones y enriquecimientos utilizando varias transformaciones de SSIS.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_10","title":"Componentes del Flujo de Datos","text":"<p>1. Leer EP-EDF-11</p> <ul> <li>Descripci\u00f3n: Origen de datos Excel que lee la hoja <code>Hoja1$</code> para obtener la informaci\u00f3n.</li> <li>Propiedades:<ul> <li>Tiempo de espera: 0 (sin l\u00edmite).</li> <li>Modo de acceso: Predeterminado.</li> </ul> </li> <li>Columnas de salida:<ul> <li><code>BP_ESTUDIANTE</code>, <code>IDCASO</code>, <code>ANIO_ACADEMICO</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>FECHA_ATENCION</code>, <code>FECHA_SOLUCION</code>, <code>ESTADO</code>, <code>QUIEN_REMITE</code>, <code>NOTIFICACION_A_PADRES</code>, <code>MOTIVO_ATENCION</code>.</li> </ul> </li> </ul> <p>2. Data Conversion</p> <ul> <li>Descripci\u00f3n: Conversi\u00f3n de tipos de datos y ajuste de columnas.</li> <li>Propiedades:<ul> <li>Agrega un prefijo <code>Copy of</code> a las columnas convertidas.</li> <li>Convierte tipos de datos a <code>wstr</code>, <code>i4</code>, o <code>date</code> seg\u00fan corresponda.</li> </ul> </li> <li>Manejo de errores: <ul> <li>Disposici\u00f3n de error: <code>FailComponent</code>.</li> </ul> </li> </ul> <p>3. Derived Column</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas a partir de las columnas de entrada.</li> <li>Columnas creadas:<ul> <li><code>ID_FECHA</code>: Construido a partir del a\u00f1o, mes y d\u00eda de <code>Copy of FECHA_ATENCION</code>.</li> <li><code>ANIO_ACADEMICO</code>: Extra\u00eddo del a\u00f1o de <code>Copy of FECHA_ATENCION</code>.</li> </ul> </li> </ul> <p>4. Lookup</p> <ul> <li>Descripci\u00f3n: Busca en la tabla <code>DIM_POBLACION_MATRICULA</code> para enriquecer los datos con el identificador <code>ID_POBLACION_MATRICULA</code>.</li> <li>Consulta SQL: <code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> <li>Condiciones de b\u00fasqueda: <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> </ul> <p>5. Derived Column 1</p> <ul> <li>Descripci\u00f3n: Valida y ajusta el valor de <code>ID_POBLACION_MATRICULA</code> derivado.</li> <li>Expresi\u00f3n derivada:<ul> <li>Si el valor de <code>ID_POBLACION_MATRICULA</code> es nulo, asigna <code>-1</code>.</li> </ul> </li> </ul> <p>6. Lookup 1</p> <ul> <li>Descripci\u00f3n: Valida si el registro ya existe en la tabla <code>FACT_PSICORIENTACION</code> en funci\u00f3n de <code>ID_CASO</code>, <code>ID_FECHA</code>, y <code>ID_POBLACION_MATRICULA</code>.</li> <li>Consulta SQL: <pre><code>SELECT * \nFROM [Colegio].[FACT_PSICORIENTACION]\nWHERE ID_CASO = ? AND ID_FECHA = ? AND ID_POBLACION_MATRICULA = ?\n</code></pre></li> </ul> <p>7. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>FACT_PSICORIENTACION</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Colegio\".\"FACT_PSICORIENTACION\"</code>.</li> <li>Tama\u00f1o de lote: 0 (predeterminado, utiliza el tama\u00f1o del buffer interno).</li> <li>Tiempo de espera del comando: 30 segundos.</li> <li>Uso de <code>SqlBulkCopy</code>: Activado para mejorar el rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_16","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-11\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant Lookup1 as Lookup DIM_POBLACION_MATRICULA\n    participant DerivedColumn2 as Derived Column Ajustado\n    participant Lookup2 as Lookup FACT_PSICORIENTACION\n    participant Destination as Destino ADO.NET\n\n    ExcelSource-&gt;&gt;DataConversion: Leer datos desde Excel\n    DataConversion-&gt;&gt;DerivedColumn: Convertir datos y crear ID_FECHA\n    DerivedColumn-&gt;&gt;Lookup1: Validar informaci\u00f3n con DIM_POBLACION_MATRICULA\n    Lookup1-&gt;&gt;DerivedColumn2: Validar ID_POBLACION_MATRICULA\n    DerivedColumn2-&gt;&gt;Lookup2: Verificar existencia en FACT_PSICORIENTACION\n    Lookup2-&gt;&gt;Destination: Insertar en la tabla destino</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_reemplazo_docente","title":"Componente <code>Procesar FACT_REEMPLAZO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>Este paquete SSIS realiza la extracci\u00f3n, transformaci\u00f3n y carga de datos relacionados con la facturaci\u00f3n del reemplazo de docentes. Incluye tareas de conversi\u00f3n de datos, columnas derivadas, b\u00fasquedas en tablas de dimensiones y la carga en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_11","title":"Componentes del Flujo de Datos","text":"<ul> <li>Leer EP-EDF-03 Descripci\u00f3n: Fuente de datos que lee informaci\u00f3n desde un archivo Excel en la hoja \"Hoja1$\". Propiedades:         - <code>CommandTimeout</code>: 0         - <code>OpenRowset</code>: \"Hoja1$\" Columnas de Salida:  ID_REEMPLAZO, TIPO_DOCUMENTO_DOCENTE_AUSENTE, DOCUMENTO_DOCENTE_AUSENTE, GRADO, FECHA, BLOQUE_HORARIO, NUMERO_HORAS, CURSO, DOCENTE_AUSENTE, DOCENTE_REEMPLAZA, TIPO_DOCUMENTO_DOCENTE_REEMPLAZA, DOCUMENTO_DOCENTE_REEMPLAZA</li> <li> <p>Data Conversion Descripci\u00f3n: Realiza conversiones de tipos de datos para columnas espec\u00edficas. Columnas Transformadas:  </p> <ul> <li><code>ANIO_ACADEMICO \u2192 DT_I4</code></li> <li><code>TIPO_DOCUMENTO_DOCENTE_AUSENTE \u2192 wstr (longitud 20)</code></li> <li><code>DOCUMENTO_DOCENTE_AUSENTE \u2192 wstr (longitud 40)</code></li> <li><code>FECHA \u2192 date</code></li> <li><code>BLOQUE_HORARIO \u2192 wstr (longitud 40)</code></li> </ul> </li> <li> <p>Derived Column Descripci\u00f3n: Genera nuevas columnas basadas en expresiones. Columnas Derivadas:         ID_FECHA: Calculado como <code>(DT_I4)(YEAR([Copy of FECHA]) * 10000 + MONTH([Copy of FECHA]) * 100 + DAY([Copy of FECHA]))</code>.</p> </li> <li> <p>Lookup (DIM_PERSONAL) Descripci\u00f3n: Busca informaci\u00f3n de personal docente ausente en la tabla <code>[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]</code>. SQL Utilizado: <pre><code>SELECT [ID_PERSONAL],\n    CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO,\n    [ID_UNIDAD],\n    [TIPO_DOCUMENTO],\n    [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1;\n</code></pre> Columnas Vinculadas:         - Copy of TIPO_DOCUMENTO_DOCENTE_AUSENTE \u2192 TIPO_DOCUMENTO         - Copy of DOCUMENTO_DOCENTE_AUSENTE \u2192 DOCUMENTO         - Copy of ANIO_ACADEMICO \u2192 ANIO_ACADEMICO  </p> </li> <li> <p>Lookup (DIM_GRADO) Descripci\u00f3n: Busca informaci\u00f3n del grado en la tabla <code>[Colegio].[DIM_GRADO]</code>. SQL Utilizado: <pre><code>SELECT * FROM [Colegio].[DIM_GRADO];\n</code></pre> Columnas Vinculadas:         - Copy of GRADO \u2192 DESC_GRADO  </p> </li> <li> <p>Destino ADO.NET Descripci\u00f3n: Carga los datos transformados en la tabla <code>\"Colegio\".\"FACT_REEMPLAZO_DOCENTE\"</code>. Propiedades:         - <code>BatchSize</code>: 0         - <code>CommandTimeout</code>: 30         - <code>UseBulkInsertWhenPossible</code>: true Columnas de Entrada:  ID_FECHA  , ID_PERSONAL_AUSENTE  , ID_PERSONAL_REEMPLAZA  , ID_CURSO  , ID_GRADO  , ANIO_ACADEMICO  , FECHA  </p> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_17","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-03\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupDimPersonal as Lookup DIM_PERSONAL\n    participant LookupDimGrado as Lookup DIM_GRADO\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Transformaci\u00f3n de datos\n    DataConversion -&gt;&gt; DerivedColumn: Generaci\u00f3n de columnas derivadas\n    DerivedColumn -&gt;&gt; LookupDimPersonal: B\u00fasqueda de personal\n    LookupDimPersonal -&gt;&gt; LookupDimGrado: B\u00fasqueda de grado\n    LookupDimGrado -&gt;&gt; ADONETDestination: Carga de datos</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_reserva_espacios","title":"Componente <code>Procesar FACT_RESERVA_ESPACIOS</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>Este paquete SSIS procesa los datos relacionados con la reserva de espacios educativos. Realiza la extracci\u00f3n desde un archivo Excel, transforma los datos mediante conversiones y c\u00e1lculos, realiza b\u00fasquedas de informaci\u00f3n adicional en tablas de dimensiones y carga los datos transformados en una tabla de destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_12","title":"Componentes del Flujo de Datos","text":"<ul> <li> <p>Leer EP-EDF-12</p> <ul> <li>Descripci\u00f3n: Este componente extrae los datos desde un archivo Excel. Utiliza la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida:<code>ANIO_ACADEMICO</code>, <code>ID_RESERVA</code>, <code>FECHA_SOLICITUD</code>, <code>FECHA_RESERVA</code>, <code>TIPO_DOCUMENTO_DOCENTO</code>, <code>DOCUMENTO_DOCENTE</code>, <code>CORREO_DOCENTE</code>, <code>HORA_INICIO</code>, <code>HORA_FIN</code>, <code>ACTIVIDAD_PLANEADA</code>, <code>PLACA_PORTATIL</code>, <code>VIDEOBEAM</code></li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipos de datos para asegurar la compatibilidad con los componentes posteriores.</li> <li>Transformaciones:<ul> <li>ANIO_ACADEMICO \u2192 <code>DT_I4</code></li> <li>ID_RESERVA \u2192 <code>DT_I4</code></li> <li>FECHA_SOLICITUD \u2192 <code>DT_DATE</code></li> <li>FECHA_RESERVA \u2192 <code>DT_DATE</code></li> <li>TIPO_DOCUMENTO_DOCENTE \u2192 <code>wstr</code> (40)</li> <li>DOCUMENTO_DOCENTE \u2192 <code>wstr</code> (20)</li> <li>CORREO_DOCENTE \u2192 <code>wstr</code> (200)</li> <li>HORA_INICIO \u2192 <code>wstr</code> (40)</li> <li>HORA_FIN \u2192 <code>wstr</code> (40)</li> <li>ACTIVIDAD_PLANEADA \u2192 <code>wstr</code> (40)</li> <li>PLACA_PORTATIL \u2192 <code>wstr</code> (40)</li> <li>VIDEOBEAM \u2192 <code>wstr</code> (40)</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas a partir de c\u00e1lculos con las columnas existentes.</li> <li>Transformaciones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)(YEAR([Copy of FECHA_RESERVA]) * 10000 + MONTH([Copy of FECHA_RESERVA]) * 100 + DAY([Copy of FECHA_RESERVA]))</code></li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_PERSONAL)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]</code> para obtener informaci\u00f3n adicional del personal docente.</li> <li>SQL Utilizado:     <pre><code>SELECT [ID_PERSONAL],\n       CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO,\n       [ID_UNIDAD],\n       [TIPO_DOCUMENTO],\n       [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1;\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li>Copy of ANIO_ACADEMICO \u2192 ANIO_ACADEMICO</li> <li>Copy of TIPO_DOCUMENTO_DOCENTE \u2192 TIPO_DOCUMENTO</li> <li>Copy of DOCUMENTO_DOCENTE \u2192 DOCUMENTO</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>\"Colegio\".\"FACT_RESERVA_ESPACIOS\"</code>.</li> <li>Propiedades:<ul> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Columnas de Entrada:     <code>ID_FECHA</code>, <code>ID_PERSONAL</code>, <code>Copy of ID_RESERVA</code>, <code>Copy of DOCUMENTO_DOCENTE</code>, <code>Copy of FECHA_SOLICITUD</code>, <code>Copy of FECHA_RESERVA</code>, <code>Copy of CORREO_DOCENTE</code>, <code>Copy of HORA_INICIO</code>, <code>Copy of HORA_FIN</code>, <code>Copy of ACTIVIDAD_PLANEADA</code>, <code>Copy of PLACA_PORTATIL</code>, <code>Copy of VIDEOBEAM</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_18","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-12\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupDimPersonal as Lookup DIM_PERSONAL\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Transformaci\u00f3n de datos\n    DataConversion -&gt;&gt; DerivedColumn: Generaci\u00f3n de columnas derivadas\n    DerivedColumn -&gt;&gt; LookupDimPersonal: B\u00fasqueda de datos adicionales\n    LookupDimPersonal -&gt;&gt; ADONETDestination: Carga de datos transformados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_saber11_colegios","title":"Componente <code>Procesar FACT_SABER11_COLEGIOS</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>Este paquete de SSIS procesa datos relacionados con las evaluaciones del SABER 11 para colegios, extrayendo informaci\u00f3n de un archivo Excel, transformando y enriqueciendo los datos con c\u00e1lculos derivados y b\u00fasquedas, y carg\u00e1ndolos en una tabla de destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_13","title":"Componentes del Flujo de Datos","text":"<ul> <li> <p>Leer EP-EDF-08</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel ubicado en <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code> (a\u00f1o acad\u00e9mico del registro)</li> <li><code>ID_REGISTRO</code> (identificador del registro)</li> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> (c\u00f3digo DANE del establecimiento educativo)</li> <li><code>NOMBRE_ESTABLECIMIENTO_EDUCATIVO</code> (nombre del establecimiento)</li> <li><code>RESULTADO</code> (resultado del examen SABER 11)</li> <li><code>CATEGORIA_SABER11</code> (categor\u00eda del colegio seg\u00fan el SABER 11)</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipo de datos para asegurar la compatibilidad con los siguientes pasos del flujo de datos.</li> <li>Transformaciones:<ul> <li><code>ANIO_ACADEMICO</code> \u2192 <code>DT_I4</code></li> <li><code>ID_REGISTRO</code> \u2192 <code>wstr</code> (255)</li> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> \u2192 <code>wstr</code> (40)</li> <li><code>NOMBRE_ESTABLECIMIENTO_EDUCATIVO</code> \u2192 <code>wstr</code> (200)</li> <li><code>RESULTADO</code> \u2192 <code>wstr</code> (40)</li> <li><code>CATEGORIA_SABER11</code> \u2192 <code>wstr</code> (40)</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>[DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS]</code> para enriquecer los datos con informaci\u00f3n adicional.</li> <li>SQL Utilizado:     <pre><code>SELECT [ID_REGISTRO],\n       [ID_FECHA],\n       CAST([ANIO_ACADEMICO] AS INT) AS ANIO_ACADEMICO,\n       [COD_ESTABLECIMIENTO_EDUCATIVO],\n       [NOMBRE_EE],\n       [RESULTADO],\n       [CATEGORIA_SABER11]\nFROM [DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS];\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> \u2192 <code>COD_ESTABLECIMIENTO_EDUCATIVO</code></li> <li><code>ANIO_ACADEMICO</code> \u2192 <code>ANIO_ACADEMICO</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Calcula una columna derivada para el identificador de fecha.</li> <li>Transformaciones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)((DT_STR,4,1252)ANIO_ACADEMICO + \"1201\")</code></li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino <code>\"Colegio\".\"FACT_SABER11_COLEGIOS\"</code>.</li> <li>Propiedades:<ul> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_FECHA</code> (identificador \u00fanico para la fecha derivada)</li> <li><code>ANIO_ACADEMICO</code> (a\u00f1o acad\u00e9mico)</li> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> (c\u00f3digo DANE del establecimiento)</li> <li><code>NOMBRE_ESTABLECIMIENTO_EDUCATIVO</code> (nombre del establecimiento)</li> <li><code>RESULTADO</code> (resultado del examen)</li> <li><code>CATEGORIA_SABER11</code> (categor\u00eda seg\u00fan el examen SABER 11)</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_19","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-08\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup SABER11\n    participant DerivedColumn as Derived Column\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Transformaci\u00f3n de datos\n    DataConversion -&gt;&gt; Lookup: Enriquecimiento de datos\n    Lookup -&gt;&gt; DerivedColumn: Generaci\u00f3n de columnas derivadas\n    DerivedColumn -&gt;&gt; ADONETDestination: Carga de datos transformados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_saber11_individual","title":"Componente <code>Procesar FACT_SABER11_INDIVIDUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>Este paquete de SSIS procesa datos individuales del SABER 11, extrayendo informaci\u00f3n desde un archivo Excel, transformando y enriqueciendo los datos mediante conversiones, columnas derivadas y b\u00fasquedas, para finalmente almacenarlos en una tabla de destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_14","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Leer EP-EDF-07</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel ubicado en <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida: <code>ANIO_ACADEMICO</code>, <code>ID_REGISTRO</code>, <code>RESULTADO</code>, <code>BP_ESTUDIANTE</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>FECHA</code>, <code>TEMATICA</code></li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas para asegurar la compatibilidad con el resto del flujo.</li> <li>Transformaciones:<ul> <li><code>ANIO_ACADEMICO</code> \u2192 <code>DT_I4</code></li> <li><code>RESULTADO</code> \u2192 <code>wstr</code> (40)</li> <li><code>BP_ESTUDIANTE</code> \u2192 <code>wstr</code> (40)</li> <li><code>TIPO_DOCUMENTO</code> \u2192 <code>wstr</code> (40)</li> <li><code>DOCUMENTO</code> \u2192 <code>wstr</code> (20)</li> <li><code>FECHA</code> \u2192 <code>date</code></li> <li><code>TEMATICA</code> \u2192 <code>wstr</code> (40)</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Genera un identificador \u00fanico para las fechas en formato <code>YYYYMMDD</code>.</li> <li>Transformaciones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)(YEAR([FECHA]) * 10000 + MONTH([FECHA]) * 100 + DAY([FECHA]))</code></li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_POBLACION_MATRICULA)</p> <ul> <li>Descripci\u00f3n: Enriquecer los datos con informaci\u00f3n de la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li><code>BP_ESTUDIANTE</code> \u2192 <code>PARTNER</code></li> </ul> </li> <li>Salida:<ul> <li><code>ID_POBLACION_MATRICULA</code></li> </ul> </li> </ul> </li> <li> <p>Lookup (FACT_SABER11_INDIVIDUAL)</p> <ul> <li>Descripci\u00f3n: Verifica si los datos ya existen en la tabla de destino <code>[Colegio].[FACT_SABER11_INDIVIDUAL]</code>.</li> <li>Consulta SQL:     <pre><code>SELECT \n    [ID_REGISTRO],\n    [ID_FECHA],\n    CAST([ANIO_ACADEMICO] AS INT) AS ANIO_ACADEMICO,\n    [ID_POBLACION_MATRICULA],\n    [TEMATICA],\n    [RESULTADO]\nFROM [Colegio].[FACT_SABER11_INDIVIDUAL]\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li><code>ANIO_ACADEMICO</code></li> <li><code>TEMATICA</code></li> <li><code>ID_POBLACION_MATRICULA</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column (Validaci\u00f3n de ID_POBLACION_MATRICULA)</p> <ul> <li>Descripci\u00f3n: Agrega una validaci\u00f3n para la columna <code>ID_POBLACION_MATRICULA</code>.</li> <li>Transformaciones:<ul> <li><code>ID_POBLACION_MATRICULA</code>: <code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA</code></li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>\"Colegio\".\"FACT_SABER11_INDIVIDUAL\"</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"FACT_SABER11_INDIVIDUAL\"</code></li> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_FECHA</code></li> <li><code>ID_POBLACION_MATRICULA</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>TEMATICA</code></li> <li><code>RESULTADO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_20","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-07\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column (Fecha)\n    participant LookupDIM as Lookup DIM_POBLACION_MATRICULA\n    participant LookupFACT as Lookup FACT_SABER11_INDIVIDUAL\n    participant DerivedColumn2 as Derived Column (Validaci\u00f3n)\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Convertir tipos de datos\n    DataConversion -&gt;&gt; DerivedColumn: Crear ID_FECHA\n    DerivedColumn -&gt;&gt; LookupDIM: Enriquecer datos con ID_POBLACION_MATRICULA\n    LookupDIM -&gt;&gt; LookupFACT: Verificar existencia en FACT_SABER11_INDIVIDUAL\n    LookupFACT -&gt;&gt; DerivedColumn2: Validar ID_POBLACION_MATRICULA\n    DerivedColumn2 -&gt;&gt; ADONETDestination: Insertar datos en tabla de destino</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_servicio_social","title":"Componente <code>Procesar FACT_SERVICIO_SOCIAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>Este paquete de SSIS procesa datos relacionados con el servicio social de estudiantes, transformando y enriqueciendo la informaci\u00f3n desde un archivo Excel para almacenarla en una base de datos relacional. Incluye conversiones de datos, b\u00fasqueda de informaci\u00f3n relacionada y validaciones, y finalmente inserta los datos en una tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_15","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Leer EP-EDF-13</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel, ubicado en la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code>, <code>BP_ESTUDIANTE</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>GRADO</code>, <code>CURSO</code>, <code>HORARIO</code>, <code>PROYECTO</code>, <code>PAZ_Y_SALVO</code>, <code>HORAS_EJECUTADAS</code>, <code>AUTORIZACION_ACUDIENTE</code></li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte las columnas para asegurar compatibilidad en el flujo.</li> <li>Transformaciones:<ul> <li><code>ANIO_ACADEMICO</code> \u2192 <code>DT_I4</code></li> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>GRADO</code>, <code>CURSO</code>, <code>HORARIO</code>, <code>PROYECTO</code>, <code>PAZ_Y_SALVO</code>, <code>HORAS_EJECUTADAS</code>, <code>AUTORIZACION_ACUDIENTE</code> \u2192 <code>wstr</code></li> </ul> </li> <li>Columnas Convertidas: Todas las columnas del componente de entrada.</li> </ul> </li> <li> <p>Lookup: DIM_POBLACION_MATRICULA</p> <ul> <li>Descripci\u00f3n: Busca el identificador de poblaci\u00f3n en la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code> usando <code>BP_ESTUDIANTE</code>.</li> <li>Consulta SQL:     <pre><code>SELECT *\nFROM [Colegio].[DIM_POBLACION_MATRICULA]\nWHERE [PARTNER] = ?\n</code></pre></li> <li>Columnas de Salida: <code>ID_POBLACION_MATRICULA</code></li> </ul> </li> <li> <p>Lookup: DIM_CURSO</p> <ul> <li>Descripci\u00f3n: Busca el identificador del curso en la tabla <code>[Colegio].[DIM_CURSO]</code> usando <code>DESC_CURSO</code>.</li> <li>Consulta SQL:     <pre><code>SELECT *\nFROM [Colegio].[DIM_CURSO]\nWHERE [DESC_CURSO] = ?\n</code></pre></li> <li>Columnas de Salida: <code>ID_CURSO</code></li> </ul> </li> <li> <p>Lookup: DIM_GRADO</p> <ul> <li>Descripci\u00f3n: Busca el identificador del grado en la tabla <code>[Colegio].[DIM_GRADO]</code> usando <code>DESC_GRADO</code>.</li> <li>Consulta SQL:     <pre><code>SELECT *\nFROM [Colegio].[DIM_GRADO]\nWHERE [DESC_GRADO] = ?\n</code></pre></li> <li>Columnas de Salida: <code>ID_GRADO</code></li> </ul> </li> <li> <p>Lookup: FACT_SERVICIO_SOCIAL</p> <ul> <li>Descripci\u00f3n: Verifica la existencia de registros en la tabla <code>[Colegio].[FACT_SERVICIO_SOCIAL]</code>.</li> <li>Consulta SQL:     <pre><code>SELECT [ID_REGISTRO], [ANIO_ACADEMICO], [ID_POBLACION_MATRICULA], [ID_CURSO], [ID_GRADO]\nFROM [Colegio].[FACT_SERVICIO_SOCIAL]\nWHERE [ANIO_ACADEMICO] = ? AND [ID_POBLACION_MATRICULA] = ? AND [ID_CURSO] = ? AND [ID_GRADO] = ?\n</code></pre></li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Agrega validaciones para columnas enriquecidas.</li> <li>Transformaciones:<ul> <li><code>ID_POBLACION_MATRICULA</code>: <code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA</code></li> <li><code>ID_CURSO</code>: <code>ISNULL(ID_CURSO) ? -1 : ID_CURSO</code></li> <li><code>ID_GRADO</code>: <code>ISNULL(ID_GRADO) ? -1 : ID_GRADO</code></li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>\"Colegio\".\"FACT_SERVICIO_SOCIAL\"</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"FACT_SERVICIO_SOCIAL\"</code></li> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_21","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-13\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup DIM_POBLACION_MATRICULA\n    participant Lookup2 as Lookup DIM_CURSO\n    participant Lookup3 as Lookup DIM_GRADO\n    participant Lookup4 as Lookup FACT_SERVICIO_SOCIAL\n    participant DerivedColumn as Derived Column\n    participant ADO as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Convertir datos\n    DataConversion -&gt;&gt; Lookup1: Buscar ID_POBLACION_MATRICULA\n    Lookup1 -&gt;&gt; Lookup2: Buscar ID_CURSO\n    Lookup2 -&gt;&gt; Lookup3: Buscar ID_GRADO\n    Lookup3 -&gt;&gt; Lookup4: Verificar existencia\n    Lookup4 -&gt;&gt; DerivedColumn: Validar IDs\n    DerivedColumn -&gt;&gt; ADO: Insertar datos en FACT_SERVICIO_SOCIAL</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/","title":"05. CEDESARROLLO_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#cedesarrollo_dimensiones","title":"CEDESARROLLO_DIMENSIONES","text":"<p>El paquete SSIS \"05-CEDESARROLLO_DIMENSIONES\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar datos esenciales relacionados con dimensiones clave como per\u00edodos acad\u00e9micos, programas educativos, jornadas, y poblaci\u00f3n matriculada. Este paquete asegura la calidad e integridad de los datos consolidados en el Data Warehouse <code>DWH_COMFENALCO</code>, proporcionando una base s\u00f3lida para an\u00e1lisis estrat\u00e9gicos y toma de decisiones.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El prop\u00f3sito principal es gestionar, transformar y cargar datos relacionados con dimensiones transversales del \u00e1mbito educativo y administrativo, garantizando su consistencia y disponibilidad para an\u00e1lisis detallados en plataformas de inteligencia de negocios.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PROGRAMA</code>, <code>DIM_JORNADA</code>, <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Archivos Excel:</li> <li>Informaci\u00f3n de jornadas y programas.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaciones (<code>Lookup</code>):<ul> <li>Asegura consistencia mediante b\u00fasquedas en tablas maestras como <code>DIM_ESTUDIANTES</code> y <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Garantiza compatibilidad con las tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Genera identificadores y valores predeterminados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_PERIODO_ACADEMICO</code></li> <li><code>DIM_PROGRAMA</code></li> <li><code>DIM_JORNADA</code></li> <li><code>DIM_POBLACION_MATRICULA</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python para automatizar tareas de descarga y validaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_PERIODO_ACADEMICO:</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_UNIDAD</code>, <code>PERIODO_ACADEMICO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>.</li> </ul> </li> <li> <p>DIM_PROGRAMA:</p> <ul> <li><code>ID_PROGRAMA</code>, <code>NOMBRE_PROGRAMA</code>, <code>DESCRIPCION</code>.</li> </ul> </li> <li> <p>DIM_JORNADA:</p> <ul> <li><code>ID_JORNADA</code>, <code>NOMBRE_JORNADA</code>, <code>HORARIO</code>.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA:</p> <ul> <li><code>ID_POBLACION</code>, <code>NOMBRE</code>, <code>DOCUMENTO</code>, <code>GENERO</code>, <code>FECHA_NACIMIENTO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagramas","title":"Diagramas","text":"<p>1. Diagrama de Flujo de Datos</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de dimensiones\n    SSIS -&gt;&gt; Excel: Leer informaci\u00f3n adicional\n    SSIS -&gt;&gt; Python: Ejecutar scripts de validaci\u00f3n\n    SSIS -&gt;&gt; DWH: Cargar datos procesados</code></pre> <p>2. Diagrama ER para Tablas de Dimensiones</p> <pre><code>erDiagram\n    DIM_PERIODO_ACADEMICO {\n        int ID_PERIODO\n        int ID_UNIDAD\n        string PERIODO_ACADEMICO\n        date FECHA_INICIO\n        date FECHA_FIN\n    }\n    DIM_PROGRAMA {\n        int ID_PROGRAMA\n        string NOMBRE_PROGRAMA\n        string DESCRIPCION\n    }\n    DIM_JORNADA {\n        int ID_JORNADA\n        string NOMBRE_JORNADA\n        string HORARIO\n    }\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION\n        string NOMBRE\n        string DOCUMENTO\n        string GENERO\n        date FECHA_NACIMIENTO\n    }\n    DIM_PERIODO_ACADEMICO ||--|| DIM_JORNADA : \"Relaci\u00f3n de Per\u00edodo con Jornadas\"\n    DIM_JORNADA ||--|| DIM_PROGRAMA : \"Asociaci\u00f3n a Programas\"\n    DIM_POBLACION_MATRICULA ||--|| DIM_PROGRAMA : \"Estudiantes en Programas\"</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-actualizar-dim-estudiantes","title":"Componente <code>Actualizar Dim Estudiantes</code>","text":"<p>Este componente es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS dise\u00f1ado para actualizar la dimensi\u00f3n de estudiantes en la base de datos. La tarea toma como entrada los datos extra\u00eddos y transformados (provenientes del componente \"Consulta Motor\") y los carga en la tabla \"Cedesarrollo\".\"DIM_ESTUDIANTES\" utilizando una conexi\u00f3n ADO.NET. Esto garantiza que la informaci\u00f3n de los estudiantes se mantenga actualizada y refleje los cambios que provienen de las fuentes de datos integradas.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<ul> <li> <p>Actualizaci\u00f3n de Datos de Estudiantes:   Integrar y actualizar la informaci\u00f3n de la dimensi\u00f3n de estudiantes, asegurando que los registros contengan los datos m\u00e1s recientes provenientes de diversas fuentes.</p> </li> <li> <p>Consolidaci\u00f3n de Informaci\u00f3n:   Actualizar campos clave como el tipo de documento, n\u00famero de documento y los identificadores asociados (ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE) en la tabla de estudiantes, permitiendo an\u00e1lisis precisos en el Data Warehouse.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-tecnica","title":"Descripci\u00f3n T\u00e9cnica","text":"<ul> <li> <p>Tipo de Tarea:   Data Flow Task (Microsoft.Pipeline).</p> </li> <li> <p>Origen de Datos:   La informaci\u00f3n se recibe de la salida del componente \"Consulta Motor\", que extrae y transforma los datos desde el \u00e1rea de staging.</p> </li> <li> <p>Transformaciones y Mapeos:   Los datos provistos incluyen, entre otros, las siguientes columnas:</p> <ul> <li>TIPO_DOCUMENTO (cadena de caracteres, 40 caracteres).</li> <li>DOCUMENTO (cadena de caracteres, 255 caracteres).</li> <li>ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE (n\u00fameros enteros).</li> </ul> </li> <li> <p>Destino de Datos:   Los registros se cargan en la tabla \"Cedesarrollo\".\"DIM_ESTUDIANTES\" mediante un destino ADO.NET configurado para:</p> <ul> <li>Utilizar inserciones masivas (Bulk Insert) para optimizar el rendimiento.</li> <li>Par\u00e1metros configurados: <code>BatchSize</code> = 0 y <code>CommandTimeout</code> = 30 segundos.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#flujo-de-ejecucion","title":"Flujo de Ejecuci\u00f3n","text":"<ol> <li> <p>Extracci\u00f3n y Transformaci\u00f3n:    La salida del componente \"Consulta Motor\" suministra los datos de estudiantes, los cuales incluyen la informaci\u00f3n necesaria para la actualizaci\u00f3n de la dimensi\u00f3n.</p> </li> <li> <p>Carga de Datos:    Los datos transformados se cargan en la tabla \"Cedesarrollo\".\"DIM_ESTUDIANTES\" actualizando o insertando nuevos registros seg\u00fan corresponda, asegurando que la dimensi\u00f3n refleje la informaci\u00f3n m\u00e1s reciente.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ConsultaMotor as Componente \"Consulta Motor\"\n    participant ADO_Dest as Destino ADO.NET (\"Actualizar Registros\")\n    participant DB as Base de Datos\n\n    ConsultaMotor -&gt;&gt; ADO_Dest: Env\u00eda datos (TIPO_DOCUMENTO, DOCUMENTO, ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE)\n    ADO_Dest -&gt;&gt; DB: Actualiza la tabla \"Cedesarrollo\".\"DIM_ESTUDIANTES\"\n    DB --&gt;&gt; ADO_Dest: Confirmaci\u00f3n de actualizaci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_jornada","title":"Componente <code>DIM_JORNADA</code>","text":"<p>El contenedor <code>DIM_JORNADA</code> es un contenedor de secuencias que agrupa dos flujos de datos relacionados con la actualizaci\u00f3n de la dimensi\u00f3n de jornadas. Este contenedor integra dos procesos principales: uno denominado <code>DIM_JORNADA cede</code> y otro <code>DIM_JORNADA emp</code>. Cada uno se encarga de procesar, transformar y cargar datos de jornadas desde fuentes Excel hacia la tabla de destino, aplicando distintas validaciones y transformaciones espec\u00edficas para cada flujo.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#1-proceso-dim_jornada-cede","title":"1. Proceso: DIM_JORNADA cede","text":"<p>Objetivo: Procesar y transformar datos relacionados con jornadas para la dimensi\u00f3n \u201ccede\u201d. Se realiza la lectura de datos desde un archivo Excel, se aplican transformaciones como la conversi\u00f3n y derivaci\u00f3n de columnas, se filtran registros vac\u00edos, y se enriquecen los datos mediante un componente Lookup que compara con la tabla de destino para identificar registros nuevos.</p> <p>Componentes del Flujo:</p> <ul> <li> <p>Excel Source:   Extrae datos de la hoja <code>Sheet1$</code> utilizando un administrador de conexi\u00f3n OLE DB.</p> </li> <li> <p>Sort JORNADA:   Ordena los registros por el campo <code>JORNADA</code> y elimina duplicados, garantizando un flujo de datos limpio y ordenado.</p> </li> <li> <p>ELIMINAR VACIOS (Conditional Split):   Filtra filas que no sean nulas y cuyo largo sea mayor a 0 en la columna <code>JORNADA</code> utilizando la condici\u00f3n: <pre><code>!ISNULL(JORNADA) &amp;&amp; LEN(JORNADA) &gt; 0\n</code></pre></p> </li> <li> <p>Derived Column:   Transforma el campo <code>JORNADA</code> para ajustarlo a un formato de cadena de longitud m\u00e1xima 40 y asigna valores constantes para campos como <code>ID_UNIDAD</code> (valor fijo 2) y <code>ID_JORNADA</code> (inicialmente 0).</p> </li> <li> <p>Lookup:   Realiza una b\u00fasqueda en la tabla de destino <code>[Cedesarrollo].[DIM_JORNADA]</code> utilizando los campos <code>JORNADA</code> (convertida) e <code>ID_UNIDAD</code> para determinar si el registro ya existe.  </p> <ul> <li>No coincidencias: Los registros que no se encuentran se env\u00edan a la siguiente etapa para ser insertados.</li> </ul> </li> <li> <p>Guardar en DIM_JORNADA:   Inserta los registros procesados y validados en la tabla destino <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code>.  </p> <ul> <li>Propiedades clave: </li> <li>BatchSize = 0  </li> <li>CommandTimeout = 30 segundos  </li> <li>Inserci\u00f3n masiva activada (UseBulkInsertWhenPossible = true)</li> </ul> </li> </ul> <p>Diagrama de Secuencia (DIM_JORNADA cede):</p> <pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source\n    participant Sort as Sort JORNADA\n    participant EliminarVacios as ELIMINAR VACIOS\n    participant DerivedColumn as Derived Column\n    participant Lookup as Lookup\n    participant Guardar as Guardar en DIM_JORNADA\n\n    ExcelSource -&gt;&gt; Sort: Extrae datos de la hoja Sheet1$\n    Sort -&gt;&gt; EliminarVacios: Ordena y elimina duplicados\n    EliminarVacios -&gt;&gt; DerivedColumn: Filtra registros v\u00e1lidos\n    DerivedColumn -&gt;&gt; Lookup: Transforma y asigna ID_UNIDAD\n    Lookup -&gt;&gt; Guardar: Env\u00eda registros no coincidentes</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#2-proceso-dim_jornada-emp","title":"2. Proceso: DIM_JORNADA emp","text":"<p>Objetivo: Procesar y transformar datos relacionados con jornadas para la dimensi\u00f3n \u201cemp\u201d. Este flujo se orienta a la extracci\u00f3n de informaci\u00f3n de otra fuente Excel, con sus propias transformaciones y validaciones para asegurar que los datos sean consistentes antes de ser cargados en la misma tabla de destino <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code>.</p> <p>Componentes del Flujo:</p> <ul> <li> <p>Excel Source 1:   Lee los datos de la hoja <code>Sheet1$</code> desde un archivo Excel utilizando un administrador de conexi\u00f3n espec\u00edfico para esta fuente.</p> </li> <li> <p>Sort:   Ordena los registros por la columna <code>JORNADA</code> y elimina duplicados, prepar\u00e1ndolos para el procesamiento posterior.</p> </li> <li> <p>Conditional Split:   Filtra las filas verificando que el campo <code>JORNADA</code> no sea nulo y tenga contenido (condici\u00f3n: <code>!ISNULL(JORNADA) &amp;&amp; LEN(JORNADA) &gt; 0</code>).</p> </li> <li> <p>Derived Column:   Genera la columna <code>JORNADA_Convertida</code>, convirtiendo el valor del campo <code>JORNADA</code> a una cadena de longitud 40. Adem\u00e1s, asigna valores fijos a <code>ID_UNIDAD</code> (valor 3) y a <code>ID_JORNADA</code> (inicialmente 0).</p> </li> <li> <p>Lookup:   Compara los registros procesados con la tabla de destino <code>[Cedesarrollo].[DIM_JORNADA]</code> mediante un Lookup que utiliza los campos <code>JORNADA_Convertida</code> e <code>ID_UNIDAD</code> para identificar registros existentes.  </p> <ul> <li>Registros sin coincidencia: Se env\u00edan a la salida de \u201cNo Match\u201d para ser insertados.</li> </ul> </li> <li> <p>Destino de ADO.NET:   Inserta los datos transformados y filtrados en la tabla <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code>.  </p> <ul> <li>Propiedades clave: </li> <li>BatchSize = 0  </li> <li>CommandTimeout = 30 segundos  </li> <li>Bulk Insert activado</li> </ul> </li> </ul> <p>Diagrama de Secuencia (DIM_JORNADA emp):</p> <pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source 1\n    participant Sort as Sort\n    participant ConditionalSplit as Conditional Split\n    participant DerivedColumn as Derived Column\n    participant Lookup as Lookup\n    participant Destino as Destino de ADO.NET\n\n    ExcelSource -&gt;&gt; Sort: Extrae datos de Excel\n    Sort -&gt;&gt; ConditionalSplit: Ordena y filtra registros v\u00e1lidos\n    ConditionalSplit -&gt;&gt; DerivedColumn: Pasa registros v\u00e1lidos\n    DerivedColumn -&gt;&gt; Lookup: Aplica transformaciones y asigna ID_UNIDAD\n    Lookup -&gt;&gt; Destino: Inserta registros nuevos en DIM_JORNADA</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_periodo_academico-py","title":"Componente <code>dim_periodo_academico py</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tarea dim_periodo_academico py ejecuta un script de Python para procesar la dimensi\u00f3n <code>PERIODO_ACADEMICO</code>. Este script realiza operaciones espec\u00edficas relacionadas con la extracci\u00f3n, transformaci\u00f3n y carga (ETL) para actualizar la tabla de dimensiones en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#detalles-de-la-configuracion","title":"Detalles de la Configuraci\u00f3n","text":"<ol> <li> <p>Ejecutable</p> <ul> <li>Ruta del ejecutable:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Script ejecutado:      <pre><code>dim_periodo_academico.py\n</code></pre></li> </ul> </li> <li> <p>Directorio de trabajo</p> <ul> <li>Ruta:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul> </li> <li> <p>Argumentos</p> <ul> <li>Script llamado con el siguiente comando:     <pre><code>dim_periodo_academico.py\n</code></pre></li> </ul> </li> <li> <p>Propiedades Avanzadas</p> <ul> <li>Variables utilizadas:<ul> <li><code>Python_Executable</code>: Variable del proyecto que define la ruta del ejecutable de Python.</li> <li><code>Working_Directory</code>: Variable que especifica el directorio base para los scripts.</li> </ul> </li> <li>Propiedad de <code>Executable</code>:      <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>Propiedad de <code>WorkingDirectory</code>:      <pre><code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSISPackage as Paquete SSIS\n    participant PythonScript as dim_periodo_academico.py\n\n    SSISPackage-&gt;&gt;PythonScript: Llama al ejecutable de Python\n    PythonScript-&gt;&gt;Database: Procesa datos de `PERIODO_ACADEMICO`\n    PythonScript-&gt;&gt;SSISPackage: Retorna el estado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_periodo_academico","title":"Componente <code>DIM_PERIODO_ACADEMICO</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos en SSIS realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) para la dimensi\u00f3n <code>DIM_PERIODO_ACADEMICO</code>. Utiliza datos de una fuente de Excel, realiza conversiones de tipo y valida los registros con una tabla de referencia antes de cargarlos en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae los datos desde una hoja de Excel llamada <code>Sheet1$</code>.</li> <li>Conexi\u00f3n: <code>Administrador de conexiones con Excel 8</code>.</li> <li>Columnas Extra\u00eddas:<ul> <li><code>PERIODO</code> (Texto, longitud 255)</li> <li><code>ID_UNIDAD</code> (Real)</li> <li><code>FECHA_INICIO</code> (Fecha)</li> <li><code>FECHA_FIN</code> (Fecha)</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos de entrada en tipos y formatos espec\u00edficos.</li> <li>Columnas Convertidas:</li> <li><code>_PERIODO</code> (Texto, longitud 40)</li> <li><code>_ID_UNIDAD</code> (Entero)</li> <li><code>_FECHA_INICIO</code> (Fecha)</li> <li><code>_FECHA_FIN</code> (Fecha)</li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Compara los registros con la tabla <code>DIM_PERIODO_ACADEMICO</code> en la base de datos para identificar coincidencias.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code>.</li> <li>Consulta de Validaci\u00f3n: <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\nWHERE [PERIODO_ACADEMICO] = ? \n    AND [ID_UNIDAD] = ?\n</code></pre></li> <li>Columnas Validadas: <code>PERIODO_ACADEMICO</code>, <code>ID_UNIDAD</code></li> <li>Salidas:<ul> <li><code>Match Output</code>: Registros coincidentes.</li> <li><code>No Match Output</code>: Registros sin coincidencias, enviados para carga.</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Inserta los registros no coincidentes en la tabla de destino.</li> <li>Tabla de Destino: <code>\"Cedesarrollo\".\"DIM_PERIODO_ACADEMICO\"</code>.</li> <li>Propiedades:</li> <li>Inserci\u00f3n Masiva: Activada.</li> <li>Batch Size: 0 (Utiliza el tama\u00f1o predeterminado del b\u00fafer de SSIS).</li> <li>Timeout de Comando: 30 segundos.</li> <li>Columnas Insertadas: <code>PERIODO_ACADEMICO</code>, <code>ID_UNIDAD</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Fuente de Excel\n    participant DataConversion as Conversi\u00f3n de Datos\n    participant Lookup as Validaci\u00f3n de Datos\n    participant Destino as Base de Datos\n\n    Excel-&gt;&gt;DataConversion: Extraer datos\n    DataConversion-&gt;&gt;Lookup: Validar con tabla de referencia\n    Lookup-&gt;&gt;Destino: Insertar registros no coincidentes</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-tarea-cede_diseno_curricular","title":"Componente <code>Tarea cede_Dise\u00f1o_Curricular</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Tarea cede_Dise\u00f1o_Curricular</code> es un componente de ejecuci\u00f3n de procesos en SSIS que utiliza un script Python para procesar o descargar datos relacionados con el dise\u00f1o curricular de una instituci\u00f3n educativa. Este script es ejecutado en un entorno Python configurado previamente.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#detalles-del-componente","title":"Detalles del Componente","text":"<ul> <li>Tipo de Tarea: <code>Execute Process Task</code>.</li> <li>Descripci\u00f3n: Ejecuta un script Python (<code>download.py</code>) con un argumento espec\u00edfico (<code>--key cede_Dise\u00f1o_Curricular</code>) para realizar tareas como descargar o transformar datos asociados al dise\u00f1o curricular.</li> <li>Propiedades Clave:<ul> <li>Ejecutable: Ruta al ejecutable de Python configurado en la variable <code>Python_Executable</code> del proyecto.</li> <li>Directorio de Trabajo: Ruta configurada en la variable <code>Working_Directory</code> del proyecto.</li> <li>Argumentos: <code>download.py --key cede_Dise\u00f1o_Curricular</code>.</li> </ul> </li> </ul> <p>Propiedades T\u00e9cnicas</p> Propiedad Valor Executable <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code> Working Directory <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code> Arguments <code>download.py --key cede_Dise\u00f1o_Curricular</code> Tiempo de Ejecuci\u00f3n No especificado (timeout predeterminado del sistema). <p>Flujo de Trabajo</p> <ol> <li> <p>Inicio del Proceso: </p> <ul> <li>La tarea se inicia autom\u00e1ticamente al ejecutarse el paquete SSIS.</li> </ul> </li> <li> <p>Definici\u00f3n del Contexto:</p> <ul> <li>El entorno de ejecuci\u00f3n y los argumentos se configuran din\u00e1micamente utilizando expresiones vinculadas a las variables del proyecto:</li> <li><code>@[$Project::Python_Executable]</code> para el ejecutable.</li> <li><code>@[$Project::Working_Directory]</code> para el directorio de trabajo.</li> </ul> </li> <li> <p>Ejecuci\u00f3n del Script:</p> <ul> <li>El script Python (<code>download.py</code>) se ejecuta con el argumento <code>--key cede_Dise\u00f1o_Curricular</code>.</li> <li>El script puede realizar operaciones como descarga de datos, validaci\u00f3n, transformaci\u00f3n, etc.</li> </ul> </li> <li> <p>Finalizaci\u00f3n:</p> <ul> <li>El proceso concluye una vez que el script finaliza su ejecuci\u00f3n. Los resultados del script pueden ser monitoreados mediante los logs configurados en el paquete.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as Script Python\n    participant Sistema as Sistema Operativo\n\n    SSIS -&gt;&gt; Python: Ejecutar `download.py --key cede_Dise\u00f1o_Curricular`\n    Python -&gt;&gt; Sistema: Leer datos del directorio configurado\n    Sistema -&gt;&gt; Python: Proveer acceso a los archivos\n    Python -&gt;&gt; Python: Procesar o transformar datos\n    Python -&gt;&gt; SSIS: Retornar estado de finalizaci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_programa","title":"Componente <code>Data DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Data DIM_PROGRAMA</code> implementa un flujo de datos para extraer informaci\u00f3n de un archivo Excel, procesarla mediante operaciones de clasificaci\u00f3n, agregaci\u00f3n y b\u00fasquedas, y finalmente cargar los datos en la tabla <code>DIM_PROGRAMA</code> de la base de datos. Este proceso se utiliza para estructurar y consolidar datos relacionados con programas acad\u00e9micos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos: <code>Excel Source</code></p> <ul> <li>Prop\u00f3sito: Leer datos desde un archivo Excel ubicado en la ruta configurada en el administrador de conexiones <code>OleDbConnection</code>.</li> <li>Columnas Procesadas:<ul> <li><code>PROGRAMA</code></li> <li><code>COD_MODULO</code></li> <li><code>MODULO</code></li> <li><code>SEMESTRE</code>, entre otras.</li> </ul> </li> <li>Propiedades Principales:<ul> <li>Tabla de Origen: <code>Sheet1$</code></li> <li>Acceso: Modo directo (<code>AccessMode = 0</code>).</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Sort PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Ordenar los datos por la columna <code>PROGRAMA</code> y eliminar duplicados.</li> <li>Propiedades Principales:<ul> <li>Columna de Ordenaci\u00f3n: <code>PROGRAMA</code>.</li> <li>Eliminaci\u00f3n de Duplicados: Activada.</li> </ul> </li> <li>Salida:<ul> <li>Datos ordenados para el componente de b\u00fasqueda.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Lookup PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Realizar una b\u00fasqueda en la tabla <code>DIM_PROGRAMA</code> para identificar programas existentes.</li> <li>Propiedades Principales:<ul> <li>SQL: <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA] WHERE [PROGRAMA] = ?\n</code></pre></li> <li>Comportamiento de No Coincidencia: Las filas sin coincidencias se env\u00edan al componente de agregaci\u00f3n.</li> </ul> </li> <li>Salida:<ul> <li>Coincidencias: Filas que ya existen en la tabla <code>DIM_PROGRAMA</code>.</li> <li>No Coincidencias: Filas nuevas que requieren agregaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Aggregate 1</code></p> <ul> <li>Prop\u00f3sito: Consolidar datos agrupados por la columna <code>PROGRAMA</code>.</li> <li>Propiedades Principales:<ul> <li>Columna de Agrupaci\u00f3n: <code>PROGRAMA</code>.</li> <li>Escala de Claves: Baja (500,000 valores aproximados).</li> </ul> </li> <li>Salida:<ul> <li>Datos agrupados enviados al destino.</li> </ul> </li> </ul> </li> <li> <p>Destino: <code>Guardar DIM_PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Cargar los datos procesados en la tabla <code>DIM_PROGRAMA</code> de la base de datos.</li> <li>Propiedades Principales:<ul> <li>Tabla de Destino: <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code>.</li> <li>Inserci\u00f3n Masiva: Activada.</li> </ul> </li> <li>Columnas Procesadas:<ul> <li><code>PROGRAMA</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Excel Source\n    participant Sort as Sort PROGRAMA\n    participant Lookup as Lookup PROGRAMA\n    participant Aggregate as Aggregate 1\n    participant Destino as Guardar DIM_PROGRAMA\n\n    Excel -&gt;&gt; Sort: Leer datos\n    Sort -&gt;&gt; Lookup: Ordenar datos\n    Lookup -&gt;&gt; Aggregate: Enviar no coincidencias\n    Aggregate -&gt;&gt; Destino: Enviar datos agregados\n    Destino -&gt;&gt; Destino: Cargar en `DIM_PROGRAMA`</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_plan_curricular","title":"Componente <code>Data DIM_PLAN_CURRICULAR</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente <code>Data DIM_PLAN_CURRICULAR</code> es un flujo de datos que extrae informaci\u00f3n desde una fuente Excel, realiza transformaciones derivadas y operaciones de b\u00fasqueda, y finalmente inserta los datos procesados en la tabla <code>DIM_PLAN_CURRICULAR</code> de la base de datos. Este flujo asegura la consolidaci\u00f3n y estructuraci\u00f3n de la informaci\u00f3n del plan curricular.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos: <code>PLAN_CURRICULAR</code></p> <ul> <li>Prop\u00f3sito: Leer datos desde un archivo Excel utilizando el administrador de conexiones <code>OleDbConnection</code>.</li> <li>Columnas Procesadas:<ul> <li><code>PROGRAMA</code>, <code>COD_MODULO</code>, <code>MODULO</code>, <code>SEMESTRE</code>, <code>INTENSIDAD_HORARIA</code>, entre otras.</li> </ul> </li> <li>Propiedades Principales:<ul> <li>Tabla de Origen: <code>Sheet1$</code></li> <li>Modo de Acceso: Directo (<code>AccessMode = 0</code>).</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Tranformar Columnas</code></p> <ul> <li>Prop\u00f3sito: Crear nuevas columnas derivadas a partir de columnas existentes.</li> <li>Columnas Derivadas:<ul> <li><code>_SEMESTRE</code>: Convertido de <code>SEMESTRE</code> a formato <code>DT_WSTR, 40</code>.</li> <li><code>_MODULO</code>: Convertido de <code>MODULO</code> a formato <code>DT_WSTR, 200</code>.</li> <li><code>_INTENSIDAD_HORARIA</code>, <code>_INTENSIDAD_HORARIA_SEMANAL</code>, <code>_NO_CREDITOS</code>: Convertidas a formato <code>DT_WSTR, 40</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Lookup ID_PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Verificar y asociar la clave primaria <code>ID_PROGRAMA</code> de la tabla <code>DIM_PROGRAMA</code> con las filas procesadas.</li> <li>Propiedades Principales:<ul> <li>SQL: <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA] WHERE [PROGRAMA] = ?\n</code></pre></li> <li>Comportamiento de No Coincidencia: Ignorar fallas (<code>IgnoreFailure</code>).</li> </ul> </li> <li>Salida:<ul> <li>Coincidencias: Filas existentes en <code>DIM_PROGRAMA</code>.</li> <li>No Coincidencias: Se procesan en el siguiente paso.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Lookup DIM_PLAN_CURRICULAR</code></p> <ul> <li>Prop\u00f3sito: Identificar filas ya existentes en la tabla <code>DIM_PLAN_CURRICULAR</code>.</li> <li>Propiedades Principales:<ul> <li>SQL: <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PLAN_CURRICULAR] WHERE [MODULO] = ?\n</code></pre></li> <li>Comportamiento de No Coincidencia: Filas nuevas se env\u00edan al destino.</li> </ul> </li> </ul> </li> <li> <p>Destino: <code>Guardar DIM_PLAN_CURRICULAR</code></p> <ul> <li>Prop\u00f3sito: Insertar los datos procesados en la tabla <code>DIM_PLAN_CURRICULAR</code> de la base de datos.</li> <li>Propiedades Principales:<ul> <li>Tabla de Destino: <code>\"Cedesarrollo\".\"DIM_PLAN_CURRICULAR\"</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible = true</code>).</li> </ul> </li> <li>Columnas Procesadas: <code>_MODULO</code>, <code>_INTENSIDAD_HORARIA</code>, <code>_INTENSIDAD_HORARIA_SEMANAL</code>, <code>_NO_CREDITOS</code>, <code>_SEMESTRE</code>, <code>ID_PROGRAMA</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as PLAN_CURRICULAR\n    participant Transform as Tranformar Columnas\n    participant LookupID as Lookup ID_PROGRAMA\n    participant LookupPlan as Lookup DIM_PLAN_CURRICULAR\n    participant Destino as Guardar DIM_PLAN_CURRICULAR\n\n    Excel -&gt;&gt; Transform: Leer datos\n    Transform -&gt;&gt; LookupID: Generar columnas derivadas\n    LookupID -&gt;&gt; LookupPlan: Enviar registros coincidentes\n    LookupPlan -&gt;&gt; Destino: Enviar filas nuevas\n    Destino -&gt;&gt; Destino: Insertar en DIM_PLAN_CURRICULAR</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-tarea-ep-ept-05","title":"Componente <code>Tarea EP-EPT-05</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EPT-05 es un componente de ejecuci\u00f3n de procesos (Execute Process Task) que forma parte del contenedor DIM_PLAN_CURRICULAR emp. Su funci\u00f3n es ejecutar un script de Python para realizar operaciones complementarias al flujo principal de actualizaci\u00f3n de la dimensi\u00f3n de planes curriculares. Este script, <code>download.py</code>, se invoca con el par\u00e1metro <code>--key EPEPT05</code>, lo que indica que se ejecutan tareas espec\u00edficas relacionadas con el proceso \"EPEPT05\".</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#propiedades-principales","title":"Propiedades Principales","text":"<ul> <li> <p>Ejecutable:</p> <ul> <li>Se utiliza el int\u00e9rprete de Python definido din\u00e1micamente a trav\u00e9s de la variable de proyecto <code>@[$Project::Python_Executable]</code>.</li> <li>Ruta de ejemplo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> </ul> </li> <li> <p>Directorio de Trabajo:</p> <ul> <li>Configurado din\u00e1micamente mediante la expresi\u00f3n: <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code></li> <li>Esto asegura que el script se ejecute en el entorno adecuado.</li> </ul> </li> <li> <p>Argumentos del Script:</p> <ul> <li>Se ejecuta el comando: <code>download.py --key EPEPT05</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#funcionalidad-y-proposito","title":"Funcionalidad y Prop\u00f3sito","text":"<ul> <li> <p>Objetivo:   Este componente se encarga de ejecutar el script Python que realiza tareas complementarias (por ejemplo, descarga de datos o validaciones previas) necesarias para la actualizaci\u00f3n de la dimensi\u00f3n de planes curriculares.</p> </li> <li> <p>Integraci\u00f3n en el Proceso Global:   La ejecuci\u00f3n de esta tarea se realiza antes de iniciar el procesamiento principal de datos en el contenedor DIM_PLAN_CURRICULAR emp, garantizando que el entorno y la informaci\u00f3n requerida est\u00e9n preparados para las operaciones siguientes.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea EP-EPT-05\n    participant OS as Sistema Operativo\n    participant PythonScript as Script download.py\n\n    SSIS -&gt;&gt; OS: Ejecuta el int\u00e9rprete de Python\n    OS -&gt;&gt; PythonScript: Llama a `download.py --key EPEPT05`\n    PythonScript --&gt;&gt; OS: Retorna resultado del proceso (\u00e9xito o error)\n    OS --&gt;&gt; SSIS: Devuelve el estado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_programa_1","title":"Componente Data DIM_PROGRAMA","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_PROGRAMA es un Data Flow Task que se encarga de extraer, transformar y cargar datos provenientes de un archivo Excel, para finalmente insertarlos en la tabla de destino <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code> de la base de datos. Este flujo de datos consolida informaci\u00f3n sobre programas acad\u00e9micos, garantizando la integridad y calidad de los datos antes de su almacenamiento.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#funcionalidad-y-proceso","title":"Funcionalidad y Proceso","text":"<p>El proceso se divide en varias etapas, las cuales se describen a continuaci\u00f3n:</p> <ol> <li> <p>Extracci\u00f3n de Datos (Excel Source)</p> <ul> <li>Fuente: Se utiliza un origen de datos Excel para leer informaci\u00f3n de la hoja <code>Sheet1$</code>.</li> <li>Columnas Procesadas: Entre las columnas se encuentra la columna <code>PROGRAMA</code>, que es el dato clave a trabajar.</li> <li>Conexi\u00f3n: Se emplea un administrador de conexi\u00f3n OLE DB (definido en el Connection Manager <code>Excel_Connection_Dim_Programa_DE</code>).</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos</p> <ul> <li>Aggregate 1:     Se utiliza una transformaci\u00f3n de tipo Aggregate para agrupar los registros por la columna <code>PROGRAMA</code>.  <ul> <li>Funci\u00f3n: Re\u00fane las filas para obtener un conjunto \u00fanico de valores de <code>PROGRAMA</code>.  </li> <li>Par\u00e1metros: </li> <li>KeyScale: Se especifica como 0 (valor bajo, es decir, para aproximadamente 500,000 claves).</li> </ul> </li> <li>Sort PROGRAMA:     Antes del agrupamiento o para garantizar un orden correcto, se aplica una transformaci\u00f3n Sort que ordena los datos en base a la columna <code>PROGRAMA</code> (eliminando duplicados).</li> <li>Lookup ID_PROGRAMA:     Se realiza un Lookup para obtener la clave primaria <code>ID_PROGRAMA</code> de la tabla <code>[Cedesarrollo].[DIM_PROGRAMA]</code>.  <ul> <li>SQL del Lookup: <pre><code>select * from [Cedesarrollo].[DIM_PROGRAMA] where [PROGRAMA] = ?\n</code></pre></li> <li>Comportamiento:   Si se encuentra una coincidencia, se recupera el <code>ID_PROGRAMA</code> correspondiente; de lo contrario, se considerar\u00e1 que la fila es nueva.</li> </ul> </li> <li>Lookup PROGRAMA:     Otra transformaci\u00f3n Lookup se utiliza para validar la existencia del valor de <code>PROGRAMA</code> en la dimensi\u00f3n, usando la misma columna como par\u00e1metro de b\u00fasqueda.<ul> <li>SQL del Lookup: <pre><code>select * from (select * from [Cedesarrollo].[DIM_PROGRAMA]) [refTable]\nwhere [refTable].[PROGRAMA] = ?\n</code></pre></li> <li>NoMatchBehavior:   Se configura para enviar a la salida \u201cno match\u201d aquellas filas que no tienen coincidencia, permitiendo la posterior inserci\u00f3n de nuevos registros.</li> </ul> </li> </ul> </li> <li> <p>Componente de Script</p> <ul> <li>Componente de Script Personalizado:     Se incluye un Script Component (implementado en C#) que recibe la columna <code>PROGRAMA</code> y aplica una transformaci\u00f3n para capitalizar el valor (por ejemplo, convertirlo a \"Title Case\").  <ul> <li>Funci\u00f3n: </li> <li>Lee el valor original de <code>PROGRAMA</code>.</li> <li>Utiliza la cultura \u201ces-ES\u201d para convertir el texto a formato Title Case.</li> <li>Almacena el resultado en una columna de salida denominada <code>PROGRAMACAPITALIZADO</code>.</li> </ul> </li> <li>Prop\u00f3sito:     Este paso permite unificar el formato de los nombres de programa antes de su inserci\u00f3n en la base de datos.</li> </ul> </li> <li> <p>Carga de Datos (Destino: ADO.NET Destination)</p> <ul> <li>Destino:     La transformaci\u00f3n final consiste en el componente ADO.NET Destination que inserta los datos transformados en la tabla <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code>.</li> <li>Propiedades Clave: <ul> <li>BatchSize: 0 (se utiliza el tama\u00f1o predeterminado del b\u00fafer de SSIS).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: Activado, para mejorar el rendimiento de la inserci\u00f3n masiva.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-flujo-de-datos","title":"Diagrama de Flujo de Datos","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#flowchart-td-aexcel-source-bsort-programa-ordena-y-elimina-duplicados-b-caggregate-1-agrupa-por-programa-c-dlookup-id_programa-obtiene-id-si-existe-d-elookup-programa-valida-existencia-en-dim_programa-e-fcomponente-de-script-capitaliza-programa-f-gguardar-dim_programa-inserta-en-la-tabla-de-destino","title":"<pre><code>flowchart TD\n    A[Excel Source] --&gt; B[Sort PROGRAMA Ordena y elimina duplicados]\n    B --&gt; C[Aggregate 1 Agrupa por PROGRAMA]\n    C --&gt; D[Lookup ID_PROGRAMA Obtiene ID si existe]\n    D --&gt; E[Lookup PROGRAMA Valida existencia en DIM_PROGRAMA]\n    E --&gt; F[Componente de Script Capitaliza PROGRAMA]\n    F --&gt; G[Guardar DIM_PROGRAMA Inserta en la tabla de destino]</code></pre>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_plan_curricular_1","title":"Componente: Data DIM_PLAN_CURRICULAR","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_PLAN_CURRICULAR es un Data Flow Task que procesa la informaci\u00f3n de planes curriculares proveniente de un archivo Excel. Su objetivo es transformar y validar los datos antes de insertarlos en la tabla de destino en la base de datos, asegurando la calidad e integridad de la informaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#proceso-etl","title":"Proceso ETL","text":"<p>El flujo de datos se compone de los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n de Datos (Excel Source)</p> <ul> <li>Origen: Se extraen datos desde la hoja <code>Sheet1$</code> de un archivo Excel.</li> <li>Columnas Clave: <ul> <li><code>REGISTRO</code></li> <li><code>PROGRAMA</code></li> <li><code>COD_MODULO</code></li> <li><code>MODULO</code></li> <li><code>ABREVIACI\u00d3N</code></li> <li><code>SEMESTRE</code></li> <li><code>INTENSIDAD_HORARIA</code></li> <li><code>INTENSIDAD_HORARIA_SEMANAL</code></li> <li><code>NO_CREDITOS</code></li> </ul> </li> <li>Conexi\u00f3n: Utiliza un administrador de conexi\u00f3n OLE DB definido en <code>Excel_Connection_Dim_Programa_DE</code>.</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos \u2013 Tranformar Columnas (Derived Column)</p> <ul> <li>Funci\u00f3n:     Se crean columnas derivadas para formatear y convertir los valores extra\u00eddos:<ul> <li><code>_SEMESTRE</code>: Convierte el valor de <code>SEMESTRE</code> a una cadena de 40 caracteres.</li> <li><code>_INTENSIDAD_HORARIA</code>: Convierte el valor de <code>INTENSIDAD_HORARIA</code> a una cadena de 40 caracteres.</li> <li><code>_INTENSIDAD_HORARIA_SEMANAL</code>: Convierte el valor de <code>INTENSIDAD_HORARIA_SEMANAL</code> a una cadena de 40 caracteres.</li> <li><code>_NO_CREDITOS</code>: Convierte el valor de <code>NO_CREDITOS</code> a una cadena de 40 caracteres.</li> <li><code>_MODULO</code>: Convierte el valor de <code>MODULO</code> a una cadena de 200 caracteres.</li> </ul> </li> <li>Objetivo: Normalizar y preparar los datos para la validaci\u00f3n y la carga.</li> </ul> </li> <li> <p>Ordenaci\u00f3n \u2013 Sort PROGRAMA (Sort)</p> <ul> <li>Funci\u00f3n:     Ordena los datos en funci\u00f3n de la columna <code>PROGRAMA</code>, eliminando duplicados para facilitar el procesamiento posterior.</li> <li>Propiedades Destacadas:<ul> <li>EliminateDuplicates: Activado.</li> <li>MaximumThreads: -1 (utiliza el m\u00e1ximo disponible).</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n y Enriquecimiento \u2013 Lookup Transformations</p> <ul> <li> <p>Lookup DIM_PLAN_CURRICULAR:</p> <ul> <li>Objetivo:   Verificar si el valor de la columna derivada <code>_MODULO</code> ya existe en la tabla de destino.</li> <li>Consulta: <pre><code>select * from (select * from [Cedesarrollo].[DIM_PLAN_CURRICULAR]) [refTable]\nwhere [refTable].[MODULO] = ?\n</code></pre></li> <li>Comportamiento en No Coincidencia:   Los registros sin coincidencia se env\u00edan a la salida \u201cLookup No Match Output\u201d, lo que indica que son nuevos y deben insertarse.</li> </ul> </li> <li> <p>Lookup ID_PROGRAMA:</p> <ul> <li>Objetivo:   Obtener el <code>ID_PROGRAMA</code> correspondiente desde la tabla <code>[Cedesarrollo].[DIM_PROGRAMA]</code> utilizando el valor de <code>PROGRAMA</code> extra\u00eddo del archivo Excel.</li> <li>Consulta: <pre><code>select * from [Cedesarrollo].[DIM_PROGRAMA] where [PROGRAMA] = ?\n</code></pre></li> <li>Uso:   La salida de este Lookup se utiliza en la siguiente transformaci\u00f3n para separar registros existentes de aquellos nuevos.</li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n de Datos \u2013 Conditional Split</p> <ul> <li>Funci\u00f3n:     Eval\u00faa la existencia del valor <code>ID_PROGRAMA</code> (resultado del Lookup ID_PROGRAMA).  </li> <li>Condici\u00f3n: <ul> <li>Case 1: Registros donde <code>ID_PROGRAMA</code> no es <code>NULL</code> (lo que indica que ya existe un registro relacionado).</li> <li>Default: Registros donde <code>ID_PROGRAMA</code> es <code>NULL</code> (nuevos registros que deben ser insertados).</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos \u2013 Guardar DIM_PLAN_CURRICULAR (ADO.NET Destination)</p> <ul> <li>Funci\u00f3n:     Inserta los registros nuevos (por ejemplo, los provenientes del \u201cCase 1\u201d del Conditional Split) en la tabla <code>\"Cedesarrollo\".\"DIM_PLAN_CURRICULAR\"</code>.</li> <li>Propiedades Clave:<ul> <li>BatchSize: 0 (utiliza el tama\u00f1o del buffer interno).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: True, para optimizar la inserci\u00f3n masiva.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-flujo-de-datos_1","title":"Diagrama de Flujo de Datos","text":"<pre><code>flowchart TD\n    Start[Inicio: Excel Source PLAN_CURRICULAR]\n    Transform[Transformar Columnas: Crear _SEMESTRE, _INTENSIDAD_HORARIA, _INTENSIDAD_HORARIA_SEMANAL, _NO_CREDITOS, _MODULO]\n    Sort[Ordenar PROGRAMA: Sort PROGRAMA]\n    LookupPlan[Verificar Existencia: Lookup DIM_PLAN_CURRICULAR]\n    LookupID[Obtener ID: Lookup ID_PROGRAMA]\n    Split[Evaluar Registro: Conditional Split]\n    Save[Guardar Nuevos Registros en DIM_PLAN_CURRICULAR]\n    Existing[Gestionar Registros Existentes]\n    End[Fin]\n\n    Start --&gt; Transform\n    Transform --&gt; Sort\n    Sort --&gt; LookupPlan\n    LookupPlan --&gt; LookupID\n    LookupID --&gt; Split\n    Split -- \"Si ID_PROGRAMA no es nulo\" --&gt; Save\n    Split -- \"Si ID_PROGRAMA es nulo\" --&gt; Existing\n    Save --&gt; End\n    Existing --&gt; End</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/","title":"06. CEDESARROLLO_FACT","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#cedesarrollo_fact","title":"CEDESARROLLO_FACT","text":"<p>El paquete SSIS \"06-CEDESARROLLO_FACT\" es un sistema robusto dise\u00f1ado para realizar procesos ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) relacionados con datos operativos educativos y administrativos. Este paquete se enfoca en integrar informaci\u00f3n sobre matr\u00edculas, jornadas, programas, per\u00edodos acad\u00e9micos y evaluaciones, consolidando datos desde m\u00faltiples fuentes en el Data Warehouse <code>DWH_COMFENALCO</code>. El objetivo principal es asegurar la disponibilidad de datos precisos y consistentes para an\u00e1lisis estrat\u00e9gico y generaci\u00f3n de reportes.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El paquete tiene como prop\u00f3sito principal gestionar y transformar datos cr\u00edticos de varias fuentes. A trav\u00e9s de un flujo de trabajo modular y escalable, asegura la integraci\u00f3n de los datos, prepar\u00e1ndolos para an\u00e1lisis detallados y toma de decisiones estrat\u00e9gicas.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>DIM_ESTUDIANTES</code>: Informaci\u00f3n b\u00e1sica de estudiantes.</li> <li><code>DIM_JORNADA</code>: Detalles de las jornadas acad\u00e9micas.</li> <li><code>DIM_PROGRAMA</code>: Datos de programas educativos.</li> <li><code>FACT_NOTAS</code>: Registros de notas finales de los estudiantes.</li> <li>Archivos Excel y CSV:</li> <li>Planes curriculares.</li> <li>Programas educativos y datos de matr\u00edculas.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexi\u00f3n ADO.NET para acceso eficiente a bases de datos.</li> <li>Conexi\u00f3n OLE DB para lectura de archivos Excel y CSV.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>C\u00e1lculo de campos adicionales como <code>ID_PROGRAMA</code> y <code>NOTA_PROMEDIO</code>.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Comparaci\u00f3n de datos con tablas maestras como <code>DIM_PERIODO_ACADEMICO</code> y <code>DIM_JORNADA</code> para garantizar consistencia.</li> </ul> </li> <li>Clasificaci\u00f3n (<code>Conditional Split</code>):<ul> <li>Filtrado de datos bas\u00e1ndose en condiciones como registros v\u00e1lidos e inv\u00e1lidos.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad entre columnas de entrada y destino.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas utilizadas:<ul> <li><code>DIM_PERIODO_ACADEMICO</code>: Detalles de los per\u00edodos acad\u00e9micos.</li> <li><code>DIM_JORNADA</code>: Informaci\u00f3n sobre jornadas.</li> <li><code>DIM_PROGRAMA</code>: Datos de programas educativos.</li> <li><code>FACT_NOTAS</code>: Registros consolidados de evaluaciones.</li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones Masivas (<code>Bulk Insert</code>): Activada para maximizar el rendimiento en la carga de datos.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python:<ul> <li>Automatizan tareas como descargas desde rutas predefinidas y validaci\u00f3n de datos en tiempo real.</li> </ul> </li> <li>Integraci\u00f3n:<ul> <li>Uso de variables din\u00e1micas para ajustar rutas de trabajo y par\u00e1metros espec\u00edficos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_ESTUDIANTES:</p> <ul> <li><code>ID_ESTUDIANTE</code>: Identificador \u00fanico.</li> <li><code>NOMBRE</code>: Nombre del estudiante.</li> <li><code>DOCUMENTO</code>: Documento de identidad.</li> </ul> </li> <li> <p>DIM_JORNADA:</p> <ul> <li><code>ID_JORNADA</code>: Identificador de la jornada.</li> <li><code>JORNADA</code>: Descripci\u00f3n de la jornada.</li> </ul> </li> <li> <p>DIM_PROGRAMA:</p> <ul> <li><code>ID_PROGRAMA</code>: Identificador \u00fanico.</li> <li><code>NOMBRE_PROGRAMA</code>: Nombre del programa acad\u00e9mico.</li> </ul> </li> <li> <p>FACT_NOTAS:</p> <ul> <li><code>ID_NOTA</code>: Identificador \u00fanico de la nota.</li> <li><code>ID_ESTUDIANTE</code>: Relaci\u00f3n con el estudiante.</li> <li><code>ID_JORNADA</code>: Relaci\u00f3n con la jornada.</li> <li><code>NOTA_FINAL</code>: Evaluaci\u00f3n final.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos (Data Flow Diagram - DFD)</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extrae datos de DIM_ESTUDIANTES, DIM_JORNADA y FACT_NOTAS\n    SSIS -&gt;&gt; Python: Ejecuta scripts para validaci\u00f3n y descargas\n    SSIS -&gt;&gt; DWH: Carga datos procesados en tablas destino</code></pre> <ol> <li>Diagrama de Transformaciones y Validaciones</li> </ol> <pre><code>graph TD\n    %% Entradas\n    A1[DIM_ESTUDIANTES] --&gt; T1[Derived Column: Transformaci\u00f3n de campos]\n    A2[DIM_JORNADA] --&gt; T2[Lookup: Validaci\u00f3n de jornadas]\n    A3[FACT_NOTAS] --&gt; T3[Conditional Split: Filtrado de registros]\n\n    %% Transformaciones\n    T1 --&gt; L1[Lookup ID_ESTUDIANTE]\n    T2 --&gt; L2[Lookup ID_JORNADA]\n    T3 --&gt; C1[Guardar datos transformados]</code></pre> <ol> <li>Diagrama ER para Tablas de Dimensiones</li> </ol> <pre><code>erDiagram\n    DIM_ESTUDIANTES {\n        int ID_ESTUDIANTE\n        string NOMBRE\n        string DOCUMENTO\n    }\n    DIM_JORNADA {\n        int ID_JORNADA\n        string JORNADA\n    }\n    DIM_PROGRAMA {\n        int ID_PROGRAMA\n        string NOMBRE_PROGRAMA\n    }\n    FACT_NOTAS {\n        int ID_NOTA\n        int ID_ESTUDIANTE\n        int ID_JORNADA\n        float NOTA_FINAL\n    }\n    DIM_ESTUDIANTES ||--|| DIM_JORNADA : \"Relaci\u00f3n Estudiante-Jornada\"\n    DIM_JORNADA ||--|| FACT_NOTAS : \"Jornada-Notas\"\n    DIM_PROGRAMA ||--|| FACT_NOTAS : \"Programa-Notas\"</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_desertores","title":"FACT_DESERTORES","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-cede_cancelados_desertores","title":"Componente <code>Tarea cede_Cancelados_Desertores</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tarea cede_Cancelados_Desertores es un componente de tipo Execute Process Task en SSIS que se utiliza para ejecutar un proceso externo mediante un script de Python. Este script se encarga de descargar y procesar los datos relacionados con cancelaciones y desertores, informaci\u00f3n que posteriormente se integrar\u00e1 en el flujo de datos del paquete FACT_DESERTORES para an\u00e1lisis y reportes.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Execute Process Task  </li> <li>Ejecutable: Utiliza la variable de proyecto <code>@[$Project::Python_Executable]</code>, que apunta al ejecutable de Python configurado.  </li> <li>Argumentos: <code>download.py --key cede_Cancelados_Desertores</code> </li> <li>Directorio de Trabajo:   Se establece mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con el path <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code> </li> <li>Ruta F\u00edsica Ejemplo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code> </li> <li>Propiedades Adicionales:<ul> <li>Filtro de registro: <code>FilterKind=0</code> </li> <li>ThreadHint: <code>0</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<p>El siguiente diagrama de secuencia ilustra el proceso que se ejecuta en esta tarea:</p> <p><pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta download.py --key cede_Cancelados_Desertores\n    Python -&gt;&gt; Python: Descarga y procesa datos de cancelados y desertores\n    Python -&gt;&gt; SSIS: Retorna resultado de la ejecuci\u00f3n</code></pre> Aqu\u00ed tienes la documentaci\u00f3n para el componente dim_Estudiantes py dentro del paquete FACT_DESERTORES:</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-dim_estudiantes-py","title":"Componente <code>dim_Estudiantes py</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente dim_Estudiantes py es una tarea de tipo Execute Process Task en SSIS, dise\u00f1ada para ejecutar un script de Python que procesa la dimensi\u00f3n de estudiantes. Este proceso se utiliza para extraer, transformar y preparar los datos de la dimensi\u00f3n de estudiantes, integr\u00e1ndolos en el sistema ETL de FACT_DESERTORES.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_1","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Execute Process Task  </li> <li>Ejecutable: Utiliza la variable de proyecto <code>@[$Project::Python_Executable]</code>, que apunta al ejecutable de Python configurado.  </li> <li>Argumentos: <code>dim_Estudiantes.py</code> </li> <li>Directorio de Trabajo:   Se define mediante la variable <code>@[$Project::Working_Directory]</code> concatenada con el path <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code> </li> <li>Ruta F\u00edsica Ejemplo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<p>El siguiente diagrama de secuencia muestra el proceso que se ejecuta en esta tarea:</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta dim_Estudiantes.py\n    Python -&gt;&gt; Python: Procesa la dimensi\u00f3n de estudiantes\n    Python -&gt;&gt; SSIS: Retorna resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-truncar-tabla-temporal","title":"Componente <code>Truncar tabla Temporal</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente Truncar tabla Temporal es una tarea de tipo Execute SQL Task que se utiliza para limpiar la tabla temporal utilizada en el proceso ETL de FACT_DESERTORES. Concretamente, se encarga de truncar la tabla <code>[STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code>, eliminando todos sus registros antes de cargar nuevos datos. Esto garantiza que el \u00e1rea de staging se encuentre limpia y preparada para el proceso de integraci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_2","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Execute SQL Task  </li> <li>Conexi\u00f3n: Utiliza la conexi\u00f3n identificada por <code>{5972EC76-2533-4771-BB68-A92E1CDD645D}</code> para conectarse al servidor SQL donde reside la tabla.  </li> <li>Sentencia SQL: <pre><code>TRUNCATE TABLE [STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO]\n</code></pre></li> <li>Descripci\u00f3n: Ejecuta la sentencia SQL para truncar la tabla temporal, eliminando todos los registros existentes y dejando la tabla lista para la carga de nuevos datos.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<p>El siguiente diagrama muestra el proceso que se ejecuta en esta tarea:</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n\n    SSIS -&gt;&gt; SQL: Ejecuta TRUNCATE TABLE STAGE_AREA.Transversal.TMP_DESERTORES_CEDESARROLLO\n    SQL --&gt;&gt; SSIS: Confirma truncamiento</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-tabla-temporal","title":"Componente <code>Actualizar Tabla Temporal</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar Tabla Temporal es un Data Flow Task que se encarga de actualizar la tabla temporal utilizada para almacenar informaci\u00f3n sobre desertores en el proceso ETL. Este flujo extrae datos desde una fuente Excel, aplicando las transformaciones necesarias y finalmente cargando la informaci\u00f3n en la tabla <code>[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code>. La tarea es fundamental para garantizar que los datos temporales est\u00e9n actualizados y listos para su posterior procesamiento.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source: cede_desertores</p> <ul> <li>Descripci\u00f3n: Extrae datos de un archivo Excel (hoja <code>Sheet1$</code>) que contiene informaci\u00f3n relevante de desertores.</li> <li>Columnas Extra\u00eddas:<ul> <li>PROGRAMA</li> <li>NOMBRE_ESTUDIANTE</li> <li>FECHA</li> <li>TIPO</li> <li>CAUSA</li> <li>OBSERVACIONES</li> <li>SEDE</li> <li>JORNADA</li> </ul> </li> <li>Conexi\u00f3n: Utiliza el Connection Manager configurado para Excel (por ejemplo, <code>Excel_Connection_Fact_Desertores_CE</code>).</li> </ul> </li> <li> <p>Destino ADO.NET: TMP_DESERTORES_CEDESARROLLO</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla temporal <code>[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code> del \u00e1rea de staging.</li> <li>Propiedades:<ul> <li>Tabla Destino: <code>\"Transversal\".\"TMP_DESERTORES_CEDESARROLLO\"</code></li> <li>Batch Size: <code>0</code> (usa el tama\u00f1o predeterminado del buffer)</li> <li>Command Timeout: <code>30</code> segundos</li> <li>Uso de Bulk Insert: Activado para mejorar el rendimiento.</li> </ul> </li> <li>Conexi\u00f3n: Utiliza el Connection Manager asignado a la base de datos de staging (por ejemplo, <code>STAGE_AREA</code>).</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#flujo-del-proceso","title":"Flujo del Proceso","text":"<ol> <li>Extracci\u00f3n: El componente Excel Source extrae la informaci\u00f3n de la hoja <code>Sheet1$</code> del archivo configurado.</li> <li>(Opcional) Procesamiento/Transformaci\u00f3n: Si bien en este caso no se indican transformaciones adicionales, en muchos escenarios se pueden incluir pasos intermedios para validar o transformar los datos antes de la carga.</li> <li>Carga: Los datos extra\u00eddos se env\u00edan directamente al destino ADO.NET, donde se insertan en la tabla temporal.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-flujo","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el proceso de actualizaci\u00f3n de la tabla temporal:</p> <pre><code>graph TD\n    A[Excel Source: cede_desertores] --&gt; B[Procesamiento de Datos]\n    B --&gt; C[Destino ADO.NET: TMP_DESERTORES_CEDESARROLLO]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-dim_programa","title":"Componente <code>Actualizar DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar DIM_PROGRAMA es un Data Flow Task que forma parte del proceso ETL del paquete FACT_DESERTORES. Su funci\u00f3n es identificar los programas que a\u00fan no han sido registrados en la tabla de dimensi\u00f3n DIM_PROGRAMA y posteriormente insertar dichos registros en la base de datos. Para ello, se consume informaci\u00f3n de la tabla temporal (almacenada en el \u00e1rea de staging) y se realiza un proceso de comparaci\u00f3n (lookup) con la tabla de destino para detectar los registros faltantes. Finalmente, los programas identificados se insertan en la tabla <code>[Cedesarrollo].[DIM_PROGRAMA]</code>.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-de-componentes-y-flujo","title":"Detalle de Componentes y Flujo","text":"<ol> <li> <p>Identificar programas</p> <ul> <li>Tipo de Componente: Data Reader Source (adaptado mediante un Managed Component Host)</li> <li>Funci\u00f3n: Ejecuta una instrucci\u00f3n SQL para extraer la lista de programas distintos desde la tabla temporal <code>[STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code> que a\u00fan no se han registrado en la tabla de dimensi\u00f3n.  </li> <li>SQL Utilizado:     <pre><code>SELECT DISTINCT d.[PROGRAMA]\nFROM [STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO] d\nLEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PROGRAMA] p ON d.[PROGRAMA] = p.[PROGRAMA]\nWHERE p.ID_PROGRAMA IS NULL\n</code></pre></li> <li>Objetivo: Extraer los registros de programas nuevos que deben ser insertados.</li> </ul> </li> <li> <p>Guardar DIM_PROGRAMA</p> <ul> <li>Tipo de Componente: ADO.NET Destination</li> <li>Funci\u00f3n: Inserta en la tabla <code>[Cedesarrollo].[DIM_PROGRAMA]</code> los registros identificados en el paso anterior.</li> <li>Propiedades Clave:<ul> <li>Tabla Destino: <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code></li> <li>Batch Size: 0 (usa el tama\u00f1o predeterminado del buffer)</li> <li>Command Timeout: 30 segundos</li> <li>Bulk Insert: Activado (para optimizar el rendimiento)</li> </ul> </li> <li>Conexi\u00f3n: Utiliza el Connection Manager asignado a la base de datos destino (por ejemplo, <code>DWH_COMFENALCO_Destino</code>).</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#flujo-del-proceso_1","title":"Flujo del Proceso","text":"<ol> <li> <p>Extracci\u00f3n de Datos:    El componente Identificar programas se conecta a la base de datos y ejecuta la consulta SQL para obtener la lista de programas presentes en la tabla temporal que no tienen un registro en DIM_PROGRAMA.</p> </li> <li> <p>Carga de Datos:    Los datos extra\u00eddos se env\u00edan al componente Guardar DIM_PROGRAMA, el cual inserta los registros nuevos en la tabla de destino.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-flujo-del-proceso","title":"Diagrama de Flujo del Proceso","text":"<pre><code>graph TD\n    A[Identificar programas: Extraer lista de programas nuevos]\n    B[Guardar DIM_PROGRAMA: Insertar registros en DIM_PROGRAMA]\n    A --&gt; B</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-fact_desercion","title":"Componente <code>Actualizar FACT_DESERCION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar FACT_DESERCION es un Data Flow Task que forma parte del proceso ETL del paquete FACT_DESERTORES. Su objetivo es extraer la informaci\u00f3n de desertores a trav\u00e9s de una consulta SQL compleja, validar y transformar los datos obtenidos y, finalmente, insertar en la tabla de hechos FACT_DESERCION de la base de datos. La consulta utiliza varias CTE y uniones (JOIN) para consolidar informaci\u00f3n de distintos or\u00edgenes (como la tabla temporal de desertores, dimensiones de jornada, periodo acad\u00e9mico y estudiantes) y detectar aquellos registros que a\u00fan no existen en FACT_DESERCION.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-de-componentes-y-flujo-del-proceso","title":"Detalle de Componentes y Flujo del Proceso","text":"<ol> <li> <p>Consulta (Data Reader Source)</p> <ul> <li>Tipo de Componente: Managed Component Host (Data Reader Source)</li> <li>Funci\u00f3n: Ejecuta una consulta SQL que utiliza CTE para:<ul> <li>Extraer datos de desertores desde la tabla temporal <code>[STAGE_AREA].[Transversal].[TMP_DESERTORES_CEDESARROLLO]</code>.</li> <li>Estandarizar nombres y calcular identificadores, como <code>ID_FECHA</code> y <code>PERIODO_ACADEMICO</code>.</li> <li>Unir los datos con dimensiones como DIM_JORNADA, DIM_PERIODO_ACADEMICO y la dimensi\u00f3n de estudiantes (a trav\u00e9s de un LEFT JOIN sobre el nombre estandarizado).</li> <li>Seleccionar \u00fanicamente los registros que a\u00fan no tienen un valor asignado en la columna <code>ID_DESERCION</code> de FACT_DESERCION.</li> </ul> </li> <li>SQL Utilizado:     La consulta SQL (con CTE) extrae columnas como <code>NOMBRE_ESTUDIANTE</code>, <code>SEDE</code>, <code>ID_FECHA</code>, <code>FECHA</code>, <code>TIPO</code>, <code>CAUSA</code>, <code>OBSERVACIONES</code>, junto con identificadores provenientes de las uniones con DIM_JORNADA, DIM_PERIODO_ACADEMICO y la dimensi\u00f3n de estudiantes.</li> </ul> </li> <li> <p>Salida de Origen</p> <ul> <li>La salida de la consulta (Data Reader) contiene los registros que cumplen la condici\u00f3n de no estar presentes en FACT_DESERCION (es decir, aquellos con <code>ID_DESERCION</code> nulo).</li> </ul> </li> <li> <p>Destino \u2013 Guardar en FACT_DESERCION</p> <ul> <li>Tipo de Componente: ADO.NET Destination</li> <li>Funci\u00f3n: Inserta los registros resultantes de la consulta en la tabla de hechos <code>[Cedesarrollo].[FACT_DESERCION]</code>.</li> <li>Propiedades Clave:<ul> <li>Tabla Destino: <code>\"Cedesarrollo\".\"FACT_DESERCION\"</code></li> <li>Batch Size: 0 (se usa el tama\u00f1o predeterminado del buffer)</li> <li>Command Timeout: 30 segundos</li> <li>Bulk Insert: Activado para optimizar el rendimiento</li> </ul> </li> <li>Conexi\u00f3n: Utiliza el Connection Manager configurado para el destino de datos (por ejemplo, <code>DWH_COMFENALCO_Destino</code>).</li> </ul> </li> <li> <p>Flujo de Datos</p> </li> <li>Los datos fluyen desde la ejecuci\u00f3n de la consulta (que consolida la informaci\u00f3n de desertores) hasta el componente de destino, el cual inserta \u00fanicamente aquellos registros nuevos que no tienen un <code>ID_DESERCION</code> asignado.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama de proceso muestra de forma esquem\u00e1tica el flujo de datos dentro de este Data Flow Task:</p> <pre><code>graph TD\n    A[Consulta: Extraer y consolidar datos de desertores]\n    B[Salida de Origen: Registros sin ID_DESERCION]\n    C[Destino ADO.NET: Guardar en FACT_DESERCION]\n\n    A --&gt; B\n    B --&gt; C</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-id_periodo","title":"Componente <code>Actualizar ID_PERIODO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar ID_PERIODO es una tarea de ejecuci\u00f3n SQL (Execute SQL Task) que se encarga de actualizar el campo ID_PERIODO en la tabla de hechos FACT_DESERCION del esquema Cedesarrollo. Para lograr esto, el proceso sigue estos pasos:</p> <ol> <li> <p>Calcular el PERIODO_ACADEMICO:    Se utiliza una expresi\u00f3n basada en la columna FECHA para generar un valor en el formato <code>YYYY-S</code>, donde:</p> <ul> <li><code>S = '1'</code> para los meses de enero a junio (primer semestre).</li> <li><code>S = '2'</code> para los meses de julio a diciembre (segundo semestre).</li> </ul> </li> <li> <p>Construir una tabla temporal (CTE):    Se crea la CTE PeriodoTemp que extrae el ID_DESERCION, FECHA y el PERIODO_ACADEMICO calculado a partir de la tabla FACT_DESERCION.</p> </li> <li> <p>Actualizar FACT_DESERCION:    Se realiza una actualizaci\u00f3n en la tabla FACT_DESERCION mediante un <code>INNER JOIN</code> entre la CTE PeriodoTemp y la dimensi\u00f3n DIM_PERIODO_ACADEMICO, usando como condici\u00f3n de uni\u00f3n el valor calculado de PERIODO_ACADEMICO y filtrando adem\u00e1s por ID_UNIDAD igual a 2. De esta manera, se asigna el ID_PERIODO correcto a cada registro de FACT_DESERCION.</p> </li> <li> <p>Verificaci\u00f3n:    Finalmente, se ejecuta una consulta SELECT para validar que la actualizaci\u00f3n se realiz\u00f3 correctamente, mostrando los campos ID_DESERCION, ID_PERIODO y FECHA.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_1","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama muestra de forma esquem\u00e1tica los pasos del proceso:</p> <pre><code>graph TD\n    A[Inicio: FACT_DESERCION]\n    B[Crear CTE PeriodoTemp]\n    C[Calcular PERIODO_ACADEMICO a partir de FECHA]\n    D[Unir con DIM_PERIODO_ACADEMICO filtrar por ID_UNIDAD = 2]\n    E[Actualizar ID_PERIODO en FACT_DESERCION]\n    F[Verificar resultados con SELECT]\n\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_estado_matriculas","title":"FACT_ESTADO_MATRICULAS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ejecutar-sql","title":"Componente <code>Tarea Ejecutar SQL</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>Esta tarea se encarga de gestionar la existencia y el contenido de la tabla temporal TMP_MATRICULAS_CEDESARROLLO dentro del \u00e1rea de staging (STAGE_AREA.Transversal). El proceso eval\u00faa si la tabla ya existe; en caso afirmativo, la vac\u00eda mediante la instrucci\u00f3n <code>TRUNCATE TABLE</code>, y si no existe, la crea con la estructura definida.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso","title":"Detalles del Proceso","text":"<ol> <li> <p>Verificaci\u00f3n de la existencia de la tabla:    Utilizando la funci\u00f3n <code>OBJECT_ID</code>, se determina si la tabla TMP_MATRICULAS_CEDESARROLLO ya existe en el esquema STAGE_AREA.Transversal.</p> </li> <li> <p>Si la tabla existe:    Se ejecuta la instrucci\u00f3n <code>TRUNCATE TABLE</code> para eliminar todos los registros existentes y dejarla lista para la carga de nuevos datos.</p> </li> <li> <p>Si la tabla no existe:    Se crea la tabla TMP_MATRICULAS_CEDESARROLLO en el esquema Transversal con la siguiente estructura:</p> <ul> <li>Columnas para almacenar informaci\u00f3n relacionada con la matr\u00edcula, como JORNADA, NOMBRE_ESTUDIANTE, TIPO_DOCUMENTO, DOCUMENTO_ESTUDIANTE, FECHA_MATRICULA, TELEFONO, CELULAR, CORREO, SEMESTRE, ESTADO, SEDE, PROGRAMA, ID_UNIDAD.</li> <li>Columnas derivadas para almacenar valores transformados: _SEMESTRE, _CORREO, _CELULAR, _TELEFONO, _NOMBRE_ESTUDIANTE, _SEDE.</li> <li>Columnas adicionales para validaci\u00f3n y relaciones: DOCUMENTOS_COMPLETOS, ID_JORNADA, ID_PROGRAMA, FECHA_INICIO_PERIODO.</li> </ul> </li> <li> <p>Finalizaci\u00f3n:    El script concluye asegur\u00e1ndose de que, seg\u00fan el escenario, la tabla temporal se encuentre disponible y en un estado limpio para ser utilizada en posteriores procesos de ETL.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_2","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama de proceso ilustra de forma esquem\u00e1tica las operaciones realizadas por esta tarea:</p> <pre><code>graph TD\n    A[Inicio: Verificar existencia de TMP_MATRICULAS_CEDESARROLLO] --&gt; B{\u00bfTabla existe?}\n    B -- S\u00ed --&gt; C[Truncar tabla: TRUNCATE TABLE]\n    B -- No --&gt; D[Crear tabla con estructura definida]\n    D --&gt; E[Fin: Tabla creada]\n    C --&gt; E[Fin: Tabla vaciada]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-truncar-tabla-temporal-listas","title":"Componente <code>Truncar tabla temporal Listas</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Esta tarea es una operaci\u00f3n de ejecuci\u00f3n SQL que se encarga de vaciar la tabla temporal TMP_LISTADO_MATRICULAS_Q10 ubicada en el esquema STAGE_AREA.Transversal. Su funci\u00f3n principal es limpiar la tabla antes de iniciar procesos posteriores de carga y transformaci\u00f3n de datos, garantizando que no existan registros antiguos que puedan interferir con la nueva carga.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_1","title":"Detalles del Proceso","text":"<ol> <li> <p>Objetivo:    Eliminar todos los registros existentes en la tabla TMP_LISTADO_MATRICULAS_Q10 para asegurar que la tabla est\u00e9 en estado limpio antes de utilizarla en el flujo ETL.</p> </li> <li> <p>Acciones Realizadas:  </p> <ul> <li>Se ejecuta la instrucci\u00f3n <code>TRUNCATE TABLE</code> sobre la tabla [STAGE_AREA].[Transversal].[TMP_LISTADO_MATRICULAS_Q10].</li> <li>Esta acci\u00f3n elimina r\u00e1pidamente todos los datos de la tabla sin afectar su estructura, permitiendo una recarga eficiente de la informaci\u00f3n.</li> </ul> </li> <li> <p>Beneficios:  </p> <ul> <li>Integridad de Datos: Evita la acumulaci\u00f3n de datos obsoletos o duplicados en la etapa de staging.</li> <li>Rendimiento: El uso de <code>TRUNCATE TABLE</code> es m\u00e1s eficiente que un <code>DELETE</code> sin cl\u00e1usula <code>WHERE</code> para tablas grandes, ya que se resetea la estructura de almacenamiento.</li> <li>Preparaci\u00f3n para ETL: Garantiza que la tabla temporal est\u00e9 lista para recibir nuevos datos, lo cual es fundamental en procesos de integraci\u00f3n y transformaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_3","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama ilustra el proceso ejecutado por esta tarea:</p> <pre><code>graph TD\n    A[Inicio: Verificar existencia de TMP_LISTADO_MATRICULAS_Q10] --&gt; B[Ejecutar TRUNCATE TABLE]\n    B --&gt; C[Tabla temporal vaciada]\n    C --&gt; D[Fin del proceso]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-actualizar-dim_programa_1","title":"Componente <code>Actualizar DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>El componente Actualizar DIM_PROGRAMA es un Data Flow Task que forma parte del flujo ETL del paquete FACT_DESERTORES. Su prop\u00f3sito es extraer informaci\u00f3n de programas acad\u00e9micos de una fuente (por ejemplo, un archivo Excel que contiene el listado de estudiantes o programas) y cargar los registros que a\u00fan no existen en la tabla de dimensi\u00f3n DIM_PROGRAMA del esquema Cedesarrollo.</p> <p>Este componente se encarga de identificar los programas nuevos (aquellos que no est\u00e1n registrados en DIM_PROGRAMA) y, posteriormente, los inserta en la tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_2","title":"Detalles del Proceso","text":"<ol> <li> <p>Identificar Registros Nuevos </p> <ul> <li>El componente \"Identificar programas\" ejecuta una consulta SQL contra la tabla temporal (por ejemplo, una tabla en el \u00e1rea de staging) para extraer los programas que a\u00fan no han sido registrados en DIM_PROGRAMA.</li> <li>Se utiliza una instrucci\u00f3n que compara los datos extra\u00eddos con la informaci\u00f3n ya existente en DIM_PROGRAMA (mediante un LEFT JOIN y filtrando los registros donde el campo ID_PROGRAMA es NULL).</li> </ul> </li> <li> <p>Cargar Datos en DIM_PROGRAMA </p> <ul> <li>Una vez identificados los registros nuevos, el componente \"Guardar DIM_PROGRAMA\" inserta dichos registros en la tabla [Cedesarrollo].[DIM_PROGRAMA].</li> <li>Se utiliza la inserci\u00f3n masiva (Bulk Insert) para optimizar el rendimiento.</li> </ul> </li> <li> <p>Conexi\u00f3n y Configuraci\u00f3n </p> <ul> <li>El componente utiliza un administrador de conexiones configurado para el destino (DWH_COMFENALCO_Destino).</li> <li>Se definen propiedades como el tama\u00f1o del lote (BatchSize), tiempo de espera (CommandTimeout) y el uso de la interfaz SqlBulkCopy para mejorar el rendimiento.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_4","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama ilustra el flujo de datos para actualizar la tabla DIM_PROGRAMA:</p> <pre><code>graph TD\n    A[Identificar programas nuevos] --&gt; B[Generar conjunto de registros nuevos]\n    B --&gt; C[Guardar DIM_PROGRAMA]\n    C --&gt; D[Tabla DIM_PROGRAMA actualizada]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-matriculas-cedesarrollo","title":"Componente <code>Matriculas Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente Matriculas Cedesarrollo es un Data Flow Task encargado de procesar informaci\u00f3n de matr\u00edculas correspondientes al \u00e1rea de Cedesarrollo. Este flujo extrae datos desde un archivo Excel (utilizando el componente \"Listado cede\"), aplica transformaciones para estandarizar la informaci\u00f3n (por ejemplo, derivando un valor fijo para el identificador de unidad, que en este caso es 2) y carga el resultado en una tabla de staging denominada TMP_LISTADO_MATRICULAS_Q10 ubicada en el esquema Transversal.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_3","title":"Detalles del Proceso","text":"<ol> <li> <p>Extracci\u00f3n de Datos \u2013 Listado cede </p> <ul> <li>Fuente: Se utiliza un componente Excel Source denominado \"Listado cede\" para extraer los datos de la hoja de Excel.  </li> <li>Columnas Extra\u00eddas: Entre las columnas extra\u00eddas se encuentran:  <ul> <li>JORNADA </li> <li>NOMBRE_ESTUDIANTE </li> <li>TIPO_DOCUMENTO </li> <li>DOCUMENTO_ESTUDIANTE </li> <li>FECHA_MATRICULA </li> <li>TELEFONO </li> <li>CELULAR </li> <li>CORREO </li> <li>SEMESTRE </li> <li>ESTADO </li> <li>SEDE </li> <li>PROGRAMA</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos \u2013 Derivaci\u00f3n del ID_UNIDAD </p> <ul> <li>Componente: \"cede Derived ID_UNIDAD\"  </li> <li>Funci\u00f3n: Utiliza una transformaci\u00f3n Derived Column para agregar una nueva columna llamada ID_UNIDAD con un valor constante de 2.  </li> <li>Prop\u00f3sito: Este valor permite clasificar los registros como pertenecientes al \u00e1rea de Cedesarrollo, facilitando la integraci\u00f3n y posterior an\u00e1lisis.</li> </ul> </li> <li> <p>Carga de Datos \u2013 TMP_LISTADO_MATRICULAS_Q10 </p> <ul> <li>Destino: El componente \"TMP_MATRICULAS_Q10\" carga la informaci\u00f3n transformada en la tabla de staging [Transversal].[TMP_LISTADO_MATRICULAS_Q10].  </li> <li>Propiedades Clave: <ul> <li>Se utiliza la inserci\u00f3n masiva (Bulk Insert) para optimizar el rendimiento.  </li> <li>Configurado para trabajar con un tama\u00f1o de lote que se adapta al b\u00fafer interno de SSIS.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_5","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama muestra el flujo general de datos en este componente:</p> <pre><code>graph TD\n    A[Excel Source: Listado cede] --&gt; B[Derived Column: cede Derived ID_UNIDAD]\n    B --&gt; C[Destino: TMP_LISTADO_MATRICULAS_Q10]\n    C --&gt; D[Datos cargados en staging]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tmp_matriculas_cedesarrollo","title":"Componente <code>TMP_MATRICULAS_CEDESARROLLO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>El componente TMP_MATRICULAS_CEDESARROLLO es un Data Flow Task encargado de cargar y unificar datos de matr\u00edculas de Cedesarrollo en la tabla de staging [Transversal].[TMP_LISTADO_MATRICULAS_Q10]. Este flujo de datos toma la informaci\u00f3n procesada y consolidada (por medio de la transformaci\u00f3n \"Unificacion Listas Q10\") y la env\u00eda al destino, donde se almacena para procesos posteriores de integraci\u00f3n y an\u00e1lisis.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_4","title":"Detalles del Proceso","text":"<ol> <li> <p>Unificaci\u00f3n de Listas (Unificacion Listas Q10)</p> <ul> <li>Funci\u00f3n:     Extrae y unifica datos provenientes de una fuente consolidada (por ejemplo, registros de matr\u00edculas extra\u00eddos del Excel \"Listado cede\"). Esta transformaci\u00f3n estandariza la informaci\u00f3n, elimina duplicados y genera un conjunto de datos unificado.</li> <li>Columnas Clave: <ul> <li>NOMBRE_ESTUDIANTE  </li> <li>TIPO_DOCUMENTO  </li> <li>DOCUMENTO_ESTUDIANTE  </li> <li>FECHA_MATRICULA  </li> <li>TELEFONO  </li> <li>CELULAR  </li> <li>CORREO  </li> <li>SEMESTRE  </li> <li>ESTADO  </li> <li>SEDE  </li> <li>PROGRAMA  </li> <li>ID_UNIDAD  </li> <li>DOCUMENTOS_COMPLETOS  </li> <li>JORNADA</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos \u2013 Tabla Temporal</p> <ul> <li>Funci\u00f3n:     El componente \"Tabla Temporal\" utiliza el destino ADO.NET para insertar los datos unificados en la tabla [Transversal].[TMP_LISTADO_MATRICULAS_Q10].</li> <li>Propiedades Destacadas: <ul> <li>Inserci\u00f3n masiva habilitada para optimizar el rendimiento.  </li> <li>Par\u00e1metros de BatchSize y CommandTimeout configurados para un procesamiento eficiente.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_6","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama ilustra el flujo de datos en el componente:</p> <pre><code>graph TD\n    A[Unificacion Listas Q10 Fuente ADO.NET] --&gt; B[Tabla Temporal Destino]\n    B --&gt; C[Datos cargados en TMP_LISTADO_MATRICULAS_Q10]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-fact_estado_matriculas","title":"Componente <code>FACT_ESTADO_MATRICULAS</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>El componente Poblar Tabla FACT_ESTADO_MATRICULAS es un Data Flow Task que se encarga de extraer, transformar y cargar (ETL) datos para la tabla de hechos FACT_ESTADO_MATRICULAS. La informaci\u00f3n consolidada proviene de una consulta SQL que unifica y filtra registros de matr\u00edculas, asegur\u00e1ndose de insertar \u00fanicamente aquellos registros nuevos (aquellos que a\u00fan no se encuentren en la tabla destino). Este proceso permite actualizar la informaci\u00f3n del estado de matr\u00edcula en el entorno de Cedesarrollo, vinculando datos de estudiantes, programas, jornadas, periodos y fechas.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-proceso_5","title":"Detalles del Proceso","text":"<ol> <li> <p>Consulta de Origen (FACT_ESTADO_MATRICULAS Consulta):</p> <ul> <li>Funci\u00f3n:     Se ejecuta una consulta SQL que utiliza expresiones con cl\u00e1usulas WITH para crear subconjuntos de datos (por ejemplo, la CTE Matriculas) y generar valores calculados, como el identificador de fecha (ID_FECHA) y el periodo acad\u00e9mico derivado.</li> <li>Uniones y Filtros: <ul> <li>Se relaciona la fuente de datos con la tabla de estudiantes y, opcionalmente, con la tabla de periodos acad\u00e9micos.</li> <li>Se utiliza la funci\u00f3n ROW_NUMBER para eliminar duplicados y seleccionar s\u00f3lo el primer registro por estudiante, jornada, programa, periodo y semestre.</li> </ul> </li> <li>Resultado:     Se retorna un conjunto de datos que incluye campos clave como ID_PERIODO, ID_PROGRAMA, SEDE, ID_JORNADA, NOMBRE_ESTUDIANTE, ID_ESTUDIANTE, ID_FECHA, FECHA_MATRICULA, TELEFONO, CELULAR, CORREO, DOCUMENTOS_COMPLETOS, SEMESTRE, FECHA_INICIO_PERIODO y un campo de control (ID_MATRICULA) que, si es nulo, indica que el registro no existe en FACT_ESTADO_MATRICULAS.</li> </ul> </li> <li> <p>Salida de la Consulta:</p> <ul> <li>Los datos resultantes de la consulta se env\u00edan a la salida \"Salida de origen de ADO NET\" para su posterior procesamiento y carga.</li> </ul> </li> <li> <p>Carga en la Tabla Destino:</p> <ul> <li>Destino ADO.NET:     El componente utiliza el destino ADO.NET configurado para insertar los registros en la tabla [Cedesarrollo].[FACT_ESTADO_MATRICULAS].</li> <li>Propiedades Clave: <ul> <li>Se configura para realizar inserciones en bloque (Bulk Insert) con un BatchSize de 0 y un CommandTimeout de 30 segundos.</li> <li>Se utilizan las columnas extra\u00eddas por la consulta para alimentar la tabla destino, garantizando que se inserten s\u00f3lo aquellos registros que a\u00fan no se encuentren en la tabla (seg\u00fan la condici\u00f3n WHERE de la consulta).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-proceso_7","title":"Diagrama del Proceso","text":"<p>El siguiente diagrama ilustra de forma esquem\u00e1tica el flujo de datos dentro de este componente:</p> <pre><code>graph TD\n    A[Consulta FACT_ESTADO_MATRICULAS]\n    B[Salida de origen de ADO NET]\n    C[Destino ADO.NET: FACT_ESTADO_MATRICULAS]\n\n    A --&gt; B\n    B --&gt; C</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_graduados","title":"FACT_GRADUADOS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_programa","title":"Componente <code>Data DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_PROGRAMA est\u00e1 dise\u00f1ado para extraer, transformar y cargar (ETL) la informaci\u00f3n de los programas educativos provenientes de un archivo Excel. El proceso incluye la eliminaci\u00f3n de duplicados, la agregaci\u00f3n de datos y la verificaci\u00f3n de la existencia del programa a trav\u00e9s de una transformaci\u00f3n de b\u00fasqueda (Lookup). Finalmente, los registros \u00fanicos se insertan en la tabla [Cedesarrollo].[DIM_PROGRAMA].</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-proceso","title":"Detalle del Proceso","text":"<ol> <li> <p>Excel Source (Listado cede):</p> <ul> <li>Funci\u00f3n:     Extrae los datos de un archivo Excel, espec\u00edficamente de la hoja Sheet1, que contiene informaci\u00f3n relacionada con los programas (entre otros campos como JORNADA, NOMBRE_ESTUDIANTE, TIPO_DOCUMENTO, DOCUMENTO, etc.).</li> <li>Salida:     Genera un conjunto de registros que se utilizan como base para el procesamiento.</li> </ul> </li> <li> <p>Derived Column (cede Derived ID_UNIDAD):</p> <ul> <li>Funci\u00f3n:     Agrega o modifica columnas en el flujo de datos. En este caso, se crea una nueva columna ID_UNIDAD con un valor constante igual a 2, asignando la unidad correspondiente para el entorno de Cedesarrollo.</li> <li>Salida:     Los registros ahora incluyen el campo ID_UNIDAD.</li> </ul> </li> <li> <p>Sort PROGRAMA:</p> <ul> <li>Funci\u00f3n:     Ordena los registros por la columna PROGRAMA en orden ascendente. Se configura para eliminar duplicados, asegurando que cada programa se procese una sola vez.</li> <li>Salida:     Registros \u00fanicos y ordenados por PROGRAMA.</li> </ul> </li> <li> <p>Lookup PROGRAMA:</p> <ul> <li>Funci\u00f3n:     Realiza una b\u00fasqueda en la tabla [Cedesarrollo].[DIM_PROGRAMA] para identificar aquellos registros que ya existen en la dimensi\u00f3n.  <ul> <li>La consulta de Lookup se basa en la columna PROGRAMA.</li> <li>La propiedad NoMatchBehavior est\u00e1 configurada para enviar los registros sin coincidencias a la salida de \u201cno match\u201d, lo que permite identificar los nuevos programas.</li> </ul> </li> <li>Salida:     Se generan dos salidas:<ul> <li>Lookup Match Output: Registros que ya existen en la dimensi\u00f3n.</li> <li>Lookup No Match Output: Registros nuevos que deben ser insertados.</li> </ul> </li> </ul> </li> <li> <p>Aggregate 1:</p> <ul> <li>Funci\u00f3n:     Agrega (agrupa) los registros nuevos provenientes de la salida \u201cno match\u201d del Lookup.  <ul> <li>Se agrupa por la columna PROGRAMA.</li> <li>Se utiliza una funci\u00f3n de agregaci\u00f3n (en este caso, la propia columna) para garantizar que se obtenga un registro \u00fanico para cada programa.</li> </ul> </li> <li>Salida:     Un conjunto consolidado de programas nuevos.</li> </ul> </li> <li> <p>Destino ADO.NET \u2013 Guardar DIM_PROGRAMA:</p> <ul> <li>Funci\u00f3n:     Inserta los registros \u00fanicos resultantes en la tabla [Cedesarrollo].[DIM_PROGRAMA].</li> <li>Configuraci\u00f3n: <ul> <li>Se utiliza el proveedor ADO.NET configurado para el destino DWH_COMFENALCO_Destino.</li> <li>Se habilita el uso de inserci\u00f3n masiva (Bulk Insert) para mejorar el rendimiento.</li> </ul> </li> <li>Resultado:     La dimensi\u00f3n DIM_PROGRAMA queda actualizada con los nuevos programas.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-flujo-de-datos","title":"Diagrama de Flujo de Datos","text":"<pre><code>flowchart TD\n    A[Excel Source: Listado cede] --&gt; B[Derived Column: cede Derived ID_UNIDAD Asigna ID_UNIDAD = 2]\n    B --&gt; C[Sort PROGRAMA Ordena y elimina duplicados]\n    C --&gt; D[Lookup PROGRAMA Verifica existencia en DIM_PROGRAMA]\n    D -- \"No Match\" --&gt; E[Aggregate 1 Agrupa por PROGRAMA]\n    E --&gt; F[Destino ADO.NET: Guardar DIM_PROGRAMA]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_jornada","title":"Componente <code>Data DIM_JORNADA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_JORNADA extrae informaci\u00f3n relacionada con las jornadas acad\u00e9micas desde un archivo Excel, la transforma y la prepara para integrarse a la dimensi\u00f3n [Cedesarrollo].[DIM_JORNADA]. Este componente utiliza diversas transformaciones para garantizar que los datos sean consistentes, se eliminen duplicados y se enriquezcan con informaci\u00f3n de referencia.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-proceso_1","title":"Detalle del Proceso","text":"<ol> <li> <p>Excel Source 1:</p> <ul> <li>Funci\u00f3n:     Lee los datos desde un archivo Excel (hoja Sheet1) que contiene informaci\u00f3n sobre jornadas, as\u00ed como otros campos relevantes como ID_MATRICULA, TIPO_DOCUMENTO, DOCUMENTO, GRUPO, SEDE, PROGRAMA, PERIODO_ACADEMICO, SEMESTRE, FECHA_GRADUADO, ACTA_GRADUADO, FOLIO_GRADUADO, ZONA, \u00daLTIMA FECHA DE ACTUALIZACI\u00d3N y ID_UNIDAD.</li> <li>Salida:     Proporciona el conjunto de registros que servir\u00e1 como base para las transformaciones posteriores.</li> </ul> </li> <li> <p>Sort JORNADA:</p> <ul> <li>Funci\u00f3n:     Ordena los datos en funci\u00f3n de la columna JORNADA (y de ID_UNIDAD como segundo criterio), eliminando registros duplicados.  </li> <li>Salida:     Un conjunto ordenado y sin duplicados, que garantiza que cada jornada se procese de manera \u00fanica.</li> </ul> </li> <li> <p>Transformar Columnas (Derived Column):</p> <ul> <li>Funci\u00f3n:     Crea nuevas columnas derivadas, en este caso:</li> <li>_JORNADA: Se transforma y se ajusta el valor de la columna JORNADA para asegurar consistencia (por ejemplo, se puede estandarizar el formato o recortar espacios).</li> <li>_ID_UNIDAD: Convierte el valor de ID_UNIDAD al tipo de dato correcto (en este ejemplo se transforma a entero).</li> <li>Salida:     Los registros salen enriquecidos con las columnas _JORNADA y _ID_UNIDAD, prepar\u00e1ndolos para el siguiente paso.</li> </ul> </li> <li> <p>Aggregate:</p> <ul> <li>Funci\u00f3n:     Agrupa los registros bas\u00e1ndose en las columnas _JORNADA y _ID_UNIDAD. Esta agregaci\u00f3n garantiza que para cada combinaci\u00f3n \u00fanica de jornada y unidad se obtenga un solo registro.</li> <li>Salida:     Registros consolidados y agrupados, listos para ser verificados y comparados con la tabla de referencia.</li> </ul> </li> <li> <p>Filtrar Registros (Conditional Split):</p> <ul> <li>Funci\u00f3n:     Utiliza una condici\u00f3n (por ejemplo, verificando que la columna _JORNADA no sea nula ni est\u00e9 vac\u00eda) para dirigir solo los registros v\u00e1lidos al flujo de carga.</li> <li>Salida:     Se env\u00edan los registros v\u00e1lidos a la siguiente transformaci\u00f3n y los registros con errores o datos faltantes a la salida de error.</li> </ul> </li> <li> <p>Lookup DIM_JORNADA:</p> <ul> <li>Funci\u00f3n:     Realiza una b\u00fasqueda en la tabla [Cedesarrollo].[DIM_JORNADA] utilizando las columnas JORNADA e ID_UNIDAD para determinar si el registro ya existe.  <ul> <li>Par\u00e1metros:   Se utilizan los valores transformados (_JORNADA y _ID_UNIDAD) para hacer la comparaci\u00f3n.</li> </ul> </li> <li>Salida: <ul> <li>Lookup Match Output: Registros que ya existen en la dimensi\u00f3n.</li> <li>Lookup No Match Output: Registros nuevos que no tienen coincidencia en la tabla de referencia y, por tanto, deben ser insertados.</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_JORNADA (Destino ADO.NET):</p> <ul> <li>Funci\u00f3n:     Inserta los registros nuevos (provenientes de la salida \u201cno match\u201d del Lookup) en la tabla [Cedesarrollo].[DIM_JORNADA].  </li> <li>Configuraci\u00f3n: <ul> <li>Se utiliza un Connection Manager ADO.NET configurado para el destino DWH_COMFENALCO_Destino.</li> <li>La tarea est\u00e1 optimizada para inserciones masivas (Bulk Insert) para mejorar el rendimiento.</li> </ul> </li> <li>Resultado:     La dimensi\u00f3n DIM_JORNADA se actualiza con la informaci\u00f3n de nuevas jornadas, garantizando la integridad y consistencia de los datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-del-flujo-de-datos","title":"Diagrama del Flujo de Datos","text":"<pre><code>flowchart TD\n    A[Excel Source 1: Lee datos de jornada y otros campos]\n    B[Sort JORNADA: Ordena y elimina duplicados]\n    C[Transformar Columnas: Crea _JORNADA y _ID_UNIDAD]\n    D[Aggregate: Agrupa registros por _JORNADA y _ID_UNIDAD]\n    E[Filtrar Registros: Verifica que _JORNADA no sea nulo]\n    F[Lookup DIM_JORNADA: Busca coincidencias en la dimensi\u00f3n]\n    G[Guardar DIM_JORNADA: Inserta registros nuevos en Cedesarrollo.DIM_JORNADA]\n\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n    F -- \"No Match\" --&gt; G</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-fact_graduados","title":"Componente **<code>Data FACT_GRADUADOS</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#objetivo","title":"Objetivo","text":"<p>Procesar la informaci\u00f3n de graduados proveniente de un archivo Excel, transformarla (incluyendo el ajuste de fechas, conversi\u00f3n de tipos y enriquecimiento de datos a trav\u00e9s de m\u00faltiples Lookup) y cargarla en la tabla FACT_GRADUADOS para facilitar el an\u00e1lisis y reportes.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#flujo-del-proceso_2","title":"Flujo del Proceso","text":"<ol> <li> <p>Excel Source:</p> <ul> <li>Funci\u00f3n:     Extrae los registros de graduados desde una hoja de Excel (Sheet1). Columnas clave extra\u00eddas: <ul> <li>ID_MATRICULA  </li> <li>TIPO_DOCUMENTO  </li> <li>DOCUMENTO  </li> <li>GRUPO  </li> <li>SEDE  </li> <li>JORNADA  </li> <li>PROGRAMA  </li> <li>PERIODO_ACADEMICO  </li> <li>SEMESTRE  </li> <li>FECHA_GRADUADO  </li> <li>ACTA_GRADUADO  </li> <li>FOLIO_GRADUADO  </li> <li>ZONA  </li> <li>\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N  </li> <li>ID_UNIDAD</li> </ul> </li> </ul> </li> <li> <p>Derived Column \u2013 Ajuste de \"\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N\":</p> <ul> <li>Funci\u00f3n:     Se eval\u00faa la columna \u00daLTIMA FECHA DE ACTUALIZACI\u00d3N. Si es nula, se reemplaza por la fecha actual (GETDATE()); de lo contrario, se conserva el valor original.</li> <li>Expresi\u00f3n Utilizada: <pre><code>ISNULL([\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N]) ? GETDATE() : [\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N]\n</code></pre></li> <li>Resultado:     Se garantiza que siempre exista una fecha v\u00e1lida para el registro.</li> </ul> </li> <li> <p>Lookup Transformations:</p> <ul> <li>Lookup ACTA GRADO:     \u2013 Se busca en la tabla [Cedesarrollo].[FACT_GRADUADOS] mediante los valores de ACTA_GRADUADO, ID_ESTUDIANTE y ID_PROGRAMA para verificar la existencia de registros de graduados.</li> <li>Lookup ID_ESTUDIANTE:     \u2013 Se consulta la dimensi\u00f3n [Cedesarrollo].[DIM_ESTUDIANTES] utilizando el DOCUMENTO del graduado para obtener el ID_ESTUDIANTE.</li> <li>Lookup ID_JORNADA:     \u2013 Se realiza la b\u00fasqueda en [Cedesarrollo].[DIM_JORNADA] usando el campo JORNADA (y se considera la unidad) para extraer el ID_JORNADA.</li> <li>Lookup ID_PERIODO:     \u2013 Se utiliza la columna PERIODO_ACADEMICO para buscar el ID_PERIODO en la dimensi\u00f3n [Cedesarrollo].[DIM_PERIODO_ACADEMICO].</li> <li>Lookup ID_PROGRAMA:     \u2013 Se asocia el campo PROGRAMA con la dimensi\u00f3n [Cedesarrollo].[DIM_PROGRAMA] para obtener el ID_PROGRAMA.</li> </ul> </li> <li> <p>Multicast:</p> <ul> <li>Funci\u00f3n:     Duplica el flujo de datos para enviarlo a diferentes destinos o transformaciones sin realizar cambios adicionales. Esto permite que la informaci\u00f3n se enrute de manera paralela a diferentes procesos.</li> </ul> </li> <li> <p>Transformaciones Adicionales (Derived Column \u2013 Transforma Columnas &amp; Transformar Columnas):</p> <ul> <li>Funci\u00f3n:     Se crean nuevas columnas derivadas para normalizar y formatear los campos importantes, tales como:</li> <li>Ejemplos de columnas transformadas:<ul> <li>_TIPO_DOCUMENTO: Conversi\u00f3n y estandarizaci\u00f3n del tipo de documento.</li> <li>_DOCUMENTO: Conversi\u00f3n del n\u00famero de documento a formato de texto.</li> <li>_GRUPO, _ZONA, _SEDE, _JORNADA, _PROGRAMA, _SEMESTRE: Ajuste y formateo de los valores para asegurar consistencia.</li> <li>_ACTA_GRADUADO, _FOLIO_GRADUADO, _DIPLOMA_GRADUADO: Conversi\u00f3n y normalizaci\u00f3n de estos campos cr\u00edticos para identificar el documento de graduaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Destino \u2013 Guardar FACT_GRADUADOS:</p> <ul> <li>Funci\u00f3n:     Inserta el conjunto final de datos transformados en la tabla [Cedesarrollo].[FACT_GRADUADOS].  </li> <li>Configuraci\u00f3n del Destino:<ul> <li>Se utiliza un Connection Manager ADO.NET apuntando a DWH_COMFENALCO_Destino.</li> <li>Est\u00e1 optimizado para operaciones de inserci\u00f3n masiva (Bulk Insert) para mejorar el rendimiento.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-resumido-del-flujo","title":"Diagrama Resumido del Flujo","text":"<pre><code>flowchart TD\n    A[Excel Source: Extrae datos de graduados]\n    B[Derived Column: Ajusta '\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N']\n    C[Lookup ACTA GRADO: Verifica ACTA_GRADUADO, ID_ESTUDIANTE y ID_PROGRAMA]\n    D[Lookup ID_ESTUDIANTE: Busca ID_ESTUDIANTE en DIM_ESTUDIANTES]\n    E[Lookup ID_JORNADA: Obtiene ID_JORNADA desde DIM_JORNADA]\n    F[Lookup ID_PERIODO: Determina ID_PERIODO desde DIM_PERIODO_ACADEMICO]\n    G[Lookup ID_PROGRAMA: Relaciona PROGRAMA con DIM_PROGRAMA]\n    H[Multicast: Duplica flujo de datos]\n    I[Transforma Columnas: Deriva nuevos campos _TIPO_DOCUMENTO, _DOCUMENTO, etc.]\n    J[Transformar Columnas: Ajusta y normaliza los datos finales]\n    K[Guardar FACT_GRADUADOS: Inserta datos en la tabla destino]\n\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n    G --&gt; H\n    H --&gt; I\n    I --&gt; J\n    J --&gt; K</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_inscripcion_matriculas","title":"FACT_INSCRIPCION_MATRICULAS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_programa-1","title":"Componente <code>Data DIM_PROGRAMA 1</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_PROGRAMA 1 se encarga de procesar informaci\u00f3n de programas acad\u00e9micos, realizando operaciones de extracci\u00f3n desde una fuente de Excel, transformaci\u00f3n de datos y carga en una tabla de destino. Incluye tareas de ordenamiento, b\u00fasqueda y agregaci\u00f3n de registros.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li>Hoja: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>TIPO_DOCUMENTO, REFERENCIA, INSCRITO, FECHA, DOCUMENTO_ESTUDIANTE, PROGRAMA, NOMBRE, SEDE, JORNADA</code></li> </ul> </li> </ul> </li> <li> <p>Sort PROGRAMA</p> <ul> <li>Descripci\u00f3n: Ordena los datos en funci\u00f3n de la columna PROGRAMA.</li> <li>Propiedades:<ul> <li>Elimina duplicados: <code>true</code></li> <li>Orden por columna: PROGRAMA en orden ascendente.</li> </ul> </li> </ul> </li> <li> <p>Lookup PROGRAMA</p> <ul> <li>Descripci\u00f3n: Realiza un cruce de informaci\u00f3n con la tabla DIM_PROGRAMA para enriquecer los datos.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA]</code></li> <li>Comportamiento ante no coincidencias: Envia registros sin coincidencia a un flujo separado.</li> </ul> </li> </ul> </li> <li> <p>Aggregate 1</p> <ul> <li>Descripci\u00f3n: Realiza operaciones de agregaci\u00f3n sobre la columna PROGRAMA.</li> <li>Propiedades:<ul> <li>Factor de extensi\u00f3n de memoria: <code>25%</code></li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_PROGRAMA</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino DIM_PROGRAMA.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Table\n\n    SSIS -&gt;&gt; Excel: Extraer datos\n    Excel -&gt;&gt; SSIS: Datos procesados\n    SSIS -&gt;&gt; SQL: Lookup con DIM_PROGRAMA\n    SQL -&gt;&gt; SSIS: Resultados del cruce\n    SSIS -&gt;&gt; SQL: Carga de datos en DIM_PROGRAMA</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-fact_inscripcion_matriculas","title":"Componente <code>Data FACT_INSCRIPCION_MATRICULAS</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data FACT_INSCRIPCION_MATRICULAS maneja la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con la inscripci\u00f3n de matr\u00edculas. Incluye tareas de b\u00fasqueda, transformaci\u00f3n y derivaci\u00f3n de columnas, con la carga final en una tabla de hechos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>TIPO_DOCUMENTO,REFERENCIA,INSCRITO,FECHA,DOCUMENTO_ESTUDIANTE,PROGRAMA,NOMBRE,SEDE,JORNADA</code></li> </ul> </li> </ul> </li> <li> <p>Lookup ID_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Busca y asocia el identificador del estudiante desde la tabla DIM_ESTUDIANTES.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code></li> <li>Columna de uni\u00f3n: DOCUMENTO</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PROGRAMA</p> <ul> <li>Descripci\u00f3n: Busca y asocia el identificador del programa desde la tabla DIM_PROGRAMA.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA]</code></li> <li>Columna de uni\u00f3n: PROGRAMA</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_JORNADA</p> <ul> <li>Descripci\u00f3n: Busca y asocia el identificador de la jornada desde la tabla DIM_JORNADA.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]</code></li> <li>Columna de uni\u00f3n: JORNADA</li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas</p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas con transformaciones personalizadas.</li> <li>Columnas derivadas:<ul> <li><code>_INSCRITO</code>: <code>(DT_WSTR,40)INSCRITO</code></li> <li><code>_FECHA</code>: <code>(DT_DATE)FECHA</code></li> <li><code>_ID_PERIODO</code>: <code>-1</code></li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_INSCRIPCION_MATRICULAS</p> <ul> <li>Descripci\u00f3n: Busca coincidencias en la tabla FACT_INSCRIPCION_MATRICULAS.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]</code></li> <li>Columnas de uni\u00f3n: ID_ESTUDIANTE, ID_PROGRAMA, ID_JORNADA</li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_INSCRIPCION_MATRICULAS</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla de destino.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_INSCRIPCION_MATRICULAS\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Table\n\n    SSIS -&gt;&gt; Excel: Extraer datos\n    Excel -&gt;&gt; SSIS: Datos procesados\n    SSIS -&gt;&gt; SQL: Lookup con DIM_ESTUDIANTES\n    SQL -&gt;&gt; SSIS: Resultado Lookup ID_ESTUDIANTE\n    SSIS -&gt;&gt; SQL: Lookup con DIM_PROGRAMA\n    SQL -&gt;&gt; SSIS: Resultado Lookup ID_PROGRAMA\n    SSIS -&gt;&gt; SQL: Lookup con DIM_JORNADA\n    SQL -&gt;&gt; SSIS: Resultado Lookup ID_JORNADA\n    SSIS -&gt;&gt; SQL: Carga datos en FACT_INSCRIPCION_MATRICULAS</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_notas","title":"FACT_NOTAS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-cede_historico_notas","title":"Componente <code>Tarea cede_Historico_Notas</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>La tarea cede_Historico_Notas ejecuta un proceso externo para descargar datos hist\u00f3ricos de notas utilizando un script de Python.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-proceso","title":"Componentes del Proceso","text":"<ol> <li>Tarea cede_Historico_Notas<ul> <li>Descripci\u00f3n: Ejecuta un script de Python para descargar datos hist\u00f3ricos de notas.</li> <li>Propiedades:<ul> <li>Ruta del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos: <code>download.py --key cede_Historico_Notas</code></li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key cede_Historico_Notas`\n    Python -&gt;&gt; Python: Descarga datos de notas hist\u00f3ricas\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-dim_estudiantes-py_1","title":"Componente <code>dim_Estudiantes py</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>La tarea dim_Estudiantes py ejecuta un proceso externo para procesar la dimensi\u00f3n de estudiantes utilizando un script de Python.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-proceso_1","title":"Componentes del Proceso","text":"<ol> <li>dim_Estudiantes py<ul> <li>Descripci\u00f3n: Ejecuta un script de Python para procesar la tabla de dimensi\u00f3n de estudiantes.</li> <li>Propiedades:<ul> <li><code>Ruta del ejecutable</code>: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li><code>Argumentos</code>: <code>dim_Estudiantes.py</code></li> <li><code>Directorio de trabajo</code>: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `dim_Estudiantes.py`\n    Python -&gt;&gt; Python: Procesa la dimensi\u00f3n de estudiantes\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_jornada_1","title":"Componente <code>Data DIM_JORNADA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_JORNADA realiza el flujo de datos necesario para procesar y cargar la tabla de dimensi\u00f3n DIM_JORNADA. Incluye la extracci\u00f3n desde un archivo de Excel, transformaciones de datos y la carga en una base de datos de destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>JORNADA, SEDE, PERIODO_ACADEMICO, CURSO, NOMBRE_ESTUDIANTE, PRIMER_CORTE, SEGUNDO_CORTE, TERCER_CORTE, NOTA_FINAL, INASISTENCIAS_ACUMULADAS, MODULO, FECHA_INICIO, PROGRAMA_ACADEMICO, NOMBRE_DOCENTE, FECHA_FIN</code></li> </ul> </li> </ul> </li> <li> <p>Transformar ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Deriva una nueva columna con un identificador de unidad fijo.</li> <li>Columnas derivadas:<ul> <li>ID_UNIDAD: <code>2</code></li> </ul> </li> </ul> </li> <li> <p>Sort ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Ordena los datos por JORNADA y ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Eliminaci\u00f3n de duplicados: <code>true</code></li> </ul> </li> </ul> </li> <li> <p>Ajustar Ancho Columnas</p> <ul> <li>Descripci\u00f3n: Ajusta el ancho de las columnas procesadas.</li> <li>Columnas derivadas:<ul> <li>_JORNADA: <code>(DT_WSTR,40)JORNADA</code></li> <li>_ID_UNIDAD: <code>(DT_I4)ID_UNIDAD</code></li> </ul> </li> </ul> </li> <li> <p>Filtrar Registros Nulos</p> <ul> <li>Descripci\u00f3n: Filtra registros con valores nulos o vac\u00edos en la columna _JORNADA.</li> <li>Condici\u00f3n: <code>!ISNULL(_JORNADA) &amp;&amp; LEN(TRIM(_JORNADA)) &gt; 0</code></li> </ul> </li> <li> <p>Lookup DIM_JORNADA</p> <ul> <li>Descripci\u00f3n: Busca y asocia los registros en la tabla DIM_JORNADA con base en las columnas _JORNADA y _ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]</code></li> <li>Columnas de uni\u00f3n: JORNADA, ID_UNIDAD</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_JORNADA</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla DIM_JORNADA.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant DB as Database\n\n    SSIS -&gt;&gt; Excel: Extrae datos de `Sheet1$`\n    Excel -&gt;&gt; SSIS: Devuelve datos extra\u00eddos\n    SSIS -&gt;&gt; SSIS: Realiza transformaciones y ajustes\n    SSIS -&gt;&gt; DB: Guarda datos en `DIM_JORNADA`</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_periodo_academico","title":"Componente <code>Data DIM_PERIODO_ACADEMICO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_PERIODO_ACADEMICO realiza un flujo de datos para procesar y cargar la tabla de dimensi\u00f3n DIM_PERIODO_ACADEMICO. Este flujo incluye la extracci\u00f3n desde un archivo de Excel, transformaciones de datos y la carga en una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>PERIODO_ACADEMICO, SEDE, JORNADA, CURSO, NOMBRE_ESTUDIANTE, PRIMER_CORTE, SEGUNDO_CORTE, TERCER_CORTE, NOTA_FINAL, INASISTENCIAS_ACUMULADAS, MODULO, FECHA_INICIO, PROGRAMA_ACADEMICO, NOMBRE_DOCENTE, FECHA_FIN</code></li> </ul> </li> </ul> </li> <li> <p>Crear ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Deriva una nueva columna con un identificador de unidad fijo.</li> <li>Columnas derivadas:<ul> <li>ID_UNIDAD: <code>3</code></li> </ul> </li> </ul> </li> <li> <p>Sort PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Ordena los datos por PERIODO_ACADEMICO y ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Eliminaci\u00f3n de duplicados: <code>true</code></li> </ul> </li> </ul> </li> <li> <p>Ajustar Ancho Columnas</p> <ul> <li>Descripci\u00f3n: Ajusta el ancho de las columnas procesadas.</li> <li>Columnas derivadas:<ul> <li>_PERIODO_ACADEMICO: <code>(DT_WSTR,40)PERIODO_ACADEMICO</code></li> <li>_ID_UNIDAD: <code>(DT_I4)ID_UNIDAD</code></li> </ul> </li> </ul> </li> <li> <p>Filtrar Registros Vac\u00edos</p> <ul> <li>Descripci\u00f3n: Filtra registros con valores vac\u00edos o nulos en la columna _PERIODO_ACADEMICO.</li> <li>Condici\u00f3n: <code>!ISNULL(_PERIODO_ACADEMICO) &amp;&amp; LEN(TRIM(_PERIODO_ACADEMICO)) &gt; 0</code></li> </ul> </li> <li> <p>Lookup DIM_PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Busca y asocia registros en la tabla DIM_PERIODO_ACADEMICO con base en las columnas _PERIODO_ACADEMICO y _ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code></li> <li>Columnas de uni\u00f3n: PERIODO_ACADEMICO, ID_UNIDAD</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla DIM_PERIODO_ACADEMICO.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_PERIODO_ACADEMICO\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencias","title":"Diagrama de Secuencias","text":"<pre><code>graph TD\n    A(Excel Source) --&gt; B(Crear ID_UNIDAD: Deriva ID_UNIDAD=3)\n    B --&gt; C(Sort PERIODO_ACADEMICO: Ordena por PERIODO_ACADEMICO, ID_UNIDAD)\n    C --&gt; D(Ajustar Ancho Columnas: Deriva _PERIODO_ACADEMICO y _ID_UNIDAD)\n    D --&gt; E(Filtrar Registros Vac\u00edos: Elimina registros vac\u00edos)\n    E --&gt; F(Lookup DIM_PERIODO_ACADEMICO: Busca en DIM_PERIODO_ACADEMICO)\n    F --&gt; G(Guardar DIM_PERIODO_ACADEMICO: Carga a la tabla destino)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-flow-task","title":"Componente <code>Data Flow Task</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>El componente Data Flow Task tiene como prop\u00f3sito principal realizar la integraci\u00f3n, transformaci\u00f3n y carga de datos desde diversas fuentes hacia un destino final, aplicando transformaciones y validaciones requeridas para asegurar la calidad de los datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-de-los-componentes-del-flujo-de-datos","title":"Detalle de los Componentes del Flujo de Datos","text":"<ol> <li> <p>Combinar las tablas</p> <ul> <li>Descripci\u00f3n: Realiza una operaci\u00f3n de combinaci\u00f3n tipo JOIN entre dos conjuntos de datos. Se utiliza para consolidar datos en base a un campo clave.</li> <li>Propiedades:<ul> <li>Tipo de combinaci\u00f3n: <code>INNER JOIN</code>.</li> <li>N\u00famero de columnas clave: <code>1</code>.</li> <li>Manejo de nulos: Se trata como valores iguales.</li> <li>Buffers m\u00e1ximos por entrada: <code>5</code>.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada izquierda: Datos ordenados por <code>_NOMBRE_ESRTUDIANTE</code>.</li> <li>Entrada derecha: Datos ordenados por <code>NOMBRE_ESTUDIANTE</code>.</li> <li>Salida: Datos combinados con columnas provenientes de ambas entradas.</li> </ul> </li> </ul> </li> <li> <p>DIM_ESTUDIANTES PROCESADO</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla DIM_ESTUDIANTES para agregar informaci\u00f3n adicional a los registros actuales.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code>.</li> <li>Manejo de filas sin coincidencia: Se redirigen a una salida de error.</li> </ul> </li> <li>Conexiones:<ul> <li>Fuente de datos: OLE DB Connection Manager a DWH_COMFENALCO_Destino_OLEDB.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: <code>_DOCUMENTO</code>.</li> <li>Salida: <code>ID_ESTUDIANTE</code> mapeado desde la tabla de referencia.</li> </ul> </li> </ul> </li> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde una hoja de Excel para procesarlos en el flujo de datos.</li> <li>Propiedades:<ul> <li>Tabla/hoja: <code>Sheet1$</code>.</li> <li>Modo de acceso: Directo.</li> </ul> </li> <li>Conexiones:<ul> <li>Administrador de conexiones: OLE DB Connection Manager configurado para Excel.</li> </ul> </li> <li>Salidas:<ul> <li>Salida principal: Datos le\u00eddos con columnas como <code>PERIODO_ACADEMICO</code>, <code>JORNADA</code>, y <code>NOMBRE_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_NOTAS</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla FACT_NOTAS del destino de base de datos.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Cedesarrollo\".\"FACT_NOTAS\"</code>.</li> <li>Tama\u00f1o del lote: <code>0</code> (autom\u00e1tico).</li> <li>Uso de inserci\u00f3n masiva: Habilitado.</li> </ul> </li> <li>Conexiones:<ul> <li>Fuente: OLE DB Connection Manager configurado a DWH_COMFENALCO_Destino.</li> </ul> </li> <li>Entradas:<ul> <li>Datos combinados y enriquecidos con columnas como <code>PRIMER_CORTE</code>, <code>SEGUNDO_CORTE</code>, y <code>NOTA_FINAL</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_NOTAS</p> <ul> <li>Descripci\u00f3n: Valida si las notas ya existen en la tabla destino mediante un proceso de b\u00fasqueda.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_NOTAS] WHERE CURSO = ?</code>.</li> <li>Manejo de filas sin coincidencia: Redirige a una salida espec\u00edfica.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: Claves combinadas como <code>CURSO</code>, <code>ID_JORNADA</code>, y <code>ID_ESTUDIANTE</code>.</li> <li>Salida: Coincidencias y no coincidencias gestionadas separadamente.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_JORNADA</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_JORNADA</code> basado en el campo <code>JORNADA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Fuente: OLE DB Connection Manager.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: <code>JORNADA</code>.</li> <li>Salida: <code>ID_JORNADA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Recupera el <code>ID_PERIODO</code> usando el campo <code>PERIODO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code>.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: <code>PERIODO_ACADEMICO</code>.</li> <li>Salida: <code>ID_PERIODO</code>.</li> </ul> </li> </ul> </li> <li> <p>Sort NOMBRE_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Ordena los datos por el campo <code>_NOMBRE_ESRTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Elimina duplicados: No.</li> <li>Orden: Ascendente por <code>_NOMBRE_ESRTUDIANTE</code>.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: Datos procesados.</li> <li>Salida: Datos ordenados.</li> </ul> </li> </ul> </li> <li> <p>Sort _NOMBRE_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Similar al componente anterior, ordena los datos por el campo <code>_NOMBRE_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Elimina duplicados: No.</li> <li>Orden: Ascendente por <code>_NOMBRE_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n Columnas</p> <ul> <li>Descripci\u00f3n: Aplica transformaciones para generar columnas derivadas.</li> <li>Propiedades:<ul> <li>Agrega columnas como <code>_CURSO</code> y <code>_NOMBRE_DOCENTE</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    Excel[Excel Source 1] --&gt; Transformacion[Transformaci\u00f3n Columnas]\n    Transformacion --&gt; DIM_ESTUDIANTES[Lookup DIM_ESTUDIANTES]\n    DIM_ESTUDIANTES --&gt; CombinarTablas[Combinar las tablas]\n    CombinarTablas --&gt; Sort1[Sort NOMBRE_ESTUDIANTE]\n    Sort1 --&gt; LookupPERIODO[Lookup ID_PERIODO]\n    Sort1 --&gt; LookupJORNADA[Lookup ID_JORNADA]\n    LookupPERIODO --&gt; Guardar[Guardar FACT_NOTAS]\n    LookupJORNADA --&gt; Guardar\n    Sort1 --&gt; Guardar\n    _NOMBRE_ESTUDIANTE[Sort _NOMBRE_ESTUDIANTE] --&gt; Guardar</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_facturacion","title":"FACT_FACTURACION","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-cede_ingresos","title":"Componente <code>Tarea cede_Ingresos</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>El componente Tarea cede_Ingresos es un proceso ejecutado externamente que utiliza un script Python para descargar y procesar datos de ingresos relacionados con el proyecto COMFENALCO_EDUCACION. Este componente permite la integraci\u00f3n de datos externos al flujo de trabajo de SSIS, automatizando la adquisici\u00f3n de informaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-componente","title":"Detalle del Componente","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python externo para procesar datos de ingresos. Este script interact\u00faa con un servicio o base de datos externa, descargando y preparando la informaci\u00f3n para el an\u00e1lisis posterior.</li> <li>Propiedades:<ul> <li>Script ejecutado: <code>download.py</code>.</li> <li>Par\u00e1metro pasado: <code>--key cede_Ingresos</code>.</li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Utiliza las variables del proyecto:<ul> <li>Python_Executable: Ruta del ejecutable de Python.</li> <li>Working_Directory: Ruta del directorio base del proyecto.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea cede_Ingresos\n    participant Python as Script Python\n\n    SSIS -&gt;&gt; Python: Ejecutar `download.py --key cede_Ingresos`\n    Python -&gt;&gt; Python: Descargar y procesar datos de ingresos\n    Python -&gt;&gt; SSIS: Retornar datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-06-archivos-manuales","title":"Componente <code>Tarea EP-EPT-06 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EPT-06 (archivos manuales) es una tarea de ejecuci\u00f3n de proceso dise\u00f1ada para procesar datos de manera manual a trav\u00e9s de un script Python. Este componente forma parte del flujo de trabajo de FACT_FACTURACION, permitiendo la obtenci\u00f3n de informaci\u00f3n espec\u00edfica asociada con el identificador EPEPT06.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-componente_1","title":"Detalle del Componente","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python para procesar archivos manuales relacionados con el proyecto. Esta tarea es esencial para integrar datos que requieren intervenci\u00f3n manual antes de su inclusi\u00f3n en el flujo automatizado.</li> <li>Propiedades:<ul> <li>Script ejecutado: <code>download.py</code>.</li> <li>Par\u00e1metro pasado: <code>--key EPEPT06</code>.</li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Utiliza las variables del proyecto:<ul> <li>Python_Executable: Ruta del ejecutable de Python.</li> <li>Working_Directory: Ruta del directorio base del proyecto.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea EP-EPT-06\n    participant Python as Script Python\n\n    SSIS -&gt;&gt; Python: Ejecutar `download.py --key EPEPT06`\n    Python -&gt;&gt; Python: Procesar archivos manuales asociados\n    Python -&gt;&gt; SSIS: Retornar resultados procesados</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-fact_facturacion","title":"Componente <code>Tarea fact_facturacion</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_24","title":"Descripci\u00f3n General","text":"<p>El componente Tarea fact_facturacion es una tarea de ejecuci\u00f3n de proceso utilizada para automatizar el procesamiento de datos de facturaci\u00f3n mediante un script Python. Este componente forma parte del flujo de trabajo de FACT_FACTURACION, desempe\u00f1ando un rol crucial en la generaci\u00f3n de reportes y el manejo de datos relacionados con la facturaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-componente_2","title":"Detalle del Componente","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python encargado del procesamiento de la informaci\u00f3n de facturaci\u00f3n.</li> <li>Propiedades:<ul> <li>Script ejecutado: <code>fact_facturacion.py</code>.</li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Utiliza las variables del proyecto:<ul> <li>Python_Executable: Ruta del ejecutable de Python.</li> <li>Working_Directory: Ruta del directorio base del proyecto.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_11","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea fact_facturacion\n    participant Python as Script Python\n\n    SSIS -&gt;&gt; Python: Ejecutar `fact_facturacion.py`\n    Python -&gt;&gt; Python: Procesar datos de facturaci\u00f3n\n    Python -&gt;&gt; SSIS: Retornar resultados procesados</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-fact_facturacion","title":"Componente <code>Data FACT_FACTURACION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_25","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data FACT_FACTURACION se encarga de extraer, transformar y cargar informaci\u00f3n relacionada con la facturaci\u00f3n. Este componente integra datos provenientes de un archivo Excel (EP-EPT-06) y realiza las siguientes operaciones:</p> <ol> <li>Data Conversion: Convierte el tipo de datos de la columna FUENTE_RECURSOS del flujo de entrada (proveniente del Excel) a un formato de cadena de longitud 40.  </li> <li>Derived Column Transformation: Crea columnas derivadas mediante expresiones. Entre las columnas generadas se encuentran:  <ul> <li>_DOCUMENTO_PAGO: Convierte el valor de DOCUMENTO_PAGO a una cadena de 20 caracteres.  </li> <li>ID_FECHA: Calcula un identificador num\u00e9rico basado en la fecha contable, combinando a\u00f1o, mes y d\u00eda.  </li> <li>_CONCEPTO: Genera una versi\u00f3n en cadena (longitud 255) del campo CONCEPTO.  </li> <li>_ID_CONCEPTO: Convierte el campo ID_CONCEPTO a entero.  </li> <li>_TIPO_DOCUMENTO: Convierte TIPO_DOCUMENTO_PAGO a una cadena de 40 caracteres.  </li> <li>_NO_RECIBO: Convierte NO_RECIBO a una cadena de 40 caracteres.  </li> <li>_ANIO_CONTABLE: Deriva el a\u00f1o de FECHA_CONTABLE en formato cadena (40 caracteres).  </li> </ul> </li> <li>Lookup Transformations:  <ul> <li>Se ejecuta un primer Lookup que, mediante la combinaci\u00f3n de los campos NO_RECIBO y la versi\u00f3n derivada de DOCUMENTO_PAGO, consulta la tabla FACT_FACTURACION para determinar si existen registros previos (para evitar duplicados).  </li> <li>Se utilizan dos Lookups consecutivos: el primero consulta la tabla destino mediante una expresi\u00f3n SQL sin par\u00e1metros y el segundo utiliza par\u00e1metros para comparar NO_RECIBO y DOCUMENTO_PAGO.</li> </ul> </li> <li>Destino ADO.NET: Finalmente, el flujo carga los datos transformados y validados en la tabla de destino FACT_FACTURACION. Entre las columnas de destino se encuentran:  <ul> <li>FECHA_CONTABLE, VALOR_FACTURADO, VALOR_PAGADO, ID_FECHA, TIPO_DOCUMENTO_PAGO, DOCUMENTO_PAGO, CAJERO, ID_CONCEPTO, CONCEPTO, NO_RECIBO, ID_TARIFA, ID_CATEGORIA y FUENTE_RECURSOS.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-proceso","title":"Diagrama de Proceso","text":"<p>El siguiente diagrama de proceso describe de forma resumida el flujo de datos de Data FACT_FACTURACION:</p> <pre><code>flowchart TD\n    A[EP-EPT-06: Fuente Excel] --&gt; B[Data Conversion: Convertir FUENTE_RECURSOS]\n    B --&gt; C[Derived Column: Crear columnas derivadas]\n    C --&gt; D[Lookup 1: Consulta FACT_FACTURACION por NO_RECIBO y DOCUMENTO_PAGO]\n    D --&gt; E[Lookup 1 1: Consulta adicional para obtener ID_CATEGORIA]\n    E --&gt; F[Destino ADO.NET: Insertar datos en FACT_FACTURACION]</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-de-componentes","title":"Detalle de Componentes","text":"<ol> <li> <p>Data Conversion </p> <ul> <li>Entrada: Columna FUENTE_RECURSOS (tipo cadena, 255 caracteres) proveniente del Excel.  </li> <li>Salida: Columna convertida denominada Copy of FUENTE_RECURSOS con tipo cadena y longitud 40.</li> </ul> </li> <li> <p>Derived Column Transformation </p> <ul> <li>Operaciones:<ul> <li>_DOCUMENTO_PAGO: Convierte DOCUMENTO_PAGO a DT_WSTR(20).</li> <li>ID_FECHA: Calcula (YEAR(FECHA_CONTABLE) * 10000 + MONTH(FECHA_CONTABLE) * 100 + DAY(FECHA_CONTABLE)).</li> <li>_CONCEPTO, _ID_CONCEPTO, _TIPO_DOCUMENTO, _NO_RECIBO y _ANIO_CONTABLE: Se generan mediante expresiones que formatean y convierten los valores extra\u00eddos.</li> </ul> </li> </ul> </li> <li> <p>Lookup 1 y Lookup 1 1 </p> <ul> <li>Lookup 1: Realiza una consulta que une registros de la salida del Derived Column con la tabla FACT_FACTURACION.  </li> <li>Lookup 1 1: Complementa la b\u00fasqueda utilizando par\u00e1metros basados en CONCEPTO, ANIO_CONTABLE y el resultado del primer Lookup para obtener el ID_TARIFA y validar la categor\u00eda.</li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Acci\u00f3n: Inserta el conjunto final de datos en la tabla FACT_FACTURACION utilizando una inserci\u00f3n masiva para optimizar el rendimiento.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>EP-EPT-06 (Excel Source)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code>.</li> <li>Columnas extra\u00eddas:     <code>NO_RECIBO</code>, <code>FECHA_CONTABLE</code>, <code>PAGADO_POR</code>, <code>TIPO_DOCUMENTO_PAGO</code>, <code>DOCUMENTO_PAGO</code>, <code>CAJERO</code>, <code>ID_CONCEPTO</code>, <code>CONCEPTO</code>, <code>VALOR_FACTURADO</code>, <code>NOMBRE</code>, <code>VALOR_1</code>, <code>VALOR_PAGADO</code>.</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Crea columnas derivadas mediante expresiones para transformar datos existentes.</li> <li>Columnas derivadas:<ul> <li>_DOCUMENTO_PAGO: <code>(DT_WSTR,20)DOCUMENTO_PAGO</code>.</li> <li>ID_FECHA: <code>(DT_I4)(YEAR(FECHA_CONTABLE) * 10000 + MONTH(FECHA_CONTABLE) * 100 + DAY(FECHA_CONTABLE))</code>.</li> <li>_CONCEPTO: <code>(DT_WSTR,255)CONCEPTO</code>.</li> <li>_ID_CONCEPTO: <code>(DT_I4)ID_CONCEPTO</code>.</li> <li>_TIPO_DOCUMENTO: <code>(DT_WSTR,40)TIPO_DOCUMENTO_PAGO</code>.</li> <li>_NO_RECIBO: <code>(DT_WSTR,40)NO_RECIBO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Busca y asocia datos desde la tabla FACT_FACTURACION.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_FACTURACION]</code>.</li> <li>Condiciones de uni\u00f3n:<ul> <li><code>NO_RECIBO</code> con <code>NO_RECIBO</code>.</li> <li><code>_DOCUMENTO_PAGO</code> con <code>DOCUMENTO_PAGO</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla de destino en la base de datos.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_FACTURACION\"</code>.</li> <li>Inserci\u00f3n masiva habilitada: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_12","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(EP-EPT-06: Fuente Excel) --&gt; B(Derived Column: Transformaciones)\n    B --&gt; C(Lookup: Buscar en FACT_FACTURACION)\n    C --&gt; D(Destino de ADO NET: Cargar datos en FACT_FACTURACION)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_horario","title":"FACT_HORARIO","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-04-achivos-manuales","title":"Componente <code>Tarea EP-EPT-04 (achivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_26","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-04 (achivos manuales) es un proceso externo que se ejecuta mediante un script de Python. Su funci\u00f3n es descargar de forma manual los archivos necesarios para el procesamiento de datos de horarios acad\u00e9micos. Esta tarea forma parte del flujo de integraci\u00f3n de FACT_HORARIO y permite que los datos descargados est\u00e9n disponibles en el entorno de trabajo para etapas posteriores del proceso ETL.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-la-tarea","title":"Propiedades de la Tarea","text":"<ul> <li>Tipo de Tarea: Ejecutar proceso externo.</li> <li> <p>Ejecutable:   La ruta se configura mediante la variable del proyecto: <code>@[$Project::Python_Executable]</code>   En este caso, la ruta real es: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Argumentos: <code>download.py --key EPEPT04</code></p> </li> <li> <p>Directorio de Trabajo:   Se configura mediante la variable: <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code></p> </li> <li> <p>Configuraciones Adicionales:</p> <ul> <li>La tarea utiliza un filtro de registro (LoggingOptions) configurado con <code>FilterKind=0</code>.</li> <li>El valor de <code>ThreadHint</code> se establece en <code>0</code> para indicar que no se sugiere un n\u00famero espec\u00edfico de hilos.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-proceso_1","title":"Diagrama de Proceso","text":"<p>El siguiente diagrama de proceso describe la ejecuci\u00f3n de la tarea:</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta download.py --key EPEPT04\n    Python -&gt;&gt; Python: Descarga archivos manuales para FACT_HORARIO\n    Python -&gt;&gt; SSIS: Retorna resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_horario","title":"Componente <code>Procesar FACT_HORARIO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_27","title":"Descripci\u00f3n General","text":"<p>Este paquete SSIS tiene como objetivo procesar los datos relacionados con horarios acad\u00e9micos. Incluye m\u00faltiples transformaciones para extraer, transformar y cargar datos (ETL) desde archivos de Excel hacia una base de datos compatible con ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source </p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel.  </li> <li>Propiedades:  <ul> <li>Nombre de hoja: <code>'EP-EPT-04$'</code> </li> <li>Timeout del comando: <code>0</code> (sin l\u00edmite).  </li> <li>AccessMode: <code>0</code> (modo directo).  </li> </ul> </li> <li>Conexiones: OleDbConnection.  </li> <li>Columnas de salida:  <ul> <li><code>MODULO</code>, <code>PERIODO ACADEMICO</code>, <code>PROGRAMA</code>, <code>JORNADA</code>, <code>SEMESTRE</code>, etc.  </li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PROGRAMA </p> <ul> <li>Descripci\u00f3n: Asocia datos del m\u00f3dulo con su respectivo programa.  </li> <li>Propiedades:  <ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PLAN_CURRICULAR] WHERE MODULO = ?</code> </li> <li>Tipo de cach\u00e9: <code>Completa</code>.  </li> </ul> </li> <li>Conexi\u00f3n: OleDbConnection.  </li> <li>Columnas de entrada: <code>MODULO</code>.  </li> <li>Columnas de salida: <code>ID_PROGRAMA</code>, <code>ID_MODULO</code>.  </li> </ul> </li> <li> <p>Join Tablas </p> <ul> <li>Descripci\u00f3n: Une dos flujos de datos ordenados.  </li> <li>Propiedades:  <ul> <li>Tipo de uni\u00f3n: <code>INNER</code>.  </li> <li>Columnas clave: <code>SEMESTRE</code>, <code>GRUPO</code>.  </li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas </p> <ul> <li>Descripci\u00f3n: Aplica transformaciones derivadas a las columnas.  </li> <li>Columnas de salida:  <ul> <li><code>NOMBRE_DOCENTE</code>: <code>(DT_WSTR,200)_DOCENTE</code>.  </li> <li><code>HORA_FIN</code>: <code>(DT_WSTR,40)FIN</code>.  </li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_HORARIO </p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_HORARIO</code>.  </li> <li>Propiedades:  <ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_HORARIO\"</code>.  </li> <li>Tama\u00f1o de lotes: <code>0</code>.  </li> </ul> </li> <li>Columnas de entrada: <code>GRUPO</code>, <code>ID_MODULO</code>, <code>ID_PERIODO</code>, <code>NOMBRE_DOCENTE</code>, etc.  </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_13","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Excel Source\n    participant Lookup as Lookup ID_PROGRAMA\n    participant Join as Join Tablas\n    participant Transform as Transformar Columnas\n    participant Save as Guardar FACT_HORARIO\n\n    Excel -&gt;&gt; Lookup: Env\u00eda datos (MODULO)\n    Lookup -&gt;&gt; Join: Devuelve ID_PROGRAMA\n    Join -&gt;&gt; Transform: Realiza uni\u00f3n\n    Transform -&gt;&gt; Save: Transformaciones derivadas\n    Save -&gt;&gt; DB: Inserta datos en FACT_HORARIO</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_ausentismo_docente","title":"FACT_AUSENTISMO_DOCENTE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-edf-02-achivos-manuales","title":"Componente Tarea EP-EDF-02 (achivos manuales)","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_28","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EDF-02 (achivos manuales) ejecuta un proceso externo mediante un script de Python. Este script est\u00e1 dise\u00f1ado para descargar y preparar datos manuales asociados al archivo identificado como EP-EDF-02.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-componente","title":"Detalles del Componente","text":"<p>Propiedades</p> <ul> <li>Tipo de Tarea: Ejecutar proceso externo.</li> <li>Ruta del Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> <li>Argumentos:<ul> <li><code>download.py --key EPEDF02</code>.</li> </ul> </li> <li>Directorio de Trabajo:<ul> <li><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> </ul> </li> </ul> <p>Variables Utilizadas</p> <ul> <li>@[$Project::Python_Executable]: Ruta al ejecutable de Python.</li> <li>@[$Project::Working_Directory]: Ruta base del directorio de trabajo.</li> </ul> <p>Descripci\u00f3n del Script</p> <ul> <li>Script: <code>download.py</code>.</li> <li>Argumento Principal: <code>--key EPEDF02</code>, utilizado para identificar el archivo espec\u00edfico a procesar.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_14","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEDF02`\n    Python -&gt;&gt; Python: Descarga datos correspondientes a EPEDF02\n    Python -&gt;&gt; SSIS: Finaliza ejecuci\u00f3n del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_ausentismo_docente","title":"Componente <code>Procesar FACT_AUSENTISMO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_29","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_AUSENTISMO_DOCENTE gestiona el flujo de datos para la extracci\u00f3n, transformaci\u00f3n y carga de informaci\u00f3n sobre ausentismo docente. Inicia con la lectura de un archivo Excel, realiza transformaciones en columnas, utiliza b\u00fasquedas en tablas relacionadas y finalmente carga los datos transformados en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel EP-EDF-02 (Excel Source)</p> <ul> <li>Descripci\u00f3n: Extrae datos de un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code>.</li> <li>Columnas extra\u00eddas:     <code>PERIODO_ACADEMICO</code>, <code>FECHA</code>, <code>NOMBRE_DOCENTE</code>, <code>CARGO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>, <code>AUSENCIA_HORAS</code>, <code>AUSENCIA_DIAS</code>, <code>TIPO_AUSENCIA</code>, <code>PERMISO</code>, <code>MOTIVO_AUSENCIA</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformacion de Columnas</p> <ul> <li>Descripci\u00f3n: Realiza transformaciones para crear nuevas columnas derivadas.</li> <li>Columnas derivadas:<ul> <li>_PERIODO: <code>(DT_WSTR,40)PERIODO_ACADEMICO</code>.</li> <li>ID_FECHA: <code>[REPLACE]([REPLACE]([REPLACE](FECHA,\"-\",\"\"),\"/\",\"\"),\".\",\"\")</code>.</li> <li>_MOTIVO_AUSENCIA: <code>(DT_WSTR,40)MOTIVO_AUSENCIA</code>.</li> <li>_FECHA: <code>(DT_DATE)FECHA</code>.</li> <li>_DOCENTE: <code>(DT_WSTR,200)NOMBRE_DOCENTE</code>.</li> <li>_CARGO: <code>(DT_WSTR,40)CARGO</code>.</li> <li>_INICIO: <code>(DT_DATE)FECHA_INICIO</code>.</li> <li>_FIN: <code>(DT_DATE)FECHA_FIN</code>.</li> <li>_HORAS: <code>(DT_WSTR,40)AUSENCIA_HORAS</code>.</li> <li>_DIAS: <code>(DT_WSTR,40)AUSENCIA_DIAS</code>.</li> <li>_TIPO: <code>(DT_WSTR,40)TIPO_AUSENCIA</code>.</li> <li>_PERMISO: <code>(DT_WSTR,40)PERMISO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Busca el ID del periodo acad\u00e9mico en la tabla DIM_PERIODO_ACADEMICO.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code>.</li> <li>Condiciones de uni\u00f3n:<ul> <li><code>_PERIODO</code> con <code>PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Columna _ID_FECHA</p> <ul> <li>Descripci\u00f3n: Convierte el valor de ID_FECHA a tipo entero.</li> <li>Propiedades:<ul> <li>Expresi\u00f3n: <code>(DT_I4)ID_FECHA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_AUSENTISMO_DOCENTE</p> <ul> <li>Descripci\u00f3n: Busca datos en la tabla de destino para determinar registros existentes.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]</code>.</li> <li>Condiciones de uni\u00f3n:<ul> <li><code>_DOCENTE</code> con <code>NOMBRE_DOCENTE</code>.</li> <li><code>ID_PERIODO</code> con <code>ID_PERIODO</code>.</li> <li><code>_ID_FECHA</code> con <code>ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_AUSENTISMO_DOCENTE</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla destino.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_AUSENTISMO_DOCENTE\"</code>.</li> <li>Inserci\u00f3n masiva habilitada: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_15","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(EP-EDF-02: Fuente Excel) --&gt; B(Transformacion de Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Columna _ID_FECHA)\n    D --&gt; E(Lookup FACT_AUSENTISMO_DOCENTE)\n    E --&gt; F(Guardar FACT_AUSENTISMO_DOCENTE)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_permiso_estudiante","title":"FACT_PERMISO_ESTUDIANTE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-edf-04-achivos-manuales","title":"Componente <code>Tarea EP-EDF-04 (achivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_30","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EDF-04 (achivos manuales) ejecuta un proceso externo mediante un script de Python. Este script est\u00e1 dise\u00f1ado para descargar y procesar datos manuales relacionados con el archivo identificado como EP-EDF-04.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-componente_1","title":"Detalles del Componente","text":"<p>Propiedades</p> <ul> <li>Tipo de Tarea: Ejecutar proceso externo.</li> <li>Ruta del Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> <li>Argumentos:<ul> <li><code>download.py --key EPEDF04</code>.</li> </ul> </li> <li>Directorio de Trabajo:<ul> <li><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> </ul> </li> </ul> <p>Variables Utilizadas</p> <ul> <li>@[$Project::Python_Executable]: Ruta al ejecutable de Python.</li> <li>@[$Project::Working_Directory]: Ruta base del directorio de trabajo.</li> </ul> <p>Descripci\u00f3n del Script</p> <ul> <li>Script: <code>download.py</code>.</li> <li>Argumento Principal: <code>--key EPEDF04</code>, utilizado para identificar el archivo espec\u00edfico a procesar.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_16","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEDF04`\n    Python -&gt;&gt; Python: Descarga datos correspondientes a EPEDF04\n    Python -&gt;&gt; SSIS: Reporta resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_permiso_estudiante","title":"Componente <code>Procesar FACT_PERMISO_ESTUDIANTE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_31","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_PERMISO_ESTUDIANTE extrae datos de un archivo Excel (<code>EP-EDF-04</code>), transforma y enriquece los datos utilizando varias transformaciones, y finalmente los carga en una tabla destino en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<p>1. Excel Source (EP-EDF-04)</p> <ul> <li>Descripci\u00f3n: Carga datos desde el archivo Excel asociado a la hoja <code>Sheet1$</code>.</li> <li>Propiedades:<ul> <li>Timeout de Comando: <code>0</code> (sin l\u00edmite).</li> <li>Modo de Acceso: <code>OpenRowset</code>.</li> </ul> </li> <li>Columnas Procesadas:   <code>PERIODO ACADEMICO</code>, <code>DOC_ESTUDIANTE</code>, <code>MODULO</code>, <code>FECHA</code>, <code>HORA</code>, <code>MOTIVO_AUSENCIA</code>, <code>SOPORTE_AUSENCIA</code>.</li> </ul> <p>2. Transformar Columnas</p> <ul> <li>Descripci\u00f3n: Aplica transformaciones para crear nuevas columnas y enriquecer los datos.</li> <li>Columnas Derivadas:<ul> <li><code>_PERIODO</code>: Transformaci\u00f3n de <code>PERIODO ACADEMICO</code>.</li> <li><code>DOCUMENTO</code>: Transformaci\u00f3n de <code>DOC_ESTUDIANTE</code>.</li> <li><code>_MODULO</code>: Transformaci\u00f3n de <code>MODULO</code>.</li> <li><code>ID_FECHA</code>: Deriva un identificador de fecha.</li> <li><code>_FECHA</code>: Conversi\u00f3n a formato de fecha.</li> <li><code>_HORA</code>, <code>_MOTIVO_AUSENCIA</code>, <code>_SOPORTE_AUSENCIA</code>.</li> </ul> </li> </ul> <p>3. Lookup ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Enlaza informaci\u00f3n de la tabla <code>DIM_PERIODO_ACADEMICO</code> para identificar el ID del periodo acad\u00e9mico.</li> <li>Consulta SQL:   <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\nWHERE [PERIODO_ACADEMICO] = ?\n</code></pre></li> <li>Salida:     <code>ID_PERIODO</code>.</li> </ul> <p>4. Lookup ID_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Consulta la tabla <code>DIM_ESTUDIANTES</code> para obtener el ID del estudiante basado en su documento.</li> <li>Consulta SQL:   <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_ESTUDIANTES]\nWHERE [DOCUMENTO] = ?\n</code></pre></li> <li>Salida:   <code>ID_ESTUDIANTE</code>.</li> </ul> <p>5. Lookup FACT_PERMISO_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Verifica si existe un permiso para el estudiante en la tabla <code>FACT_PERMISO_ESTUDIANTE</code> utilizando m\u00faltiples claves.</li> <li>Consulta SQL:   <pre><code>SELECT * \nFROM [Cedesarrollo].[FACT_PERMISO_ESTUDIANTE]\nWHERE [ID_FECHA] = ? \n  AND [ID_PERIODO] = ? \n  AND [ID_ESTUDIANTE] = ?\n</code></pre></li> </ul> <p>6. Destino ADO.NET (Guardar FACT_PERMISO_ESTUDIANTE)</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>FACT_PERMISO_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Tabla Destino: <code>\"Cedesarrollo\".\"FACT_PERMISO_ESTUDIANTE\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (ajustado al tama\u00f1o del buffer).</li> <li>Timeout de Comando: <code>30</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_17","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant DB as SQL Server Database\n\n    SSIS -&gt;&gt; Excel: Carga datos de EP-EDF-04\n    Excel -&gt;&gt; SSIS: Env\u00eda datos al flujo\n    SSIS -&gt;&gt; DB: Consulta ID_PERIODO desde DIM_PERIODO_ACADEMICO\n    SSIS -&gt;&gt; DB: Consulta ID_ESTUDIANTE desde DIM_ESTUDIANTES\n    SSIS -&gt;&gt; DB: Verifica datos en FACT_PERMISO_ESTUDIANTE\n    SSIS -&gt;&gt; DB: Inserta datos en FACT_PERMISO_ESTUDIANTE</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#dim_preguntas_cotizacion","title":"DIM_PREGUNTAS_COTIZACION","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-12-archivos-manuales","title":"Componente <code>Tarea EP-EPT-12 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_32","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EPT-12 (archivos manuales) utiliza el componente Execute Process Task para ejecutar un script Python que descarga datos asociados con la clave <code>EPEPT12</code>.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-configuracion","title":"Propiedades de Configuraci\u00f3n","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python ubicado en el entorno de trabajo para descargar datos.</li> <li>Archivo Ejecutable: <code>python.exe</code> del entorno virtual en:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos:   <pre><code>download.py --key EPEPT12\n</code></pre></li> <li>Directorio de Trabajo:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_18","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT12`\n    Python -&gt;&gt; Python: Descarga datos asociados a la clave\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-valor-nulo-por-defecto","title":"Componente <code>Valor nulo por defecto</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_33","title":"Descripci\u00f3n General","text":"<p>El componente Valor nulo por defecto es una tarea de ejecuci\u00f3n SQL en SSIS que se utiliza para garantizar que exista un registro por defecto en la tabla de dimensi\u00f3n DIM_PREGUNTAS_COTIZACION. En concreto, verifica si ya existe un registro con ID_PREGUNTAS igual a -1. Si no existe, inserta un registro con los siguientes valores: - ID_PREGUNTAS: -1 - PREGUNTA: \"PREGUNTA_NO_IDENTIFICADA\" - OBSERVACIONES: \"SIN_OBSERVACIONES\"</p> <p>Este registro se utiliza para representar valores nulos o no identificados en el proceso de carga de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_3","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Ejecutar SQL (Execute SQL Task)</li> <li>Conexi\u00f3n: Se utiliza el administrador de conexiones con ID <code>{C2A27DDB-56C2-4889-8A4B-7AA7124DFFD7}</code> para conectarse al servidor de destino.</li> <li>Script SQL:   <pre><code>-- Verificar si ya existe el registro con ID_PREGUNTA -1\nIF NOT EXISTS (SELECT 1 FROM [DWH_COMFENALCO].[Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] WHERE ID_PREGUNTAS = -1)\nBEGIN\n    -- Insertar -1 para preguntas de cotizaciones\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] ON;\n    INSERT INTO [DWH_COMFENALCO].[Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] (ID_PREGUNTAS, PREGUNTA, OBSERVACIONES)\n    VALUES (-1, 'PREGUNTA_NO_IDENTIFICADA', 'SIN_OBSERVACIONES');\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] OFF;\nEND;\n</code></pre></li> <li>Tiempo de Espera y Otras Opciones: Se utilizan las configuraciones predeterminadas para la tarea SQL.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-proceso_2","title":"Diagrama de Proceso","text":"<p>El siguiente diagrama ilustra el proceso que ejecuta este componente:</p> <pre><code>sequenceDiagram\n    SSIS Package -&gt;&gt; SQL Server: Ejecuta la tarea SQL\n    SQL Server --&gt;&gt; SQL Server: Verifica existencia de registro con ID_PREGUNTAS = -1\n    alt Registro no existe\n        SQL Server -&gt;&gt; SQL Server: Inserta registro por defecto\n    else Registro ya existe\n        SQL Server -&gt;&gt; SQL Server: No realiza acci\u00f3n\n    end\n    SQL Server --&gt;&gt; SSIS Package: Retorna resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_evaluacion_formacion","title":"Componente <code>Procesar FACT_EVALUACION_FORMACION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_34","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_EVALUACION_FORMACION tiene como prop\u00f3sito extraer, transformar y cargar datos relacionados con las preguntas de cotizaci\u00f3n en la tabla destino DIM_PREGUNTAS_COTIZACION. Utiliza un archivo Excel como fuente y realiza transformaciones y validaciones antes de insertar los datos en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_9","title":"Componentes del Flujo de Datos","text":"<p>1. Componente EP-EPT-12 (Fuente Excel)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel en la hoja <code>Sheet1$</code>.</li> <li>Propiedades:<ul> <li>Conexi\u00f3n: Administrador de conexiones con Excel.</li> <li>Columnas de salida:<ul> <li><code>PREGUNTA</code>: Texto relacionado con las preguntas de cotizaci\u00f3n.</li> <li><code>OBSERVACIONES</code>: Comentarios u observaciones adicionales.</li> </ul> </li> </ul> </li> </ul> <p>2. Transformaci\u00f3n de Columnas</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas de las existentes o las formatea seg\u00fan sea necesario.</li> <li>Columnas de salida:<ul> <li><code>_PREGUNTA</code>: Conversi\u00f3n de <code>PREGUNTA</code> al formato <code>DT_WSTR</code> con una longitud de 200.</li> <li><code>_OBSERVACIONES</code>: Conversi\u00f3n de <code>OBSERVACIONES</code> al formato <code>DT_WSTR</code> con una longitud de 200.</li> </ul> </li> </ul> <p>3. Lookup</p> <ul> <li>Descripci\u00f3n: Verifica si las preguntas ya existen en la tabla destino para evitar duplicados.</li> <li>Fuente de referencia: Tabla DIM_PREGUNTAS_COTIZACION.</li> <li>Propiedades:<ul> <li>SQL de b\u00fasqueda:      <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PREGUNTAS_COTIZACION]\n</code></pre></li> <li>Comportamiento en caso de no coincidencias: Enviar filas al siguiente paso.</li> </ul> </li> </ul> <p>4. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta datos nuevos en la tabla DIM_PREGUNTAS_COTIZACION.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_PREGUNTAS_COTIZACION\"</code>.</li> <li>Conexi\u00f3n: Administrador de conexiones con ADO.NET.</li> <li>Columnas cargadas:<ul> <li><code>PREGUNTA</code>.</li> <li><code>OBSERVACIONES</code>.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_19","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Fuente Excel\n    participant SSIS as Flujo de Datos\n    participant DB as Base de Datos\n\n    Excel -&gt;&gt; SSIS: Extrae datos (PREGUNTA, OBSERVACIONES)\n    SSIS -&gt;&gt; SSIS: Aplica transformaciones (_PREGUNTA, _OBSERVACIONES)\n    SSIS -&gt;&gt; DB: Verifica duplicados (Lookup)\n    SSIS -&gt;&gt; DB: Inserta datos nuevos</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_plan_cobertura","title":"FACT_PLAN_COBERTURA","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-07-archivos-manuales","title":"Componente <code>Tarea EP-EPT-07 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_35","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EPT-07 (archivos manuales) ejecuta un proceso externo mediante un script de Python. Su prop\u00f3sito es descargar los datos relacionados con el plan de cobertura, proces\u00e1ndolos desde un archivo externo y prepar\u00e1ndolos para su integraci\u00f3n en el flujo de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo","title":"Componentes del Flujo","text":"<p>1. Ejecutar Proceso (EP-EPT-07)</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python ubicado en el directorio de trabajo para descargar los datos correspondientes.</li> <li>Propiedades:</li> <li>Archivo ejecutable:     <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos del script:     <pre><code>download.py --key EPEPT07\n</code></pre></li> <li>Directorio de trabajo:     <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> <li>Propiedades din\u00e1micas:<ul> <li><code>Executable</code>: @[$Project::Python_Executable]</li> <li><code>WorkingDirectory</code>: @[$Project::Working_Directory] + \"\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\"</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_20","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT07`\n    Python -&gt;&gt; Python: Descarga datos de Plan de Cobertura\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_plan_cobertura","title":"Componente <code>Procesar FACT_PLAN_COBERTURA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_36","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_PLAN_COBERTURA permite extraer, transformar y cargar (ETL) datos relacionados con el plan de cobertura. Utiliza varias transformaciones y b\u00fasquedas para preparar los datos antes de almacenarlos en el destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_10","title":"Componentes del Flujo de Datos","text":"<p>1. Fuente de Excel (EP-EPT-07)</p> <ul> <li>Descripci\u00f3n: Extrae datos de una hoja de c\u00e1lculo de Excel.</li> <li>Propiedades:<ul> <li>Nombre del objeto de base de datos: <code>Sheet1$</code></li> <li>Conexi\u00f3n: Administrador de conexiones con Excel 17</li> <li>Columnas de salida: <code>,UNIDAD,MODALIDAD,CATEGOR\u00cdA,USOS_PROYECTADOS,USUARIOS_PROYECTADOS,PERIODO_ACADEMICO,PROGRAMA</code></li> </ul> </li> </ul> <p>2. Columna Derivada</p> <ul> <li>Descripci\u00f3n: Genera una nueva columna <code>_PERIODO</code> basada en la columna <code>PERIODO ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Expresi\u00f3n derivada: <code>(DT_WSTR,40)[PERIODO ACADEMICO]</code></li> <li>Columna de salida: <code>_PERIODO</code></li> </ul> </li> </ul> <p>3. B\u00fasqueda de ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_PERIODO_ACADEMICO</code> para obtener el ID del per\u00edodo acad\u00e9mico asociado.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\nWHERE [PERIODO_ACADEMICO] = ?\n</code></pre></li> <li>Columnas relacionadas:<ul> <li>Entrada: <code>_PERIODO</code></li> <li>Salida: <code>ID_PERIODO</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_21","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Fuente de Excel\n    participant SQL as SQL Lookup\n\n    SSIS -&gt;&gt; Excel: Extrae datos desde \"Sheet1$\"\n    Excel -&gt;&gt; SSIS: Env\u00eda datos transformados\n    SSIS -&gt;&gt; SQL: Realiza b\u00fasqueda en \"DIM_PERIODO_ACADEMICO\"\n    SQL -&gt;&gt; SSIS: Retorna ID_PERIODO</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_desempenho_docente_de","title":"FACT_DESEMPENHO_DOCENTE_DE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-08-archivos-manuales","title":"Componente <code>Tarea EP-EPT-08 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_37","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-08 es un componente de tipo <code>Execute Process Task</code> que ejecuta un script de Python para descargar datos necesarios en el flujo de trabajo del paquete SSIS. El script se ejecuta utilizando un entorno virtual Python previamente configurado.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_4","title":"Propiedades del Componente","text":"<ul> <li>Ruta del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos: <code>download.py --key EPEPT08</code></li> <li>Directorio de trabajo:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_22","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT08`\n    Python -&gt;&gt; Python: Descarga datos\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_desempenho_docente_de","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE_DE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_38","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_DESEMPENHO_DOCENTE_DE es responsable de la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de los datos de evaluaci\u00f3n de desempe\u00f1o docente en la base de datos destino <code>Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE</code>. Incluye transformaciones para derivar columnas, realizar b\u00fasquedas en tablas relacionadas y cargar los datos procesados en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_11","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source (EP-EPT-08) </p> <ul> <li>Descripci\u00f3n: Extrae datos de una hoja de c\u00e1lculo Excel denominada <code>Sheet1$</code>.</li> <li>Propiedades:  <ul> <li>Nombre de la tabla u objeto: <code>Sheet1$</code>.  </li> <li>Conexi\u00f3n: Administrador de conexiones Excel 18.  </li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas </p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas como <code>_PERIODO_ACADEMICO</code>, <code>_ID_FECHA</code>, y <code>_ID_UNIDAD</code> a partir de las columnas de entrada.  </li> <li>Propiedades de las columnas derivadas:  <ul> <li><code>_PERIODO_ACADEMICO</code>: Convierte <code>PERIODO_ACADEMICO</code> a <code>DT_WSTR</code> (40).  </li> <li><code>_ID_FECHA</code>: Calcula un identificador num\u00e9rico basado en <code>FECHA</code>.  </li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO </p> <ul> <li>Descripci\u00f3n: Busca el identificador de per\u00edodo acad\u00e9mico en la tabla <code>DIM_PERIODO_ACADEMICO</code>.  </li> <li>Propiedades:  <ul> <li>Consulta SQL: <code>SELECT * FROM DIM_PERIODO_ACADEMICO</code>.  </li> </ul> </li> </ul> </li> <li> <p>Lookup 1 </p> <ul> <li>Descripci\u00f3n: Compara los datos actuales con los registros en <code>FACT_DESEMPENHO_DOCENTE_DE</code> para verificar duplicados.  </li> <li>Propiedades:  <ul> <li>Condici\u00f3n de b\u00fasqueda: Coincide con <code>NOMBRE_DOCENTE</code>, <code>PROGRAMA</code>, <code>ID_FECHA</code>, entre otros campos.  </li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET </p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en <code>FACT_DESEMPENHO_DOCENTE_DE</code>.  </li> <li>Propiedades:  <ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_DESEMPENHO_DOCENTE_DE\"</code>.  </li> <li>Inserci\u00f3n masiva habilitada.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_23","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Excel Source\n    participant Transform as Transformar Columnas\n    participant LookupPeriodo as Lookup ID_PERIODO\n    participant LookupFact as Lookup FACT_DESEMPENHO_DOCENTE_DE\n    participant ADO as Destino de ADO NET\n\n    Excel -&gt;&gt; Transform: Enviar datos\n    Transform -&gt;&gt; LookupPeriodo: Buscar ID_PERIODO\n    LookupPeriodo -&gt;&gt; LookupFact: Validar duplicados\n    LookupFact -&gt;&gt; ADO: Insertar nuevos registros</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_desempenho_docente_ce","title":"FACT_DESEMPENHO_DOCENTE_CE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_desempenho_docente_ce","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE_CE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_39","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EDF-09 (archivos manuales) ejecuta un proceso externo para descargar datos de evaluaci\u00f3n del desempe\u00f1o docente utilizando un script en Python. Este componente forma parte de la soluci\u00f3n ETL dise\u00f1ada para integrar datos en el sistema.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_5","title":"Propiedades del Componente","text":"<ol> <li>Descripci\u00f3n: Ejecuta un script de Python que descarga datos necesarios para el proceso ETL.</li> <li>Script Python: <code>download.py</code></li> <li>Argumentos: <code>--key EPEDF09</code></li> <li>Ejecutable:    Ruta del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Directorio de Trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_24","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEDF09`\n    Python -&gt;&gt; Python: Descarga datos para FACT_DESEMPENHO_DOCENTE_CE\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_desempenho_docente_ce_1","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE_CE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_40","title":"Descripci\u00f3n General","text":"<p>Este componente Procesar FACT_DESEMPENHO_DOCENTE_CE realiza la integraci\u00f3n y transformaci\u00f3n de datos para evaluar el desempe\u00f1o docente centralizado. Se utiliza una combinaci\u00f3n de fuentes de datos Excel, transformaciones derivadas, b\u00fasquedas (lookups) y carga de datos a un destino compatible con ADO.NET en una base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_12","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente Excel (EP-EDF-09):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel que contiene la informaci\u00f3n inicial de desempe\u00f1o docente.</li> <li>Propiedades:<ul> <li>Tabla o rango: <code>Sheet1$</code></li> <li>Columnas principales: <code>ID_UNIDAD</code>, <code>PERIODO_ACADEMICO</code>, <code>NOMBRE_DOCENTE</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Columnas:</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas o ajusta valores en las existentes.</li> <li>Propiedades:<ul> <li>Ejemplo: Convierte <code>PERIODO_ACADEMICO</code> a una columna derivada <code>_PERIODO_ACADEMICO</code>.</li> <li>Ajusta <code>ID_UNIDAD</code> de <code>wstr</code> a <code>i4</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO:</p> <ul> <li>Descripci\u00f3n: Busca informaci\u00f3n del periodo acad\u00e9mico desde la tabla <code>DIM_PERIODO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Modo de b\u00fasqueda: Exact Match.</li> <li>Columna unida: <code>PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup Principal:</p> <ul> <li>Descripci\u00f3n: Relaciona datos adicionales desde <code>FACT_DESEMPENHO_DOCENTE_CE</code>.</li> <li>Propiedades:<ul> <li>Criterios: <code>ID_UNIDAD</code>, <code>NOMBRE_DOCENTE</code>, <code>ID_PERIODO</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_DESEMPENHO_DOCENTE_CE</code>.</li> <li>Propiedades:<ul> <li>Nombre de tabla: <code>\"Cedesarrollo\".\"FACT_DESEMPENHO_DOCENTE_CE\"</code></li> <li>Tama\u00f1o de lote: <code>0</code> (predeterminado).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_25","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Fuente Excel) --&gt; B(Transformar Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Lookup Principal)\n    D --&gt; E(Destino ADO.NET)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_asistencia_act_bienestar","title":"FACT_ASISTENCIA_ACT_BIENESTAR","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-11-archivos-manuales","title":"Componente <code>Tarea EP-EPT-11 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_41","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-11 (archivos manuales) ejecuta un script en Python que descarga los datos necesarios para alimentar el flujo de datos del paquete. Este proceso es fundamental para asegurar que los archivos requeridos est\u00e9n disponibles en el entorno de trabajo antes de procesar la informaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-la-tarea_1","title":"Propiedades de la Tarea","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python para descargar archivos manuales asociados al flujo de datos.</li> <li>Propiedades Configuradas:<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>download.py --key EPEPT11</code></li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#funcionamiento","title":"Funcionamiento","text":"<ol> <li>El script se ejecuta usando el int\u00e9rprete de Python configurado en el entorno virtual localizado en el directorio <code>env</code>.</li> <li>Descarga el archivo identificado por la clave <code>EPEPT11</code> mediante el comando <code>download.py</code>.</li> <li>Al completarse, los datos quedan disponibles en el directorio de trabajo especificado.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_26","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT11`\n    Python -&gt;&gt; Python: Descarga datos para archivos manuales\n    Python -&gt;&gt; SSIS: Reporta \u00e9xito o error</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_asistencia_act_bienestar","title":"Componente <code>Procesar FACT_ASISTENCIA_ACT_BIENESTAR</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_42","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_ASISTENCIA_ACT_BIENESTAR integra, transforma y carga informaci\u00f3n relacionada con la asistencia a actividades de bienestar. Este proceso incluye extracciones desde Excel, transformaciones de columnas, b\u00fasquedas en tablas auxiliares y la carga final de los datos en la tabla destino de SQL Server.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_13","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente Excel (EP-EPT-11):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel con informaci\u00f3n inicial de asistencia.</li> <li>Propiedades:<ul> <li>Tabla o rango: <code>Sheet1$</code></li> <li>Columnas principales: <code>PERIODO_ACADEMICO</code>, <code>DOCUMENTO</code>, <code>FECHA</code>, <code>ACTIVIDAD</code>, <code>ASISTIO</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Columnas:</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas y realiza conversiones de formato.</li> <li>Propiedades:<ul> <li>Convierte <code>FECHA</code> a formato <code>date</code> y deriva <code>ID_FECHA</code>.</li> <li>Ajusta los tipos de datos para <code>DOCUMENTO</code> y <code>TIPO_DOCUMENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO:</p> <ul> <li>Descripci\u00f3n: Busca el ID del periodo acad\u00e9mico en la tabla <code>DIM_PERIODO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Columna de uni\u00f3n: <code>PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_ESTUDIANTE:</p> <ul> <li>Descripci\u00f3n: Encuentra el ID del estudiante utilizando el documento de identificaci\u00f3n desde la tabla <code>DIM_ESTUDIANTES</code>.</li> <li>Propiedades:<ul> <li>Columna de uni\u00f3n: <code>DOCUMENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_ASISTENCIA_ACT_BIENESTAR:</p> <ul> <li>Descripci\u00f3n: Verifica duplicados en la tabla destino antes de la carga.</li> <li>Propiedades:<ul> <li>Criterios: <code>ID_FECHA</code>, <code>ID_PERIODO</code>, <code>ID_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_ASISTENCIA_ACT_BIENESTAR</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_ASISTENCIA_ACT_BIENESTAR\"</code>.</li> <li>Tama\u00f1o de lote: <code>0</code> (predeterminado).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_27","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Fuente Excel) --&gt; B(Transformar Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Lookup ID_ESTUDIANTE)\n    D --&gt; E(Lookup FACT_ASISTENCIA_ACT_BIENESTAR)\n    E --&gt; F(Destino ADO.NET)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_evaluacion_plan_curricular","title":"FACT_EVALUACION_PLAN_CURRICULAR","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-09-archivos-manuales","title":"Componente <code>Tarea EP-EPT-09 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_43","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-09 (archivos manuales) es una tarea de proceso que ejecuta un script en Python para descargar los archivos necesarios relacionados con la evaluaci\u00f3n del plan curricular. Este paso es crucial para garantizar que los datos requeridos est\u00e9n disponibles antes de procesar la informaci\u00f3n en el flujo de datos del paquete.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-la-tarea_2","title":"Propiedades de la Tarea","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python para descargar archivos relacionados con el plan curricular.</li> <li>Propiedades Configuradas:<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>download.py --key EPEPT09</code></li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#funcionamiento_1","title":"Funcionamiento","text":"<ol> <li>El script <code>download.py</code> se ejecuta a trav\u00e9s del int\u00e9rprete de Python especificado en el entorno virtual.</li> <li>Usa el argumento <code>--key EPEPT09</code> para identificar los datos a descargar.</li> <li>Los archivos descargados se almacenan en el directorio de trabajo configurado, asegurando la disponibilidad para las siguientes etapas del flujo.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_28","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT09`\n    Python -&gt;&gt; Python: Descarga datos relacionados con EPEPT09\n    Python -&gt;&gt; SSIS: Reporta \u00e9xito o error</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_evaluacion_plan_curricular","title":"Componente <code>Procesar FACT_EVALUACION_PLAN_CURRICULAR</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_44","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_EVALUACION_PLAN_CURRICULAR es una tarea de flujo de datos en un paquete SSIS que se encarga de extraer datos desde un archivo Excel, transformar las columnas necesarias y cargar la informaci\u00f3n procesada en una tabla en la base de datos. Este proceso incluye pasos de b\u00fasqueda y transformaci\u00f3n para asegurar la consistencia de los datos y su adecuaci\u00f3n para an\u00e1lisis posteriores.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_14","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source (EP-EPT-09) </p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (hoja <code>Sheet1$</code>) relacionado con la evaluaci\u00f3n del plan curricular.</li> <li>Propiedades:<ul> <li>Archivo de Origen: Conexi\u00f3n OLE DB configurada para Excel.</li> <li>Columnas Extra\u00eddas:</li> <li><code>ID_UNIDAD</code></li> <li><code>UNIDAD</code></li> <li><code>PERIODO_ACADEMICO</code></li> <li><code>CALIFICACION</code></li> <li><code>OBSERVACIONES</code></li> </ul> </li> <li>Conexi\u00f3n: Administrador de conexiones de Excel 21.</li> </ul> </li> <li> <p>Derived Column (Transformar Columnas) </p> <ul> <li>Descripci\u00f3n: Aplica transformaciones a las columnas de entrada, generando nuevas columnas derivadas.</li> <li>Columnas Derivadas:<ul> <li><code>_PERIODO_ACADEMICO</code>: Transformaci\u00f3n de <code>PERIODO_ACADEMICO</code> para formato interno.</li> <li><code>_ID_UNIDAD</code>: Conversi\u00f3n de <code>ID_UNIDAD</code> a entero.</li> <li><code>_UNIDAD</code>, <code>_CALIFICACION</code>, <code>_OBSERVACIONES</code>: Procesadas para asegurar consistencia.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO </p> <ul> <li>Descripci\u00f3n: Busca informaci\u00f3n adicional en la tabla <code>[Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code> relacionada con el per\u00edodo acad\u00e9mico.</li> <li>Propiedades:<ul> <li>SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code>.</li> <li>Columna de uni\u00f3n: <code>_PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_EVALUACION_PLAN_CURRICULAR </p> <ul> <li>Descripci\u00f3n: Valida si los datos ya existen en la tabla <code>[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]</code> para evitar duplicados.</li> <li>Propiedades:<ul> <li>SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR] WHERE [ID_UNIDAD] = ? AND [ID_PERIODO] = ?</code>.</li> </ul> </li> </ul> </li> <li> <p>ADO.NET Destination (Guardar FACT_EVALUACION_PLAN_CURRICULAR) </p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados y validados en la tabla <code>[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Cedesarrollo\".\"FACT_EVALUACION_PLAN_CURRICULAR\"</code>.</li> <li>Batch Size: 0 (usa tama\u00f1o predeterminado).</li> <li>Modo de inserci\u00f3n: Bulk Insert para mejor rendimiento.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_29","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(EP-EPT-09: Extraer Excel) --&gt; B(Transformar Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Lookup FACT_EVALUACION_PLAN_CURRICULAR)\n    D --&gt; E(Guardar FACT_EVALUACION_PLAN_CURRICULAR)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_evaluacion_formacion","title":"FACT_EVALUACION_FORMACION","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-10-archivos-manuales","title":"Componente <code>Tarea EP-EPT-10 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_45","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EPT-10 (archivos manuales) ejecuta un proceso externo utilizando un script de Python para descargar datos relacionados con la evaluaci\u00f3n de formaci\u00f3n. La tarea es parte de un paquete SSIS y est\u00e1 configurada para garantizar que los datos se procesen correctamente antes de ser utilizados en el flujo de datos del paquete.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_15","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Execute Process Task (EP-EPT-10) </p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python ubicado en el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Propiedades:<ul> <li>Executable: Ruta del ejecutable de Python configurado mediante una variable de proyecto (<code>@[$Project::Python_Executable]</code>).</li> <li>Argumentos: <code>download.py --key EPEPT10</code>.</li> <li>Directorio de Trabajo: <code>\\\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> </ul> </li> <li>Prop\u00f3sito:<ul> <li>Descargar datos necesarios para el proceso de evaluaci\u00f3n de formaci\u00f3n.</li> <li>Asegurar que los archivos est\u00e1n actualizados antes de continuar con las siguientes tareas en el flujo de datos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_30","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Inicia Tarea EP-EPT-10) --&gt; B(Ejecuta Python Script)\n    B --&gt; C(Descarga datos)\n    C --&gt; D(Contin\u00faa flujo SSIS)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_evaluacion_formacion_1","title":"Componente <code>Procesar FACT_EVALUACION_FORMACION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_46","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_EVALUACION_FORMACION es una tarea de flujo de datos en un paquete SSIS. Su objetivo principal es extraer datos desde un archivo Excel, transformarlos y realizar un Lookup en la base de datos antes de cargar los datos en la tabla destino <code>Cedesarrollo.FACT_EVALUACION_FORMACION</code>. </p> <p>Este proceso incluye tareas de transformaci\u00f3n de columnas, validaci\u00f3n de datos y manejo de errores para garantizar la calidad y coherencia de la informaci\u00f3n cargada.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_16","title":"Componentes del Flujo de Datos","text":"<p>1. Excel Source (EP-EPT-10)     - Descripci\u00f3n: Extrae datos de un archivo Excel ubicado en un directorio espec\u00edfico.     - Propiedades:         - Hoja de trabajo: <code>Sheet1$</code>.         - Conexi\u00f3n: Administrador de conexiones configurado para Excel (<code>Administrador de conexiones con Excel 22</code>).  </p> <p>2. Derived Column Transformation     - Descripci\u00f3n: Realiza transformaciones en los datos extra\u00eddos, generando nuevas columnas derivadas o modificando las existentes.     - Propiedades principales:         - Transformaci\u00f3n de datos como <code>TIPO_DOCUMENTO_ENCUESTADO</code>, <code>DOCUMENTO_ENCUESTADO</code>, y columnas de evaluaci\u00f3n (<code>ASPECTO_1</code> a <code>ASPECTO_9</code>).  </p> <p>3. Lookup Transformation     - Descripci\u00f3n: Realiza una b\u00fasqueda de datos en la tabla <code>FACT_EVALUACION_FORMACION</code> para validar y complementar la informaci\u00f3n procesada.     - Propiedades principales:         - SQL de referencia: <pre><code>SELECT * \nFROM Cedesarrollo.FACT_EVALUACION_FORMACION\nWHERE DOCUMENTO_ENCUESTADO = ? \n    AND ID_TARIFA = ?\n</code></pre>         - Manejo de filas sin coincidencia: Env\u00eda las filas al destino final para carga.  </p> <p>4. Destino ADO.NET     - Descripci\u00f3n: Carga los datos procesados en la tabla <code>Cedesarrollo.FACT_EVALUACION_FORMACION</code>.     - Propiedades principales:         - Nombre de la tabla: <code>\"Cedesarrollo\".\"FACT_EVALUACION_FORMACION\"</code>.         - Inserci\u00f3n masiva: Activada para optimizar el rendimiento.  </p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_31","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant Derived as Derived Columns\n    participant Lookup as Lookup Table\n    participant ADO as ADO.NET Destination\n\n    SSIS -&gt;&gt; Excel: Extrae datos de archivo\n    Excel -&gt;&gt; Derived: Transforma columnas\n    Derived -&gt;&gt; Lookup: Busca datos existentes\n    Lookup -&gt;&gt; ADO: Env\u00eda filas sin coincidencia\n    ADO -&gt;&gt; SSIS: Finaliza carga de datos</code></pre> <pre><code>graph TD\n    A(Inicio) --&gt; B(Excel Source: EP-EPT-10)\n    B --&gt; C(Transformar Columnas)\n    C --&gt; D(Lookup Transformation)\n    D --&gt; E(Destino ADO.NET)\n    E --&gt; F(Finalizaci\u00f3n)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_cotizaciones","title":"FACT_COTIZACIONES","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-tarea-am-dre-05-archivos-manuales","title":"Componente <code>Procesar Tarea AM-DRE-05 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_47","title":"Descripci\u00f3n General","text":"<p>Esta tarea ejecuta un script Python para descargar datos necesarios para el proceso de integraci\u00f3n de <code>FACT_COTIZACIONES</code>. El script se ejecuta desde un entorno virtual configurado en el proyecto y utiliza una clave espec\u00edfica <code>AMDRE05</code> para identificar los datos que se deben procesar.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo_1","title":"Componentes del Flujo","text":"<p>1. Tarea de Ejecuci\u00f3n de Proceso: AM-DRE-05     - Descripci\u00f3n: Ejecuta el script Python <code>download.py</code> para obtener los datos relevantes.     - Propiedades:         - Ejecutable: <code>python.exe</code> ubicado en el entorno virtual configurado.         - Directorio de Trabajo: <code>\\\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.         - Argumentos del Script: <code>download.py --key AMDRE05</code>.  </p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-ejecucion","title":"Diagrama de Ejecuci\u00f3n","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key AMDRE05`\n    Python -&gt;&gt; Python: Descarga datos de cotizaciones\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-fact_cotizacion","title":"Componente <code>Tarea fact_cotizacion</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_48","title":"Descripci\u00f3n General","text":"<p>La tarea fact_cotizacion es un componente de tipo Execute Process Task en SSIS que se encarga de ejecutar un proceso externo mediante un script de Python. En este caso, se ejecuta el script <code>fact_cotizacion.py</code>, el cual se utiliza para procesar y consolidar informaci\u00f3n relacionada con las cotizaciones. La tarea se configura utilizando variables de proyecto para definir la ruta del ejecutable de Python y el directorio de trabajo.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_6","title":"Propiedades del Componente","text":"<ul> <li>Tipo de Tarea: Execute Process Task  </li> <li>Ejecutable:   Se utiliza la variable de proyecto <code>@[$Project::Python_Executable]</code>, que apunta a la ruta del ejecutable de Python.  </li> <li>Argumentos: <code>fact_cotizacion.py</code></li> <li>Directorio de Trabajo:   Se configura con la variable de proyecto <code>@[$Project::Working_Directory]</code> concatenada con el path <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> <li>Ruta F\u00edsica (ejemplo): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Propiedades Adicionales:  <ul> <li>Filtro de registro: <code>FilterKind=0</code> </li> <li>ThreadHint: <code>0</code> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_32","title":"Diagrama de Secuencia","text":"<p>El siguiente diagrama de secuencia ilustra el proceso que se ejecuta en esta tarea:</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta fact_cotizacion.py\n    Python -&gt;&gt; Python: Procesa y consolida datos de cotizaciones\n    Python -&gt;&gt; SSIS: Retorna resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_cotizaciones","title":"Componente <code>Procesar FACT_COTIZACIONES</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_49","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_COTIZACIONES representa una tarea de flujo de datos en SSIS dise\u00f1ada para extraer, transformar y cargar informaci\u00f3n de cotizaciones desde un archivo Excel hacia una base de datos. Este proceso incluye transformaciones derivadas, operaciones de b\u00fasqueda, combinaciones de datos y ordenamientos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-de-los-componentes-del-flujo-de-datos","title":"Detalles de los Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos: Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae los datos de un archivo Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0 (tiempo de espera infinito).</li> <li><code>OpenRowset</code>: Sheet1$.</li> <li><code>AccessMode</code>: 0 (modo de acceso por defecto).</li> </ul> </li> <li>Conexi\u00f3n:<ul> <li><code>ConnectionManager</code>: Administrador de conexiones con Excel 23.</li> </ul> </li> <li>Salidas:<ul> <li>Columnas: FECHA_REGISTRO, NOMBRE, DOCUMENTO, TIPO_DOCUMENTO, ESTADO_COTIZACION, PREGUNTA, RESPUESTA.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Derived Column (Transformar Columnas)</p> <ul> <li>Descripci\u00f3n: Crea columnas derivadas mediante expresiones.</li> <li>Propiedades:<ul> <li>Ejemplo: Generaci\u00f3n de <code>_ID_FECHA</code> reemplazando caracteres en <code>FECHA_REGISTRO</code>.</li> </ul> </li> <li>Columnas Derivadas:<ul> <li><code>_ID_FECHA</code>, <code>_DOCUMENTO</code>, <code>_TIPO_DOCUMENTO</code>, <code>_NOMBRE</code>, <code>_EST_COTIZACION</code>, <code>_PREGUNTA</code>, <code>_RESPUESTA</code>, <code>_FECHA_REGISTRO</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Lookup (ID_ESTUDIANTE)</p> <ul> <li>Descripci\u00f3n: Busca datos en la tabla <code>DIM_ESTUDIANTES</code>.</li> <li>Propiedades:<ul> <li>SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code>.</li> <li>Comportamiento: Ignorar fallos de coincidencia.</li> </ul> </li> <li>Entradas:<ul> <li><code>_DOCUMENTO</code>.</li> </ul> </li> <li>Salidas:<ul> <li>Coincidencias: <code>ID_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Sort</p> <ul> <li>Descripci\u00f3n: Ordena los datos de entrada en orden ascendente por columnas espec\u00edficas.</li> <li>Propiedades:<ul> <li><code>MaximumThreads</code>: -1 (uso autom\u00e1tico de hilos).</li> </ul> </li> <li>Columnas Ordenadas:<ul> <li><code>PREGUNTA</code>, <code>_PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Merge Join</p> <ul> <li>Descripci\u00f3n: Combina dos flujos de datos ordenados mediante un Join INNER.</li> <li>Propiedades:<ul> <li><code>JoinType</code>: INNER JOIN.</li> </ul> </li> <li>Entradas:<ul> <li>Izquierda: Datos ordenados por <code>PREGUNTA</code>.</li> <li>Derecha: Datos ordenados por <code>_PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos: ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos combinados en la tabla <code>FACT_COTIZACIONES</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Cedesarrollo\".\"FACT_COTIZACIONES\"</code>.</li> <li><code>BatchSize</code>: 0.</li> </ul> </li> <li>Entradas:<ul> <li>Columnas transformadas y combinadas.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_33","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Database\n\n    SSIS -&gt;&gt; Excel: Extrae datos de Sheet1$\n    SSIS -&gt;&gt; SSIS: Realiza transformaci\u00f3n derivada\n    SSIS -&gt;&gt; SQL: Realiza Lookup ID_ESTUDIANTE\n    SSIS -&gt;&gt; SSIS: Ordena datos\n    SSIS -&gt;&gt; SSIS: Combina flujos (Merge Join)\n    SSIS -&gt;&gt; SQL: Carga datos en FACT_COTIZACIONES</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#restaurar-llaves-foraneas-esquema-cedesarrollo","title":"Restaurar llaves foraneas esquema Cedesarrollo","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#documentacion-xml-del-componente-restaurar-llaves-foraneas-esquema-cedesarrollo","title":"Documentaci\u00f3n XML del Componente \"Restaurar llaves for\u00e1neas esquema Cedesarrollo\"","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_50","title":"Descripci\u00f3n General","text":"<p>El componente Restaurar llaves for\u00e1neas esquema Cedesarrollo es una tarea de ejecuci\u00f3n de SQL en SSIS que se utiliza para restaurar las restricciones de clave for\u00e1nea dentro del esquema <code>Cedesarrollo</code>. Adem\u00e1s, este proceso limpia la tabla temporal <code>ForeignKeys_Cedesarrollo</code> al final de la ejecuci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-componente_2","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar SQL</p> <ul> <li>Descripci\u00f3n: Ejecuta un script SQL que reconstruye las claves for\u00e1neas en el esquema <code>Cedesarrollo</code>.</li> <li>Conexi\u00f3n:</li> <li><code>ConnectionManagerID</code>: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code> (Conexi\u00f3n al servidor SQL donde se encuentra el esquema <code>Cedesarrollo</code>).</li> <li>Propiedades:</li> <li><code>SqlStatementSource</code>: Contiene el siguiente script SQL:</li> </ul> <pre><code>-- Restaurar restricciones de clave for\u00e1nea para el esquema Cedesarrollo\nDECLARE @restoreSql_Cedesarrollo NVARCHAR(MAX) = '';\n\nSELECT @restoreSql_Cedesarrollo += 'ALTER TABLE ' + QUOTENAME('Cedesarrollo') + '.' + QUOTENAME(fk.TableName) \n    + ' ADD CONSTRAINT ' + QUOTENAME(fk.ConstraintName) \n    + ' FOREIGN KEY (' + QUOTENAME(fk.ColumnName) + ') REFERENCES ' \n    + QUOTENAME(\n        CASE \n            WHEN fk.ReferencedTableName IN ('DIM_AFILIADOS', 'DIM_APORTANTE_NOAFILIADO', 'DIM_BENEFICIARIOS', 'DIM_CAPACIDAD_FISICA', 'DIM_CATEGORIA', 'DIM_CUENTA_CONTABLE', 'DIM_EMPRESAS', 'DIM_INFRAESTRUCTURA_CCF', 'DIM_PERSONAL', 'DIM_SEDES', 'DIM_TARIFAS_SERVICIOS', 'DIM_UNIDAD', 'DIM_UNIDADES_ORGANIZATIVAS')\n            THEN 'Transversal'\n            WHEN fk.ReferencedTableName = 'DIM_TIEMPO' \n            THEN 'Dwh' \n            ELSE 'Cedesarrollo'\n        END\n    ) + '.' + QUOTENAME(fk.ReferencedTableName) \n    + '(' + QUOTENAME(fk.ReferencedColumnName) + '); '\nFROM dbo.ForeignKeys_Cedesarrollo;\n\n-- Ejecutamos el SQL para restaurar las llaves for\u00e1neas del esquema Cedesarrollo\nEXEC sp_executesql @restoreSql_Cedesarrollo;\n\n-- Limpiar la tabla persistente\nDROP TABLE dbo.ForeignKeys_Cedesarrollo;\n</code></pre> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_34","title":"Diagrama de Secuencia","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-del-proceso","title":"Descripci\u00f3n del Proceso","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS -&gt;&gt; SQL: Declara variable @restoreSql_Cedesarrollo\n    SQL -&gt;&gt; SQL: Construye sentencias ALTER TABLE din\u00e1micamente\n    SQL -&gt;&gt; SQL: Ejecuta las sentencias con sp_executesql\n    SQL -&gt;&gt; SQL: Elimina la tabla temporal ForeignKeys_Cedesarrollo</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/","title":"07. PROTECCION_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#proteccion_dimensiones","title":"PROTECCION_DIMENSIONES","text":"<p>El paquete SSIS \"07-PROTECCION_DIMENSIONES\" est\u00e1 dise\u00f1ado para gestionar flujos ETL que procesan datos cr\u00edticos relacionados con dimensiones de protecci\u00f3n, como preguntas y respuestas educativas, caracter\u00edsticas de campos y establecimientos educativos. Este paquete asegura un flujo de trabajo eficiente, consolidando datos desde m\u00faltiples fuentes y garantizando su integridad en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es transformar y cargar datos clave para dimensiones educativas y de protecci\u00f3n social. Esto incluye validar informaci\u00f3n de campos, programas y encuestas, asegurando que los datos consolidados sean precisos, consistentes y preparados para an\u00e1lisis estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes utilizadas:<ul> <li>Archivos Excel: Informaci\u00f3n sobre preguntas, respuestas, programas y caracter\u00edsticas de campos.</li> <li>Bases de Datos: Validaci\u00f3n de registros en tablas maestras como <code>DIM_PROGRAMA</code>, <code>DIM_PREGUNTAS_EE_JEC</code> y <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>.</li> </ul> </li> <li>Conexiones configuradas:<ul> <li>Administradores OLE DB y ADO.NET.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad de tipos entre columnas de entrada y destino.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Garantiza consistencia mediante b\u00fasquedas en tablas maestras.</li> </ul> </li> <li>Clasificaci\u00f3n (<code>Conditional Split</code>):<ul> <li>Filtra registros v\u00e1lidos y redirige no v\u00e1lidos.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas destino:<ul> <li><code>DIM_CAMPOS_CARACT</code></li> <li><code>DIM_PROGRAMA</code></li> <li><code>DIM_PREGUNTAS_EE_JEC</code></li> <li><code>DIM_RESPUESTAS_EE_JEC</code></li> <li><code>DIM_ESTABLECIMIENTO_EDUCATIVO</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para optimizar la carga.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Integraci\u00f3n de scripts Python para automatizar descargas desde SharePoint y procesar datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_CAMPOS_CARACT:</p> <ul> <li><code>ID_CARACTERISTICA</code>: Identificador \u00fanico.</li> <li><code>PREGUNTA</code>: Texto de la pregunta.</li> <li><code>OBSERVACIONES</code>: Informaci\u00f3n adicional.</li> </ul> </li> <li> <p>DIM_PROGRAMA:</p> <ul> <li><code>ID_PROGRAMA</code>: Identificador del programa.</li> <li><code>NOMBRE_PROGRAMA</code>: Descripci\u00f3n del programa.</li> </ul> </li> <li> <p>DIM_PREGUNTAS_EE_JEC:</p> <ul> <li><code>ID_PREGUNTA</code>: Identificador \u00fanico.</li> <li><code>PREGUNTA</code>: Texto de la pregunta.</li> <li><code>ID_PROGRAMA</code>: Relaci\u00f3n con el programa.</li> </ul> </li> <li> <p>DIM_RESPUESTAS_EE_JEC:</p> <ul> <li><code>ID_RESPUESTA</code>: Identificador \u00fanico.</li> <li><code>RESPUESTA</code>: Texto de la respuesta.</li> <li><code>ID_PREGUNTA</code>: Relaci\u00f3n con la pregunta.</li> </ul> </li> <li> <p>DIM_ESTABLECIMIENTO_EDUCATIVO:</p> <ul> <li><code>ID_ESTABLECIMIENTO</code>: Identificador \u00fanico.</li> <li><code>NOMBRE_ESTABLECIMIENTO</code>: Nombre del establecimiento.</li> <li><code>REPRESENTANTE_LEGAL</code>: Persona responsable.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos (Data Flow Diagram - DFD)</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Fuente de Excel\n    participant DB as Base de Datos\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; Excel: Extraer datos de campos, programas y preguntas\n    SSIS -&gt;&gt; DB: Validar registros en tablas maestras\n    SSIS -&gt;&gt; Python: Ejecutar scripts para extracci\u00f3n desde SharePoint\n    SSIS -&gt;&gt; DWH: Cargar datos procesados en tablas destino</code></pre> <ol> <li>Diagrama de Transformaciones y Validaciones</li> </ol> <pre><code>graph TD\n    A1[Datos de Campos y Programas] --&gt; T1[Conversi\u00f3n de Datos]\n    A2[Preguntas y Respuestas] --&gt; T2[Lookup: Validar Preguntas]\n    T1 --&gt; T3[Clasificaci\u00f3n por Condicional Split]\n    T2 --&gt; L1[Lookup: Validar Respuestas]\n    T3 --&gt; C1[Cargar datos validados]</code></pre> <ol> <li>Diagrama ER para Tablas de Dimensiones</li> </ol> <pre><code>erDiagram\n    DIM_CAMPOS_CARACT {\n        int ID_CARACTERISTICA\n        string PREGUNTA\n        string OBSERVACIONES\n    }\n    DIM_PROGRAMA {\n        int ID_PROGRAMA\n        string NOMBRE_PROGRAMA\n    }\n    DIM_PREGUNTAS_EE_JEC {\n        int ID_PREGUNTA\n        string PREGUNTA\n        int ID_PROGRAMA\n    }\n    DIM_RESPUESTAS_EE_JEC {\n        int ID_RESPUESTA\n        string RESPUESTA\n        int ID_PREGUNTA\n    }\n    DIM_ESTABLECIMIENTO_EDUCATIVO {\n        int ID_ESTABLECIMIENTO\n        string NOMBRE_ESTABLECIMIENTO\n        string REPRESENTANTE_LEGAL\n    }\n    DIM_PROGRAMA ||--|| DIM_PREGUNTAS_EE_JEC : \"Asociado a programas\"\n    DIM_PREGUNTAS_EE_JEC ||--|| DIM_RESPUESTAS_EE_JEC : \"Relaci\u00f3n Pregunta-Respuesta\"\n    DIM_ESTABLECIMIENTO_EDUCATIVO ||--|| DIM_PROGRAMA : \"Conexi\u00f3n con programas\"</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-ejecucion-etls","title":"Componente <code>Ejecuci\u00f3n ETLs</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Este componente ejecuta un proceso Python encargado de la conexi\u00f3n y extracci\u00f3n de datos desde SharePoint para la carpeta espec\u00edfica <code>Protecci\u00f3n</code>, ubicada dentro de la estructura de archivos del proyecto. Es parte del flujo de automatizaci\u00f3n de ETL en un paquete de SSIS.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ul> <li> <p>Descripci\u00f3n: Este componente utiliza una tarea de tipo <code>Execute Process Task</code> en SSIS para invocar un script Python que se encuentra dentro del entorno virtual configurado para el proyecto.</p> </li> <li> <p>Propiedades:</p> <ul> <li> <p>Executable:      <pre><code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"\n</code></pre>     Especifica la ruta al ejecutable de Python dentro del entorno virtual del proyecto.</p> </li> <li> <p>WorkingDirectory:     <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\03.Proteccion\"\n</code></pre>     Define el directorio de trabajo donde se encuentra el script Python.</p> </li> <li> <p>Arguments:      <pre><code>SharePoint_Connection_Proteccion.py\n</code></pre>     Indica el script que ser\u00e1 ejecutado para conectar y procesar los datos de SharePoint.</p> </li> <li> <p>TimeOut:     <pre><code>@[$Project::Tiempo_Espera_Segundos]\n</code></pre>     Configura el tiempo m\u00e1ximo de espera en segundos para que el proceso se complete, definido en 600 segundos (10 minutos).</p> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo-del-proceso","title":"Diagrama de Flujo del Proceso","text":"<p>El siguiente diagrama ilustra el flujo de ejecuci\u00f3n para el componente Ejecuci\u00f3n ETLs:</p> <pre><code>graph TD\n    A[Inicio del proceso] --&gt; B[Obtener ruta del ejecutable Python]\n    B --&gt; C[Definir directorio de trabajo]\n    C --&gt; D[Ejecutar script SharePoint_Connection_Proteccion.py]\n    D --&gt; E[Esperar a la finalizaci\u00f3n del proceso Timeout: 600 seg]\n    E --&gt; F[\u00bfProceso completado exitosamente?]\n    F --&gt; G[Registrar \u00e9xito en logs]:::success\n    F --&gt; H[Registrar error y abortar]:::error\n    G --&gt; I[Fin del proceso]\n    H --&gt; I</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_campos_caract","title":"Componente <code>Data DIM_CAMPOS_CARACT</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_CAMPOS_CARACT forma parte de un flujo ETL desarrollado en SSIS para cargar y transformar datos relacionados con las caracter\u00edsticas de campos en la tabla <code>DIM_CAMPOS_CARACT</code> dentro del esquema <code>Protecci\u00f3n</code>. Este proceso incluye la lectura de datos desde un archivo Excel, conversi\u00f3n de datos, validaci\u00f3n mediante un componente de tipo Lookup, y finalmente, la carga en la base de datos de destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Conecta y extrae datos desde una hoja llamada <code>Sheet1$</code> en un archivo Excel, con columnas <code>PREGUNTA</code> y <code>OBSERVACIONES</code>.</li> <li>Propiedades:<ul> <li>AccessMode: 0 (por tabla u objeto).</li> <li>Hoja seleccionada: <code>Sheet1$</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Convierte los datos extra\u00eddos a un formato compatible con los siguientes componentes del flujo.</li> <li>Columnas Convertidas:<ul> <li><code>PREGUNTA</code> \u2192 <code>Copy of PREGUNTA</code>.</li> <li><code>OBSERVACIONES</code> \u2192 <code>Copy of OBSERVACIONES</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida y enriquece los datos mediante la b\u00fasqueda de correspondencias en la tabla destino <code>DIM_CAMPOS_CARACT</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_CAMPOS_CARACT]\nWHERE [PREGUNTA] = ?\n</code></pre></li> <li>Columnas Salida:<ul> <li><code>PREGUNTA_</code>.</li> <li><code>OBSERVACIONES_</code>.</li> <li><code>ID_PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados y validados en la tabla <code>DIM_CAMPOS_CARACT</code> dentro del esquema <code>Protecci\u00f3n</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (tama\u00f1o predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva si es posible).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el flujo completo de datos del componente Data DIM_CAMPOS_CARACT:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Conversi\u00f3n de datos]\n    C --&gt; D[Validaci\u00f3n mediante Lookup]\n    D --&gt; E{\u00bfCoincidencia encontrada?}\n    E -- S\u00ed --&gt; F[Cargar datos en ADO NET Destination]\n    E -- No --&gt; G[Registrar datos no coincidentes]\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_preguntas_ee_jec","title":"Componente <code>Data DIM_PREGUNTAS_EE_JEC</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>Este componente gestiona un flujo de datos ETL que extrae preguntas relacionadas con ejecuci\u00f3n de eventos educativos desde un archivo Excel y las procesa para ser almacenadas en la tabla <code>DIM_PREGUNTAS_EE_JEC</code> del esquema <code>Protecci\u00f3n</code>. Incluye validaciones, transformaciones, y manejo de datos no coincidentes.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae los datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PROGRAMA</code></li> <li><code>PREGUNTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde una hoja).</li> <li>Conexi\u00f3n: Administrador de conexiones <code>Excel_Connection_Dim_Preguntas_JEC</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Programas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida los programas en los datos de entrada con los registros existentes en <code>DIM_PROGRAMA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PROGRAMA]\nWHERE [PROGRAMA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia encontrada: Asocia el <code>ID_PROGRAMA</code>.</li> <li>Sin coincidencia: Redirige a la etapa de conversi\u00f3n de datos.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas extra\u00eddas (<code>PREGUNTA</code>) a un formato compatible con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>PREGUNTA</code> \u2192 <code>Copy of PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup):</p> <ul> <li>Descripci\u00f3n: Verifica si las preguntas existen en la tabla destino <code>DIM_PREGUNTAS_EE_JEC</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_JEC]\nWHERE [PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>DIM_PREGUNTAS_EE_JEC</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_1","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el flujo completo del componente Data DIM_PREGUNTAS_EE_JEC:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n de Programas Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Preguntas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_respuesta_ee_jec","title":"Componente <code>Data DIM_RESPUESTA_EE_JEC</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos procesa respuestas asociadas a preguntas de encuestas educativas (<code>DIM_RESPUESTA_EE_JEC</code>). Las respuestas se extraen de un archivo Excel, se validan con las tablas existentes y se cargan en la base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PREGUNTA</code></li> <li><code>RESPUESTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde la hoja).</li> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_Respuestas_JEC</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida que las preguntas existan en <code>DIM_PREGUNTAS_EE_JEC</code> y asigna el <code>ID_PREGUNTA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_JEC]\nWHERE [PREGUNTA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia encontrada: Asocia el <code>ID_PREGUNTA</code>.</li> <li>Sin coincidencia: Redirige al flujo de transformaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas de texto para compatibilidad con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>RESPUESTA</code> \u2192 <code>Copy of RESPUESTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Respuestas (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida que las respuestas no est\u00e9n duplicadas en <code>DIM_RESPUESTAS_EE_JEC</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_RESPUESTAS_EE_JEC]\nWHERE [RESPUESTA] = ? AND [ID_PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga las respuestas validadas y procesadas en <code>DIM_RESPUESTAS_EE_JEC</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_2","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama muestra el proceso completo del flujo de datos:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n de Preguntas Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Respuestas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_preguntas_aipi","title":"Componente <code>Data DIM_PREGUNTAS_AIPI</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos carga preguntas relacionadas con el programa AIPI en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code>. El proceso incluye validaci\u00f3n, transformaci\u00f3n de datos y carga en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PROGRAMA</code></li> <li><code>PREGUNTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde la hoja).</li> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_Preguntas_AIPI</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n del Programa (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida que el programa asociado a la pregunta exista en la tabla <code>DIM_PROGRAMA</code> y asigna el <code>ID_PROGRAMA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PROGRAMA]\nWHERE [PROGRAMA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia encontrada: Asocia el <code>ID_PROGRAMA</code>.</li> <li>Sin coincidencia: Redirige al flujo de transformaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas para compatibilidad con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>PREGUNTA</code> \u2192 <code>Copy of PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida que las preguntas no est\u00e9n duplicadas en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_AIPI]\nWHERE [PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga las preguntas validadas y procesadas en <code>DIM_PREGUNTAS_EE_AIPI</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_3","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el proceso:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n del Programa Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Preguntas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_respuesta_aipi","title":"Componente <code>Data DIM_RESPUESTA_AIPI</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos realiza la carga de respuestas relacionadas con el programa AIPI en la tabla <code>DIM_RESPUESTAS_EE_AIPI</code>. El proceso incluye validaci\u00f3n, conversi\u00f3n de datos y carga en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PREGUNTA</code></li> <li><code>RESPUESTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde la hoja).</li> <li>Conexi\u00f3n: <code>Excel_Connection_Respuesta_AIPI</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida que la pregunta asociada a la respuesta exista en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code> y asigna el <code>ID_PREGUNTA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_AIPI]\nWHERE [PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas para compatibilidad con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>RESPUESTA</code> \u2192 <code>Copy of RESPUESTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Respuestas (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida que las respuestas no est\u00e9n duplicadas en la tabla <code>DIM_RESPUESTAS_EE_AIPI</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_RESPUESTAS_EE_AIPI]\nWHERE [RESPUESTA] = ? AND [ID_PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga las respuestas validadas y procesadas en <code>DIM_RESPUESTAS_EE_AIPI</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_4","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el proceso:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n de Preguntas Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Respuestas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-cargar_dim_sedes","title":"Componente <code>Cargar_DIM_SEDES</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente Cargar_DIM_SEDES es una tarea de tipo Execute SQL Task en SSIS. Su funci\u00f3n principal es limpiar (truncar) la tabla de staging que contiene informaci\u00f3n de poblaci\u00f3n de protecci\u00f3n antes de realizar nuevas cargas de datos. Esto asegura que la tabla est\u00e9 vac\u00eda y preparada para la inserci\u00f3n de datos actualizados.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#detalles-tecnicos","title":"Detalles T\u00e9cnicos","text":"<ul> <li>Tipo de Tarea: Execute SQL Task</li> <li>Nombre del Componente: <code>Cargar_DIM_SEDES</code></li> <li>Descripci\u00f3n: Ejecuta una sentencia SQL para truncar la tabla <code>[STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION]</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#propiedades-principales","title":"Propiedades Principales","text":"<ul> <li>Connection: Utiliza la conexi\u00f3n referenciada por el ID <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code>.</li> <li> <p>SQL Statement:   <pre><code>truncate table [STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION]\n</code></pre>   Esta sentencia limpia completamente la tabla para permitir la inserci\u00f3n de nuevos datos sin residuos de cargas anteriores.</p> </li> <li> <p>Task Contact: <code>Execute SQL Task; Microsoft Corporation; SQL Server 2022; \u00a9 2022 Microsoft Corporation; All Rights Reserved; http://www.microsoft.com/sql/support/default.asp;1</code></p> </li> <li> <p>ThreadHint: 0 (Sin sugerencia de hilos).</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo-del-proceso_1","title":"Diagrama de Flujo del Proceso","text":"<p>El siguiente diagrama ilustra el flujo de ejecuci\u00f3n para el componente Cargar_DIM_SEDES:</p> <pre><code>graph TD\n    A[Inicio del Proceso] --&gt; B[Conectar a la base de datos]\n    B --&gt; C[Ejecutar sentencia SQL]\n    C --&gt; D[Truncar la tabla DIM_POBLACION_PROTECCION]\n    D --&gt; E[Registrar resultado de la operaci\u00f3n]\n    E --&gt; F[Fin del Proceso]</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_poblacion-to_stage_area","title":"Componente <code>Data DIM_POBLACION TO_STAGE_AREA</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_POBLACION TO_STAGE_AREA es un flujo de datos (Data Flow Task) dentro de un paquete SSIS que se encarga de extraer informaci\u00f3n de poblaci\u00f3n desde un archivo Excel, convertir el formato de algunas columnas y posteriormente cargar los datos transformados en una tabla de staging ubicada en el esquema Transversal. En este caso, la tabla destino es <code>[STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION]</code>. Este proceso forma parte de la preparaci\u00f3n de los datos antes de su integraci\u00f3n final en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source 1) </p> <ul> <li>Descripci\u00f3n: Conecta y extrae datos desde un archivo Excel.  </li> <li>Propiedades:<ul> <li>Hoja seleccionada: <code>Sheet1$</code></li> <li>Se extraen las columnas: <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion 1) </p> <ul> <li>Descripci\u00f3n: Transforma los datos extra\u00eddos para ajustarse a los requerimientos del destino.  </li> <li>Columnas Convertidas:<ul> <li>La columna <code>DOCUMENTO</code> se convierte a un nuevo campo denominado <code>Copy of DOCUMENTO</code> con un tama\u00f1o de 40 caracteres.</li> <li>La columna <code>TIPO_DOCUMENTO</code> se convierte a <code>Copy of TIPO_DOCUMENTO</code> con un tama\u00f1o de 20 caracteres.</li> </ul> </li> <li>Propiedades adicionales:<ul> <li>Se activa la opci\u00f3n de conversi\u00f3n sin uso de FastParse (FastParse = false) para asegurar la correcta transformaci\u00f3n de los datos.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination: Destino de ADO NET 1) </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de staging <code>[STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION]</code>.  </li> <li>Propiedades:<ul> <li>TableOrViewName: <code>\"Transversal\".\"DIM_POBLACION_PROTECCION\"</code></li> <li>BatchSize: 0 (usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> para mejorar el rendimiento mediante inserciones masivas.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo-del-proceso_2","title":"Diagrama de Flujo del Proceso","text":"<p>El siguiente diagrama ilustra el flujo completo de datos para el componente Data DIM_POBLACION TO_STAGE_AREA:</p> <pre><code>graph TD\n    A[Inicio del Proceso] --&gt; B[Extracci\u00f3n de datos desde Excel Source]\n    B --&gt; C[Conversi\u00f3n de datos Data Conversion]\n    C --&gt; D[Carga en destino ADO NET]\n    D --&gt; E[Fin del Proceso]</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_poblacion","title":"Componente <code>Data DIM_POBLACION</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Este componente procesa y carga informaci\u00f3n sobre la poblaci\u00f3n en la tabla <code>DIM_POBLACION</code> del esquema <code>Proteccion</code>. El flujo de datos extrae registros desde un archivo Excel, realiza conversiones de datos y luego inserta la informaci\u00f3n en el destino mediante un ADO NET Destination. Adem\u00e1s, se incorpora un componente que obtiene datos desde la fuente mediante una consulta SQL que utiliza una expresi\u00f3n CTE (Common Table Expression) para transformar y validar los datos de poblaci\u00f3n provenientes de la etapa (<code>STAGE_AREA</code>).</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source 1)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel, leyendo la hoja <code>Sheet1$</code> y capturando las columnas <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> <li>Propiedades:<ul> <li>OpenRowset: <code>Sheet1$</code></li> <li>AccessMode: 0 (lectura directa desde la hoja)</li> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_Poblacion</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion 1)</p> <ul> <li>Descripci\u00f3n: Convierte las columnas extra\u00eddas para ajustarlas a los requerimientos del destino.</li> <li>Columnas Convertidas:<ul> <li><code>DOCUMENTO</code> \u2192 <code>Copy of DOCUMENTO</code> (convertido a <code>wstr</code> con longitud 40)</li> <li><code>TIPO_DOCUMENTO</code> \u2192 <code>Copy of TIPO_DOCUMENTO</code> (convertido a <code>wstr</code> con longitud 20)</li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos SQL (poblacion)</p> <ul> <li>Descripci\u00f3n: Utiliza una consulta SQL que define la CTE <code>DIM_POBLACION_PROTECCION</code> para transformar y validar los registros provenientes de la etapa <code>STAGE_AREA</code>. Se aplican m\u00faltiples LEFT JOIN a tablas de referencia (DIM_EMPRESAS, DIM_AFILIADOS, DIM_BENEFICIARIOS y DIM_APORTANTE_NOAFILIADO) para obtener los identificadores correspondientes. Luego, se filtran los registros que a\u00fan no han sido cargados en la tabla destino <code>DIM_POBLACION</code> (de modo que los registros duplicados se descarten).</li> <li>SQL:     <pre><code>WITH DIM_POBLACION_PROTECCION as (\n    SELECT \n        pp.TIPO_DOCUMENTO, \n        pp.DOCUMENTO,\n        CASE WHEN e.ID_EMPRESA IS NULL THEN -1 ELSE e.ID_EMPRESA END AS ID_EMPRESA,\n        CASE WHEN a.ID_AFILIADO IS NULL THEN -1 ELSE a.ID_AFILIADO END AS ID_AFILIADO,\n        CASE WHEN b.ID_BENEFICIARIO IS NULL THEN -1 ELSE b.ID_BENEFICIARIO END AS ID_BENEFICIARIO,\n        CASE WHEN an.ID_APORTANTE IS NULL THEN -1 ELSE an.ID_APORTANTE END AS ID_APORTANTE\n    FROM [STAGE_AREA].[Transversal].[DIM_POBLACION_PROTECCION] pp\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] e\n        ON pp.TIPO_DOCUMENTO = e.COD_TIPO_DOCUMENTO AND pp.DOCUMENTO = e.DOCUMENTO\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a\n        ON pp.TIPO_DOCUMENTO = a.COD_TIPO_DOCUMENTO AND pp.DOCUMENTO = a.NUMERO_DOCUMENTO\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b\n        ON pp.TIPO_DOCUMENTO = b.COD_TIPO_DOCUMENTO AND pp.DOCUMENTO = b.NUMERO_DOCUMENTO\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] an\n        ON pp.TIPO_DOCUMENTO = an.COD_TIPO_DOCUMENTO AND pp.DOCUMENTO = an.DOCUMENTO\n)\nSELECT pp.* \nFROM DIM_POBLACION_PROTECCION pp\nLEFT JOIN [DWH_COMFENALCO].[Proteccion].[DIM_POBLACION] ppp\n    ON pp.TIPO_DOCUMENTO = ppp.TIPO_DOCUMENTO\n    AND pp.DOCUMENTO = ppp.DOCUMENTO\n    AND pp.ID_EMPRESA = ppp.ID_EMPRESA\n    AND pp.ID_AFILIADO = ppp.ID_AFILIADO\n    AND pp.ID_BENEFICIARIO = ppp.ID_BENEFICIARIO\n    AND pp.ID_APORTANTE = ppp.ID_APORTANTE\nWHERE ppp.TIPO_DOCUMENTO IS NULL\n</code></pre></li> <li>Conexi\u00f3n: Utiliza el administrador de conexiones <code>DWH_COMFENALCO</code>.</li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination)</p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados y validados en la tabla <code>DIM_POBLACION</code> del esquema <code>Proteccion</code>.</li> <li>Propiedades:<ul> <li>TableOrViewName: <code>\"Proteccion\".\"DIM_POBLACION\"</code></li> <li>BatchSize: 0</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: <code>true</code></li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo-del-proceso_3","title":"Diagrama de Flujo del Proceso","text":"<pre><code>graph TD\n    A[Inicio] --&gt; B[Extracci\u00f3n de datos desde Excel Source 1]\n    B --&gt; C[Conversi\u00f3n de Datos Data Conversion 1]\n    C --&gt; D[Obtenci\u00f3n de datos mediante SQL poblacion]\n    D --&gt; E[Carga en ADO NET Destination Proteccion.DIM_POBLACION]\n    E --&gt; F[Fin]</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-establecimiento_educativo","title":"Componente <code>Data ESTABLECIMIENTO_EDUCATIVO</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>Este componente procesa informaci\u00f3n relacionada con establecimientos educativos y la carga en la tabla <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>. El flujo asegura que los datos sean validados y transformados antes de insertarse en el destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae los datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>NOMBRE_ESTABLECIMIENTO</code></li> <li><code>REPRESENTANTE_LEGAL</code></li> <li><code>DIRECCION</code></li> <li><code>MUNICIPIO</code></li> </ul> </li> <li>Propiedades:<ul> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_EE</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Datos (Lookup):</p> <ul> <li>Descripci\u00f3n: Busca si los registros ya existen en la tabla <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code> para evitar duplicados.</li> <li>Condiciones de B\u00fasqueda:<ul> <li><code>NOMBRE_ESTABLECIMIENTO</code></li> <li><code>REPRESENTANTE_LEGAL</code></li> <li><code>DIRECCION</code></li> <li><code>MUNICIPIO</code>.</li> </ul> </li> <li>Salida:<ul> <li>Filas coincidentes se eliminan del flujo.</li> <li>Filas no coincidentes contin\u00faan hacia el destino.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos (ADO.NET Destination):</p> <ul> <li>Descripci\u00f3n: Inserta los datos validados y \u00fanicos en la tabla <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>.</li> <li>Columnas de Entrada:<ul> <li><code>NOMBRE_ESTABLECIMIENTO</code></li> <li><code>REPRESENTANTE_LEGAL</code></li> <li><code>DIRECCION</code></li> <li><code>MUNICIPIO</code>.</li> </ul> </li> <li>Propiedades:<ul> <li>BatchSize: 0 (por defecto).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_5","title":"Diagrama de Flujo","text":"<pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n con Lookup]\n    C --&gt;|No Coincide| D[Carga en ADO.NET Destination]\n    C --&gt;|Coincide| E[Descartar Registros]\n    D --&gt; F[Fin]\n    E --&gt; F</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/","title":"08. PROTECCION_FACT","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#proteccion_fact","title":"PROTECCION_FACT","text":"<p>El paquete SSIS \"08-PROTECCION_FACT\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar informaci\u00f3n cr\u00edtica relacionada con operaciones de protecci\u00f3n social, como la caracterizaci\u00f3n de beneficiarios, diagn\u00f3sticos, entregas de materiales y visitas de seguimiento. Este paquete consolida datos de m\u00faltiples fuentes en el Data Warehouse <code>DWH_COMFENALCO</code>, asegurando su calidad, consistencia y disponibilidad para an\u00e1lisis y reportes estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es integrar datos operativos de protecci\u00f3n, garantizando la integridad y estructuraci\u00f3n de la informaci\u00f3n para apoyar an\u00e1lisis avanzados y toma de decisiones en el \u00e1mbito social y educativo.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos </p> <ul> <li>Fuentes Principales: <ul> <li>Archivos Planos:   Se procesan datos desde archivos planos que alimentan las siguientes tablas de hechos: <code>FACT_CARACTERIZACION</code>, <code>FACT_DIAGNOSTICOS_EE_JEC</code>, <code>FACT_ENTREGA_MATERIAL</code>, <code>FACT_VISITAS</code> y <code>FACT_DESERCION</code>.</li> <li>Bases de Datos Relacionales:   Se extrae informaci\u00f3n desde dimensiones y tablas de referencia como <code>DIM_TIEMPO</code>, <code>DIM_POBLACION</code>, <code>DIM_PROGRAMA</code>, <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>, entre otras.</li> </ul> </li> <li>Herramientas y Conexiones:     Se emplean conexiones OLE DB y ADO.NET para la integraci\u00f3n de datos.</li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos </p> <ul> <li>Validaciones (<code>Lookup</code>):   Se realizan b\u00fasquedas en tablas maestras para enriquecer los datos de entrada, por ejemplo, en <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code> o <code>DIM_PREGUNTAS_EE_JEC</code>.</li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):   Se garantiza la compatibilidad de los datos al convertir tipos y longitudes seg\u00fan lo requiera el destino.</li> <li>Columnas Derivadas (<code>Derived Column</code>):   Se generan claves \u00fanicas y se asignan valores predefinidos para facilitar la integraci\u00f3n.</li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse </p> <ul> <li>Tablas Procesadas: <ul> <li><code>FACT_CARACTERIZACION</code></li> <li><code>FACT_DIAGNOSTICOS_EE_JEC</code></li> <li><code>FACT_ENTREGA_MATERIAL</code></li> <li><code>FACT_VISITAS</code></li> <li><code>FACT_DESERCION</code></li> </ul> </li> <li>Configuraci\u00f3n de Carga:   Se habilitan las inserciones masivas para optimizar el rendimiento y se aseguran la integridad referencial y la consistencia en la carga de datos.</li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts </p> <ul> <li>Uso de scripts SQL din\u00e1micos para la restauraci\u00f3n de claves for\u00e1neas en esquemas como Transversal, Cedesarrollo, Proteccion y Colegio, garantizando la integridad referencial en el Data Warehouse.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>FACT_CARACTERIZACION: </p> <ul> <li>Columnas clave: <code>ID_POBLACION</code>, <code>ID_PROGRAMA</code>, <code>ID_FECHA</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>FACT_DIAGNOSTICOS_EE_JEC: </p> <ul> <li>Columnas clave: <code>ID_FECHA</code>, <code>ID_PREGUNTA</code>, <code>ID_RESPUESTA</code>, <code>ID_REGISTRO</code>.</li> </ul> </li> <li> <p>FACT_ENTREGA_MATERIAL: </p> <ul> <li>Columnas clave: <code>ID_FECHA_ENTREGA</code>, <code>ID_MATERIAL</code>, <code>ID_PERSONAL</code>, <code>CANTIDAD_MATERIAL</code>.</li> </ul> </li> <li> <p>FACT_VISITAS: </p> <ul> <li>Columnas clave: <code>ID_FECHA</code>, <code>ID_PROGRAMA</code>, <code>MUNICIPIO</code>, <code>FECHA_PLANEADA</code>, <code>FECHA_EJECUTADA</code>.</li> </ul> </li> <li> <p>FACT_DESERCION: </p> <ul> <li>Columnas clave: <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>, <code>ID_POBLACION</code>, <code>ID_FECHA_REGISTRO</code>, <code>PROGRAMA</code>, <code>CAUSA</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Planos\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de dimensiones clave\n    SSIS -&gt;&gt; Excel: Leer datos desde archivos planos\n    SSIS -&gt;&gt; Python: Restaurar claves for\u00e1neas\n    SSIS -&gt;&gt; DWH: Cargar datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-truncar-caracterizacion-stage_area","title":"Componente <code>Truncar Caracterizacion STAGE_AREA</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Este componente es una tarea de tipo Execute SQL Task en SSIS dise\u00f1ada para truncar la tabla <code>[STAGE_AREA].[Transversal].[FACT_CARACTERIZACION_PROTECCION]</code>. El prop\u00f3sito principal es limpiar la tabla en el \u00e1rea de staging antes de cargar nuevos datos, asegurando que no existan registros previos que puedan interferir con el proceso ETL.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#propiedades-del-componente","title":"Propiedades del Componente","text":"<ul> <li> <p>Conexi\u00f3n:   Utiliza la conexi\u00f3n identificada por <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code>.</p> </li> <li> <p>SQL Statement:   Ejecuta la siguiente instrucci\u00f3n SQL:   <pre><code>truncate table [STAGE_AREA].[Transversal].[FACT_CARACTERIZACION_PROTECCION]\n</code></pre></p> </li> <li> <p>Descripci\u00f3n:   \"Tarea Ejecutar SQL\" que se encarga de vaciar la tabla de staging para la caracterizaci\u00f3n de protecci\u00f3n.</p> </li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Task\n    participant SQL as SQL Server\n\n    SSIS -&gt;&gt; SQL: Ejecuta \"truncate table STAGE_AREA.Transversal.FACT_CARACTERIZACION_PROTECCION\"\n    SQL -&gt;&gt; SQL: Vac\u00eda la tabla</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_caracterizacion-stage_area","title":"Componente <code>Data FACT_CARACTERIZACION STAGE_AREA</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>Este componente forma parte de un flujo ETL en SSIS que procesa la informaci\u00f3n relacionada con la caracterizaci\u00f3n para el entorno de staging. Su objetivo es extraer datos desde un archivo plano, aplicar las transformaciones y conversiones necesarias, y finalmente cargar los datos resultantes en la tabla de destino Transversal.FACT_CARACTERIZACION_PROTECCION dentro del entorno de STAGE_AREA. Esto permite preparar los datos para su posterior integraci\u00f3n y validaci\u00f3n en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source </p> <ul> <li>Descripci\u00f3n:     Extrae datos desde un archivo plano (por ejemplo, CSV) que contiene columnas como DOCUMENTO, PROGRAMA, PREGUNTA, RESPUESTA, OBSERVACIONES, FECHA y TIPO_DOCUMENTO.</li> <li>Propiedades: <ul> <li>RetainNulls: false (no se retienen los valores nulos de origen).</li> <li>No se utiliza una columna para el nombre del archivo.</li> </ul> </li> <li>Salida:     Los datos extra\u00eddos se env\u00edan al siguiente componente para su transformaci\u00f3n.</li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Descripci\u00f3n:     Inserta los datos transformados en la tabla de destino. Se utiliza para cargar la informaci\u00f3n final en la tabla Transversal.FACT_CARACTERIZACION_PROTECCION.</li> <li>Propiedades Clave: <ul> <li>TableOrViewName:   \"Transversal\".\"FACT_CARACTERIZACION_PROTECCION\"</li> <li>BatchSize:   0 (se usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS).</li> <li>CommandTimeout:   30 segundos.</li> <li>UseBulkInsertWhenPossible:   true (habilita la inserci\u00f3n masiva para optimizar el rendimiento).</li> </ul> </li> <li>Conexi\u00f3n:     Se utiliza un administrador de conexiones configurado con el identificador DWH del \u00e1rea de staging.</li> <li>Mapeo de Columnas:     Se asignan columnas provenientes del Flat File Source a las columnas correspondientes del destino. Entre ellas se incluyen DOCUMENTO, PROGRAMA, PREGUNTA, RESPUESTA, OBSERVACIONES, TIPO_DOCUMENTO y FECHA.</li> </ul> </li> <li> <p>Rutas del Flujo de Datos </p> <ul> <li>Se establece una ruta directa desde la salida del Flat File Source hacia la entrada del Destino ADO.NET, lo que indica que todos los datos extra\u00eddos se pasan sin separaci\u00f3n intermedia a la carga final en la tabla de staging.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_caracterizacion","title":"Componente <code>Data FACT_CARACTERIZACION</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>Este componente forma parte de un flujo ETL en SSIS que extrae, transforma y carga datos de caracterizaci\u00f3n. La fuente de datos se define mediante una instrucci\u00f3n SQL que utiliza una CTE para preparar la informaci\u00f3n proveniente de la tabla de staging. Se unen datos de diversas dimensiones (poblaci\u00f3n, programa y campos de caracterizaci\u00f3n) para calcular un identificador de fecha basado en la fecha original. Posteriormente, se filtran los registros para incluir solo aquellos que a\u00fan no se encuentran en la tabla de destino. Finalmente, los datos se cargan en la tabla Proteccion.FACT_CARACTERIZACION en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (caract)</p> <ul> <li>Descripci\u00f3n:     Extrae datos utilizando una instrucci\u00f3n SQL que define una CTE llamada FACT_CARACTERIZACION_PROTECCION. La consulta recupera columnas como FECHA, ID_POBLACION, ID_PROGRAMA, ID_PREGUNTA, RESPUESTA y OBSERVACIONES. Adem\u00e1s, se calcula el identificador de fecha (ID_FECHA) a partir de la fecha, utilizando una concatenaci\u00f3n de a\u00f1o, mes y d\u00eda.</li> <li>Detalle de la Consulta SQL:     La consulta extrae registros de la tabla en el \u00e1rea de staging y realiza LEFT JOIN con las dimensiones DIM_POBLACION, DIM_PROGRAMA y DIM_CAMPOS_CARACT para relacionar la informaci\u00f3n. Finalmente, se seleccionan \u00fanicamente los registros que no tienen coincidencia en la tabla de destino FACT_CARACTERIZACION.</li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n:     Convierte el campo FECHA (extra\u00eddo en formato de cadena) a tipo dbTimeStamp. El resultado se almacena en la columna \"Copy of FECHA\" para garantizar la compatibilidad con el destino.</li> <li>Propiedades Relevantes: <ul> <li>Conversi\u00f3n de FECHA a formato de fecha y hora (dbTimeStamp).</li> <li>Se maneja la disposici\u00f3n de error configurada para abortar el componente en caso de error.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n:     Inserta los datos transformados y convertidos en la tabla de destino Proteccion.FACT_CARACTERIZACION.</li> <li>Propiedades Clave: <ul> <li>TableOrViewName: \"Transversal\".\"FACT_CARACTERIZACION_PROTECCION\" (para staging) o \"Proteccion\".\"FACT_CARACTERIZACION\" (para la carga final, seg\u00fan contexto de integraci\u00f3n).</li> <li>BatchSize: 0 (se utiliza el tama\u00f1o predeterminado del b\u00fafer interno de SSIS).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: true (habilita la inserci\u00f3n masiva para optimizar el rendimiento).</li> </ul> </li> <li>Mapeo de Columnas:     Se mapean columnas clave como ID_FECHA, ID_POBLACION, ID_PROGRAMA, ID_PREGUNTA, RESPUESTA y OBSERVACIONES desde la salida de la transformaci\u00f3n hasta el destino final.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-flujo-del-proceso","title":"Diagrama de Flujo del Proceso","text":"<p>El flujo de procesamiento se puede resumir de la siguiente manera:</p> <pre><code>graph TD\n    A[SQL Data Source] --&gt; B[Data Conversion]\n    B --&gt; C[ADO NET Destination]</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_diagnosticos_ee_jec","title":"Componente <code>Data FACT_DIAGNOSTICOS_EE_JEC</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>Este componente es un flujo de datos (Data Flow Task) de SSIS dise\u00f1ado para procesar y cargar datos relacionados con diagn\u00f3sticos en el entorno educativo (EE) para el m\u00f3dulo JEC. El proceso extrae informaci\u00f3n de un archivo plano, realiza conversiones de datos, aplica varias transformaciones de b\u00fasqueda (Lookup) para enriquecer los datos con claves de dimensiones y hechos, y finalmente carga los registros resultantes en la tabla destino Proteccion.FACT_DIAGNOSTICOS_EE_JEC en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source 1</p> <ul> <li>Descripci\u00f3n:     Extrae datos desde un archivo plano (CSV) utilizando la conexi\u00f3n definida por <code>Csv_Connection_Fact_Diagnosticos_EE_JEC</code>.</li> <li>Columnas de salida:     Incluye campos como:<ul> <li><code>FECHA</code></li> <li><code>PROGRAMA</code></li> <li><code>PREGUNTA</code></li> <li><code>RESPUESTA</code></li> <li><code>ID_REGISTRO</code></li> <li><code>FECHA_HORA_INICIO</code></li> <li><code>FECHA_HORA_FIN</code></li> <li><code>CORREO_FUNCIONARIO</code></li> <li><code>NOMBRE_FUNCIONARIO</code></li> <li><code>TOTAL_PUNTOS</code></li> <li><code>RECTOR</code></li> <li><code>FECHA_ULT_MODIF</code></li> </ul> </li> <li>Errores:     Las filas con errores son redirigidas a la salida de error con informaci\u00f3n adicional en las columnas <code>ErrorCode</code> y <code>ErrorColumn</code>.</li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n:     Convierte los datos extra\u00eddos a los tipos y formatos requeridos para su procesamiento posterior. Por ejemplo, convierte las cadenas que representan fechas en valores del tipo dbTimeStamp y realiza conversiones de texto a tipos num\u00e9ricos cuando es necesario.</li> <li>Columnas Convertidas: <ul> <li><code>ID_REGISTRO</code> se convierte a tipo numeric.</li> <li><code>FECHA_HORA_INICIO</code> y <code>FECHA_HORA_FIN</code> se convierten a tipo dbTimeStamp.</li> <li>Otros campos de texto (como <code>CORREO_FUNCIONARIO</code>, <code>NOMBRE_FUNCIONARIO</code>, <code>TOTAL_PUNTOS</code>, <code>RECTOR</code>, <code>FECHA</code>, <code>RESPUESTA</code>, <code>PREGUNTA</code> y <code>PROGRAMA</code>) se mantienen en formato cadena (wstr) con longitudes definidas.</li> </ul> </li> </ul> </li> <li> <p>Lookup Transformations</p> <ul> <li>Lookup (DIM_TIEMPO):<ul> <li>Descripci\u00f3n:   Realiza una b\u00fasqueda en la dimensi\u00f3n del tiempo para obtener el identificador de fecha (<code>ID_FECHA</code>) usando el valor convertido de la columna Copy of FECHA.</li> <li>SQL de Referencia: <code>SELECT * FROM [Dwh].[DIM_TIEMPO] WHERE FECHA = ?</code></li> </ul> </li> <li>Lookup 1 (DIM_PREGUNTAS_EE_JEC):<ul> <li>Descripci\u00f3n:   Cruza la columna convertida Copy of PREGUNTA con la tabla <code>DIM_PREGUNTAS_EE_JEC</code> para asociar cada registro con su correspondiente <code>ID_PREGUNTA</code>.</li> <li>SQL de Referencia: <code>SELECT * FROM [Proteccion].[DIM_PREGUNTAS_EE_JEC] WHERE PREGUNTA = ?</code></li> </ul> </li> <li>Lookup 2 (DIM_RESPUESTAS_EE_JEC):<ul> <li>Descripci\u00f3n:   Usa las columnas Copy of RESPUESTA y el <code>ID_PREGUNTA</code> obtenido previamente para buscar el <code>ID_RESPUESTA</code> en la tabla <code>DIM_RESPUESTAS_EE_JEC</code>.</li> <li>SQL de Referencia: <code>SELECT * FROM [Proteccion].[DIM_RESPUESTAS_EE_JEC] WHERE RESPUESTA = ? AND ID_PREGUNTA = ?</code></li> </ul> </li> <li>Lookup 3 (FACT_DIAGNOSTICOS_EE_JEC):<ul> <li>Descripci\u00f3n:   Verifica la existencia de registros duplicados en la tabla destino mediante una combinaci\u00f3n de varias columnas (FECHA_HORA_INICIO, FECHA_HORA_FIN, CORREO_FUNCIONARIO, NOMBRE_FUNCIONARIO, TOTAL_PUNTOS, RECTOR, RESPUESTA, ID_PREGUNTA y ID_RESPUESTA). Los registros sin coincidencia se permiten continuar para su inserci\u00f3n.</li> <li>SQL de Referencia:   La consulta compara todas las columnas clave para identificar duplicados.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n:     Inserta los datos transformados y validados en la tabla Proteccion.FACT_DIAGNOSTICOS_EE_JEC.</li> <li>Propiedades Clave: <ul> <li>TableOrViewName: <code>\"Proteccion\".\"FACT_DIAGNOSTICOS_EE_JEC\"</code></li> <li>BatchSize: 0 (usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true (habilita la inserci\u00f3n masiva para optimizar el rendimiento)</li> </ul> </li> <li>Columnas Cargadas:     Se cargan campos como:<ul> <li><code>ID_FECHA</code> (obtenido de Lookup DIM_TIEMPO)</li> <li><code>ID_PREGUNTA</code> (obtenido de Lookup 1)</li> <li><code>ID_RESPUESTA</code> (obtenido de Lookup 2)</li> <li>Adem\u00e1s, se incluyen columnas provenientes de la Data Conversion: Copy of ID_REGISTRO, Copy of FECHA_HORA_INICIO, Copy of FECHA_HORA_FIN, Copy of CORREO_FUNCIONARIO, Copy of NOMBRE_FUNCIONARIO, Copy of TOTAL_PUNTOS, Copy of RECTOR</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-flujo-del-proceso_1","title":"Diagrama de Flujo del Proceso","text":"<p>El proceso se puede resumir de la siguiente manera:</p> <pre><code>graph TD\n    A[Flat File Source] --&gt; B[Data Conversion]\n    B --&gt; C[Lookup: DIM_TIEMPO]\n    C --&gt; D[Lookup 1: DIM_PREGUNTAS_EE_JEC]\n    D --&gt; E[Lookup 2: DIM_RESPUESTAS_EE_JEC]\n    E --&gt; F[Lookup 3: Verificaci\u00f3n de duplicados en FACT_DIAGNOSTICOS_EE_JEC]\n    F --&gt; G[ADO.NET Destination]</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_diagnosticos_ee_aipi","title":"Componente <code>Data FACT_DIAGNOSTICOS_EE_AIPI</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente Data FACT_DIAGNOSTICOS_EE_AIPI es un flujo de datos (Data Flow Task) de SSIS dise\u00f1ado para extraer, transformar y cargar informaci\u00f3n de diagn\u00f3sticos para el m\u00f3dulo EE AIPI. Este proceso parte de un archivo plano que contiene informaci\u00f3n relevante, la cual es convertida a los formatos necesarios, enriquecida mediante varias transformaciones de b\u00fasqueda (Lookup) y, finalmente, insertada en la tabla destino Proteccion.FACT_DIAGNOSTICOS_EE_AIPI en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source</p> <ul> <li>Descripci\u00f3n:     Extrae datos desde un archivo plano delimitado utilizando la conexi\u00f3n configurada (<code>Csv_Connection_Fact_Diagnosticos_EE_AIPI</code>). Las columnas incluidas son:  <ul> <li>ESTABLECIMIENTO EDUCATIVO</li> <li>NOMBRE_SEDE</li> <li>MUNICIPIO</li> <li>ENTIDAD_ADMINISTRADORA</li> <li>DIRECCION</li> <li>FECHA</li> <li>PROGRAMA</li> <li>PREGUNTA</li> <li>RESPUESTA</li> <li>ID_REGISTRO</li> <li>FECHA_HORA_INICIO</li> <li>FECHA_HORA_FIN</li> <li>CORREO_FUNCIONARIO</li> <li>NOMBRE_FUNCIONARIO</li> <li>TOTAL_PUNTOS</li> <li>RECTOR</li> <li>FECHA_ULT_MODIF</li> </ul> </li> <li>Manejo de Errores:     Las filas que presenten errores durante la extracci\u00f3n se redirigen a una salida de error, registrando informaci\u00f3n adicional (por ejemplo, <code>ErrorCode</code> y <code>ErrorColumn</code>).</li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n:     Convierte las columnas extra\u00eddas a los tipos de datos requeridos para el procesamiento posterior. Se crean columnas de copia para asegurar la integridad y compatibilidad de la informaci\u00f3n. Por ejemplo:</li> <li>Columnas Convertidas: <ul> <li>Copy of ESTABLECIMIENTO EDUCATIVO (cadena extendida, wstr, longitud 255)</li> <li>Copy of NOMBRE_SEDE (wstr, longitud 200)</li> <li>Copy of MUNICIPIO (wstr, longitud 255)</li> <li>Copy of ENTIDAD_ADMINISTRADORA (wstr, longitud 255)</li> <li>Copy of DIRECCION (wstr, longitud 300)</li> <li>Copy of FECHA (convertido a dbTimeStamp)</li> <li>Copy of PREGUNTA (wstr, longitud 255)</li> <li>Copy of RESPUESTA (wstr, longitud 255)</li> <li>Otros campos necesarios para el enriquecimiento.</li> </ul> </li> </ul> </li> <li> <p>Transformaciones Lookup</p> <ul> <li>Lookup 1: DIM_ESTABLECIMIENTO_EDUCATIVO<ul> <li>Descripci\u00f3n:   Cruza la columna Copy of ESTABLECIMIENTO EDUCATIVO con la dimensi\u00f3n de establecimientos educativos para obtener el <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>.</li> <li>SQL de Referencia: <code>select * from [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] where NOMBRE_ESTABLECIMIENTO = ?</code></li> </ul> </li> <li>Lookup 2: DIM_PREGUNTAS_EE_AIPI<ul> <li>Descripci\u00f3n:   Utiliza la columna Copy of PREGUNTA para buscar el <code>ID_PREGUNTA</code> en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code>.</li> <li>SQL de Referencia: <code>select * from [Proteccion].[DIM_PREGUNTAS_EE_AIPI] where PREGUNTA = ?</code></li> </ul> </li> <li>Lookup 3: DIM_RESPUESTAS_EE_AIPI<ul> <li>Descripci\u00f3n:   Cruza la columna Copy of RESPUESTA junto con el <code>ID_PREGUNTA</code> obtenido previamente para asociar el registro con el <code>ID_RESPUESTA</code> en la tabla <code>DIM_RESPUESTAS_EE_AIPI</code>.</li> <li>SQL de Referencia: <code>select * from [Proteccion].[DIM_RESPUESTAS_EE_AIPI] where RESPUESTA = ? and ID_PREGUNTA = ?</code></li> </ul> </li> <li>Lookup 4: Validaci\u00f3n de Duplicados<ul> <li>Descripci\u00f3n:   Verifica la existencia de registros duplicados en la tabla destino. Esta transformaci\u00f3n utiliza m\u00faltiples columnas (por ejemplo, Copy of NOMBRE_SEDE, Copy of MUNICIPIO, Copy of ENTIDAD_ADMINISTRADORA, Copy of DIRECCION, Copy of FECHA, Copy of RESPUESTA, <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>, <code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>) para identificar si el registro ya existe en Proteccion.FACT_DIAGNOSTICOS_EE_AIPI.</li> <li>SQL de Referencia:   La consulta se estructura para comparar todas las columnas clave y enviar a la salida de \"No Match\" aquellos registros que no tengan duplicados.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n:     Inserta los datos finales, ya convertidos y enriquecidos, en la tabla Proteccion.FACT_DIAGNOSTICOS_EE_AIPI.</li> <li>Propiedades Clave:<ul> <li>TableOrViewName: <code>\"Proteccion\".\"FACT_DIAGNOSTICOS_EE_AIPI\"</code></li> <li>BatchSize: 0 (usa el tama\u00f1o predeterminado del b\u00fafer interno de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true</li> </ul> </li> <li>Columnas Cargadas:     Se incluyen columnas provenientes de la Data Conversion y los Lookups, tales como:<ul> <li><code>ID_FECHA</code> (obtenido de Lookup DIM_TIEMPO, si se aplicara)</li> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code></li> <li><code>ID_PREGUNTA</code></li> <li><code>ID_RESPUESTA</code></li> <li>Copy of ID_REGISTRO</li> <li>Copy of FECHA_HORA_INICIO</li> <li>Copy of FECHA_HORA_FIN</li> <li>Copy of CORREO_FUNCIONARIO</li> <li>Copy of NOMBRE_FUNCIONARIO</li> <li>Copy of TOTAL_PUNTOS</li> <li>Copy of RECTOR</li> <li>Entre otros campos relevantes.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-flujo-del-proceso_2","title":"Diagrama de Flujo del Proceso","text":"<p>El proceso general se representa de la siguiente forma:</p> <pre><code>graph TD\n    A[Flat File Source] --&gt; B[Data Conversion]\n    B --&gt; C[Lookup 1: DIM_ESTABLECIMIENTO_EDUCATIVO]\n    C --&gt; D[Lookup 2: DIM_PREGUNTAS_EE_AIPI]\n    D --&gt; E[Lookup 3: DIM_RESPUESTAS_EE_AIPI]\n    E --&gt; F[Lookup 4: Validaci\u00f3n de Duplicados]\n    F --&gt; G[Destino ADO.NET]</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_venta","title":"Componente <code>Data FACT_VENTA</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente Data FACT_VENTA es un Data Flow Task de SSIS que se encarga de extraer, transformar y cargar informaci\u00f3n de ventas en el entorno de protecci\u00f3n. La informaci\u00f3n se obtiene desde un archivo plano (CSV) y se procesa mediante varias transformaciones antes de insertarla en la tabla de destino Proteccion.FACT_VENTA. Este proceso integra la conversi\u00f3n de tipos de datos, el enriquecimiento mediante b\u00fasquedas en tablas de referencia (Lookup) y el uso de transformaciones derivadas para generar nuevos valores, como la asignaci\u00f3n de identificadores y la estandarizaci\u00f3n de campos.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source</p> <ul> <li>Funci\u00f3n:     Extrae los datos desde un archivo plano delimitado. Entre las columnas que se leen se encuentran:<ul> <li>FECHA</li> <li>CODIGO</li> <li>DOCUMENTO</li> <li>NOMBRE_USUARIO</li> <li>CATEGORIA_VENTA</li> <li>SERVICIO</li> <li>TIPO_DOCUMENTO</li> <li>VALOR_PAGADO_SIN_IMP</li> <li>COSTO</li> <li>SUBSIDIO</li> <li>PROGRAMA</li> </ul> </li> <li>Manejo de Errores:     Los registros que presenten problemas durante la extracci\u00f3n se env\u00edan a una salida de error, la cual captura c\u00f3digos y columnas de error para su posterior an\u00e1lisis.</li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Funci\u00f3n:     Convierte las columnas extra\u00eddas a los tipos de datos requeridos para el procesamiento. Por ejemplo, convierte la columna FECHA a un valor de tipo dbTimeStamp y ajusta las longitudes de campos de texto, como DOCUMENTO, NOMBRE_USUARIO, CATEGORIA_VENTA, SERVICIO y TIPO_DOCUMENTO.</li> <li>Resultado:     Se generan columnas \u201cCopy of \u2026\u201d que garantizan que los datos cumplen con el formato esperado en las transformaciones posteriores.</li> </ul> </li> <li> <p>Derived Column (Transformaci\u00f3n Derivada)</p> <ul> <li>Funci\u00f3n:     Crea nuevas columnas o modifica las existentes aplicando expresiones. En este caso, se utiliza para calcular y asignar valores derivados, como la conversi\u00f3n de la categor\u00eda de venta a un c\u00f3digo num\u00e9rico o la extracci\u00f3n del a\u00f1o a partir de la fecha.</li> <li>Ejemplo de Expresi\u00f3n:     Se eval\u00faa la columna de categor\u00eda y, seg\u00fan su valor, se asigna un c\u00f3digo espec\u00edfico (por ejemplo, \u201cA\u201d \u2192 1, \u201cB\u201d \u2192 2, etc.).</li> </ul> </li> <li> <p>Lookup \u2013 Dimensi\u00f3n Tiempo</p> <ul> <li>Funci\u00f3n:     Busca informaci\u00f3n en la dimensi\u00f3n de tiempo (almacenada en la base de datos DWH) utilizando el campo FECHA convertido. De esta forma se obtiene el identificador de fecha (ID_FECHA) que se usar\u00e1 en el registro de ventas.</li> <li>Consulta de Referencia:     Una instrucci\u00f3n SQL que extrae todos los registros de la dimensi\u00f3n de tiempo y filtra aquellos cuyo campo FECHA coincide con el valor procesado.</li> </ul> </li> <li> <p>Lookup \u2013 Dimensi\u00f3n Poblaci\u00f3n</p> <ul> <li>Funci\u00f3n:     Utiliza los campos DOCUMENTO y TIPO_DOCUMENTO (ya convertidos) para buscar y obtener el identificador de poblaci\u00f3n (ID_POBLACION) desde la tabla DIM_POBLACION del esquema Proteccion.</li> <li>Consulta de Referencia:     La instrucci\u00f3n SQL compara DOCUMENTO y TIPO_DOCUMENTO para encontrar la fila correspondiente.</li> </ul> </li> <li> <p>Lookup \u2013 Tarifas de Servicios</p> <ul> <li>Funci\u00f3n:     Consulta la tabla de tarifas de servicios (DIM_TARIFAS_SERVICIOS) del esquema Transversal para recuperar el identificador de tarifa (ID_TARIFA) aplicable al servicio registrado. Esta transformaci\u00f3n utiliza campos como SERVICIO, la categor\u00eda derivada y el a\u00f1o de la fecha.</li> <li>Consulta de Referencia:     Se utiliza una instrucci\u00f3n SQL parametrizada para filtrar la tarifa que corresponda a los datos de entrada.</li> </ul> </li> <li> <p>Lookup \u2013 Verificaci\u00f3n de Duplicados</p> <ul> <li>Funci\u00f3n:     Realiza una b\u00fasqueda en la tabla FACT_VENTA para detectar registros ya existentes. Esta verificaci\u00f3n se realiza comparando campos clave (por ejemplo, FECHA, DOCUMENTO, CATEGORIA_VENTA, SERVICIO, TIPO_DOCUMENTO, ID_POBLACION e ID_TARIFA). Los registros que no tengan coincidencias (es decir, que sean nuevos) se env\u00edan a la salida de \u201cNo Match\u201d, mientras que los duplicados se descartan.</li> <li>Importancia:     Garantiza la integridad de la carga evitando la inserci\u00f3n de registros repetidos.</li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Funci\u00f3n:     Inserta los registros procesados y verificados en la tabla Proteccion.FACT_VENTA.</li> <li>Propiedades Principales:<ul> <li>TableOrViewName: <code>\"Proteccion\".\"FACT_VENTA\"</code></li> <li>BatchSize: 0 (se utiliza el tama\u00f1o de b\u00fafer predeterminado de SSIS)</li> <li>CommandTimeout: 30 segundos</li> <li>UseBulkInsertWhenPossible: true (para mejorar el rendimiento mediante inserciones masivas)</li> </ul> </li> <li>Columnas Cargadas:     Se incluyen campos provenientes de las etapas previas, como el identificador de fecha (ID_FECHA), identificador de poblaci\u00f3n (ID_POBLACION), identificador de tarifa (ID_TARIFA), adem\u00e1s de los campos originales o derivados de la fuente.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#flujo-del-proceso","title":"Flujo del Proceso","text":"<p>El flujo de datos se organiza en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    La fuente (Flat File Source) lee los datos del archivo CSV.</p> </li> <li> <p>Conversi\u00f3n:    La transformaci\u00f3n de Data Conversion ajusta el formato y tipo de datos, generando columnas \u201cCopy of \u2026\u201d.</p> </li> <li> <p>Enriquecimiento y Transformaci\u00f3n: </p> <ul> <li>La transformaci\u00f3n derivada (Derived Column) calcula nuevos valores basados en los datos convertidos.</li> <li>Las transformaciones Lookup consultan las dimensiones de tiempo, poblaci\u00f3n y tarifas, y tambi\u00e9n verifican la existencia de registros duplicados.</li> </ul> </li> <li> <p>Carga:    Finalmente, el componente ADO.NET Destination inserta los datos finales en la tabla Proteccion.FACT_VENTA.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_entrega_material","title":"Componente <code>Data FACT_ENTREGA_MATERIAL</code>","text":"<p>Parte del paquete SSIS que ejecuta un Data Flow Task para el proceso ETL de entrega de material en el entorno de protecci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente Data FACT_ENTREGA_MATERIAL se encarga de extraer datos desde un archivo plano (CSV), transformarlos y finalmente cargarlos en la tabla de destino Proteccion.FACT_ENTREGA_MATERIAL. El proceso incluye la conversi\u00f3n de formatos de datos, enriquecimiento mediante b\u00fasquedas en tablas de referencia (Lookup) y la validaci\u00f3n de la informaci\u00f3n antes de insertarla en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#detalle-de-componentes","title":"Detalle de Componentes","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#1-flat-file-source-1","title":"1. Flat File Source 1","text":"<ul> <li>Funci\u00f3n:   Extrae los datos de un archivo CSV.  </li> <li>Columnas extra\u00eddas: <ul> <li>FECHA_ENTREGA  </li> <li>ID_PERSONAL  </li> <li>ID_MATERIAL  </li> <li>NOMBRE_MATERIAL  </li> <li>TIPO_MATERIAL  </li> <li>CANTIDAD_MATERIAL  </li> <li>VALOR_MATERIAL  </li> <li>TIPO_DOCUMENTO  </li> <li>DOCUMENTO  </li> <li>PROGRAMA  </li> </ul> </li> <li>Manejo de errores:   Las filas con problemas durante la lectura se redirigen a una salida de error, la cual captura informaci\u00f3n sobre el error para su an\u00e1lisis.</li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#2-data-conversion","title":"2. Data Conversion","text":"<ul> <li>Funci\u00f3n:   Convierte los datos de las columnas extra\u00eddas al formato requerido por el proceso.  </li> <li>Columnas convertidas: <ul> <li>Se generan nuevas columnas (prefijadas con \"Copy of \u2026\") para:</li> <li>FECHA_ENTREGA: Convertida a tipo dbTimeStamp </li> <li>TIPO_DOCUMENTO, DOCUMENTO, NOMBRE_MATERIAL, TIPO_MATERIAL, PROGRAMA: Convertidas a cadenas de longitud adecuada  </li> </ul> </li> <li>Importancia:   Garantiza que los datos cumplan con los requisitos de formato y tipo para las siguientes transformaciones y la carga final.</li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#3-lookup","title":"3. Lookup","text":"<p>Se utilizan varias transformaciones Lookup para enriquecer la informaci\u00f3n y relacionarla con datos de referencia:</p> <ul> <li> <p>Lookup (sin n\u00famero): </p> <ul> <li>Funci\u00f3n:   Consulta la dimensi\u00f3n de tiempo (DIM_TIEMPO) para obtener el identificador de fecha (ID_FECHA) basado en la columna FECHA convertida.  </li> <li>Consulta:   Se utiliza una instrucci\u00f3n SQL parametrizada que filtra la dimensi\u00f3n de tiempo seg\u00fan el valor de FECHA.</li> </ul> </li> <li> <p>Lookup 1: </p> <ul> <li>Funci\u00f3n:   Recupera el identificador de programa (ID_PROGRAMA) a partir del valor de PROGRAMA.  </li> <li>Consulta:   La transformaci\u00f3n ejecuta una consulta en la tabla DIM_PROGRAMA del esquema Proteccion, filtrando por el campo PROGRAMA.</li> </ul> </li> <li> <p>Lookup 2: </p> <ul> <li>Funci\u00f3n:   Busca el identificador de poblaci\u00f3n (ID_POBLACION) utilizando los valores TIPO_DOCUMENTO y DOCUMENTO.  </li> <li>Consulta:   Se consulta la tabla DIM_POBLACION de Proteccion, comparando ambos campos para obtener el valor correspondiente.</li> </ul> </li> <li> <p>Lookup 3: </p> <ul> <li>Funci\u00f3n:   Valida y enriquece la informaci\u00f3n final consultando la tabla FACT_ENTREGA_MATERIAL.  </li> <li>Consulta:   Se utiliza una consulta parametrizada que verifica la existencia de un registro en FACT_ENTREGA_MATERIAL usando como filtros FECHA_ENTREGA, NOMBRE_MATERIAL, TIPO_MATERIAL, ID_FECHA, ID_PROGRAMA e ID_POBLACION.  </li> <li>Comportamiento:   Se ha configurado el Lookup para enviar a la salida \u201cNo Match\u201d las filas que no tienen coincidencia, permitiendo la inserci\u00f3n \u00fanicamente de nuevos registros.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#4-destino-adonet-proteccionfact_entrega_material","title":"4. Destino ADO.NET (Proteccion.FACT_ENTREGA_MATERIAL)","text":"<ul> <li>Funci\u00f3n:   Carga los datos finales transformados en la tabla de destino Proteccion.FACT_ENTREGA_MATERIAL.  </li> <li>Propiedades importantes: </li> <li>TableOrViewName: <code>\"Proteccion\".\"FACT_ENTREGA_MATERIAL\"</code> </li> <li>BatchSize: 0 (usa el tama\u00f1o de b\u00fafer predeterminado de SSIS)  </li> <li>CommandTimeout: 30 segundos  </li> <li>UseBulkInsertWhenPossible: true (para inserciones masivas que optimizan el rendimiento)</li> <li>Columnas cargadas:   Se insertan campos provenientes del proceso, entre ellos:  </li> <li>ID_PERSONAL, ID_MATERIAL  </li> <li>Los valores convertidos y enriquecidos, como FECHA_ENTREGA, ID_FECHA, ID_PROGRAMA, ID_POBLACION  </li> <li>Otras columnas con datos relativos al material entregado, como CANTIDAD_MATERIAL y VALOR_MATERIAL</li> </ul>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#flujo-del-proceso_1","title":"Flujo del Proceso","text":"<p>El proceso ETL en Data FACT_ENTREGA_MATERIAL se estructura en los siguientes pasos:</p> <ol> <li> <p>Extracci\u00f3n:    El Flat File Source extrae los registros desde el archivo CSV.</p> </li> <li> <p>Conversi\u00f3n:    La transformaci\u00f3n Data Conversion genera versiones convertidas de los campos (por ejemplo, FECHA_ENTREGA a dbTimeStamp) para asegurar la compatibilidad con las transformaciones siguientes.</p> </li> <li> <p>Enriquecimiento y Validaci\u00f3n: </p> </li> <li>Las transformaciones Lookup consultan diferentes tablas de referencia para enriquecer y validar la informaci\u00f3n, verificando datos de tiempo, programa y poblaci\u00f3n.  </li> <li> <p>Se utiliza un Lookup adicional para descartar registros duplicados mediante la verificaci\u00f3n en la tabla de entrega de material.</p> </li> <li> <p>Carga:    Los registros transformados y validados se insertan en la tabla de destino utilizando el componente ADO.NET, con inserciones masivas para un rendimiento \u00f3ptimo.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_visitas","title":"Componente <code>Data FACT_VISITAS</code>","text":"<p>Este Data Flow Task se encarga de procesar informaci\u00f3n relacionada con visitas, realizando la extracci\u00f3n desde un archivo plano, la transformaci\u00f3n (incluida la conversi\u00f3n de datos y el enriquecimiento mediante m\u00faltiples b\u00fasquedas) y la carga en la tabla de destino en el esquema Proteccion.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#resumen-del-proceso","title":"Resumen del Proceso","text":"<p>Objetivo Principal: El flujo procesa registros de visitas, asegurando que los datos se transformen y enriquezcan adecuadamente antes de ser insertados en la tabla de destino Proteccion.FACT_VISITAS en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-clave","title":"Componentes Clave","text":"<ol> <li> <p>Flat File Source </p> <ul> <li>Funci\u00f3n: Extrae datos de un archivo plano (por ejemplo, CSV) con columnas como MUNICIPIO, FECHA_PLANEADA, ID_PERSONAL, PERSONAL, ACTIVIDAD, LUGAR, FECHA_EJECUTADA y PROGRAMA.</li> <li>Errores: Se redirigen a una salida de error en caso de problemas de conversi\u00f3n o lectura.</li> </ul> </li> <li> <p>Data Conversion </p> <ul> <li>Funci\u00f3n: Convierte las columnas extra\u00eddas al formato requerido.  </li> <li>Transformaciones: <ul> <li>Convierte la columna MUNICIPIO a un tipo de dato wstr con una longitud de 40 caracteres.  </li> <li>Convierte FECHA_PLANEADA y FECHA_EJECUTADA a dbTimeStamp, asegurando la correcta interpretaci\u00f3n de las fechas.</li> </ul> </li> <li>Objetivo: Garantizar la compatibilidad de tipos para las siguientes transformaciones y la carga.</li> </ul> </li> <li> <p>Lookup (sin n\u00famero y numerados) </p> <ul> <li>Lookup (general): <ul> <li>Consulta: Realiza una b\u00fasqueda en la dimensi\u00f3n de tiempo (DIM_TIEMPO) del Data Warehouse ([Dwh].[DIM_TIEMPO]), utilizando la fecha (FECHA) como par\u00e1metro para obtener el identificador de fecha (ID_FECHA).</li> </ul> </li> <li>Lookup 1: <ul> <li>Funci\u00f3n: Enriquecer la informaci\u00f3n con el identificador de programa (ID_PROGRAMA) consultando la tabla DIM_PROGRAMA en el esquema Proteccion, bas\u00e1ndose en el valor del campo PROGRAMA.</li> </ul> </li> <li>Lookup 2: <ul> <li>Funci\u00f3n: A trav\u00e9s de la verificaci\u00f3n de la poblaci\u00f3n, se obtiene o valida el identificador de poblaci\u00f3n (ID_POBLACION) mediante la comparaci\u00f3n de columnas (por ejemplo, TIPO_DOCUMENTO y DOCUMENTO) en la tabla DIM_POBLACION.</li> </ul> </li> <li>Manejo de filas sin coincidencia: <ul> <li>Los registros sin coincidencia en el Lookup se env\u00edan a una salida espec\u00edfica (Lookup No Match Output) para ser procesados (por ejemplo, para ser insertados como nuevos registros).</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Funci\u00f3n: Carga los datos finales en la tabla Proteccion.FACT_VISITAS.</li> <li>Propiedades Importantes: <ul> <li>Se utiliza la conexi\u00f3n ADO.NET con configuraci\u00f3n de inserci\u00f3n masiva (UseBulkInsertWhenPossible=true).</li> <li>Se definen propiedades como BatchSize (0, para usar el b\u00fafer interno de SSIS) y CommandTimeout (30 segundos).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#flujo-de-datos","title":"Flujo de Datos","text":"<ol> <li> <p>Extracci\u00f3n:    Los datos se leen desde el archivo plano a trav\u00e9s del componente Flat File Source.</p> </li> <li> <p>Conversi\u00f3n y Preparaci\u00f3n:    La transformaci\u00f3n Data Conversion genera columnas \"Copy of \u2026\" para las variables clave (por ejemplo, FECHA, DOCUMENTO, etc.), asegurando que los formatos sean los adecuados para los procesos posteriores.</p> </li> <li> <p>Enriquecimiento Mediante Lookups: </p> </li> <li>El primer Lookup asocia la fecha con el identificador correspondiente (ID_FECHA).  </li> <li>Lookups adicionales (Lookup 1 y Lookup 2) recuperan y validan el ID_PROGRAMA y el ID_POBLACION, respectivamente.</li> <li> <p>En caso de que alg\u00fan registro ya exista (por ejemplo, para evitar duplicados), el proceso puede redirigirlo a una salida de \u201cno match\u201d o \u201cerror\u201d seg\u00fan la configuraci\u00f3n.</p> </li> <li> <p>Carga:    Finalmente, el componente Destino de ADO NET inserta los datos transformados y enriquecidos en la tabla de destino Proteccion.FACT_VISITAS.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_desercion","title":"Componente <code>Data FACT_DESERCION</code>","text":"<p>Este flujo se encarga de procesar informaci\u00f3n relacionada con la deserci\u00f3n (abandono escolar) y consolidarla en la tabla Proteccion.FACT_DESERCION en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>Prop\u00f3sito: Extraer, transformar y cargar datos de deserci\u00f3n educativa. Los registros se leen desde un archivo plano (por ejemplo, CSV) y se transforman para asegurar la consistencia de la informaci\u00f3n antes de insertarlos en la tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-clave_1","title":"Componentes Clave","text":"<ol> <li> <p>Flat File Source </p> <ul> <li>Funci\u00f3n:     Lee datos de un archivo de texto. Las columnas extra\u00eddas incluyen, entre otras, <code>FECHA_REGISTRO</code>, <code>PROGRAMA</code>, <code>NOMBRE_EE</code>, <code>DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>ANIO_ACADEMICO</code> y <code>CAUSA</code>.</li> <li>Manejo de errores:     Los errores de conversi\u00f3n se redirigen a una salida de error, permitiendo el control y la depuraci\u00f3n de registros con datos inv\u00e1lidos.</li> </ul> </li> <li> <p>Data Conversion </p> <ul> <li>Funci\u00f3n:     Convierte los datos extra\u00eddos a los tipos requeridos para el procesamiento posterior.  </li> <li>Transformaciones espec\u00edficas: <ul> <li>Convierte <code>FECHA_REGISTRO</code> a formato dbTimeStamp.</li> <li>Crea columnas \"Copy of ...\" para <code>PROGRAMA</code>, <code>NOMBRE_EE</code>, <code>DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>ANIO_ACADEMICO</code> y <code>CAUSA</code> en los formatos requeridos.</li> </ul> </li> <li>Objetivo:     Garantizar la correcta transformaci\u00f3n de los datos y la compatibilidad con los siguientes procesos.</li> </ul> </li> <li> <p>Lookup Transformations </p> <ul> <li>Lookup General:     Utiliza la dimensi\u00f3n de tiempo ([Dwh].[DIM_TIEMPO]) para asociar la fecha de registro a su identificador (ID_FECHA). La consulta utiliza la fecha como par\u00e1metro para filtrar el registro correspondiente.</li> <li>Lookup 1:     Busca en la dimensi\u00f3n de programas ([Proteccion].[DIM_PROGRAMA]) para obtener el identificador de programa (ID_PROGRAMA) a partir del campo PROGRAMA.</li> <li>Lookup 2:     Se conecta a la dimensi\u00f3n de establecimientos educativos para asociar el registro con el identificador de establecimiento (ID_ESTABLECIMIENTO_EDUCATIVO).  </li> <li>Lookup 3:     Consulta la dimensi\u00f3n de poblaci\u00f3n ([Proteccion].[DIM_POBLACION]) utilizando el DOCUMENTO y TIPO_DOCUMENTO, lo que permite determinar o validar el identificador de poblaci\u00f3n (ID_POBLACION).</li> <li>Configuraci\u00f3n de manejo de filas sin coincidencia:     Los registros que no encuentran correspondencia en alguna de las b\u00fasquedas se canalizan a una salida de \"no match\", permitiendo su revisi\u00f3n o la inserci\u00f3n de nuevos registros en otras etapas.</li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Funci\u00f3n:     Inserta los datos transformados y enriquecidos en la tabla Proteccion.FACT_DESERCION.</li> <li>Propiedades importantes: <ul> <li>Se utiliza la interfaz ADO.NET con opciones de inserci\u00f3n masiva para optimizar el rendimiento (UseBulkInsertWhenPossible=true).</li> <li>Los par\u00e1metros como BatchSize y CommandTimeout se configuran para asegurar la estabilidad durante la carga.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#flujo-de-datos_1","title":"Flujo de Datos","text":"<ol> <li> <p>Extracci\u00f3n:    Los datos se leen desde el archivo plano mediante el componente Flat File Source.</p> </li> <li> <p>Transformaci\u00f3n: </p> </li> <li>El componente Data Conversion genera versiones convertidas de cada columna (por ejemplo, \"Copy of FECHA_REGISTRO\") para asegurar el formato correcto.</li> <li> <p>Las transformaciones Lookup enriquecen los datos obteniendo identificadores clave (ID_FECHA, ID_PROGRAMA, ID_ESTABLECIMIENTO_EDUCATIVO, ID_POBLACION) a partir de las dimensiones correspondientes.</p> </li> <li> <p>Carga:    Finalmente, el componente Destino de ADO NET inserta los datos procesados en la tabla Proteccion.FACT_DESERCION del Data Warehouse.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-data-fact_plan_cobertura","title":"Componente <code>Data FACT_PLAN_COBERTURA</code>","text":"<p>Se encarga de extraer, transformar y cargar los datos del plan de cobertura en la tabla Proteccion.FACT_PLAN_COBERTURA.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Objetivo: Integrar y transformar datos relacionados con el plan de cobertura, obtenidos de un archivo Excel, para consolidarlos en la tabla de destino. Los datos incluyen informaci\u00f3n sobre la cobertura proyectada, la l\u00ednea de intervenci\u00f3n, el a\u00f1o y el municipio.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-clave_2","title":"Componentes Clave","text":"<ol> <li> <p>Excel Source </p> <ul> <li>Funci\u00f3n:     Extrae los registros del archivo Excel. Entre las columnas extra\u00eddas se encuentran:<ul> <li>COBERTURA PROYECTADA</li> <li>LINEA DE INTERVENCION</li> <li>ANIO</li> <li>MUNICIPIO</li> <li>Adem\u00e1s, se incluyen otras columnas de soporte (por ejemplo, INSTTITUCIONES EDUCATIVAS) para la realizaci\u00f3n de b\u00fasquedas posteriores.</li> </ul> </li> <li>Detalles:     Utiliza la hoja \"Sheet1$\" y extrae las columnas con los datos originales.</li> </ul> </li> <li> <p>Data Conversion </p> <ul> <li>Funci\u00f3n:     Convierte las columnas extra\u00eddas a los formatos adecuados para las transformaciones y la carga en el destino.  </li> <li>Transformaciones realizadas: <ul> <li>Crea columnas \"Copy of ...\" para cada uno de los campos relevantes:</li> <li>Copy of COBERTURA PROYECTADA</li> <li>Copy of LINEA DE INTERVENCION</li> <li>Copy of ANIO</li> <li>Copy of MUNICIPIO</li> </ul> </li> <li>Objetivo:     Asegurar que los datos tengan el tipo y la longitud correcta para las siguientes etapas del proceso.</li> </ul> </li> <li> <p>Lookup Transformations    Se utilizan varios Lookups para enriquecer y validar la informaci\u00f3n:</p> <ul> <li>Lookup:     Consulta la dimensi\u00f3n de tiempo ([Dwh].[DIM_TIEMPO]) para obtener el identificador de fecha (ID_FECHA) a partir de la fecha extra\u00edda.</li> <li>Lookup 1:     Se conecta a la dimensi\u00f3n de programas ([Proteccion].[DIM_PROGRAMA]) para obtener el identificador de programa (ID_PROGRAMA) a partir del campo PROGRAMA.</li> <li>Lookup 2:     Valida y/o obtiene datos de establecimientos educativos o de otros dominios para complementar el registro (por ejemplo, utilizando los campos MUNICIPIO, LINEA DE INTERVENCION, COBERTURA PROYECTADA y ANIO para verificar la existencia de un registro similar en el destino).</li> <li>Configuraci\u00f3n:     Cada transformaci\u00f3n de Lookup utiliza par\u00e1metros basados en las columnas convertidas para unir los datos y, en caso de no encontrar coincidencia, canaliza los registros a una salida \"no match\" para su revisi\u00f3n.</li> </ul> </li> <li> <p>Destino ADO.NET </p> <ul> <li>Funci\u00f3n:     Inserta los datos transformados y enriquecidos en la tabla Proteccion.FACT_PLAN_COBERTURA.</li> <li>Configuraci\u00f3n:     Se utiliza la interfaz ADO.NET con opciones de inserci\u00f3n masiva (UseBulkInsertWhenPossible activado) para optimizar el rendimiento. Adem\u00e1s, se configuran par\u00e1metros como BatchSize y CommandTimeout para asegurar una carga eficiente y confiable.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-restaurar-llaves-foraneas","title":"Componente <code>Restaurar llaves foraneas</code>","text":"<p>Esta tarea de ejecuci\u00f3n SQL en SSIS, dise\u00f1ada para restaurar las restricciones de claves for\u00e1neas en distintos esquemas de la base de datos. A continuaci\u00f3n se describe el proceso:</p> <p>Objetivo: Restaurar las restricciones de claves for\u00e1neas que fueron previamente removidas o almacenadas de forma persistente, utilizando scripts SQL generados din\u00e1micamente para cada esquema (Transversal, Cedesarrollo, Proteccion y Colegio).</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#detalles-del-proceso","title":"Detalles del Proceso","text":"<ol> <li> <p>Generaci\u00f3n Din\u00e1mica de SQL:    Para cada esquema, se construye una instrucci\u00f3n SQL din\u00e1mica que:</p> <ul> <li>Utiliza un bucle (a trav\u00e9s de una agregaci\u00f3n en la consulta) para recorrer la tabla persistente correspondiente (por ejemplo, <code>dbo.ForeignKeys_Transversal</code>).</li> <li>Para cada restricci\u00f3n, se arma un comando <code>ALTER TABLE</code> que intenta agregar la clave for\u00e1nea usando <code>BEGIN TRY...END TRY</code> y <code>BEGIN CATCH...END CATCH</code> para capturar y notificar cualquier error (por ejemplo, si la constraint no puede agregarse).</li> </ul> </li> <li> <p>Ejecuci\u00f3n de las Instrucciones:    Una vez generadas las cadenas SQL para cada esquema, se ejecutan mediante la instrucci\u00f3n <code>EXEC sp_executesql</code> para restaurar las restricciones.</p> </li> <li> <p>Limpieza (Opcional):    Las l\u00edneas comentadas indican que, de ser necesario, se puede eliminar la tabla persistente con las definiciones de las llaves for\u00e1neas (<code>DROP TABLE dbo.ForeignKeys_&lt;Esquema&gt;</code>).</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#esquemas-procesados","title":"Esquemas Procesados","text":"<ul> <li>Transversal: Se restauran las restricciones definidas en la tabla <code>dbo.ForeignKeys_Transversal</code>.</li> <li>Cedesarrollo: Se restauran las restricciones definidas en la tabla <code>dbo.ForeignKeys_Cedesarrollo</code>, determinando din\u00e1micamente el esquema de referencia (Transversal, Dwh o Cedesarrollo) seg\u00fan la tabla de referencia.</li> <li>Proteccion: Se restauran las restricciones definidas en la tabla <code>dbo.ForeignKeys_Proteccion</code>, utilizando una l\u00f3gica similar para determinar el esquema de referencia.</li> <li>Colegio: Se restauran las restricciones definidas en la tabla <code>dbo.ForeignKeys_Colegio</code>, asignando el esquema adecuado (Transversal, Dwh o Colegio).</li> </ul>"},{"location":"02.Paquetes_SSIS/09-ETLS_CUBO/","title":"09. ETLS_CUBO","text":""},{"location":"02.Paquetes_SSIS/09-ETLS_CUBO/#etls-cubo","title":"ETLS CUBO","text":"<p>El paquete SSIS \"ETLS CUBO\" est\u00e1 dise\u00f1ado para gestionar procesos ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) enfocados en datos transversales y financieros. Este paquete asegura la correcta preparaci\u00f3n de tablas, la consolidaci\u00f3n de datos y la integraci\u00f3n eficiente en el Data Warehouse <code>DWH_COMFENALCO</code>, proporcionando una base s\u00f3lida para an\u00e1lisis y generaci\u00f3n de reportes.</p> <p>ETL PAQUETE 09</p>"},{"location":"03.Cubo/00.Introduccion/","title":"Introducci\u00f3n","text":""},{"location":"03.Cubo/00.Introduccion/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El cubo desarrollado en SSIS (SQL Server Integration Services) es una soluci\u00f3n anal\u00edtica dise\u00f1ada para procesar, consolidar y estructurar datos de m\u00faltiples fuentes dentro de un modelo sem\u00e1ntico. Este modelo permite realizar an\u00e1lisis multidimensionales, facilitando la toma de decisiones estrat\u00e9gicas y operativas mediante m\u00e9tricas clave, segmentaciones, y relaciones entre diversas dimensiones y hechos.</p> <p>El cubo integra datos desde un Data Warehouse centralizado, asegurando consistencia y eficiencia en la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de informaci\u00f3n. Este enfoque proporciona una vista consolidada y anal\u00edtica de los datos organizacionales.</p>"},{"location":"03.Cubo/00.Introduccion/#objetivos-del-cubo","title":"Objetivos del Cubo","text":"<p>1. Consolidaci\u00f3n de Datos:</p> <ul> <li>Unificar informaci\u00f3n procedente de diferentes tablas y dimensiones.</li> <li>Proveer datos consistentes para el an\u00e1lisis organizacional.</li> </ul> <p>2. An\u00e1lisis Multidimensional:</p> <ul> <li>Facilitar la creaci\u00f3n de reportes din\u00e1micos y visualizaciones anal\u00edticas.</li> <li>Permitir el desglose de informaci\u00f3n por jerarqu\u00edas, periodos y categor\u00edas.</li> </ul> <p>3. Optimizaci\u00f3n de Decisiones:</p> <ul> <li>Proveer m\u00e9tricas clave como ingresos, aportes, cobertura, y desempe\u00f1o.</li> <li>Ayudar en la identificaci\u00f3n de tendencias y oportunidades de mejora.</li> </ul>"},{"location":"03.Cubo/00.Introduccion/#principales-componentes-del-cubo","title":"Principales Componentes del Cubo","text":"<p>1. Dimensiones:</p> <ul> <li>Representan las jerarqu\u00edas y atributos que permiten segmentar y analizar los datos.</li> <li>Ejemplo: DIM_UNIDAD, DIM_TIEMPO_MENSUAL, y DIM_CATEGORIA.</li> </ul> <p>2. Hechos:</p> <ul> <li>Contienen los datos medibles y m\u00e9tricas clave para el an\u00e1lisis.</li> <li>Ejemplo: FACT_ACTIVIDADES, FACT_PERSONAL, y FACT_FINANCIERA.</li> </ul> <p>3. Relaciones:</p> <ul> <li>Definen c\u00f3mo las dimensiones y los hechos interact\u00faan entre s\u00ed.</li> <li>Aseguran consistencia y precisi\u00f3n en el modelo.</li> </ul> <p>4. Medidas:</p> <ul> <li>Proveen c\u00e1lculos predefinidos como sumas, promedios y conteos.</li> <li>Ejemplo: # Empresas Afiliadas Caja, Valor Aportes Totales.</li> </ul>"},{"location":"03.Cubo/00.Introduccion/#beneficios-del-cubo","title":"Beneficios del Cubo","text":"<p>1. Agilidad Anal\u00edtica:</p> <ul> <li>Generaci\u00f3n r\u00e1pida de informes para diversas \u00e1reas de la organizaci\u00f3n.</li> <li>Reducci\u00f3n de tiempos en la obtenci\u00f3n y an\u00e1lisis de datos.</li> </ul> <p>2. Consistencia y Calidad de Datos:</p> <ul> <li>Integraci\u00f3n de datos con controles de calidad y validaciones.</li> <li>Centralizaci\u00f3n de la informaci\u00f3n para evitar duplicidades o inconsistencias.</li> </ul> <p>3. Escalabilidad:</p> <ul> <li>Capacidad de adaptarse a nuevas necesidades de negocio a\u00f1adiendo dimensiones, hechos o medidas.</li> </ul> <p>4. Decisiones Basadas en Datos:</p> <ul> <li>Facilitaci\u00f3n de insights clave para la toma de decisiones fundamentadas.</li> </ul>"},{"location":"03.Cubo/00.Introduccion/#vista-del-modelo","title":"Vista del modelo","text":""},{"location":"03.Cubo/00.Introduccion/#diagrama-de-relaciones-y-tablas","title":"Diagrama de Relaciones y Tablas","text":"<pre><code>graph TD\n    FACT_ACTIVIDADES[Transversal FACT_ACTIVIDADES]\n    FACT_PERSONAL[Transversal FACT_PERSONAL]\n    FACT_FINANCIERA[Transversal FACT_FINANCIERA]\n    FACT_EVALUACION_DOCENTE[Transversal FACT_EVALUACION_DOCENTE]\n    DIM_UNIDAD[Transversal DIM_UNIDAD]\n    DIM_CATEGORIA[Transversal DIM_CATEGORIA]\n    DIM_TIEMPO[Transversal DIM_TIEMPO_MENSUAL]\n\n    FACT_ACTIVIDADES --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_ACTIVIDADES --&gt; DIM_CATEGORIA[ID_CATEGORIA]\n    FACT_ACTIVIDADES --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_FINANCIERA --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_TIEMPO[ID_FECHA]</code></pre>"},{"location":"03.Cubo/01.Origen/","title":"01. ORIGEN Y MEDIDAS","text":""},{"location":"03.Cubo/01.Origen/#origen-de-datos-del-cubo","title":"Origen de Datos del Cubo","text":""},{"location":"03.Cubo/01.Origen/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El origen de datos es un componente estructurado que conecta el cubo de SSIS con el Data Warehouse principal. Esta conexi\u00f3n permite la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos necesarios para las operaciones anal\u00edticas.</p>"},{"location":"03.Cubo/01.Origen/#detalles-de-configuracion","title":"Detalles de Configuraci\u00f3n","text":"<p>1. Tipo de Origen: </p> <ul> <li>Estructurado (<code>structured</code>).</li> </ul> <p>2. Nombre del Origen:</p> <ul> <li><code>SQL/10 5 21 29\\\\bi;DWH_COMFENALCO</code>.</li> </ul> <p>3. Detalles de Conexi\u00f3n:</p> <ul> <li>Protocolo: <code>tds</code> (Tabular Data Stream, utilizado para bases de datos SQL Server).</li> <li>Direcci\u00f3n:<ul> <li>Servidor: <code>10.5.21.29\\bi</code>.</li> <li>Base de Datos: <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ul> <p>4. Autenticaci\u00f3n:</p> <ul> <li>Tipo: <code>UsernamePassword</code>.</li> <li>Usuario: <code>prov_quality2</code>.</li> <li>Conexi\u00f3n encriptada: <code>false</code>.</li> </ul> <p>5. Credenciales:</p> <ul> <li>Ruta: <code>10.5.21.29\\\\bi;DWH_COMFENALCO</code>.</li> <li>Cifrado: No aplica (<code>EncryptConnection: false</code>).</li> </ul>"},{"location":"03.Cubo/01.Origen/#proposito","title":"Prop\u00f3sito","text":"<p>El origen de datos garantiza la conectividad y el acceso a las tablas y medidas necesarias para el funcionamiento del cubo. Este origen permite a los paquetes de SSIS consumir datos directamente desde el DWH para su an\u00e1lisis y explotaci\u00f3n.</p>"},{"location":"03.Cubo/01.Origen/#medidas","title":"Medidas","text":""},{"location":"03.Cubo/01.Origen/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tabla Medidas contiene columnas calculadas y una serie de medidas configuradas para realizar an\u00e1lisis y c\u00e1lculos dentro del cubo. Estas medidas se utilizan para analizar datos clave y generar m\u00e9tricas significativas para la toma de decisiones.</p>"},{"location":"03.Cubo/01.Origen/#estructura","title":"Estructura","text":"<p>Cada medida calculada se describe brevemente, indicando su objetivo, la l\u00f3gica DAX utilizada y (donde aplica) el formato de salida.</p> <ol> <li> <p># Unidades </p> <ul> <li>Objetivo: Retorna el conteo distinto de unidades (ID_UNIDAD) de la dimensi\u00f3n \u201cTransversal DIM_UNIDAD\u201d, excluyendo la unidad 5.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n    DISTINCTCOUNT('Transversal DIM_UNIDAD'[ID_UNIDAD]),\n    'Transversal DIM_UNIDAD'[ID_UNIDAD] &lt;&gt; 5\n)\nreturn IF( ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Valor num\u00e9rico (sin formato adicional).</li> </ul> </li> <li> <p># Empresas Afiliadas Caja </p> <ul> <li>Objetivo: Calcula el n\u00famero de empresas afiliadas (con TIPO_POBLACION = \"EMPRESA\" y ACTIVIDAD = \"AFILIACION\") seg\u00fan la unidad seleccionada; devuelve 0 para algunas unidades y aplica filtros para otras.  </li> <li>Expresi\u00f3n DAX (resumida): <pre><code>VAR EmpresasCalculo = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[TIPO_POBLACION] = \"EMPRESA\",\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n)\nVAR EmpresasCalculoSinFiltros = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[TIPO_POBLACION] = \"EMPRESA\",\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\",\n    REMOVEFILTERS('Transversal DIM_UNIDAD')\n)\nvar dev = SWITCH(\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1,2,4}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) = 3, EmpresasCalculoSinFiltros,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) = 5, EmpresasCalculo,\n    EmpresasCalculo\n)\nreturn IF( ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># Afiliados Caja </p> <ul> <li>Objetivo: Retorna el conteo de afiliados (TIPO_POBLACION = \"AFILIADO\") con actividad \"AFILIACION\", usando variantes con y sin filtros seg\u00fan la unidad seleccionada.  </li> <li>Expresi\u00f3n DAX: Similar a la medida anterior, usando SWITCH y dos variables (AfiliadosCalculo y AfiliadosCalculoSinFiltros).  </li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># Beneficiarios Caja </p> <ul> <li>Objetivo: Calcula el n\u00famero de beneficiarios (TIPO_POBLACION = \"BENEFICIARIO\") en actividad \"AFILIACION\", aplicando l\u00f3gica similar a las medidas de afiliados y empresas.  </li> <li>Expresi\u00f3n DAX: Utiliza dos variables para el c\u00e1lculo con o sin filtros y SWITCH para determinar el valor final.  </li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># Aportes Totales </p> <ul> <li>Objetivo: Suma el campo NUMERO_APORTES para registros cuya actividad es \"APORTES\", considerando dos variantes (con y sin filtros de unidad).  </li> <li>Expresi\u00f3n DAX: <pre><code>VAR AportesCalculo = CALCULATE(\n    SUM('Transversal FACT_ACTIVIDADES'[NUMERO_APORTES]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"APORTES\"\n)\nVAR AportesCalculoSinFiltros = CALCULATE(\n    SUM('Transversal FACT_ACTIVIDADES'[NUMERO_APORTES]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"APORTES\",\n    REMOVEFILTERS('Transversal DIM_UNIDAD')\n)\nvar dev = SWITCH(\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1,2,3,4}, AportesCalculoSinFiltros,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) = 5, AportesCalculo,\n    AportesCalculo\n)\nreturn IF( ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico (con formato de moneda: \\$ #,0.00).</li> </ul> </li> <li> <p>Valor Aportes Totales </p> <ul> <li>Objetivo: Suma el campo TOTAL_APORTES para actividad \"APORTES\", aplicando la misma l\u00f3gica condicional que en # Aportes Totales.  </li> <li>Expresi\u00f3n DAX: Similar a la medida anterior pero usando SUM('...'[TOTAL_APORTES]).  </li> <li>Formato: Moneda (formateada).</li> </ul> </li> <li> <p>#Empresas_Atendidas </p> <ul> <li>Objetivo: Cuenta las empresas atendidas, es decir, el n\u00famero de registros \u00fanicos de ID_EMPRESA en FACT_ACTIVIDADES (excluyendo -1 y unidad 5).  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[ID_EMPRESA]),\n    'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n)\nreturn IF( ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>#Afiliados_Atendidos </p> <ul> <li>Objetivo: Similar a la medida anterior, pero para ID_AFILIADO.  </li> <li>Expresi\u00f3n DAX: Usa DISTINCTCOUNTNOBLANK sobre ID_AFILIADO con condiciones similares.  </li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>#Beneficiarios_Atendidos </p> <ul> <li>Objetivo: Calcula la cantidad de beneficiarios atendidos mediante DISTINCTCOUNTNOBLANK de ID_BENEFICIARIO.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO]),\n    'Transversal FACT_ACTIVIDADES'[ID_BENEFICIARIO] &lt;&gt; -1,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n)\nreturn IF( ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Cumplimiento_Cobertura         - Objetivo: Mide el cumplimiento de la cobertura comparando la cobertura ejecutada con la proyectada.         - Expresi\u00f3n DAX: <pre><code>IF([Cobertura proyectada] = 0, -1, [Cobertura ejecutada] / [Cobertura proyectada])\n</code></pre>         - Formato: Porcentaje (0.00 %).</p> </li> <li> <p>Cantidad_Usos         - Objetivo: Cuenta el n\u00famero total de usos de la actividad en FACT_ACTIVIDADES, excluyendo registros de unidad 5 o en blanco.         - Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   count('Transversal FACT_ACTIVIDADES'[ACTIVIDAD]),\n   'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n   'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n)\nreturn IF( ISBLANK(dev), -1, dev)\n</code></pre>         - Formato: Num\u00e9rico.</p> </li> <li> <p>Cantidad_Aportes_Totales         - Objetivo: Devuelve el valor de la medida \u201c# Aportes Totales\u201d.         - Expresi\u00f3n DAX: <pre><code>[# Aportes Totales]\n</code></pre>         - Formato: Hereda el formato de \u201c# Aportes Totales\u201d.</p> </li> <li> <p>Valor_Aportes_Totales         - Objetivo: Devuelve el valor de la medida \u201cValor Aportes Totales\u201d.         - Expresi\u00f3n DAX: <pre><code>[Valor Aportes Totales]\n</code></pre>         - Formato: Moneda.</p> </li> <li> <p>Cantidad de aportes empresas atendidas Educacion </p> <ul> <li>Objetivo: Calcula el total de aportes (en n\u00famero) para los registros donde [POBLACION_EDUCACION] es \"SI\".  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE([# Aportes Totales], 'Transversal FACT_ACTIVIDADES'[POBLACION_EDUCACION] = \"SI\")\nreturn IF( ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Valor de aportes empresas atendidas Educacion </p> <ul> <li>Objetivo: Calcula el valor total de aportes para empresas atendidas en educaci\u00f3n (filtrados por POBLACION_EDUCACION = \"SI\").  </li> <li>Expresi\u00f3n DAX: Similar a la medida anterior pero sobre [Valor Aportes Totales].  </li> <li>Formato: Moneda.</li> </ul> </li> <li> <p>Cantidad de subsidio a la demand </p> <ul> <li>Objetivo: Cuenta la cantidad de registros en que el SUBSIDIO es mayor a 0, para registros con partner distinto de \"0000000000\" y unidad diferente a 5.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   count('Transversal FACT_ACTIVIDADES'[SUBSIDIO]),\n   'Transversal FACT_ACTIVIDADES'[PARTNER] &lt;&gt; \"0000000000\",\n   'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n   'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK(),\n   'Transversal FACT_ACTIVIDADES'[SUBSIDIO] &gt; 0\n)\nreturn if( ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Valor de subsidio  a la demanda </p> <ul> <li>Objetivo: Suma el campo SUBSIDIO para registros que cumplen condiciones similares a la medida anterior.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   sum('Transversal FACT_ACTIVIDADES'[SUBSIDIO]),\n   'Transversal FACT_ACTIVIDADES'[PARTNER] &lt;&gt; \"0000000000\",\n   'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n   'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Moneda.</li> </ul> </li> <li> <p>% Poblaci\u00f3n Atendida por Educaci\u00f3n </p> <ul> <li>Objetivo: Calcula el porcentaje de poblaci\u00f3n atendida por educaci\u00f3n dividiendo el conteo de registros atendidos por el total de afiliados en \"AFILIACION\".  </li> <li>Expresi\u00f3n DAX: <pre><code>VAR PoblacionAtendida = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[PARTNER] &lt;&gt; \"0000000000\",\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; 5,\n    'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] &lt;&gt; BLANK()\n)\nVAR Poblacion = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[PARTNER] &lt;&gt; \"0000000000\",\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n)\nvar dev = PoblacionAtendida / Poblacion\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Cobertura ejecutada </p> <ul> <li>Objetivo: Cuenta la cantidad de registros (usando DISTINCTCOUNTNOBLANK) para calcular la cobertura ejecutada, filtrando registros con partner distinto de \"0000000000\" y unidad \u2260 5.  </li> <li>Expresi\u00f3n DAX: Similar a las medidas de conteo de empresas/afiliados/beneficiarios.  </li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Cantidad de Graduados </p> <ul> <li>Objetivo: Cuenta el n\u00famero de graduados mediante DISTINCTCOUNT de PARTNER para registros con ACTIVIDAD \"GRADUADOS\".  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n   'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"GRADUADOS\"\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Porcentaje de promocion </p> <ul> <li>Objetivo: Valor fijo de 0 (indicando que no se calcula promoci\u00f3n).  </li> <li>Expresi\u00f3n DAX: <pre><code>0\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Porcentaje de desercion </p> <ul> <li>Objetivo: Calcula el ratio de deserciones respecto al total (sumando RETIROS y ESTADO_MATRICULAS).  </li> <li>Expresi\u00f3n DAX: <pre><code>VAR Total = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] IN {\"ESTADO_MATRICULAS\", \"RETIROS\"}\n)\nVAR Deserciones = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] IN {\"RETIROS\"}\n)\nvar dev = Deserciones / Total\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Porcentaje de empresas que repiten la compra de los servicios de fomento empresarial </p> <ul> <li>Objetivo: Calcula la proporci\u00f3n de empresas que han realizado compras repetidas en servicios de fomento, bas\u00e1ndose en condiciones espec\u00edficas definidas en un SWITCH.  </li> <li>Expresi\u00f3n DAX: Utiliza variables para contar empresas que repiten y el total de empresas, luego DIVIDE.  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Porcentaje de usuarios que repiten la compra de servicios de protecci\u00f3n social </p> <ul> <li>Objetivo: Determina el porcentaje de usuarios (afiliados) que han repetido la compra de servicios de protecci\u00f3n social.  </li> <li>Expresi\u00f3n DAX: Usa variables para calcular Usuarios_repiten y Usuarios_Totales, luego su divisi\u00f3n.  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p># Espacios f\u00edsicos (Salones) </p> <ul> <li>Objetivo: Retorna el n\u00famero de salones activos (seg\u00fan DIM_CAPACIDAD_FISICA).  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   DISTINCTCOUNT('Transversal DIM_CAPACIDAD_FISICA'[ID_SALON]),\n   'Transversal DIM_CAPACIDAD_FISICA'[ESTADO] = \"ACTIVO\"\n)\nRETURN IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># Servicios ofertados </p> <ul> <li>Objetivo: Calcula el n\u00famero de servicios ofertados (basado en DIM_TARIFAS_SERVICIOS) considerando la unidad seleccionada y otros filtros.  </li> <li>Expresi\u00f3n DAX: Utiliza SELECTEDVALUE y SWITCH para aplicar condiciones seg\u00fan la unidad.  </li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># Servicios vendidos </p> <ul> <li>Objetivo: Cuenta los servicios vendidos mediante DISTINCTCOUNT de CON_OBJETO_TARIFA de DIM_TARIFAS_SERVICIOS, relacion\u00e1ndolo con FACT_ACTIVIDADES.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   DISTINCTCOUNT('Transversal DIM_TARIFAS_SERVICIOS'[CON_OBJETO_TARIFA]),\n   RELATEDTABLE('Transversal FACT_ACTIVIDADES')\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># Estudiantes activos </p> <ul> <li>Objetivo: Calcula el n\u00famero de estudiantes activos restando retiros y graduados de las matriculaciones aprobadas.  </li> <li>Expresi\u00f3n DAX: <pre><code>VAR colegio_matriculas = CALCULATE(\n   DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n   'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\",\n   'Transversal FACT_ACTIVIDADES'[ESTADO] = \"APROBADA\"\n)\nVAR colegio_retiros = CALCULATE(\n   DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n   'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"RETIROS\"\n)\nVAR colegio_graduados = CALCULATE(\n   DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n   'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"GRADUADOS\"\n)\nvar dev = colegio_matriculas - colegio_retiros - colegio_graduados\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># Estudiantes por salon </p> <ul> <li>Objetivo: Calcula el promedio de estudiantes activos por sal\u00f3n.  </li> <li>Expresi\u00f3n DAX: <pre><code>IF([# Espacios f\u00edsicos (Salones)] = 0, 0, [# Estudiantes activos] / [# Espacios f\u00edsicos (Salones)])\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># Docentes y profesionales </p> <ul> <li>Objetivo: Cuenta el n\u00famero de docentes/profesionales activos seg\u00fan FACT_PERSONAL.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   DISTINCTCOUNTNOBLANK('Transversal FACT_PERSONAL'[ID_PERSONAL]),\n   'Transversal FACT_PERSONAL'[ID_PERSONAL] &lt;&gt; -1\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># PQRS </p> <ul> <li>Objetivo: Calcula la cantidad de registros de PQR.  </li> <li>Expresi\u00f3n DAX: <pre><code>IF(\n   ISBLANK(\n      CALCULATE(\n         DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_PQR]),\n         'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"PQR\"\n      )\n   ),\n   -1,\n   CALCULATE(\n      DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_PQR]),\n      'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"PQR\"\n   )\n)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Numero de usos por PQRS </p> <ul> <li>Objetivo: Calcula el promedio de usos por cada PQR.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = if([# PQRS] = 0, 0, [Cantidad_Usos] / [# PQRS])\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Porcentaje de Promotores </p> <ul> <li>Objetivo: Calcula el porcentaje de promotores (usuarios NSU con calificaci\u00f3n \u2265 7) sobre el total de NSU.  </li> <li>Expresi\u00f3n DAX: Utiliza variables para contar total y promotores, luego divide.  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Porcentaje de detractores </p> <ul> <li>Objetivo: Calcula el porcentaje de detractores (usuarios NSU con calificaci\u00f3n &lt; 7) sobre el total de NSU.  </li> <li>Expresi\u00f3n DAX: Similar a la medida anterior pero para detractores.  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Calificaciones de docentes </p> <ul> <li>Objetivo: Calcula el promedio de las calificaciones definitivas de los docentes a partir de FACT_EVALUACION_DOCENTE.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = AVERAGEX(\n   'Transversal FACT_EVALUACION_DOCENTE',\n   IFERROR(VALUE('Transversal FACT_EVALUACION_DOCENTE'[CALIFICACION_DEFINITIVA]), BLANK())\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>% de estudiantes con resultado superior al 50% de valor total de la Prueba </p> <ul> <li>Objetivo: Calcula la proporci\u00f3n de estudiantes que superan el 50% del valor total en la prueba Saber 11 (a partir de FACT_UNIDADES).  </li> <li>Expresi\u00f3n DAX: Divide la suma de estudiantes con puntaje mayor a 250 por el total de estudiantes.  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Resultado de la Categor\u00eda de las pruebas Saber 11 para la CEC </p> <ul> <li>Objetivo: Devuelve la categor\u00eda seleccionada (o \u201cSin Dato\u201d si est\u00e1 en blanco) a partir de FACT_UNIDADES.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(SELECTEDVALUE('Transversal FACT_UNIDADES'[CATEGORIA_SABER11]))\nreturn IF(ISBLANK(dev), \"Sin Dato\", dev)\n</code></pre></li> <li>Formato: Texto.</li> </ul> </li> <li> <p>Porcentaje de efectividad en las cotizaciones Fomento empresarial-I7404 </p> <ul> <li>Objetivo: Retorna el valor de la medida [% efectividad en las cotizaciones Fomento empresarial] (definida externamente).  </li> <li>Expresi\u00f3n DAX: <pre><code>[% efectividad en las cotizaciones Fomento empresarial]\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Ingresos ejecutados / Ingresos presupuestados </p> <ul> <li>Objetivo: Calcula la relaci\u00f3n entre los ingresos ejecutados (por prestaci\u00f3n de servicios) y los ingresos presupuestados.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = DIVIDE(\n   [Valor de los ingresos percibidos por la prestaci\u00f3n de servicios (Ingresos ejecutados)],\n   CALCULATE(SUM('Transversal FACT_FINANCIERA'[INGRESOS]), 'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"PRESUPUESTO_CONTABLE\"),\n   0\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico (relaci\u00f3n).</li> </ul> </li> <li> <p>#Empresas que compran servicios de fomento empresarial </p> <ul> <li>Objetivo: Cuenta el n\u00famero de empresas (ID_EMPRESA) que compran servicios de fomento empresarial, filtrando seg\u00fan condiciones espec\u00edficas (unidad 3, actividad \"FACTURACION\").  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[ID_EMPRESA]),\n   'Transversal FACT_ACTIVIDADES'[ID_EMPRESA] &lt;&gt; -1,\n   'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 3,\n   'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"FACTURACION\"\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>\u00edndice de resultados para el plantel educativo </p> <ul> <li>Objetivo: Valor fijo; en este caso se establece en 0.  </li> <li>Expresi\u00f3n DAX: <pre><code>0\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>#Afiliados atendidos por Proteccion Social </p> <ul> <li>Objetivo: Cuenta los afiliados atendidos en programas de protecci\u00f3n social (para la unidad 4).  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[ID_AFILIADO]),\n   'Transversal FACT_ACTIVIDADES'[ID_AFILIADO] &lt;&gt; -1,\n   'Transversal FACT_ACTIVIDADES'[ID_UNIDAD] = 4\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Cobertura para Empleados de la Caja de Compensacion en programas de educacion </p> <ul> <li>Objetivo: Calcula la cobertura ejecutada para empleados de la Caja (filtrando por PARTNER_EMPRESA = \"0060007786\").  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE([Cobertura ejecutada], 'Transversal FACT_ACTIVIDADES'[PARTNER_EMPRESA] = \"0060007786\")\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Porcentaje de afiliados atendidos respecto al total atendido (Protecci\u00f3n Social) </p> <ul> <li>Objetivo: Calcula el porcentaje de afiliados atendidos en protecci\u00f3n social en relaci\u00f3n al total de afiliados (medida [#Afiliados atendidos por Proteccion Social] / [# Afiliados Caja]).  </li> <li>Expresi\u00f3n DAX: <pre><code>[#Afiliados atendidos por Proteccion Social] / [# Afiliados Caja]\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Porcentaje de poblaci\u00f3n FOSFEC respecto al total atendido (Desarrollo Empresarial) </p> <ul> <li>Objetivo: Calcula el porcentaje de la poblaci\u00f3n FOSFEC atendida en Desarrollo Empresarial, utilizando filtros sobre la actividad \"FACTURACION\" y categor\u00edas espec\u00edficas.  </li> <li>Expresi\u00f3n DAX: Utiliza variables para contar poblaci\u00f3n FOSFEC y total, y luego DIVIDE.  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Cobertura proyectada </p> <ul> <li>Objetivo: Suma la poblaci\u00f3n proyectada de la unidad educativa (a partir de FACT_UNIDADES, para ORIGEN \"FACT_SABER11_INDIVIDUAL\").  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   SUM('Transversal FACT_UNIDADES'[POBLACION_PROYECTADA]),\n   'Transversal FACT_UNIDADES'[ORIGEN] = \"FACT_SABER11_INDIVIDUAL\"\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Movilidad academica </p> <ul> <li>Objetivo: Devuelve el valor de [# Estudiantes activos] (mismo valor).  </li> <li>Expresi\u00f3n DAX: <pre><code>[# Estudiantes activos]\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Nivel se satisfacci\u00f3n a partir de la NSU promedio </p> <ul> <li>Objetivo: Calcula el promedio de la NSU (calificaciones de satisfacci\u00f3n) a partir de FACT_EVALUACION_DOCENTE.  </li> <li>Expresi\u00f3n DAX: Utiliza AVERAGEX con manejo de errores.  </li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Promotores promedio del proceso  a partir de la NSU </p> <ul> <li>Objetivo: Calcula la proporci\u00f3n de usuarios con NSU \u2265 9 sobre el total de NSU, midiendo el promedio de promotores.  </li> <li>Expresi\u00f3n DAX: Usa variables Total y Promotores y realiza la divisi\u00f3n.  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Cantidad de matriculas </p> <ul> <li>Objetivo: Cuenta las matriculaciones aprobadas (ACTIVIDAD \"ESTADO_MATRICULAS\" con ESTADO \"APROBADA\").  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   COUNTROWS('Transversal FACT_ACTIVIDADES'),\n   'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\",\n   'Transversal FACT_ACTIVIDADES'[ESTADO] = \"APROBADA\"\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Valor del subsidio a la demanda a partir de las transacciones realizadas por los afiliados </p> <ul> <li>Objetivo: Devuelve el valor de subsidio a la demanda; es una referencia a la medida \u201cValor de subsidio  a la demanda\u201d.  </li> <li>Expresi\u00f3n DAX: <pre><code>[Valor de subsidio  a la demanda]\n</code></pre></li> <li>Formato: Moneda.</li> </ul> </li> <li> <p>Numero de transacciones de afiliados con categoria A y B </p> <ul> <li>Objetivo: Cuenta el n\u00famero de transacciones de afiliados que cumplen con categor\u00edas A y B, seg\u00fan la l\u00f3gica definida en la consulta (usando COUNTROWS).  </li> <li>Expresi\u00f3n DAX: Utiliza COUNTROWS y filtros en CATEGORIA_VENTA.</li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Resultado del ejercicio / Resultado presupuestado </p> <ul> <li>Objetivo: Calcula la relaci\u00f3n entre el resultado del ejercicio y el resultado presupuestado a partir de FACT_FINANCIERA.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   SUM('Transversal FACT_FINANCIERA'[RESULTADO_EJERCICIO]),\n   'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"EJECUCION_CONTABLE\"\n) /\nCALCULATE(\n   SUM('Transversal FACT_FINANCIERA'[RESULTADO_EJERCICIO]),\n   'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"PRESUPUESTO_CONTABLE\"\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Relaci\u00f3n num\u00e9rica.</li> </ul> </li> <li> <p>Valor de los ingresos percibidos por la prestaci\u00f3n de servicios (Ingresos ejecutados) </p> <ul> <li>Objetivo: Suma los ingresos ejecutados a partir de FACT_FINANCIERA para la actividad \"EJECUCION_CONTABLE\".  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   SUM('Transversal FACT_FINANCIERA'[INGRESOS]),\n   'Transversal FACT_FINANCIERA'[ACTIVIDAD] = \"EJECUCION_CONTABLE\"\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Moneda.</li> </ul> </li> <li> <p>Porcentaje de estudiantes de la JEC que desertan de la Instituci\u00f3n Educativa </p> <ul> <li>Objetivo: Calcula el porcentaje de estudiantes que desertan (retirados) en la JEC, basado en actividades espec\u00edficas.  </li> <li>Expresi\u00f3n DAX: Utiliza variables para contar deserciones y total de alumnos, y luego divide.</li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Porcentaje de estudiantes de AIPI que desertan de la Institucion Educativa </p> <ul> <li>Objetivo: Similar a la medida anterior pero para AIPI.</li> <li>Expresi\u00f3n DAX: Uso de variables y divisi\u00f3n.</li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Desercion temprana de FOSFEC </p> <ul> <li>Objetivo: Cuenta el n\u00famero de deserciones tempranas seg\u00fan la actividad \"INASISTENCIA_FOSFEC\".  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = CALCULATE(\n   DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n   'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"INASISTENCIA_FOSFEC\"\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p># horas contratadas </p> <ul> <li>Objetivo: Suma las horas contratadas mensualmente (para el concepto \"CONTRATACION\") en FACT_PERSONAL.  </li> <li>Expresi\u00f3n DAX: Utiliza SUM sobre HORAS_CONTRATADAS_MENSUAL con filtro.</li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Reductores de capacidad contratada </p> <ul> <li>Objetivo: Suma las horas correspondientes a ausentismo o reemplazos (que reducen la capacidad contratada).  </li> <li>Expresi\u00f3n DAX: Suma de HORAS_CONTRATADAS_MENSUAL para conceptos \"AUSENTISMO\" o \"REEMPLAZO\".</li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>% real de tiempo administrativo </p> <ul> <li>Objetivo: Calcula el porcentaje real de tiempo administrativo utilizando la f\u00f3rmula:   (0.3 * [# horas contratadas] - [# Horas empleadas en cubrir ausencias]) / [# horas contratadas].  </li> <li>Expresi\u00f3n DAX: Basada en la divisi\u00f3n de esa diferencia.</li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p># Horas empleadas en cubrir ausencias </p> <ul> <li>Objetivo: Suma las horas empleadas en cubrir ausencias (para el concepto \"REEMPLAZO\").  </li> <li>Expresi\u00f3n DAX: <pre><code>IF(\n   ISBLANK(\n      CALCULATE(\n         SUM('Transversal FACT_PERSONAL'[HORAS_CONTRATADAS_MENSUAL]),\n         'Transversal FACT_PERSONAL'[CONCEPTO] = \"REEMPLAZO\"\n      )\n   ),\n   -1,\n   CALCULATE(\n      SUM('Transversal FACT_PERSONAL'[HORAS_CONTRATADAS_MENSUAL]),\n      'Transversal FACT_PERSONAL'[CONCEPTO] = \"REEMPLAZO\"\n   )\n)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>% Utilizaci\u00f3n de las bibliotecas virtuales </p> <ul> <li>Objetivo: Calcula el porcentaje de uso de bibliotecas virtuales comparando el conteo de usuarios de \"BIBLIOTECA_VIRTUAL\" con el de \"ESTADO_MATRICULAS\" (para la unidad 1).  </li> <li>Expresi\u00f3n DAX: <pre><code>var personas_biblioteca = CALCULATE(\n    DISTINCTCOUNTNOBLANK('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"BIBLIOTECA_VIRTUAL\"\n)\nvar personas_total = CALCULATE(\n    DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]),\n    'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"ESTADO_MATRICULAS\",\n    'Transversal DIM_CAPACIDAD_FISICA'[ID_UNIDAD] = 1\n)\nvar dev = personas_biblioteca / personas_total\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Inversiones en la infraestructura f\u00edsica </p> <ul> <li>Objetivo: Suma los ingresos correspondientes a inversiones en infraestructura f\u00edsica (filtrando por cuentas que comienzan con \"1516\").  </li> <li>Expresi\u00f3n DAX: Utiliza SUM con filtro sobre FACT_FINANCIERA.</li> <li>Formato: Moneda.</li> </ul> </li> <li> <p>Inversion en infraestructura tecnologica </p> <ul> <li>Objetivo: Suma los ingresos correspondientes a inversiones en infraestructura tecnol\u00f3gica (cuentas que comienzan con \"1528\").  </li> <li>Expresi\u00f3n DAX: Similar a la medida anterior.</li> <li>Formato: Moneda.</li> </ul> </li> <li> <p>% Rotaci\u00f3n de la planta Total </p> <ul> <li>Objetivo: Calcula la rotaci\u00f3n de personal mediante la diferencia entre contrataciones e ingresos y retiros, sobre el total de contrataciones.  </li> <li>Expresi\u00f3n DAX: <pre><code>var Ingresos = CALCULATE(count('Transversal FACT_PERSONAL'[ID_PERSONAL]), 'Transversal FACT_PERSONAL'[CONCEPTO] = \"CONTRATACION\")\nvar Retiros = CALCULATE(count('Transversal FACT_PERSONAL'[ID_PERSONAL]), 'Transversal FACT_PERSONAL'[CONCEPTO] = \"FIN_CONTRATACION\")\nvar dev = (Ingresos - Retiros) / Ingresos\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>% de Estudiantes matriculados con documentos completos del total de matriculados </p> <ul> <li>Objetivo: Calcula el porcentaje de estudiantes que cuentan con documentos completos (seg\u00fan FACT_UNIDADES).  </li> <li>Expresi\u00f3n DAX: Divide el n\u00famero de estudiantes con documentos completos entre el total de estudiantes.</li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>% de afiliados beneficiados desde PS respecto a la poblaci\u00f3n impactada de PS </p> <ul> <li>Objetivo: Calcula la proporci\u00f3n de afiliados beneficiados en protecci\u00f3n social en relaci\u00f3n al total atendido en PS.  </li> <li>Expresi\u00f3n DAX: <pre><code>[#Afiliados atendidos por Proteccion Social] / [# Afiliados Caja]\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>% Empresas Atendidas </p> <ul> <li>Objetivo: Calcula el porcentaje de empresas atendidas comparando el n\u00famero de empresas atendidas con el total de empresas afiliadas.  </li> <li>Expresi\u00f3n DAX: Utiliza DIVIDE sobre el conteo de empresas atendidas y el total.</li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>% afiliados por educacion </p> <ul> <li>Objetivo: Relaciona el n\u00famero de afiliados atendidos con el total de afiliados en caja.  </li> <li>Expresi\u00f3n DAX: <pre><code>[#Afiliados_Atendidos] / [# Afiliados Caja]\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>% Beneficiarios Atendidos </p> <ul> <li>Objetivo: Calcula el porcentaje de beneficiarios atendidos respecto al total de beneficiarios en caja; devuelve -1 si el denominador es cero.  </li> <li>Expresi\u00f3n DAX: <pre><code>[#Beneficiarios_Atendidos] / [# Beneficiarios Caja]\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>N\u00famero de iniciativas </p> <ul> <li>Objetivo: Suma el resultado de las iniciativas (desde FACT_UNIDADES para ACTIVIDAD \"INICIATIVAS\").  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = SUMX(\n    FILTER('Transversal FACT_UNIDADES', 'Transversal FACT_UNIDADES'[ACTIVIDAD] = \"INICIATIVAS\"),\n    VALUE('Transversal FACT_UNIDADES'[RESULTADO])\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>% evaluaciones por debajo del promedio </p> <ul> <li>Objetivo: Calcula el porcentaje de evaluaciones de docentes por debajo del promedio.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = COUNTROWS('Transversal FACT_EVALUACION_DOCENTE') \n   / COUNTROWS('Transversal FACT_EVALUACION_DOCENTE')\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre> (La l\u00f3gica completa incluye un COUNTROWS filtrado por calificaciones menores al promedio.) </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Incremento del % de rentabilidad del servicio sin fomento al empleo </p> <ul> <li>Objetivo: Valor fijo de 0.8.  </li> <li>Expresi\u00f3n DAX: <pre><code>0.8\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Nivel de ejecuci\u00f3n del fondo JEC </p> <ul> <li>Objetivo: Calcula el nivel de ejecuci\u00f3n del fondo JEC usando resultados de FACT_FINANCIERA para cuentas espec\u00edficas (ID_CUENTA en {941, 953} y AREA \"JORNADA ESCOLAR COMPLEMENTARIA\").  </li> <li>Expresi\u00f3n DAX: Utiliza CALCULATE sobre el resultado dividido por el presupuestado.  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Nivel de ejecuci\u00f3n del fondo PAIPI </p> <ul> <li>Objetivo: Similar a la medida anterior pero para AREA \"ATENCION INTEGRAL A LA NINEZ\".  </li> <li>Expresi\u00f3n DAX: An\u00e1loga a la medida para JEC.  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Atencion usuarios de los programas de proteccion social </p> <ul> <li>Objetivo: Devuelve el valor de la medida [#Afiliados atendidos por Proteccion Social].  </li> <li>Expresi\u00f3n DAX: <pre><code>[#Afiliados atendidos por Proteccion Social]\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Evaluaci\u00f3n de la Pertinencia del Dise\u00f1o Curricular por el Sector Productivo </p> <ul> <li>Objetivo: Calcula el promedio de evaluaciones para el dise\u00f1o curricular (desde FACT_UNIDADES para ACTIVIDAD \"EVALUACION DISENO CURRICULAR\").  </li> <li>Expresi\u00f3n DAX: Utiliza AVERAGEX.  </li> <li>Formato: Num\u00e9rico o Texto (seg\u00fan resultado).</li> </ul> </li> <li> <p>% efectividad en las cotizaciones Fomento empresarial </p> <ul> <li>Objetivo: Retorna la efectividad en las cotizaciones para fomento empresarial.  </li> <li>Expresi\u00f3n DAX: Referencia a la medida externa [% efectividad en las cotizaciones Fomento empresarial].  </li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Productividad del portafolio de desarrollo empresarial </p> <ul> <li>Objetivo: Calcula la productividad dividiendo [# Servicios vendidos] entre [# Servicios ofertados] para la unidad 3.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = [# Servicios vendidos] / [# Servicios ofertados]\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Cantidad de poblaci\u00f3n FOSFEC atendida por Desarrollo Empresarial </p> <ul> <li>Objetivo: Valor fijo de 0 (sin datos asignados).  </li> <li>Expresi\u00f3n DAX: <pre><code>0\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Numero de aportes de empresas atendidas por Educaci\u00f3n </p> <ul> <li>Objetivo: Devuelve el valor de la medida [# Aportes Totales].  </li> <li>Expresi\u00f3n DAX: <pre><code>[# Aportes Totales]\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Atenci\u00f3n poblaci\u00f3n vulnerable </p> <ul> <li>Objetivo: Calcula la atenci\u00f3n a la poblaci\u00f3n vulnerable aplicando filtros en FACT_ACTIVIDADES seg\u00fan criterios de vulnerabilidad.  </li> <li>Expresi\u00f3n DAX: Utiliza CALCULATE con REMOVEFILTERS y condiciones espec\u00edficas.</li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>% accidentalidad de la poblaci\u00f3n estudiantil </p> <ul> <li>Objetivo: Calcula la proporci\u00f3n de accidentalidad (casos de ENFERMERIA) sobre la cantidad total de estudiantes matriculados en la unidad 1.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = DIVIDE(\n   DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]) where ACTIVIDAD=\"ENFERMERIA\",\n   DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]) where ACTIVIDAD=\"ESTADO_MATRICULAS\" and unit=1,\n   0\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>% Estudiantes matriculados con documentos completos del total de matriculados </p> <ul> <li>Objetivo: Retorna la medida ya definida para el porcentaje de estudiantes con documentos completos.  </li> <li>Expresi\u00f3n DAX: <pre><code>[% de Estudiantes matriculados con documentos completos del total de matriculados]\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Detractores promedio del proceso a partir de la NSU </p> <ul> <li>Objetivo: Calcula la proporci\u00f3n de detractores (usuarios NSU con calificaci\u00f3n &lt; 7) respecto al total, para medir la insatisfacci\u00f3n.  </li> <li>Expresi\u00f3n DAX: Usa variables para detractores y total NSU.</li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>%Afiliados Atendidos </p> <ul> <li>Objetivo: Calcula el porcentaje de afiliados atendidos respecto al total de afiliados en caja.  </li> <li>Expresi\u00f3n DAX: <pre><code>[#Afiliados_Atendidos] / [# Afiliados Caja]\n</code></pre></li> <li>Formato: Porcentaje.</li> </ul> </li> <li> <p>Resuldato NPS </p> <ul> <li>Objetivo: Calcula el promedio de las calificaciones NSU, representando el Net Promoter Score.  </li> <li>Expresi\u00f3n DAX: <pre><code>var dev = AVERAGEX(\n   FILTER('Transversal FACT_ACTIVIDADES', 'Transversal FACT_ACTIVIDADES'[CALIFICACION] &lt;&gt; BLANK()),\n   IFERROR(VALUE('Transversal FACT_ACTIVIDADES'[CALIFICACION]), 0)\n)\nreturn IF(ISBLANK(dev), -1, dev)\n</code></pre></li> <li>Formato: Num\u00e9rico.</li> </ul> </li> <li> <p>Variacion desercion respecto vigencia anterior </p> <ul> <li>Objetivo: Calcula la variaci\u00f3n porcentual de deserciones entre el per\u00edodo actual y el anterior, utilizando fechas y conteos de RETIROS.  </li> <li>Expresi\u00f3n DAX: Usa variables para obtener fechas m\u00ednimas y m\u00e1ximas, calcular retiros y luego la variaci\u00f3n.</li> <li>Formato: Porcentaje.</li> </ul> </li> </ol>"},{"location":"03.Cubo/01.Origen/#proposito_1","title":"Prop\u00f3sito","text":"<p>1. Proveer c\u00e1lculos espec\u00edficos como conteos, sumas y agregaciones sobre datos transversales.</p> <p>2. Facilitar m\u00e9tricas clave como n\u00famero de unidades, afiliados, beneficiarios y aportes.</p> <p>3. Apoyar an\u00e1lisis avanzados eliminando restricciones de filtros seg\u00fan sea necesario.</p> <p>4. Generar informaci\u00f3n valiosa para la toma de decisiones estrat\u00e9gicas y operativas.</p>"},{"location":"03.Cubo/02.Tablas%20copy/","title":"02.Tablas copy","text":""},{"location":"03.Cubo/02.Tablas%20copy/#tablas","title":"Tablas","text":""},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-dim_unidad","title":"Tabla: Transversal DIM_UNIDAD","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_UNIDAD es una dimensi\u00f3n que define las unidades organizacionales o funcionales del sistema. Esta tabla es fundamental para categorizar y segmentar datos relacionados con las actividades y procesos empresariales.</p> <p></p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla","title":"Estructura de la Tabla","text":"<p>1. Nombre de la Tabla: <code>Transversal DIM_UNIDAD</code>.</p> <p>2. Columnas:</p> <ul> <li>ID_UNIDAD:<ul> <li>Tipo de Datos: <code>int64</code>.</li> <li>Descripci\u00f3n: Identificador \u00fanico de cada unidad.</li> <li>Columna Fuente: <code>ID_UNIDAD</code>.</li> </ul> </li> <li>UNIDAD:<ul> <li>Tipo de Datos: <code>string</code>.</li> <li>Descripci\u00f3n: Nombre descriptivo de la unidad.</li> <li>Columna Fuente: <code>UNIDAD</code>.</li> </ul> </li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#particiones","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos de la tabla).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_UNIDAD = Source{[Schema=\"Transversal\", Item=\"DIM_UNIDAD\"]}[Data]\nin\n    Transversal_DIM_UNIDAD\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_UNIDAD se utiliza para:</p> <ul> <li>Proveer una referencia jer\u00e1rquica o categ\u00f3rica para an\u00e1lisis y segmentaciones.</li> <li>Establecer relaciones con otras tablas, como hechos o medidas, en el modelo sem\u00e1ntico del cubo.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#relacion-con-el-cubo","title":"Relaci\u00f3n con el Cubo","text":"<p>Esta tabla se integra con otras dimensiones y hechos para calcular medidas como: - N\u00famero de actividades por unidad. - Rendimiento de procesos espec\u00edficos.</p> <p>Entendido, aqu\u00ed est\u00e1 la documentaci\u00f3n ajustada con la numeraci\u00f3n en negritas dentro del formato Markdown:</p>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-dim_tiempo_mensual","title":"Tabla: Transversal DIM_TIEMPO_MENSUAL","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_TIEMPO_MENSUAL es una dimensi\u00f3n de tiempo que permite segmentar los datos en diferentes niveles temporales, como d\u00edas, semanas, meses, bimestres, trimestres, cuatrimestres, semestres y a\u00f1os. Proporciona una estructura detallada para an\u00e1lisis cronol\u00f3gicos.</p> <p></p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_1","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA FECHA dateTime FECHA DESC_FECHA string DESC_FECHA ID_SEMANA int64 ID_SEMANA DESC_SEMANA string DESC_SEMANA ID_NO_MES int64 ID_NO_MES DESC_NO_MES string DESC_NO_MES ID_MES int64 ID_MES DESC_MES string DESC_MES DESC_MES_CORTA string DESC_MES_CORTA ID_BIMESTRE int64 ID_BIMESTRE DESC_BIMESTRE string DESC_BIMESTRE ID_TRIMESTRE int64 ID_TRIMESTRE DESC_TRIMESTRE string DESC_TRIMESTRE ID_CUATRIMESTRE int64 ID_CUATRIMESTRE DESC_CUATRIMESTRE string DESC_CUATRIMESTRE ID_SEMESTRE int64 ID_SEMESTRE DESC_SEMESTRE string DESC_SEMESTRE ID_ANIO int64 ID_ANIO ID_ANIO_ANT int64 ID_ANIO_ANT NUM_DIA_SEMANA int64 NUM_DIA_SEMANA FESTIVO int64 FESTIVO FECHA_CORTA dateTime FECHA_CORTA"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_1","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:       <pre><code>let\n      Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n      Transversal_DIM_TIEMPO_MENSUAL = Source{[Schema=\"Transversal\",Item=\"DIM_TIEMPO_MENSUAL\"]}[Data]\nin\n      Transversal_DIM_TIEMPO_MENSUAL\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_1","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_TIEMPO_MENSUAL se utiliza para:</p> <ul> <li>Segmentar datos en intervalos de tiempo espec\u00edficos.</li> <li>Proporcionar jerarqu\u00edas temporales para an\u00e1lisis (d\u00eda, semana, mes, bimestre, trimestre, cuatrimestre, semestre y a\u00f1o).</li> <li>Relacionar datos temporales con otras dimensiones y hechos para an\u00e1lisis detallados.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-dim_categoria","title":"Tabla: Transversal DIM_CATEGORIA","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_CATEGORIA define las categor\u00edas utilizadas en el modelo para clasificar datos. Esta dimensi\u00f3n permite agrupar y segmentar informaci\u00f3n relacionada con diferentes \u00e1reas del sistema.</p> <p></p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_2","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente COD_CATEGORIA string COD_CATEGORIA DESCRIPCION string DESCRIPCION"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_2","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_CATEGORIA = Source{[Schema=\"Transversal\",Item=\"DIM_CATEGORIA\"]}[Data]\nin\n    Transversal_DIM_CATEGORIA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_2","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_CATEGORIA se utiliza para:</p> <ul> <li>Clasificar informaci\u00f3n en grupos o categor\u00edas predefinidas.</li> <li>Relacionar datos categorizados con otras dimensiones y hechos para an\u00e1lisis m\u00e1s detallados.</li> <li>Facilitar la segmentaci\u00f3n de datos en reportes y consultas.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-fact_actividades","title":"Tabla: Transversal FACT_ACTIVIDADES","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_ACTIVIDADES registra informaci\u00f3n detallada sobre las actividades realizadas por afiliados y empresas, incluyendo datos demogr\u00e1ficos, econ\u00f3micos, y sobre aportes. Esta tabla es clave para el an\u00e1lisis de hechos y m\u00e9tricas relacionadas con las actividades.</p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_3","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente PARTNER string PARTNER ID_EMPRESA int64 ID_EMPRESA ID_AFILIADO int64 ID_AFILIADO ID_TIPO_AFILIADO int64 ID_TIPO_AFILIADO TIPO_AFILIADO string TIPO_AFILIADO ID_CATEGORIA int64 ID_CATEGORIA FECHA_AFILIACION dateTime FECHA_AFILIACION FECHA_RETIRO dateTime FECHA_RETIRO ID_GENERO int64 ID_GENERO ID_ESTADO_CIVIL int64 ID_ESTADO_CIVIL ID_PERTENENCIA_ETNICA int64 ID_PERTENENCIA_ETNICA ID_FACTOR_VULNERABILIDAD int64 ID_FACTOR_VULNERABILIDAD ESTRATO int64 ESTRATO ID_CIUDAD int64 ID_CIUDAD SALARIO_BASICO double SALARIO_BASICO FECHA_MENSUAL dateTime FECHA_MENSUAL ID_FECHA int64 ID_FECHA ID_UNIDAD int64 ID_UNIDAD ESTADOREGISTRO string ESTADOREGISTRO PARTNER_AFILIADO string PARTNER_AFILIADO PARTNER_EMPRESA string PARTNER_EMPRESA TIPO_POBLACION string TIPO_POBLACION ACTIVIDAD string ACTIVIDAD TOTAL_APORTES double TOTAL_APORTES NUMERO_APORTES int64 NUMERO_APORTES"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_3","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_ACTIVIDADES = Source{[Schema=\"Transversal\",Item=\"FACT_ACTIVIDADES\"]}[Data]\nin\n    Transversal_FACT_ACTIVIDADES\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_3","title":"Prop\u00f3sito","text":"<p>La tabla FACT_ACTIVIDADES se utiliza para:</p> <ul> <li>Analizar informaci\u00f3n demogr\u00e1fica, econ\u00f3mica y de aportes de afiliados y empresas.</li> <li>Calcular m\u00e9tricas relacionadas con actividades y aportes.</li> <li>Proveer datos detallados para informes y an\u00e1lisis multidimensionales.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-fact_personal","title":"Tabla: Transversal FACT_PERSONAL","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_PERSONAL almacena informaci\u00f3n relacionada con el personal, sus asignaciones y las horas contratadas. Es \u00fatil para el an\u00e1lisis de recursos humanos y la planificaci\u00f3n operativa.</p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_4","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA ID_PERSONAL int64 ID_PERSONAL NOMBRE string NOMBRE CONCEPTO string CONCEPTO DESCRIPCION string DESCRIPCION FECHA_FIN dateTime FECHA_FIN HORAS_CONTRATADAS_MENSUAL int64 HORAS_CONTRATADAS_MENSUAL ID_UNIDAD int64 ID_UNIDAD"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_4","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_PERSONAL = Source{[Schema=\"Transversal\",Item=\"FACT_PERSONAL\"]}[Data]\nin\n    Transversal_FACT_PERSONAL\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_4","title":"Prop\u00f3sito","text":"<p>La tabla FACT_PERSONAL se utiliza para:</p> <ul> <li>Analizar las asignaciones y contratos del personal.</li> <li>Monitorear las horas contratadas mensualmente.</li> <li>Relacionar los datos del personal con otras dimensiones para informes y planificaci\u00f3n estrat\u00e9gica.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-fact_financiera","title":"Tabla: Transversal FACT_FINANCIERA","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_FINANCIERA contiene informaci\u00f3n detallada sobre los datos financieros de la organizaci\u00f3n, incluyendo cuentas, ingresos, gastos, y resultados. Es una fuente fundamental para el an\u00e1lisis financiero y la generaci\u00f3n de informes.</p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_5","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA ID_ANIO int64 ID_ANIO ID_MES int64 ID_MES ID_CEBE string ID_CEBE CEBE string CEBE DESCRIPCION_CEBE string DESCRIPCION_CEBE DEPARTAMENTO string DEPARTAMENTO AREA string AREA SUBAREA string SUBAREA SEGMENTO string SEGMENTO DESCRIPCION_SEGMENTO string DESCRIPCION_SEGMENTO CODIGO_SSF int64 CODIGO_SSF NOMBRE_SSF string NOMBRE_SSF ID_CUENTA string ID_CUENTA CUENTA string CUENTA CUENTA_HOMOLOGA string CUENTA_HOMOLOGA DESCRIPCION string DESCRIPCION TIPO_CUENTA string TIPO_CUENTA TIPO_OPERACION string TIPO_OPERACION GRUPO_CUENTA string GRUPO_CUENTA SUBGRUPO_CUENTA string SUBGRUPO_CUENTA GRUPO_OPERACION string GRUPO_OPERACION CUENTA_SSF string CUENTA_SSF DESCRIPCION_SSF string DESCRIPCION_SSF CUENTA_DESCRIPCION string CUENTA_DESCRIPCION CUENTA_DESCRIPCION_SSF string CUENTA_DESCRIPCION_SSF SIGNO_INGRESOS int64 SIGNO_INGRESOS CLASIFICACION int64 CLASIFICACION SEGMENT string SEGMENT IMPORTE int64 IMPORTE INGRESOS int64 INGRESOS INGRESOS_OPERACIONALES int64 INGRESOS_OPERACIONALES GASTOS int64 GASTOS GASTOS_OPERACIONALES int64 GASTOS_OPERACIONALES GASTOS_OPERACIONALES_ADMIN int64 GASTOS_OPERACIONALES_ADMIN RESULTADO_EJERCICIO int64 RESULTADO_EJERCICIO COSTOS int64 COSTOS ACTIVO int64 ACTIVO PASIVO int64 PASIVO PATRIMONIO int64 PATRIMONIO GASTOS_CON_DISTRIBUCION int64 GASTOS_CON_DISTRIBUCION GASTOS_SIN_DISTRIBUCION int64 GASTOS_SIN_DISTRIBUCION"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_5","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_FINANCIERA = Source{[Schema=\"Transversal\",Item=\"FACT_FINANCIERA\"]}[Data]\nin\n    Transversal_FACT_FINANCIERA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_5","title":"Prop\u00f3sito","text":"<p>La tabla FACT_FINANCIERA se utiliza para:</p> <ul> <li>Analizar el comportamiento financiero de la organizaci\u00f3n.</li> <li>Evaluar ingresos, gastos, costos, y resultados financieros.</li> <li>Relacionar los datos financieros con otras dimensiones para an\u00e1lisis multidimensionales y generaci\u00f3n de informes detallados.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-transversal-fact_evaluacion_docente","title":"Tabla: Transversal FACT_EVALUACION_DOCENTE","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_EVALUACION_DOCENTE almacena informaci\u00f3n relacionada con las evaluaciones acad\u00e9micas de los docentes, incluyendo calificaciones definitivas, per\u00edodos acad\u00e9micos y datos personales. Es clave para el an\u00e1lisis del desempe\u00f1o docente.</p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_6","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente PERIODO_ACADEMICO string PERIODO_ACADEMICO ID_UNIDAD int64 ID_UNIDAD ID_PERSONAL int64 ID_PERSONAL NOMBRE_DOCENTE string NOMBRE_DOCENTE CALIFICACION_DEFINITIVA string CALIFICACION_DEFINITIVA ID_FECHA int64 ID_FECHA"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_6","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_EVALUACION_DOCENTE = Source{[Schema=\"Transversal\",Item=\"FACT_EVALUACION_DOCENTE\"]}[Data]\nin\n    Transversal_FACT_EVALUACION_DOCENTE\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_6","title":"Prop\u00f3sito","text":"<p>La tabla FACT_EVALUACION_DOCENTE se utiliza para:</p> <ul> <li>Analizar el desempe\u00f1o acad\u00e9mico de los docentes.</li> <li>Generar informes de calificaciones definitivas por per\u00edodo acad\u00e9mico.</li> <li>Relacionar datos de evaluaci\u00f3n docente con otras dimensiones como unidades y fechas.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#tabla-calculatedtableindicadores","title":"Tabla: CalculatedTableIndicadores","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>La tabla CalculatedTableIndicadores es una tabla calculada que contiene indicadores clave para el an\u00e1lisis y evaluaci\u00f3n del rendimiento en diversas \u00e1reas, como cobertura, movilidad acad\u00e9mica, promoci\u00f3n, deserci\u00f3n, matr\u00edculas, graduados, y satisfacci\u00f3n.</p> <p></p>"},{"location":"03.Cubo/02.Tablas%20copy/#estructura-de-la-tabla_7","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente indicador string (calculada) [indicador]"},{"location":"03.Cubo/02.Tablas%20copy/#particiones_7","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>CalculatedTable 1</code>.</p> <p>2. Fuente:</p> <ul> <li>Tipo: <code>calculated</code>.</li> <li>Expresi\u00f3n:      <pre><code>DATATABLE (\n    \"indicador\", STRING, \n    { \n        {\"Cumplimiento Cobertura\"},\n        {\"Cobertura Proyectada\"},\n        {\"Movilidad Academica\"},\n        {\"Porcentaje de Promoci\u00f3n\"},\n        {\"Porcentaje de Deserci\u00f3n\"},\n        {\"Cantidad de Matr\u00edculas\"},\n        {\"Cantidad de Graduados\"},\n        {\"Cantidad de PQRs\"},\n        {\"Nivel de satisfacci\u00f3n a partir de la NSU promedio\"},\n        {\"Promotores promedio del Proceso a partir de la NSU\"},\n        {\"Detractores promedio del Proceso a partir de la NSU\"}\n    }\n)\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito_7","title":"Prop\u00f3sito","text":"<p>La tabla CalculatedTableIndicadores se utiliza para:</p> <ul> <li>Listar y categorizar indicadores clave para el an\u00e1lisis.</li> <li>Servir como base para reportes y consultas espec\u00edficas relacionadas con la evaluaci\u00f3n del desempe\u00f1o.</li> <li>Proveer una visi\u00f3n consolidada de los indicadores m\u00e1s relevantes para la organizaci\u00f3n.</li> </ul>"},{"location":"03.Cubo/02.Tablas%20copy/#relaciones-del-modelo","title":"Relaciones del Modelo","text":""},{"location":"03.Cubo/02.Tablas%20copy/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Las relaciones definen c\u00f3mo las tablas del modelo interact\u00faan entre s\u00ed, asegurando la coherencia y la integridad de los datos en los an\u00e1lisis. A continuaci\u00f3n se detallan las relaciones establecidas entre las tablas del modelo.</p> Nombre Tabla Origen Columna Origen Tabla Destino Columna Destino e8e7ee5e-2bb5-447c-8a42-40fa4ccf9143 Transversal FACT_ACTIVIDADES ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 1a8196d0-09e6-4d0c-9f29-4a8d0ff4ee13 Transversal FACT_ACTIVIDADES ID_CATEGORIA Transversal DIM_CATEGORIA COD_CATEGORIA e4a99626-9ef6-4da8-89db-664ec2a6d8c8 Transversal FACT_ACTIVIDADES ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 395ef55c-3800-4448-bc48-46690276bd39 Transversal FACT_PERSONAL ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA cdfe13d4-3917-431a-b0c9-b496df147a20 Transversal FACT_PERSONAL ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD a8efdf32-e907-42ab-a950-937906c7b167 Transversal FACT_EVALUACION_DOCENTE ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 632bc53c-67b6-4634-82f9-8adbfc71e691 Transversal FACT_EVALUACION_DOCENTE ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 7246e8e1-e2c3-4a17-89eb-c077680b0f6b Transversal FACT_FINANCIERA ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA"},{"location":"03.Cubo/02.Tablas%20copy/#diagrama-de-relaciones-y-tablas","title":"Diagrama de Relaciones y Tablas","text":"<p>A continuaci\u00f3n, se presenta el diagrama de relaciones del modelo utilizando formato Mermaid para visualizar las conexiones entre tablas y sus relaciones:</p> <pre><code>graph TD\n    FACT_ACTIVIDADES[Transversal FACT_ACTIVIDADES]\n    FACT_PERSONAL[Transversal FACT_PERSONAL]\n    FACT_FINANCIERA[Transversal FACT_FINANCIERA]\n    FACT_EVALUACION_DOCENTE[Transversal FACT_EVALUACION_DOCENTE]\n    DIM_UNIDAD[Transversal DIM_UNIDAD]\n    DIM_CATEGORIA[Transversal DIM_CATEGORIA]\n    DIM_TIEMPO[Transversal DIM_TIEMPO_MENSUAL]\n\n    FACT_ACTIVIDADES --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_ACTIVIDADES --&gt; DIM_CATEGORIA[ID_CATEGORIA]\n    FACT_ACTIVIDADES --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_FINANCIERA --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_TIEMPO[ID_FECHA]</code></pre>"},{"location":"03.Cubo/02.Tablas%20copy/#explicacion-del-diagrama","title":"Explicaci\u00f3n del Diagrama","text":"<ol> <li> <p>Tablas de Hechos:</p> <ul> <li>FACT_ACTIVIDADES: Conecta con DIM_UNIDAD, DIM_CATEGORIA, y DIM_TIEMPO_MENSUAL.</li> <li>FACT_PERSONAL: Relacionada con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> <li>FACT_FINANCIERA: Conecta con DIM_TIEMPO_MENSUAL.</li> <li>FACT_EVALUACION_DOCENTE: Conecta con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> </ul> </li> <li> <p>Tablas de Dimensiones:</p> <ul> <li>DIM_UNIDAD: Relaciona hechos mediante el campo <code>ID_UNIDAD</code>.</li> <li>DIM_CATEGORIA: Relaciona hechos mediante el campo <code>ID_CATEGORIA</code>.</li> <li>DIM_TIEMPO_MENSUAL: Relaciona hechos mediante el campo <code>ID_FECHA</code>.</li> </ul> </li> </ol>"},{"location":"03.Cubo/02.Tablas%20copy/#proposito-de-las-relaciones","title":"Prop\u00f3sito de las Relaciones","text":"<ul> <li> <p>Conexi\u00f3n entre hechos y dimensiones: Permitir que las tablas de hechos como FACT_ACTIVIDADES, FACT_PERSONAL, FACT_FINANCIERA y FACT_EVALUACION_DOCENTE se relacionen directamente con sus dimensiones correspondientes.</p> </li> <li> <p>Integridad de Datos: Garantizar que los datos en el modelo est\u00e9n relacionados de manera l\u00f3gica y consistente.</p> </li> <li> <p>Facilitar el An\u00e1lisis Multidimensional: Habilitar an\u00e1lisis por jerarqu\u00edas y categor\u00edas, como tiempo, unidad, y categor\u00eda.</p> </li> </ul>"},{"location":"03.Cubo/02.Tablas/","title":"02. TABLAS","text":""},{"location":"03.Cubo/02.Tablas/#tablas","title":"Tablas","text":""},{"location":"03.Cubo/02.Tablas/#tabla-transversal-dim_unidad","title":"Tabla: Transversal DIM_UNIDAD","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_UNIDAD es una dimensi\u00f3n clave del modelo sem\u00e1ntico que define las unidades organizacionales o funcionales del sistema. Esta tabla permite clasificar y segmentar la informaci\u00f3n de los procesos y actividades, sirviendo como eje de referencia para relacionar datos en otras tablas del cubo (por ejemplo, para an\u00e1lisis de actividades o m\u00e9tricas espec\u00edficas por unidad).</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla","title":"Estructura de la Tabla","text":"<p>La tabla est\u00e1 compuesta por las siguientes columnas:</p> Columna Tipo de Datos Columna Fuente Descripci\u00f3n ID_UNIDAD int64 ID_UNIDAD Identificador \u00fanico de cada unidad organizacional. UNIDAD string UNIDAD Nombre descriptivo de la unidad (por ejemplo, \"Ventas\", \"Operaciones\", etc.)."},{"location":"03.Cubo/02.Tablas/#particiones","title":"Particiones","text":"<ul> <li>Nombre de la Partici\u00f3n: Partition  </li> <li>Vista de Datos: full (carga completa de los datos de la tabla).  </li> <li>Fuente:   La tabla se obtiene a trav\u00e9s de una consulta en M con la siguiente expresi\u00f3n:</li> </ul> <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_UNIDAD = Source{[Schema=\"Transversal\",Item=\"DIM_UNIDAD\"]}[Data]\nin\n    Transversal_DIM_UNIDAD\n</code></pre>"},{"location":"03.Cubo/02.Tablas/#proposito","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n Transversal DIM_UNIDAD se utiliza para:</p> <ul> <li>Identificaci\u00f3n y Clasificaci\u00f3n: Proveer una llave para identificar cada unidad operativa o funcional en el modelo.  </li> <li>Segmentaci\u00f3n Anal\u00edtica: Permitir el filtrado y segmentaci\u00f3n de datos en an\u00e1lisis y reportes, facilitando comparaciones y relaciones entre distintas unidades.  </li> <li>Integraci\u00f3n del Modelo: Servir como referencia en las relaciones entre las tablas de hechos y otras dimensiones, asegurando consistencia en el an\u00e1lisis de la informaci\u00f3n empresarial.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-dim_tiempo_mensual","title":"Tabla: Transversal DIM_TIEMPO_MENSUAL","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_TIEMPO_MENSUAL es una dimensi\u00f3n temporal dise\u00f1ada para segmentar la informaci\u00f3n en diferentes niveles cronol\u00f3gicos. Esta tabla consolida datos de fechas y sus descripciones, permitiendo analizar la informaci\u00f3n en intervalos espec\u00edficos como d\u00edas, semanas, meses, bimestres, trimestres, cuatrimestres, semestres y a\u00f1os. Su estructura detallada facilita la integraci\u00f3n de datos temporales con los hechos del cubo, permitiendo an\u00e1lisis hist\u00f3ricos y tendencias a lo largo del tiempo.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_1","title":"Estructura de la Tabla","text":"<p>La tabla est\u00e1 compuesta por las siguientes columnas:</p> <ul> <li>ID_FECHA </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_FECHA  </li> <li> <p>Descripci\u00f3n: Identificador \u00fanico de la fecha.</p> </li> <li> <p>FECHA </p> </li> <li>Tipo de Datos: dateTime  </li> <li>Fuente: FECHA  </li> <li> <p>Descripci\u00f3n: Representa la fecha completa.</p> </li> <li> <p>DESC_FECHA </p> </li> <li>Tipo de Datos: string  </li> <li>Fuente: DESC_FECHA  </li> <li> <p>Descripci\u00f3n: Descripci\u00f3n textual de la fecha (por ejemplo, \"Lunes, 01 de Enero de 2024\").</p> </li> <li> <p>ID_SEMANA </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_SEMANA  </li> <li> <p>Descripci\u00f3n: N\u00famero identificador de la semana del a\u00f1o.</p> </li> <li> <p>DESC_SEMANA </p> </li> <li>Tipo de Datos: string  </li> <li>Fuente: DESC_SEMANA  </li> <li> <p>Descripci\u00f3n: Descripci\u00f3n o nombre de la semana.</p> </li> <li> <p>ID_NO_MES </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_NO_MES  </li> <li> <p>Descripci\u00f3n: N\u00famero del mes en formato num\u00e9rico (por ejemplo, 1 para enero).</p> </li> <li> <p>DESC_NO_MES </p> </li> <li>Tipo de Datos: string  </li> <li>Fuente: DESC_NO_MES  </li> <li> <p>Descripci\u00f3n: Descripci\u00f3n num\u00e9rica del mes.</p> </li> <li> <p>ID_MES </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_MES  </li> <li> <p>Descripci\u00f3n: Identificador del mes.</p> </li> <li> <p>DESC_MES </p> </li> <li>Tipo de Datos: string  </li> <li>Fuente: DESC_MES  </li> <li> <p>Descripci\u00f3n: Nombre completo del mes (por ejemplo, \"Enero\").</p> </li> <li> <p>DESC_MES_CORTA </p> </li> <li>Tipo de Datos: string  </li> <li>Fuente: DESC_MES_CORTA  </li> <li> <p>Descripci\u00f3n: Versi\u00f3n abreviada del nombre del mes (por ejemplo, \"Ene\").</p> </li> <li> <p>ID_BIMESTRE </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_BIMESTRE  </li> <li> <p>Descripci\u00f3n: Identificador del bimestre.</p> </li> <li> <p>DESC_BIMESTRE </p> </li> <li>Tipo de Datos: string  </li> <li>Fuente: DESC_BIMESTRE  </li> <li> <p>Descripci\u00f3n: Descripci\u00f3n del bimestre.</p> </li> <li> <p>ID_TRIMESTRE </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_TRIMESTRE  </li> <li> <p>Descripci\u00f3n: Identificador del trimestre.</p> </li> <li> <p>DESC_TRIMESTRE </p> </li> <li>Tipo de Datos: string  </li> <li>Fuente: DESC_TRIMESTRE  </li> <li> <p>Descripci\u00f3n: Descripci\u00f3n del trimestre.</p> </li> <li> <p>ID_CUATRIMESTRE </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_CUATRIMESTRE  </li> <li> <p>Descripci\u00f3n: Identificador del cuatrimestre.</p> </li> <li> <p>DESC_CUATRIMESTRE </p> </li> <li>Tipo de Datos: string  </li> <li>Fuente: DESC_CUATRIMESTRE  </li> <li> <p>Descripci\u00f3n: Descripci\u00f3n del cuatrimestre.</p> </li> <li> <p>ID_SEMESTRE </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_SEMESTRE  </li> <li> <p>Descripci\u00f3n: Identificador del semestre.</p> </li> <li> <p>DESC_SEMESTRE </p> </li> <li>Tipo de Datos: string  </li> <li>Fuente: DESC_SEMESTRE  </li> <li> <p>Descripci\u00f3n: Descripci\u00f3n del semestre.</p> </li> <li> <p>ID_ANIO </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_ANIO  </li> <li> <p>Descripci\u00f3n: A\u00f1o correspondiente a la fecha.</p> </li> <li> <p>ID_ANIO_ANT </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: ID_ANIO_ANT  </li> <li> <p>Descripci\u00f3n: A\u00f1o anterior al actual, utilizado para comparaciones temporales.</p> </li> <li> <p>NUM_DIA_SEMANA </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: NUM_DIA_SEMANA  </li> <li> <p>Descripci\u00f3n: N\u00famero del d\u00eda de la semana (por ejemplo, 1 para lunes).</p> </li> <li> <p>FESTIVO </p> </li> <li>Tipo de Datos: int64  </li> <li>Fuente: FESTIVO  </li> <li> <p>Descripci\u00f3n: Indicador de festivo (1 si la fecha es festiva, 0 en caso contrario).</p> </li> <li> <p>FECHA_CORTA </p> </li> <li>Tipo de Datos: dateTime  </li> <li>Fuente: FECHA_CORTA  </li> <li>Descripci\u00f3n: Representaci\u00f3n abreviada o simplificada de la fecha, \u00fatil para visualizaciones y c\u00e1lculos r\u00e1pidos.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#particiones_1","title":"Particiones","text":"<p>La tabla cuenta con una partici\u00f3n configurada de la siguiente forma:</p> <ul> <li>Nombre de la Partici\u00f3n: <code>Partition</code></li> <li>Vista de Datos: <code>full</code> (se carga la totalidad de los datos de la tabla).</li> <li>Fuente:   Se obtiene mediante la siguiente expresi\u00f3n en M:</li> </ul> <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_TIEMPO_MENSUAL = Source{[Schema=\"Transversal\",Item=\"DIM_TIEMPO_MENSUAL\"]}[Data]\nin\n    Transversal_DIM_TIEMPO_MENSUAL\n</code></pre>"},{"location":"03.Cubo/02.Tablas/#proposito_1","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n Transversal DIM_TIEMPO_MENSUAL se utiliza para:</p> <ul> <li>Segmentaci\u00f3n Temporal: Dividir los datos en intervalos espec\u00edficos (d\u00eda, semana, mes, bimestre, trimestre, cuatrimestre, semestre y a\u00f1o) para facilitar el an\u00e1lisis cronol\u00f3gico.</li> <li>Jerarqu\u00edas Temporales: Permitir an\u00e1lisis jer\u00e1rquicos que vinculan datos detallados (como d\u00edas y semanas) con niveles m\u00e1s agregados (meses, trimestres, a\u00f1os), lo cual es fundamental para la elaboraci\u00f3n de informes y dashboards.</li> <li>Integraci\u00f3n de Datos: Servir como llave para relacionar informaci\u00f3n de hechos (por ejemplo, en las tablas de actividades, personal o financiera) con el tiempo, asegurando la consistencia y calidad en los an\u00e1lisis.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-dim_categoria","title":"Tabla: Transversal DIM_CATEGORIA","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_CATEGORIA define las categor\u00edas utilizadas en el modelo para clasificar datos. Esta dimensi\u00f3n permite agrupar y segmentar informaci\u00f3n relacionada con diferentes \u00e1reas del sistema.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_2","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente COD_CATEGORIA string COD_CATEGORIA DESCRIPCION string DESCRIPCION"},{"location":"03.Cubo/02.Tablas/#particiones_2","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>   let\n       Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n       Transversal_DIM_CATEGORIA = Source{[Schema=\"Transversal\",Item=\"DIM_CATEGORIA\"]}[Data]\n   in\n       Transversal_DIM_CATEGORIA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_2","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_CATEGORIA se utiliza para:</p> <ul> <li>Clasificar informaci\u00f3n en grupos o categor\u00edas predefinidas.</li> <li>Relacionar datos categorizados con otras dimensiones y hechos para an\u00e1lisis m\u00e1s detallados.</li> <li>Facilitar la segmentaci\u00f3n de datos en reportes y consultas.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_actividades","title":"Tabla: Transversal FACT_ACTIVIDADES","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_ACTIVIDADES es el hecho central del modelo sem\u00e1ntico y consolida informaci\u00f3n de diversas actividades realizadas en el entorno empresarial. Esta tabla integra datos provenientes de m\u00faltiples procesos ETL \u2013 tales como afiliaci\u00f3n, pagos, PQR, evaluaciones, entre otros \u2013 y contiene informaci\u00f3n demogr\u00e1fica, econ\u00f3mica y operativa. Es fundamental para el an\u00e1lisis multidimensional y el c\u00e1lculo de m\u00e9tricas clave en el cubo.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_3","title":"Estructura de la Tabla","text":"<p>La tabla est\u00e1 compuesta por las siguientes columnas:</p> Columna Tipo de Datos Fuente/Expresi\u00f3n Descripci\u00f3n (Resumen) PARTNER string PARTNER Identificador principal del socio o entidad registrada. ID_EMPRESA int64 ID_EMPRESA Identificador de la empresa asociada. ID_AFILIADO int64 ID_AFILIADO Identificador del afiliado. ID_TIPO_AFILIADO int64 ID_TIPO_AFILIADO Identificador del tipo de afiliado. TIPO_AFILIADO string TIPO_AFILIADO Descripci\u00f3n textual del tipo de afiliado. ID_CATEGORIA int64 ID_CATEGORIA Identificador de la categor\u00eda a la que pertenece el registro. FECHA_AFILIACION dateTime FECHA_AFILIACION Fecha en que se realiz\u00f3 la afiliaci\u00f3n o inicio de la actividad. FECHA_RETIRO dateTime FECHA_RETIRO Fecha de retiro o fin de la actividad, si aplica. ID_GENERO int64 ID_GENERO Identificador del g\u00e9nero, para an\u00e1lisis demogr\u00e1fico. ID_ESTADO_CIVIL int64 ID_ESTADO_CIVIL Estado civil del registro. ID_PERTENENCIA_ETNICA int64 ID_PERTENENCIA_ETNICA Identificador de la pertenencia \u00e9tnica. ID_FACTOR_VULNERABILIDAD int64 ID_FACTOR_VULNERABILIDAD Factor de vulnerabilidad asociado, si aplica. ESTRATO int64 ESTRATO Nivel socioecon\u00f3mico del registro. ID_CIUDAD int64 ID_CIUDAD Identificador de la ciudad. SALARIO_BASICO double SALARIO_BASICO Valor del salario b\u00e1sico asociado. FECHA_MENSUAL dateTime FECHA_MENSUAL Fecha de referencia mensual para la actividad. ID_FECHA int64 ID_FECHA Clave que relaciona el registro con la dimensi\u00f3n temporal. ID_UNIDAD int64 ID_UNIDAD Identificador de la unidad operativa asociada. ESTADOREGISTRO string ESTADOREGISTRO Estado del registro (por ejemplo, \"CURRENT\"). PARTNER_AFILIADO string PARTNER_AFILIADO Identificador adicional para el afiliado, cuando aplica. PARTNER_EMPRESA string PARTNER_EMPRESA Identificador de la empresa en el caso de registros empresariales. TIPO_POBLACION string TIPO_POBLACION Define el tipo de poblaci\u00f3n involucrada (ej. \"AFILIADO\", \"EMPRESA\", \"BENEFICIARIO\", etc.). ACTIVIDAD string ACTIVIDAD Tipo de actividad registrada (por ejemplo, \"AFILIACION\", \"PQR\", \"PAGOS\", etc.). TOTAL_APORTES double TOTAL_APORTES Valor total de aportes realizados. NUMERO_APORTES int64 NUMERO_APORTES N\u00famero total de aportes registrados. ADEUDA double ADEUDA Monto adeudado, cuando aplica. ANIO_ACADEMICO int64 ANIO_ACADEMICO A\u00f1o acad\u00e9mico relacionado con el registro. CANTIDAD_MATERIAL int64 CANTIDAD_MATERIAL Cantidad de material involucrado en la actividad (si aplica). CALIFICACION string CALIFICACION Calificaci\u00f3n o puntaje asignado en evaluaciones o procesos similares. CAUSA string CAUSA Motivo o causa asociada al registro, \u00fatil en procesos de reclamos o PQR. CATEGORIA_VENTA string CATEGORIA_VENTA Categor\u00eda de venta asociada, cuando corresponde. COSTO double COSTO Costo asociado a la actividad o registro. CURSO string CURSO Curso o programa acad\u00e9mico, en caso de actividades educativas. DESCRIPCION string DESCRIPCION Descripci\u00f3n detallada del registro o actividad. ESTADO string ESTADO Estado actual del registro, por ejemplo, \"PAGADO\" o \"SIN PAGO\". ESTADO_PAGO string ESTADO_PAGO Estado del pago asociado al registro. FECHA_ADMISION dateTime FECHA_ADMISION Fecha de admisi\u00f3n o inicio de procesos educativos. ID_CONCEPTO int64 ID_CONCEPTO Identificador del concepto asociado (por ejemplo, tipo de pago). ID_CURSO int64 ID_CURSO Identificador del curso relacionado, cuando aplica. ID_ESTADO_GESTION int64 ID_ESTADO_GESTION Estado de gesti\u00f3n del proceso registrado. ID_GRADO int64 ID_GRADO Identificador del grado acad\u00e9mico, cuando corresponde. ID_MATERIAL int64 ID_MATERIAL Identificador del material, si est\u00e1 involucrado en la actividad. ID_POBLACION int64 ID_POBLACION Identificador de la poblaci\u00f3n (por ejemplo, de estudiantes). ID_PROGRAMA int64 ID_PROGRAMA Identificador del programa acad\u00e9mico o de servicios. ID_PREGUNTA int64 ID_PREGUNTA Identificador de la pregunta en procesos de evaluaci\u00f3n o PQR. NO_PRESTAMOS int64 NO_PRESTAMOS N\u00famero de pr\u00e9stamos o servicios prestados, cuando aplica. RESPUESTA string RESPUESTA Respuesta asociada a evaluaciones o PQR. SERVICIO_TRANSPORTE string SERVICIO_TRANSPORTE Indica si se provee servicio de transporte en el contexto del registro. SUBSIDIO double SUBSIDIO Valor del subsidio aplicado, cuando corresponde. VALOR_FACTURADO double VALOR_FACTURADO Monto facturado en la transacci\u00f3n o actividad. VALOR_MATERIAL double VALOR_MATERIAL Valor del material involucrado, en caso de actividades relacionadas. VALOR_PAGADO double VALOR_PAGADO Monto pagado en la transacci\u00f3n o actividad. VALOR_PAGADO_SIN_IMP double VALOR_PAGADO_SIN_IMP Valor pagado sin incluir impuestos, cuando aplica. POBLACION_EDUCACION string POBLACION_EDUCACION Indicador de si el registro pertenece al \u00e1mbito educativo. ID_PQR string ID_PQR Identificador de la PQR (Preguntas, Quejas y Reclamos) asociada al registro. ESTADO_PQR string ESTADO_PQR Estado de la PQR. ID_BENEFICIARIO int64 ID_BENEFICIARIO Identificador del beneficiario en procesos de afiliaci\u00f3n o PQR. CAUSA_PQR string CAUSA_PQR Causa asociada a la PQR. TIPO_PQRS string TIPO_PQRS Tipo de PQR (por ejemplo, Pregunta, Queja, Reclamo). ID_TARIFA int64 ID_TARIFA Identificador de la tarifa o servicio relacionado. DESCRIPCION_ calculated (string) \u2013 Valor calculado: <code>COALESCE('Transversal FACT_ACTIVIDADES'[DESCRIPCION], \"INDEFINIDO\")</code>. TIPO_OPERACION_ calculated (string) \u2013 Valor calculado: <code>COALESCE('Transversal FACT_ACTIVIDADES'[TIPO_POBLACION], \"INDEFINIDO\")</code>. PARTNER_EMPRESA_ calculated (string) \u2013 Valor calculado: <code>COALESCE('Transversal FACT_ACTIVIDADES'[PARTNER_EMPRESA], \"INDEFINIDO\")</code>. ID_GENERO_ calculated (int64) \u2013 Valor calculado: <code>COALESCE('Transversal FACT_ACTIVIDADES'[ID_GENERO], -1)</code>."},{"location":"03.Cubo/02.Tablas/#particiones_3","title":"Particiones","text":"<ul> <li>Nombre de la Partici\u00f3n: Partition  </li> <li>Vista de Datos: full (carga completa de los datos).  </li> <li>Fuente:   La tabla se obtiene mediante la siguiente expresi\u00f3n en M:</li> </ul> <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_ACTIVIDADES = Source{[Schema=\"Transversal\", Item=\"FACT_ACTIVIDADES\"]}[Data]\nin\n    Transversal_FACT_ACTIVIDADES\n</code></pre>"},{"location":"03.Cubo/02.Tablas/#proposito_3","title":"Prop\u00f3sito","text":"<p>La tabla Transversal FACT_ACTIVIDADES se utiliza para:</p> <ul> <li>Consolidar Datos de Actividades: Integrar informaci\u00f3n proveniente de diversos procesos ETL (afiliaci\u00f3n, PQR, pagos, evaluaciones, etc.) en un \u00fanico hecho.</li> <li>An\u00e1lisis Multidimensional: Servir como base para el c\u00e1lculo de m\u00e9tricas clave, permitiendo segmentar y analizar la informaci\u00f3n por diferentes dimensiones (unidad, tiempo, categor\u00eda, etc.).</li> <li>Soporte a Reportes y Dashboards: Proveer datos detallados para la generaci\u00f3n de informes estrat\u00e9gicos y operativos, facilitando la identificaci\u00f3n de tendencias y oportunidades de mejora.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_personal","title":"Tabla: Transversal FACT_PERSONAL","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_PERSONAL almacena informaci\u00f3n relacionada con el personal, sus asignaciones y las horas contratadas. Es \u00fatil para el an\u00e1lisis de recursos humanos y la planificaci\u00f3n operativa.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_4","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA ID_PERSONAL int64 ID_PERSONAL NOMBRE string NOMBRE CONCEPTO string CONCEPTO DESCRIPCION string DESCRIPCION FECHA_FIN dateTime FECHA_FIN HORAS_CONTRATADAS_MENSUAL int64 HORAS_CONTRATADAS_MENSUAL ID_UNIDAD int64 ID_UNIDAD DESCRIPCION_ string Calculada <p>Nota: La columna <code>DESCRIPCION_</code> es una columna calculada que proporciona una descripci\u00f3n adicional basada en la l\u00f3gica del modelo.</p>"},{"location":"03.Cubo/02.Tablas/#particiones_4","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_PERSONAL = Source{[Schema=\"Transversal\",Item=\"FACT_PERSONAL\"]}[Data]\nin\n    Transversal_FACT_PERSONAL\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_4","title":"Prop\u00f3sito","text":"<p>La tabla FACT_PERSONAL se utiliza para:</p> <ul> <li>Analizar las asignaciones y contratos del personal.</li> <li>Monitorear las horas contratadas mensualmente.</li> <li>Relacionar los datos del personal con otras dimensiones para informes y planificaci\u00f3n estrat\u00e9gica.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_financiera","title":"Tabla: Transversal FACT_FINANCIERA","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_FINANCIERA contiene informaci\u00f3n detallada sobre los datos financieros de la organizaci\u00f3n, incluyendo cuentas, ingresos, gastos y resultados. Es una fuente fundamental para el an\u00e1lisis financiero y la generaci\u00f3n de informes.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_5","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA ID_ANIO int64 ID_ANIO ID_MES int64 ID_MES ID_CEBE string ID_CEBE CEBE string CEBE DESCRIPCION_CEBE string DESCRIPCION_CEBE DEPARTAMENTO string DEPARTAMENTO AREA string AREA SUBAREA string SUBAREA SEGMENTO string SEGMENTO DESCRIPCION_SEGMENTO string DESCRIPCION_SEGMENTO CODIGO_SSF int64 CODIGO_SSF NOMBRE_SSF string NOMBRE_SSF ID_CUENTA string ID_CUENTA CUENTA string CUENTA CUENTA_HOMOLOGA string CUENTA_HOMOLOGA DESCRIPCION string DESCRIPCION TIPO_CUENTA string TIPO_CUENTA TIPO_OPERACION string TIPO_OPERACION GRUPO_CUENTA string GRUPO_CUENTA SUBGRUPO_CUENTA string SUBGRUPO_CUENTA GRUPO_OPERACION string GRUPO_OPERACION CUENTA_SSF string CUENTA_SSF DESCRIPCION_SSF string DESCRIPCION_SSF CUENTA_DESCRIPCION string CUENTA_DESCRIPCION CUENTA_DESCRIPCION_SSF string CUENTA_DESCRIPCION_SSF SIGNO_INGRESOS int64 SIGNO_INGRESOS CLASIFICACION int64 CLASIFICACION SEGMENT string SEGMENT IMPORTE int64 IMPORTE INGRESOS int64 INGRESOS INGRESOS_OPERACIONALES int64 INGRESOS_OPERACIONALES GASTOS int64 GASTOS GASTOS_OPERACIONALES int64 GASTOS_OPERACIONALES GASTOS_OPERACIONALES_ADMIN int64 GASTOS_OPERACIONALES_ADMIN RESULTADO_EJERCICIO int64 RESULTADO_EJERCICIO COSTOS int64 COSTOS ACTIVO int64 ACTIVO PASIVO int64 PASIVO PATRIMONIO int64 PATRIMONIO GASTOS_CON_DISTRIBUCION int64 GASTOS_CON_DISTRIBUCION GASTOS_SIN_DISTRIBUCION int64 GASTOS_SIN_DISTRIBUCION ... ... ... <p>Nota: La tabla incluye columnas adicionales como <code>ID_UNIDAD</code> y otras relacionadas con detalles financieros espec\u00edficos.</p>"},{"location":"03.Cubo/02.Tablas/#particiones_5","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_FINANCIERA = Source{[Schema=\"Transversal\",Item=\"FACT_FINANCIERA\"]}[Data]\nin\n    Transversal_FACT_FINANCIERA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_5","title":"Prop\u00f3sito","text":"<p>La tabla FACT_FINANCIERA se utiliza para:</p> <ul> <li>Analizar el comportamiento financiero de la organizaci\u00f3n.</li> <li>Evaluar ingresos, gastos, costos y resultados financieros.</li> <li>Relacionar los datos financieros con otras dimensiones para an\u00e1lisis multidimensionales y generaci\u00f3n de informes detallados.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_evaluacion_docente","title":"Tabla: Transversal FACT_EVALUACION_DOCENTE","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_EVALUACION_DOCENTE almacena informaci\u00f3n relacionada con las evaluaciones acad\u00e9micas de los docentes, incluyendo calificaciones definitivas, per\u00edodos acad\u00e9micos y datos personales. Es clave para el an\u00e1lisis del desempe\u00f1o docente.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_6","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente PERIODO_ACADEMICO string PERIODO_ACADEMICO ID_UNIDAD int64 ID_UNIDAD ID_PERSONAL int64 ID_PERSONAL NOMBRE_DOCENTE string NOMBRE_DOCENTE CALIFICACION_DEFINITIVA string CALIFICACION_DEFINITIVA ID_FECHA int64 ID_FECHA"},{"location":"03.Cubo/02.Tablas/#particiones_6","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_EVALUACION_DOCENTE = Source{[Schema=\"Transversal\",Item=\"FACT_EVALUACION_DOCENTE\"]}[Data]\nin\n    Transversal_FACT_EVALUACION_DOCENTE\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_6","title":"Prop\u00f3sito","text":"<p>La tabla FACT_EVALUACION_DOCENTE se utiliza para:</p> <ul> <li>Analizar el desempe\u00f1o acad\u00e9mico de los docentes.</li> <li>Generar informes de calificaciones definitivas por per\u00edodo acad\u00e9mico.</li> <li>Relacionar datos de evaluaci\u00f3n docente con otras dimensiones como unidades y fechas.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-calculatedtableindicadores","title":"Tabla: CalculatedTableIndicadores","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>La tabla CalculatedTableIndicadores es una tabla calculada que contiene indicadores clave para el an\u00e1lisis y evaluaci\u00f3n del rendimiento en diversas \u00e1reas, como cobertura, movilidad acad\u00e9mica, promoci\u00f3n, deserci\u00f3n, matr\u00edculas, graduados y satisfacci\u00f3n.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_7","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente indicador string (calculada) [indicador]"},{"location":"03.Cubo/02.Tablas/#particiones_7","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>CalculatedTable 1</code>.</p> <p>2. Fuente:</p> <ul> <li>Tipo: <code>calculated</code>.</li> <li>Expresi\u00f3n:      <pre><code>DATATABLE (\n    \"indicador\", STRING, \n    { \n        {\"Cumplimiento Cobertura\"},\n        {\"Cobertura Proyectada\"},\n        {\"Movilidad Academica\"},\n        {\"Porcentaje de Promoci\u00f3n\"},\n        {\"Porcentaje de Deserci\u00f3n\"},\n        {\"Cantidad de Matr\u00edculas\"},\n        {\"Cantidad de Graduados\"},\n        {\"Cantidad de PQRs\"},\n        {\"Nivel de satisfacci\u00f3n a partir de la NSU promedio\"},\n        {\"Promotores promedio del Proceso a partir de la NSU\"},\n        {\"Detractores promedio del Proceso a partir de la NSU\"}\n    }\n)\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_7","title":"Prop\u00f3sito","text":"<p>La tabla CalculatedTableIndicadores se utiliza para:</p> <ul> <li>Listar y categorizar indicadores clave para el an\u00e1lisis.</li> <li>Servir como base para reportes y consultas espec\u00edficas relacionadas con la evaluaci\u00f3n del desempe\u00f1o.</li> <li>Proveer una visi\u00f3n consolidada de los indicadores m\u00e1s relevantes para la organizaci\u00f3n.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#relaciones-del-modelo","title":"Relaciones del Modelo","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Las relaciones definen c\u00f3mo las tablas del modelo interact\u00faan entre s\u00ed, asegurando la coherencia y la integridad de los datos en los an\u00e1lisis. A continuaci\u00f3n se detallan las relaciones establecidas entre las tablas del modelo, actualizadas con la informaci\u00f3n del JSON.</p> Nombre Tabla Origen Columna Origen Tabla Destino Columna Destino 1469e10f-7f24-448b-90b5-5efb1e0546e7 Transversal FACT_ACTIVIDADES ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 7db82b4d-6aa3-4be9-9281-0442a2f8b24c Transversal FACT_ACTIVIDADES ID_CATEGORIA Transversal DIM_CATEGORIA COD_CATEGORIA 5a5c2b47-ec17-4247-828f-02289a229d06 Transversal FACT_ACTIVIDADES ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 395ef55c-3800-4448-bc48-46690276bd39 Transversal FACT_PERSONAL ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA cdfe13d4-3917-431a-b0c9-b496df147a20 Transversal FACT_PERSONAL ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD a8efdf32-e907-42ab-a950-937906c7b167 Transversal FACT_EVALUACION_DOCENTE ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 632bc53c-67b6-4634-82f9-8adbfc71e691 Transversal FACT_EVALUACION_DOCENTE ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 7246e8e1-e2c3-4a17-89eb-c077680b0f6b Transversal FACT_FINANCIERA ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA e01f4c3c-2a45-4889-b297-c92f354929bb Transversal FACT_FINANCIERA ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD"},{"location":"03.Cubo/02.Tablas/#diagrama-de-relaciones-y-tablas","title":"Diagrama de Relaciones y Tablas","text":"<p>A continuaci\u00f3n, se presenta el diagrama de relaciones del modelo utilizando formato Mermaid para visualizar las conexiones entre tablas y sus relaciones, actualizado para incluir la relaci\u00f3n entre Transversal FACT_FINANCIERA y Transversal DIM_UNIDAD:</p> <pre><code>graph TD\n    FACT_ACTIVIDADES[Transversal FACT_ACTIVIDADES]\n    FACT_PERSONAL[Transversal FACT_PERSONAL]\n    FACT_FINANCIERA[Transversal FACT_FINANCIERA]\n    FACT_EVALUACION_DOCENTE[Transversal FACT_EVALUACION_DOCENTE]\n    DIM_UNIDAD[Transversal DIM_UNIDAD]\n    DIM_CATEGORIA[Transversal DIM_CATEGORIA]\n    DIM_TIEMPO[Transversal DIM_TIEMPO_MENSUAL]\n\n    FACT_ACTIVIDADES --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_ACTIVIDADES --&gt; DIM_CATEGORIA[ID_CATEGORIA]\n    FACT_ACTIVIDADES --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_FINANCIERA --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_FINANCIERA --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_TIEMPO[ID_FECHA]</code></pre>"},{"location":"03.Cubo/02.Tablas/#explicacion-del-diagrama","title":"Explicaci\u00f3n del Diagrama","text":"<ol> <li>Tablas de Hechos:</li> <li>FACT_ACTIVIDADES: Conecta con DIM_UNIDAD, DIM_CATEGORIA y DIM_TIEMPO_MENSUAL.</li> <li>FACT_PERSONAL: Relacionada con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> <li>FACT_FINANCIERA: Conecta con DIM_TIEMPO_MENSUAL y DIM_UNIDAD (relaci\u00f3n a\u00f1adida del JSON).</li> <li> <p>FACT_EVALUACION_DOCENTE: Conecta con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</p> </li> <li> <p>Tablas de Dimensiones:</p> </li> <li>DIM_UNIDAD: Relaciona hechos mediante el campo <code>ID_UNIDAD</code>.</li> <li>DIM_CATEGORIA: Relaciona hechos mediante el campo <code>ID_CATEGORIA</code>.</li> <li>DIM_TIEMPO_MENSUAL: Relaciona hechos mediante el campo <code>ID_FECHA</code>.</li> </ol>"},{"location":"03.Cubo/02.Tablas/#proposito-de-las-relaciones","title":"Prop\u00f3sito de las Relaciones","text":"<ul> <li>Conexi\u00f3n entre hechos y dimensiones: Permitir que las tablas de hechos como FACT_ACTIVIDADES, FACT_PERSONAL, FACT_FINANCIERA y FACT_EVALUACION_DOCENTE se relacionen directamente con sus dimensiones correspondientes.</li> <li>Integridad de Datos: Garantizar que los datos en el modelo est\u00e9n relacionados de manera l\u00f3gica y consistente.</li> <li>Facilitar el An\u00e1lisis Multidimensional: Habilitar an\u00e1lisis por jerarqu\u00edas y categor\u00edas, como tiempo, unidad y categor\u00eda.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#cambios-realizados","title":"Cambios Realizados","text":"<ol> <li>Estructura de Tablas:</li> <li>Transversal FACT_ACTIVIDADES: Se a\u00f1adi\u00f3 una nota sobre columnas adicionales como <code>ADEUDA</code>, <code>ANIO_ACADEMICO</code> y <code>CALIFICACION</code>.</li> <li>Transversal FACT_PERSONAL: Se incluy\u00f3 la columna calculada <code>DESCRIPCION_</code> del JSON.</li> <li> <p>Transversal FACT_FINANCIERA: Se a\u00f1adi\u00f3 una nota sobre columnas adicionales, incluyendo <code>ID_UNIDAD</code>.</p> </li> <li> <p>Relaciones del Modelo:</p> </li> <li>Se actualiz\u00f3 la tabla de relaciones con los nombres y detalles correctos del JSON, incluyendo la relaci\u00f3n adicional entre Transversal FACT_FINANCIERA y Transversal DIM_UNIDAD (<code>e01f4c3c-2a45-4889-b297-c92f354929bb</code>).</li> <li> <p>Los nombres de las relaciones se ajustaron para reflejar los identificadores del JSON.</p> </li> <li> <p>Diagrama Mermaid:</p> </li> <li>Se a\u00f1adi\u00f3 la relaci\u00f3n entre Transversal FACT_FINANCIERA y Transversal DIM_UNIDAD para reflejar la estructura actualizada del modelo.</li> </ol> <p>Este texto ahora est\u00e1 completamente actualizado con la informaci\u00f3n del JSON, manteniendo la claridad y el formato original. Si necesitas algo m\u00e1s o hay algo que no est\u00e9 claro, \u00a1h\u00e1zmelo saber!</p>"},{"location":"03.Cubo/03.ETL/","title":"03. ETL","text":""},{"location":"03.Cubo/03.ETL/#fact_mineria","title":"FACT_MINERIA","text":"<p>El paquete SSIS \"FACT_MINERIA\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar datos relacionados con actividades de miner\u00eda de datos en el \u00e1mbito educativo. Este paquete consolida informaci\u00f3n para an\u00e1lisis avanzados en el Data Warehouse <code>DWH_COMFENALCO</code>, enfoc\u00e1ndose en dos \u00e1reas principales: el Colegio y la Educaci\u00f3n T\u00e9cnica y Continua.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es integrar datos operativos de diferentes fuentes para construir una base de datos anal\u00edtica que soporte procesos de miner\u00eda de datos, permitiendo identificar patrones, tendencias y relaciones en actividades educativas tanto en colegios como en programas de educaci\u00f3n t\u00e9cnica y continua.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Preparaci\u00f3n del Entorno </p> <ul> <li>Truncar Tabla:  Elimina todos los registros existentes en la tabla <code>FACT_MINERIA</code> para evitar duplicaciones o inconsistencias durante la carga de nuevos datos.</li> <li>Uso de <code>TRUNCATE TABLE</code>:  Esta operaci\u00f3n optimiza el rendimiento eliminando registros de forma masiva, sin afectar la estructura de la tabla.</li> </ul> </li> <li> <p>M\u00f3dulo MINERIA_COLEGIO </p> <ul> <li>Proceso Matr\u00edcula (Temporal):  Procesa informaci\u00f3n detallada de inscripciones matriculares, calculando indicadores de gesti\u00f3n para codeudor, secretar\u00eda acad\u00e9mica, psicolog\u00eda y coordinaci\u00f3n acad\u00e9mica.</li> <li>Gesti\u00f3n Matr\u00edculas:  Transforma y carga datos relacionados con gestiones de matr\u00edcula escolar, asignando fechas iniciales, finales y clasificando actividades.</li> <li>PQRs Colegio:  Integra informaci\u00f3n de peticiones, quejas y reclamos presentados por acudientes en el \u00e1mbito escolar.</li> </ul> </li> <li> <p>M\u00f3dulo MINERIA_EDUCACION_TECNICA_Y_CONTINUA </p> <ul> <li>Inscripci\u00f3n:  Captura y procesa datos de inscripciones de estudiantes desde fuentes operativas en Cedesarrollo, segmentando por origen (afiliados, beneficiarios, empresas).</li> <li>Admisi\u00f3n:  Gestiona informaci\u00f3n de admisiones, diferenciando entre estudiantes nuevos y antiguos.</li> <li>Pago:  Procesa datos financieros relacionados con pagos de cursos, integrando informaci\u00f3n temporal y econ\u00f3mica.</li> <li>PQRs:  Consolida datos de peticiones, quejas y reclamos en programas de educaci\u00f3n t\u00e9cnica y continua.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagramas","title":"Diagramas","text":""},{"location":"03.Cubo/03.ETL/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>flowchart TD\n    A[Truncar Tabla] --&gt; B{\u00c1rea Educativa}\n    B --&gt;|Colegio| C[Proceso Matr\u00edcula Temporal]\n    C --&gt; D[Gesti\u00f3n Matr\u00edculas]\n    D --&gt; E[PQRs Colegio]\n    B --&gt;|Educaci\u00f3n T\u00e9cnica y Continua| F[Inscripci\u00f3n]\n    F --&gt; G[Admisi\u00f3n]\n    G --&gt; H[Pago]\n    H --&gt; I[PQRs]\n    E --&gt; J[FACT_MINERIA]\n    I --&gt; J</code></pre>"},{"location":"03.Cubo/03.ETL/#2-modelo-de-datos-simplificado","title":"2. Modelo de Datos Simplificado","text":"<pre><code>erDiagram\n    FACT_MINERIA {\n        string BP\n        int ID_FECHA_MENSUAL\n        int ID_ANIO_ACADEMICO\n        int ID_UNIDAD\n        datetime FECHA_INICIAL\n        datetime FECHA_FINAL\n        string ACTIVIDAD\n        int TIEMPO_SEGUNDOS\n        decimal VALOR_PAGADO\n        int ID_CATEGORIA\n        int ID_CURSO\n        int ID_TIPO_ESTUDIANTE\n    }\n    DIM_TIEMPO_MENSUAL {\n        int ID_FECHA\n        string NOMBRE_MES\n        int NUMERO_MES\n        int ANIO\n    }\n    DIM_AFILIADOS {\n        string PARTNER\n        int ID_CATEGORIA\n        string NOMBRE\n    }\n    DIM_BENEFICIARIOS {\n        string PARTNER\n        int ID_AFILIADO\n        string NOMBRE\n    }\n    FACT_PQRS {\n        int ID_FECHA\n        int ID_AFILIADO\n        int ID_BENEFICIARIO\n        datetime FECHA_CREACION\n        datetime FECHA_RESOLUCION\n        string CAUSA\n    }\n    FACT_MINERIA }|--|| DIM_TIEMPO_MENSUAL : \"asocia periodos\"\n    FACT_MINERIA }|--|| DIM_AFILIADOS : \"vincula afiliados\"\n    FACT_MINERIA }|--|| DIM_BENEFICIARIOS : \"vincula beneficiarios\"\n    FACT_PQRS ||--|{ FACT_MINERIA : \"alimenta\"</code></pre>"},{"location":"03.Cubo/03.ETL/#componentes","title":"Componentes","text":""},{"location":"03.Cubo/03.ETL/#componente-truncar-tablas-cubo","title":"Componente <code>Truncar Tablas Cubo</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Truncar Tablas Cubo</code> es una tarea de ejecuci\u00f3n SQL integrada en un paquete SSIS (SQL Server Integration Services) dise\u00f1ado para preparar el entorno del Data Warehouse <code>DWH_COMFENALCO</code> antes de la carga de datos. Su funci\u00f3n principal es eliminar todo el contenido de las tablas destino especificadas mediante el comando <code>TRUNCATE TABLE</code>, asegurando que est\u00e9n vac\u00edas y listas para recibir nuevos datos.</p>"},{"location":"03.Cubo/03.ETL/#proposito","title":"Prop\u00f3sito","text":"<ol> <li>Preparar el Data Warehouse:  <ul> <li>Elimina datos existentes en las tablas destino para evitar duplicaciones o inconsistencias durante la carga de nuevos datos.  </li> </ul> </li> <li>Optimizar el Rendimiento:  <ul> <li>Utiliza <code>TRUNCATE TABLE</code> en lugar de <code>DELETE</code>, lo que permite una eliminaci\u00f3n r\u00e1pida y eficiente de registros sin registrar cada operaci\u00f3n individualmente en el log de transacciones.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas","title":"Tablas Afectadas","text":"<p>El componente ejecuta comandos de truncado sobre las siguientes tablas en el esquema <code>Transversal</code> del Data Warehouse <code>DWH_COMFENALCO</code>:</p> <ol> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_UNIDADES]</code>:  <ul> <li>Tabla de hechos que almacena informaci\u00f3n relacionada con unidades operativas.  </li> </ul> </li> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code>:  <ul> <li>Contiene datos consolidados de actividades asociadas a afiliados, empresas y aportes.  </li> </ul> </li> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE]</code>:  <ul> <li>Registra evaluaciones de desempe\u00f1o docente.  </li> </ul> </li> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA]</code>:  <ul> <li>Tabla de hechos para datos financieros.  </li> </ul> </li> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_PERSONAL]</code>:  <ul> <li>Almacena informaci\u00f3n sobre personal, como ausentismo y contrataciones.  </li> </ul> </li> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]</code>:  <ul> <li>Incluye datos relevantes para procesos de miner\u00eda de datos en an\u00e1lisis educativo.  </li> </ul> </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]</code>:  <ul> <li>Dimensi\u00f3n temporal que organiza informaci\u00f3n por meses.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada: <pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_UNIDADES];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_PERSONAL];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_MINERIA];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL];\n</code></pre></p> <p>Caracter\u00edsticas del Comando: - Eficiencia: <code>TRUNCATE TABLE</code> elimina todos los registros de las tablas de forma masiva, reiniciando los contadores de identidad (si los hay) y liberando el espacio asignado sin registrar operaciones individuales. - Seguridad: El comando no se ejecutar\u00e1 si existen restricciones de claves for\u00e1neas activas que referencien las tablas, lo que previene errores accidentales en la integridad referencial. - Conexi\u00f3n: Utiliza el administrador de conexiones <code>DWH_COMFENALCO</code> para acceder a la base de datos.</p>"},{"location":"03.Cubo/03.ETL/#configuracion-en-el-xml","title":"Configuraci\u00f3n en el XML","text":"<p>Aunque el XML proporcionado no incluye expl\u00edcitamente la definici\u00f3n completa del componente <code>Truncar Tablas Cubo</code> como una tarea independiente (probablemente porque est\u00e1 en otra secci\u00f3n del paquete o en un archivo relacionado), se puede inferir su existencia y prop\u00f3sito a partir de la estructura general del paquete SSIS <code>09-ETLS_CUBO</code>. Este paquete incluye m\u00faltiples tareas de flujo de datos y configuraciones que dependen de un entorno limpio, como lo indica la presencia de tareas como <code>DIM_TIEMPO_MENSUAL</code>. La tarea de truncado ser\u00eda t\u00edpicamente una <code>Execute SQL Task</code> con las siguientes propiedades deducidas:</p> <ul> <li>Nombre: \"Truncar Tablas Cubo\" (basado en la documentaci\u00f3n del segundo documento).  </li> <li>Tipo de Ejecutable: <code>Microsoft.ExecuteSQLTask</code> (tarea est\u00e1ndar para ejecutar comandos SQL en SSIS).  </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code> (referenciada en el XML como <code>connectionManagerRefId=\"Project.ConnectionManagers[DWH_COMFENALCO]\"</code>).  </li> <li>SQLStatement: El script SQL mostrado anteriormente.  </li> <li>DTSID: Un identificador \u00fanico similar a los presentes en el XML, como <code>{AAB88391-9629-4545-8D33-0A167480054E}</code>.  </li> </ul>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Paquete SSIS\n    participant SQLServer as Servidor SQL\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_UNIDADES\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_ACTIVIDADES\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_EVALUACION_DOCENTE\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_FINANCIERA\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_PERSONAL\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_MINERIA\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE DIM_TIEMPO_MENSUAL\n    SQLServer --&gt;&gt; SSIS: Confirmaci\u00f3n de ejecuci\u00f3n</code></pre>"},{"location":"03.Cubo/03.ETL/#contexto-dentro-del-paquete-ssis","title":"Contexto dentro del Paquete SSIS","text":"<p>El componente <code>Truncar Tablas Cubo</code> es una tarea cr\u00edtica que se ejecuta al inicio del proceso ETL (Extract, Transform, Load) en el paquete <code>09-ETLS_CUBO</code>. Su prop\u00f3sito es garantizar que las tablas de hechos y dimensiones est\u00e9n limpias antes de que tareas como <code>DIM_TIEMPO_MENSUAL</code> (presente en el XML bajo <code>&lt;DTS:Executable DTS:refId=\"Package\\DIM_TIEMPO_MENSUAL\"&gt;</code>) y otras carguen nuevos datos. Esto asegura la integridad y consistencia de los datos en el cubo OLAP resultante.</p>"},{"location":"03.Cubo/03.ETL/#dim_tiempo_mensual","title":"DIM_TIEMPO_MENSUAL","text":"<p><code>DIM_TIEMPO_MENSUAL</code> es un componente clave dentro del paquete SSIS (SQL Server Integration Services) denominado <code>09-ETLS_CUBO</code>. Este componente es una tarea de flujo de datos dise\u00f1ada para generar y cargar datos en la tabla de dimensi\u00f3n temporal <code>DIM_TIEMPO_MENSUAL</code>, ubicada en el esquema <code>Transversal</code> del Data Warehouse <code>DWH_COMFENALCO</code>. Su prop\u00f3sito principal es proporcionar una dimensi\u00f3n de tiempo a nivel mensual que sirve como base para el an\u00e1lisis temporal en un cubo OLAP.</p>"},{"location":"03.Cubo/03.ETL/#que-hace-dim_tiempo_mensual","title":"\u00bfQu\u00e9 hace DIM_TIEMPO_MENSUAL?","text":"<ol> <li> <p>Generaci\u00f3n de Datos Temporales:    Crea registros que representan cada mes dentro de un rango de fechas definido, desde enero de 2019 hasta diciembre de 2024.  </p> </li> <li> <p>Estructuraci\u00f3n de la Dimensi\u00f3n de Tiempo:    Organiza los datos en una tabla con atributos como identificadores, nombres de meses, a\u00f1os y fechas, facilitando consultas y an\u00e1lisis basados en periodos mensuales.</p> </li> <li> <p>Soporte al Cubo OLAP:    Act\u00faa como una dimensi\u00f3n esencial en el cubo OLAP, permitiendo a los usuarios realizar an\u00e1lisis temporales de manera eficiente.</p> </li> </ol>"},{"location":"03.Cubo/03.ETL/#detalles-de-la-implementacion","title":"Detalles de la Implementaci\u00f3n","text":"<ul> <li> <p>Ubicaci\u00f3n:   Los datos se cargan en la tabla <code>[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]</code>.</p> </li> <li> <p>Fuente de Datos:   No depende de una fuente externa; los datos se generan din\u00e1micamente dentro del flujo de datos de SSIS utilizando l\u00f3gica interna.</p> </li> <li> <p>Proceso en SSIS:  </p> <ul> <li>Tarea de Flujo de Datos: Llamada \"DIM_TIEMPO_MENSUAL\".  </li> <li>Componentes:  </li> <li>Origen: Un script o componente que genera las fechas mensuales.  </li> <li>Transformaciones:  <ul> <li><code>Derived Column</code>: Calcula valores como el nombre del mes, n\u00famero del mes, a\u00f1o, etc.  </li> <li><code>Data Conversion</code>: Ajusta tipos de datos si es necesario.  </li> </ul> </li> <li>Destino: Inserta los datos en la tabla mediante un componente OLE DB.</li> </ul> </li> <li> <p>Rango de Fechas:   Cubre desde enero de 2019 hasta diciembre de 2024, generando un registro por cada mes en este periodo.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#estructura-de-la-tabla","title":"Estructura de la Tabla","text":"<p>La tabla <code>DIM_TIEMPO_MENSUAL</code> contiene las siguientes columnas:</p> Columna Descripci\u00f3n Ejemplo <code>ID_MES</code> Identificador \u00fanico del mes (clave primaria) <code>201901</code> <code>NOMBRE_MES</code> Nombre completo del mes en espa\u00f1ol <code>Enero</code> <code>NUMERO_MES</code> N\u00famero del mes (1 a 12) <code>1</code> <code>ANIO</code> A\u00f1o correspondiente <code>2019</code> <code>MES_ANIO</code> Combinaci\u00f3n de mes y a\u00f1o <code>Enero 2019</code> <code>FECHA_INICIO</code> Primer d\u00eda del mes <code>2019-01-01</code> <code>FECHA_FIN</code> \u00daltimo d\u00eda del mes <code>2019-01-31</code>"},{"location":"03.Cubo/03.ETL/#como-se-generan-los-datos","title":"\u00bfC\u00f3mo se Generan los Datos?","text":"<ul> <li>L\u00f3gica:   Se utiliza un bucle o script en SSIS para iterar mes a mes desde 2019 hasta 2024.  </li> <li>C\u00e1lculos:  <ul> <li><code>ID_MES</code>: Puede ser un valor como <code>YYYYMM</code> (e.g., 201901).  </li> <li><code>NOMBRE_MES</code>: Extra\u00eddo de funciones de fecha (en espa\u00f1ol).  </li> <li><code>NUMERO_MES</code>: N\u00famero del mes (1 al 12).  </li> <li><code>ANIO</code>: A\u00f1o de la fecha.  </li> <li><code>MES_ANIO</code>: Concatenaci\u00f3n de <code>NOMBRE_MES</code> y <code>ANIO</code>.  </li> <li><code>FECHA_INICIO</code>: Primer d\u00eda del mes.  </li> <li><code>FECHA_FIN</code>: \u00daltimo d\u00eda del mes, ajustado seg\u00fan el mes y a\u00f1o (e.g., 28 o 29 para febrero).</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Ejecuci\u00f3n:   Esta tarea suele ejecutarse despu\u00e9s de limpiar las tablas del cubo (e.g., tarea <code>Truncar Tablas Cubo</code>), asegurando que la dimensi\u00f3n est\u00e9 lista antes de cargar datos de hechos.  </li> <li>Dependencias:   Tablas de hechos como <code>FACT_UNIDADES</code> o <code>FACT_ACTIVIDADES</code> usan esta dimensi\u00f3n para vincular datos a periodos mensuales en el cubo OLAP.</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_actividadesafiliacion-mensual-empresas","title":"<code>FACT_ACTIVIDADES\\\\Afiliacion mensual Empresas</code>","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\Afiliacion mensual Empresas</code> forma parte del paquete SSIS <code>09-ETLS_CUBO</code> y est\u00e1 dise\u00f1ado para gestionar datos relacionados con la afiliaci\u00f3n mensual de empresas dentro del Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, te detallo su prop\u00f3sito, funcionamiento e implementaci\u00f3n:</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p><code>FACT_ACTIVIDADES\\\\Afiliacion mensual Empresas</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_ACTIVIDADES</code> del paquete SSIS <code>09-ETLS_CUBO</code>. Su objetivo principal es:</p> <ol> <li>Extraer datos de afiliaci\u00f3n mensual de empresas desde una fuente de origen.</li> <li>Transformar esos datos aplicando l\u00f3gica de negocio.</li> <li>Cargar la informaci\u00f3n procesada en la tabla de hechos <code>FACT_ACTIVIDADES</code>, que sirve como base para an\u00e1lisis en un cubo OLAP.</li> </ol> <p>Esta tabla de hechos centraliza informaci\u00f3n sobre diversas actividades, incluyendo la afiliaci\u00f3n de empresas, para facilitar reportes y an\u00e1lisis multidimensionales.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete","title":"Ubicaci\u00f3n en el Paquete","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Tarea de Flujo de Datos: <code>FACT_ACTIVIDADES</code></li> <li>Componente: <code>Afiliacion mensual Empresas</code> (un subcomponente o transformaci\u00f3n dentro de la tarea mencionada).</li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_1","title":"Prop\u00f3sito","text":"<p>El componente tiene las siguientes funciones clave:</p> <ul> <li>Extracci\u00f3n: Obtiene datos de afiliaci\u00f3n de empresas, probablemente desde una tabla staging o una vista.</li> <li>Transformaci\u00f3n: Procesa los datos para calcular m\u00e9tricas como el n\u00famero de empresas afiliadas por mes.</li> <li>Carga: Inserta los datos transformados en <code>FACT_ACTIVIDADES</code>, vincul\u00e1ndolos con dimensiones relevantes como tiempo o empresas.</li> </ul>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion","title":"Detalles de Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:</p> <ul> <li>Aunque la fuente exacta no se especifica aqu\u00ed, suele ser una tabla intermedia (staging) o una vista que contiene informaci\u00f3n de afiliaci\u00f3n de empresas.</li> </ul> </li> <li> <p>Transformaciones:</p> <ul> <li>Derived Column: Genera columnas calculadas necesarias para la tabla de hechos.</li> <li>Lookup: Conecta los datos con dimensiones como <code>DIM_TIEMPO_MENSUAL</code> para obtener claves for\u00e1neas (e.g., <code>ID_MES</code>).</li> <li>Aggregate: Puede realizar agregaciones, como sumar el n\u00famero de empresas afiliadas por mes.</li> </ul> </li> <li> <p>Destino:</p> <ul> <li>Los datos procesados se cargan en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code>.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio","title":"L\u00f3gica de Negocio","text":"<ul> <li>C\u00e1lculo de Afiliaci\u00f3n Mensual: Determina cu\u00e1ntas empresas est\u00e1n afiliadas en un mes espec\u00edfico y, posiblemente, otros indicadores como nuevas afiliaciones o cancelaciones.</li> <li>Vinculaci\u00f3n Temporal: Asocia cada registro con el mes correspondiente en la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code>.</li> <li>Integridad: Garantiza que las claves for\u00e1neas en <code>FACT_ACTIVIDADES</code> coincidan con registros v\u00e1lidos en las dimensiones relacionadas.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_1","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Dependencias: Requiere que la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> est\u00e9 cargada previamente para vincular los datos temporales.</li> <li>Secuencia: Se ejecuta despu\u00e9s de tareas iniciales como el truncado de tablas y la carga de dimensiones, pero antes de procesos que usen los datos de <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_actividadesalmacenar-max-afiliados","title":"<code>FACT_ACTIVIDADES\\\\Almacenar MAX afiliados</code>","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\Almacenar MAX afiliados</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_ACTIVIDADES</code> del paquete SSIS <code>09-ETLS_CUBO</code>. Su prop\u00f3sito es calcular y almacenar el n\u00famero m\u00e1ximo de afiliados en la tabla de hechos <code>FACT_ACTIVIDADES</code>, proporcionando una medida clave para el an\u00e1lisis de datos en el Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su funcionalidad, implementaci\u00f3n y relevancia dentro del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p><code>FACT_ACTIVIDADES\\\\Almacenar MAX afiliados</code> se encarga de:</p> <ol> <li>Extraer datos relevantes sobre afiliados desde una fuente de origen.</li> <li>Calcular el n\u00famero m\u00e1ximo de afiliados seg\u00fan criterios espec\u00edficos (por ejemplo, por empresa, por mes, etc.).</li> <li>Almacenar esta medida en la tabla de hechos <code>FACT_ACTIVIDADES</code> para su uso en an\u00e1lisis multidimensionales.</li> </ol> <p>Esta tarea es fundamental para identificar picos de afiliaci\u00f3n y analizar tendencias a lo largo del tiempo en el cubo OLAP.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_1","title":"Ubicaci\u00f3n en el Paquete","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Tarea de Flujo de Datos: <code>FACT_ACTIVIDADES</code></li> <li>Componente: <code>Almacenar MAX afiliados</code> (una transformaci\u00f3n o c\u00e1lculo dentro del flujo de datos).</li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_2","title":"Prop\u00f3sito","text":"<p>El componente tiene las siguientes funciones clave:</p> <ul> <li>Extracci\u00f3n: Obtiene datos de afiliados desde una tabla staging o vista.</li> <li>Transformaci\u00f3n: Calcula el n\u00famero m\u00e1ximo de afiliados utilizando agregaciones.</li> <li>Carga: Inserta la medida calculada en <code>FACT_ACTIVIDADES</code>, vincul\u00e1ndola con las dimensiones correspondientes (como tiempo o empresas).</li> </ul>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_1","title":"Detalles de Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:</p> <ul> <li>Los datos provienen de una fuente que contiene informaci\u00f3n detallada sobre afiliados, como una tabla staging o una vista en la base de datos.</li> </ul> </li> <li> <p>Transformaciones:</p> <ul> <li>Aggregate: Se utiliza para agrupar los datos y calcular el valor m\u00e1ximo de afiliados seg\u00fan las dimensiones relevantes (por ejemplo, por mes o por empresa).</li> <li>Lookup: Conecta los datos agregados con dimensiones como <code>DIM_TIEMPO_MENSUAL</code> para obtener las claves for\u00e1neas (e.g., <code>ID_MES</code>).</li> <li>Derived Column: Puede generar columnas adicionales necesarias para la tabla de hechos.</li> </ul> </li> <li> <p>Destino:</p> <ul> <li>Los resultados se cargan en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> utilizando un componente OLE DB Destination.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_1","title":"L\u00f3gica de Negocio","text":"<ul> <li>C\u00e1lculo del M\u00e1ximo de Afiliados: Determina el n\u00famero m\u00e1ximo de afiliados en un contexto espec\u00edfico, como el m\u00e1ximo n\u00famero de afiliados por empresa en un mes.</li> <li>Vinculaci\u00f3n con Dimensiones: Asocia el valor m\u00e1ximo con las claves for\u00e1neas de las dimensiones relevantes (e.g., <code>ID_MES</code>, <code>ID_EMPRESA</code>).</li> <li>Integridad de Datos: Asegura que los valores calculados sean consistentes y precisos para su uso en an\u00e1lisis.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_2","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Dependencias: Requiere que las dimensiones como <code>DIM_TIEMPO_MENSUAL</code> est\u00e9n cargadas previamente para vincular correctamente los datos.</li> <li>Secuencia: Se ejecuta despu\u00e9s de la carga de dimensiones y antes de otras tareas que puedan depender de los datos en <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#importancia","title":"Importancia","text":"<p>El c\u00e1lculo y almacenamiento del n\u00famero m\u00e1ximo de afiliados es crucial para:</p> <ul> <li>Identificar per\u00edodos o empresas con picos de afiliaci\u00f3n.</li> <li>Comparar el rendimiento entre diferentes empresas o regiones.</li> <li>Tomar decisiones informadas basadas en tendencias hist\u00f3ricas.</li> </ul> <p>Al integrar esta medida en <code>FACT_ACTIVIDADES</code>, se enriquece el cubo OLAP y se mejora la capacidad anal\u00edtica del Data Warehouse.</p>"},{"location":"03.Cubo/03.ETL/#fact_actividadescontenedor-de-bucles-forafiliacion-mensual-afiliados","title":"<code>FACT_ACTIVIDADES\\\\Contenedor de bucles For\\\\Afiliacion mensual Afiliados</code>","text":"<p>Forma parte del paquete SSIS dentro del proceso ETL del Data Warehouse <code>DWH_COMFENALCO</code>, espec\u00edficamente en el paquete <code>09-ETLS_CUBO</code>. A continuaci\u00f3n, te explico de qu\u00e9 se trata y c\u00f3mo funciona:</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-y-contexto","title":"Ubicaci\u00f3n y Contexto","text":"<ul> <li>Este componente est\u00e1 dentro de la tarea de flujo de datos <code>FACT_ACTIVIDADES</code>.</li> <li>Se encuentra anidado en un Contenedor de bucles For, que es una estructura en SSIS dise\u00f1ada para repetir un conjunto de tareas o procesos bas\u00e1ndose en una condici\u00f3n o un conjunto de valores.</li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_3","title":"Prop\u00f3sito","text":"<p>El Contenedor de bucles For tiene como objetivo procesar datos de manera iterativa. En este caso, se utiliza para manejar la afiliaci\u00f3n mensual de afiliados, probablemente iterando sobre una lista de meses o periodos de tiempo. Por cada iteraci\u00f3n, el componente <code>Afiliacion mensual Afiliados</code> se encarga de procesar los datos correspondientes a un mes espec\u00edfico.</p>"},{"location":"03.Cubo/03.ETL/#funcionamiento","title":"Funcionamiento","text":"<ol> <li> <p>Iteraci\u00f3n:</p> <ul> <li>El contenedor define un bucle que recorre diferentes periodos (por ejemplo, una lista de meses: enero, febrero, marzo, etc.).</li> <li>En cada vuelta del bucle, se ejecuta el componente <code>Afiliacion mensual Afiliados</code>.</li> </ul> </li> <li> <p>Tareas del Componente:</p> <ul> <li>Extracci\u00f3n: Obtiene los datos de afiliados para el mes correspondiente, posiblemente desde una tabla temporal o staging.</li> <li>Transformaci\u00f3n: Realiza c\u00e1lculos o procesamientos espec\u00edficos, como determinar el n\u00famero de afiliados activos en ese mes.</li> <li>Carga: Inserta los datos procesados en la tabla de hechos <code>FACT_ACTIVIDADES</code>, vincul\u00e1ndolos con las dimensiones relevantes del Data Warehouse.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#fact_actividadesalmacenar-max-beneficiarios","title":"<code>FACT_ACTIVIDADES\\\\Almacenar MAX beneficiarios</code>","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\Almacenar MAX beneficiarios</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_ACTIVIDADES</code> del paquete SSIS <code>09-ETLS_CUBO</code>. Su prop\u00f3sito es calcular y almacenar el n\u00famero m\u00e1ximo de beneficiarios en la tabla de hechos <code>FACT_ACTIVIDADES</code>, proporcionando una medida clave para el an\u00e1lisis de datos en el Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su funcionalidad, implementaci\u00f3n y relevancia dentro del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p><code>FACT_ACTIVIDADES\\\\Almacenar MAX beneficiarios</code> se encarga de:</p> <ol> <li>Extraer datos relevantes sobre beneficiarios desde una fuente de origen.</li> <li>Calcular el n\u00famero m\u00e1ximo de beneficiarios seg\u00fan criterios espec\u00edficos (por ejemplo, por empresa, por mes, etc.).</li> <li>Almacenar esta medida en la tabla de hechos <code>FACT_ACTIVIDADES</code> para su uso en an\u00e1lisis multidimensionales.</li> </ol> <p>Esta tarea es fundamental para identificar picos en el n\u00famero de beneficiarios y analizar tendencias a lo largo del tiempo en el cubo OLAP, lo cual es \u00fatil para la planificaci\u00f3n de recursos y la evaluaci\u00f3n de la capacidad de servicio.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-en-el-paquete_2","title":"Ubicaci\u00f3n en el Paquete","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Tarea de Flujo de Datos: <code>FACT_ACTIVIDADES</code></li> <li>Componente: <code>Almacenar MAX beneficiarios</code> (una transformaci\u00f3n o c\u00e1lculo dentro del flujo de datos).</li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito_4","title":"Prop\u00f3sito","text":"<p>El componente tiene las siguientes funciones clave:</p> <ul> <li>Extracci\u00f3n: Obtiene datos de beneficiarios desde una tabla staging o vista.</li> <li>Transformaci\u00f3n: Calcula el n\u00famero m\u00e1ximo de beneficiarios utilizando agregaciones.</li> <li>Carga: Inserta la medida calculada en <code>FACT_ACTIVIDADES</code>, vincul\u00e1ndola con las dimensiones correspondientes (como tiempo o empresas).</li> </ul>"},{"location":"03.Cubo/03.ETL/#detalles-de-implementacion_2","title":"Detalles de Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:</p> <ul> <li>Los datos provienen de una fuente que contiene informaci\u00f3n detallada sobre beneficiarios, como una tabla staging o una vista en la base de datos.</li> </ul> </li> <li> <p>Transformaciones:</p> <ul> <li>Aggregate: Se utiliza para agrupar los datos y calcular el valor m\u00e1ximo de beneficiarios seg\u00fan las dimensiones relevantes (por ejemplo, por mes o por empresa).</li> <li>Lookup: Conecta los datos agregados con dimensiones como <code>DIM_TIEMPO_MENSUAL</code> para obtener las claves for\u00e1neas (e.g., <code>ID_MES</code>).</li> <li>Derived Column: Puede generar columnas adicionales necesarias para la tabla de hechos.</li> </ul> </li> <li> <p>Destino:</p> <ul> <li>Los resultados se cargan en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> utilizando un componente OLE DB Destination.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_2","title":"L\u00f3gica de Negocio","text":"<ul> <li>C\u00e1lculo del M\u00e1ximo de Beneficiarios: Determina el n\u00famero m\u00e1ximo de beneficiarios en un contexto espec\u00edfico, como el m\u00e1ximo n\u00famero de beneficiarios por empresa en un mes.</li> <li>Vinculaci\u00f3n con Dimensiones: Asocia el valor m\u00e1ximo con las claves for\u00e1neas de las dimensiones relevantes (e.g., <code>ID_MES</code>, <code>ID_EMPRESA</code>).</li> <li>Integridad de Datos: Asegura que los valores calculados sean consistentes y precisos para su uso en an\u00e1lisis.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_3","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Dependencias: Requiere que las dimensiones como <code>DIM_TIEMPO_MENSUAL</code> est\u00e9n cargadas previamente para vincular correctamente los datos.</li> <li>Secuencia: Se ejecuta despu\u00e9s de la carga de dimensiones y antes de otras tareas que puedan depender de los datos en <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_actividadescontenedor-de-bucles-for-1afiliacion-mensual-beneficiarios","title":"<code>FACT_ACTIVIDADES\\\\Contenedor de bucles For 1\\\\Afiliacion mensual Beneficiarios</code>","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\Contenedor de bucles For 1\\\\Afiliacion mensual Beneficiarios</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_ACTIVIDADES</code>, que pertenece al paquete SSIS <code>09-ETLS_CUBO</code>. Este componente desempe\u00f1a un papel clave en el proceso ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) al procesar datos de afiliaci\u00f3n mensual de beneficiarios de manera eficiente mediante un contenedor de bucle For. A continuaci\u00f3n, se explica su prop\u00f3sito, funcionamiento y relevancia.</p>"},{"location":"03.Cubo/03.ETL/#que-hace-este-componente","title":"\u00bfQu\u00e9 hace este componente?","text":"<p>Este componente est\u00e1 dise\u00f1ado para:</p> <ol> <li>Iterar sobre periodos: Utiliza un contenedor de bucle For en SSIS para recorrer una serie de periodos, probablemente meses, de manera secuencial.</li> <li>Procesar datos por periodo: Para cada iteraci\u00f3n, extrae, transforma y carga los datos de afiliaci\u00f3n de beneficiarios correspondientes al periodo actual.</li> <li>Almacenar resultados: Inserta los datos procesados en la tabla de hechos <code>FACT_ACTIVIDADES</code>, que forma parte del Data Warehouse <code>DWH_COMFENALCO</code>, para su uso en an\u00e1lisis multidimensionales.</li> </ol> <p>El enfoque basado en bucles permite manejar grandes vol\u00famenes de datos dividi\u00e9ndolos en unidades m\u00e1s peque\u00f1as (por ejemplo, un mes a la vez), lo que mejora la eficiencia y facilita la carga incremental.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion-dentro-del-paquete-ssis","title":"Ubicaci\u00f3n dentro del paquete SSIS","text":"<ul> <li>Paquete: <code>09-ETLS_CUBO</code></li> <li>Flujo de datos: <code>FACT_ACTIVIDADES</code></li> <li>Contenedor: <code>Contenedor de bucles For 1</code></li> <li>Tarea espec\u00edfica: <code>Afiliacion mensual Beneficiarios</code></li> </ul> <p>Este componente opera dentro de un flujo de datos m\u00e1s amplio que alimenta la tabla <code>FACT_ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#funcionamiento-detallado","title":"Funcionamiento detallado","text":"<p>El componente sigue un proceso estructurado:</p> <ol> <li> <p>Configuraci\u00f3n del bucle For:</p> <ul> <li>Se define una variable (por ejemplo, <code>MesActual</code>) que se actualiza en cada iteraci\u00f3n para representar el periodo procesado.</li> <li>El bucle recorre una lista predefinida de meses o periodos.</li> </ul> </li> <li> <p>Extracci\u00f3n:</p> <ul> <li>Para cada iteraci\u00f3n, se extraen datos de afiliaci\u00f3n de beneficiarios desde una fuente (como una base de datos origen), filtrados por el periodo actual.</li> </ul> </li> <li> <p>Transformaci\u00f3n:</p> <ul> <li>Columna derivada: Se generan columnas calculadas necesarias para la tabla de hechos.</li> <li>B\u00fasqueda (Lookup): Los datos se vinculan con dimensiones como <code>DIM_TIEMPO_MENSUAL</code> para asignar claves for\u00e1neas (por ejemplo, <code>ID_MES</code>).</li> <li>Agregaci\u00f3n: Si es necesario, se calculan m\u00e9tricas como el n\u00famero total de beneficiarios afiliados por mes.</li> </ul> </li> <li> <p>Carga:</p> <ul> <li>Los datos transformados se insertan en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> mediante un componente OLE DB Destination.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#importancia-en-el-proceso-etl","title":"Importancia en el proceso ETL","text":"<p>El uso de un contenedor de bucle For en este componente aporta varios beneficios:</p> <ul> <li>Eficiencia: Divide el procesamiento de grandes vol\u00famenes de datos en partes manejables.</li> <li>Flexibilidad: Permite incorporar nuevos periodos sin cambiar la l\u00f3gica principal del flujo.</li> <li>Escalabilidad: Facilita la gesti\u00f3n de datos hist\u00f3ricos o actuales de manera incremental.</li> </ul> <p>Adem\u00e1s, asegura que los datos en <code>FACT_ACTIVIDADES</code> est\u00e9n correctamente vinculados a dimensiones como <code>DIM_TIEMPO_MENSUAL</code>, manteniendo la integridad y consistencia necesarias para an\u00e1lisis posteriores.</p>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_4","title":"Relaci\u00f3n con otros componentes","text":"<ul> <li>Dependencias: Requiere que la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> est\u00e9 cargada previamente para asociar los datos con los periodos correctos.</li> <li>Secuencia: Se ejecuta despu\u00e9s de la carga de dimensiones y antes de tareas que utilicen los datos de <code>FACT_ACTIVIDADES</code>.</li> </ul> <p>El componente <code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_PQRS</code> forma parte de un paquete SSIS (SQL Server Integration Services), espec\u00edficamente el paquete <code>09-ETLS_CUBO</code>, y est\u00e1 relacionado con un proceso ETL (Extract, Transform, Load) dise\u00f1ado para cargar datos en un Data Warehouse, probablemente <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, te explico de manera detallada qu\u00e9 es y cu\u00e1l es su prop\u00f3sito.</p>"},{"location":"03.Cubo/03.ETL/#fact_actividadesfact_actividades_pqrs","title":"<code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_PQRS</code>","text":"<ul> <li><code>FACT_ACTIVIDADES_PQRS</code>: La parte <code>_PQRS</code>, este componente se enfoca en un subconjunto espec\u00edfico de datos dentro de <code>FACT_ACTIVIDADES</code>, relacionado con \"Peticiones, Quejas, Reclamos y Sugerencias\" (PQRS), un t\u00e9rmino com\u00fan en la gesti\u00f3n de servicios o atenci\u00f3n al cliente.</li> </ul>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_PQRS</code> tiene como objetivo principal procesar datos relacionados con PQRS dentro del flujo ETL. Sus funciones espec\u00edficas son:</p> <ol> <li>Extracci\u00f3n: Obtiene datos de PQRS desde una fuente de origen, que podr\u00eda ser una base de datos operativa, un archivo plano u otro sistema donde se registren estas interacciones.</li> <li>Transformaci\u00f3n: Prepara los datos para que se ajusten al esquema de la tabla <code>FACT_ACTIVIDADES</code>. Esto puede incluir:<ul> <li>C\u00e1lculo de medidas, como el n\u00famero de PQRS por periodo o tipo.</li> <li>Mapeo de claves for\u00e1neas a tablas de dimensiones (por ejemplo, tiempo, cliente o tipo de actividad).</li> <li>Limpieza y normalizaci\u00f3n de datos.</li> </ul> </li> <li>Carga: Inserta los datos transformados en la tabla de hechos <code>FACT_ACTIVIDADES</code>, espec\u00edficamente en registros relacionados con actividades de PQRS.</li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-en-ssis","title":"Implementaci\u00f3n en SSIS","text":"<p>En el contexto de SSIS, <code>FACT_ACTIVIDADES_PQRS</code> es probablemente una tarea de flujo de datos dentro del paquete. Esta tarea incluir\u00eda:</p> <ul> <li>Origen de Datos: Un componente como OLE DB Source o ADO NET Source, configurado con una consulta SQL que extrae datos de PQRS. Por ejemplo, podr\u00eda filtrar registros donde el tipo de actividad sea \"PQRS\".</li> <li>Transformaciones: Algunas transformaciones comunes podr\u00edan ser:<ul> <li>Derived Column: Para crear o modificar columnas.</li> <li>Lookup: Para vincular los datos con claves for\u00e1neas de dimensiones.</li> <li>Data Conversion: Para ajustar tipos de datos.</li> <li>Aggregate: Para realizar c\u00e1lculos, como sumar el n\u00famero de PQRS.</li> </ul> </li> <li>Destino: Un componente como OLE DB Destination que carga los datos en <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-el-paquete","title":"Relaci\u00f3n con el Paquete","text":"<ul> <li>Dependencias: Este componente depende de que las tablas de dimensiones (como tiempo, clientes o tipos de actividad) est\u00e9n cargadas previamente, ya que necesita sus claves for\u00e1neas.</li> <li>Secuencia: En el paquete <code>09-ETLS_CUBO</code>, se ejecutar\u00eda despu\u00e9s de las tareas que cargan las dimensiones y antes de cualquier tarea que use los datos de <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#importancia_1","title":"Importancia","text":"<p>Este componente es clave para: - Centralizaci\u00f3n: Re\u00fane datos de PQRS en una tabla de hechos para an\u00e1lisis multidimensionales. - An\u00e1lisis: Proporciona datos estructurados para reportes y dashboards sobre calidad de servicio o satisfacci\u00f3n del cliente. - Integridad: Asegura que los datos de PQRS est\u00e9n correctamente vinculados a las dimensiones para an\u00e1lisis precisos.</p>"},{"location":"03.Cubo/03.ETL/#fact_actividadesfact_actividades_nps","title":"<code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_NPS</code>","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_NPS</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_ACTIVIDADES</code>, que pertenece al paquete SSIS <code>09-ETLS_CUBO</code>. Su funci\u00f3n principal es procesar y cargar datos relacionados con el Net Promoter Score (NPS) en la tabla de hechos <code>FACT_ACTIVIDADES</code> del Data Warehouse <code>DWH_COMFENALCO</code>. Este componente forma parte de un proceso ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) dise\u00f1ado para analizar la satisfacci\u00f3n y lealtad del cliente.</p>"},{"location":"03.Cubo/03.ETL/#que-es-el-nps","title":"\u00bfQu\u00e9 es el NPS?","text":"<p>El Net Promoter Score (NPS) es una m\u00e9trica que mide la lealtad y satisfacci\u00f3n de los clientes basada en una pregunta clave: \"\u00bfQu\u00e9 tan probable es que recomiende nuestro servicio/producto a un amigo o colega?\" Los clientes responden en una escala de 0 a 10 y se clasifican en tres categor\u00edas:</p> <ul> <li>Promotores (9-10): Clientes leales y entusiastas.</li> <li>Pasivos (7-8): Clientes satisfechos pero indiferentes.</li> <li>Detractores (0-6): Clientes insatisfechos que podr\u00edan da\u00f1ar la reputaci\u00f3n.</li> </ul> <p>El c\u00e1lculo del NPS se realiza con la f\u00f3rmula: NPS = (% Promotores) - (% Detractores).</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_1","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_ACTIVIDADES_NPS</code> tiene como objetivo:</p> <ol> <li>Extraer: Obtener datos de encuestas NPS desde una fuente de origen, como una tabla staging o una vista.</li> <li>Transformar: Procesar las respuestas para clasificarlas en promotores, pasivos y detractores, y calcular el NPS por periodo, empresa o servicio.</li> <li>Cargar: Insertar las m\u00e9tricas calculadas en la tabla <code>FACT_ACTIVIDADES</code> para su uso en an\u00e1lisis multidimensionales.</li> </ol> <p>Esto permite a la organizaci\u00f3n evaluar la experiencia del cliente y tomar decisiones basadas en datos.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Flujo de Datos: <code>FACT_ACTIVIDADES</code></li> <li>Componente: <code>FACT_ACTIVIDADES_NPS</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:    Los datos se extraen de una fuente que contiene respuestas de encuestas NPS, como una base de datos transaccional o una tabla temporal.</p> </li> <li> <p>Transformaciones:  </p> <ul> <li>Clasificaci\u00f3n: Se asignan las respuestas a las categor\u00edas de promotores (9-10), pasivos (7-8) y detractores (0-6).  </li> <li>C\u00e1lculo: Se agregan las respuestas para determinar el n\u00famero de promotores, pasivos y detractores, y se calcula el NPS.  </li> <li>Vinculaci\u00f3n: Se conectan los datos con dimensiones como <code>DIM_TIEMPO_MENSUAL</code> o <code>DIM_EMPRESA</code> para asociar las m\u00e9tricas con claves for\u00e1neas (e.g., <code>ID_MES</code>, <code>ID_EMPRESA</code>).</li> </ul> </li> <li> <p>Destino:    Los resultados se insertan en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> utilizando un componente OLE DB Destination.</p> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_3","title":"L\u00f3gica de Negocio","text":"<ul> <li>Clasificaci\u00f3n:  <ul> <li>Promotores: Puntuaciones 9-10.  </li> <li>Pasivos: Puntuaciones 7-8.  </li> <li>Detractores: Puntuaciones 0-6.  </li> </ul> </li> <li>C\u00e1lculo del NPS:  <ul> <li><code>% Promotores = (N\u00famero de Promotores / Total de Respuestas) * 100</code> </li> <li><code>% Detractores = (N\u00famero de Detractores / Total de Respuestas) * 100</code> </li> <li><code>NPS = % Promotores - % Detractores</code> </li> </ul> </li> <li>Agrupaci\u00f3n: Las m\u00e9tricas se calculan por grupos relevantes, como mes o empresa.</li> </ul>"},{"location":"03.Cubo/03.ETL/#importancia_2","title":"Importancia","text":"<p>El componente <code>FACT_ACTIVIDADES_NPS</code> es esencial porque: - Proporciona m\u00e9tricas clave sobre la satisfacci\u00f3n y lealtad del cliente. - Permite identificar tendencias y \u00e1reas de mejora. - Facilita comparaciones entre periodos o empresas. - Alimenta el cubo OLAP para an\u00e1lisis avanzados.</p>"},{"location":"03.Cubo/03.ETL/#fact_actividadesfact_actividades_proteccion","title":"<code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_PROTECCION</code>","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_PROTECCION</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_ACTIVIDADES</code>, que forma parte del paquete SSIS <code>09-ETLS_CUBO</code>. Este componente est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con actividades de protecci\u00f3n en la tabla de hechos <code>FACT_ACTIVIDADES</code> del Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su prop\u00f3sito, implementaci\u00f3n y relevancia en el contexto del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-proteccion-en-este-contexto","title":"\u00bfQu\u00e9 significa \"Protecci\u00f3n\" en este contexto?","text":"<p>El t\u00e9rmino \"Protecci\u00f3n\" podr\u00eda referirse a actividades espec\u00edficas gestionadas por COMFENALCO (una caja de compensaci\u00f3n familiar en Colombia), como:</p> <ul> <li>Servicios de seguridad social (por ejemplo, protecci\u00f3n laboral o beneficios asociados).</li> <li>Programas de asistencia o cobertura para afiliados y beneficiarios.</li> <li>Actividades relacionadas con la gesti\u00f3n de riesgos o protecci\u00f3n de datos.</li> </ul> <p>Dado que no se proporciona un contexto expl\u00edcito, asumir\u00e9 que se trata de un subconjunto de datos dentro de <code>FACT_ACTIVIDADES</code> que mide o registra actividades relacionadas con alg\u00fan tipo de servicio o programa de protecci\u00f3n.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_2","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_ACTIVIDADES_PROTECCION</code> tiene como objetivo:</p> <ol> <li>Extraer: Obtener datos relacionados con actividades de protecci\u00f3n desde una fuente de origen, como una base de datos operativa o una tabla staging.</li> <li>Transformar: Procesar los datos para calcular m\u00e9tricas relevantes (por ejemplo, n\u00famero de beneficiarios protegidos, eventos registrados, o costos asociados) y vincularlos a dimensiones.</li> <li>Cargar: Insertar los datos transformados en la tabla <code>FACT_ACTIVIDADES</code> para su uso en an\u00e1lisis multidimensionales dentro del cubo OLAP.</li> </ol> <p>Este componente permite analizar c\u00f3mo se desempe\u00f1an los servicios o programas de protecci\u00f3n en t\u00e9rminos de cobertura, impacto o uso.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion_1","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Flujo de Datos: <code>FACT_ACTIVIDADES</code></li> <li>Componente: <code>FACT_ACTIVIDADES_PROTECCION</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_1","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:  </p> <ul> <li>Los datos se extraen de una fuente que contiene informaci\u00f3n sobre actividades de protecci\u00f3n, como una tabla transaccional o una vista espec\u00edfica.</li> </ul> </li> <li> <p>Transformaciones:  </p> <ul> <li>Derived Column: Genera columnas calculadas o ajusta datos seg\u00fan sea necesario (por ejemplo, categorizar tipos de protecci\u00f3n).  </li> <li>Lookup: Vincula los datos con dimensiones como <code>DIM_TIEMPO_MENSUAL</code> (para el periodo) o una dimensi\u00f3n de empresas/afiliados (para identificar qui\u00e9n recibe la protecci\u00f3n).  </li> <li>Aggregate: Calcula m\u00e9tricas como el n\u00famero total de eventos de protecci\u00f3n o beneficiarios cubiertos por periodo.</li> </ul> </li> <li> <p>Destino:  </p> <ul> <li>Los datos procesados se insertan en <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> mediante un componente OLE DB Destination.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_4","title":"L\u00f3gica de Negocio","text":"<ul> <li>M\u00e9tricas:  <ul> <li>N\u00famero de beneficiarios protegidos por mes.  </li> <li>Cantidad de eventos o actividades de protecci\u00f3n registradas.  </li> <li>Costos asociados (si aplica).  </li> </ul> </li> <li>Vinculaci\u00f3n:  <ul> <li>Cada registro se asocia con claves for\u00e1neas de dimensiones relevantes, como <code>ID_MES</code> (de <code>DIM_TIEMPO_MENSUAL</code>) o <code>ID_EMPRESA</code>.  </li> </ul> </li> <li>Consistencia: Asegura que los datos sean precisos y est\u00e9n alineados con las necesidades del cubo OLAP.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_5","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Dependencias: Requiere que las dimensiones relevantes (como <code>DIM_TIEMPO_MENSUAL</code>) est\u00e9n cargadas previamente.  </li> <li>Secuencia: Se ejecuta despu\u00e9s de la carga de dimensiones y antes de tareas que consuman los datos de <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#importancia_3","title":"Importancia","text":"<p>El componente <code>FACT_ACTIVIDADES_PROTECCION</code> es clave para: - Monitoreo: Permite rastrear el desempe\u00f1o de los programas o servicios de protecci\u00f3n. - Toma de decisiones: Proporciona datos para evaluar la efectividad o el alcance de estas actividades. - An\u00e1lisis multidimensional: Enriquece el cubo OLAP con informaci\u00f3n espec\u00edfica sobre protecci\u00f3n, \u00fatil para reportes y dashboards.</p>"},{"location":"03.Cubo/03.ETL/#fact_actividadesfact_actividades_cedesarrollo","title":"<code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_CEDESARROLLO</code>","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_CEDESARROLLO</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_ACTIVIDADES</code>, que pertenece al paquete SSIS <code>09-ETLS_CUBO</code>. Este componente est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con actividades de CEDESARROLLO en la tabla de hechos <code>FACT_ACTIVIDADES</code> del Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su prop\u00f3sito, implementaci\u00f3n y relevancia dentro del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-cedesarrollo-en-este-contexto","title":"\u00bfQu\u00e9 significa \"CEDESARROLLO\" en este contexto?","text":"<p>El t\u00e9rmino \"CEDESARROLLO\" no tiene una definici\u00f3n universalmente clara sin contexto adicional, pero en el \u00e1mbito de COMFENALCO (una caja de compensaci\u00f3n familiar en Colombia), podr\u00eda referirse a:</p> <ul> <li>Centros de Desarrollo: Actividades relacionadas con centros de formaci\u00f3n, capacitaci\u00f3n o desarrollo profesional/communityario.</li> <li>Programas Espec\u00edficos: Un programa o iniciativa interna de COMFENALCO enfocada en desarrollo social, educativo o econ\u00f3mico.</li> <li>Acr\u00f3nimo: Podr\u00eda ser una abreviatura de un nombre m\u00e1s largo (por ejemplo, \"Centro de Desarrollo\").</li> </ul> <p>Dado que estamos trabajando con un Data Warehouse y un cubo OLAP, asumiremos que CEDESARROLLO se refiere a un tipo de actividad espec\u00edfica (como cursos, talleres o servicios de desarrollo) que se mide y analiza.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_3","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_ACTIVIDADES_CEDESARROLLO</code> tiene como objetivo:</p> <ol> <li>Extraer: Obtener datos relacionados con actividades de CEDESARROLLO desde una fuente de origen, como una base de datos operativa o una tabla staging.</li> <li>Transformar: Procesar los datos para calcular m\u00e9tricas relevantes (por ejemplo, n\u00famero de participantes, eventos realizados, o impacto) y vincularlos a dimensiones.</li> <li>Cargar: Insertar los datos transformados en la tabla <code>FACT_ACTIVIDADES</code> para su uso en an\u00e1lisis multidimensionales dentro del cubo OLAP.</li> </ol> <p>Esto permite medir y analizar el desempe\u00f1o o impacto de las actividades de CEDESARROLLO en el contexto de COMFENALCO.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion_2","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Flujo de Datos: <code>FACT_ACTIVIDADES</code></li> <li>Componente: <code>FACT_ACTIVIDADES_CEDESARROLLO</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_2","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:  </p> <ul> <li>Los datos se extraen de una fuente que contiene informaci\u00f3n sobre actividades de CEDESARROLLO, como una tabla transaccional o una vista espec\u00edfica.</li> </ul> </li> <li> <p>Transformaciones:  </p> <ul> <li>Derived Column: Genera columnas calculadas o ajusta datos seg\u00fan sea necesario (por ejemplo, categorizar tipos de actividades de desarrollo).  </li> <li>Lookup: Vincula los datos con dimensiones como <code>DIM_TIEMPO_MENSUAL</code> (para el periodo) o una dimensi\u00f3n de empresas/participantes (para identificar qui\u00e9n participa).  </li> <li>Aggregate: Calcula m\u00e9tricas como el n\u00famero total de eventos, participantes o resultados por periodo.</li> </ul> </li> <li> <p>Destino:  </p> <ul> <li>Los datos procesados se insertan en <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> mediante un componente OLE DB Destination.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_5","title":"L\u00f3gica de Negocio","text":"<ul> <li>M\u00e9tricas:  <ul> <li>N\u00famero de participantes en actividades de CEDESARROLLO por mes.  </li> <li>Cantidad de eventos o talleres realizados.  </li> <li>Indicadores de impacto (si aplica, como horas de capacitaci\u00f3n).  </li> </ul> </li> <li>Vinculaci\u00f3n:  <ul> <li>Cada registro se asocia con claves for\u00e1neas de dimensiones relevantes, como <code>ID_MES</code> (de <code>DIM_TIEMPO_MENSUAL</code>) o <code>ID_EMPRESA</code>.  </li> </ul> </li> <li>Consistencia: Asegura que los datos sean precisos y est\u00e9n alineados con las necesidades del cubo OLAP.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_6","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Dependencias: Requiere que las dimensiones relevantes (como <code>DIM_TIEMPO_MENSUAL</code>) est\u00e9n cargadas previamente.  </li> <li>Secuencia: Se ejecuta despu\u00e9s de la carga de dimensiones y antes de tareas que consuman los datos de <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#importancia_4","title":"Importancia","text":"<p>El componente <code>FACT_ACTIVIDADES_CEDESARROLLO</code> es clave para: - Monitoreo: Permite rastrear el desempe\u00f1o de las actividades de desarrollo. - Toma de decisiones: Proporciona datos para evaluar la efectividad o el alcance de estas iniciativas. - An\u00e1lisis multidimensional: Enriquece el cubo OLAP con informaci\u00f3n espec\u00edfica sobre CEDESARROLLO, \u00fatil para reportes y dashboards.</p>"},{"location":"03.Cubo/03.ETL/#fact_actividadesfact_actividades_colegio","title":"<code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_COLEGIO</code>","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\FACT_ACTIVIDADES_COLEGIO</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_ACTIVIDADES</code>, que pertenece al paquete SSIS <code>09-ETLS_CUBO</code>. Este componente est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con actividades de colegio en la tabla de hechos <code>FACT_ACTIVIDADES</code> del Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su prop\u00f3sito, implementaci\u00f3n y relevancia en el contexto del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-colegio-en-este-contexto","title":"\u00bfQu\u00e9 significa \"COLEGIO\" en este contexto?","text":"<p>En el \u00e1mbito de COMFENALCO, una caja de compensaci\u00f3n familiar en Colombia, \"COLEGIO\" probablemente se refiere a actividades asociadas con instituciones educativas gestionadas o apoyadas por la entidad. Esto podr\u00eda incluir:</p> <ul> <li>Matriculaci\u00f3n de estudiantes.</li> <li>Participaci\u00f3n en actividades educativas o extracurriculares.</li> <li>M\u00e9tricas relacionadas con el desempe\u00f1o escolar o asistencia.</li> <li>Programas educativos espec\u00edficos para afiliados o beneficiarios.</li> </ul> <p>Dado que estamos en un Data Warehouse y un cubo OLAP, este componente se enfoca en medir y analizar actividades relacionadas con el \u00e1mbito escolar.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_4","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_ACTIVIDADES_COLEGIO</code> tiene como objetivo:</p> <ol> <li>Extraer: Obtener datos relacionados con actividades de colegio desde una fuente de origen, como una base de datos operativa o una tabla staging.</li> <li>Transformar: Procesar los datos para calcular m\u00e9tricas relevantes (por ejemplo, n\u00famero de estudiantes matriculados, eventos escolares realizados, o asistencia) y vincularlos a dimensiones.</li> <li>Cargar: Insertar los datos transformados en la tabla <code>FACT_ACTIVIDADES</code> para su uso en an\u00e1lisis multidimensionales dentro del cubo OLAP.</li> </ol> <p>Esto permite evaluar el impacto y el desempe\u00f1o de las actividades educativas en el contexto de COMFENALCO.</p>"},{"location":"03.Cubo/03.ETL/#ubicacion_3","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Flujo de Datos: <code>FACT_ACTIVIDADES</code></li> <li>Componente: <code>FACT_ACTIVIDADES_COLEGIO</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_3","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:  </p> <ul> <li>Los datos se extraen de una fuente que contiene informaci\u00f3n sobre actividades escolares, como una tabla transaccional o una vista espec\u00edfica.</li> </ul> </li> <li> <p>Transformaciones:  </p> <ul> <li>Derived Column: Genera columnas calculadas o ajusta datos seg\u00fan sea necesario (por ejemplo, categorizar tipos de actividades escolares).  </li> <li>Lookup: Vincula los datos con dimensiones como <code>DIM_TIEMPO_MENSUAL</code> (para el periodo) o una dimensi\u00f3n de colegios/estudiantes (para identificar participantes).  </li> <li>Aggregate: Calcula m\u00e9tricas como el n\u00famero total de estudiantes, eventos escolares o asistencia por periodo.</li> </ul> </li> <li> <p>Destino:  </p> <ul> <li>Los datos procesados se insertan en <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> mediante un componente OLE DB Destination.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_6","title":"L\u00f3gica de Negocio","text":"<ul> <li>M\u00e9tricas:  <ul> <li>N\u00famero de estudiantes matriculados por mes o a\u00f1o escolar.  </li> <li>Cantidad de actividades o eventos escolares realizados.  </li> <li>Indicadores de asistencia o participaci\u00f3n (si aplica).  </li> </ul> </li> <li>Vinculaci\u00f3n:  <ul> <li>Cada registro se asocia con claves for\u00e1neas de dimensiones relevantes, como <code>ID_MES</code> (de <code>DIM_TIEMPO_MENSUAL</code>) o <code>ID_COLEGIO</code>.  </li> </ul> </li> <li>Consistencia: Asegura que los datos sean precisos y est\u00e9n alineados con las necesidades del cubo OLAP.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_7","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Dependencias: Requiere que las dimensiones relevantes (como <code>DIM_TIEMPO_MENSUAL</code>) est\u00e9n cargadas previamente.  </li> <li>Secuencia: Se ejecuta despu\u00e9s de la carga de dimensiones y antes de tareas que consuman los datos de <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_actividadescontenedor-de-bucles-for-1-1aportes-totales","title":"<code>FACT_ACTIVIDADES\\\\Contenedor de bucles For 1 1\\\\Aportes Totales</code>","text":"<p>El componente <code>FACT_ACTIVIDADES\\\\Contenedor de bucles For 1 1\\\\Aportes Totales</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_ACTIVIDADES</code>, que pertenece al paquete SSIS <code>09-ETLS_CUBO</code>. Este componente est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con los aportes realizados en la tabla de hechos <code>FACT_ACTIVIDADES</code> del Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su prop\u00f3sito, implementaci\u00f3n y relevancia en el contexto del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-aportes-totales-en-este-contexto","title":"\u00bfQu\u00e9 significa \"Aportes Totales\" en este contexto?","text":"<p>En el \u00e1mbito de COMFENALCO, \"Aportes Totales\" se refiere a la consolidaci\u00f3n de los aportes econ\u00f3micos realizados por afiliados, los cuales se agrupan por empresa, afiliado y mes. Este componente se encarga de sumar los aportes individuales, contar el n\u00famero de aportes y, adicionalmente, determinar si los afiliados pertenecen a la poblaci\u00f3n educativa, lo que permite un an\u00e1lisis multidimensional preciso dentro del cubo OLAP.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_5","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>Aportes Totales</code> tiene como objetivo:</p> <ol> <li> <p>Extraer: </p> <ul> <li>Obtener los registros de aportes desde la tabla fuente <code>[DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET]</code> y relacionarlos con la dimensi\u00f3n temporal <code>DIM_TIEMPO_MENSUAL</code> mediante una condici\u00f3n de fecha.</li> </ul> </li> <li> <p>Transformar: </p> <ul> <li>Agregar y consolidar los datos de aportes, calculando la suma total de aportes y el n\u00famero de aportes (conteo) para cada combinaci\u00f3n de empresa, afiliado y mes.</li> <li>Determinar, mediante expresiones condicionales, si el afiliado pertenece a la poblaci\u00f3n educativa, a partir de informaci\u00f3n adicional proveniente de la tabla <code>FACT_ACTIVIDADES</code>.</li> <li>Integrar datos de afiliaci\u00f3n (como PARTNER_AFILIADO y PARTNER_EMPRESA) a trav\u00e9s de una uni\u00f3n con un conjunto de datos derivado (CTE partnerTable).</li> </ul> </li> <li> <p>Cargar: </p> <ul> <li>Insertar los datos transformados en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code> utilizando un componente OLE DB Destination, asegurando el correcto mapeo de columnas y la integraci\u00f3n con las dimensiones existentes.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_4","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Flujo de Datos: <code>FACT_ACTIVIDADES</code></li> <li>Componente: <code>FACT_ACTIVIDADES\\\\Contenedor de bucles For 1 1\\\\Aportes Totales</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_4","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:    Se utiliza un componente OLE DB Source para extraer los registros desde la tabla <code>[DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET]</code>. La extracci\u00f3n se realiza mediante una consulta SQL que:</p> <ul> <li>Calcula el primer d\u00eda del mes a partir de la columna <code>FECHA_CONTABLE</code> y lo convierte en el formato adecuado (ID_FECHA).</li> <li>Filtra los datos seg\u00fan un mes espec\u00edfico, determinado por la variable de iteraci\u00f3n <code>@VarTime</code> y la variable calculada <code>@MesFiltrado</code>.</li> </ul> </li> <li> <p>Transformaciones:    La consulta SQL del componente realiza las siguientes operaciones:</p> <ul> <li>Declaraci\u00f3n de Variables y C\u00e1lculo del Mes a Filtrar:  Se declara la variable <code>@MinMes</code> para obtener el m\u00ednimo mes registrado y se define <code>@VarTime</code> (proporcionado como par\u00e1metro de iteraci\u00f3n) para calcular el mes a filtrar (<code>@MesFiltrado</code>).</li> <li>CTE Aportes_Total:  Se agrupan los aportes por <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, y el mes (convertido a formato de fecha y string), calculando:<ul> <li><code>TOTAL_APORTES</code>: La suma de los aportes.</li> <li><code>NUMERO_APORTES</code>: El conteo de aportes.</li> <li>Se asigna la constante 'APORTES' en la columna <code>ACTIVIDAD</code>.</li> </ul> </li> <li>CTE Poblacion_Educacion_Mes, AfiliadosMes y AfiliadosEducacionMes:  Se extraen datos para identificar la poblaci\u00f3n educativa y filtrar los afiliados que pertenecen a este grupo.</li> <li>CTE consulta y partnerTable:  Se realiza una uni\u00f3n para determinar, mediante una condici\u00f3n CASE, si el afiliado forma parte de la poblaci\u00f3n educativa (<code>POBLACION_EDUCACION</code>) y se integran los datos de PARTNER_AFILIADO y PARTNER_EMPRESA.</li> <li>Selecci\u00f3n Final:  Se obtienen todos los campos relevantes, aplicando la funci\u00f3n <code>COALESCE</code> para asignar valores predeterminados a PARTNER_AFILIADO y PARTNER_EMPRESA si no existen registros asociados.</li> </ul> </li> <li> <p>Destino:    El componente Destino de ADO NET se encarga de insertar los datos procesados en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</code>. Se realiza el mapeo de las columnas de salida del OLE DB Source con las columnas de la tabla de destino, incluyendo:</p> <ul> <li>Identificadores (como <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>ID_FECHA</code>).</li> <li>Datos agregados (<code>TOTAL_APORTES</code>, <code>NUMERO_APORTES</code>).</li> <li>Campos adicionales derivados de la transformaci\u00f3n (por ejemplo, <code>ACTIVIDAD</code>, <code>POBLACION_EDUCACION</code>).</li> </ul> </li> <li> <p>C\u00f3digo SQL Utilizado:    La siguiente es la instrucci\u00f3n SQL que se ejecuta en el componente OLE DB Source:</p> </li> </ol> <pre><code>DECLARE @MinMes VARCHAR(8);\n\nSELECT \n    @MinMes = MIN(LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01')\nFROM \n    [DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET] a\nINNER JOIN \n    [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t\nON LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112)\n\n -- Paso 2: Declarar la variable para determinar el mes\nDECLARE @VarTime INT = ?; -- Ajusta este valor seg\u00fan la iteraci\u00f3n que quieras filtrar\n\n -- Calcular el mes a filtrar basado en @VarTime\nDECLARE @MesFiltrado INT = CONVERT(INT, FORMAT(DATEADD(MONTH, @VarTime - 1, CONVERT(DATE, @MinMes)), 'yyyyMM') + '01');\n\n --SELECT @MesFiltrado AS MinID_FECHA;\n\nWITH Aportes_Total AS (\nSELECT \n    ISNULL(a.[BP_EMPRESA],'0000000000') as 'PARTNER', \n    a.[ID_EMPRESA],\n    a.[ID_AFILIADO],\n    CONVERT(DATE, LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01') AS FECHA_MENSUAL,\n    LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' AS ID_FECHA,\n    SUM(CONVERT(DECIMAL(18, 2), a.[APORTE])) AS TOTAL_APORTES,\n    COUNT(a.[APORTE]) AS NUMERO_APORTES,\n    ISNULL(a.[BP_EMPRESA],'0000000000') AS BP_EMPRESA,\n    a.[BP_AFILIADO],\n    'APORTES' AS ACTIVIDAD\nFROM \n    [DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET] a\nINNER JOIN \n    [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t\n    ON LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112)\nWHERE LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' = @MesFiltrado\nGROUP BY \n    a.[ID_EMPRESA],\n    a.[ID_AFILIADO],\n    LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01',\n    a.[BP_EMPRESA],\n    a.[BP_AFILIADO]),\nPoblacion_Educacion_Mes AS (\nSELECT DISTINCT \n      [ID_FECHA],\n      [PARTNER]\n  FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n  WHERE ACTIVIDAD != 'AFILIACION'),\nAfiliadosMes AS (\nSELECT DISTINCT \n      [ID_FECHA],\n      [PARTNER],\n      [PARTNER_AFILIADO]\n  FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n  WHERE ACTIVIDAD = 'AFILIACION' AND PARTNER_AFILIADO IS NOT NULL\n),\nAfiliadosEducacionMes AS (\nSELECT \n    am.[ID_FECHA],\n    am.[PARTNER_AFILIADO]\nFROM AfiliadosMes am\nINNER JOIN Poblacion_Educacion_Mes pem ON am.[ID_FECHA] = pem.[ID_FECHA] and am.PARTNER = pem.PARTNER\n),\nconsulta AS (\n  SELECT DISTINCT ap.*,  \n      CASE WHEN aem.PARTNER_AFILIADO IS NULL THEN 'NO' ELSE 'SI' END AS POBLACION_EDUCACION,\n       -1 AS ID_CURSO,\n       -1 AS ID_PROGRAMA,\n       -1 AS ID_PERTENENCIA_ETNICA,\n       -1 AS ID_GENERO,\n       -1 AS ID_FACTOR_VULNERABILIDAD,\n       -1 AS ID_ESTADO_CIVIL,\n       -1 AS ID_TARIFA,\n       -1 AS ID_CATEGORIA,\n      5 AS ID_UNIDAD\n  FROM Aportes_Total ap\n  LEFT JOIN AfiliadosEducacionMes aem ON ap.ID_FECHA = aem.ID_FECHA AND ap.BP_AFILIADO = aem.PARTNER_AFILIADO\n),\npartnerTable AS (\n  SELECT PARTNER, ID_FECHA,\n      MAX([PARTNER_AFILIADO]) AS PARTNER_AFILIADO,\n      MAX([PARTNER_EMPRESA]) AS PARTNER_EMPRESA\n  FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n  WHERE ACTIVIDAD = 'AFILIACION'\n  GROUP BY [PARTNER], ID_FECHA\n)\nSELECT  c.*, \n    COALESCE(pt.[PARTNER_AFILIADO], '0000000000') AS PARTNER_AFILIADO,\n    COALESCE(pt.[PARTNER_EMPRESA] , '0000000000') AS PARTNER_EMPRESA\nFROM  consulta c\nLEFT JOIN  partnerTable pt\n    ON c.[PARTNER] = pt.[PARTNER]\n    AND c.ID_FECHA = pt.ID_FECHA;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_7","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Consolidaci\u00f3n de Aportes:   Se agrupan los aportes registrados por empresa y afiliado para un mes determinado, obteniendo la suma total de aportes y el n\u00famero de aportes realizados.</p> </li> <li> <p>Determinaci\u00f3n de Pertenencia a la Poblaci\u00f3n Educativa:   A trav\u00e9s de uniones con datos de afiliaci\u00f3n, se eval\u00faa si el afiliado forma parte de la poblaci\u00f3n educativa, asignando un valor 'SI' o 'NO' en la columna <code>POBLACION_EDUCACION</code>.</p> </li> <li> <p>Integraci\u00f3n de Datos de Afiliaci\u00f3n:   Se unen los datos resultantes con informaci\u00f3n adicional (como PARTNER_AFILIADO y PARTNER_EMPRESA) obtenida del historial de afiliaci\u00f3n para enriquecer el conjunto final de datos.</p> </li> <li> <p>Iteraci\u00f3n y Filtrado:   El componente se ejecuta dentro de un contenedor de bucles que utiliza la variable <code>@VarTime</code> para iterar y procesar datos mes a mes, permitiendo la actualizaci\u00f3n incremental de la informaci\u00f3n.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_8","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Dependencias: </p> <ul> <li>Requiere que la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> est\u00e9 cargada previamente para la correcta asignaci\u00f3n de fechas (ID_FECHA y FECHA_MENSUAL).</li> <li>Depende de la existencia y precisi\u00f3n de los registros en la tabla <code>[DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET]</code> y de los datos hist\u00f3ricos de afiliaci\u00f3n en <code>FACT_ACTIVIDADES</code> para determinar la pertenencia a la poblaci\u00f3n educativa.</li> </ul> </li> <li> <p>Secuencia:   Se ejecuta dentro de un contenedor de bucles (FOR LOOP) que itera seg\u00fan la variable <code>@MaxIterationApor</code>, procesando los aportes mes a mes antes de que otros procesos posteriores utilicen los datos consolidados en <code>FACT_ACTIVIDADES</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_personal_cubo","title":"<code>FACT_PERSONAL_CUBO</code>","text":"<p>El componente <code>FACT_PERSONAL_CUBO</code> es una tarea espec\u00edfica dentro del flujo de datos <code>FACT_PERSONAL</code>, que pertenece al paquete SSIS <code>09-ETLS_CUBO</code>. Este componente est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con el personal en la tabla de hechos <code>FACT_PERSONAL</code> del Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su prop\u00f3sito, implementaci\u00f3n y relevancia en el contexto del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-personal-en-este-contexto","title":"\u00bfQu\u00e9 significa \"PERSONAL\" en este contexto?","text":"<p>En el \u00e1mbito de COMFENALCO, \"PERSONAL\" se refiere a la informaci\u00f3n relacionada con los empleados y colaboradores, que incluye datos de ausentismo, contrataciones y otros indicadores laborales. Estos datos son fundamentales para analizar la gesti\u00f3n de recursos humanos y evaluar el impacto de las pol\u00edticas de personal en el desempe\u00f1o organizacional.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_6","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_PERSONAL_CUBO</code> tiene como objetivo:</p> <ol> <li> <p>Extraer: </p> <ul> <li>Obtener datos relacionados con el personal desde una fuente de datos operativa o una tabla staging, que incluya informaci\u00f3n detallada sobre contrataciones, ausentismo y otros eventos laborales.</li> </ul> </li> <li> <p>Transformar: </p> <ul> <li>Procesar y limpiar los datos para calcular m\u00e9tricas relevantes, como el total de contrataciones y la suma de d\u00edas de ausentismo.</li> <li>Realizar transformaciones mediante componentes como Derived Column para generar indicadores adicionales y Lookup para asociar cada registro con la dimensi\u00f3n temporal (<code>DIM_TIEMPO_MENSUAL</code>).</li> <li>Consolidar informaci\u00f3n proveniente de m\u00faltiples fuentes; en este caso, la consulta SQL unifica datos de ausentismo, reemplazo, contrataci\u00f3n y fin de contrataci\u00f3n para formar un conjunto integrado de registros.</li> </ul> </li> <li> <p>Cargar: </p> <ul> <li>Insertar los datos transformados en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_PERSONAL]</code> mediante un componente OLE DB Destination, garantizando que la informaci\u00f3n se vincule correctamente con las dimensiones del cubo OLAP.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_5","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Flujo de Datos: <code>FACT_PERSONAL</code></li> <li>Componente: <code>FACT_PERSONAL_CUBO</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_5","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos: </p> <ul> <li>Se extraen los registros del personal desde diversas fuentes que contienen datos actualizados sobre empleados, tales como:<ul> <li>[DWH_COMFENALCO].[Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]</li> <li>[DWH_COMFENALCO].[Colegio].[FACT_REEMPLAZO_DOCENTE]</li> <li>[DWH_COMFENALCO].[Colegio].[FACT_AUSENTISMO_DOCENTE]</li> <li>[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]  La fuente se consume mediante un componente de tipo Data Reader (Microsoft.DataReaderSourceAdapter) que ejecuta una instrucci\u00f3n SQL para consolidar los diferentes eventos relacionados con el personal.</li> </ul> </li> </ul> </li> <li> <p>Transformaciones: </p> <ul> <li>Derived Column:  Se generan columnas calculadas para definir indicadores adicionales, por ejemplo, para diferenciar entre ausentismo, reemplazo, contrataci\u00f3n y fin de contrataci\u00f3n.</li> <li>Lookup:  Se vinculan los registros resultantes con la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> para asociar cada registro a un per\u00edodo espec\u00edfico mediante la columna <code>ID_FECHA</code>.</li> <li> <p>Aggregate (impl\u00edcito en la consolidaci\u00f3n SQL):  La instrucci\u00f3n SQL unifica y consolida los datos de las diferentes fuentes mediante la cl\u00e1usula <code>UNION</code>, estandarizando el formato de <code>ID_FECHA</code> y asegurando que cada registro contenga la informaci\u00f3n necesaria para su posterior an\u00e1lisis.</p> </li> <li> <p>C\u00f3digo SQL Utilizado:  La consulta SQL que se utiliza en el componente es la siguiente:</p> </li> </ul> <pre><code>SELECT uni.ID_FECHA, uni.ID_PERSONAL, uni.NOMBRE, uni.CONCEPTO, uni.DESCRIPCION, uni.FECHA_FIN,\n       uni.HORAS_CONTRATADAS_MENSUAL, pers.ID_UNIDAD, AUSENCIA_HORAS, TIPO_AUSENCIA  \nFROM (\n    SELECT LEFT([ID_FECHA], 6) * 100 + 1 AS ID_FECHA,\n           [ID_PERSONAL],\n           [NOMBRE_DOCENTE] AS NOMBRE,\n           'AUSENTISMO' AS CONCEPTO,\n           [MOTIVO_AUSENCIA] AS DESCRIPCION,\n           [FECHA_FIN],\n           NULL AS HORAS_CONTRATADAS_MENSUAL,\n           AUSENCIA_HORAS,\n           TIPO_AUSENCIA\n    FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]\n\n    UNION \n\n    SELECT LEFT([ID_FECHA], 6) * 100 + 1 AS ID_FECHA,\n           [ID_PERSONAL_REEMPLAZA] AS ID_PERSONAL,\n           [DOCENTE_REEMPLAZA] AS NOMBRE,\n           'REEMPLAZO' AS CONCEPTO,\n           NULL AS DESCRIPCION,\n           NULL AS FECHA_FIN,\n           NULL AS HORAS_CONTRATADAS_MENSUAL,\n           NULL AS AUSENCIA_HORAS,\n           NULL AS TIPO_AUSENCIA\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_REEMPLAZO_DOCENTE]\n\n    UNION \n\n    SELECT LEFT([ID_FECHA], 6) * 100 + 1 AS ID_FECHA,\n           [ID_PERSONAL],\n           [NOMBRE_DOCENTE] AS NOMBRE,\n           'AUSENTISMO' AS CONCEPTO,\n           [MOTIVO_AUSENCIA] AS DESCRIPCION,\n           [FECHA_FIN],\n           NULL AS HORAS_CONTRATADAS_MENSUAL,\n           AUSENCIA_HORAS,\n           TIPO_AUSENCIA\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_AUSENTISMO_DOCENTE]\n\n    UNION \n\n    SELECT LEFT(CONVERT(INT, FORMAT([FECHA_INICIO_CONTRATACION], 'yyyyMMdd')), 6) * 100 + 1 AS ID_FECHA,\n           [ID_PERSONAL],\n           [NOMBRE] AS NOMBRE,\n           'CONTRATACION' AS CONCEPTO,\n           NULL AS DESCRIPCION,\n           [FECHA_FIN_CONTRATACION] AS FECHA_FIN,\n           [HORAS_CONTRATADAS_MENSUAL],\n           NULL AS AUSENCIA_HORAS,\n           NULL AS TIPO_AUSENCIA\n    FROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\n\n    UNION \n\n    SELECT LEFT(CONVERT(INT, FORMAT([FECHA_FIN_CONTRATACION], 'yyyyMMdd')), 6) * 100 + 1 AS ID_FECHA,\n           [ID_PERSONAL],\n           [NOMBRE] AS NOMBRE,\n           'FIN_CONTRATACION' AS CONCEPTO,\n           [CAUSA_TERMINACION_CONTRATO] AS DESCRIPCION,\n           NULL AS FECHA_FIN,\n           NULL AS HORAS_CONTRATADAS_MENSUAL,\n           NULL AS AUSENCIA_HORAS,\n           NULL AS TIPO_AUSENCIA\n    FROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\n) AS uni\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM\n    ON uni.ID_FECHA = dimM.ID_FECHA \nLEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL] pers\n    ON uni.ID_PERSONAL = pers.ID_PERSONAL;\n</code></pre> </li> <li> <p>Destino: </p> <ul> <li>Se utiliza un componente Destino de ADO NET que inserta los datos transformados en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_PERSONAL]</code>.  </li> <li> <p>Las columnas mapeadas incluyen:</p> <ul> <li><code>ID_FECHA</code></li> <li><code>ID_PERSONAL</code></li> <li><code>NOMBRE</code></li> <li><code>CONCEPTO</code></li> <li><code>DESCRIPCION</code></li> <li><code>FECHA_FIN</code></li> <li><code>HORAS_CONTRATADAS_MENSUAL</code></li> <li><code>ID_UNIDAD</code></li> </ul> </li> <li> <p>El mapeo asegura que cada columna de salida del componente de origen se alinee con el esquema de la tabla destino.</p> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_8","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Indicadores de Personal:   Se consolidan eventos relacionados con el personal (ausentismo, reemplazos, contrataciones y finalizaciones) para proporcionar una visi\u00f3n integral de la gesti\u00f3n del personal en COMFENALCO.</p> </li> <li> <p>Vinculaci\u00f3n Temporal:   Cada registro se asocia con un per\u00edodo espec\u00edfico mediante la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> (a trav\u00e9s de la columna <code>ID_FECHA</code>), lo que facilita el an\u00e1lisis comparativo y el seguimiento de tendencias a lo largo del tiempo.</p> </li> <li> <p>Integraci\u00f3n de Datos:   La consulta SQL unifica datos de m\u00faltiples fuentes, estandarizando el formato de la fecha (<code>ID_FECHA</code>) y asegurando que los registros se carguen en un \u00fanico conjunto que refleje todos los eventos laborales relevantes.</p> </li> <li> <p>Validaci\u00f3n y Consistencia:   Se aplican conversiones y validaciones en el flujo de datos para garantizar que los datos cargados sean precisos y cumplan con los est\u00e1ndares definidos en el Data Warehouse.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_9","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Dependencias: </p> <ul> <li>Requiere que la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> est\u00e9 previamente cargada para la correcta asignaci\u00f3n de la fecha (<code>ID_FECHA</code>).</li> <li>Depende de la existencia y precisi\u00f3n de los registros en las fuentes <code>[DWH_COMFENALCO].[Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]</code>, <code>[DWH_COMFENALCO].[Colegio].[FACT_REEMPLAZO_DOCENTE]</code> y <code>[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]</code> para consolidar los eventos del personal.</li> </ul> </li> <li> <p>Secuencia:   Se ejecuta en la etapa de carga de hechos dentro del paquete <code>09-ETLS_CUBO</code>, despu\u00e9s de la carga de dimensiones y antes de otros procesos anal\u00edticos que utilicen la informaci\u00f3n consolidada de personal.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_evaluacion_docente_cubo","title":"<code>FACT_EVALUACION_DOCENTE_CUBO</code>","text":"<p>El componente <code>FACT_EVALUACION_DOCENTE_CUBO</code> es una tarea espec\u00edfica dentro del flujo de datos del paquete SSIS <code>09-ETLS_CUBO</code>. Este componente est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con la evaluaci\u00f3n de docentes en la tabla de hechos <code>FACT_EVALUACION_DOCENTE</code> del Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su prop\u00f3sito, implementaci\u00f3n y relevancia en el contexto del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-evaluacion-docente-en-este-contexto","title":"\u00bfQu\u00e9 significa \"EVALUACI\u00d3N DOCENTE\" en este contexto?","text":"<p>En el \u00e1mbito de COMFENALCO, \"EVALUACI\u00d3N DOCENTE\" se refiere al an\u00e1lisis y medici\u00f3n del desempe\u00f1o de los docentes a trav\u00e9s de indicadores de calidad educativa. Estos indicadores, como la calificaci\u00f3n definitiva, permiten evaluar la efectividad y el desempe\u00f1o de los docentes, informaci\u00f3n clave para la mejora continua de la gesti\u00f3n educativa.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_7","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_EVALUACION_DOCENTE_CUBO</code> tiene como objetivo:</p> <ol> <li> <p>Extraer: </p> <ul> <li>Obtener datos relacionados con la evaluaci\u00f3n de los docentes desde diversas fuentes, integrando informaci\u00f3n proveniente de sistemas operativos (por ejemplo, de las \u00e1reas de Colegio y Cedesarrollo).</li> </ul> </li> <li> <p>Transformar: </p> <ul> <li>Consolidar los datos provenientes de distintas fuentes mediante la uni\u00f3n de resultados (UNION) para unificar el formato y estandarizar la informaci\u00f3n.</li> <li>Seleccionar campos clave como el per\u00edodo acad\u00e9mico, la unidad, el identificador y nombre del docente, la calificaci\u00f3n definitiva y la fecha de referencia (ID_FECHA).</li> <li>Relacionar la informaci\u00f3n consolidada con la dimensi\u00f3n temporal <code>DIM_TIEMPO_MENSUAL</code> para asegurar la correcta segmentaci\u00f3n de los datos por per\u00edodos.</li> </ul> </li> <li> <p>Cargar: </p> <ul> <li>Insertar los datos transformados en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE]</code> mediante un componente Destino de ADO NET, garantizando que la informaci\u00f3n se integre adecuadamente en el cubo OLAP para su an\u00e1lisis.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_6","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Flujo de Datos: Dentro del proceso de carga de hechos, correspondiente a la evaluaci\u00f3n docente.</li> <li>Componente: <code>FACT_EVALUACION_DOCENTE_CUBO</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_6","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:    El componente utiliza un origen de datos basado en ADO.NET (Microsoft.DataReaderSourceAdapter) para ejecutar una instrucci\u00f3n SQL que extrae y consolida los datos de evaluaci\u00f3n docente. La consulta unifica informaci\u00f3n de tres or\u00edgenes:</p> <ul> <li>[DWH_COMFENALCO].[Colegio].[FACT_DESEMPENHO_DOCENTE]</li> <li>[DWH_COMFENALCO].[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_CE] (con uni\u00f3n a [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO])</li> <li>[DWH_COMFENALCO].[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_DE] (con uni\u00f3n a [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO])</li> </ul> </li> <li> <p>Transformaciones:    La instrucci\u00f3n SQL consolida los datos utilizando la cl\u00e1usula <code>UNION</code>, estandarizando el formato de la fecha mediante el c\u00e1lculo de <code>ID_FECHA</code> y seleccionando los siguientes campos:</p> <ul> <li>PERIODO_ACADEMICO: Identifica el a\u00f1o o periodo de evaluaci\u00f3n.</li> <li>ID_UNIDAD: Indica la unidad administrativa o educativa.</li> <li>ID_PERSONAL: Identificador del docente evaluado.</li> <li>NOMBRE_DOCENTE: Nombre del docente.</li> <li>CALIFICACION_DEFINITIVA: Valor que representa la evaluaci\u00f3n final del docente.</li> <li>ID_FECHA: Fecha que se utiliza para vincular la evaluaci\u00f3n con la dimensi\u00f3n temporal, mediante la uni\u00f3n con <code>DIM_TIEMPO_MENSUAL</code>.</li> </ul> </li> <li> <p>C\u00f3digo SQL Utilizado:    La consulta ejecutada por el componente es la siguiente:</p> </li> </ol> <pre><code>SELECT PERIODO_ACADEMICO, ID_UNIDAD, ID_PERSONAL, NOMBRE_DOCENTE, CALIFICACION_DEFINITIVA, uni.ID_FECHA\nFROM (\n    SELECT \n        [ANIO_ACADEMICO] AS PERIODO_ACADEMICO,\n        5 AS ID_UNIDAD,\n        [ID_PERSONAL],\n        [NOMBRE_DOCENTE],\n        [TOTAL_GENERAL] AS CALIFICACION_DEFINITIVA,\n        [ID_FECHA]\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_DESEMPENHO_DOCENTE]\n\n    UNION\n\n    SELECT \n        c2.[PERIODO_ACADEMICO],\n        c1.[ID_UNIDAD],\n        c1.[ID_PERSONAL],\n        c1.[NOMBRE_DOCENTE],\n        c1.[CALIFICACION_DEFINITIVA],\n        NULL AS ID_FECHA -- NO TIENE FECHA, NECESARIO IMPLEMENTAR PARA FILTAR CON FECHA MENSUAL DE INTER\u00c9S\n    FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_CE] AS c1\n    LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] AS c2\n        ON c1.ID_PERIODO = c2.ID_PERIODO\n\n    UNION\n\n    SELECT \n        c2.[PERIODO_ACADEMICO],\n        c1.[ID_UNIDAD],\n        c1.[ID_PERSONAL],\n        c1.[NOMBRE_DOCENTE],\n        c1.[CALIFICACION] AS CALIFICACION_DEFINITIVA,\n        c1.[ID_FECHA]\n    FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_DE] AS c1\n    LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] AS c2\n        ON c1.ID_PERIODO = c2.ID_PERIODO\n) uni\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM\n    ON uni.ID_FECHA = dimM.ID_FECHA;\n</code></pre> <ol> <li>Destino:    Un componente Destino de ADO NET se encarga de cargar los datos resultantes en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE]</code>. Se realiza el mapeo de las columnas extra\u00eddas (como <code>PERIODO_ACADEMICO</code>, <code>ID_UNIDAD</code>, <code>ID_PERSONAL</code>, <code>NOMBRE_DOCENTE</code>, <code>CALIFICACION_DEFINITIVA</code> y <code>ID_FECHA</code>) con las correspondientes columnas en la tabla destino.</li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_9","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Consolidaci\u00f3n de Evaluaciones:   La consulta SQL unifica las evaluaciones de docentes provenientes de diferentes sistemas (Colegio y Cedesarrollo) para generar un conjunto \u00fanico de registros de evaluaci\u00f3n docente.</p> </li> <li> <p>Est\u00e1ndar Temporal:   Al estandarizar la fecha a trav\u00e9s de <code>ID_FECHA</code> y vincularla con la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code>, se garantiza que las evaluaciones puedan analizarse en funci\u00f3n del tiempo.</p> </li> <li> <p>Validaci\u00f3n y Consistencia:   Se aplican conversiones y uniones l\u00f3gicas en la consulta para asegurar que los datos consolidados sean precisos, facilitando su uso en an\u00e1lisis comparativos y en la generaci\u00f3n de reportes.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_10","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Dependencias: </p> <ul> <li>Requiere que la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> est\u00e9 previamente cargada para la correcta asignaci\u00f3n de la fecha (ID_FECHA).  </li> <li>Depende de la calidad y consistencia de los datos provenientes de las fuentes <code>FACT_DESEMPENHO_DOCENTE</code>, <code>FACT_DESEMPENHO_DOCENTE_CE</code> y <code>FACT_DESEMPENHO_DOCENTE_DE</code>.</li> </ul> </li> <li> <p>Secuencia:   Se ejecuta en la etapa de carga de hechos dentro del paquete <code>09-ETLS_CUBO</code>, despu\u00e9s de la carga de dimensiones y antes de otros procesos anal\u00edticos que utilicen la informaci\u00f3n consolidada de evaluaci\u00f3n docente.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_financiera_cubo","title":"<code>FACT_FINANCIERA_CUBO</code>","text":"<p>El componente <code>FACT_FINANCIERA_CUBO</code> es una tarea espec\u00edfica dentro del flujo de datos del paquete SSIS <code>09-ETLS_CUBO</code>. Este componente est\u00e1 dise\u00f1ado para procesar y cargar datos financieros en la tabla de hechos <code>FACT_FINANCIERA</code> del Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su prop\u00f3sito, implementaci\u00f3n y relevancia en el contexto del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-financiera-en-este-contexto","title":"\u00bfQu\u00e9 significa \"FINANCIERA\" en este contexto?","text":"<p>En el \u00e1mbito de COMFENALCO, \"FINANCIERA\" hace referencia a la informaci\u00f3n contable y financiera relacionada con las transacciones y el presupuesto. Este componente integra datos provenientes de registros contables y presupuestarios para analizar el desempe\u00f1o financiero, permitiendo evaluar ingresos, gastos, resultados y otros indicadores clave de la salud financiera de la organizaci\u00f3n.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_8","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_FINANCIERA_CUBO</code> tiene como objetivo:</p> <ol> <li> <p>Extraer: </p> <ul> <li>Obtener datos contables desde la fuente <code>[DWH_COMFENALCO].[Transversal].[FACT_DETALLE_CONTABLE]</code> y datos presupuestarios desde <code>[DWH_COMFENALCO].[Transversal].[FACT_PRESUPUESTO]</code>.</li> </ul> </li> <li> <p>Transformar: </p> <ul> <li>Consolidar y transformar la informaci\u00f3n financiera mediante una consulta SQL que unifica y agrupa datos.  </li> <li>Realizar conversiones de datos (por ejemplo, convertir campos num\u00e9ricos a cadenas en ciertos casos) utilizando un componente de Data Conversion para garantizar la compatibilidad de tipos de datos.  </li> <li>Aplicar filtros y condiciones, como excluir ciertos tipos de cuentas (por ejemplo, las de 'INGRESOS', 'COSTOS' y 'GASTOS') y seleccionar solo cuentas cuyos prefijos cumplan criterios espec\u00edficos.</li> </ul> </li> <li> <p>Cargar: </p> <ul> <li>Insertar los datos transformados y consolidados en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA]</code> mediante un componente Destino de ADO NET, asegurando que los datos se integren de manera correcta en el cubo OLAP para su posterior an\u00e1lisis.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_7","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Flujo de Datos: Correspondiente al proceso de carga de hechos financieros.</li> <li>Componente: <code>FACT_FINANCIERA_CUBO</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_7","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos: </p> <ul> <li>El componente utiliza un origen de datos basado en ADO.NET (Microsoft.DataReaderSourceAdapter) para extraer la informaci\u00f3n financiera.  </li> <li>Se emplea una consulta SQL que extrae datos de la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_DETALLE_CONTABLE]</code>, uni\u00e9ndolos con la dimensi\u00f3n de tiempo (a trav\u00e9s de <code>[DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]</code>) y con las dimensiones de unidades organizativas y cuentas contables (a trav\u00e9s de <code>[DWH_COMFENALCO].[Financiera].[DIM_UNIDADES_ORGANIZATIVAS]</code> y <code>[DWH_COMFENALCO].[Financiera].[DIM_CUENTA_CONTABLE]</code>).  </li> <li>Adem\u00e1s, se incluye un <code>UNION</code> con registros provenientes de <code>[DWH_COMFENALCO].[Transversal].[FACT_PRESUPUESTO]</code> para integrar datos presupuestarios.</li> </ul> </li> <li> <p>Transformaciones: </p> <ul> <li>Data Conversion:  Se convierte la informaci\u00f3n de columnas espec\u00edficas, como <code>SEGMENTO</code>, <code>SEGMENT</code>, <code>CUENTA_DESCRIPCION_SSF</code> e <code>ID_CEBE</code>, a tipos de datos adecuados para la carga.</li> <li> <p>Consolidaci\u00f3n mediante SQL:  La consulta SQL realiza operaciones de agregaci\u00f3n y agrupaci\u00f3n para consolidar los datos financieros. Entre las transformaciones destacan:</p> <ul> <li>C\u00e1lculo de totales y sumatorias (por ejemplo, SUM de IMPORTE, INGRESOS, GASTOS, etc.).</li> <li>Filtrado de registros, excluyendo aquellos con cuentas de tipos no deseados y seleccionando solo cuentas con ciertos prefijos.</li> <li>Uni\u00f3n de datos contables y presupuestarios para obtener una vista consolidada de la ejecuci\u00f3n financiera.</li> </ul> </li> <li> <p>C\u00f3digo SQL Utilizado:  La consulta ejecutada es la siguiente:</p> </li> </ul> <pre><code>SELECT uni.*\n    ,ID_UNIDAD\nFROM (\n    SELECT  Tp.[ID_MES]*100+1 AS ID_FECHA,\n            Tp.[ID_ANIO],\n            Tp.[ID_MES],\n            Ft.[ID_CEBE],\n            Uo.[CEBE],\n            Upper(Uo.[CEBE_DESCRIPCION]) AS [DESCRIPCION_CEBE], \n            Upper(Uo.[DEPARTAMENTO]) AS [DEPARTAMENTO],\n            Upper(Uo.[AREA]) AS [AREA],\n            Upper(Uo.[SUBAREA]) AS [SUBAREA],\n            Uo.[SEGMENTO],\n            Uo.[DESCRIPCION_SEGMENTO],\n            Uo.[CODIGO_SSF],\n            Uo.[NOMBRE_SSF],\n            Ft.[ID_CUENTA],\n            Ct.[CUENTA],\n            Ct.[CUENTA_HOMOLOGA],\n            Upper(Ct.[DESCRIPCION]) AS [DESCRIPCION],\n            Upper(Ct.[TIPO_CUENTA]) AS [TIPO_CUENTA],\n            Upper(Ct.[TIPO_OPERACION]) AS [TIPO_OPERACION],\n            Upper(Ct.[GRUPO_CUENTA]) AS [GRUPO_CUENTA],\n            Upper(Ct.[SUBGRUPO_CUENTA]) AS [SUBGRUPO_CUENTA],\n            Upper(Ct.[GRUPO_OPERACION]) AS [GRUPO_OPERACION],\n            Ct.[CUENTA_SSF],\n            Upper(Ct.[DESCRIPCION_SSF]) AS [DESCRIPCION_SSF],\n            Upper(Ct.[CUENTA_DESCRIPCION]) AS [CUENTA_DESCRIPCION],\n            Upper(Ct.[CUENTA_DESCRIPCION_SSF]) AS [CUENTA_DESCRIPCION_SSF],\n            Ct.[SIGNO_INGRESOS],\n            Ct.[CLASIFICACION],\n            Ft.[SEGMENT],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[IMPORTE],0))) AS [IMPORTE],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[INGRESOS],0))) AS [INGRESOS],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[INGRESOS_OPERACIONALES],0))) AS [INGRESOS_OPERACIONALES],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS],0))) AS [GASTOS],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_OPERACIONALES],0))) AS [GASTOS_OPERACIONALES],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_OPERACIONALES_ADMIN],0))) AS [GASTOS_OPERACIONALES_ADMIN],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[RESULTADO_EJERCICIO],0))) AS [RESULTADO_EJERCICIO],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[COSTOS],0))) AS [COSTOS],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[ACTIVO],0))) AS [ACTIVO],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[PASIVO],0))) AS [PASIVO],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[PATRIMONIO],0))) AS [PATRIMONIO],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_CON_DISTRIBUCION],0))) AS [GASTOS_CON_DISTRIBUCION],\n            Try_Convert(Numeric(18,0),Sum(isnull(Ft.[GASTOS_SIN_DISTRIBUCION],0))) AS [GASTOS_SIN_DISTRIBUCION],\n            'EJECUCION_CONTABLE' AS ACTIVIDAD\n    FROM [DWH_COMFENALCO].[Transversal].[FACT_DETALLE_CONTABLE] AS Ft\n    LEFT JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] Tp ON Ft.ID_FECHA = Tp.ID_FECHA\n    LEFT JOIN [DWH_COMFENALCO].[Financiera].[DIM_UNIDADES_ORGANIZATIVAS] Uo ON Ft.ID_CEBE = Uo.ID_CEBE\n    INNER JOIN [DWH_COMFENALCO].[Financiera].[DIM_CUENTA_CONTABLE] Ct ON Ft.ID_CUENTA = Ct.ID_CUENTA\n    WHERE Ct.TIPO_CUENTA NOT IN ('INGRESOS','COSTOS','GASTOS')\n      AND LEFT(Ct.CUENTA,4) IN (1516,1528)\n    GROUP BY \n        Tp.[ID_ANIO], Tp.[ID_MES], Ft.[ID_CEBE], Uo.[CEBE], Uo.[CEBE_DESCRIPCION],\n        Uo.[DEPARTAMENTO], Uo.[AREA], Uo.[SUBAREA], Uo.[SEGMENTO],\n        Uo.[DESCRIPCION_SEGMENTO], Uo.[CODIGO_SSF], Uo.[NOMBRE_SSF], Ft.[ID_CUENTA],\n        Ct.[CUENTA], Ct.[CUENTA_HOMOLOGA], Ct.[DESCRIPCION], Ct.[TIPO_CUENTA],\n        Ct.[TIPO_OPERACION], Ct.[GRUPO_CUENTA], Ct.[SUBGRUPO_CUENTA], Ct.[GRUPO_OPERACION],\n        Ct.[CUENTA_SSF], Ct.[DESCRIPCION_SSF], Ct.[CUENTA_DESCRIPCION], Ct.[CUENTA_DESCRIPCION_SSF],\n        Ct.[SIGNO_INGRESOS], Ct.[CLASIFICACION], Ft.[SEGMENT]\n    ) uni\n    INNER JOIN ( SELECT ID_FECHA AS ID_FECHA2 FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] ) dimM \n        ON uni.ID_FECHA = dimM.ID_FECHA2 \n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_UNIDADES_ORGANIZATIVAS] do \n        ON uni.ID_CEBE = do.ID_CEBE\n    UNION\n    SELECT uni.*, ID_UNIDAD \n    FROM (\n        SELECT [ID_FECHA],\n               NULL AS [ID_ANIO],\n               NULL AS [ID_MES],\n               [ID_CEBE],\n               NULL AS [CEBE],\n               NULL AS [DESCRIPCION_CEBE],\n               NULL AS [DEPARTAMENTO],\n               NULL AS [AREA],\n               NULL AS [SUBAREA],\n               NULL AS [SEGMENTO],\n               NULL AS [DESCRIPCION_SEGMENTO],\n               NULL AS [CODIGO_SSF],\n               NULL AS [NOMBRE_SSF],\n               [ID_CUENTA],\n               NULL AS [CUENTA],\n               NULL AS [CUENTA_HOMOLOGA],\n               NULL AS [DESCRIPCION],\n               NULL AS [TIPO_CUENTA],\n               NULL AS [TIPO_OPERACION],\n               NULL AS [GRUPO_CUENTA],\n               NULL AS [SUBGRUPO_CUENTA],\n               NULL AS [GRUPO_OPERACION],\n               NULL AS [CUENTA_SSF],\n               NULL AS [DESCRIPCION_SSF],\n               NULL AS [CUENTA_DESCRIPCION],\n               NULL AS [CUENTA_DESCRIPCION_SSF],\n               NULL AS [SIGNO_INGRESOS],\n               NULL AS [CLASIFICACION],\n               [SEGMENT],\n               [VALOR] AS [IMPORTE],\n               [INGRESOS],\n               [INGRESOS_OPERACIONALES],\n               [GASTOS],\n               [GASTOS_OPERACIONALES],\n               [GASTOS_OPERACIONALES_ADMIN],\n               NULL AS [RESULTADO_EJERCICIO],\n               [COSTOS],\n               NULL AS [ACTIVO],\n               NULL AS [PASIVO],\n               NULL AS [PATRIMONIO],\n               NULL AS [GASTOS_CON_DISTRIBUCION],\n               NULL AS [GASTOS_SIN_DISTRIBUCION],\n               'PRESUPUESTO_CONTABLE' AS ACTIVIDAD\n        FROM [DWH_COMFENALCO].[Transversal].[FACT_PRESUPUESTO]\n    ) uni\n    INNER JOIN ( SELECT ID_FECHA AS ID_FECHA2 FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] ) dimM \n        ON uni.ID_FECHA = dimM.ID_FECHA2\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_UNIDADES_ORGANIZATIVAS] do \n        ON uni.ID_CEBE = do.ID_CEBE;\n</code></pre> </li> <li> <p>Destino: </p> <ul> <li>Se utiliza un componente Destino de ADO NET para cargar los datos transformados en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA]</code>.  </li> <li>El mapeo entre las columnas de salida del origen y la estructura de la tabla destino se realiza de manera precisa, asegurando que campos como <code>ID_FECHA</code>, <code>ID_ANIO</code>, <code>ID_MES</code>, <code>ID_CEBE</code>, <code>CEBE</code>, <code>DESCRIPCION_CEBE</code>, <code>DEPARTAMENTO</code>, <code>AREA</code>, <code>SUBAREA</code>, <code>SEGMENTO</code>, <code>IMPORTE</code>, <code>INGRESOS</code>, <code>GASTOS</code>, entre otros, se carguen correctamente.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_10","title":"L\u00f3gica de Negocio","text":"<ul> <li>Consolidaci\u00f3n de Datos Financieros:   La consulta SQL consolida dos conjuntos de datos: uno de los registros contables (ejecuci\u00f3n contable) y otro de los presupuestos contables, unific\u00e1ndolos mediante la cl\u00e1usula <code>UNION</code>.  </li> <li>Filtrado y Agrupaci\u00f3n:   Se agrupan los datos por diversos atributos (como a\u00f1o, mes, cuenta, segmento, etc.) y se aplican sumatorias para calcular totales de importes, ingresos, gastos y otros indicadores financieros.  </li> <li>Vinculaci\u00f3n Temporal y Organizacional:   Los datos se vinculan con la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO_MENSUAL</code>) y con la dimensi\u00f3n de unidades organizativas, lo que permite un an\u00e1lisis multidimensional en el cubo OLAP.</li> <li>Est\u00e1ndar de Cuentas:   Se filtra la informaci\u00f3n para excluir ciertos tipos de cuentas (como 'INGRESOS', 'COSTOS' y 'GASTOS') y se seleccionan solo aquellas cuentas que cumplen criterios espec\u00edficos en su prefijo.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_11","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Dependencias: </p> <ul> <li>Requiere que la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> est\u00e9 cargada previamente para la correcta asignaci\u00f3n de la fecha (<code>ID_FECHA</code>).  </li> <li>Depende de las tablas de origen, como <code>FACT_DETALLE_CONTABLE</code> y <code>FACT_PRESUPUESTO</code>, para la obtenci\u00f3n de la informaci\u00f3n financiera.</li> <li>Se apoya en las dimensiones de unidades organizativas para vincular los datos contables con las \u00e1reas y departamentos correspondientes.</li> </ul> </li> <li> <p>Secuencia:   Se ejecuta en la etapa de carga de hechos dentro del paquete <code>09-ETLS_CUBO</code>, despu\u00e9s de la carga de dimensiones y antes de procesos anal\u00edticos o reportes que utilicen la informaci\u00f3n consolidada en <code>FACT_FINANCIERA</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_unidades","title":"<code>FACT_UNIDADES</code>","text":"<p>El componente <code>FACT_UNIDADES</code> es una tarea espec\u00edfica dentro del flujo de datos del paquete SSIS <code>09-ETLS_CUBO</code>. Este componente est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con la cobertura proyectada de unidades educativas (o \u201cunidades\u201d) en la tabla de hechos <code>FACT_UNIDADES</code> del Data Warehouse <code>DWH_COMFENALCO</code>. A continuaci\u00f3n, se detalla su prop\u00f3sito, implementaci\u00f3n y relevancia en el contexto del proceso ETL.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-unidades-en-este-contexto","title":"\u00bfQu\u00e9 significa \"UNIDADES\" en este contexto?","text":"<p>En el \u00e1mbito de COMFENALCO, \"UNIDADES\" se refiere a las entidades o unidades operativas educativas para las cuales se proyecta la cobertura poblacional y se eval\u00faan indicadores relacionados con la matr\u00edcula y otros aspectos administrativos. Este componente consolida informaci\u00f3n proveniente de diferentes fuentes \u2013como datos presupuestarios, planes de cobertura y resultados de pruebas\u2013 para obtener una visi\u00f3n integral de la cobertura proyectada en cada unidad.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_9","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_UNIDADES</code> tiene como objetivo:</p> <ol> <li> <p>Extraer: </p> <ul> <li>Obtener datos relevantes sobre la cobertura proyectada de las unidades, utilizando informaci\u00f3n proveniente de diversas fuentes, tales como:<ul> <li>DIM_PRESUPUESTO (datos presupuestarios de cobertura).</li> <li>FACT_PLAN_COBERTURA de Cedesarrollo y Protecci\u00f3n.</li> <li>FACT_SABER11_INDIVIDUAL y FACT_SABER11_COLEGIOS (indicadores de resultados y cobertura en pruebas SABER 11).</li> </ul> </li> </ul> </li> <li> <p>Transformar: </p> <ul> <li>Consolidar y transformar la informaci\u00f3n mediante una consulta SQL que unifica datos de las diferentes fuentes mediante la cl\u00e1usula <code>UNION</code>.  </li> <li>Establecer valores predeterminados en columnas clave, por ejemplo, asignando un valor de <code>-1</code> a <code>ID_CURSO</code> cuando no se disponga de la informaci\u00f3n, o utilizando <code>COALESCE</code> para definir la unidad operativa (por defecto, 5).  </li> <li>Calcular y agrupar datos, tales como la suma de la poblaci\u00f3n proyectada y el conteo de estudiantes, lo cual permite evaluar la cobertura en cada unidad.</li> </ul> </li> <li> <p>Cargar: </p> <ul> <li>Insertar los datos transformados en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_UNIDADES]</code> mediante un componente Destino de ADO NET, asegurando que cada campo se mapee correctamente con el esquema de la tabla destino.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_8","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>09-ETLS_CUBO</code></li> <li>Flujo de Datos: Dentro del proceso de carga de hechos, correspondiente a la cobertura y proyecci\u00f3n de unidades.</li> <li>Componente: <code>FACT_UNIDADES</code></li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_8","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos: </p> <ul> <li>El componente utiliza un origen de datos basado en ADO.NET (Microsoft.DataReaderSourceAdapter) configurado en el componente denominado <code>unidades</code>.  </li> <li>La consulta SQL utilizada extrae datos de m\u00faltiples or\u00edgenes, a trav\u00e9s de subconsultas unidas mediante <code>UNION</code>, para consolidar:<ul> <li>Datos de la dimensi\u00f3n presupuestaria (extra\u00eddos de [Colegio].[DIM_PRESUPUESTO]).</li> <li>Datos de planes de cobertura provenientes de [Cedesarrollo].[FACT_PLAN_COBERTURA] y [Proteccion].[FACT_PLAN_COBERTURA].</li> <li>Datos de pruebas SABER 11, tanto individuales como por colegios, y de deserci\u00f3n en educaci\u00f3n.</li> </ul> </li> <li>Cada subconsulta transforma y agrupa la informaci\u00f3n, calculando el campo <code>ID_FECHA_MENSUAL</code> mediante una conversi\u00f3n basada en la fecha y asignando la etiqueta de actividad correspondiente (por ejemplo, \"COBERTURA PROYECTADA\" o \"SABER 11\").</li> </ul> </li> <li> <p>Transformaciones: </p> <ul> <li>Se aplican conversiones de datos a trav\u00e9s de un componente de Data Conversion para asegurar la compatibilidad de los tipos de datos (por ejemplo, convertir campos num\u00e9ricos a cadenas donde sea necesario).</li> <li>La consulta SQL consolida los datos de las distintas fuentes y realiza operaciones de agregaci\u00f3n, como el c\u00e1lculo de la suma de la poblaci\u00f3n proyectada.</li> <li>Se utilizan funciones como <code>COALESCE</code> para asignar valores por defecto, garantizando la integridad de la informaci\u00f3n cuando ciertos campos son nulos.</li> </ul> </li> <li> <p>C\u00f3digo SQL Utilizado:    La consulta SQL empleada en el componente es la siguiente:</p> </li> </ol> <pre><code>SELECT un.* \nFROM (\n    SELECT \n        COALESCE(ID_CURSO, -1) AS ID_CURSO,\n        GRADO,\n        COALESCE(ID_UNIDAD, 5) AS ID_UNIDAD,\n        CATEGORIA,\n        ID_PLAN_COBERTURA,\n        CAST(ID_ESTABLECIMIENTO_EDUCATIVO AS nvarchar(40)) AS ID_ESTABLECIMIENTO_EDUCATIVO,\n        ID_PROGRAMA,\n        ID_FECHA_MENSUAL,\n        SUM(CAST(POBL_PROYECT AS INT)) AS POBLACION_PROYECTADA,\n        ORIGEN,  \n        'COBERTURA PROYECTADA' AS ACTIVIDAD, \n        NULL AS RESULTADO,\n        NULL AS CATEGORIA_SABER11,\n        NULL AS CAUSA,\n        NULL AS NUM_POBLACION,\n        NULL AS CALIFICACION,\n        NULL AS DOCUMENTOS_COMPLETOS,\n        NULL AS NUM_ESTUDIANTES,\n        NULL AS NUM_MAYOR_250,\n        NULL AS TEMATICA\n    FROM (\n         -- DIM_PRESUPUESTO\n        SELECT \n            [ID_CURSO],\n            [GRADO],\n            [ID_ANIO_PRESUPUESTO] * 10000 + 101 AS ID_FECHA_MENSUAL,\n            'DIM_PRESUPUESTO' AS ORIGEN,\n            POBL_PROYECT\n        FROM [DWH_COMFENALCO].[Colegio].[DIM_PRESUPUESTO]\n    ) l\n    GROUP BY \n        [ID_CURSO], [GRADO], ID_FECHA_MENSUAL, ORIGEN\n    UNION\n     -- [Cedesarrollo].[FACT_PLAN_COBERTURA]\n    SELECT \n         -1 AS ID_CURSO,\n        NULL AS GRADO,\n        COALESCE(ID_UNIDAD, 5) AS ID_UNIDAD,\n        [CATEGORIA] AS CATEGORIA,\n        NULL AS ID_PLAN_COBERTURA,\n        NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n        [ID_PROGRAMA] AS ID_PROGRAMA,\n        ID_FECHA_MENSUAL,\n        SUM(CAST([USUARIOS_PROYECTADOS] AS INT)) AS POBLACION_PROYECTADA,\n        ORIGEN\n    FROM (\n        SELECT \n            FORMAT([FECHA_INICIO], 'yyyyMMdd') AS ID_FECHA_MENSUAL,\n            up.[ID_UNIDAD],\n            [CATEGORIA],\n            [ID_PROGRAMA],\n            [USUARIOS_PROYECTADOS],\n            'FACT_PLAN_COBERTURA' AS ORIGEN\n        FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_PLAN_COBERTURA] up\n        LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] pa\n            ON up.ID_PERIODO = pa.ID_PERIODO\n    ) ll\n    GROUP BY \n        [ID_UNIDAD], [CATEGORIA], ID_FECHA_MENSUAL, [ID_PROGRAMA], ORIGEN\n    UNION\n     -- [Proteccion].[FACT_PLAN_COBERTURA]\n    SELECT \n         -1 AS ID_CURSO,\n        NULL AS GRADO,\n        5 AS ID_UNIDAD,\n        NULL AS CATEGORIA,\n        [ID_PLAN_COBERTURA] AS ID_PLAN_COBERTURA,\n        [ID_ESTABLECIMIENTO_EDUCATIVO] AS ID_ESTABLECIMIENTO_EDUCATIVO,\n        [ID_PROGRAMA] AS ID_PROGRAMA,\n        ID_FECHA_MENSUAL,\n        SUM(CAST([POBLACION_PROYECTADA] AS INT)) AS POBLACION_PROYECTADA,\n        ORIGEN\n    FROM (\n        SELECT \n            [ID_PLAN_COBERTURA],\n            [ANIO] * 10000 + 101 AS ID_FECHA_MENSUAL,\n            [ID_ESTABLECIMIENTO_EDUCATIVO],\n            [ID_PROGRAMA],\n            [COBERTURA_PROYECTADA] AS POBLACION_PROYECTADA,\n            'FACT_PLAN_COBERTURA' AS ORIGEN\n        FROM [DWH_COMFENALCO].[Proteccion].[FACT_PLAN_COBERTURA]\n    ) ll\n    GROUP BY \n        [ID_PLAN_COBERTURA], [ID_ESTABLECIMIENTO_EDUCATIVO], [ID_PROGRAMA], ID_FECHA_MENSUAL, ORIGEN\n    UNION\n     -- [Colegio].[FACT_SABER11_INDIVIDUAL]\n    SELECT \n        COALESCE(ID_CURSO, -1) AS ID_CURSO,\n        GRADO,\n        COALESCE(ID_UNIDAD, 5) AS ID_UNIDAD,\n        CATEGORIA,\n        ID_PLAN_COBERTURA,\n        ID_ESTABLECIMIENTO_EDUCATIVO,\n        ID_PROGRAMA,\n        LEFT([ID_FECHA],6)*100+1 AS ID_FECHA_MENSUAL,\n        POBLACION_PROYECTADA,\n        ORIGEN,\n        ACTIVIDAD,\n        NULL AS RESULTADO,\n        CATEGORIA_SABER11,\n        CAUSA,\n        NUM_POBLACION,\n        CALIFICACION,\n        DOCUMENTOS_COMPLETOS,\n        COUNT(DISTINCT([ID_REGISTRO])) AS NUM_ESTUDIANTES,\n        COUNT(DISTINCT CASE WHEN CAST([RESULTADO] AS int) &gt;= 250 THEN [ID_REGISTRO] ELSE NULL END) AS NUM_MAYOR_250,\n        TEMATICA\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_SABER11_INDIVIDUAL]\n    GROUP BY  \n        ID_CURSO, GRADO, ID_UNIDAD, CATEGORIA, ID_PLAN_COBERTURA,\n        ID_ESTABLECIMIENTO_EDUCATIVO, ID_PROGRAMA,\n        LEFT([ID_FECHA],6)*100+1, POBLACION_PROYECTADA, ORIGEN, ACTIVIDAD,\n        CATEGORIA_SABER11, CAUSA, NUM_POBLACION, CALIFICACION,\n        DOCUMENTOS_COMPLETOS, TEMATICA\n    UNION\n     -- [Colegio].[FACT_SABER11_COLEGIOS]\n    SELECT  \n        1 AS ID_CURSO,\n        'UNDECIMO' AS GRADO,\n        5 AS ID_UNIDAD,\n        NULL AS CATEGORIA,\n        NULL AS ID_PLAN_COBERTURA,\n        [COD_ESTABLECIMIENTO_EDUCATIVO] AS ID_ESTABLECIMIENTO_EDUCATIVO,\n        NULL AS ID_PROGRAMA,\n        LEFT([ID_FECHA],6)*100+1 AS ID_FECHA_MENSUAL,\n        NULL AS POBLACION_PROYECTADA,\n        'FACT_SABER11_COLEGIOS_CEC' AS ORIGEN,\n        'SABER 11' AS ACTIVIDAD,\n        [RESULTADO],\n        [CATEGORIA_SABER11],\n        NULL AS CAUSA,\n        NULL AS NUM_POBLACION,\n        NULL AS CALIFICACION,\n        NULL AS DOCUMENTOS_COMPLETOS,\n        NULL AS NUM_ESTUDIANTES,\n        NULL AS NUM_MAYOR_250,\n        NULL AS TEMATICA\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS]\n    WHERE [COD_ESTABLECIMIENTO_EDUCATIVO] = 313001003095\n    UNION\n     -- [Proteccion].[FACT_DESERCION]\n    SELECT \n        COALESCE(ID_CURSO, -1) AS ID_CURSO,\n        GRADO,\n        COALESCE(ID_UNIDAD, 5) AS ID_UNIDAD,\n        CATEGORIA,\n        ID_PLAN_COBERTURA,\n        CAST(ID_ESTABLECIMIENTO_EDUCATIVO AS nvarchar(40)) AS ID_ESTABLECIMIENTO_EDUCATIVO,\n        ID_PROGRAMA,\n        LEFT([ID_FECHA],6)*100+1 AS ID_FECHA_MENSUAL,\n        POBLACION_PROYECTADA,\n        ORIGEN,\n        ACTIVIDAD,\n        RESULTADO,\n        CATEGORIA_SABER11,\n        [CAUSA],\n        COUNT(DISTINCT([ID_POBLACION])) AS NUM_POBLACION,\n        NULL AS CALIFICACION,\n        NULL AS DOCUMENTOS_COMPLETOS,\n        NULL AS NUM_ESTUDIANTES,\n        NULL AS NUM_MAYOR_250,\n        NULL AS TEMATICA\n    FROM [DWH_COMFENALCO].[Proteccion].[FACT_DESERCION]\n    GROUP BY  \n        ID_CURSO, GRADO, ID_UNIDAD, CATEGORIA, ID_PLAN_COBERTURA,\n        CAST(ID_ESTABLECIMIENTO_EDUCATIVO AS nvarchar(40)), ID_PROGRAMA,\n        LEFT([ID_FECHA],6)*100+1, POBLACION_PROYECTADA, ORIGEN, ACTIVIDAD,\n        RESULTADO, CATEGORIA_SABER11, [CAUSA]\n    UNION \n     -- [Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]\n    SELECT \n         -1 AS ID_CURSO,\n        NULL AS GRADO,\n        COALESCE(fep.[ID_UNIDAD], 5) AS ID_UNIDAD,\n        NULL AS CATEGORIA,\n        NULL AS ID_PLAN_COBERTURA,\n        NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n        NULL AS ID_PROGRAMA,\n        FORMAT([FECHA_INICIO], 'yyyyMMdd') AS ID_FECHA_MENSUAL,\n        NULL AS POBLACION_PROYECTADA,\n        'FACT_EVALUACION_PLAN_CURRICULAR' AS ORIGEN,\n        'EVALUACION DISENO CURRICULAR' AS ACTIVIDAD,\n        NULL AS RESULTADO,\n        NULL AS CATEGORIA_SABER11,\n        NULL AS CAUSA,\n        NULL AS NUM_POBLACION,\n        [CALIFICACION],\n        NULL AS DOCUMENTOS_COMPLETOS,\n        NULL AS NUM_ESTUDIANTES,\n        NULL AS NUM_MAYOR_250,\n        NULL AS TEMATICA\n    FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR] fep\n    LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] pa\n        ON fep.ID_PERIODO = pa.ID_PERIODO\n    UNION \n     -- [Cedesarrollo].[FACT_ESTADO_MATRICULAS]\n    SELECT \n         -1 AS ID_CURSO,\n        NULL AS GRADO,\n        5 AS ID_UNIDAD,\n        NULL AS CATEGORIA,\n        NULL AS ID_PLAN_COBERTURA,\n        NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n        NULL AS ID_PROGRAMA,\n        LEFT([ID_FECHA],6)*100+1 AS ID_FECHA_MENSUAL,\n        NULL AS POBLACION_PROYECTADA,\n        'FACT_ESTADO_MATRICULAS' AS ORIGEN,\n        'MATRICULAS_ESTUDIANTES' AS ACTIVIDAD,\n        NULL AS RESULTADO,\n        NULL AS CATEGORIA_SABER11,\n        NULL AS CAUSA,\n        NULL AS NUM_POBLACION,\n        NULL AS CALIFICACION,\n        DOCUMENTOS_COMPLETOS,\n        COUNT(DISTINCT(ID_ESTUDIANTE)) AS NUM_ESTUDIANTES,\n        NULL AS NUM_MAYOR_250,\n        NULL AS TEMATICA\n    FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS]\n    GROUP BY ID_FECHA, DOCUMENTOS_COMPLETOS\n) un\nINNER JOIN (SELECT ID_FECHA AS ID_FECHA2 FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]) dimM\n    ON un.ID_FECHA_MENSUAL = dimM.ID_FECHA2;\n</code></pre> <ol> <li>Destino: <ul> <li>Se utiliza un componente Destino de ADO NET para insertar los datos consolidados en la tabla <code>[DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA]</code>.  </li> <li>El mapeo entre las columnas resultantes de la consulta y las columnas de la tabla destino se realiza de forma precisa, asegurando la integridad y consistencia de la informaci\u00f3n financiera cargada.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_11","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Consolidaci\u00f3n de Informaci\u00f3n Financiera:   La consulta SQL unifica datos contables y presupuestarios de varias fuentes (incluyendo registros de ejecuci\u00f3n contable, presupuestos y otros indicadores financieros) mediante la cl\u00e1usula <code>UNION</code>, lo que permite obtener una visi\u00f3n consolidada de la situaci\u00f3n financiera.</p> </li> <li> <p>Filtrado y Agrupaci\u00f3n:   Se agrupan y suman los valores de importe, ingresos, gastos, entre otros, para calcular totales que faciliten el an\u00e1lisis de la ejecuci\u00f3n contable y la comparaci\u00f3n con el presupuesto.</p> </li> <li> <p>Vinculaci\u00f3n Temporal y Organizacional:   Los datos se relacionan con la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO_MENSUAL</code>) y con la dimensi\u00f3n de unidades organizativas, lo que posibilita un an\u00e1lisis multidimensional de la informaci\u00f3n financiera.</p> </li> <li> <p>Estandarizaci\u00f3n de Cuentas:   Se filtra la informaci\u00f3n para excluir ciertos tipos de cuentas (por ejemplo, aquellas que se consideren no relevantes) y se seleccionan cuentas espec\u00edficas basadas en sus prefijos, garantizando la relevancia de los datos consolidados.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_12","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Dependencias: </p> <ul> <li>Requiere que la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> est\u00e9 cargada previamente para la correcta asignaci\u00f3n del campo <code>ID_FECHA_MENSUAL</code>.</li> <li>Depende de la calidad y consistencia de los datos de origen, tales como <code>FACT_DETALLE_CONTABLE</code> y <code>FACT_PRESUPUESTO</code>, para consolidar la informaci\u00f3n financiera.</li> <li>Se apoya en las dimensiones de unidades organizativas y cuentas contables para vincular los datos a las \u00e1reas y departamentos correspondientes.</li> </ul> </li> <li> <p>Secuencia:   Se ejecuta en la etapa de carga de hechos dentro del paquete <code>09-ETLS_CUBO</code>, despu\u00e9s de la carga de dimensiones y antes de otros procesos anal\u00edticos o reportes que utilicen la informaci\u00f3n consolidada en <code>FACT_FINANCIERA</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_colegiotruncar-tabla","title":"<code>FACT_MINERIA\\\\MINERIA_COLEGIO\\\\Truncar Tabla</code>","text":"<p>El componente <code>FACT_MINERIA\\\\MINERIA_COLEGIO\\\\Truncar Tabla</code> es una tarea de ejecuci\u00f3n SQL (Execute SQL Task) dentro del paquete SSIS, utilizado para preparar el entorno de carga de datos en la secci\u00f3n de miner\u00eda, espec\u00edficamente para la miner\u00eda en el contexto de colegios. Su funci\u00f3n principal es vaciar la tabla de hechos <code>FACT_MINERIA</code> en el esquema <code>Transversal</code> de la base de datos <code>DWH_COMFENALCO</code>, asegurando que la tabla est\u00e9 limpia antes de proceder a cargar nuevos datos.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-truncar-tabla-en-este-contexto","title":"\u00bfQu\u00e9 significa \"Truncar Tabla\" en este contexto?","text":"<p>En este contexto, \"Truncar Tabla\" se refiere a la acci\u00f3n de eliminar todos los registros de una tabla de forma r\u00e1pida y eficiente mediante el comando <code>TRUNCATE TABLE</code>. Esta operaci\u00f3n elimina los datos sin registrar cada eliminaci\u00f3n individualmente en el log de transacciones, lo que la hace ideal para reiniciar la tabla antes de un nuevo proceso de carga de datos.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_10","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>FACT_MINERIA\\\\MINERIA_COLEGIO\\\\Truncar Tabla</code> tiene como objetivos:</p> <ol> <li> <p>Preparar el Entorno de Carga: </p> <ul> <li>Elimina todos los registros existentes en la tabla <code>FACT_MINERIA</code> para evitar la acumulaci\u00f3n de datos obsoletos o duplicados antes de insertar la nueva informaci\u00f3n resultante del proceso de miner\u00eda.</li> </ul> </li> <li> <p>Optimizar el Rendimiento: </p> <ul> <li>Al utilizar el comando <code>TRUNCATE TABLE</code>, la operaci\u00f3n se realiza de forma r\u00e1pida y eficiente, reiniciando cualquier contador de identidad y liberando espacio de almacenamiento de manera inmediata.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_9","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: Parte del proceso ETL en <code>09-ETLS_CUBO</code>.</li> <li>Contexto: Se ubica en la secci\u00f3n <code>FACT_MINERIA\\\\MINERIA_COLEGIO</code>, que agrupa las tareas relacionadas con la miner\u00eda de datos en colegios.</li> <li>Componente: <code>Truncar Tabla</code> (Execute SQL Task).</li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_9","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Tipo de Tarea: </p> <ul> <li>Se utiliza una tarea de ejecuci\u00f3n SQL (Execute SQL Task) para ejecutar el comando de truncado.</li> </ul> </li> <li> <p>Conexi\u00f3n: </p> <ul> <li>La tarea utiliza el administrador de conexiones referenciado como <code>DWH_COMFENALCO</code>, lo que garantiza el acceso a la base de datos correcta.</li> </ul> </li> <li> <p>C\u00f3digo SQL Utilizado: </p> <ul> <li>La instrucci\u00f3n SQL ejecutada es:</li> </ul> <pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_MINERIA];\n</code></pre> <ul> <li>Este comando elimina de forma masiva todos los registros de la tabla, dej\u00e1ndola lista para una nueva carga.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_12","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Integridad y Limpieza de Datos:   Garantiza que la tabla de hechos de miner\u00eda est\u00e9 vac\u00eda antes de cada ejecuci\u00f3n del proceso ETL, previniendo la duplicaci\u00f3n y asegurando la integridad de los nuevos datos que se cargar\u00e1n.</p> </li> <li> <p>Optimizaci\u00f3n de Procesos ETL:   Al eliminar los datos de forma r\u00e1pida y sin afectar el log de transacciones de manera individual, se mejora el rendimiento general del proceso de carga.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_13","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Secuencia del Proceso ETL:   Esta tarea se ejecuta generalmente al inicio del proceso de miner\u00eda, justo antes de la inserci\u00f3n de nuevos registros en la tabla <code>FACT_MINERIA</code>.</p> </li> <li> <p>Dependencias: </p> <ul> <li>Depende de la correcta configuraci\u00f3n del administrador de conexiones (<code>DWH_COMFENALCO</code>).</li> <li>Es una tarea preparatoria que influye en la calidad y consistencia de los datos que se cargar\u00e1n posteriormente en el cubo OLAP.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_colegioproceso-matricula-temporal","title":"<code>FACT_MINERIA\\\\MINERIA_COLEGIO\\\\Proceso Matr\u00edcula (Temporal)</code>","text":"<p>El componente <code>FACT_MINERIA\\\\MINERIA_COLEGIO\\\\Proceso Matr\u00edcula (Temporal)</code> es una tarea de flujo de datos (Data Flow Task) que forma parte del proceso de miner\u00eda de datos en colegios, ubicado dentro del \u00e1rea de miner\u00eda del Data Warehouse. Esta tarea est\u00e1 dise\u00f1ada para extraer, transformar y cargar (ETL) informaci\u00f3n relacionada con el proceso de matr\u00edcula (en un contexto temporal) a partir de diversas fuentes, realizando consolidaciones y c\u00e1lculos espec\u00edficos para evaluar el comportamiento y desempe\u00f1o de las inscripciones.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-proceso-matricula-temporal-en-este-contexto","title":"\u00bfQu\u00e9 significa \"Proceso Matr\u00edcula (Temporal)\" en este contexto?","text":"<p>En este contexto, el t\u00e9rmino \"Proceso Matr\u00edcula (Temporal)\" se refiere a la fase de procesamiento y consolidaci\u00f3n de datos de inscripciones o matr\u00edculas, en la que se integran y transforman registros provenientes de las inscripciones escolares. Se consideran aspectos como indicadores de codeudor, secretar\u00eda acad\u00e9mica, psicolog\u00eda y coordinaci\u00f3n acad\u00e9mica, entre otros, para medir el tiempo de gesti\u00f3n y cumplimiento de ciertos procesos en el \u00e1mbito de la matr\u00edcula.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_11","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>Proceso Matr\u00edcula (Temporal)</code> tiene como objetivos:</p> <ol> <li> <p>Extraer Datos de Matr\u00edcula: </p> <ul> <li>Recupera informaci\u00f3n detallada de la tabla de inscripciones matriculares, consolidando datos relevantes como fecha, a\u00f1o acad\u00e9mico, identificador del estudiante (BP), categor\u00eda, curso y tipo de estudiante.</li> </ul> </li> <li> <p>Calcular Indicadores de Gesti\u00f3n: </p> <ul> <li>Utiliza expresiones condicionales y operaciones de consolidaci\u00f3n (mediante subconsultas, PIVOT y OUTER APPLY) para determinar indicadores clave, tales como:<ul> <li>Indicadores y puntajes de codeudor:    Se calcula si existe o no codeudor, el puntaje asignado y se eval\u00faa la proporci\u00f3n de cumplimiento.</li> <li>Indicadores para secretar\u00eda acad\u00e9mica, psicolog\u00eda y coordinaci\u00f3n acad\u00e9mica:    Se determina la existencia, puntaje y condiciones para cada \u00e1rea, comparando los tiempos de gesti\u00f3n con el total esperado y verificando el cumplimiento.</li> <li>Otros indicadores de gesti\u00f3n:    Se registran indicadores generales de proceso, cumplimiento, estado de admisi\u00f3n y desistimiento.</li> </ul> </li> </ul> </li> <li> <p>Consolidar la Informaci\u00f3n para su An\u00e1lisis: </p> <ul> <li>La salida de este componente contiene los datos transformados y calculados, listos para ser cargados en la tabla de hechos correspondiente, lo que permitir\u00e1 su posterior an\u00e1lisis y generaci\u00f3n de reportes en el Data Warehouse.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_10","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: Ubicado en el proceso de miner\u00eda dentro del \u00e1rea <code>FACT_MINERIA\\\\MINERIA_COLEGIO</code>.</li> <li>Tarea del Flujo de Datos: <code>Proceso Matr\u00edcula (Temporal)</code></li> <li>Prop\u00f3sito: Consolidar y transformar los datos de inscripci\u00f3n para la evaluaci\u00f3n del proceso de matr\u00edcula en colegios.</li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_10","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Origen de Datos y Consulta SQL: </p> <ul> <li>La tarea utiliza un componente de fuente de datos (Data Reader Source) que ejecuta una compleja instrucci\u00f3n SQL.  </li> <li> <p>SQL Command:  La consulta SQL est\u00e1 dividida en secciones que incluyen comentarios para facilitar su mantenimiento. La consulta realiza:</p> <ul> <li>Selecci\u00f3n y agrupaci\u00f3n: Se agrupan datos de la tabla de inscripciones (<code>FACT_INSCRIPCION_MATRICULAS</code>) de distintos sistemas, uniendo informaci\u00f3n de diversas dimensiones (tiempo, categor\u00edas, cursos, tipo de estudiante, etc.).</li> <li>Uso de OUTER APPLY y PIVOT: Se aplican estas t\u00e9cnicas para transformar filas en columnas, permitiendo obtener valores agregados (como el tiempo de gesti\u00f3n) para distintos estados del proceso (por ejemplo, codeudor, secretar\u00eda acad\u00e9mica, psicolog\u00eda y coordinaci\u00f3n acad\u00e9mica).</li> <li>C\u00e1lculo de indicadores: Se determinan indicadores binarios (0 o 1) y se establecen condiciones basadas en comparaciones con el total de gesti\u00f3n, as\u00ed como la evaluaci\u00f3n del cumplimiento (IND_CUMPLIMIENTO) y estados del proceso (IND_EN_PROCESO, IND_ADMITIDO, IND_NO_ADMITIDO, IND_DESISTIDO).</li> </ul> </li> <li> <p>Fragmento SQL: <pre><code>SELECT  \n    FT.ID_FECHA,\n    FT.ID_ANIO_ACADEMICO,\n    FT.BP,\n    FT.ID_CATEGORIA,\n    FT.ID_CURSO,\n    FT.ID_TIPO_ESTUDIANTE,\n    CASE WHEN FT2.[1] IS NULL THEN 0 ELSE 1 END AS IND_CODEUDOR,\n    CASE WHEN FT2.[1] = FT4.T_TOTAL_GESTION AND ISNULL(FT3.IND_CUMPLIMIENTO,1) = 0 THEN 0 ELSE 1 END AS P_CODEUDOR,\n    FT2.[1] AS T_CODEUDOR,\n    ...\nFROM\n    ( ... ) FT\n    OUTER APPLY ( ... ) FT2\n    OUTER APPLY ( ... ) FT3\n    OUTER APPLY ( ... ) FT4\n    OUTER APPLY ( ... ) FT5\n</code></pre> (El SQL completo est\u00e1 disponible en el componente, y se recomienda su revisi\u00f3n en el entorno de desarrollo para entender todos los detalles y condiciones aplicadas.)</p> </li> </ul> </li> <li> <p>Transformaciones Adicionales: </p> <ul> <li>La consulta utiliza diversas funciones de conversi\u00f3n, condicionales (CASE), y agregaciones para calcular los indicadores y consolidar la informaci\u00f3n en un formato uniforme.</li> </ul> </li> <li> <p>Destino de los Datos: </p> <ul> <li>Los datos extra\u00eddos y transformados se env\u00edan a un componente posterior (TMP_PROCESO_MATRICULA_COLEGIO) para su almacenamiento temporal o consolidaci\u00f3n adicional.  </li> <li>Este destino se configura para escribir los resultados en una tabla temporal (<code>TMP_PROCESO_MATRICULA_COLEGIO</code>) ubicada en el \u00e1rea de staging (STAGE_AREA), lo que permite validar la transformaci\u00f3n antes de su integraci\u00f3n final en el Data Warehouse.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_13","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Integraci\u00f3n de Procesos de Matr\u00edcula:   Se consolidan datos de inscripciones provenientes de diferentes or\u00edgenes y sistemas, evaluando indicadores espec\u00edficos relacionados con:</p> <ul> <li>La existencia y desempe\u00f1o de codeudores.</li> <li>La participaci\u00f3n de \u00e1reas de apoyo acad\u00e9mico como secretar\u00eda, psicolog\u00eda y coordinaci\u00f3n.</li> <li>El cumplimiento de tiempos de gesti\u00f3n y otros indicadores de proceso.</li> </ul> </li> <li> <p>Evaluaci\u00f3n del Cumplimiento:   Se comparan los tiempos de gesti\u00f3n registrados con el total esperado (T_TOTAL_GESTION) y se determina si se cumplen los criterios establecidos para cada \u00e1rea (indicadores P_CODEUDOR, P_SECRETARIA_ACADEMICA, P_PSICOLOGIA, P_COORDINACION_ACADEMICA).</p> </li> <li> <p>Determinaci\u00f3n de Estados del Proceso:   Se generan indicadores binarios para reflejar la existencia de ciertos estados (por ejemplo, codeudor, secretar\u00eda, psicolog\u00eda, coordinaci\u00f3n) y el cumplimiento general del proceso de matr\u00edcula.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_14","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Preprocesamiento:   Este componente se ejecuta como parte del proceso de miner\u00eda para los datos de matr\u00edcula, donde se prepara la informaci\u00f3n antes de la carga final en las tablas de hechos o en procesos de an\u00e1lisis posterior.</p> </li> <li> <p>Integraci\u00f3n en el Flujo ETL:   Los datos transformados por este flujo son utilizados para alimentar reportes y an\u00e1lisis en el Data Warehouse, proporcionando indicadores clave sobre el proceso de matr\u00edcula en colegios.</p> </li> <li> <p>Dependencias: </p> <ul> <li>Depende de la correcta integraci\u00f3n y calidad de los datos provenientes de <code>FACT_INSCRIPCION_MATRICULAS</code> y otras dimensiones relacionadas.</li> <li>La configuraci\u00f3n de las conexiones (principalmente <code>DWH_COMFENALCO</code>) es esencial para acceder a las fuentes de datos y escribir en el \u00e1rea de staging.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_colegiogestion-matriculas","title":"<code>FACT_MINERIA\\MINERIA_COLEGIO\\Gestion Matriculas</code>","text":"<p>El componente <code>Package\\FACT_MINERIA\\MINERIA_COLEGIO\\Gestion Matriculas</code> es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS que forma parte del proceso ETL para el m\u00f3dulo de miner\u00eda en colegios. Su funci\u00f3n principal es gestionar la transformaci\u00f3n y carga de la informaci\u00f3n relacionada con las matr\u00edculas escolares, proveniente de un \u00e1rea de staging, hacia el Data Warehouse, facilitando el an\u00e1lisis de la gesti\u00f3n de matr\u00edculas en el contexto de miner\u00eda.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-gestion-matriculas-en-este-contexto","title":"\u00bfQu\u00e9 significa \"Gestion Matriculas\" en este contexto?","text":"<p>En este contexto, \"Gestion Matriculas\" se refiere al proceso de extracci\u00f3n, transformaci\u00f3n y carga de datos relacionados con el proceso de matr\u00edcula en colegios. Esto incluye la consolidaci\u00f3n de informaci\u00f3n sobre per\u00edodos acad\u00e9micos, fechas de inicio y fin de las gestiones, tiempo invertido en el proceso y la clasificaci\u00f3n de la actividad (por ejemplo, \"Gesti\u00f3n Codeudor\", \"Gesti\u00f3n Secretaria Acad\u00e9mica\", \"Gesti\u00f3n Psicolog\u00eda\", \"Gesti\u00f3n Coordinaci\u00f3n Acad\u00e9mica\", \"En Proceso\", \"Estudiante Admitido\", \"Estudiante No Admitido\" y \"Estudiante Con Proceso Desistido\").</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_12","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>Gestion Matriculas</code> tiene como objetivos:</p> <ol> <li> <p>Extraer datos de matr\u00edculas: </p> <ul> <li>Obtener registros de la tabla de staging <code>[STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO]</code> que contienen informaci\u00f3n detallada del proceso de matr\u00edcula en colegios.</li> </ul> </li> <li> <p>Transformar la informaci\u00f3n: </p> <ul> <li>Realizar conversiones y transformaciones de datos, por ejemplo:<ul> <li>Calcular el campo <code>ID_FECHA_MENSUAL</code> a partir del a\u00f1o acad\u00e9mico.</li> <li>Convertir el campo <code>ID_FECHA</code> a tipo <code>datetime</code> para obtener la <code>FECHA_INICIAL</code>.</li> <li>Calcular la <code>FECHA_FINAL</code> sumando los segundos especificados en <code>TIEMPO_SEGUNDOS</code> a la <code>FECHA_INICIAL</code>.</li> </ul> </li> <li>Asignar un valor fijo de <code>1</code> a <code>ID_UNIDAD</code>.</li> <li>Determinar la actividad del proceso (p. ej., \"Gesti\u00f3n Codeudor\", \"Gesti\u00f3n Secretaria Acad\u00e9mica\", etc.) seg\u00fan indicadores espec\u00edficos.</li> </ul> </li> <li> <p>Cargar la informaci\u00f3n en el Data Warehouse: </p> <ul> <li>Enviar los datos transformados al destino configurado para su inserci\u00f3n en la tabla de hechos de miner\u00eda en el Data Warehouse, utilizando el administrador de conexiones <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_11","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: Se ubica dentro del proceso <code>FACT_MINERIA\\MINERIA_COLEGIO</code>.</li> <li>Tarea de Flujo de Datos: <code>Gestion Matriculas</code>.</li> <li>Componentes Principales:<ul> <li>Consulta Matriculas Colegio Mineria: Componente que extrae y transforma los datos de matr\u00edculas.</li> <li>Destino de ADO NET: Componente que carga la informaci\u00f3n en la tabla de destino en el Data Warehouse.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_11","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:</p> <ul> <li>Se utiliza el componente <code>Consulta Matriculas Colegio Mineria</code> para extraer datos de la tabla <code>[STAGE_AREA].[Transversal].[TMP_PROCESO_MATRICULA_COLEGIO]</code>.  </li> <li>La consulta SQL realiza lo siguiente:<ul> <li>Selecciona campos como <code>BP</code>, <code>ID_FECHA_MENSUAL</code>, <code>ID_ANIO_ACADEMICO</code>, y calcula los campos <code>FECHA_INICIAL</code> y <code>FECHA_FINAL</code>:</li> <li><code>FECHA_INICIAL</code> se obtiene convirtiendo <code>ID_FECHA</code> a <code>datetime</code>.</li> <li><code>FECHA_FINAL</code> se calcula utilizando la funci\u00f3n <code>DATEADD(SECOND, TIEMPO_SEGUNDOS, FECHA_INICIAL)</code>.</li> <li>Asigna el valor <code>1</code> a <code>ID_UNIDAD</code>.</li> <li>Extrae adem\u00e1s campos que identifican la actividad (por ejemplo, \"Gesti\u00f3n Codeudor\", \"Gesti\u00f3n Secretaria Acad\u00e9mica\", \"Gesti\u00f3n Psicolog\u00eda\" o \"Gesti\u00f3n Coordinaci\u00f3n Acad\u00e9mica\") seg\u00fan indicadores (como <code>P_CODEUDOR</code>, <code>P_SECRETARIA_ACADEMICA</code>, <code>P_PSICOLOGIA</code> y **<code>P_COORDINACION_ACADEMICA</code>).</li> <li>Se agrupan y unifican los resultados mediante <code>UNION ALL</code> para consolidar la informaci\u00f3n de distintas actividades.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n:</p> <ul> <li>La consulta transforma el campo <code>ID_ANIO_ACADEMICO</code> concaten\u00e1ndolo con '0101' y convirti\u00e9ndolo en un entero para generar <code>ID_FECHA_MENSUAL</code>.</li> <li>Se utilizan conversiones de tipo para asegurar que los campos de fecha sean compatibles y se calculen correctamente.</li> <li>Se definen actividades espec\u00edficas y se asignan valores a <code>TIEMPO_SEGUNDOS</code> para reflejar el tiempo invertido en cada proceso de matr\u00edcula.</li> </ul> </li> <li> <p>Carga:</p> <ul> <li>El componente <code>Destino de ADO NET</code> recibe los datos transformados y los carga en la tabla de destino, configurada para la miner\u00eda en el Data Warehouse, utilizando la conexi\u00f3n <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_14","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Consolidaci\u00f3n de Matr\u00edculas:   Se integran datos de diferentes procesos de matr\u00edcula (por ejemplo, Codeudor, Secretar\u00eda Acad\u00e9mica, Psicolog\u00eda y Coordinaci\u00f3n Acad\u00e9mica) en un \u00fanico flujo de datos, permitiendo un an\u00e1lisis global del proceso de matriculaci\u00f3n en colegios.</p> </li> <li> <p>Gesti\u00f3n del Tiempo:   Se generan dos columnas cruciales:  </p> <ul> <li><code>FECHA_INICIAL</code>: Marca el inicio del proceso de matr\u00edcula.</li> <li><code>FECHA_FINAL</code>: Determina el final del proceso sumando los segundos especificados en <code>TIEMPO_SEGUNDOS</code>.</li> </ul> </li> <li> <p>Clasificaci\u00f3n de Actividades:   La actividad se etiqueta seg\u00fan el tipo de proceso de matr\u00edcula, lo que facilita el an\u00e1lisis y la generaci\u00f3n de reportes espec\u00edficos por actividad.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_15","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Integraci\u00f3n en el Proceso ETL de Miner\u00eda:   Este componente es crucial para consolidar y transformar los datos de matr\u00edcula, que se integrar\u00e1n en el cubo OLAP del Data Warehouse para an\u00e1lisis posteriores.</p> </li> <li> <p>Dependencia Dimensional:   Se relaciona con la dimensi\u00f3n temporal <code>DIM_TIEMPO_MENSUAL</code>, ya que se utiliza para calcular y validar el campo <code>ID_FECHA_MENSUAL</code>.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_colegiopqrs-colegio","title":"<code>FACT_MINERIA\\MINERIA_COLEGIO\\PQRs Colegio</code>","text":"<p>El componente <code>PQRs Colegio</code> es una tarea de flujo de datos (Data Flow Task) dentro del proceso ETL del m\u00f3dulo de miner\u00eda para colegios. Este flujo se encarga de extraer, transformar y cargar informaci\u00f3n relacionada con las PQRs (Peticiones, Quejas y Reclamos) emitidas por los acudientes de los estudiantes, integrando datos provenientes de diversas fuentes para su an\u00e1lisis en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-pqrs-colegio-en-este-contexto","title":"\u00bfQu\u00e9 significa \"PQRs Colegio\" en este contexto?","text":"<p>En este entorno, \"PQRs Colegio\" se refiere a la informaci\u00f3n relativa a las peticiones, quejas y reclamos presentados por los acudientes de los estudiantes en el \u00e1mbito escolar. Estos registros permiten analizar la gesti\u00f3n de incidencias y la calidad del servicio en los colegios, siendo esenciales para el monitoreo y mejora continua de los procesos administrativos y educativos.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_13","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>PQRs Colegio</code> tiene como principales objetivos:</p> <ol> <li> <p>Extraer Datos de PQRs: </p> <ul> <li>Recuperar registros de la tabla de hechos <code>FACT_PQRS</code> y combinarlos con informaci\u00f3n de afiliados y acudientes, para identificar las PQRs presentadas por los acudientes.</li> </ul> </li> <li> <p>Transformar la Informaci\u00f3n: </p> <ul> <li>Utilizar una consulta SQL compleja con expresiones comunes (CTE) para:<ul> <li>Calcular el campo <code>ID_FECHA_MENSUAL</code> a partir de la fecha de creaci\u00f3n de la PQR.</li> <li>Extraer el a\u00f1o acad\u00e9mico y establecer la unidad (en este caso, la unidad es 1).</li> <li>Determinar las fechas de inicio y finalizaci\u00f3n del proceso PQR (convertir la fecha original y calcular el lapso en segundos mediante <code>DATEDIFF</code>).</li> <li>Clasificar la actividad concatenando la palabra \"PQR\" con la causa, en min\u00fascula, para formar el descriptor de actividad.</li> </ul> </li> <li>Posteriormente, se realiza un LEFT JOIN con los datos de inscripciones (tomados de <code>FACT_INSCRIPCION_MATRICULAS</code> en el \u00e1mbito colegio) para agregar informaci\u00f3n adicional de clasificaci\u00f3n, como categor\u00eda, curso y tipo de estudiante.</li> </ul> </li> <li> <p>Cargar la Informaci\u00f3n: </p> <ul> <li>Los datos transformados se env\u00edan a la tabla <code>[Transversal].[FACT_MINERIA]</code> utilizando un componente de destino ADO NET, facilitando su posterior an\u00e1lisis en el Data Warehouse.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_12","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>Package\\FACT_MINERIA\\MINERIA_COLEGIO\\PQRs Colegio</code></li> <li>Tarea de Flujo de Datos: <code>PQRs Colegio</code></li> <li>Componentes Principales:<ul> <li>Consulta PQRs: Extrae y transforma la informaci\u00f3n proveniente de las PQRs.</li> <li>FACT_MINERIA: Encargado de formatear y preparar la informaci\u00f3n para la carga.</li> <li>Lookup: Realiza b\u00fasquedas en la tabla de destino para complementar la informaci\u00f3n, bas\u00e1ndose en el campo <code>BP</code>.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_12","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos: Consulta PQRs</p> <ul> <li> <p>Extracci\u00f3n:  El componente <code>Consulta PQRs</code> utiliza una consulta SQL que define varias CTE:</p> <ul> <li><code>PQRS_ACUDIENTES</code>: Extrae los datos de PQRs de la tabla <code>FACT_PQRS</code>, realizando conversiones para obtener:</li> <li><code>BP</code>: El identificador del acudiente (a partir de la clave del estudiante).</li> <li><code>ID_FECHA_MENSUAL</code>: Se calcula convirtiendo la parte correspondiente de la fecha de la PQR a un entero (por ejemplo, YYYYMM01).</li> <li><code>ID_ANIO_ACADEMICO</code>: Extra\u00eddo del campo de fecha, transformado para reflejar el a\u00f1o acad\u00e9mico.</li> <li><code>FECHA_INICIAL</code> y <code>FECHA_FINAL</code>: Derivadas de los campos <code>FECHA_CREACION</code> y <code>FECHA_RESOLUCION</code> respectivamente.</li> <li><code>ACTIVIDAD</code>: Se forma concatenando la palabra \"PQR\" con la causa (en min\u00fascula).</li> <li> <p><code>TIEMPO_SEGUNDOS</code>: Calculado mediante la funci\u00f3n <code>DATEDIFF</code> en segundos entre la fecha de creaci\u00f3n y la fecha de resoluci\u00f3n.</p> </li> <li> <p><code>UniqueRows</code> e <code>Inscripcion_Matriculas</code>:        Estas CTE se utilizan para seleccionar, a partir de la tabla <code>FACT_INSCRIPCION_MATRICULAS</code> (del \u00e1mbito colegio), la fila \u00fanica por acudiente y a\u00f1o acad\u00e9mico que contiene informaci\u00f3n de inscripci\u00f3n, permitiendo obtener los valores de <code>ID_CATEGORIA</code>, <code>ID_CURSO</code> y <code>ID_TIPO_ESTUDIANTE</code>.</p> </li> </ul> </li> <li> <p>Combinaci\u00f3n:  Finalmente, se realiza un <code>LEFT JOIN</code> entre los datos de <code>PQRS_ACUDIENTES</code> y <code>Inscripcion_Matriculas</code> para incorporar la clasificaci\u00f3n correspondiente a cada registro de PQR.</p> </li> <li> <p>Consulta SQL:  La consulta SQL completa del componente es la siguiente:</p> </li> </ul> <pre><code>WITH PQRS_ACUDIENTES AS (\n    SELECT \n        ac.[BP_ESTUDIANTE] AS BP,\n        CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n        CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n        [ID_UNIDAD],\n        [FECHA_CREACION] AS FECHA_INICIAL,\n        [FECHA_RESOLUCION] AS FECHA_FINAL,\n        CONCAT('PQR ', LOWER([CAUSA])) AS ACTIVIDAD,\n        DATEDIFF(SECOND, [FECHA_CREACION], [FECHA_RESOLUCION]) AS TIEMPO_SEGUNDOS,\n        0 AS VALOR_PAGADO\n    FROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] f\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n        ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01')\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n        ON f.[ID_AFILIADO] = a.[ID_AFILIADO]\n    INNER JOIN [DWH_COMFENALCO].[Colegio].[DIM_ACUDIENTES] ac \n        ON ac.[BP_ACUDIENTE] = a.[PARTNER]\n    WHERE f.ID_AFILIADO != -1 AND ID_UNIDAD = 1\n),\nUniqueRows AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA_FAMILIAR] AS ID_CATEGORIA,\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE],\n        ROW_NUMBER() OVER (PARTITION BY [BP], [ANIO_ACADEMICO] ORDER BY [ID] DESC) AS RowNum\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS]\n),\nInscripcion_Matriculas AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA],\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE]\n    FROM UniqueRows\n    WHERE RowNum = 1\n)\nSELECT pa.*,\n       ISNULL(im.ID_CATEGORIA, 4) AS ID_CATEGORIA,\n       ISNULL(im.ID_CURSO, -1) AS ID_CURSO,\n       ISNULL(im.ID_TIPO_ESTUDIANTE, -1) AS ID_TIPO_ESTUDIANTE\nFROM PQRS_ACUDIENTES pa\nLEFT JOIN Inscripcion_Matriculas im \n    ON im.[BP] = pa.[BP] \n    AND im.[ANIO_ACADEMICO] = pa.[ID_ANIO_ACADEMICO]\n</code></pre> </li> <li> <p>Carga de Datos:</p> <ul> <li> <p>Destino de ADO NET:  El componente de destino toma los datos procesados por la consulta y los carga en la tabla <code>[Transversal].[FACT_MINERIA]</code> del Data Warehouse.  </p> </li> <li> <p>La configuraci\u00f3n del destino utiliza la conexi\u00f3n <code>DWH_COMFENALCO</code> para insertar la informaci\u00f3n de las PQRs junto con los campos adicionales obtenidos a trav\u00e9s del LEFT JOIN.</p> </li> </ul> </li> <li> <p>Lookup (Opcional):</p> <ul> <li>Se utiliza un componente <code>Lookup</code> para comparar o complementar los datos extra\u00eddos de la fuente con los registros existentes en <code>FACT_MINERIA</code>, asegurando la integridad y consistencia de la informaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_15","title":"L\u00f3gica de Negocio","text":"<ul> <li>Consolidaci\u00f3n de PQRs:   El flujo extrae las PQRs generadas por los acudientes, calcula el per\u00edodo mensual y el tiempo de gesti\u00f3n (en segundos) y las clasifica mediante la concatenaci\u00f3n de la palabra \"PQR\" con la causa.  </li> <li>Integraci\u00f3n de Datos de Inscripci\u00f3n:   Se complementa la informaci\u00f3n de las PQRs con datos de inscripci\u00f3n (como categor\u00eda, curso y tipo de estudiante) obtenidos de la fuente de matr\u00edculas, permitiendo un an\u00e1lisis m\u00e1s integral.</li> <li>Validaci\u00f3n Temporal:   Se utiliza la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> para validar y estandarizar el campo <code>ID_FECHA_MENSUAL</code>, asegurando la coherencia temporal en los datos cargados.</li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_16","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li>Integraci\u00f3n en el M\u00f3dulo de Miner\u00eda:   Los datos procesados en <code>PQRs Colegio</code> se integran con otros m\u00f3dulos del proceso ETL de miner\u00eda, lo que permite analizar la incidencia de las PQRs junto con otros indicadores relevantes para la toma de decisiones.</li> <li>Conexi\u00f3n con Dimensiones:   La validaci\u00f3n y transformaci\u00f3n de las fechas se realiza en conjunto con la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code>, garantizando que los datos est\u00e9n alineados con el marco temporal del Data Warehouse.</li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_educacion_tecnica_y_continuainscripcion","title":"<code>FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Inscripcion</code>","text":"<p>El componente <code>Inscripcion</code> es una tarea de flujo de datos (Data Flow Task) que forma parte del proceso ETL del m\u00f3dulo de miner\u00eda para educaci\u00f3n t\u00e9cnica y continua. Este componente se encarga de extraer, transformar y cargar informaci\u00f3n relacionada con las inscripciones de estudiantes (ya sean afiliados, beneficiarios o de empresas) en el Data Warehouse <code>DWH_COMFENALCO</code>. La informaci\u00f3n consolidada es fundamental para el an\u00e1lisis y seguimiento de la gesti\u00f3n de matr\u00edculas en programas t\u00e9cnicos y de educaci\u00f3n continua.</p>"},{"location":"03.Cubo/03.ETL/#que-representa-inscripcion-en-este-contexto","title":"\u00bfQu\u00e9 representa \"Inscripcion\" en este contexto?","text":"<p>En el contexto de miner\u00eda educativa, \"Inscripcion\" se refiere al proceso de captura y procesamiento de datos de inscripciones de estudiantes. Esto incluye: - La extracci\u00f3n de datos desde las fuentes operativas en Cedesarrollo. - La transformaci\u00f3n de fechas y asignaci\u00f3n de etiquetas seg\u00fan el estado de inscripci\u00f3n. - La clasificaci\u00f3n de los registros en funci\u00f3n del origen (afiliados, beneficiarios, empresas o no aportantes).</p> <p>Esta informaci\u00f3n se utiliza para generar indicadores que permiten evaluar el desempe\u00f1o y la eficiencia en la gesti\u00f3n de matr\u00edculas.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_14","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>Inscripcion</code> tiene como objetivos:</p> <ol> <li> <p>Extraer:</p> <ul> <li>Obtener los registros de inscripci\u00f3n de la fuente <code>[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]</code>.</li> <li>Realizar uniones (JOIN) con dimensiones relacionadas, como:<ul> <li><code>[DIM_ESTUDIANTES]</code> para obtener datos del estudiante.</li> <li><code>[DIM_AFILIADOS]</code> y <code>[DIM_BENEFICIARIOS]</code> para clasificar el tipo de estudiante.</li> <li><code>[DIM_JORNADA]</code> para determinar la unidad organizacional.</li> <li><code>[DIM_TIEMPO_MENSUAL]</code> para asignar el per\u00edodo acad\u00e9mico mediante el campo <code>ID_FECHA_MENSUAL</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformar:</p> <ul> <li>Convertir la fecha de inscripci\u00f3n al formato deseado, usando la funci\u00f3n <code>FORMAT</code> para obtener el primer d\u00eda del mes en el campo <code>ID_FECHA_MENSUAL</code>.</li> <li>Extraer el a\u00f1o acad\u00e9mico mediante la funci\u00f3n <code>YEAR(im.[FECHA])</code>.</li> <li>Definir los campos <code>FECHA_INICIAL</code> y <code>FECHA_FINAL</code> a partir de la fecha de inscripci\u00f3n.</li> <li>Clasificar la inscripci\u00f3n en diferentes actividades mediante una estructura CASE:<ul> <li>Por ejemplo, \"Estudiante Inscrito\" o \"Estudiante con Proceso Desistido\" seg\u00fan el valor del campo <code>ESTADO</code>.</li> </ul> </li> <li>Asignar valores fijos para campos no aplicables en este contexto, como <code>ID_CURSO</code> e <code>ID_TIPO_ESTUDIANTE</code> (se asigna <code>-1</code>) y valores nulos para otros indicadores.</li> </ul> </li> <li> <p>Cargar:</p> <ul> <li>Insertar los datos transformados en la tabla de destino <code>[Transversal].[FACT_MINERIA]</code> mediante el componente <code>Destino de ADO NET</code>.</li> <li>La carga se realiza a trav\u00e9s de la conexi\u00f3n administrada <code>DWH_COMFENALCO</code>, garantizando la inserci\u00f3n correcta y el mapeo de las columnas.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion_13","title":"Implementaci\u00f3n","text":"<ol> <li>Consulta Inscripcion:<ul> <li>El componente <code>Consulta Inscripcion</code> ejecuta una consulta SQL que extrae datos de inscripci\u00f3n desde la tabla <code>[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]</code>.  </li> <li>La consulta se divide en varios bloques mediante <code>UNION ALL</code> para cubrir diferentes escenarios:<ul> <li>Afiliados: Registros donde se une con <code>[DIM_AFILIADOS]</code>.</li> <li>Beneficiarios: Registros donde se une con <code>[DIM_BENEFICIARIOS]</code> (con un <code>LEFT JOIN</code> a <code>[DIM_AFILIADOS]</code> para obtener informaci\u00f3n adicional).</li> <li>Empresas: Registros provenientes de empresas, utilizando <code>[DIM_EMPRESAS]</code>.</li> <li>No Aportante: Registros para los que la suma de los identificadores de afiliado, empresa y beneficiario es igual a -3.</li> </ul> </li> <li>La consulta transforma el campo <code>im.[FECHA]</code> mediante:<ul> <li><code>CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)</code> para obtener <code>ID_FECHA_MENSUAL</code>.</li> <li><code>YEAR(im.[FECHA])</code> para determinar el a\u00f1o acad\u00e9mico (<code>ID_ANIO_ACADEMICO</code>).</li> </ul> </li> <li>Se establecen valores fijos para ciertos campos, como <code>ID_CURSO</code> y <code>ID_TIPO_ESTUDIANTE</code>, asignados a <code>-1</code>.</li> <li>La columna <code>ACTIVIDAD</code> se determina mediante un <code>CASE</code>, asignando etiquetas basadas en el valor de <code>im.[ESTADO]</code> (por ejemplo, \"Estudiante Inscrito\" o \"Estudiante con Proceso Desistido\").</li> </ul> </li> </ol> <p>Fragmento del C\u00f3digo SQL Utilizado: <pre><code> -- Afiliados\nSELECT \n    a.[PARTNER] as BP,\n    CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL,\n    YEAR(im.[FECHA]) AS ID_ANIO_ACADEMICO,\n    j.[ID_UNIDAD],\n    im.[FECHA] AS FECHA_INICIAL,\n    im.[FECHA] AS FECHA_FINAL,\n    CASE\n        WHEN im.[ESTADO] = 'INSCRITO' THEN 'Estudiante Inscrito'\n        WHEN im.[ESTADO] = 'NO INSCRITO' THEN 'Estudiante con Proceso Desistido'\n        ELSE 'Sin Identificar'\n    END AS ACTIVIDAD,\n    0 AS TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    a.[ID_CATEGORIA],\n     -1 AS ID_CURSO,\n     -1 AS ID_TIPO_ESTUDIANTE,\n    im.[ID_PROGRAMA]\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] im\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e ON im.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a ON e.[ID_AFILIADO] = a.[ID_AFILIADO]\nINNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j ON im.[ID_JORNADA] = j.[ID_JORNADA]\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n    ON tm.[ID_FECHA] = CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)\nWHERE e.ID_AFILIADO != -1\n\nUNION ALL\n\n -- (Otros bloques UNION ALL para beneficiarios, empresas y no aportantes)\n</code></pre></p> <ol> <li>Destino de ADO NET:<ul> <li>El componente <code>Destino de ADO NET</code> recibe la salida del componente <code>Consulta Inscripcion</code>.</li> <li>Se configura para cargar los datos en la tabla <code>[Transversal].[FACT_MINERIA]</code> en el Data Warehouse.</li> <li>La conexi\u00f3n se establece mediante el Connection Manager <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_13","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>Package\\FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Inscripcion</code></li> <li>Tarea de Flujo de Datos: <code>Inscripcion</code></li> <li>Componentes Clave:<ul> <li>Consulta Inscripcion: Extrae y transforma los datos de inscripciones.</li> <li>Destino de ADO NET: Carga los datos transformados en la tabla de hechos de miner\u00eda.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_16","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Clasificaci\u00f3n y Segmentaci\u00f3n:</p> <ul> <li>La consulta segmenta los registros de inscripciones seg\u00fan el origen del estudiante (afiliado, beneficiario, empresa o no aportante) y asigna una etiqueta en la columna <code>ACTIVIDAD</code> para facilitar el an\u00e1lisis.</li> </ul> </li> <li> <p>Transformaci\u00f3n de Fechas:</p> <ul> <li>Se utiliza <code>FORMAT</code> y <code>CAST</code> para convertir la fecha de inscripci\u00f3n en <code>ID_FECHA_MENSUAL</code>, lo que permite relacionar el registro con la dimensi\u00f3n temporal.</li> <li>Los campos <code>FECHA_INICIAL</code> y <code>FECHA_FINAL</code> se asignan con el mismo valor de fecha, lo que indica la fecha de la inscripci\u00f3n.</li> </ul> </li> <li> <p>Valores Predeterminados:</p> <ul> <li>Se asignan valores fijos para campos no aplicables en este contexto, como <code>ID_CURSO</code> e <code>ID_TIPO_ESTUDIANTE</code>, establecidos en <code>-1</code>.</li> <li>Los campos <code>TIEMPO_SEGUNDOS</code> y <code>VALOR_PAGADO</code> se asignan a <code>0</code>, ya que para la inscripci\u00f3n estos valores no son relevantes.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#fact_mineriamineria_educacion_tecnica_y_continuaadmision","title":"<code>FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Admision</code>","text":"<p>El componente <code>Admision</code> es una tarea de flujo de datos (Data Flow Task) que forma parte del proceso ETL en el entorno de miner\u00eda, espec\u00edficamente dentro del m\u00f3dulo de educaci\u00f3n t\u00e9cnica y continua. Su funci\u00f3n es extraer, transformar y cargar informaci\u00f3n relativa a la admisi\u00f3n de estudiantes en programas educativos, consolidando datos provenientes de fuentes operacionales y de staging para su an\u00e1lisis en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"03.Cubo/03.ETL/#que-significa-admision-en-este-contexto","title":"\u00bfQu\u00e9 significa \"Admision\" en este contexto?","text":"<p>En este contexto, \"Admision\" se refiere al proceso mediante el cual se registran y validan los datos de admisi\u00f3n de estudiantes. Esto incluye informaci\u00f3n sobre: - Per\u00edodos acad\u00e9micos: Se extrae el a\u00f1o y el mes de matr\u00edcula para asociarlo con la dimensi\u00f3n temporal. - Identificadores de unidad: Se determina la unidad organizativa (por ejemplo, la escuela o centro educativo) que gestiona la admisi\u00f3n. - Fechas: Se establecen la fecha inicial y final de la admisi\u00f3n. - Actividad: Se clasifica la actividad de admisi\u00f3n, diferenciando por ejemplo entre \u201cEstudiante Admitido Nuevo\u201d y \u201cEstudiante Admitido Antiguo\u201d. - Tiempo de gesti\u00f3n: Se captura el tiempo (en segundos) invertido en el proceso de admisi\u00f3n, aunque en este caso se establece en cero, lo que puede indicar que el tiempo no es relevante para esta etapa o que se gestiona en otro proceso.</p>"},{"location":"03.Cubo/03.ETL/#proposito-del-componente_15","title":"Prop\u00f3sito del Componente","text":"<p>El componente <code>Admision</code> tiene como objetivos principales:</p> <ol> <li> <p>Extraer datos de admisi\u00f3n: </p> <ul> <li>Obtener informaci\u00f3n de las matr\u00edculas registradas en el sistema operativo, en este caso desde la tabla <code>[DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS]</code> y sus fuentes relacionadas, integrando datos de estudiantes, afiliados, beneficiarios y empresas.</li> </ul> </li> <li> <p>Transformar la informaci\u00f3n: </p> <ul> <li>Calcular el identificador del per\u00edodo (<code>ID_FECHA_MENSUAL</code>) a partir de la fecha de matr\u00edcula formateada (por ejemplo, utilizando <code>FORMAT</code> para obtener el primer d\u00eda del mes).</li> <li>Determinar el a\u00f1o acad\u00e9mico (<code>ID_ANIO_ACADEMICO</code>) y convertir las fechas de matr\u00edcula en campos de fecha tipo <code>datetime</code> para los campos <code>FECHA_INICIAL</code> y <code>FECHA_FINAL</code>.</li> <li>Clasificar el registro en funci\u00f3n de la procedencia (por ejemplo, \u201cEstudiante Admitido Nuevo\u201d o \u201cEstudiante Admitido Antiguo\u201d) seg\u00fan el valor del semestre.</li> <li>Incluir otros campos relevantes como <code>ID_CATEGORIA</code>, <code>ID_CURSO</code> y <code>ID_TIPO_ESTUDIANTE</code>, asignando valores fijos o provenientes de la fuente.</li> </ul> </li> <li> <p>Cargar la informaci\u00f3n en el Data Warehouse: </p> <ul> <li>Tras la transformaci\u00f3n, los datos se insertan en la tabla de destino <code>[Transversal].[FACT_MINERIA]</code> usando un componente de destino ADO NET, asegurando la consistencia y calidad de la informaci\u00f3n para posteriores an\u00e1lisis.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#ubicacion_14","title":"Ubicaci\u00f3n","text":"<ul> <li>Paquete SSIS: <code>Package\\FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA</code></li> <li>Tarea de Flujo de Datos: <code>Admision</code></li> <li>Componentes Principales:<ul> <li>Origen de ADO NET: Extrae los datos de admisi\u00f3n mediante una consulta SQL que integra registros de matr\u00edculas de estudiantes (afiliados, beneficiarios y empresas) y los transforma para obtener campos como el per\u00edodo acad\u00e9mico, fechas y actividad.</li> <li>Destino de ADO NET: Carga los datos transformados en la tabla <code>[Transversal].[FACT_MINERIA]</code> en el Data Warehouse.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_14","title":"Implementaci\u00f3n","text":"<ol> <li> <p>Fuente de Datos:</p> <ul> <li>Se utiliza el componente <code>Origen de ADO NET</code> para ejecutar una consulta SQL que extrae datos de admisi\u00f3n. La consulta:<ul> <li>Selecciona campos como <code>BP</code>, <code>ID_FECHA_MENSUAL</code>, <code>ID_ANIO_ACADEMICO</code>, <code>ID_UNIDAD</code>, <code>FECHA_INICIAL</code>, <code>FECHA_FINAL</code>, <code>ACTIVIDAD</code>, <code>TIEMPO_SEGUNDOS</code>, y otros indicadores.</li> <li>Utiliza funciones como <code>CAST</code> y <code>FORMAT</code> para transformar y normalizar las fechas. Por ejemplo, se calcula el <code>ID_FECHA_MENSUAL</code> a partir de la fecha de matr\u00edcula formateada como <code>yyyyMM01</code>.</li> <li>Diferencia la actividad de admisi\u00f3n bas\u00e1ndose en condiciones sobre el campo <code>SEMESTRE</code>, determinando si el estudiante es \"Admitido Nuevo\" o \"Admitido Antiguo\".</li> <li>Integra datos de distintas fuentes (afiliados, beneficiarios y empresas) mediante cl\u00e1usulas <code>UNION ALL</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n:</p> <ul> <li>Se transforma la fecha de matr\u00edcula para generar:<ul> <li><code>ID_FECHA_MENSUAL</code>: Un entero que representa el primer d\u00eda del mes del a\u00f1o acad\u00e9mico.</li> <li><code>FECHA_INICIAL</code> y <code>FECHA_FINAL</code>: Convertidos a tipo <code>datetime</code> para poder usarse en an\u00e1lisis temporales.</li> </ul> </li> <li>Se asigna un valor fijo de <code>1</code> a <code>ID_UNIDAD</code>, lo que puede representar la unidad organizativa correspondiente.</li> <li>Se clasifica la actividad de admisi\u00f3n mediante un <code>CASE</code> que eval\u00faa el campo <code>SEMESTRE</code>.</li> </ul> </li> <li> <p>Carga:</p> <ul> <li>El componente <code>Destino de ADO NET</code> recibe la salida del origen y la inserta en la tabla <code>[Transversal].[FACT_MINERIA]</code> usando la conexi\u00f3n administrada <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#logica-de-negocio_17","title":"L\u00f3gica de Negocio","text":"<ul> <li> <p>Integraci\u00f3n de Matr\u00edculas:   Se consolidan diferentes tipos de registros de admisi\u00f3n (por afiliados, beneficiarios y empresas) en una \u00fanica estructura, permitiendo analizar de manera integral la gesti\u00f3n de matr\u00edculas en el \u00e1mbito de la educaci\u00f3n t\u00e9cnica y continua en miner\u00eda.</p> </li> <li> <p>Conversi\u00f3n y Normalizaci\u00f3n de Fechas:   La conversi\u00f3n de la fecha de matr\u00edcula a un formato est\u00e1ndar (<code>ID_FECHA_MENSUAL</code>) permite la correcta integraci\u00f3n con la dimensi\u00f3n temporal del Data Warehouse, facilitando la generaci\u00f3n de reportes y an\u00e1lisis por per\u00edodos.</p> </li> <li> <p>Clasificaci\u00f3n de la Actividad:   La l\u00f3gica del <code>CASE</code> en la consulta SQL determina la etiqueta de la actividad de admisi\u00f3n, diferenciando entre \"Estudiante Admitido Nuevo\" y \"Estudiante Admitido Antiguo\", lo que permite analizar tendencias y desempe\u00f1o en la admisi\u00f3n.</p> </li> <li> <p>Aseguramiento de la Calidad de los Datos:   Las transformaciones y conversiones se realizan para garantizar que los datos sean consistentes, precisos y compatibles con la estructura de la tabla de destino.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#relacion-con-otros-componentes_17","title":"Relaci\u00f3n con Otros Componentes","text":"<ul> <li> <p>Integraci\u00f3n con la Dimensi\u00f3n Temporal:   La generaci\u00f3n del campo <code>ID_FECHA_MENSUAL</code> permite relacionar estos registros con la dimensi\u00f3n <code>DIM_TIEMPO_MENSUAL</code> para an\u00e1lisis temporales.</p> </li> <li> <p>Consolidaci\u00f3n en el Data Warehouse:   Los datos transformados se cargan en la tabla <code>[Transversal].[FACT_MINERIA]</code>, donde se integran con otras \u00e1reas del Data Warehouse para generar informes y an\u00e1lisis multidimensionales.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/#componente-fact_mineriamineria_educacion_tecnica_y_continuapago","title":"Componente <code>FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Pago</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente <code>Pago</code> es una tarea de flujo de datos (<code>Data Flow Task</code>) dentro del paquete SSIS <code>09-ETLS_CUBO</code>, ubicada en la jerarqu\u00eda <code>Package\\FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA</code>. Este componente est\u00e1 dise\u00f1ado para procesar y cargar datos relacionados con pagos en el contexto de educaci\u00f3n t\u00e9cnica y continua, integr\u00e1ndolos en la tabla de hechos <code>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]</code> del Data Warehouse <code>DWH_COMFENALCO</code>. Aunque no se proporciona el XML espec\u00edfico para esta tarea, su estructura y prop\u00f3sito pueden inferirse del contexto del paquete y de la documentaci\u00f3n previa.</p>"},{"location":"03.Cubo/03.ETL/#proposito_5","title":"Prop\u00f3sito","text":"<ol> <li>Procesamiento de Datos de Pagos:  <ul> <li>Extrae informaci\u00f3n de pagos desde una fuente de datos (probablemente una tabla operacional o intermedia), la transforma para ajustarla al modelo de datos de <code>FACT_MINERIA</code>, y la carga en el Data Warehouse.  </li> </ul> </li> <li>Integraci\u00f3n con Dimensiones:  <ul> <li>Vincula los datos de pagos con dimensiones relevantes como <code>DIM_TIEMPO_MENSUAL</code>, <code>DIM_AFILIADOS</code>, o <code>DIM_BENEFICIARIOS</code> para enriquecer el an\u00e1lisis.  </li> </ul> </li> <li>Soporte al An\u00e1lisis Educativo:  <ul> <li>Proporciona m\u00e9tricas financieras clave (como el valor pagado y tiempos asociados) para an\u00e1lisis de miner\u00eda de datos en el \u00e1mbito educativo.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_1","title":"Tablas Afectadas","text":"<ul> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]</code>:  <ul> <li>Tabla de hechos destino que almacena datos procesados de pagos relacionados con educaci\u00f3n t\u00e9cnica y continua.  </li> </ul> </li> <li>Fuentes Potenciales (Inferidas):  <ul> <li>Una tabla operacional o intermedia que contiene datos de pagos (e.g., <code>FACT_PAGOS</code> o similar).  </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]</code>: Dimensi\u00f3n temporal para vincular fechas.  </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS]</code>: Dimensi\u00f3n de afiliados.  </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS]</code>: Dimensi\u00f3n de beneficiarios (si aplica).</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_15","title":"Implementaci\u00f3n","text":"<p>Dado que no se proporciona el XML espec\u00edfico para <code>Pago</code>, la implementaci\u00f3n se deduce del patr\u00f3n observado en tareas similares (como <code>PQRs</code>), ajustada al contexto de procesamiento de pagos:</p> <p>Estructura del Flujo de Datos (Inferida): 1. Origen de ADO NET:       - Descripci\u00f3n: Extrae datos de pagos desde una fuente, probablemente una tabla como <code>FACT_PAGOS</code> o una consulta que combine datos financieros y educativos.       - Consulta SQL: <pre><code>SELECT \n    a.[PARTNER] AS BP,\n    CONVERT(INT, LEFT(CAST(p.FECHA_PAGO AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n    CONVERT(INT, LEFT(CAST(p.FECHA_PAGO AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n    p.[ID_UNIDAD],\n    p.[FECHA_PAGO] AS FECHA_INICIAL,\n    p.[FECHA_PAGO] AS FECHA_FINAL,\n    'PAGO CURSO' AS ACTIVIDAD,\n    0 AS TIEMPO_SEGUNDOS,\n    p.[VALOR_PAGADO],\n    a.[ID_CATEGORIA],\n    p.[ID_CURSO],\n    p.[ID_TIPO_ESTUDIANTE]\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PAGOS] p\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n    ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(p.FECHA_PAGO AS VARCHAR), 6) + '01')\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n    ON p.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE p.ID_UNIDAD IN (2, 3) AND p.VALOR_PAGADO &gt; 0\n</code></pre>       - Conexi\u00f3n: Usa el administrador de conexiones <code>DWH_COMFENALCO</code>.       - Propiedades:         - <code>CommandTimeout</code>: 30 segundos (t\u00edpico).         - <code>AccessMode</code>: 2 (SQL Command).  </p> <ol> <li> <p>Lookup (Opcional):  </p> <ul> <li>Descripci\u00f3n: Podr\u00eda realizar una b\u00fasqueda en <code>FACT_MINERIA</code> para verificar duplicados o enriquecer datos usando una clave como <code>BP</code> o <code>ID_CURSO</code>.  </li> <li>Consulta SQL (Ejemplo): <pre><code>SELECT * FROM [Transversal].[FACT_MINERIA] WHERE [BP] = ?\n</code></pre></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_OLEDB</code>.  </li> <li>Propiedades:  <ul> <li><code>NoMatchBehavior</code>: 1 (enviar filas sin coincidencia a una salida espec\u00edfica).  </li> <li><code>CacheType</code>: 0 (sin cach\u00e9).  </li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET:  </p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en <code>FACT_MINERIA</code>.  </li> <li>Tabla Destino: <code>[Transversal].[FACT_MINERIA]</code>.  </li> <li>Columnas Mapeadas (Inferidas):  <ul> <li><code>BP</code> (wstr, 20): Identificador del afiliado o beneficiario.  </li> <li><code>ID_FECHA_MENSUAL</code> (i4): Fecha mensual derivada.  </li> <li><code>ID_ANIO_ACADEMICO</code> (i4): A\u00f1o acad\u00e9mico.  </li> <li><code>ID_UNIDAD</code> (i4): Unidad operativa.  </li> <li><code>FECHA_INICIAL</code> (dbTimeStamp): Fecha del pago.  </li> <li><code>FECHA_FINAL</code> (dbTimeStamp): Igual a inicial (sin duraci\u00f3n).  </li> <li><code>ACTIVIDAD</code> (wstr, 100): \"PAGO CURSO\" o similar.  </li> <li><code>TIEMPO_SEGUNDOS</code> (i4): 0 (sin tiempo asociado).  </li> <li><code>VALOR_PAGADO</code> (i4): Monto del pago.  </li> <li><code>ID_CATEGORIA</code> (i4): Categor\u00eda del afiliado.  </li> <li><code>ID_CURSO</code> (i4): Identificador del curso.  </li> <li><code>ID_TIPO_ESTUDIANTE</code> (i4): Tipo de estudiante.  </li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Propiedades:  <ul> <li><code>BatchSize</code>: 0 (tama\u00f1o de b\u00fafer interno).  </li> <li><code>CommandTimeout</code>: 30 segundos.  </li> <li><code>UseBulkInsertWhenPossible</code>: True.</li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#configuracion-en-el-xml-inferida","title":"Configuraci\u00f3n en el XML (Inferida)","text":"<p>Basado en el patr\u00f3n de <code>PQRs</code>, la configuraci\u00f3n aproximada ser\u00eda:</p> <pre><code>&lt;ns0:Executable xmlns:ns0=\"www.microsoft.com/SqlServer/Dts\" \n    ns0:refId=\"Package\\FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\Pago\" \n    ns0:CreationName=\"Microsoft.Pipeline\" \n    ns0:Description=\"Data Flow Task\" \n    ns0:DTSID=\"{UNIQUE-GUID}\" \n    ns0:ExecutableType=\"Microsoft.Pipeline\" \n    ns0:ObjectName=\"Pago\"&gt;\n    &lt;ns0:ObjectData&gt;\n        &lt;pipeline&gt;\n            &lt;components&gt;\n                &lt;component refId=\"Origen de ADO NET\" componentClassID=\"Microsoft.ManagedComponentHost\" name=\"Origen de ADO NET\" /&gt;\n                &lt;component refId=\"Destino de ADO NET\" componentClassID=\"Microsoft.ManagedComponentHost\" name=\"Destino de ADO NET\" /&gt;\n            &lt;/components&gt;\n            &lt;paths&gt;\n                &lt;path refId=\"Salida de origen\" startId=\"Origen de ADO NET.Outputs[Salida de origen]\" endId=\"Destino de ADO NET.Inputs[Entrada de destino]\" /&gt;\n            &lt;/paths&gt;\n        &lt;/pipeline&gt;\n    &lt;/ns0:ObjectData&gt;\n&lt;/ns0:Executable&gt;\n</code></pre> <ul> <li>DTSID: Un GUID \u00fanico (e.g., <code>{12345678-ABCD-1234-5678-1234567890AB}</code>).  </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code> para origen y destino.</li> </ul>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Paquete SSIS\n    participant Origen as Origen ADO NET\n    participant Destino as Destino ADO NET\n    participant SQLServer as Servidor SQL\n    SSIS -&gt;&gt; Origen: Ejecutar extracci\u00f3n\n    Origen -&gt;&gt; SQLServer: SELECT desde FACT_PAGOS\n    SQLServer --&gt;&gt; Origen: Datos extra\u00eddos\n    Origen -&gt;&gt; Destino: Enviar datos transformados\n    Destino -&gt;&gt; SQLServer: Cargar en FACT_MINERIA\n    SQLServer --&gt;&gt; Destino: Confirmaci\u00f3n\n    Destino --&gt;&gt; SSIS: Finalizar tarea</code></pre>"},{"location":"03.Cubo/03.ETL/#contexto-dentro-del-paquete-ssis_1","title":"Contexto dentro del Paquete SSIS","text":"<p>El componente <code>Pago</code> forma parte del procesamiento de la tabla <code>FACT_MINERIA</code> bajo el contenedor <code>MINERIA_EDUCACION_TECNICA_Y_CONTINUA</code>. Se ejecuta despu\u00e9s de tareas preparatorias como <code>Truncar Tablas Cubo</code> y junto a otras tareas como <code>PQRs</code>, contribuyendo a la integraci\u00f3n de datos financieros y educativos en el Data Warehouse. Su prop\u00f3sito es asegurar que los datos de pagos se alineen con el modelo dimensional para an\u00e1lisis de miner\u00eda de datos.</p>"},{"location":"03.Cubo/03.ETL/#componente-packagefact_mineriamineria_educacion_tecnica_y_continuapqrs","title":"Componente <code>Package\\FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA\\PQRs</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente <code>PQRs</code> es una tarea de flujo de datos (<code>Data Flow Task</code>) dentro del paquete SSIS <code>09-ETLS_CUBO</code>, ubicada en la jerarqu\u00eda <code>Package\\FACT_MINERIA\\MINERIA_EDUCACION_TECNICA_Y_CONTINUA</code>. Este componente est\u00e1 dise\u00f1ado para extraer, transformar y cargar datos relacionados con PQRs (Peticiones, Quejas y Reclamos) en el \u00e1mbito de educaci\u00f3n t\u00e9cnica y continua, integr\u00e1ndolos en la tabla de hechos <code>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]</code> del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"03.Cubo/03.ETL/#proposito_6","title":"Prop\u00f3sito","text":"<ol> <li>Procesamiento de Datos de PQRs:  <ul> <li>Extrae informaci\u00f3n de PQRs desde la tabla <code>FACT_PQRS</code>, la transforma para ajustarla al modelo de datos de <code>FACT_MINERIA</code>, y la carga en el Data Warehouse.  </li> </ul> </li> <li>Integraci\u00f3n con Dimensiones:  <ul> <li>Enlaza los datos con dimensiones como <code>DIM_TIEMPO_MENSUAL</code>, <code>DIM_AFILIADOS</code>, y <code>DIM_BENEFICIARIOS</code> para enriquecer el an\u00e1lisis.  </li> </ul> </li> <li>Soporte al An\u00e1lisis Educativo:  <ul> <li>Proporciona m\u00e9tricas clave (como tiempo de resoluci\u00f3n y categor\u00edas) para an\u00e1lisis de miner\u00eda de datos en el contexto educativo.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_2","title":"Tablas Afectadas","text":"<ul> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]</code>:  <ul> <li>Tabla de hechos destino que almacena datos procesados de PQRs relacionados con educaci\u00f3n t\u00e9cnica y continua.  </li> </ul> </li> <li>Fuentes de Datos:  <ul> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_PQRS]</code>: Tabla de hechos origen con informaci\u00f3n cruda de PQRs.  </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]</code>: Dimensi\u00f3n temporal para vincular fechas.  </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS]</code>: Dimensi\u00f3n de afiliados.  </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS]</code>: Dimensi\u00f3n de beneficiarios.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#implementacion_16","title":"Implementaci\u00f3n","text":"<p>Estructura del Flujo de Datos: El componente <code>PQRs</code> es un <code>Data Flow Task</code> (identificado por <code>Microsoft.Pipeline</code>) que incluye tres subcomponentes principales:</p> <ol> <li> <p>Origen de ADO NET:  </p> <ul> <li>Descripci\u00f3n: Extrae datos de PQRs desde <code>FACT_PQRS</code> con uniones a dimensiones relevantes.  </li> <li>Consulta SQL: <pre><code>SELECT \n    a.[PARTNER] as BP,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n    [ID_UNIDAD],\n    [FECHA_CREACION] AS FECHA_INICIAL,\n    [FECHA_RESOLUCION] AS FECHA_FINAL,\n    CONCAT('PQR ', LOWER([CAUSA])) AS ACTIVIDAD,\n    DATEDIFF(SECOND, [FECHA_CREACION], [FECHA_RESOLUCION]) AS TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    [ID_CATEGORIA],\n     -1 AS ID_CURSO,\n     -1 AS ID_TIPO_ESTUDIANTE\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] f\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n    ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01')\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n    ON f.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE f.ID_AFILIADO != -1 AND ID_UNIDAD IN (2,3)\n\nUNION ALL\nSELECT \n    b.[PARTNER] as BP,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n    [ID_UNIDAD],\n    [FECHA_CREACION] AS FECHA_INICIAL,\n    [FECHA_RESOLUCION] AS FECHA_FINAL,\n    CONCAT('PQR ', LOWER([CAUSA])) AS ACTIVIDAD,\n    DATEDIFF(SECOND, [FECHA_CREACION], [FECHA_RESOLUCION]) AS TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    ISNULL(a.[ID_CATEGORIA], 4) AS ID_CATEGORIA,\n     -1 AS ID_CURSO,\n     -1 AS ID_TIPO_ESTUDIANTE\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] f\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n    ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01')\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b \n    ON f.[ID_BENEFICIARIO] = b.[ID_BENEFICIARIO]\nLEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n    ON b.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE f.ID_BENEFICIARIO != -1 AND ID_UNIDAD IN (2,3)\n</code></pre></li> <li>Conexi\u00f3n: Usa el administrador de conexiones <code>DWH_COMFENALCO</code>.  </li> <li>Propiedades:  <ul> <li><code>CommandTimeout</code>: 30 segundos.  </li> <li><code>AccessMode</code>: 2 (SQL Command).  </li> </ul> </li> </ul> </li> <li> <p>Lookup:  </p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en <code>FACT_MINERIA</code> para verificar o enriquecer datos usando la columna <code>BP</code> como clave de uni\u00f3n.  </li> <li>Consulta SQL: <pre><code>SELECT * FROM [Transversal].[FACT_MINERIA] WHERE [BP] = ?\n</code></pre></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_OLEDB</code>.  </li> <li>Propiedades:  <ul> <li><code>NoMatchBehavior</code>: 1 (enviar filas sin coincidencia a una salida espec\u00edfica).  </li> <li><code>CacheType</code>: 0 (sin cach\u00e9).  </li> <li><code>ParameterMap</code>: Vincula la columna <code>BP</code> del origen como par\u00e1metro.  </li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET:  </p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en <code>FACT_MINERIA</code>.  </li> <li>Tabla Destino: <code>[Transversal].[FACT_MINERIA]</code>.  </li> <li>Columnas Mapeadas:  <ul> <li><code>BP</code> (wstr, 20)  </li> <li><code>ID_FECHA_MENSUAL</code> (i4)  </li> <li><code>ID_ANIO_ACADEMICO</code> (i4)  </li> <li><code>ID_UNIDAD</code> (i4)  </li> <li><code>FECHA_INICIAL</code> (dbTimeStamp)  </li> <li><code>FECHA_FINAL</code> (dbTimeStamp)  </li> <li><code>ACTIVIDAD</code> (wstr, 100)  </li> <li><code>TIEMPO_SEGUNDOS</code> (i4)  </li> <li><code>VALOR_PAGADO</code> (i4)  </li> <li><code>ID_CATEGORIA</code> (i4)  </li> <li><code>ID_CURSO</code> (i4)  </li> <li><code>ID_TIPO_ESTUDIANTE</code> (i4)  </li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Propiedades:  <ul> <li><code>BatchSize</code>: 0 (tama\u00f1o de b\u00fafer interno).  </li> <li><code>CommandTimeout</code>: 30 segundos.  </li> <li><code>UseBulkInsertWhenPossible</code>: True (usa inserci\u00f3n masiva si es compatible).  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#configuracion-en-el-xml_1","title":"Configuraci\u00f3n en el XML","text":"<ul> <li>Identificador: <code>DTSID=\"{58954d94-e22d-4d6e-acaa-93f8f254511b}\"</code>.  </li> <li>Tipo: <code>Microsoft.Pipeline</code>.  </li> <li>Nombre: <code>PQRs</code>.  </li> <li>Descripci\u00f3n: \"Data Flow Task\".  </li> <li>Estructura: Incluye los componentes <code>Origen de ADO NET</code>, <code>Lookup</code>, y <code>Destino de ADO NET</code>, conectados mediante caminos de datos (<code>paths</code>).</li> </ul>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Paquete SSIS\n    participant Origen as Origen ADO NET\n    participant Lookup as Lookup\n    participant Destino as Destino ADO NET\n    participant SQLServer as Servidor SQL\n    SSIS -&gt;&gt; Origen: Ejecutar extracci\u00f3n\n    Origen -&gt;&gt; SQLServer: SELECT desde FACT_PQRS\n    SQLServer --&gt;&gt; Origen: Datos extra\u00eddos\n    Origen -&gt;&gt; Lookup: Enviar datos (BP como clave)\n    Lookup -&gt;&gt; SQLServer: SELECT * FROM FACT_MINERIA WHERE BP = ?\n    SQLServer --&gt;&gt; Lookup: Resultados de b\u00fasqueda\n    Lookup -&gt;&gt; Destino: Enviar filas coincidentes\n    Destino -&gt;&gt; SQLServer: Cargar en FACT_MINERIA\n    SQLServer --&gt;&gt; Destino: Confirmaci\u00f3n\n    Destino --&gt;&gt; SSIS: Finalizar tarea</code></pre>"},{"location":"03.Cubo/03.ETL/#contexto-dentro-del-paquete-ssis_2","title":"Contexto dentro del Paquete SSIS","text":"<p>El componente <code>PQRs</code> forma parte del procesamiento de la tabla <code>FACT_MINERIA</code> dentro del paquete <code>09-ETLS_CUBO</code>, espec\u00edficamente bajo el contenedor <code>MINERIA_EDUCACION_TECNICA_Y_CONTINUA</code>. Se ejecuta tras tareas preparatorias como <code>Truncar Tablas Cubo</code> y contribuye a la integraci\u00f3n de datos para an\u00e1lisis de miner\u00eda en educaci\u00f3n t\u00e9cnica y continua. Su dise\u00f1o asegura que los datos de PQRs se alineen con el modelo dimensional del Data Warehouse.</p>"},{"location":"04.sharepoint/00.Introduccion/","title":"00.Introduccion","text":""},{"location":"04.sharepoint/00.Introduccion/#introduccion","title":"Introducci\u00f3n","text":""},{"location":"04.sharepoint/estructura_archivos_actualizacion/","title":"Estructura Archivos Actualizacion","text":""},{"location":"04.sharepoint/estructura_archivos_actualizacion/#sharepoint-detalle-actualizacion-archivos","title":"Sharepoint (Detalle actualizaci\u00f3n Archivos)","text":""},{"location":"04.sharepoint/estructura_archivos_actualizacion/#introduccion","title":"Introducci\u00f3n","text":"<p>La siguiente estructura detallada de los archivos organizados en SharePoint para la gesti\u00f3n de documentos relacionados con Comfenalco. Este esquema est\u00e1 dise\u00f1ado para facilitar el acceso, la actualizaci\u00f3n y el mantenimiento de los datos esenciales, asegurando que las responsabilidades y las frecuencias de actualizaci\u00f3n est\u00e9n claramente definidas.</p>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#proposito-del-documento","title":"Prop\u00f3sito del Documento","text":"<p>El prop\u00f3sito principal es servir como una gu\u00eda de referencia para:</p> <ol> <li>Ubicaci\u00f3n de Archivos: Identificar r\u00e1pidamente la ubicaci\u00f3n de cada archivo en SharePoint.</li> <li>Frecuencia de Actualizaci\u00f3n: Detallar la periodicidad con la que los archivos deben ser actualizados para mantener la informaci\u00f3n al d\u00eda.</li> <li>Responsables: Asignar claramente las responsabilidades para el mantenimiento de cada archivo.</li> <li>Observaciones Espec\u00edficas: Incluir notas relevantes, como la nomenclatura para los a\u00f1os o dependencias de terceros, para garantizar un correcto entendimiento de cada archivo.</li> </ol>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#estructura-del-documento","title":"Estructura del Documento","text":"<ol> <li>03.Archivos_Manuales:</li> <li> <p>Contiene subcarpetas que agrupan documentos seleccionados, estructuras propuestas y otros archivos categorizados en \u00e1reas como Transversal, Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica y Continua, y Protecci\u00f3n Social.</p> </li> <li> <p>Detalles por Archivo:</p> </li> <li>Cada archivo cuenta con la siguiente informaci\u00f3n:<ul> <li>Nombre del Archivo: Identificaci\u00f3n \u00fanica del documento.</li> <li>Ubicaci\u00f3n: Ruta exacta en SharePoint.</li> <li>Unidad: \u00c1rea responsable o relacionada con el contenido del archivo.</li> <li>Frecuencia de Actualizaci\u00f3n: Intervalo en el que debe ser revisado o actualizado.</li> <li>Responsable: Personas o equipos encargados del mantenimiento del documento.</li> <li>Observaciones: Detalles adicionales relevantes, como la estructura del nombre o el prop\u00f3sito del archivo.</li> </ul> </li> </ol>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#ejemplo-de-uso","title":"Ejemplo de Uso","text":"<ul> <li>Archivo: <code>AM-TRA-08.xlsx</code></li> <li>Ubicaci\u00f3n: <code>03.Archivos_Manuales/01.Archivos_Seleccionados/01.Transversal/01.Dim_Servicios</code></li> <li>Frecuencia de Actualizaci\u00f3n: Anual.</li> <li>Responsable: Planeaci\u00f3n y Presupuesto.</li> <li>Observaci\u00f3n: Archivos que incluyen un a\u00f1o en el nombre, por ejemplo, <code>AM-TRA-08_2024.xlsx</code>.</li> </ul>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#beneficios-del-documento","title":"Beneficios del Documento","text":"<ol> <li>Estandarizaci\u00f3n: Facilita el acceso y evita duplicaci\u00f3n o errores en la gesti\u00f3n documental.</li> <li>Claridad: Define roles y frecuencias, lo que asegura la actualizaci\u00f3n constante de los datos.</li> <li>Escalabilidad: Permite integrar nuevos archivos sin perder la organizaci\u00f3n.</li> </ol>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#actualizacion-de-archivos","title":"Actualizaci\u00f3n de archivos","text":"03.Archivos_Manuales 01.Archivos_Seleccionados 01.Transversal 01.Dim_Servicios <ul> <li>Archivo: AM-TRA-08.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/01.Archivos_Seleccionados/01.Transversal/01.Dim_Servicios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 02.Educacion_Formal 01.Dim_Libros <ul> <li>Archivo: AM-EDF-153.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/01.Archivos_Seleccionados/02.Educacion_Formal/01.Dim_Libros</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE BIBLIOTECA/AUXILIAR DE BIBLIOTECA Observaciones: Sin observaciones.</li> </ul> 02.Estructuras_Propuestas 01.Transversal 01.Dim_Servicios <ul> <li>Archivo: EP-TRA-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/01.Transversal/01.Dim_Servicios</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n; Planeaci\u00f3n y Presupuesto Observaciones: Sin observaciones.</li> </ul> 02.Dim_Capacidad_Fisica <ul> <li>Archivo: EP-TRA-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/01.Transversal/02.Dim_Capacidad_Fisica</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Sin observaciones.</li> </ul> 02.Educacion_Formal 01.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/01.DIM_PERSONAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 02.FACT_AUSENTISMO_DOCENTE <ul> <li>Archivo: EP-EDF-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/02.FACT_AUSENTISMO_DOCENTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORD. ACAD\u00c9MICAS Observaciones: Sin observaciones.</li> </ul> 03.FACT_BIBLIOTECA <ul> <li>Archivo: EP-EDF-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/03.FACT_BIBLIOTECA</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE BIBLIOTECA/AUXILIAR DE BIBLIOTECA Observaciones: Sin observaciones.</li> </ul> 04.FACT_BIBLIOTECA_VIRTUAL <ul> <li>Archivo: EP-EDF-06.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/04.FACT_BIBLIOTECA_VIRTUAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE BIBLIOTECA/AUXILIAR DE BIBLIOTECA Observaciones: Sin observaciones.</li> </ul> 05.FACT_DESEMPENHO_DOCENTE <ul> <li>Archivo: EP-EDF-09.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/05.FACT_DESEMPENHO_DOCENTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 06.FACT_ENFERMERIA <ul> <li>Archivo: EP-EDF-01.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/06.FACT_ENFERMERIA</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Enfermera Observaciones: Sin observaciones.</li> </ul> 07.FACT_LEGALIZACION <ul> <li>Archivo: EP-EDF-10.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/07.FACT_LEGALIZACION</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ANALISTA DE RECURSOS TECNOL\u00d3GICOS Observaciones: Sin observaciones.</li> </ul> 08.FACT_PERMISO_ESTUDIANTE <ul> <li>Archivo: EP-EDF-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/08.FACT_PERMISO_ESTUDIANTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 09.FACT_PSIORIENTACION <ul> <li>Archivo: EP-EDF-11.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/09.FACT_PSIORIENTACION</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADOR DE PSICOLOG\u00cdA Observaciones: Sin observaciones.</li> </ul> 10.FACT_REEMPLAZO_DOCENTE <ul> <li>Archivo: EP-EDF-03.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/10.FACT_REEMPLAZO_DOCENTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORD. ACAD\u00c9MICAS Observaciones: Sin observaciones.</li> </ul> 11.FACT_RESERVA_ESPACIOS <ul> <li>Archivo: EP-EDF-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/11.FACT_RESERVA_ESPACIOS</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: ANALISTA DE RECURSOS F\u00cdSICOS Y ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 12.FACT_SABER11_COLEGIOS <ul> <li>Archivo: EP-EDF-08.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/12.FACT_SABER11_COLEGIOS</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 13.FACT_SABER11_INDIVIDUAL <ul> <li>Archivo: EP-EDF-07.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/13.FACT_SABER11_INDIVIDUAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 14.FACT_SERVICIO_SOCIAL <ul> <li>Archivo: EP-EDF-13.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/14.FACT_SERVICIO_SOCIAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ASISTENTE ACAD\u00c9MICO BSMA Observaciones: Sin observaciones.</li> </ul> 03.Educacion_Tecnica 01.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/03.Educacion_Tecnica/01.DIM_PERSONAL</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 04.Educacion_Continua 01.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/04.Educacion_Continua/01.DIM_PERSONAL</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 05.Proteccion_Social 01.Caracterizacion AM-PRS-03 <ul> <li>Archivo: AM-PRS-03.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-03</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI y JEC. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> AM-PRS-10 <ul> <li>Archivo: AM-PRS-10.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-10</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para Adulto Mayor. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-102 <ul> <li>Archivo: AM-PRS-102.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-102</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Trimestral Responsable del Documento: Analista de protecci\u00f3n social Observaciones: Sin observaciones.</li> </ul> AM-PRS-11 <ul> <li>Archivo: AM-PRS-11.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-11</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para Discapacidad. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-12 <ul> <li>Archivo: AM-PRS-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-12</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para JEC. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-120 <ul> <li>Archivo: AM-PRS-120.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-120</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Analista de protecci\u00f3n social Observaciones: Sin observaciones.</li> </ul> AM-PRS-13 <ul> <li>Archivo: AM-PRS-13.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-13</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-145 <ul> <li>Archivo: AM-PRS-145.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-145</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI.</li> </ul> AM-PRS-145_CATEGORICAS <ul> <li>Archivo: AM-PRS-145_CATEGORICAS.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-145_CATEGORICAS</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: A demanda Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI.</li> </ul> AM-PRS-23 <ul> <li>Archivo: AM-PRS-23.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-23</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADORA DE PROGRAMA \u2013 AUXILIAR DE DEPARTAMENTO DE PROTECCI\u00d3N SOCIAL Observaciones: Sin observaciones.</li> </ul> AM-PRS-41 <ul> <li>Archivo: AM-PRS-41.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-41</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: AUXILIAR DE DEPARTAMENTO DE PROTECCI\u00d3N SOCIAL Observaciones: Sin observaciones.</li> </ul> AM-PRS-81 <ul> <li>Archivo: AM-PRS-81.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-81</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE PROGRAMA Observaciones: Para AIPI.</li> </ul> AM-PRS-91 <ul> <li>Archivo: AM-PRS-91.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-91</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADOR DE PROGRAMA Observaciones: Para JEC.</li> </ul> AM-PRS-91_CATEGORICAS <ul> <li>Archivo: AM-PRS-91_CATEGORICAS.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-91_CATEGORICAS</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADOR DE PROGRAMA Observaciones: Para JEC.</li> </ul> DIM_PROGRAMA <ul> <li>Archivo: ID_PROGRAMA.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/DIM_PROGRAMA</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: A demanda Responsable del Documento: Analista de protecci\u00f3n social Observaciones: Sin observaciones.</li> </ul> EP-PRS-02 <ul> <li>Archivo: EP-PSR-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PRS-02</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Sin observaciones.</li> </ul> EP-PRS-03 <ul> <li>Archivo: EP-PSR-03.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PRS-03</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Sin observaciones.</li> </ul> EP-PSR-01 <ul> <li>Archivo: EP-PSR-01.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PSR-01</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI.</li> </ul> EP-TRA-02 <ul> <li>Archivo: EP-TRA-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-TRA-02</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n Observaciones: Sin observaciones.</li> </ul> NSU/CEC <ul> <li>Archivo: CEC (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: CEC.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Cedesarrollo convenios <ul> <li>Archivo: campanas comfenalcoconvenios (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Convenios (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Convenios.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Consultorias <ul> <li>Archivo: campanas comfenalcoconsultorias (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Consultorias (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Consultorias.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Cursos y diplomados <ul> <li>Archivo: campanas comfenalcodiplomados (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Cursos y diplomados (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Cursos y diplomados.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Egresados <ul> <li>Archivo: comfenalcocedesarrolloegresados (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Egresado (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Egresado.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Estudiantes Activos <ul> <li>Archivo: base1.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base1Activos1.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base2.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base2Activos0.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base3.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base4.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base5.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Estudiantes Activos (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Estudiantes Activos.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Proteccion social <ul> <li>Archivo: campanas comfenalcoproteccion(2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoproteccion(3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoproteccion(4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoproteccion(5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Proteccion social (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Proteccion social.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> 02.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/02.DIM_PERSONAL</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 03.Otros_Archivos <ul> <li>Archivo: AM-DRE-05_08_12_2024.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: AUXILIAR ADMINISTRATIVO/ANALISTAS DE SERVICIO EMPRESARIAL/ANALISTA DE FOMENTO EMPRESARIAL Observaciones: Sin observaciones.</li> <li>Archivo: AM-DRE-16.xls Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: PERSONAL EXPERTO/ANALISTA DE FOMENTO EMPRESARIAL/ANALISTA DE SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: AM-EPT-47.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: COORDINADOR DE SERVICIOS TECNOL\u00d3GICOS Observaciones: Sin observaciones.</li> <li>Archivo: EP-EDF-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EDF-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EDF-09.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EDF-09_01_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: COORDINADOR DE SERVICIOS TECNOL\u00d3GICOS Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: PERSONAL EXPERTO/ANALISTA DE FOMENTO EMPRESARIAL/ANALISTA DE SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-06.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-06_10_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-06_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-07.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-07_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-08.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: ANALISTA SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-08_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: ANALISTA SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-09.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-10.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ANALISTA DE SERVICIOS EMPRESARIALES/ANALISTA DE FOMENTO EMPRESARIAL Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-10_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ANALISTA DE SERVICIOS EMPRESARIALES/ANALISTA DE FOMENTO EMPRESARIAL Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-11.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: A demanda Responsable del Documento: PERSONAL EXPERTO/ANALISTA DE FOMENTO EMPRESARIAL/ANALISTA DE SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> </ul> <p>```</p>"},{"location":"04.sharepoint/estructura_sharepoint/","title":"Estructura carpeta Sharepoint","text":""},{"location":"04.sharepoint/estructura_sharepoint/#sharepoint-configuracion-y-estructura","title":"Sharepoint (Configuraci\u00f3n y Estructura)","text":""},{"location":"04.sharepoint/estructura_sharepoint/#introduccion","title":"Introducci\u00f3n","text":"<p>La integraci\u00f3n de SharePoint con los procesos ETL (Extract, Transform, Load) garantiza una gesti\u00f3n centralizada, accesible y segura de los datos capturados mediante t\u00e9cnicas avanzadas de webscraping. Este enfoque permite organizar, almacenar y compartir informaci\u00f3n acad\u00e9mica y administrativa de manera eficiente, asegurando que los equipos involucrados puedan acceder a datos actualizados y estructurados.</p> <p>En el \u00e1mbito de la Educaci\u00f3n T\u00e9cnica y Continua, SharePoint se convierte en una herramienta clave para el manejo de los datos procesados, facilitando la colaboraci\u00f3n entre m\u00faltiples actores y plataformas. La implementaci\u00f3n de una estructura bien definida de carpetas y permisos asegura que los flujos de trabajo sean consistentes y escalables.</p>"},{"location":"04.sharepoint/estructura_sharepoint/#principales-caracteristicas-de-la-configuracion","title":"Principales Caracter\u00edsticas de la Configuraci\u00f3n","text":"<ol> <li>Creaci\u00f3n del Sitio del Proyecto:    El sitio COMFENALCO_EDUCACION act\u00faa como el repositorio principal de los datos extra\u00eddos, procesados y consolidados.</li> <li> <p>Estructuraci\u00f3n de Carpetas:  </p> <ul> <li>Las carpetas est\u00e1n organizadas en niveles jer\u00e1rquicos, categorizando los datos seg\u00fan su origen y prop\u00f3sito.</li> <li>Subcarpetas espec\u00edficas almacenan datos procesados y sin procesar, lo que permite un control preciso de las versiones y una f\u00e1cil recuperaci\u00f3n de informaci\u00f3n.</li> </ul> </li> <li> <p>Autenticaci\u00f3n Segura mediante Azure:  </p> <ul> <li>Registro de una aplicaci\u00f3n en Azure para la autenticaci\u00f3n de SharePoint.</li> <li>Uso de un cliente secreto y certificados para garantizar un acceso seguro a los datos.</li> </ul> </li> <li> <p>Gesti\u00f3n de Permisos:  </p> <ul> <li>Configuraci\u00f3n de permisos espec\u00edficos para aplicaciones como <code>Sites.FullControl.All</code> y <code>TermStore.Read.All</code>.</li> <li>Garant\u00eda de que solo usuarios autorizados puedan acceder y modificar la informaci\u00f3n almacenada.</li> </ul> </li> <li> <p>Automatizaci\u00f3n con Python:  </p> <ul> <li>El c\u00f3digo <code>SharePoint_Connection.py</code> permite interactuar directamente con las carpetas y archivos de SharePoint, automatizando procesos como la carga y extracci\u00f3n de datos.</li> </ul> </li> </ol>"},{"location":"04.sharepoint/estructura_sharepoint/#metodologia-para-configuracion-sharepoint-online-para-web-scrapping-y-ssis","title":"Metodolog\u00eda para Configuraci\u00f3n Sharepoint Online para Web Scrapping y SSIS","text":"<ol> <li>Crear en SharePoint el sitio del proyecto (<code>COMFENALCO_EDUCACION</code>)</li> <li> <p>En la parte de documentos crear las carpetas necesarias</p> <p></p> </li> <li> <p>En <code>Azure</code> ir a <code>Registro de Aplicaciones</code></p> </li> <li>Crear una nueva aplicaci\u00f3n.</li> <li>Asignarle un cliente secreto y copiar y guardar el <code>secret_client</code> que se genera. Solo se puede ver en este momento.</li> <li> <p>Subir un certificado. En la carpeta donde se vaya a crear la ETL de Web Scraping correr el siguiente comando y subir el archivo generado.     </p> <p>Observaciones</p> <ul> <li>Puede ser necesario instalar <code>OpenSSL</code> en Windows. Gu\u00eda para instalar <code>https://www.youtube.com/watch?v=coaGBdUcKiw</code></li> <li>Se puede tomar como referencia el siguiente video <code>https://www.youtube.com/watch?v=KWKiwpK-L5o</code></li> </ul> </li> <li> <p>Luego ir a <code>Permisos de API</code> y agregar un nuevo permiso. Buscar la aplicaci\u00f3n <code>SharePoint</code> y escoger permisos de aplicaci\u00f3n <code>Sites.FullControl.All</code>, <code>Real.All</code>, <code>TermStore.Read.all</code> </p> </li> <li>Conceder el permiso del paso anterior. Para este paso se requieren permisos de administrador en la consola de Azure. </li> <li>Con esto el c\u00f3digo de <code>SharePoint_Connection.py</code> debe funcionar. Tener cuidado de la carpeta a la cual se est\u00e1 dirigiendo en la variable <code>folder_url</code></li> </ol>"},{"location":"04.sharepoint/estructura_sharepoint/#estructura-de-la-carpeta","title":"Estructura de la Carpeta","text":""},{"location":"04.sharepoint/estructura_sharepoint/#comfenalco-educacion","title":"COMFENALCO EDUCACION","text":"Estructura de Carpetas Contraer todo Contiene los archivos resultado del WebScraping de diferentes plataformas relacionadas con la educaci\u00f3n y convenios de Comfenalco. 01.Q10 <ul> Carpeta principal con los datos extra\u00eddos del sistema Q10, organizados en categor\u00edas espec\u00edficas. 01.Educacion_Tecnica <ul> Subcarpeta con informaci\u00f3n t\u00e9cnica sobre docentes, matr\u00edculas, ingresos y notas hist\u00f3ricas. 01.Docentes <ul> Contiene archivos relacionados con los registros de los docentes procesados y sin procesar. <li>Docentes_08_12_2024.xlsx </li> <li>Docentes_09_12_2024.xlsx </li> <li>Docentes_20_11_2024.xlsx </li> <li>Docentes_21_11_2024.xlsx </li> <li>Docentes_23_11_2024.xlsx </li> <li>Docentes_23_12_2024.xlsx </li> <li>Docentes_27_12_2024.xlsx </li> </ul> 02.Disenio_Curricular <ul> Archivos relacionados con el plan de estudios (Pensum) de cada programa. <li>Dise\u00f1o_Curricular_08_12_2024.xlsx </li> <li>Dise\u00f1o_Curricular_17_12_2024.xlsx </li> <li>Dise\u00f1o_Curricular_20_11_2024.xlsx </li> <li>Dise\u00f1o_Curricular_21_11_2024.xlsx </li> <li>Dise\u00f1o_Curricular_27_12_2024.xlsx </li> </ul> 03.Listado_Matriculas <ul> Listado de matr\u00edculas con el listado de los estudiantes que fueron matriculados en un programa espec\u00edfico en el rango de fechas o periodo seleccionado. <li>Listado_Matriculas_01_01_2016_31_12_2016_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2016_31_12_2016_Act_24_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2017_31_12_2017_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2017_31_12_2017_Act_24_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2017_31_12_2017_Act_24_11_20241.xlsx </li> <li>Listado_Matriculas_01_01_2018_31_12_2018_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2018_31_12_2018_Act_24_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2019_31_12_2019_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2020_31_12_2020_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2021_31_12_2021_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2022_31_12_2022_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2023_31_12_2023_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_28_11_2024_Act_28_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_30_06_2024_Act_27_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_31_12_2024_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_31_12_2024_Act_27_12_2024.xlsx </li> </ul> 04.Ingresos <ul> Listado de archivos contiene el dinero recibido por concepto de pagos registrados en las diferentes modalidades de recaudo. <li>Ingresos_01_01_2017_31_12_2017_23_12_2024.xlsx </li> <li>Ingresos_01_01_2018_31_12_2018_23_12_2024.xlsx </li> <li>Ingresos_01_01_2019_31_12_2019_23_12_2024.xlsx </li> <li>Ingresos_01_01_2020_31_12_2020_23_12_2024.xlsx </li> <li>Ingresos_01_01_2020_31_12_2020_27_12_2024.xlsx </li> <li>Ingresos_01_01_2021_31_12_2021_23_12_2024.xlsx </li> <li>Ingresos_01_01_2022_31_12_2022_23_12_2024.xlsx </li> <li>Ingresos_01_01_2023_31_12_2023_23_12_2024.xlsx </li> <li>Ingresos_01_01_2024_31_12_2024_23_12_2024.xlsx </li> </ul> 05.Historico_Notas<ul> Historial detallado de los cursos que han sido archivados con sus respectivos estudiantes y notas. <li>- Historico_Notas_2023_2_0100c7e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_026fa7c8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_02cbe285_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0449a5e7_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_07dba647_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_092aac38_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0cddad19_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0dff50cb_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0e7858c3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_10375576_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_109d6949_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_121fad89_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_12dc19a4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_1735f955_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_185ac97e_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_1958d0f8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_1a220917_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2210ee55_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2226d5a5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2380e5e7_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_24b41186_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_273540de_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_29769f40_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2be84da8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2d29660f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2e068ad5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2ee8230e_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_306b3846_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_30cc8d74_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_32e309f0_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_33b9edfc_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_378b0fac_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_384c0f48_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4215b767_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_46b79fc3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4921f516_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4bad2c64_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4d3cc959_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4dc601e8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_541f1898_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_55a3bd93_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_55e6763f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_58f870e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_5f5f368b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_62908c57_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6500f569_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6540bc55_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_66b59284_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_68bb266b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6b58a8a9_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6ef0249a_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6f559dd2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_73887911_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7a4650f1_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7a962879_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7c26c9fe_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7e5281f2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7eaa6bf3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7ecf3546_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_81280bf5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_812e8d89_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_85fd6ce5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_885e0511_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_88851305_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_8a1dc0e8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_8ead704b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_8fd27aa1_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_91cb763c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_956755ea_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_9776db00_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_9a88ca6d_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_a8543b8f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_a895cfc3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ab2d75de_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ac6e1db1_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ad933526_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_af9aa73c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_b1d06454_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_b88458df_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_baec81f2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_bb6bce34_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_bbb5dd53_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_bec15051_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c155c17a_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c3b000d2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c576f83c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c6407892_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c9ac9d62_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_caa22d82_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_cae7be5c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_cbf22cd4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ccb297f0_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d413cda3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d573164b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d888e4af_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d9bd30a3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_dadd2624_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_db34b6b2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_dea03ce6_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_df10e46e_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_df7dbde9_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e1111635_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e6f87f14_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e7ec41ef_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e964d7d0_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ec138d23_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_eccbecbe_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_eea8e976_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f02f4642_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f0a906ec_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f104cb7f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f18569e3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f2835d58_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f75fcc99_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f8939331_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f9c45ab6_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f9d3b157_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_fa3190bf_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_fabd1fb4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_fcd657ef_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_046ce457_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_0e466b26_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_0f91b4b0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1130b71a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_12570c3e_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1a458bff_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1e01dc0c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1e36519c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1e949cc6_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1f4264e3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1f5150ed_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_248946e3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_28e1fc5a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_2c7b3b56_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_316ee9d7_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3255b38a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3283e4b3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_35394ea3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3588253c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3a428752_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3b426767_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3fa7f518_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_40fae1d1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_4ec16e1f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_50b5f8e0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_535a9c53_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_5d9b1d37_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_5ee76ea0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_62d748e5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_64183122_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_68eb8641_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_6e7f7ac5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_6f3268f9_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_6f48dd2f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_700898eb_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7044b236_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_741e9221_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_75f1b194_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_769e73ee_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_796685b9_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7b2d09b2_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7b8a67d1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7b8caefb_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7cf1c303_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7d9ff89c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7e2ece94_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7f88a9c1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7fd4026f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_82c2d334_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_86841d92_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_86fe6856_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_8870b866_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_898499c8_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_8a325911_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_8c233e77_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_9051cfba_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_91ca2296_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_95a35066_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_964ae673_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_978c7d05_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_98f3faec_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_9a46e7e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_9e635b41_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a2182500_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a4e412ce_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a80338d1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a8d30ce5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a9862f6d_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a9eb40a4_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_aa322057_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_ab514259_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_af9f6622_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b06dc7df_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b5c640c2_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b5f21992_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b8884db6_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b95c9d2a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_bb80a2a7_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_c5c6495d_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_c7133773_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_c7583eed_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_ca93eb94_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_cba65ff5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_cc57a34b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d1ce1966_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d34f5bf8_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d68444b2_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d812cccc_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d9aa91e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dc6f2109_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dccac103_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dcd84c6c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dcf2b57f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e3430d8b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e4ad961e_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e546f874_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e6a6da65_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e9175c3b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e91bf7dc_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_ef1d746b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f541b731_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f70675c0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f828cd1a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f9e953ce_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_fb4fd7a6_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_fbb74184_24_12_2024.xlsx </li> <li>- Historico_Notas_AA-Com. Org-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Compras-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Cont. Inv. Apli-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Gest. Doc-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Htas. Apoy. Tec-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Htas. Apoy. Tec-JN-G2-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-PROD.DOC-JM-S1-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-PROD.DOC-JN-S1-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-PROD.DOC-JN-S1-G2-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Sem. Tra. Emp-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_MV-Est. Can. Dist-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_MV-Estrat. Prec.-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_MV-Inv. Merc.-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-IMP.SG-SST-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-Sem. Tra. Emp-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-Sem. Tra. V.S-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-STAR-2-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_T\u00e9cnico Laboral en Auxiliar Administrativo_27_11_2024.xlsx </li> </ul> 06.Egresados_Graduados<ul> Nota: Contiene archivos de Excel con la informaci\u00f3n de los egresados y graduados.                          <li>- Graduados_2010 - 1_21_11_2024.xlsx </li> <li>- Graduados_2010 - 2_21_11_2024.xlsx </li> <li>- Graduados_2011 - 1_21_11_2024.xlsx </li> <li>- Graduados_2011 - 2_21_11_2024.xlsx </li> <li>- Graduados_2012 - 1_21_11_2024.xlsx </li> <li>- Graduados_2012 - 2_21_11_2024.xlsx </li> <li>- Graduados_2013 - 1_21_11_2024.xlsx </li> <li>- Graduados_2013 - 2_21_11_2024.xlsx </li> <li>- Graduados_2014 - 1_21_11_2024.xlsx </li> <li>- Graduados_2014 - 2_21_11_2024.xlsx </li> <li>- Graduados_2015 - 1_21_11_2024.xlsx </li> <li>- Graduados_2015 - 2_21_11_2024.xlsx </li> <li>- Graduados_2016 - 1_21_11_2024.xlsx </li> <li>- Graduados_2016 - 1_24_12_2024.xlsx </li> <li>- Graduados_2016 - 2_21_11_2024.xlsx </li> <li>- Graduados_2016 - 2_24_12_2024.xlsx </li> <li>- Graduados_2017 - 1_21_11_2024.xlsx </li> <li>- Graduados_2017 - 1_24_12_2024.xlsx </li> <li>- Graduados_2017 - 2_21_11_2024.xlsx </li> <li>- Graduados_2017 - 2_24_12_2024.xlsx </li> <li>- Graduados_2018-1_21_11_2024.xlsx </li> <li>- Graduados_2018-1_24_12_2024.xlsx </li> <li>- Graduados_2018-2_21_11_2024.xlsx </li> <li>- Graduados_2018-2_24_12_2024.xlsx </li> <li>- Graduados_2019-1 CONVENIO_21_11_2024.xlsx </li> <li>- Graduados_2019-1 CONVENIO_24_12_2024.xlsx </li> <li>- Graduados_2019-1_21_11_2024.xlsx </li> <li>- Graduados_2019-1_24_12_2024.xlsx </li> <li>- Graduados_2019-2_21_11_2024.xlsx </li> <li>- Graduados_2019-2_24_12_2024.xlsx </li> <li>- Graduados_2020-1_21_11_2024.xlsx </li> <li>- Graduados_2020-1_24_12_2024.xlsx </li> <li>- Graduados_2020-2_21_11_2024.xlsx </li> <li>- Graduados_2020-2_24_12_2024.xlsx </li> <li>- Graduados_2021-1_21_11_2024.xlsx </li> <li>- Graduados_2021-1_24_12_2024.xlsx </li> <li>- Graduados_2021-2_21_11_2024.xlsx </li> <li>- Graduados_2021-2_24_12_2024.xlsx </li> <li>- Graduados_2022-1_21_11_2024.xlsx </li> <li>- Graduados_2022-1_24_12_2024.xlsx </li> <li>- Graduados_2022-2_21_11_2024.xlsx </li> <li>- Graduados_2022-2_24_12_2024.xlsx </li> <li>- Graduados_2023-1_21_11_2024.xlsx </li> <li>- Graduados_2023-1_24_12_2024.xlsx </li> <li>- Graduados_2023-2_21_11_2024.xlsx </li> <li>- Graduados_2023-2_24_12_2024.xlsx </li> <li>- Graduados_2024-1_21_11_2024.xlsx </li> <li>- Graduados_2024-1_24_12_2024.xlsx </li> <li>- Graduados_2024-1_27_12_2024.xlsx </li> <li>- Graduados_2024-2_21_11_2024.xlsx </li> <li>- Graduados_2024-2_24_12_2024.xlsx </li> <li>- Graduados_2024-2_27_12_2024.xlsx </li> <li>- Graduados_23_12_2024.xlsx </li> <li>- Graduados_Agosto 2024_23_12_2024.xlsx </li> <li>- Graduados_Julio 2024_23_12_2024.xlsx </li> <li>- Graduados_Junio 2024_23_12_2024.xlsx </li> <li>- Graduados_Octubre 2024_23_12_2024.xlsx </li> <li>- Graduados_Septiembre 2024_23_12_2024.xlsx </li> </ul> 07.Cancelados_Desertores<ul> Nota: Contiene los registros de estudiantes que han cancelado su matr\u00edcula con su respectiva causa y descripci\u00f3n.                          <li>- Cancelados_desertores_01_02_2024_04_10_2024.xlsx </li> <li>- Cancelados_desertores_01_02_2024_22_03_2024.xlsx </li> <li>- Cancelados_desertores_03_02_2020_12_12_2020.xlsx </li> <li>- Cancelados_desertores_10_02_2022_21_10_2022.xlsx </li> <li>- Cancelados_desertores_11_02_2023_09_10_2023.xlsx </li> <li>- Cancelados_desertores_11_03_2019_03_12_2019.xlsx </li> <li>- Cancelados_desertores_28_02_2021_23_12_2021.xlsx </li> <li>- Cancelados_desertores_31_08_2018_04_10_2018.xlsx </li> </ul> Procesados<ul> Nota: Esta secci\u00f3n contiene los archivos procesados, organizados seg\u00fan la misma estructura jer\u00e1rquica de carpetas original. Los datos han sido preparados y optimizados para su integraci\u00f3n y consumo directo mediante SSIS, garantizando compatibilidad y eficiencia en los procesos ETL.                          01.Docentes<ul> <li>- procesado_cede_Docentes_08_12_2024_20_27.xlsx </li> <li>- procesado_cede_Docentes_23_12_2024_14_39.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_11_52.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_11_53.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_12_18.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_12_26.xlsx </li> 02.Disenio_Curricular<ul> <li>- procesado_cede_Dise\u00f1o_Curricular_08_12_2024_20_28.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_23_12_2024_14_41.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_27_12_2024_12_02.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_27_12_2024_12_03.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_27_12_2024_14_05.xlsx </li> 03.Listado_Matriculas<ul> <li>- procesado_cede_Listado_Matriculas_08_12_2024_20_21.xlsx </li> <li>- procesado_cede_Listado_Matriculas_08_12_2024_20_26.xlsx </li> <li>- procesado_cede_Listado_Matriculas_17_12_2024_09_34.xlsx </li> <li>- procesado_cede_Listado_Matriculas_23_12_2024_14_45.xlsx </li> <li>- procesado_cede_Listado_Matriculas_27_12_2024_12_09.xlsx </li> 04.Ingresos<ul> <li>- procesado_cede_Ingresos_08_12_2024_20_32.xlsx </li> <li>- procesado_cede_Ingresos_23_12_2024_14_56.xlsx </li> <li>- procesado_cede_Ingresos_27_12_2024_14_11.xlsx </li> 05.Historico_Notas<ul> <li>- procesado_cede_Historico_Notas_08_12_2024_20_36.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_08_44.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_08_50.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_09_04.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_09_20.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_09_23.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_18_15.xlsx </li> 06.Egresados_Graduados<ul> <li>- procesado_cede_Egresados_Graduados_08_12_2024_20_38.xlsx </li> <li>- procesado_cede_Egresados_Graduados_23_12_2024_21_28.xlsx </li> <li>- procesado_cede_Egresados_Graduados_24_12_2024_19_42.xlsx </li> 07.Cancelados_Desertores<ul> <li>- procesado_cede_Cancelados_Desertores_08_12_2024_20_41.xlsx </li> <li>- procesado_cede_Cancelados_Desertores_24_12_2024_20_14.xlsx </li> </ul> </ul> </ul> 02.Educacion_Continua Nota: Contiene registros de docentes relacionados con programas de educaci\u00f3n continua.                  <ul> 01.Docentes<ul> Nota: Listado de preinscritos en programas de educaci\u00f3n continua.                          <li>- Docentes_08_12_2024.xlsx </li> <li>- Docentes_20_11_2024.xlsx </li> <li>- Docentes_21_11_2024.xlsx </li> <li>- Docentes_25_12_2024.xlsx </li> <li>- Docentes_28_12_2024.xlsx </li> <li>- Docentes_30_11_2024.xlsx </li> </ul> 02.Preinscritos<ul> Nota: Archivos detallados de preinscritos en programas de educaci\u00f3n continua.                          <li>- Preinscritos_20_11_2024.xlsx </li> <li>- Preinscritos_21_11_2024.xlsx </li> <li>- Preinscritos_25_12_2024.xlsx </li> <li>- Preinscritos_27_12_2024.xlsx </li> <li>- Preinscritos_30_11_2024.xlsx </li> </ul> 03.Listado_Matriculas<ul> Nota: Listado de los estudiantes que fueron matriculados en un programa espec\u00edfico en el rango de fechas o periodo seleccionado.                          <li>- Listado_Matriculas_01_01_2018_31_12_2018_Act_30_11_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2019_30_06_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2019_31_03_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2020_31_03_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2021_31_03_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2022_31_03_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2023_31_03_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2024_31_03_2024_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2024_31_03_2024_Act_27_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2019_30_06_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2020_30_06_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2021_30_06_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2022_30_06_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2023_30_06_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2024_30_06_2024_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2024_30_06_2024_Act_27_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2018_31_12_2018_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2019_30_09_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2020_30_09_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2021_30_09_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2022_30_09_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2023_30_09_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2018_31_12_2018_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2019_31_12_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2020_31_12_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2021_31_12_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2022_31_12_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2023_31_12_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2024_31_12_2024_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2024_31_12_2024_Act_27_12_2024.xlsx </li> </ul> 04.Consolidado_inasistencias<ul> Nota: <li>- Consolidado_Inasistencias_1020.xlsx </li> <li>- Consolidado_Inasistencias_Consolidado_de_Inasistencias (1).xlsx </li> <li>- Consolidado_Inasistencias_Desarrollo Empresarial - Ma\u00f1ana_AUTOCONFIANZA_Noviembre 2024.xlsx </li> </ul> 05.Estudiantes_cancelados_por_inasistencias<ul> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Diciembre 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Diciembre 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Julio 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Septiembre 2023.xlsx </li> </ul> 06.Egresados_Graduados<ul> <li>- Graduados_Abril 2022_21_11_2024.xlsx </li> <li>- Graduados_Abril 2023_21_11_2024.xlsx </li> <li>- Graduados_Abril 2024_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2021_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2022_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2023_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2024_21_11_2024.xlsx </li> <li>- Graduados_Diciembre 2021_21_11_2024.xlsx </li> <li>- Graduados_Diciembre 2022_21_11_2024.xlsx </li> <li>- Graduados_Diciembre 2023_21_11_2024.xlsx </li> <li>- Graduados_Enero 2022_21_11_2024.xlsx </li> <li>- Graduados_Enero 2023_21_11_2024.xlsx </li> <li>- Graduados_Enero 2024_21_11_2024.xlsx </li> <li>- Graduados_Febrero 2022_21_11_2024.xlsx </li> <li>- Graduados_Febrero 2023_21_11_2024.xlsx </li> <li>- Graduados_Febrero 2024_21_11_2024.xlsx </li> <li>- Graduados_Julio 2022_21_11_2024.xlsx </li> <li>- Graduados_Julio 2023_21_11_2024.xlsx </li> <li>- Graduados_Julio 2024_21_11_2024.xlsx </li> <li>- Graduados_Junio 2022_21_11_2024.xlsx </li> <li>- Graduados_Junio 2023_21_11_2024.xlsx </li> <li>- Graduados_Junio 2024_21_11_2024.xlsx </li> <li>- Graduados_Marzo 2022_21_11_2024.xlsx </li> <li>- Graduados_Marzo 2023_21_11_2024.xlsx </li> <li>- Graduados_Marzo 2024_21_11_2024.xlsx </li> <li>- Graduados_Mayo 2022_21_11_2024.xlsx </li> <li>- Graduados_Mayo 2023_21_11_2024.xlsx </li> <li>- Graduados_Mayo 2024_21_11_2024.xlsx </li> <li>- Graduados_Noviembre 2022_21_11_2024.xlsx </li> <li>- Graduados_Noviembre 2023_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2019_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2021_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2022_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2023_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2024_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2021_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2022_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2023_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2024_21_11_2024.xlsx </li> </ul> Procesados Nota: Esta secci\u00f3n contiene los archivos procesados, organizados seg\u00fan la misma estructura jer\u00e1rquica de carpetas original. Los datos han sido preparados y optimizados para su integraci\u00f3n y consumo directo mediante SSIS, garantizando compatibilidad y eficiencia en los procesos ETL.                                                  0001.Docentes<ul> <li>- procesado_emp_Docentes_06_12_2024_19_05.xlsx </li> <li>- procesado_emp_Docentes_06_12_2024_19_06.xlsx </li> <li>- procesado_emp_Docentes_08_12_2024_20_45.xlsx </li> <li>- procesado_emp_Docentes_25_12_2024_06_53.xlsx </li> <li>- procesado_emp_Docentes_28_12_2024_06_58.xlsx </li> </ul> 02.Preinscritos<ul> <li>- procesado_emp_Preinscritos_06_12_2024_19_09.xlsx </li> <li>- procesado_emp_Preinscritos_08_12_2024_20_52.xlsx </li> </ul> 03.Listado_Matriculas<ul> <li>- procesado_emp_Listado_Matriculas_06_12_2024_19_08.xlsx </li> <li>- procesado_emp_Listado_Matriculas_08_12_2024_20_48.xlsx </li> <li>- procesado_emp_Listado_Matriculas_25_12_2024_11_37.xlsx </li> <li>- procesado_emp_Listado_Matriculas_25_12_2024_13_05.xlsx </li> </ul> 04.Consolidado_inasistencias<ul> <li>- procesado_emp_Consolidado_inasistencias_15_12_2024_10_03.xlsx </li> <li>- procesado_emp_Consolidado_inasistencias_15_12_2024_10_11.xlsx </li> <li>- procesado_emp_Consolidado_inasistencias_28_12_2024_07_25.xlsx </li> </ul> 05.Estudiantes_cancelados_por_inasistencias<ul> <li>- procesado_emp_Estudiantes_inasistencias_07_12_2024_04_36.xlsx </li> <li>- procesado_emp_Estudiantes_inasistencias_08_12_2024_20_56.xlsx </li> <li>- procesado_emp_Estudiantes_inasistencias_28_12_2024_07_36.xlsx </li> </ul> 06.Egresados_Graduados<ul> <li>- procesado_emp_Egresados_Graduados_06_12_2024_19_11.xlsx </li> <li>- procesado_emp_Egresados_Graduados_08_12_2024_20_55.xlsx </li> <li>- procesado_emp_Egresados_Graduados_08_12_2024_21_01.xlsx </li> <li>- procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx </li> </ul> </ul> 02.C4C <ul> Datos relevantes de la plataforma C4C, divididos en categor\u00edas de educaci\u00f3n y protecci\u00f3n social. 01.Educacion<ul> <li>-archivos_C4C_Educacion.xlsx</li> </ul> 02.Proteccion<ul> <li>-archivos_C4C_Proteccion.xlsx</li> </ul> </ul> 03.Archivos_Manuales <ul> Carpeta que agrupa archivos manuales organizados por tem\u00e1ticas y \u00e1reas espec\u00edficas. 01.Archivos_Seleccionados <ul> 01.Transversal <ul> 01.Dim_Servicios<ul> <li>- AM-TRA-08.xlsx</li> <li>- AM-TRA-08_2022.xlsx</li> <li>- AM-TRA-08_2023.xlsx</li> <li>- AM-TRA-08_2024.xlsx</li> </ul> </ul> 02.Educacion_Formal <ul> 01.Dim_Libros<ul> <li>- AM-EDF-153.xlsx</li> </ul> </ul> 03.Educacion_Tecnica <li>archivos_manuales.xlsx</li> 04.Educacion_Continua <li>archivos_manuales.xlsx</li> 05.Proteccion_Social <li>archivos_manuales.xlsx</li> 02.Estructuras_Propuestas <ul> 01.Transversal <ul> 01.Dim_Servicios<ul> <li>- EP-TRA-04.xlsx</li> <li>- EP-TRA-04_2023.xlsx</li> <li>- EP-TRA-04_2024.xlsx</li> </ul> 02.Dim_Capacidad_Fisica<ul> <li>- EP-TRA-12.xlsx</li> </ul> </ul> 02.Educacion_Formal <ul> 01.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2022.xlsx</li> <li>- EP-TRA-05_2023.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> 02.FACT_AUSENTISMO_DOCENTE<ul> <li>- EP-EDF-02.xlsx</li> </ul> 03.FACT_BIBLIOTECA<ul> <li>- EP-EDF-05.xlsx</li> </ul> 04.FACT_BIBLIOTECA_VIRTUAL<ul> <li>- EP-EDF-06.xlsx</li> </ul> 05.FACT_DESEMPENHO_DOCENTE<ul> <li>- EP-EDF-09.xlsx</li> </ul> 06.FACT_ENFERMERIA<ul> <li>- EP-EDF-01.xlsx</li> </ul> 07.FACT_LEGALIZACION<ul> <li>- EP-EDF-10.xlsx</li> </ul> 08.FACT_PERMISO_ESTUDIANTE<ul> <li>- EP-EDF-04.xlsx</li> </ul> 09.FACT_PSIORIENTACION<ul> <li>- EP-EDF-11.xlsx</li> </ul> 10.FACT_REEMPLAZO_DOCENTE<ul> <li>- EP-EDF-03.xlsx</li> </ul> 11.FACT_RESERVA_ESPACIOS<ul> <li>- EP-EDF-12.xlsx</li> </ul> 12.FACT_SABER11_COLEGIOS<ul> <li>- EP-EDF-08.xlsx</li> </ul> 13.FACT_SABER11_INDIVIDUAL<ul> <li>- EP-EDF-07.xlsx</li> </ul> 14.FACT_SERVICIO_SOCIAL<ul> <li>- EP-EDF-13.xlsx</li> </ul> 15.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2022.xlsx</li> <li>- EP-TRA-05_2023.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> 16.DIM_TARIFAS_SERVICIOS<ul> <li>- EP-TRA-04_2024.xlsx</li> </ul> </ul> 03.Educacion_Tecnica <ul> 01.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> </ul> 04.Educacion_Continua <ul> 01.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> </ul> 05.Proteccion_Social <ul> 01.Caracterizacion <ul> AM-PRS-03 <ul><li>- AM-PRS-03-2022.xlsx</li></ul> AM-PRS-10 <ul><li>- AM-PRS-10-202405.xlsx</li></ul> <ul><li>- AM-PRS-10.xlsx</li> AM-PRS-102 <ul><li>- AM-PRS-102.xlsx </li> AM-PRS-11 <ul> <li>- AM-PRS-11-202401.xlsx</li> <li>- AM-PRS-11-202402.xlsx</li> <li>- AM-PRS-11-202403.xlsx</li> <li>- AM-PRS-11-202404.xlsx</li> <li>- AM-PRS-11-202405.xlsx</li> <li>- AM-PRS-11.xlsx</li> </ul> AM-PRS-12 <ul> <li>- AM-PRS-12-2024.xlsx</li> <li>- AM-PRS-12.xlsx</li> </ul> AM-PRS-120 <ul> <li>- AM-PRS-120-202402.xlsx</li> <li>- AM-PRS-120-202403.xlsx</li> <li>- AM-PRS-120-202404.xlsx</li> <li>- AM-PRS-120-202405.xlsx</li> <li>- AM-PRS-120.xlsx</li> </ul> AM-PRS-13 <ul> <li>- AM-PRS-13-2023.xlsx</li> <li>- AM-PRS-13.xlsx</li> </ul> AM-PRS-145 <ul><li>- AM-PRS-145.xlsx </li> AM-PRS-145_CATEGORICAS <ul><li>- AM-PRS-145_CATEGORICAS.xlsx </li> AM-PRS-23 <ul><li>- AM-PRS-23.xlsx</li> AM-PRS-41 <ul><li>- AM-PRS-41.xlsx </li> AM-PRS-81 <ul><li>- AM-PRS-81.xlsx </li> AM-PRS-91 <ul><li>- AM-PRS-91.xlsx </li> AM-PRS-91_CATEGORICAS <ul><li>- AM-PRS-91_CATEGORICAS.xlsx </li> AM-TRA-11 <ul><li>- AM-TRA-11.txt </li> DIM_PROGRAMA <ul><li>- ID_PROGRAMA.xlsx </li> EP-PRS-02 <ul><li>- EP-PSR-02.xlsx </li> EP-PRS-03 <ul><li>- EP-PSR-03.xlsx </li> EP-PSR-01 <ul><li>- EP-PSR-01.xlsx </li> EP-TRA-02 <ul><li>- EP-TRA-02.xlsx </li> NSU CEC <ul> <li>CEC (2).txt </li> <li>CEC.txt </li> <li>comfenalcocec (2).txt </li> <li>comfenalcocec (3).txt </li> <li>comfenalcocec (4).txt </li> <li>comfenalcocec (5).txt </li> <li>comfenalcocec.txt </li> </ul> Cedesarrollo convenios <ul> <li>campanas comfenalcoconvenios (2).txt</li> <li>campanas comfenalcoconvenios (3).txt</li> <li>campanas comfenalcoconvenios (4).txt</li> <li>campanas comfenalcoconvenios (5).txt</li> <li>campanas comfenalcoconvenios.txt</li> <li>Convenios (2).txt</li> <li>Convenios.txt</li> </ul> Consultorias <ul> <li>campanas comfenalcoconsultorias (2).txt</li> <li>campanas comfenalcoconsultorias (3).txt</li> <li>campanas comfenalcoconsultorias (4).txt</li> <li>campanas comfenalcoconsultorias (5).txt</li> <li>campanas comfenalcoconsultorias.txt</li> <li>Consultorias (2).txt</li> <li>Consultorias.txt</li> </ul> Cursos y diplomados <ul> <li>campanas comfenalcodiplomados (2).txt</li> <li>campanas comfenalcodiplomados (3).txt</li> <li>campanas comfenalcodiplomados (4).txt</li> <li>campanas comfenalcodiplomados (5).txt</li> <li>campanas comfenalcodiplomados.txt</li> <li>Cursos y diplomados (2).txt</li> <li>Cursos y diplomados.txt</li> </ul> Egresados <ul> <li>comfenalcocedesarrolloegresados (2).txt</li> <li>comfenalcocedesarrolloegresados (3).txt</li> <li>comfenalcocedesarrolloegresados (4).txt</li> <li>comfenalcocedesarrolloegresados (5).txt</li> <li>comfenalcocedesarrolloegresados.txt</li> <li>Egresado (2).txt</li> <li>Egresado.txt</li> </ul> Estudiantes Activos <ul> <li>base1.txt</li> <li>base1Activos1.txt</li> <li>base2.txt</li> <li>base2Activos0.txt</li> <li>base3.txt</li> <li>base4.txt</li> <li>base5.txt</li> <li>Estudiantes Activos (2).txt</li> <li>Estudiantes Activos.txt</li> </ul> Proteccion social <ul> <li>campanas comfenalcoproteccion(2).txt</li> <li>campanas comfenalcoproteccion(3).txt</li> <li>campanas comfenalcoproteccion(4).txt</li> <li>campanas comfenalcoproteccion(5).txt</li> <li>Proteccion social (2).txt</li> <li>Proteccion social.txt</li> </ul> 02.DIM_PERSONAL <ul><li>- EP-TRA-05.xlsx  </li> <ul><li>- EP-TRA-02.xlsx </li> </ul> </ul> </ul> 03.Otros_Archivos <ul> <li>AM-DRE-05_08_12_2024.xlsx</li> <li>AM-DRE-05_25_12_2024.xlsx</li> <li>AM-DRE-16.xls</li> <li>AM-EPT-47.xlsx</li> <li>EP-EDF-02.xlsx</li> <li>EP-EDF-04.xlsx</li> <li>EP-EDF-09.xlsx</li> <li>EP-EPT-04.xlsx</li> <li>EP-EPT-06.xlsx</li> <li>EP-EPT-07.xlsx</li> <li>EP-EPT-08.xlsx</li> <li>EP-EPT-09.xlsx</li> <li>EP-EPT-10.xlsx</li> <li>EP-EPT-11.xlsx</li> <li>EP-EPT-12.xlsx</li> </ul> </ul> <p>Nota: Desplegar los items para ver su contenido</p>"},{"location":"05.Power_BI/00.Introduccion%20copy/","title":"00.Introduccion copy","text":""},{"location":"05.Power_BI/00.Introduccion%20copy/#visualizaciones-del-tablero-analitico-de-educacion","title":"Visualizaciones del Tablero Anal\u00edtico de Educaci\u00f3n","text":""},{"location":"05.Power_BI/00.Introduccion%20copy/#1-menu-de-navegacion","title":"1. Men\u00fa de Navegaci\u00f3n","text":"<p>El tablero se estructura en varias secciones principales, cada una enfocada en un aspecto clave del proceso educativo. Estas secciones incluyen an\u00e1lisis espec\u00edficos que permiten evaluar tanto la productividad como el impacto social del sistema educativo:</p> <p></p> <ul> <li> <p>Productividad Organizacional - An\u00e1lisis de Desempe\u00f1o y Calidad:  </p> <p>Aborda la calidad del proceso educativo, evaluando indicadores como desempe\u00f1o docente y resultados en evaluaciones externas.  </p> </li> <li> <p>Productividad Organizacional - An\u00e1lisis de Eficiencia:  </p> <p>Analiza el uso de recursos, inversiones en infraestructura y el rendimiento operativo del sistema educativo.  </p> </li> <li> <p>Impacto Social y Comunitario - An\u00e1lisis por Servicio:  </p> <p>Examina c\u00f3mo los servicios educativos impactan a los beneficiarios seg\u00fan diferentes categor\u00edas y \u00e1reas de acci\u00f3n.  </p> </li> <li> <p>Impacto Social y Comunitario - An\u00e1lisis por Empresa:  </p> <p>Relaciona los servicios proporcionados a empresas afiliadas con los subsidios y aportes realizados.  </p> </li> </ul>"},{"location":"05.Power_BI/00.Introduccion%20copy/#2-analisis-del-perfil-del-proceso-de-educacion","title":"2. An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n","text":"<p>Esta secci\u00f3n brinda un panorama general del estado del proceso educativo, resaltando:</p> <ul> <li>Informaci\u00f3n consolidada de afiliados, beneficiarios y empresas atendidas.  </li> <li>Indicadores clave relacionados con la utilizaci\u00f3n de recursos y la experiencia del usuario.  </li> </ul> <p>Objetivo: Ofrecer un contexto general que facilite la identificaci\u00f3n de tendencias y \u00e1reas cr\u00edticas en las operaciones educativas.</p>"},{"location":"05.Power_BI/00.Introduccion%20copy/#3-productividad-organizacional-analisis-de-desempeno-y-calidad","title":"3. Productividad Organizacional - An\u00e1lisis de Desempe\u00f1o y Calidad","text":"<p>El an\u00e1lisis en esta secci\u00f3n incluye:</p> <ul> <li>Evaluaci\u00f3n del impacto de las estrategias educativas en los resultados de estudiantes y docentes.  </li> <li>M\u00e9tricas sobre calidad educativa, como la relaci\u00f3n entre cobertura y desempe\u00f1o acad\u00e9mico.  </li> </ul> <p>Objetivo: Garantizar que la calidad de los programas educativos responda a los est\u00e1ndares esperados y fomente un aprendizaje efectivo.</p>"},{"location":"05.Power_BI/00.Introduccion%20copy/#4-productividad-organizacional-analisis-de-eficiencia","title":"4. Productividad Organizacional - An\u00e1lisis de Eficiencia","text":"<p>Esta secci\u00f3n est\u00e1 dise\u00f1ada para identificar oportunidades de mejora en la gesti\u00f3n de recursos mediante el an\u00e1lisis de:</p> <ul> <li>Uso de infraestructura f\u00edsica y tecnol\u00f3gica.  </li> <li>Indicadores de gesti\u00f3n como tiempo administrativo efectivo y rotaci\u00f3n del personal.  </li> </ul> <p>Objetivo: Optimizar los recursos disponibles y maximizar la eficiencia operativa del sistema educativo.</p>"},{"location":"05.Power_BI/00.Introduccion%20copy/#5-impacto-social-y-comunitario-analisis-por-servicio","title":"5. Impacto Social y Comunitario - An\u00e1lisis por Servicio","text":"<p>Permite desglosar el impacto generado por servicios educativos individuales, considerando indicadores como:  </p> <ul> <li>Inclusi\u00f3n y accesibilidad para diferentes grupos demogr\u00e1ficos.  </li> <li>Participaci\u00f3n en actividades de bienestar y desarrollo.  </li> </ul> <p>Objetivo: Cuantificar el impacto de cada servicio en t\u00e9rminos de bienestar social y comunitario.</p>"},{"location":"05.Power_BI/00.Introduccion%20copy/#6-impacto-social-y-comunitario-analisis-por-empresa","title":"6. Impacto Social y Comunitario - An\u00e1lisis por Empresa","text":"<p>Esta visualizaci\u00f3n combina datos relacionados con las empresas afiliadas y los servicios educativos que reciben. Se analizan:</p> <ul> <li>Subsidios otorgados y servicios vendidos seg\u00fan tipo de operaci\u00f3n.  </li> <li>Relaci\u00f3n entre los aportes empresariales y los beneficios obtenidos.  </li> </ul> <p>Objetivo: Medir el retorno de inversi\u00f3n social y econ\u00f3mica desde la perspectiva empresarial, asegurando la sostenibilidad del sistema educativo.</p>"},{"location":"05.Power_BI/00.Introduccion%20copy/#diagrama-de-flujo-general","title":"Diagrama de Flujo General","text":"<pre><code>flowchart TD\n    A[Perfil del Proceso Educativo] --&gt; B[Desempe\u00f1o y Calidad]\n    A --&gt; C[Eficiencia]\n    A --&gt; D[Impacto por Servicio]\n    A --&gt; E[Impacto por Empresa]\n    B --&gt; F[Indicadores de Resultados]\n    C --&gt; G[Uso de Recursos]\n    D --&gt; H[Impacto Social por Categor\u00eda]\n    E --&gt; I[Relaci\u00f3n Servicios-Aportes]</code></pre>"},{"location":"05.Power_BI/00.Introduccion%20copy/#conclusion","title":"Conclusi\u00f3n","text":"<p>El tablero anal\u00edtico est\u00e1 dise\u00f1ado para ofrecer una visi\u00f3n integral del proceso educativo, permitiendo a los responsables tomar decisiones estrat\u00e9gicas basadas en datos. Su estructura modular facilita la identificaci\u00f3n de oportunidades de mejora y el seguimiento del impacto en todos los niveles, desde la eficiencia operativa hasta los beneficios sociales y econ\u00f3micos.</p>"},{"location":"05.Power_BI/00.Introduccion/","title":"Introducci\u00f3n","text":""},{"location":"05.Power_BI/00.Introduccion/#tableros-analiticos-del-proceso-de-educacion","title":"Tableros Anal\u00edticos del Proceso de Educaci\u00f3n","text":""},{"location":"05.Power_BI/00.Introduccion/#vision-general-de-los-dashboards","title":"Visi\u00f3n General de los Dashboards","text":"<p>El sistema de dashboards para el proceso de Educaci\u00f3n proporciona un an\u00e1lisis multidimensional que abarca desde indicadores operativos hasta m\u00e9tricas de impacto social. A continuaci\u00f3n se detalla la estructura y funcionalidad de cada visualizaci\u00f3n:</p>"},{"location":"05.Power_BI/00.Introduccion/#analisis-del-perfil-del-proceso-de-educacion","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n","text":"<p>Objetivo de la Visualizaci\u00f3n: Proporcionar una visi\u00f3n integral del proceso de Educaci\u00f3n, resaltando indicadores estrat\u00e9gicos y datos clave sobre el estado actual de cada unidad de negocio. Facilita la toma de decisiones y el monitoreo de aspectos relevantes como empresas atendidas, afiliados, beneficiarios y servicios ofertados/vendidos.</p>"},{"location":"05.Power_BI/00.Introduccion/#estructura-y-elementos-principales","title":"Estructura y Elementos Principales:","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite navegar entre distintos an\u00e1lisis estrat\u00e9gicos (Productividad Organizacional, Impacto Social y Comunitario)</li> <li>Facilita cambios de perspectiva sin perder contexto</li> </ul> </li> <li> <p>Panel Lateral Izquierdo: </p> <ul> <li>Unidades de Negocio: Filtrado por unidad espec\u00edfica</li> <li>Totales de Negocio: Resumen de datos agregados</li> <li>Utilizaci\u00f3n: Informaci\u00f3n sobre uso de servicios</li> <li>Capacidad F\u00edsica: Disponibilidad de infraestructura</li> <li>Experiencia de Usuario: Satisfacci\u00f3n de beneficiarios</li> </ul> </li> <li> <p>Zona Central - Indicadores Generales:</p> <ul> <li>Empresas Atendidas: Organizaciones que reciben servicios</li> <li>Afiliados Atendidos: Cantidad de afiliados con acceso a servicios</li> <li>Beneficiarios Atendidos: Personas beneficiadas directa o indirectamente</li> <li>Servicios Ofertados/Vendidos: Comparativa entre oferta y venta efectiva</li> <li>Aportes y Subsidios: Informaci\u00f3n sobre financiaci\u00f3n y cobertura</li> </ul> </li> </ol>"},{"location":"05.Power_BI/00.Introduccion/#indicadores-de-utilizacion","title":"Indicadores de Utilizaci\u00f3n","text":"<p>Objetivo: Brindar perspectiva detallada sobre la utilizaci\u00f3n de servicios educativos, incluyendo afiliados, empresas y beneficiarios atendidos, as\u00ed como datos de promoci\u00f3n, deserci\u00f3n y recuperaci\u00f3n de afiliados.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-destacados","title":"Elementos Destacados:","text":"<ul> <li>Afiliados Atendidos: Usuarios que utilizan servicios educativos</li> <li>Empresas Atendidas: Organizaciones participantes en programas</li> <li>Beneficiarios Atendidos: Personas que reciben servicios directos</li> <li>Cobertura por Categor\u00eda: Personas atendidas por categor\u00eda (A, B, C)</li> <li>Indicadores de Continuidad: Tasas de promoci\u00f3n, deserci\u00f3n y recuperaci\u00f3n</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades","title":"Funcionalidades:","text":"<ul> <li>Comparaciones temporales de indicadores</li> <li>Enfoque en trayectoria del usuario (promoci\u00f3n/deserci\u00f3n)</li> <li>An\u00e1lisis de tendencias en utilizaci\u00f3n de servicios</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#indicadores-de-capacidad","title":"Indicadores de Capacidad","text":"<p>Objetivo: Mostrar la capacidad de prestaci\u00f3n del proceso educativo mediante la comparaci\u00f3n entre servicios ofertados y vendidos, y la distribuci\u00f3n de docentes por unidad.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-clave","title":"Elementos Clave:","text":"<ul> <li>Servicios Ofertados por Unidad: Proporci\u00f3n de servicios disponibles</li> <li>Servicios Vendidos por Unidad: Servicios efectivamente contratados</li> <li>Docentes por Unidad: Distribuci\u00f3n de recursos humanos</li> <li>Indicadores Num\u00e9ricos: Totales globales para referencia r\u00e1pida</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades-principales","title":"Funcionalidades Principales:","text":"<ul> <li>Comparaci\u00f3n oferta vs. venta para identificar efectividad</li> <li>An\u00e1lisis de distribuci\u00f3n de recursos humanos</li> <li>Identificaci\u00f3n de brechas o excedentes de capacidad</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#experiencia-de-usuario","title":"Experiencia de Usuario","text":"<p>Objetivo: Ofrecer una perspectiva integral de satisfacci\u00f3n y experiencia de usuarios en el proceso educativo, mediante indicadores clave como NPS y tiempo de resoluci\u00f3n.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-principales","title":"Elementos Principales:","text":"<ul> <li>Net Promoter Score (NPS): Disposici\u00f3n de usuarios a recomendar servicios</li> <li>Resoluci\u00f3n Promedio: Tiempo para resolver solicitudes o inquietudes</li> <li>Porcentaje de Promotores y Detractores: Proporci\u00f3n de usuarios satisfechos e insatisfechos</li> <li>Causas Principales: Razones de insatisfacci\u00f3n o requerimientos frecuentes</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_1","title":"Funcionalidades:","text":"<ul> <li>Seguimiento del NPS en tiempo real</li> <li>An\u00e1lisis de causas ra\u00edz de insatisfacci\u00f3n</li> <li>Enfoque en la resoluci\u00f3n eficiente de problemas</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#productividad-organizacional","title":"Productividad Organizacional","text":""},{"location":"05.Power_BI/00.Introduccion/#analisis-de-desempeno-y-calidad","title":"An\u00e1lisis de Desempe\u00f1o y Calidad","text":"<p>Objetivo: Presentar el comportamiento de resultados de las unidades educativas y su impacto en la calidad de formaci\u00f3n y gesti\u00f3n organizacional.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-clave_1","title":"Elementos Clave:","text":"<ul> <li>Empresas/Afiliados/Beneficiarios Atendidos: Indicadores de alcance</li> <li>Calificaci\u00f3n de Satisfacci\u00f3n: Percepci\u00f3n de calidad (escala 1-10)</li> <li>Resultados por Sede: Efectividad de cada ubicaci\u00f3n</li> <li>Tasas de Certificaci\u00f3n y Deserci\u00f3n: Indicadores de eficacia formativa</li> <li>Incremento de Empresas: Crecimiento en demanda de servicios</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#panel-lateral-opciones-de-analisis","title":"Panel Lateral - Opciones de An\u00e1lisis:","text":"<ol> <li>Desempe\u00f1o: Visi\u00f3n general de cumplimiento y productividad</li> <li>Comportamientos Hist\u00f3ricos: Tendencias a lo largo del tiempo</li> <li>Comportamiento Financiero: Rentabilidad y costos operativos</li> <li>Experiencia de Usuario: Satisfacci\u00f3n y percepci\u00f3n</li> <li>An\u00e1lisis Miner\u00eda: Herramientas avanzadas para patrones</li> </ol>"},{"location":"05.Power_BI/00.Introduccion/#comportamientos-historicos","title":"Comportamientos Hist\u00f3ricos","text":"<p>Objetivo: Proporcionar visi\u00f3n longitudinal del desempe\u00f1o educativo para identificar tendencias y patrones temporales.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-destacados_1","title":"Elementos Destacados:","text":"<ul> <li>Cantidad de Graduados: Evoluci\u00f3n hist\u00f3rica de graduaciones</li> <li>Indicadores de Desempe\u00f1o: Datos agregados de empresas, afiliados y beneficiarios</li> <li>Gr\u00e1ficos Comparativos: Visualizaci\u00f3n de tendencias temporales</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_2","title":"Funcionalidades:","text":"<ul> <li>Identificaci\u00f3n de tendencias, picos y comportamientos estacionales</li> <li>Comparaciones entre diferentes per\u00edodos</li> <li>Correlaci\u00f3n con otros indicadores (deserci\u00f3n, certificaci\u00f3n)</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#comportamiento-financiero","title":"Comportamiento Financiero","text":"<p>Objetivo: Ofrecer perspectiva financiera del proceso educativo, destacando aportes, subsidios, inversi\u00f3n y ejecuci\u00f3n presupuestal.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-principales_1","title":"Elementos Principales:","text":"<ul> <li>Aportes y Subsidios: Montos y fuentes de financiaci\u00f3n</li> <li>Inversi\u00f3n y Ejecuci\u00f3n: Uso del presupuesto asignado</li> <li>Top 10 Empresas Aportantes: Principales contribuyentes</li> <li>Valor Pagado por Estado: Distribuci\u00f3n de pagos seg\u00fan estado</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_3","title":"Funcionalidades:","text":"<ul> <li>Seguimiento de ejecuci\u00f3n presupuestal</li> <li>Identificaci\u00f3n de principales aportantes</li> <li>Control de pagos y estado de cartera</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#experiencia-de-usuario-productividad","title":"Experiencia de Usuario (Productividad)","text":"<p>Objetivo: Brindar perspectiva clara de satisfacci\u00f3n integrando NPS, PQR por unidad y tasa de deserci\u00f3n.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-clave_2","title":"Elementos Clave:","text":"<ul> <li>PQR por Unidad: Peticiones, quejas y reclamos por \u00e1rea</li> <li>Net Promoter Score: \u00cdndice de recomendaci\u00f3n de servicios</li> <li>Deserci\u00f3n: Tasa de abandono de programas formativos</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_4","title":"Funcionalidades:","text":"<ul> <li>Integraci\u00f3n de PQR con \u00edndice NPS</li> <li>Enfoque en retenci\u00f3n de estudiantes</li> <li>Comparaci\u00f3n hist\u00f3rica de indicadores post-implementaci\u00f3n de mejoras</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#analisis-mineria","title":"An\u00e1lisis Miner\u00eda","text":"<p>Objetivo: Integrar t\u00e9cnicas de Process Mining para analizar secuencia y eficiencia de procesos educativos.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-principales_2","title":"Elementos Principales:","text":"<ul> <li>Mapa de Procesos: Recorrido gr\u00e1fico de actividades</li> <li>Indicadores de Eficiencia: Duraci\u00f3n promedio, repeticiones</li> <li>Visualizaci\u00f3n de Flujos: Transiciones entre estados de proceso</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_5","title":"Funcionalidades:","text":"<ul> <li>Descubrimiento de procesos reales vs. te\u00f3ricos</li> <li>Detecci\u00f3n de cuellos de botella y retrasos</li> <li>Optimizaci\u00f3n de flujos de trabajo</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#analisis-de-eficiencia","title":"An\u00e1lisis de Eficiencia","text":"<p>Objetivo: Proporcionar visi\u00f3n detallada de eficiencia en servicios educativos, enfocada en inversi\u00f3n, utilizaci\u00f3n de recursos y capacidad disponible.</p>"},{"location":"05.Power_BI/00.Introduccion/#areas-de-analisis","title":"\u00c1reas de An\u00e1lisis:","text":"<ol> <li>Educaci\u00f3n Formal: Programas acad\u00e9micos de larga duraci\u00f3n</li> <li>Educaci\u00f3n T\u00e9cnica: Formaciones t\u00e9cnicas o tecnol\u00f3gicas</li> <li>Educaci\u00f3n Continua: Cursos y diplomados de actualizaci\u00f3n</li> <li>Protecci\u00f3n Social: Programas y servicios sociales</li> </ol>"},{"location":"05.Power_BI/00.Introduccion/#indicadores-principales","title":"Indicadores Principales:","text":"<ul> <li>Horas Contratadas: Disponibilidad para formaci\u00f3n</li> <li>Reductores de Capacidad: Factores que disminuyen capacidad efectiva</li> <li>Movilidad Acad\u00e9mica: Intercambio entre sedes o programas</li> <li>Utilizaci\u00f3n de Recursos Digitales: Aprovechamiento de plataformas</li> <li>Inversi\u00f3n en Infraestructura: Mejoras f\u00edsicas y tecnol\u00f3gicas</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#educacion-tecnica","title":"Educaci\u00f3n T\u00e9cnica","text":"<p>Objetivo: Ofrecer panorama de eficiencia en gesti\u00f3n de Educaci\u00f3n T\u00e9cnica, resaltando capacidad y utilizaci\u00f3n.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-destacados_2","title":"Elementos Destacados:","text":"<ul> <li>Horas Contratadas vs. Horas en Uso: Relaci\u00f3n entre disponibilidad y uso efectivo</li> <li>Reductores por Turno/Evento: Factores que afectan capacidad</li> <li>Top Servicios M\u00e1s Usados: Recursos con mayor demanda</li> <li>Indicadores de Utilizaci\u00f3n: Porcentajes de ocupaci\u00f3n</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_6","title":"Funcionalidades:","text":"<ul> <li>Identificaci\u00f3n de cuellos de botella</li> <li>Priorizaci\u00f3n de recursos seg\u00fan demanda</li> <li>Optimizaci\u00f3n de oferta formativa</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#educacion-continua","title":"Educaci\u00f3n Continua","text":"<p>Objetivo: Brindar visi\u00f3n detallada de eficiencia en programas de Educaci\u00f3n Continua.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-clave_3","title":"Elementos Clave:","text":"<ul> <li>Horas Contratadas vs. Efectivas: Comparativa de tiempo programado vs. utilizado</li> <li>Uso del Tiempo y Sesiones: N\u00famero y duraci\u00f3n de actividades</li> <li>Asistencia de Usuarios: Participaci\u00f3n real vs. inscripciones</li> <li>Tendencia de Demanda: Variaci\u00f3n temporal en participaci\u00f3n</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_7","title":"Funcionalidades:","text":"<ul> <li>Detecci\u00f3n de ineficiencias en programaci\u00f3n</li> <li>An\u00e1lisis de evoluci\u00f3n de demanda</li> <li>Ajuste de oferta seg\u00fan participaci\u00f3n real</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#proteccion-social","title":"Protecci\u00f3n Social","text":"<p>Objetivo: Visi\u00f3n enfocada en eficiencia de programas de Protecci\u00f3n Social, cobertura y capacidad.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-principales_3","title":"Elementos Principales:","text":"<ul> <li>N\u00famero de Servicios: Variedad de servicios ofrecidos</li> <li>N\u00famero de Sedes: Infraestructura disponible</li> <li>N\u00famero de Beneficiarios: Personas atendidas</li> <li>Proyecci\u00f3n de Aforo: Capacidad m\u00e1xima vs. demanda real</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_8","title":"Funcionalidades:","text":"<ul> <li>Monitoreo de cobertura y capacidad</li> <li>Priorizaci\u00f3n de recursos seg\u00fan impacto</li> <li>An\u00e1lisis por programa o categor\u00eda</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#impacto-social-y-comunitario","title":"Impacto Social y Comunitario","text":""},{"location":"05.Power_BI/00.Introduccion/#analisis-por-servicio","title":"An\u00e1lisis por Servicio","text":"<p>Objetivo: Presentar impacto social de servicios ofrecidos, destacando atenci\u00f3n a poblaci\u00f3n vulnerable y satisfacci\u00f3n.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-clave_4","title":"Elementos Clave:","text":"<ul> <li>Porcentaje Promotores/Detractores: Satisfacci\u00f3n con servicios</li> <li>Atenci\u00f3n a Poblaci\u00f3n Vulnerable: Alcance inclusivo</li> <li>Afiliados/Empresas Atendidas: Volumen de usuarios</li> <li>Distribuci\u00f3n Socioecon\u00f3mica: Afiliados por estrato y g\u00e9nero</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_9","title":"Funcionalidades:","text":"<ul> <li>Medici\u00f3n de satisfacci\u00f3n y recomendaci\u00f3n</li> <li>Enfoque en inclusi\u00f3n y equidad</li> <li>Segmentaci\u00f3n interactiva por servicio o grupo poblacional</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#analisis-por-empresa","title":"An\u00e1lisis por Empresa","text":"<p>Objetivo: Perspectiva enfocada en empresas participantes, analizando relaci\u00f3n entre aportes, compra de servicios y subsidios.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-principales_4","title":"Elementos Principales:","text":"<ul> <li>N\u00famero de Empresas Atendidas: Organizaciones impactadas</li> <li>Aportes a la Demanda: Contribuci\u00f3n econ\u00f3mica empresarial</li> <li>Valor de Subsidios: Apoyo recibido por empresas</li> <li>Indicador Total: M\u00e9trica consolidada para comparaci\u00f3n</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_10","title":"Funcionalidades:","text":"<ul> <li>An\u00e1lisis de contribuci\u00f3n vs. beneficio</li> <li>Segmentaci\u00f3n por sector/tama\u00f1o</li> <li>Identificaci\u00f3n de oportunidades de alianza</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#relacion-de-servicios-y-aportes","title":"Relaci\u00f3n de Servicios y Aportes","text":"<p>Objetivo: Detallar relaci\u00f3n entre servicios ofrecidos y aportes empresariales, incluyendo distribuci\u00f3n por tipo de poblaci\u00f3n.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-destacados_3","title":"Elementos Destacados:","text":"<ul> <li>Tabla Servicios vs. Empresa: Detalle de servicios y aportes</li> <li>Aportes por Poblaci\u00f3n: Distribuci\u00f3n por segmentos poblacionales</li> <li>Indicadores Globales: Datos agregados de aportes y servicios</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_11","title":"Funcionalidades:","text":"<ul> <li>Visi\u00f3n integral de contribuci\u00f3n empresarial</li> <li>An\u00e1lisis de cobertura por poblaci\u00f3n</li> <li>Detecci\u00f3n de oportunidades de expansi\u00f3n</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#servicios-vendidos-y-subsidios-historicos","title":"Servicios Vendidos y Subsidios Hist\u00f3ricos","text":"<p>Objetivo: Perspectiva hist\u00f3rica de servicios vendidos y subsidios otorgados, evaluando evoluci\u00f3n de relaciones comerciales.</p>"},{"location":"05.Power_BI/00.Introduccion/#elementos-clave_5","title":"Elementos Clave:","text":"<ul> <li>Servicios Vendidos (Hist\u00f3rico): Evoluci\u00f3n temporal de servicios adquiridos</li> <li>Cantidad Subsidiada: Servicios o cupos con subsidio</li> <li>Valor Subsidiado: Monto econ\u00f3mico total en subsidios</li> <li>Gr\u00e1ficos Comparativos: Contraste entre ventas y subsidios</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#funcionalidades_12","title":"Funcionalidades:","text":"<ul> <li>An\u00e1lisis de tendencias hist\u00f3ricas</li> <li>Enfoque en retorno social y comercial</li> <li>Identificaci\u00f3n de patrones de compra</li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#diagrama-de-flujo-integral-del-sistema","title":"Diagrama de Flujo Integral del Sistema","text":"<pre><code>flowchart TD\n    A[An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n] --&gt; B1[Indicadores de Utilizaci\u00f3n]\n    A --&gt; B2[Indicadores de Capacidad]\n    A --&gt; B3[Experiencia de Usuario]\n\n    A --&gt; C[Productividad Organizacional]\n    C --&gt; C1[An\u00e1lisis de Desempe\u00f1o y Calidad]\n    C1 --&gt; C1a[Comportamientos Hist\u00f3ricos]\n    C1 --&gt; C1b[Comportamiento Financiero]\n    C1 --&gt; C1c[Experiencia de Usuario]\n    C1 --&gt; C1d[An\u00e1lisis Miner\u00eda]\n\n    C --&gt; C2[An\u00e1lisis de Eficiencia]\n    C2 --&gt; C2a[Educaci\u00f3n T\u00e9cnica]\n    C2 --&gt; C2b[Educaci\u00f3n Continua]\n    C2 --&gt; C2c[Protecci\u00f3n Social]\n\n    A --&gt; D[Impacto Social y Comunitario]\n    D --&gt; D1[An\u00e1lisis por Servicio]\n    D --&gt; D2[An\u00e1lisis por Empresa]\n    D2 --&gt; D2a[Relaci\u00f3n de Servicios y Aportes]\n    D2 --&gt; D2b[Servicios Vendidos y Subsidios]</code></pre>"},{"location":"05.Power_BI/00.Introduccion/#conclusion","title":"Conclusi\u00f3n","text":"<p>El sistema de dashboards para el proceso de Educaci\u00f3n constituye una herramienta anal\u00edtica integral que permite:</p> <ol> <li>Toma de decisiones basada en datos a trav\u00e9s de m\u00faltiples perspectivas complementarias</li> <li>Monitoreo continuo de indicadores operativos, financieros y de impacto</li> <li>Identificaci\u00f3n proactiva de oportunidades de mejora en eficiencia y calidad</li> <li>Evaluaci\u00f3n del retorno social de las inversiones en educaci\u00f3n</li> <li>Seguimiento de la experiencia del usuario para optimizar servicios</li> </ol> <p>Esta estructura modular y completa facilita tanto an\u00e1lisis a nivel estrat\u00e9gico como profundizaciones espec\u00edficas en cada dimensi\u00f3n del proceso educativo, permitiendo a los responsables adaptar sus estrategias seg\u00fan las necesidades identificadas y los resultados obtenidos.</p>"},{"location":"05.Power_BI/01.Dashboard%20copy/","title":"01.Dashboard copy","text":""},{"location":"05.Power_BI/01.Dashboard%20copy/#analisis-del-perfil-del-proceso-de-educacion","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el estado general del proceso de Educaci\u00f3n y sus unidades de negocio a la fecha de corte. En la parte superior, se muestra un men\u00fa de navegaci\u00f3n que permite explorar diferentes an\u00e1lisis estrat\u00e9gicos. A la izquierda, se encuentran opciones para analizar aspectos clave como Totales de Negocio, Utilizaci\u00f3n, Capacidad F\u00edsica y Experiencia de Usuario. Al centro y a la derecha, se destacan indicadores estrat\u00e9gicos como empresas atendidas, afiliados atendidos, beneficiarios, servicios ofertados y vendidos, as\u00ed como informaci\u00f3n sobre aportes y subsidios. Esto permite un an\u00e1lisis integral y detallado de los datos.</p>"},{"location":"05.Power_BI/01.Dashboard%20copy/#productividad-organizacional-analisis-de-desempeno-y-calidad","title":"Productividad Organizacional - An\u00e1lisis de Desempe\u00f1o y calidad","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el comportamiento de los resultados de las unidades de Educaci\u00f3n y c\u00f3mo impactan en la calidad, tanto de la formaci\u00f3n como de la gesti\u00f3n de la unidad. En la parte superior, se encuentra un men\u00fa de navegaci\u00f3n que facilita el acceso a an\u00e1lisis relacionados con desempe\u00f1o, eficiencia y otras perspectivas estrat\u00e9gicas. A la izquierda, se ofrecen opciones para analizar aspectos clave como Desempe\u00f1o, Comportamientos hist\u00f3ricos, Comportamiento financiero, Experiencia de Usuario y An\u00e1lisis Miner\u00eda. Al centro y derecha, se destacan indicadores clave como empresas afiliadas, afiliados atendidos y beneficiarios atendidos. Adem\u00e1s, se puede seleccionar el proceso de matr\u00edcula para analizar variantes espec\u00edficas a trav\u00e9s del control deslizante.</p>"},{"location":"05.Power_BI/01.Dashboard%20copy/#productividad-organizacional-analisis-de-eficiencia","title":"Productividad Organizacional - An\u00e1lisis de Eficiencia","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el comportamiento de la capacidad, inversi\u00f3n en infraestructura y los principales indicadores de productividad. En la parte superior, se encuentra un men\u00fa de navegaci\u00f3n que permite explorar an\u00e1lisis estrat\u00e9gicos relacionados con desempe\u00f1o, eficiencia y otras perspectivas. A la izquierda, se ofrecen opciones para analizar \u00e1reas como Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua y Protecci\u00f3n Social. Al centro y a la derecha, se presentan indicadores clave como horas contratadas, inversi\u00f3n en infraestructura f\u00edsica y tecnol\u00f3gica, porcentaje de utilizaci\u00f3n de bibliotecas virtuales y movilidad acad\u00e9mica. Adem\u00e1s, se incluyen gr\u00e1ficos sobre reductores de capacidad contratada para facilitar el an\u00e1lisis detallado.</p>"},{"location":"05.Power_BI/01.Dashboard%20copy/#impacto-social-y-comunitario-analisis-por-servicio","title":"Impacto Social y Comunitario - An\u00e1lisis por Servicio","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el impacto social y comunitario de los servicios ofrecidos por el proceso de Educaci\u00f3n. En la parte superior, se encuentra un men\u00fa de navegaci\u00f3n para explorar diferentes an\u00e1lisis estrat\u00e9gicos. A la izquierda, se ofrecen opciones para analizar \u00e1reas como Educaci\u00f3n Formal, Educaci\u00f3n para el Trabajo, Desarrollo Empresarial y Protecci\u00f3n Social. En el centro y a la derecha, se destacan indicadores clave como porcentaje de detractores, porcentaje de promotores, atenci\u00f3n a poblaci\u00f3n vulnerable, afiliados atendidos y empresas atendidas. Adem\u00e1s, se incluyen gr\u00e1ficos que detallan servicios ofertados, afiliados por categor\u00eda, g\u00e9nero y estrato, as\u00ed como el recuento de actividades realizadas y empresas afiliadas por fecha.</p>"},{"location":"05.Power_BI/01.Dashboard%20copy/#impacto-social-y-comunitario-analisis-por-empresa","title":"Impacto Social y Comunitario - An\u00e1lisis por Empresa","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el impacto social de los servicios ofrecidos por el proceso de Educaci\u00f3n, agrupados por empresas. En la parte superior, se encuentra un men\u00fa de navegaci\u00f3n para explorar an\u00e1lisis estrat\u00e9gicos. A la izquierda, se ofrecen opciones para analizar indicadores por empresa, relaci\u00f3n de servicios y aportes, as\u00ed como servicios vendidos y subsidios hist\u00f3ricos. Al centro y derecha, se destacan indicadores como cantidad de aportes de empresas atendidas en Educaci\u00f3n, valor de subsidios a la demanda y n\u00famero de servicios vendidos clasificados por tipo de operaci\u00f3n. Esta visualizaci\u00f3n permite realizar un an\u00e1lisis detallado de los datos hist\u00f3ricos de servicios y subsidios.</p>"},{"location":"05.Power_BI/01.Dashboard/","title":"01. DASHBOARD","text":""},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n","text":"<p>Objetivo de la Visualizaci\u00f3n: Proporcionar una visi\u00f3n integral del proceso de Educaci\u00f3n, resaltando indicadores estrat\u00e9gicos y datos clave sobre el estado actual de cada unidad de negocio. Con esta vista se busca facilitar la toma de decisiones y el monitoreo de aspectos relevantes, como el n\u00famero de empresas atendidas, afiliados, beneficiarios y servicios ofertados o vendidos, as\u00ed como la relaci\u00f3n con aportes y subsidios.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Incluye secciones para navegar entre distintos an\u00e1lisis estrat\u00e9gicos (por ejemplo, Productividad Organizacional, Impacto Social y Comunitario, etc.).  </li> <li>Permite al usuario cambiar f\u00e1cilmente de una perspectiva a otra sin salir de la vista principal.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo: </p> <ul> <li>Contiene opciones para profundizar en aspectos clave del proceso de Educaci\u00f3n, tales como:  </li> <li>Unidades de Negocio: Permite filtrar o seleccionar la unidad espec\u00edfica a analizar.  </li> <li>Totales de Negocio: Proporciona un resumen de datos agregados (por ejemplo, ingresos totales, servicios totales, etc.).  </li> <li>Utilizaci\u00f3n: Muestra informaci\u00f3n relacionada con el uso de servicios o recursos.  </li> <li>Capacidad F\u00edsica: Indica la disponibilidad o capacidad instalada en la infraestructura de educaci\u00f3n.  </li> <li>Experiencia de Usuario: Brinda informaci\u00f3n sobre la satisfacci\u00f3n o percepciones de los beneficiarios.</li> </ul> </li> <li> <p>Zona Central de Indicadores Generales Estrat\u00e9gicos: </p> <ul> <li>Presenta m\u00e9tricas relevantes del proceso de Educaci\u00f3n, como:  </li> <li>Empresas Atendidas: N\u00famero total de organizaciones que han recibido servicios de la instituci\u00f3n.  </li> <li>Afiliados Atendidos: Cantidad de afiliados que han accedido a servicios de educaci\u00f3n.  </li> <li>Beneficiarios Atendidos: Personas que se han beneficiado directa o indirectamente de los servicios ofertados.  </li> <li>Servicios Ofertados / Vendidos: Comparaci\u00f3n entre la cantidad de servicios disponibles y los efectivamente vendidos o prestados.  </li> <li>Aportes y Subsidios: Informaci\u00f3n sobre la financiaci\u00f3n y subsidios asignados, con indicadores de valor total y cobertura.</li> </ul> </li> <li> <p>Visualizaciones de Datos y Tablas de Resumen: </p> <ul> <li>Gr\u00e1ficos de barras, l\u00edneas o tarjetas num\u00e9ricas que facilitan la lectura de los KPIs (Indicadores Clave de Desempe\u00f1o).  </li> <li>Tablas din\u00e1micas que muestran informaci\u00f3n detallada y permiten realizar comparaciones r\u00e1pidas.</li> </ul> </li> <li> <p>Filtros y Segmentaciones (Slicers): </p> <ul> <li>Ubicados normalmente en la parte derecha o superior, ayudan a refinar la informaci\u00f3n por per\u00edodos de tiempo, tipo de servicio, unidad de negocio, etc.  </li> <li>Aportan interactividad, permitiendo que los gr\u00e1ficos y tablas se actualicen en tiempo real seg\u00fan las selecciones del usuario.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave","title":"Funcionalidades Clave","text":"<ul> <li> <p>Interactividad:   Al seleccionar un filtro o hacer clic en un elemento espec\u00edfico (por ejemplo, una categor\u00eda de servicio), el resto de visualizaciones se ajusta autom\u00e1ticamente para mostrar datos relevantes a esa selecci\u00f3n.</p> </li> <li> <p>An\u00e1lisis Comparativo:   Permite comparar per\u00edodos (por ejemplo, mes actual vs. mes anterior) o tipos de servicios (Educaci\u00f3n Formal vs. Educaci\u00f3n para el Trabajo), brindando una perspectiva m\u00e1s completa de la evoluci\u00f3n y el desempe\u00f1o.</p> </li> <li> <p>Insights R\u00e1pidos:   Los indicadores principales se encuentran en la parte m\u00e1s visible de la pantalla, lo que facilita la identificaci\u00f3n de tendencias, alertas o \u00e1reas que requieran atenci\u00f3n inmediata.</p> </li> <li> <p>Drill-down / Drill-through:   Algunas visualizaciones pueden ofrecer la posibilidad de profundizar en niveles de detalle (por ejemplo, de la vista general de servicios ofertados a un desglose por categor\u00eda o por poblaci\u00f3n atendida).</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-indicadores-de-utilizacion","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n - Indicadores de Utilizaci\u00f3n","text":"<p>Objetivo de la Visualizaci\u00f3n: Proporcionar una perspectiva detallada de la utilizaci\u00f3n de los servicios educativos, abarcando el n\u00famero de afiliados, empresas y beneficiarios atendidos, as\u00ed como la cobertura de dichos servicios por categor\u00eda. Adem\u00e1s, se destacan datos sobre promoci\u00f3n, deserci\u00f3n y la recuperaci\u00f3n de afiliados, permitiendo a los usuarios comprender la efectividad y alcance de las acciones emprendidas en el proceso de Educaci\u00f3n.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_1","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite desplazarse entre distintos an\u00e1lisis estrat\u00e9gicos relacionados con la Productividad Organizacional y el Impacto Social y Comunitario.  </li> <li>Facilita el cambio de vista sin perder el contexto de los datos.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo: </p> <ul> <li>Contiene las secciones que agrupan los aspectos a analizar (p. ej., Unidades de Negocio, Totales de Negocio, Utilizaci\u00f3n, Capacidad F\u00edsica, Experiencia de Usuario).  </li> <li>Permite filtrar la informaci\u00f3n seg\u00fan la necesidad de cada usuario, enfoc\u00e1ndose en indicadores de utilizaci\u00f3n o profundizando en otros aspectos como la capacidad instalada o la percepci\u00f3n de los usuarios.</li> </ul> </li> <li> <p>Zona Central - Indicadores de Utilizaci\u00f3n: </p> <ul> <li>Afiliados Atendidos: Muestra la cantidad de afiliados que han utilizado los servicios de educaci\u00f3n en el per\u00edodo seleccionado.  </li> <li>Empresas Atendidas: Indica el n\u00famero de organizaciones que han participado o se han beneficiado de los servicios.  </li> <li>Beneficiarios Atendidos: Refleja cu\u00e1ntas personas han recibido directa o indirectamente servicios educativos.  </li> <li>Cobertura por Categor\u00eda: Destaca cu\u00e1ntas personas de cada categor\u00eda (A, B, C, etc.) han sido atendidas o est\u00e1n cubiertas por los programas educativos.  </li> <li>Promoci\u00f3n y Deserci\u00f3n: Se\u00f1ala la tasa de usuarios que avanzan en sus procesos formativos (promoci\u00f3n) o que abandonan (deserci\u00f3n).  </li> <li>Recupera: Podr\u00eda referirse a la tasa de reenganche o recaptura de usuarios que, tras desertar, regresan a los programas educativos.</li> </ul> </li> <li> <p>Panel Inferior o Secci\u00f3n de Detalle (si aplica): </p> <ul> <li>Puede incluir gr\u00e1ficas de tendencia o tablas que profundizan en la distribuci\u00f3n de usuarios por categor\u00edas, periodos de tiempo, ubicaci\u00f3n geogr\u00e1fica u otras variables de inter\u00e9s.</li> </ul> </li> <li> <p>Filtros y Segmentaciones (Slicers): </p> <ul> <li>Permiten ajustar la vista por rangos de fechas, tipos de servicios, niveles de educaci\u00f3n u otras clasificaciones internas de la organizaci\u00f3n.  </li> <li>La actualizaci\u00f3n de la informaci\u00f3n en tiempo real facilita el an\u00e1lisis comparativo y la toma de decisiones \u00e1giles.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_1","title":"Funcionalidades Clave","text":"<ul> <li> <p>Interactividad:   Cada elemento (gr\u00e1fico, tarjeta, tabla) responde a las selecciones de filtros, ofreciendo una visi\u00f3n personalizada y ajustada a las necesidades del analista.</p> </li> <li> <p>Comparaciones Temporales:   Posibilidad de comparar indicadores (p. ej., n\u00famero de beneficiarios, cobertura por categor\u00eda) en diferentes periodos, para identificar tendencias de crecimiento o disminuci\u00f3n.</p> </li> <li> <p>Enfoque en el Usuario:   M\u00e9tricas como Promoci\u00f3n, Deserci\u00f3n y Recupera se centran en la experiencia y trayectoria de los afiliados, ayudando a la organizaci\u00f3n a entender el grado de \u00e9xito y las \u00e1reas de oportunidad en los programas educativos.</p> </li> <li> <p>Desglose y Profundizaci\u00f3n (Drill-down):   Permite explorar los datos a mayor detalle, segmentando por unidades de negocio, zonas geogr\u00e1ficas, categor\u00edas de usuarios, etc.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-indicadores-de-capacidad","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n \u2013 Indicadores de Capacidad","text":"<p>Objetivo de la Visualizaci\u00f3n: Mostrar de manera clara y concisa la capacidad de prestaci\u00f3n del proceso de Educaci\u00f3n, a trav\u00e9s de la comparaci\u00f3n entre servicios ofertados y vendidos, as\u00ed como la distribuci\u00f3n de docentes por unidad. Con esta informaci\u00f3n, se busca entender el nivel de disponibilidad de recursos (humanos y de servicios) y su efectividad en t\u00e9rminos de comercializaci\u00f3n y alcance.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_2","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Proporciona acceso a los distintos m\u00f3dulos de an\u00e1lisis (por ejemplo, Productividad Organizacional, Impacto Social y Comunitario), permitiendo un cambio fluido entre vistas sin perder el contexto de la informaci\u00f3n.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo: </p> <ul> <li>Incluye opciones para analizar diferentes aspectos del proceso educativo, como Totales de Negocio, Utilizaci\u00f3n, Capacidad F\u00edsica y Experiencia de Usuario.  </li> <li>Facilita la selecci\u00f3n de la unidad de negocio o el tipo de indicador que se desea visualizar, ofreciendo una experiencia personalizada al usuario.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores de Capacidad: </p> <ul> <li>Servicios Ofertados por Unidad: Muestra, en formato gr\u00e1fico (por ejemplo, gr\u00e1fico circular o de barras), la proporci\u00f3n de servicios que cada unidad ofrece dentro del proceso de Educaci\u00f3n.  </li> <li>Servicios Vendidos por Unidad: Refleja cu\u00e1ntos de esos servicios ofertados se concretaron en ventas efectivas, permitiendo medir el \u00e9xito comercial o la demanda real.  </li> <li>Docentes por Unidad: Indica la cantidad y/o proporci\u00f3n de docentes asignados a cada unidad, brindando una visi\u00f3n de la distribuci\u00f3n de recursos humanos.  </li> <li>Indicadores Num\u00e9ricos Clave: Se pueden incluir tarjetas que destaquen totales globales (e.g., total de servicios ofertados, vendidos, docentes disponibles), ofreciendo una referencia r\u00e1pida del estado actual de la capacidad.</li> </ul> </li> <li> <p>Panel Inferior o Secci\u00f3n de Detalle (opcional): </p> <ul> <li>Puede contener tablas din\u00e1micas o gr\u00e1ficos complementarios que permitan un an\u00e1lisis m\u00e1s granular de los datos (por ejemplo, evoluci\u00f3n hist\u00f3rica de servicios ofertados vs. vendidos, categorizaci\u00f3n de docentes por especialidad, etc.).</li> </ul> </li> <li> <p>Filtros y Segmentaciones (Slicers): </p> <ul> <li>Ubicados normalmente a la derecha o en la parte superior, ofrecen la posibilidad de filtrar por fechas, tipos de servicios, categor\u00edas de unidades de negocio u otras variables relevantes.  </li> <li>Actualizan de forma interactiva los gr\u00e1ficos y tablas, facilitando el an\u00e1lisis comparativo y la toma de decisiones informada.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_2","title":"Funcionalidades Clave","text":"<ul> <li> <p>Comparaci\u00f3n Oferta vs. Venta:   Permite identificar la efectividad de cada unidad en convertir su oferta de servicios en ventas reales, aportando insights sobre posibles brechas o excedentes de capacidad.</p> </li> <li> <p>Distribuci\u00f3n de Recursos Humanos:   El indicador de docentes por unidad ofrece una visi\u00f3n clara de c\u00f3mo se reparten los recursos humanos a lo largo de las diferentes \u00e1reas, y si existen desequilibrios que requieran ajuste.</p> </li> <li> <p>An\u00e1lisis Interactivo y Din\u00e1mico:   Los usuarios pueden profundizar en \u00e1reas espec\u00edficas mediante la selecci\u00f3n de filtros, obteniendo informaci\u00f3n segmentada por periodos de tiempo, tipo de programa, poblaci\u00f3n objetivo, etc.</p> </li> <li> <p>Seguimiento de Tendencias:   Al combinar los datos de capacidad con otros indicadores (como la experiencia de usuario o la rentabilidad), se puede hacer un seguimiento de tendencias y detectar oportunidades de mejora continua.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion-experiencia-de-usuario","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n \u2013 Experiencia de Usuario","text":"<p>Objetivo de la Visualizaci\u00f3n: Ofrecer una perspectiva integral de la satisfacci\u00f3n y experiencia de los usuarios dentro del proceso de Educaci\u00f3n, a trav\u00e9s de indicadores clave como el Net Promoter Score (NPS), tiempo de resoluci\u00f3n y principales causas de insatisfacci\u00f3n o incidencias. De esta forma, se busca identificar \u00e1reas de mejora y reforzar aquellas estrategias que promuevan una experiencia positiva.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_3","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite el acceso a diferentes m\u00f3dulos de an\u00e1lisis (Productividad Organizacional, Impacto Social y Comunitario, etc.), facilitando el cambio de vista sin salir del contexto general.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo: </p> <ul> <li>Incluye las secciones para profundizar en Totales de Negocio, Utilizaci\u00f3n, Capacidad F\u00edsica y Experiencia de Usuario.  </li> <li>Ayuda a filtrar o segmentar la informaci\u00f3n seg\u00fan las necesidades del usuario, enfoc\u00e1ndose en la experiencia y percepci\u00f3n de los beneficiarios.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores de Experiencia de Usuario: </p> <ul> <li>Net Promoter Score (NPS): Mide la disposici\u00f3n de los usuarios a recomendar los servicios de la organizaci\u00f3n.  </li> <li>Resoluci\u00f3n Promedio (en D\u00edas o Horas): Refleja el tiempo que se tarda en dar soluci\u00f3n a solicitudes, quejas o inquietudes de los usuarios.  </li> <li>Porcentaje de Promotores y Detractores: Muestra la proporci\u00f3n de usuarios altamente satisfechos (promotores) frente a quienes presentan una experiencia negativa (detractores).  </li> <li>Causas Principales: Se listan las razones o temas que generan mayor insatisfacci\u00f3n o requerimientos (por ejemplo, demoras en procesos, problemas de sincron\u00eda, etc.), lo que permite focalizar acciones correctivas.</li> </ul> </li> <li> <p>Visualizaciones Clave (Tarjetas y Gr\u00e1ficos): </p> <ul> <li>Tarjetas de KPI: Presentan de forma resumida el valor de NPS, el tiempo de resoluci\u00f3n y otros indicadores cr\u00edticos para la experiencia del usuario.  </li> <li>Tabla de Causas: Detalla las principales categor\u00edas de reclamos o incidencias, acompa\u00f1adas de su frecuencia o relevancia.</li> </ul> </li> <li> <p>Filtros y Segmentaciones (Slicers): </p> <ul> <li>Ubicados en la parte derecha o superior, permiten filtrar por per\u00edodo, tipo de servicio o unidad de negocio.  </li> <li>La interactividad hace posible analizar r\u00e1pidamente las variaciones en el NPS o en las causas de insatisfacci\u00f3n para diferentes segmentos de usuarios.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_3","title":"Funcionalidades Clave","text":"<ul> <li> <p>Seguimiento del NPS en Tiempo Real:   Permite monitorear la evoluci\u00f3n del \u00edndice de satisfacci\u00f3n y detectar tendencias positivas o negativas de manera oportuna.</p> </li> <li> <p>An\u00e1lisis de Causas Ra\u00edz:   La tabla con las principales causas de insatisfacci\u00f3n facilita la priorizaci\u00f3n de acciones correctivas, optimizando los recursos y esfuerzos para mejorar la experiencia del usuario.</p> </li> <li> <p>Comparaciones Temporales y Segmentadas:   Filtrar por fechas o categor\u00edas de usuarios (afiliados, beneficiarios, empresas) posibilita la identificaci\u00f3n de patrones espec\u00edficos y la evaluaci\u00f3n de estrategias de mejora.</p> </li> <li> <p>Enfoque en la Resoluci\u00f3n de Problemas:   El indicador de tiempo promedio de resoluci\u00f3n ayuda a medir la eficiencia de los procesos de atenci\u00f3n y a establecer metas de mejora continua.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y Calidad","text":"<p>Objetivo de la Visualizaci\u00f3n: Presentar el comportamiento de los resultados de las unidades de Educaci\u00f3n y su impacto en la calidad de la formaci\u00f3n y de la gesti\u00f3n organizacional. Con esta vista, se busca ofrecer indicadores clave de desempe\u00f1o, satisfacci\u00f3n y eficiencia que permitan a los responsables de \u00e1rea y directivos tomar decisiones basadas en datos y orientar acciones de mejora continua.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_4","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite cambiar entre diferentes an\u00e1lisis estrat\u00e9gicos (p. ej., Desempe\u00f1o, Eficiencia, Experiencia de Usuario, etc.).  </li> <li>Facilita el acceso a m\u00f3dulos espec\u00edficos de la plataforma, brindando una visi\u00f3n integral de la productividad organizacional.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 Opciones de An\u00e1lisis: </p> <ul> <li>Desempe\u00f1o: Ofrece una visi\u00f3n general del cumplimiento de metas y objetivos, as\u00ed como m\u00e9tricas de productividad.  </li> <li>Comportamientos Hist\u00f3ricos: Permite revisar tendencias a lo largo del tiempo, como la evoluci\u00f3n de indicadores de calidad o niveles de asistencia.  </li> <li>Comportamiento Financiero: Se centra en la rentabilidad y los costos asociados a la operaci\u00f3n educativa, relacionando la inversi\u00f3n con los resultados obtenidos.  </li> <li>Experiencia de Usuario: Profundiza en la satisfacci\u00f3n y percepci\u00f3n de los beneficiarios, incluyendo aspectos como NPS, tiempos de respuesta y retroalimentaci\u00f3n de usuarios.  </li> <li>An\u00e1lisis Miner\u00eda: Proporciona herramientas de an\u00e1lisis m\u00e1s avanzado (por ejemplo, miner\u00eda de datos) para descubrir patrones ocultos o correlaciones relevantes.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores de Desempe\u00f1o y Calidad: </p> <ul> <li>Empresas Atendidas, Afiliados Atendidos, Beneficiarios Atendidos: KPI que reflejan el alcance de los servicios educativos y la cobertura lograda en el per\u00edodo analizado.  </li> <li>Calificaci\u00f3n de Satisfacci\u00f3n: Mide la percepci\u00f3n de calidad de los programas, habitualmente en una escala (por ejemplo, 8,5/10).  </li> <li>Resultados Sede / Tasa de Certificaci\u00f3n / Tasa de Deserci\u00f3n: Indicadores espec\u00edficos que eval\u00faan la eficacia formativa y la permanencia de los estudiantes en los programas.  </li> <li>Incremento de Empresas que Compran el Servicio: Refleja el crecimiento en la demanda de los servicios de educaci\u00f3n por parte de empresas afiliadas o externas.</li> </ul> </li> <li> <p>Visualizaciones Clave: </p> <ul> <li>Gr\u00e1ficos de Barras o L\u00edneas: Comparan periodos o muestran la evoluci\u00f3n de un indicador (e.g., empresas atendidas a lo largo del a\u00f1o).  </li> <li>Tarjetas de KPI: Destacan m\u00e9tricas principales (e.g., calificaci\u00f3n promedio, porcentaje de cumplimiento de metas).  </li> <li>Tablas de Detalle: Pueden presentar informaci\u00f3n m\u00e1s granular sobre las unidades, sedes o programas espec\u00edficos.</li> </ul> </li> <li> <p>Secci\u00f3n de Filtros y Segmentaciones (Slicers): </p> <ul> <li>Permiten ajustar el an\u00e1lisis por fecha, tipo de programa, regi\u00f3n, categor\u00eda de beneficiarios u otras variables relevantes.  </li> <li>Habilitan la personalizaci\u00f3n de la informaci\u00f3n mostrada y el an\u00e1lisis comparativo entre diferentes segmentos.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_4","title":"Funcionalidades Clave","text":"<ul> <li> <p>Monitoreo de Indicadores de Calidad:   La vista incluye m\u00e9tricas de satisfacci\u00f3n, certificaci\u00f3n y deserci\u00f3n, proporcionando una imagen clara de la calidad educativa y de gesti\u00f3n.</p> </li> <li> <p>An\u00e1lisis de Tendencias y Comparaciones Temporales:   El usuario puede identificar variaciones positivas o negativas en el desempe\u00f1o y la calidad, tomando medidas correctivas oportunas.</p> </li> <li> <p>Enfoque Integral del Desempe\u00f1o:   Al abarcar tanto aspectos de formaci\u00f3n (ej. calificaciones, deserci\u00f3n) como de gesti\u00f3n (cumplimiento de metas, rentabilidad), se obtiene una visi\u00f3n completa de la productividad organizacional.</p> </li> <li> <p>Segmentaci\u00f3n Interactiva:   El uso de slicers o filtros hace posible profundizar en datos espec\u00edficos, como la evoluci\u00f3n de la satisfacci\u00f3n por sede o la tasa de certificaci\u00f3n en un programa particular.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad-comportamientos-historicos","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y Calidad (Comportamientos Hist\u00f3ricos)","text":"<p>Objetivo de la Visualizaci\u00f3n: Proporcionar una visi\u00f3n longitudinal del desempe\u00f1o de la organizaci\u00f3n en el \u00e1mbito educativo, permitiendo a los usuarios identificar tendencias, picos y patrones a lo largo del tiempo. En particular, se resalta la Cantidad de Graduados y otros indicadores relacionados con la calidad y los resultados de la formaci\u00f3n, ofreciendo una base s\u00f3lida para la toma de decisiones estrat\u00e9gicas.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_5","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Facilita el acceso a las distintas secciones de an\u00e1lisis estrat\u00e9gico (Desempe\u00f1o, Eficiencia, Experiencia de Usuario, entre otros).  </li> <li>Mantiene la coherencia con las dem\u00e1s p\u00e1ginas de Productividad Organizacional, permitiendo un recorrido fluido entre perspectivas.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 Opciones de An\u00e1lisis: </p> <ul> <li>Desempe\u00f1o: Muestra indicadores globales de productividad y calidad.  </li> <li>Comportamientos Hist\u00f3ricos: Se centra en la evoluci\u00f3n temporal de los KPIs (por ejemplo, graduados, certificaciones, calificaciones).  </li> <li>Comportamiento Financiero: Profundiza en la rentabilidad y costos asociados a la operaci\u00f3n educativa.  </li> <li>Experiencia de Usuario: Enfatiza la satisfacci\u00f3n y percepci\u00f3n de los beneficiarios a trav\u00e9s de indicadores como NPS o tiempos de respuesta.  </li> <li>An\u00e1lisis Miner\u00eda: Integra herramientas de miner\u00eda de datos para encontrar patrones m\u00e1s complejos.</li> </ul> </li> <li> <p>Zona Central \u2013 Visualizaci\u00f3n de Comportamientos Hist\u00f3ricos: </p> <ul> <li>Cantidad de Graduados (Gr\u00e1fico de L\u00ednea): Refleja la evoluci\u00f3n del n\u00famero de graduados en un periodo determinado, permitiendo identificar tendencias, estacionalidades o impactos de pol\u00edticas espec\u00edficas.  </li> <li>Indicadores de Desempe\u00f1o (Tarjetas o Cuadros Resumen): Incluyen datos agregados de empresas atendidas, afiliados, beneficiarios, y/o tasas de aprobaci\u00f3n o deserci\u00f3n.  </li> <li>Detalle de Indicadores: Puede presentar una tabla o listado con el desglose de cada indicador (e.g., graduados por programa o sede) para un an\u00e1lisis m\u00e1s granular.</li> </ul> </li> <li> <p>Panel Inferior o Secundario (opcional): </p> <ul> <li>Puede mostrar comparaciones temporales adicionales (por ejemplo, variaci\u00f3n interanual de graduados, porcentaje de incremento o disminuci\u00f3n).  </li> <li>Incluye filtros que permiten segmentar la informaci\u00f3n por tipo de programa, unidad de negocio, fecha, entre otros.</li> </ul> </li> <li> <p>Slicers y Segmentaciones (Filtros): </p> <ul> <li>Permiten al usuario ajustar la visualizaci\u00f3n por rango de fechas, categor\u00eda de formaci\u00f3n, sede o cualquier otra dimensi\u00f3n relevante.  </li> <li>La interactividad asegura que los gr\u00e1ficos y tarjetas se actualicen de manera inmediata al seleccionar nuevos criterios.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_5","title":"Funcionalidades Clave","text":"<ul> <li> <p>An\u00e1lisis de Tendencias:   El gr\u00e1fico de l\u00ednea de Cantidad de Graduados facilita la identificaci\u00f3n de picos, ca\u00eddas o comportamientos estacionales, as\u00ed como el impacto de iniciativas espec\u00edficas (nuevos programas, becas, subsidios, etc.).</p> </li> <li> <p>Comparaciones Temporales:   Con la posibilidad de filtrar por a\u00f1os, semestres o trimestres, el usuario puede observar c\u00f3mo evolucionan los indicadores en distintos horizontes de tiempo.</p> </li> <li> <p>Detalle Interactivo (Drill-down):   Al hacer clic en una serie o punto espec\u00edfico, se puede profundizar en la informaci\u00f3n (por ejemplo, graduados por programa, por sede o por modalidad).</p> </li> <li> <p>Correlaci\u00f3n con Otros Indicadores:   El panel puede complementarse con m\u00e9tricas de deserci\u00f3n, tasas de certificaci\u00f3n o satisfacci\u00f3n del estudiante para entender c\u00f3mo cada uno influye en la productividad global.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad-comportamiento-financiero","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y Calidad (Comportamiento Financiero)","text":"<p>Objetivo de la Visualizaci\u00f3n: Ofrecer una perspectiva financiera del proceso de Educaci\u00f3n dentro de la organizaci\u00f3n, destacando el comportamiento de los aportes, subsidios, inversi\u00f3n y ejecuci\u00f3n presupuestal. Adicionalmente, se muestran indicadores que permiten identificar las principales fuentes de ingresos (empresas aportantes) y el estado de los pagos realizados, brindando una base s\u00f3lida para la toma de decisiones estrat\u00e9gicas y el control de la gesti\u00f3n financiera.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_6","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Ubicado en la parte superior, permite alternar entre diferentes m\u00f3dulos de Productividad Organizacional, como Desempe\u00f1o, Eficiencia, Experiencia de Usuario y otros enfoques estrat\u00e9gicos.  </li> <li>Facilita el recorrido por distintas perspectivas sin perder el contexto general de la informaci\u00f3n.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 Opciones de An\u00e1lisis: </p> <ul> <li>Desempe\u00f1o: Muestra la visi\u00f3n global de la productividad y calidad de la educaci\u00f3n.  </li> <li>Comportamientos Hist\u00f3ricos: Proporciona la evoluci\u00f3n temporal de indicadores clave.  </li> <li>Comportamiento Financiero: Enfatiza la distribuci\u00f3n de aportes, subsidios, ejecuci\u00f3n e inversi\u00f3n, as\u00ed como el estado de pagos y las principales empresas aportantes.  </li> <li>Experiencia de Usuario: Se enfoca en la percepci\u00f3n y satisfacci\u00f3n de afiliados y beneficiarios.  </li> <li>An\u00e1lisis Miner\u00eda: Profundiza en el an\u00e1lisis de datos, buscando correlaciones y patrones m\u00e1s complejos.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores Financieros Clave: </p> <ul> <li>Aportes y Subsidios: Refleja los montos y fuentes de financiaci\u00f3n que sostienen los programas educativos, as\u00ed como los subsidios otorgados a los beneficiarios.  </li> <li>Inversi\u00f3n y Ejecuci\u00f3n: Muestra cu\u00e1nto se ha invertido y el porcentaje de ejecuci\u00f3n respecto al presupuesto asignado, permitiendo evaluar la eficiencia del gasto.  </li> <li>Top 10 Empresas Aportantes: Destaca las principales empresas que contribuyen con recursos, ordenadas por el valor de sus aportes.  </li> <li>Valor Pagado por Estado de Pago: Visualiza la distribuci\u00f3n de los pagos realizados seg\u00fan su estado (aprobado, en proceso, etc.), facilitando el seguimiento y control financiero.</li> </ul> </li> <li> <p>Visualizaciones de Apoyo (Gr\u00e1ficos y Tablas): </p> <ul> <li>Gr\u00e1ficos de Barras o Tartas: Para ilustrar la composici\u00f3n de aportes, subsidios y pagos por estado.  </li> <li>Tablas Din\u00e1micas: Muestran detalles granulares de inversi\u00f3n, ejecuci\u00f3n y contribuciones, permitiendo un an\u00e1lisis m\u00e1s exhaustivo.</li> </ul> </li> <li> <p>Filtros y Segmentaciones (Slicers): </p> <ul> <li>Ubicados en la parte derecha o superior, habilitan la selecci\u00f3n de per\u00edodos de tiempo, categor\u00edas de inversi\u00f3n, tipos de subsidio u otras dimensiones relevantes.  </li> <li>La actualizaci\u00f3n de las m\u00e9tricas se produce en tiempo real al cambiar los filtros, aportando una experiencia de an\u00e1lisis din\u00e1mico.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_6","title":"Funcionalidades Clave","text":"<ul> <li> <p>Seguimiento de la Ejecuci\u00f3n Presupuestal:   Los indicadores de inversi\u00f3n y ejecuci\u00f3n permiten evaluar la efectividad en el uso de los recursos, comparando lo presupuestado vs. lo ejecutado.</p> </li> <li> <p>Identificaci\u00f3n de Principales Aportantes:   La lista de Top 10 Empresas Aportantes facilita la detecci\u00f3n de fuentes de financiamiento m\u00e1s relevantes, permitiendo planificar acciones de fidelizaci\u00f3n o b\u00fasqueda de nuevos aportes.</p> </li> <li> <p>Control de Pagos y Estado de Cartera:   El desglose del Valor Pagado por Estado de Pago ayuda a supervisar los pagos pendientes, en tr\u00e1mite o completados, reduciendo riesgos financieros.</p> </li> <li> <p>An\u00e1lisis Comparativo y Segmentado:   La posibilidad de filtrar por fechas, unidades de negocio o categor\u00edas de servicios aporta flexibilidad para comparar comportamientos financieros en distintos escenarios.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad-experiencia-de-usuario","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y Calidad (Experiencia de Usuario)","text":"<p>Objetivo de la Visualizaci\u00f3n: Brindar una perspectiva clara de la satisfacci\u00f3n y la experiencia de los usuarios dentro de la organizaci\u00f3n, integrando m\u00e9tricas de Net Promoter Score (NPS), PQR (Peticiones, Quejas y Reclamos) por Unidad y la tasa de Deserci\u00f3n. De esta forma, se pueden identificar oportunidades de mejora y ajustar estrategias para elevar la calidad del servicio y la retenci\u00f3n de los beneficiarios.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_7","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Ubicado en la parte superior, permite alternar entre distintas secciones de an\u00e1lisis de Productividad Organizacional (Desempe\u00f1o, Comportamientos Hist\u00f3ricos, Comportamiento Financiero, etc.).  </li> <li>Garantiza una experiencia de usuario coherente, manteniendo el contexto al cambiar de vista.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 Opciones de An\u00e1lisis: </p> <ul> <li>Desempe\u00f1o: Muestra indicadores globales de productividad y resultados.  </li> <li>Comportamientos Hist\u00f3ricos: Profundiza en la evoluci\u00f3n temporal de las m\u00e9tricas clave.  </li> <li>Comportamiento Financiero: Destaca la asignaci\u00f3n de recursos y la rentabilidad.  </li> <li>Experiencia de Usuario: Se centra en la satisfacci\u00f3n de afiliados, empresas y beneficiarios, incorporando aspectos como el NPS y la gesti\u00f3n de PQR.  </li> <li>An\u00e1lisis Miner\u00eda: Ofrece funciones avanzadas de miner\u00eda de datos para detectar patrones ocultos.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores de Experiencia de Usuario y Desempe\u00f1o Asociado: </p> <ul> <li>PQR por Unidad: Muestra la cantidad de peticiones, quejas y reclamos en cada unidad de negocio, reflejando la incidencia de problemas o inconformidades.  </li> <li>Net Promoter Score (NPS): Indica la probabilidad de que los usuarios recomienden los servicios, siendo un \u00edndice clave de satisfacci\u00f3n.  </li> <li>Deserci\u00f3n: Expone la tasa de usuarios que abandonan el proceso formativo, proporcionando se\u00f1ales sobre la efectividad de los programas y la retenci\u00f3n de beneficiarios.  </li> <li>Indicadores de Satisfacci\u00f3n y Resoluci\u00f3n: Puede incluir m\u00e9tricas como el tiempo promedio de resoluci\u00f3n de PQR o la satisfacci\u00f3n post-resoluci\u00f3n.</li> </ul> </li> <li> <p>Visualizaciones Clave (Gr\u00e1ficos y Tarjetas): </p> <ul> <li>Tarjetas de KPI: Resumen valores principales de NPS, PQR y deserci\u00f3n, facilitando la lectura r\u00e1pida de los resultados.  </li> <li>Gr\u00e1ficos de Barras o L\u00edneas: Comparan las PQR entre distintas unidades o muestran la tendencia del NPS y la deserci\u00f3n a lo largo del tiempo.  </li> <li>Tablas Din\u00e1micas: Permiten ver detalles sobre las causas de PQR, segmentaci\u00f3n de la deserci\u00f3n o la composici\u00f3n de los promotores/detractores.</li> </ul> </li> <li> <p>Slicers y Filtros: </p> <ul> <li>Ubicados a la derecha o en la parte superior, posibilitan filtrar por per\u00edodos, tipos de servicio, unidades de negocio, entre otros criterios.  </li> <li>Actualizan de manera din\u00e1mica los gr\u00e1ficos y tarjetas, habilitando an\u00e1lisis focalizados y comparativos.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_7","title":"Funcionalidades Clave","text":"<ul> <li> <p>Integraci\u00f3n de PQR y NPS:   Combinar la gesti\u00f3n de peticiones, quejas y reclamos con el Net Promoter Score ofrece una visi\u00f3n m\u00e1s completa de la experiencia de usuario, abarcando tanto los incidentes reportados como la percepci\u00f3n general del servicio.</p> </li> <li> <p>Enfoque en la Retenci\u00f3n (Deserci\u00f3n):   Al mostrar la tasa de deserci\u00f3n, se pueden identificar patrones que expliquen el abandono de los programas y planificar acciones de fidelizaci\u00f3n o mejora en la formaci\u00f3n.</p> </li> <li> <p>Segmentaci\u00f3n Interactiva:   Permite filtrar datos por unidad de negocio, rango de fechas o categor\u00eda de usuario, adaptando el an\u00e1lisis a necesidades espec\u00edficas.</p> </li> <li> <p>Comparaci\u00f3n Hist\u00f3rica:   Posibilita evaluar la evoluci\u00f3n de indicadores (por ejemplo, la reducci\u00f3n de PQR o el aumento del NPS) tras la implementaci\u00f3n de nuevas pol\u00edticas o mejoras en el servicio.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad-analisis-mineria","title":"Productividad Organizacional \u2013 An\u00e1lisis de Desempe\u00f1o y Calidad (An\u00e1lisis Miner\u00eda)","text":"<p>Objetivo de la Visualizaci\u00f3n: Integrar t\u00e9cnicas de Process Mining para profundizar en la secuencia y eficiencia de los procesos educativos y administrativos. A trav\u00e9s de la vista de An\u00e1lisis Miner\u00eda, los usuarios pueden descubrir cuellos de botella, patrones de comportamiento y oportunidades de mejora continua basadas en datos de eventos reales (event logs). Esta perspectiva facilita la comprensi\u00f3n de c\u00f3mo fluyen los procesos dentro de la organizaci\u00f3n, mostrando no solo resultados finales, sino tambi\u00e9n la ruta que siguen las tareas para lograrlos.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_8","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite desplazarse por las distintas secciones de Productividad Organizacional, como Desempe\u00f1o, Comportamientos Hist\u00f3ricos, Comportamiento Financiero y Experiencia de Usuario.  </li> <li>Facilita cambiar de vista sin perder la coherencia con el resto de an\u00e1lisis estrat\u00e9gicos.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 Opciones de An\u00e1lisis: </p> <ul> <li>Desempe\u00f1o: M\u00e9tricas de productividad y calidad en un sentido m\u00e1s general.  </li> <li>Comportamientos Hist\u00f3ricos: Tendencias y evoluci\u00f3n temporal de los indicadores clave.  </li> <li>Comportamiento Financiero: Informaci\u00f3n de costos, rentabilidad y asignaci\u00f3n de recursos.  </li> <li>Experiencia de Usuario: Indicadores de satisfacci\u00f3n y percepci\u00f3n de los beneficiarios.  </li> <li>An\u00e1lisis Miner\u00eda: Se enfoca espec\u00edficamente en el Process Mining, ofreciendo una vista detallada de los flujos de trabajo y la secuencia de eventos.</li> </ul> </li> <li> <p>Zona Central \u2013 Visualizaci\u00f3n de Process Mining (RieProcess Mining Visual u otra herramienta): </p> <ul> <li>Bienvenida y Pasos Iniciales: Explica la configuraci\u00f3n o los datos necesarios para generar el mapa de procesos. Por ejemplo, se indica c\u00f3mo cargar el archivo de eventos, definir columnas de actividad, marcas de tiempo y otras variables.  </li> <li>Mapa de Procesos / Diagrama de Flujo: Muestra gr\u00e1ficamente el recorrido de las actividades, destacando la frecuencia de cada ruta, los tiempos de espera y las transiciones entre estados.  </li> <li>Indicadores de Eficiencia: Pueden incluir m\u00e9tricas como la duraci\u00f3n promedio por actividad, el n\u00famero de repeticiones o re-trabajos, y la tasa de conformidad con los flujos de trabajo definidos.</li> </ul> </li> <li> <p>Panel Inferior o Secci\u00f3n de Detalle (opcional): </p> <ul> <li>Puede presentar estad\u00edsticas adicionales, como cu\u00e1ntos casos pasan por cada evento, tiempos promedios de ciclo, cu\u00e1ntos cuellos de botella se han identificado, etc.  </li> <li>Permite un an\u00e1lisis m\u00e1s granular, por ejemplo, filtrando los resultados por unidad de negocio, programa educativo o tipo de usuario.</li> </ul> </li> <li> <p>Slicers y Segmentaciones (Filtros): </p> <ul> <li>Permiten refinar el an\u00e1lisis por fechas, categor\u00eda de proceso, unidades involucradas, entre otros.  </li> <li>La actualizaci\u00f3n autom\u00e1tica de la vista de Process Mining al modificar filtros hace posible comparar escenarios (por ejemplo, procesos realizados en diferentes periodos o por distintas \u00e1reas).</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_8","title":"Funcionalidades Clave","text":"<ul> <li> <p>Descubrimiento de Procesos:   El Process Mining identifica el flujo real de trabajo a partir de datos de eventos, contrast\u00e1ndolo con el proceso te\u00f3rico o deseado.</p> </li> <li> <p>Detecci\u00f3n de Cuellos de Botella y Retrasos:   Al visualizar la frecuencia y duraci\u00f3n de cada actividad, se pueden encontrar pasos que generan demoras o retrabajos excesivos.</p> </li> <li> <p>Optimizaci\u00f3n de Flujos de Trabajo:   Con base en los hallazgos, es posible reconfigurar procesos para reducir tiempos, costos y mejorar la experiencia de usuarios o beneficiarios.</p> </li> <li> <p>An\u00e1lisis Interactivo y Comparativo:   Los filtros permiten segmentar los resultados, comparando la eficiencia de procesos en distintos periodos, sedes o equipos de trabajo.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-eficiencia","title":"Productividad Organizacional \u2013 An\u00e1lisis de Eficiencia","text":"<p>Objetivo de la Visualizaci\u00f3n: Proporcionar una visi\u00f3n detallada de la eficiencia en la prestaci\u00f3n de servicios educativos y sociales, enfoc\u00e1ndose en aspectos como la inversi\u00f3n en infraestructura, la utilizaci\u00f3n de recursos (horas contratadas, bibliotecas virtuales, movilidad acad\u00e9mica) y la capacidad disponible. Con esta vista, se busca identificar oportunidades de optimizaci\u00f3n y priorizar acciones que fortalezcan la productividad de la organizaci\u00f3n.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_9","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite acceder a distintas secciones de Productividad Organizacional (Desempe\u00f1o, Experiencia de Usuario, etc.).  </li> <li>Mantiene la coherencia con las otras vistas, facilitando la exploraci\u00f3n de m\u00faltiples perspectivas estrat\u00e9gicas.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 \u00c1reas de An\u00e1lisis: </p> <ul> <li>Educaci\u00f3n Formal: Incluye indicadores relacionados con programas acad\u00e9micos de larga duraci\u00f3n, como carreras o bachilleratos.  </li> <li>Educaci\u00f3n T\u00e9cnica: Se refiere a formaciones de car\u00e1cter t\u00e9cnico o tecnol\u00f3gico, con duraci\u00f3n y requisitos espec\u00edficos.  </li> <li>Educaci\u00f3n Continua: Enfatiza cursos y diplomados de actualizaci\u00f3n o especializaci\u00f3n para afiliados y beneficiarios.  </li> <li>Protecci\u00f3n Social: Abarca programas y servicios sociales complementarios, dirigidos a la comunidad.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores de Eficiencia: </p> <ul> <li>Horas Contratadas: Mide la cantidad de horas disponibles para la formaci\u00f3n, facilitando el an\u00e1lisis de uso vs. capacidad.  </li> <li>Reductores de Capacidad Contratada: Identifica los factores que disminuyen la capacidad efectiva (ausencias, mantenimientos, inhabilidades, etc.).  </li> <li>Movilidad Acad\u00e9mica: Refleja el intercambio o desplazamiento de estudiantes y docentes entre sedes o programas, promoviendo la optimizaci\u00f3n de recursos.  </li> <li>% de Utilizaci\u00f3n de Bibliotecas Virtuales: Indica el grado de aprovechamiento de las plataformas digitales, vitales para la formaci\u00f3n en entornos virtuales.  </li> <li>Inversi\u00f3n en Infraestructura: Muestra los montos destinados a mejoras f\u00edsicas y tecnol\u00f3gicas, comparando la inversi\u00f3n con el impacto en la eficiencia de los procesos.</li> </ul> </li> <li> <p>Visualizaciones Clave (Gr\u00e1ficos y Tarjetas): </p> <ul> <li>Gr\u00e1fico de Barras: Puede mostrar la relaci\u00f3n entre horas contratadas y horas efectivamente utilizadas.  </li> <li>Tarjetas de KPI: Destacan m\u00e9tricas esenciales como la tasa de ocupaci\u00f3n, porcentaje de horas ociosas, n\u00famero de personas que aprovechan la movilidad acad\u00e9mica, etc.  </li> <li>Tablas de Detalle: Presentan un desglose de la inversi\u00f3n por categor\u00eda (infraestructura, tecnolog\u00eda, formaci\u00f3n del personal), permitiendo un an\u00e1lisis m\u00e1s granular.</li> </ul> </li> <li> <p>Slicers y Filtros: </p> <ul> <li>Ubicados en la parte derecha o superior, posibilitan filtrar por rango de fechas, \u00e1rea de formaci\u00f3n, sede o programa espec\u00edfico.  </li> <li>La interactividad permite comparar la eficiencia entre distintas \u00e1reas (Educaci\u00f3n Formal vs. Educaci\u00f3n Continua, por ejemplo) o periodos de tiempo.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_9","title":"Funcionalidades Clave","text":"<ul> <li> <p>Identificaci\u00f3n de Brechas de Capacidad:   Al comparar las horas contratadas con las realmente utilizadas, se detectan subutilizaciones o excesos de demanda que requieran ajustes.</p> </li> <li> <p>Optimizaci\u00f3n de Recursos:   Analizar los reductores de capacidad contratada y la movilidad acad\u00e9mica permite dise\u00f1ar estrategias para disminuir ineficiencias y maximizar la ocupaci\u00f3n de las instalaciones y el personal.</p> </li> <li> <p>Evaluaci\u00f3n de Inversi\u00f3n vs. Impacto:   El monitoreo de la inversi\u00f3n en infraestructura y su correlaci\u00f3n con indicadores de eficiencia (por ejemplo, % de utilizaci\u00f3n de bibliotecas virtuales) brinda evidencia para priorizar proyectos de mayor retorno.</p> </li> <li> <p>Comparaci\u00f3n entre \u00c1reas de Educaci\u00f3n:   La posibilidad de segmentar por Educaci\u00f3n Formal, T\u00e9cnica, Continua o Protecci\u00f3n Social ofrece una visi\u00f3n diferenciada y facilita la toma de decisiones espec\u00edficas para cada \u00e1mbito.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-eficiencia-educacion-tecnica","title":"Productividad Organizacional \u2013 An\u00e1lisis de Eficiencia (Educaci\u00f3n T\u00e9cnica)","text":"<p> Objetivo de la Visualizaci\u00f3n: Ofrecer un panorama detallado de la eficiencia en la gesti\u00f3n de la Educaci\u00f3n T\u00e9cnica, resaltando la capacidad contratada y utilizada, la movilidad acad\u00e9mica y la frecuencia de uso de los principales servicios. El fin \u00faltimo es identificar oportunidades de mejora, optimizar recursos y alinear la oferta formativa con la demanda real de los usuarios.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_10","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite alternar entre las distintas secciones de Productividad Organizacional, como Desempe\u00f1o, Experiencia de Usuario y Comportamiento Financiero.  </li> <li>Mantiene la coherencia con las dem\u00e1s vistas, asegurando un acceso r\u00e1pido a diferentes perspectivas estrat\u00e9gicas.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 \u00c1reas de An\u00e1lisis: </p> <ul> <li>Educaci\u00f3n Formal: Dirigida a programas acad\u00e9micos extensos.  </li> <li>Educaci\u00f3n T\u00e9cnica: Se enfoca en formaciones t\u00e9cnicas y tecnol\u00f3gicas, con \u00e9nfasis en su capacidad y eficiencia.  </li> <li>Educaci\u00f3n Continua: Incluye cursos y diplomados de actualizaci\u00f3n para afiliados y beneficiarios.  </li> <li>Protecci\u00f3n Social: Abarca servicios sociales y comunitarios complementarios.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores de Eficiencia en Educaci\u00f3n T\u00e9cnica: </p> <ul> <li>Horas Contratadas vs. Horas en Uso: Muestra la proporci\u00f3n de horas disponibles para formaci\u00f3n t\u00e9cnica frente a las horas efectivamente utilizadas, facilitando la detecci\u00f3n de subutilizaci\u00f3n o sobrecarga.  </li> <li>Reductores de Capacidad Contratada (por Turno o por Evento): Identifica factores que restan capacidad a la disponibilidad total (ausencias, mantenimientos, inhabilidades, etc.).  </li> <li>Movilidad Acad\u00e9mica: Refleja el intercambio de estudiantes o docentes entre sedes o programas, evaluando la optimizaci\u00f3n de recursos humanos y f\u00edsicos.  </li> <li>Top Servicios M\u00e1s Usados: Presenta un listado o gr\u00e1fico de los servicios con mayor demanda dentro de la Educaci\u00f3n T\u00e9cnica (laboratorios, talleres, plataformas virtuales, etc.).  </li> <li>Indicadores de Utilizaci\u00f3n y Aforo: Tarjetas o gr\u00e1ficos que evidencian el porcentaje de ocupaci\u00f3n de las aulas, talleres o recursos tecnol\u00f3gicos.</li> </ul> </li> <li> <p>Visualizaciones Clave (Gr\u00e1ficos y Tarjetas): </p> <ul> <li>Gr\u00e1fico de Barras o L\u00edneas: Contrasta las horas contratadas con las utilizadas, destacando la brecha existente.  </li> <li>Tarjetas de KPI: Subrayan las m\u00e9tricas esenciales, como porcentaje de uso efectivo, n\u00famero de estudiantes por turno, nivel de movilidad acad\u00e9mica, etc.  </li> <li>Tablas de Detalle: Ofrecen informaci\u00f3n desglosada por curso, horario, sede o tipo de servicio utilizado.</li> </ul> </li> <li> <p>Slicers y Filtros: </p> <ul> <li>Ubicados a la derecha o en la parte superior, permiten segmentar los datos por rangos de fechas, tipo de programa, sede o turno.  </li> <li>La interactividad posibilita un an\u00e1lisis r\u00e1pido y comparativo entre diferentes periodos o \u00e1reas de la Educaci\u00f3n T\u00e9cnica.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_10","title":"Funcionalidades Clave","text":"<ul> <li> <p>Identificaci\u00f3n de Cuellos de Botella:   Al revisar los reductores de capacidad contratada, se pueden detectar factores que obstaculizan el uso \u00f3ptimo de los recursos, como altos niveles de inasistencia o tiempos muertos.</p> </li> <li> <p>An\u00e1lisis de Movilidad Acad\u00e9mica:   La visualizaci\u00f3n de la movilidad acad\u00e9mica permite evaluar la eficacia de los intercambios entre sedes, fomentando un uso m\u00e1s racional de los recursos disponibles.</p> </li> <li> <p>Priorizaci\u00f3n de Recursos y Servicios:   El listado de los servicios m\u00e1s usados ayuda a orientar la inversi\u00f3n y la atenci\u00f3n hacia aquellos que generan mayor demanda o impacto en la formaci\u00f3n t\u00e9cnica.</p> </li> <li> <p>Optimizaci\u00f3n de la Oferta:   Comparar las horas contratadas con las realmente utilizadas facilita la planificaci\u00f3n de cursos, el ajuste de cupos y la programaci\u00f3n de espacios, alineando la oferta con la demanda real.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-eficiencia-educacion-continua","title":"Productividad Organizacional \u2013 An\u00e1lisis de Eficiencia (Educaci\u00f3n Continua)","text":"<p>Objetivo de la Visualizaci\u00f3n: Brindar una visi\u00f3n detallada de la eficiencia y uso de recursos en los programas de Educaci\u00f3n Continua, destacando indicadores como horas contratadas, tiempo efectivo de formaci\u00f3n, n\u00famero de sesiones realizadas y asistencia de usuarios. El prop\u00f3sito es identificar oportunidades de mejora, optimizar la asignaci\u00f3n de recursos y alinear la oferta formativa con la demanda real de la comunidad.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_11","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Ubicado en la parte superior, permite cambiar entre los distintos m\u00f3dulos de Productividad Organizacional (Desempe\u00f1o, Experiencia de Usuario, Comportamiento Financiero, etc.).  </li> <li>Garantiza una experiencia coherente al desplazarse por las diferentes perspectivas de an\u00e1lisis.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 \u00c1reas de An\u00e1lisis: </p> <ul> <li>Educaci\u00f3n Formal: Informaci\u00f3n sobre programas acad\u00e9micos de mayor duraci\u00f3n.  </li> <li>Educaci\u00f3n T\u00e9cnica: Se refiere a formaciones de car\u00e1cter t\u00e9cnico o tecnol\u00f3gico.  </li> <li>Educaci\u00f3n Continua: Enfocado en cursos y diplomados de actualizaci\u00f3n y especializaci\u00f3n.  </li> <li>Protecci\u00f3n Social: Servicios y programas de apoyo social complementarios.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores de Eficiencia en Educaci\u00f3n Continua: </p> <ul> <li>Horas Contratadas vs. Horas Efectivas: Compara el total de horas contratadas para la realizaci\u00f3n de los programas con las horas efectivamente empleadas en sesiones formativas.  </li> <li>Uso del Tiempo y N\u00famero de Sesiones: Refleja cu\u00e1ntas sesiones se han llevado a cabo, su duraci\u00f3n promedio y el porcentaje de tiempo utilizado en actividades formativas.  </li> <li>Asistencia de Usuarios: Muestra el n\u00famero de participantes inscritos y su asistencia real, lo que permite evaluar la aceptaci\u00f3n y el impacto de los programas.  </li> <li>Tendencia de la Demanda: Incluye un gr\u00e1fico o m\u00e9trica que ilustre la variaci\u00f3n en la participaci\u00f3n o en la oferta de cursos a lo largo del tiempo.  </li> <li>Indicadores de Satisfacci\u00f3n o Retroalimentaci\u00f3n (opcional): Puede mostrar, si est\u00e1 disponible, la percepci\u00f3n de los participantes acerca de la calidad y relevancia de la formaci\u00f3n.</li> </ul> </li> <li> <p>Visualizaciones Clave (Gr\u00e1ficos y Tarjetas): </p> <ul> <li>Tarjetas de KPI: Destacan los valores m\u00e1s relevantes, como la tasa de utilizaci\u00f3n de horas, el n\u00famero de usuarios atendidos y la cantidad de cursos ofertados.  </li> <li>Gr\u00e1ficos de Barras o L\u00edneas: Ilustran la evoluci\u00f3n de la asistencia, la demanda de cursos o el uso efectivo del tiempo en Educaci\u00f3n Continua.  </li> <li>Tablas de Detalle: Permiten revisar la informaci\u00f3n por curso, instructor, fecha o sede, profundizando en los datos.</li> </ul> </li> <li> <p>Slicers y Filtros: </p> <ul> <li>Ubicados a la derecha o parte superior, posibilitan segmentar la informaci\u00f3n por rango de fechas, tipo de curso, categor\u00eda de usuario, entre otros.  </li> <li>La actualizaci\u00f3n din\u00e1mica de los gr\u00e1ficos y tablas ayuda a comparar periodos o a focalizar el an\u00e1lisis en programas espec\u00edficos.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_11","title":"Funcionalidades Clave","text":"<ul> <li> <p>Detecci\u00f3n de Ineficiencias:   Al observar la diferencia entre horas contratadas y horas efectivas, es posible detectar subutilizaciones o sobrecostos en la programaci\u00f3n de los cursos.</p> </li> <li> <p>Optimizaci\u00f3n de la Oferta Formativa:   Conocer el n\u00famero de sesiones realizadas y la asistencia real permite ajustar la programaci\u00f3n de cursos a la demanda, maximizando el impacto de la Educaci\u00f3n Continua.</p> </li> <li> <p>An\u00e1lisis de la Evoluci\u00f3n de la Demanda:   Mediante el seguimiento de la participaci\u00f3n y el uso de recursos a lo largo del tiempo, se identifican tendencias de crecimiento o disminuci\u00f3n en ciertos tipos de programas.</p> </li> <li> <p>Foco en la Calidad y Satisfacci\u00f3n (opcional):   Si se incluyen indicadores de satisfacci\u00f3n, se puede correlacionar la eficiencia (uso de horas, n\u00famero de sesiones) con la percepci\u00f3n de calidad y utilidad de los cursos.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-eficiencia-proteccion-social","title":"Productividad Organizacional \u2013 An\u00e1lisis de Eficiencia (Protecci\u00f3n Social)","text":"<p>Objetivo de la Visualizaci\u00f3n: Proporcionar una visi\u00f3n enfocada en la eficiencia de los programas y servicios de Protecci\u00f3n Social, abarcando la cobertura de beneficiarios, el uso de recursos y la capacidad instalada en las diferentes sedes. El fin es identificar oportunidades de mejora, optimizar la asignaci\u00f3n de fondos e infraestructura, y asegurar que los servicios sociales respondan de manera efectiva a las necesidades de la comunidad.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_12","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Ubicado en la parte superior, permite desplazarse por las distintas secciones de Productividad Organizacional (Desempe\u00f1o, Experiencia de Usuario, Comportamiento Financiero, etc.).  </li> <li>Mantiene la coherencia con las otras vistas, facilitando el acceso a m\u00faltiples perspectivas estrat\u00e9gicas.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 \u00c1reas de An\u00e1lisis: </p> <ul> <li>Educaci\u00f3n Formal: Secci\u00f3n destinada a los programas acad\u00e9micos tradicionales.  </li> <li>Educaci\u00f3n T\u00e9cnica: Centrada en la formaci\u00f3n t\u00e9cnica o tecnol\u00f3gica.  </li> <li>Educaci\u00f3n Continua: Cubre cursos de actualizaci\u00f3n y diplomados.  </li> <li>Protecci\u00f3n Social: Focaliza la presente vista, que aborda servicios sociales y comunitarios.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores de Eficiencia en Protecci\u00f3n Social: </p> <ul> <li>N\u00famero de Servicios: Refleja la variedad o cantidad de servicios de protecci\u00f3n social ofrecidos (por ejemplo, asistencia alimentaria, atenci\u00f3n al adulto mayor, etc.).  </li> <li>N\u00famero de Sedes: Indica la infraestructura disponible para prestar dichos servicios, permitiendo evaluar la distribuci\u00f3n geogr\u00e1fica o por comunidad.  </li> <li>N\u00famero de Beneficiarios: Muestra cu\u00e1ntas personas han sido atendidas, ayudando a medir el alcance y la efectividad de los programas sociales.  </li> <li>Proyecci\u00f3n de Aforo o Capacidad Instalada: Estima la capacidad m\u00e1xima de atenci\u00f3n que las sedes pueden ofrecer, compar\u00e1ndola con la demanda real para detectar subutilizaci\u00f3n o saturaci\u00f3n.  </li> <li>Tabla de Detalle por Programa o Categor\u00eda: Desglosa la informaci\u00f3n de cada servicio o programa (nombre, cobertura, tipo de poblaci\u00f3n atendida), brindando un an\u00e1lisis granular.</li> </ul> </li> <li> <p>Visualizaciones Clave (Gr\u00e1ficos y Tarjetas): </p> <ul> <li>Tarjetas de KPI: Destacan los valores principales (n\u00famero de servicios, sedes y beneficiarios), facilitando la interpretaci\u00f3n r\u00e1pida de los resultados.  </li> <li>Gr\u00e1ficos de Barras o L\u00edneas: Pueden ilustrar la evoluci\u00f3n en la prestaci\u00f3n de servicios a lo largo del tiempo o comparar la cobertura entre sedes.  </li> <li>Tablas Interactivas: Muestran datos detallados por programa, fecha, categor\u00eda o sede, permitiendo filtrar y profundizar en informaci\u00f3n espec\u00edfica.</li> </ul> </li> <li> <p>Slicers y Filtros: </p> <ul> <li>Ubicados a la derecha o en la parte superior, permiten segmentar la informaci\u00f3n por rangos de fechas, tipo de servicio, poblaci\u00f3n objetivo, sede, etc.  </li> <li>La interactividad posibilita un an\u00e1lisis m\u00e1s preciso, ajustando la visualizaci\u00f3n a las necesidades de cada \u00e1rea o usuario.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_12","title":"Funcionalidades Clave","text":"<ul> <li> <p>Monitoreo de Cobertura y Capacidad:   Al comparar la proyecci\u00f3n de aforo con el n\u00famero de beneficiarios atendidos, se identifican posibles brechas o excedentes de capacidad.</p> </li> <li> <p>Priorizaci\u00f3n de Recursos:   Conociendo el n\u00famero de servicios y sedes, as\u00ed como la demanda efectiva, es posible asignar mejor el personal, el presupuesto y los espacios f\u00edsicos a los programas con mayor impacto.</p> </li> <li> <p>An\u00e1lisis por Programa o Categor\u00eda:   La tabla de detalle permite evaluar cu\u00e1les programas son m\u00e1s utilizados y qu\u00e9 poblaci\u00f3n est\u00e1n atendiendo, facilitando la toma de decisiones basada en datos concretos.</p> </li> <li> <p>Evoluci\u00f3n Hist\u00f3rica y Comparativa:   Gr\u00e1ficos que muestren la evoluci\u00f3n del n\u00famero de beneficiarios o la apertura de nuevas sedes en el tiempo ayudan a entender tendencias y planificar expansiones o ajustes.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-servicio","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por Servicio","text":"<p>Objetivo de la Visualizaci\u00f3n: Presentar de manera detallada el impacto social y comunitario de los distintos servicios ofrecidos, destacando la atenci\u00f3n a la poblaci\u00f3n vulnerable, el nivel de satisfacci\u00f3n (porcentaje de promotores y detractores), y la distribuci\u00f3n de afiliados seg\u00fan categor\u00eda y g\u00e9nero. Adem\u00e1s, se incluye informaci\u00f3n sobre empresas atendidas, estratos socioecon\u00f3micos y recuento de actividades realizadas, brindando una perspectiva amplia de la cobertura e impacto de cada servicio en la comunidad.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_13","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Ubicado en la parte superior, permite desplazarse entre diversos an\u00e1lisis estrat\u00e9gicos (por ejemplo, An\u00e1lisis por Empresa, Productividad Organizacional, Experiencia de Usuario).  </li> <li>Mantiene la coherencia con otras vistas, facilitando un cambio fluido de perspectiva.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 \u00c1reas de An\u00e1lisis: </p> <ul> <li>Educaci\u00f3n Formal: Enfocado en la formaci\u00f3n acad\u00e9mica de larga duraci\u00f3n.  </li> <li>Educaci\u00f3n para el Trabajo: Muestra la oferta de programas de formaci\u00f3n t\u00e9cnica o capacitaci\u00f3n laboral.  </li> <li>Desarrollo Empresarial: Dirigido a servicios de acompa\u00f1amiento y consultor\u00eda para empresas.  </li> <li>Protecci\u00f3n Social: Incluye programas y servicios de apoyo social para poblaciones vulnerables.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores Clave de Impacto Social: </p> <ul> <li>Porcentaje de Detractores y Promotores: Refleja la satisfacci\u00f3n de los usuarios con los servicios, medido por un \u00edndice de recomendaci\u00f3n (NPS o similar).  </li> <li>Atenci\u00f3n a Poblaci\u00f3n Vulnerable: Indica cu\u00e1ntas personas de grupos en condici\u00f3n de vulnerabilidad han sido atendidas, destacando el alcance inclusivo de los servicios.  </li> <li>Afiliados Atendidos y Empresas Atendidas: Muestra el volumen de usuarios y empresas que han accedido a los programas, permitiendo medir la cobertura efectiva.  </li> <li>Recuento de Actividades Realizadas: Registra el total de eventos, talleres o jornadas de servicio llevadas a cabo, ofreciendo una idea de la intensidad de las intervenciones.  </li> <li>Afiliados (Caja) por Estrato y por G\u00e9nero: Desglosa la distribuci\u00f3n socioecon\u00f3mica y de g\u00e9nero de los afiliados, aportando una visi\u00f3n de la equidad en la prestaci\u00f3n de servicios.</li> </ul> </li> <li> <p>Visualizaciones Clave (Gr\u00e1ficos y Tablas): </p> <ul> <li>Gr\u00e1ficos de Barras / Pasteles: Comparan los porcentajes de promotores y detractores, o muestran la proporci\u00f3n de afiliados seg\u00fan estrato o g\u00e9nero.  </li> <li>Tarjetas de KPI: Destacan valores como el n\u00famero de empresas atendidas, la atenci\u00f3n a poblaci\u00f3n vulnerable o el recuento total de actividades.  </li> <li>Tablas Din\u00e1micas: Permiten profundizar en datos espec\u00edficos, como la clasificaci\u00f3n de actividades por tipo de servicio o el detalle de afiliados atendidos por categor\u00eda.</li> </ul> </li> <li> <p>Slicers y Filtros: </p> <ul> <li>Ubicados en la parte derecha o superior, permiten filtrar la informaci\u00f3n por rango de fechas, tipo de servicio, categor\u00eda de beneficiario, entre otros.  </li> <li>Actualizan autom\u00e1ticamente las visualizaciones, facilitando el an\u00e1lisis focalizado y comparativo.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_13","title":"Funcionalidades Clave","text":"<ul> <li> <p>Medici\u00f3n de Satisfacci\u00f3n y Recomendaci\u00f3n:   El porcentaje de promotores y detractores brinda una lectura r\u00e1pida de la aceptaci\u00f3n de los servicios y las \u00e1reas donde podr\u00eda requerirse mejora.</p> </li> <li> <p>Enfoque en Inclusi\u00f3n y Equidad:   Al mostrar la atenci\u00f3n a poblaci\u00f3n vulnerable, la distribuci\u00f3n por g\u00e9nero y estrato socioecon\u00f3mico, la vista promueve la adopci\u00f3n de estrategias de inclusi\u00f3n social.</p> </li> <li> <p>Seguimiento de Actividades y Cobertura:   El recuento de actividades y la cantidad de afiliados/empresas atendidas ofrecen un indicador del volumen de operaciones y su alcance.</p> </li> <li> <p>Segmentaci\u00f3n Interactiva:   La posibilidad de filtrar por servicio, estrato o g\u00e9nero permite analizar la efectividad y relevancia de las acciones en grupos poblacionales espec\u00edficos.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-empresa","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por Empresa","text":"<p>Objetivo de la Visualizaci\u00f3n: Brindar una perspectiva enfocada en las empresas que participan en los servicios ofrecidos por la organizaci\u00f3n, analizando indicadores clave como la relaci\u00f3n de aportes, la compra de servicios y el acceso a subsidios. Con esta vista, se busca identificar patrones de comportamiento empresarial, medir el nivel de involucramiento en programas sociales y evaluar el impacto de las alianzas entre la organizaci\u00f3n y el sector productivo.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_14","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Ubicado en la parte superior, permite desplazarse entre diferentes an\u00e1lisis estrat\u00e9gicos (por ejemplo, An\u00e1lisis por Servicio, Productividad Organizacional, Experiencia de Usuario).  </li> <li>Facilita la transici\u00f3n a otras perspectivas sin perder el contexto global del impacto social y comunitario.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 Opciones de An\u00e1lisis: </p> <ul> <li>Indicadores por Empresa: Presenta datos consolidados de cada empresa, como aportes realizados y n\u00famero de servicios utilizados.  </li> <li>Relaci\u00f3n de Servicios y Aportes: Permite visualizar qu\u00e9 servicios han sido contratados por las empresas y c\u00f3mo se relacionan con los aportes efectuados.  </li> <li>Servicios Vendidos y Subsidios: Muestra la cantidad de servicios vendidos a cada empresa y los subsidios aplicados, ofreciendo un panorama de la inversi\u00f3n social y el retorno en t\u00e9rminos de cobertura.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores Clave por Empresa: </p> <ul> <li>N\u00famero de Empresas Atendidas: Refleja cu\u00e1ntas organizaciones est\u00e1n siendo impactadas por los servicios.  </li> <li>Aportes a la Demanda: Indica la contribuci\u00f3n econ\u00f3mica de las empresas en el proceso educativo o social, relacion\u00e1ndola con la cantidad de beneficiarios o servicios financiados.  </li> <li>Valor de Subsidios: Muestra los montos de subsidios asignados a cada empresa, evidenciando el apoyo que reciben para la formaci\u00f3n o asistencia de sus afiliados.  </li> <li>Indicador Total (Gr\u00e1fico de Barras o Columnas): Ordena a las empresas seg\u00fan una m\u00e9trica consolidada (p. ej., aportes totales, servicios contratados, \u00edndice de impacto), facilitando la comparaci\u00f3n entre ellas.</li> </ul> </li> <li> <p>Visualizaciones Clave (Gr\u00e1ficos y Tablas): </p> <ul> <li>Gr\u00e1fico Comparativo por Empresa: Permite ver de forma r\u00e1pida las empresas con mayor inversi\u00f3n, mayor cantidad de servicios comprados o mayor acceso a subsidios.  </li> <li>Tabla de Detalle: Desglosa la informaci\u00f3n por tipo de servicio, categor\u00eda de aportes o periodo de an\u00e1lisis, permitiendo un estudio m\u00e1s profundo de cada caso.</li> </ul> </li> <li> <p>Slicers y Filtros: </p> <ul> <li>Ubicados en la parte derecha o superior, permiten filtrar por periodo de tiempo, sector empresarial, tama\u00f1o de la empresa o cualquier otra variable relevante.  </li> <li>Al seleccionar criterios espec\u00edficos, las visualizaciones se actualizan de forma din\u00e1mica, posibilitando an\u00e1lisis comparativos y focalizados.</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_14","title":"Funcionalidades Clave","text":"<ul> <li> <p>An\u00e1lisis de Contribuci\u00f3n y Beneficio:   Comparar los aportes de cada empresa con los servicios que reciben o subsidios que aprovechan, permite entender la balanza de inversi\u00f3n social y retorno en beneficios.</p> </li> <li> <p>Segmentaci\u00f3n por Sector o Tama\u00f1o de Empresa:   Filtrar la informaci\u00f3n por tipo de industria, n\u00famero de empleados o facturaci\u00f3n ayuda a identificar patrones de participaci\u00f3n y potenciales \u00e1reas de mejora o expansi\u00f3n.</p> </li> <li> <p>Identificaci\u00f3n de Oportunidades de Alianza:   Conocer qu\u00e9 empresas demandan m\u00e1s servicios o aportan m\u00e1s recursos permite enfocar esfuerzos de colaboraci\u00f3n y dise\u00f1ar propuestas de valor que fortalezcan la relaci\u00f3n institucional.</p> </li> <li> <p>Monitoreo de Tendencias y Cambios:   La comparaci\u00f3n hist\u00f3rica de indicadores muestra c\u00f3mo evoluciona la participaci\u00f3n empresarial en los programas, facilitando la medici\u00f3n de impacto a lo largo del tiempo.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-empresa-relacion-de-servicios-y-aportes","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por Empresa (Relaci\u00f3n de Servicios y Aportes)","text":"<p>Objetivo de la Visualizaci\u00f3n: Proporcionar un panorama detallado de la relaci\u00f3n entre los servicios ofrecidos y los aportes de las empresas, evidenciando cu\u00e1ntos y cu\u00e1les servicios han sido adquiridos o subsidiados por cada organizaci\u00f3n. Adem\u00e1s, se incluye la distribuci\u00f3n de aportes por tipo de poblaci\u00f3n, brindando una perspectiva clara del impacto y la cobertura alcanzada a trav\u00e9s de los programas ofrecidos.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_15","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite moverse entre distintos an\u00e1lisis estrat\u00e9gicos dentro de la categor\u00eda de Impacto Social y Comunitario (p. ej., An\u00e1lisis por Servicio, Productividad Organizacional, etc.).  </li> <li>Ofrece una experiencia coherente, facilitando el cambio de vista sin perder el contexto general de los datos.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 Opciones de An\u00e1lisis: </p> <ul> <li>Indicadores por Empresa: Vista enfocada en datos consolidados de cada empresa (aportes, n\u00famero de servicios utilizados, subsidios, etc.).  </li> <li>Relaci\u00f3n de Servicios y Aportes: Vista actual, centrada en la correspondencia entre los aportes realizados por las empresas y los servicios adquiridos o subsidiados.  </li> <li>Servicios Vendidos y Subsidios: Muestra el detalle de cu\u00e1ntos servicios han sido vendidos a cada empresa y la aplicaci\u00f3n de subsidios hist\u00f3ricos.</li> </ul> </li> <li> <p>Zona Central \u2013 Relaci\u00f3n de Servicios y Aportes: </p> <ul> <li>Tabla Principal (Servicios vs. Empresa): Lista o tabla que detalla cada servicio (por ejemplo, matr\u00edcula de cursos, asesor\u00edas, programas sociales) y los aportes realizados por las empresas.  </li> <li>Cantidad de Aportes por Poblaci\u00f3n (Gr\u00e1fico de Barras o Tartas): Refleja cu\u00e1ntos aportes se han destinado a diferentes segmentos poblacionales (ni\u00f1ez, adulto mayor, poblaci\u00f3n vulnerable, etc.), evidenciando el alcance social de las contribuciones.  </li> <li>Indicadores Globales: Muestran datos agregados, como el n\u00famero total de aportes, el valor econ\u00f3mico asociado y la cantidad de servicios ofrecidos o adquiridos.</li> </ul> </li> <li> <p>Visualizaciones Clave (Gr\u00e1ficos y Tablas): </p> <ul> <li>Relaci\u00f3n de Servicios y Aportes: Puede ser un gr\u00e1fico que cruce la informaci\u00f3n de servicios vs. aportes, indicando cu\u00e1ntas empresas han participado en cada servicio o el monto aportado.  </li> <li>Cantidad de Aportes por Poblaci\u00f3n: Destaca de forma visual el foco de las contribuciones, revelando si est\u00e1n orientadas mayoritariamente a una poblaci\u00f3n espec\u00edfica o si est\u00e1n equilibradas entre distintos grupos.</li> </ul> </li> <li> <p>Slicers y Filtros: </p> <ul> <li>Ubicados a la derecha o en la parte superior, permiten filtrar por rango de fechas, tipo de servicio, categor\u00eda de empresa, poblaci\u00f3n beneficiada, etc.  </li> <li>Actualizan de forma din\u00e1mica las tablas y gr\u00e1ficos, brindando la posibilidad de hacer an\u00e1lisis comparativos y segmentados (por ejemplo, ver la relaci\u00f3n de servicios y aportes de un sector industrial espec\u00edfico).</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_15","title":"Funcionalidades Clave","text":"<ul> <li> <p>Visi\u00f3n Integral de la Contribuci\u00f3n Empresarial:   Combina en un solo espacio los servicios utilizados y los aportes realizados, permitiendo entender el grado de involucramiento de cada empresa en los programas sociales.</p> </li> <li> <p>An\u00e1lisis de Cobertura por Poblaci\u00f3n:   El desglose de aportes por poblaci\u00f3n facilita la identificaci\u00f3n de los colectivos m\u00e1s beneficiados, ayudando a alinear esfuerzos con los objetivos de responsabilidad social.</p> </li> <li> <p>Comparaci\u00f3n Interactiva:   La interacci\u00f3n con los filtros posibilita contrastar aportes en distintos periodos o entre diferentes tipos de empresas, dando soporte a la toma de decisiones basada en datos.</p> </li> <li> <p>Detecci\u00f3n de Oportunidades de Expansi\u00f3n o Mejora:   Al observar qu\u00e9 servicios reciben mayores aportes y cu\u00e1les tienen menor participaci\u00f3n, se pueden replantear estrategias de promoci\u00f3n, subsidio o colaboraci\u00f3n con empresas.</p> </li> </ul>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-empresa-servicios-vendidos-y-subsidios-historicos","title":"Impacto Social y Comunitario \u2013 An\u00e1lisis por Empresa (Servicios vendidos y subsidios hist\u00f3ricos)","text":"<p>Objetivo de la Visualizaci\u00f3n: Brindar una perspectiva hist\u00f3rica de los servicios vendidos a cada empresa y de los subsidios otorgados en el tiempo. Este enfoque permite evaluar la evoluci\u00f3n de la relaci\u00f3n comercial y social con las empresas, identificar patrones de demanda y cuantificar el apoyo brindado mediante subsidios, todo con el fin de optimizar las estrategias de vinculaci\u00f3n y la gesti\u00f3n de recursos.</p>"},{"location":"05.Power_BI/01.Dashboard/#estructura-y-elementos-principales_16","title":"Estructura y Elementos Principales","text":"<ol> <li> <p>Men\u00fa Superior de Navegaci\u00f3n: </p> <ul> <li>Permite cambiar entre las secciones de Impacto Social y Comunitario (por ejemplo, An\u00e1lisis por Servicio, An\u00e1lisis por Empresa, etc.).  </li> <li>Mantiene la coherencia con otras vistas, facilitando la transici\u00f3n sin perder el contexto global.</li> </ul> </li> <li> <p>Panel Lateral Izquierdo \u2013 Opciones de An\u00e1lisis: </p> <ul> <li>Indicadores por Empresa: Ofrece datos consolidados de cada empresa (aportes, servicios adquiridos, etc.).  </li> <li>Relaci\u00f3n de Servicios y Aportes: Muestra c\u00f3mo se conectan los aportes de las empresas con los servicios utilizados.  </li> <li>Servicios vendidos y Subsidios Hist\u00f3ricos: Vista actual, enfocada en el volumen de servicios vendidos a lo largo del tiempo y la evoluci\u00f3n de los subsidios otorgados.</li> </ul> </li> <li> <p>Zona Central \u2013 Indicadores Clave de Servicios y Subsidios: </p> <ul> <li>Servicios Vendidos (Hist\u00f3rico): Presenta la cantidad de servicios adquiridos por las empresas en distintos periodos (mes, trimestre, a\u00f1o), permitiendo observar tendencias de compra.  </li> <li>Cantidad Subsidiada a la Demanda: Muestra cu\u00e1ntos servicios o cupos han sido subsidiados en cada periodo, reflejando el apoyo brindado a empresas y afiliados.  </li> <li>Valor Subsidiado a la Demanda: Indica el monto econ\u00f3mico total invertido en subsidios, facilitando el an\u00e1lisis del impacto financiero y social.  </li> <li>Gr\u00e1ficos Comparativos: Pueden presentarse en barras o l\u00edneas, contrastando la evoluci\u00f3n de servicios vendidos con la de subsidios en el tiempo.</li> </ul> </li> <li> <p>Visualizaciones Clave (Gr\u00e1ficos y Tablas): </p> <ul> <li>Gr\u00e1ficos de Tendencia: Ilustran la evoluci\u00f3n de servicios vendidos y subsidios en el tiempo, permitiendo identificar picos o ca\u00eddas significativas.  </li> <li>Tarjetas de KPI: Resumen las m\u00e9tricas m\u00e1s importantes (p. ej., total de servicios vendidos en el \u00faltimo a\u00f1o, valor acumulado de subsidios).  </li> <li>Tabla Hist\u00f3rica Detallada: Desglosa la informaci\u00f3n por empresa, rango de fechas y tipo de servicio, brindando un an\u00e1lisis granular.</li> </ul> </li> <li> <p>Slicers y Filtros: </p> <ul> <li>Ubicados en la parte derecha o superior, permiten filtrar por per\u00edodo, tipo de servicio, categor\u00eda de empresa u otras variables relevantes.  </li> <li>La actualizaci\u00f3n din\u00e1mica de los gr\u00e1ficos y tablas facilita el an\u00e1lisis focalizado (por ejemplo, ver los subsidios de un solo tipo de servicio o de un sector empresarial espec\u00edfico).</li> </ul> </li> </ol>"},{"location":"05.Power_BI/01.Dashboard/#funcionalidades-clave_16","title":"Funcionalidades Clave","text":"<ul> <li> <p>An\u00e1lisis de Tendencias Hist\u00f3ricas:   Comparar servicios vendidos y subsidios a lo largo del tiempo ayuda a entender el comportamiento de la demanda y la efectividad de los apoyos econ\u00f3micos.</p> </li> <li> <p>Enfoque en el Retorno Social y Comercial:   Al correlacionar la evoluci\u00f3n de los servicios vendidos con los subsidios otorgados, se puede estimar el equilibrio entre ingresos y aportes sociales.</p> </li> <li> <p>Segmentaci\u00f3n Interactiva:   Los filtros permiten ver la evoluci\u00f3n de la relaci\u00f3n con una empresa espec\u00edfica, un grupo de empresas o un tipo de servicio, apoyando decisiones m\u00e1s precisas.</p> </li> <li> <p>Identificaci\u00f3n de Patrones de Compra:   Detectar temporadas o periodos en los que se incrementa la venta de servicios o la solicitud de subsidios ayuda a planificar estrategias de promoci\u00f3n y asignaci\u00f3n de recursos.</p> </li> </ul>"}]}