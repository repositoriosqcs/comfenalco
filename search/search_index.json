{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"INTRODUCCI\u00d3N","text":"<p>El proyecto general de Comfenalco tiene como objetivo principal optimizar y estructurar la gesti\u00f3n de datos de la organizaci\u00f3n para facilitar la toma de decisiones informadas y estrat\u00e9gicas. A trav\u00e9s de un enfoque integral, el proyecto abarca diferentes \u00e1reas clave como educaci\u00f3n, protecci\u00f3n social, programas transversales y servicios administrativos, consolidando la informaci\u00f3n en una plataforma robusta y escalable.</p> <p>Este esfuerzo tiene como base la implementaci\u00f3n de un Data Warehouse (DWH) centralizado, el cual adopta un modelo dimensional para garantizar la eficiencia en el acceso y an\u00e1lisis de datos. Adem\u00e1s, se dise\u00f1an e implementan procesos de Extracci\u00f3n, Transformaci\u00f3n y Carga (ETL) que permiten integrar y normalizar la informaci\u00f3n proveniente de diversas fuentes operativas, asegurando su calidad y relevancia para las \u00e1reas funcionales.</p>"},{"location":"#objetivos-del-proyecto","title":"Objetivos del Proyecto","text":"<p>Objetivo General:</p> <ul> <li>Desarrollar una soluci\u00f3n tecnol\u00f3gica que permite la consolidaci\u00f3n, an\u00e1lisis y explotaci\u00f3n eficiente de los datos organizacionales para apoyar la planeaci\u00f3n estrat\u00e9gica y operativa de Comfenalco.</li> </ul> <p>Objetivos Espec\u00edficos:</p> <ol> <li>Centralizar la informaci\u00f3n de m\u00faltiples \u00e1reas en un sistema \u00fanico, garantizando la consistencia y accesibilidad de los datos.</li> <li>Dise\u00f1ar modelos de datos modulares que permiten an\u00e1lisis por dimensiones espec\u00edficas como tiempo, poblaci\u00f3n, servicios, y programas acad\u00e9micos.</li> <li>Implementar mecanismos que aseguran la integridad, seguridad y calidad de los datos procesados.</li> <li>Proveer herramientas y reportes anal\u00edticos que facilitan la supervisi\u00f3n del desempe\u00f1o y la identificaci\u00f3n de oportunidades de mejora.</li> <li>Asegurar la escalabilidad del sistema para adaptarse a futuras necesidades de informaci\u00f3n y m\u00f3dulos adicionales.</li> </ol>"},{"location":"#alcance","title":"Alcance","text":"<p>El proyecto abarca la optimizaci\u00f3n y mejora de los procesos de gesti\u00f3n de datos en \u00e1reas como:</p> <ul> <li>Educaci\u00f3n Formal y Continua: Incluyendo informaci\u00f3n sobre estudiantes, docentes, matr\u00edculas, y desempe\u00f1o acad\u00e9mico.</li> <li>Protecci\u00f3n Social: Gesti\u00f3n de poblaciones vulnerables, programas de cobertura y caracterizaci\u00f3n.</li> <li>Programas Transversales: Datos sobre servicios administrativos, financieros y operativos.</li> <li>Gesti\u00f3n de Recursos: Informaci\u00f3n de bibliotecas, transporte, y servicios auxiliares.</li> </ul> <p>La implementaci\u00f3n del DWH est\u00e1 respaldada por \u00edndices optimizados y esquemas de modelado que permiten consultas eficientes, integraciones directas con plataformas de an\u00e1lisis y reportes avanzados.</p>"},{"location":"#impacto-esperado","title":"Impacto Esperado","text":"<p>Con este proyecto, Comfenalco cuenta con una herramienta centralizada para la gesti\u00f3n y an\u00e1lisis de datos que proporciona:</p> <ul> <li>Mayor eficiencia operativa al reducir redundancias y tiempos de procesamiento.</li> <li>Toma de decisiones basada en datos con acceso r\u00e1pido a informaci\u00f3n consolidada.</li> <li>Cumplimiento normativo y de calidad gracias a procesos de auditor\u00eda y normalizaci\u00f3n.</li> <li>Escalabilidad tecnol\u00f3gica para abordar retos futuros.</li> </ul> <p>Se generan tres diagramas que integran todo el proyecto con el fin de proporcionar una visi\u00f3n clara y estructurada:</p> <ol> <li>Diagrama de flujo de datos: Representa c\u00f3mo se organizan e integran los datos desde sus fuentes hasta el Data Warehouse (DWH).</li> <li>Diagrama entidad-relaci\u00f3n: Muestra las relaciones entre las tablas principales del modelo de datos, incluyendo dimensiones y hechos.</li> <li>Diagrama de secuencia: Describe el proceso de ETL desde la extracci\u00f3n de datos hasta su carga en el DWH.</li> </ol>"},{"location":"#diagramas","title":"Diagramas","text":""},{"location":"#diagrama-1-flujo-de-datos","title":"Diagrama 1: Flujo de Datos","text":"<pre><code>graph TD\n    A(Fuentes de Datos) --&gt; B(Extracci\u00f3n)\n    B --&gt; C(Transformaci\u00f3n)\n    C --&gt; D(Carga en el Data Warehouse)\n    D --&gt; E(M\u00f3dulos Espec\u00edficos)\n    E --&gt; F(An\u00e1lisis y Reportes)\n    E --&gt; G(Integraci\u00f3n con Plataformas)\n    F --&gt; H(Toma de Decisiones Estrat\u00e9gicas)</code></pre>"},{"location":"#diagrama-2-entidad-relacion","title":"Diagrama 2: Entidad-Relaci\u00f3n","text":"<pre><code>erDiagram\n    DIM_TIEMPO {\n        int ID_FECHA PK\n        datetime FECHA\n        varchar DIA_SEMANA\n        varchar MES\n        int ANIO\n    }\n\n    DIM_ESTUDIANTES {\n        int ID_ESTUDIANTE PK\n        varchar NOMBRE\n        varchar DOCUMENTO\n        int ID_PROGRAMA FK\n    }\n\n    DIM_PROGRAMA {\n        int ID_PROGRAMA PK\n        varchar NOMBRE_PROGRAMA\n    }\n\n    FACT_MATRICULAS {\n        int ID_MATRICULA PK\n        int ID_ESTUDIANTE FK\n        int ID_FECHA FK\n        int ID_PROGRAMA FK\n        decimal COSTO\n    }\n\n    DIM_TIEMPO ||--o{ FACT_MATRICULAS : \"ID_FECHA\"\n    DIM_ESTUDIANTES ||--o{ FACT_MATRICULAS : \"ID_ESTUDIANTE\"\n    DIM_PROGRAMA ||--o{ FACT_MATRICULAS : \"ID_PROGRAMA\"</code></pre>"},{"location":"#diagrama-3-secuencia-del-proceso-etl","title":"Diagrama 3: Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    participant Fuente as Fuentes de Datos\n    participant ETL as Proceso ETL\n    participant DWH as Data Warehouse\n    participant Usuario as Usuario Final\n\n    Fuente -&gt;&gt; ETL: Proveer datos crudos\n    ETL -&gt;&gt; ETL: Limpiar y transformar datos\n    ETL -&gt;&gt; DWH: Cargar datos transformados\n    DWH -&gt;&gt; Usuario: Proveer reportes y an\u00e1lisis\n    Usuario -&gt;&gt; DWH: Consultar datos espec\u00edficos</code></pre>"},{"location":"Conexiones_BD/","title":"CONEXI\u00d3N A BASE DE DATOS","text":""},{"location":"Conexiones_BD/#documentacion-para-conexion-a-bases-de-datos-comfenalco","title":"Documentaci\u00f3n para Conexi\u00f3n a Bases de Datos Comfenalco","text":"<p>Este apartado detalla los pasos y configuraciones necesarias para acceder a las distintas fuentes de datos utilizadas en el proyecto de Comfenalco, incluyendo DWH, Q10 y C4C. </p>"},{"location":"Conexiones_BD/#requisitos-previos","title":"Requisitos Previos","text":""},{"location":"Conexiones_BD/#instalacion-y-configuracion-de-vpn","title":"Instalaci\u00f3n y Configuraci\u00f3n de VPN","text":"<ol> <li>Descargue e instale FortiClient VPN.</li> <li>Configure la conexi\u00f3n VPN de acuerdo con las instrucciones de la imagen.  </li> <li>Use las siguientes credenciales:<ul> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxxxxx</code></li> </ul> </li> </ol>"},{"location":"Conexiones_BD/#acceso-a-las-fuentes-de-datos","title":"Acceso a las Fuentes de Datos","text":""},{"location":"Conexiones_BD/#1-data-warehouse-dwh","title":"1. Data Warehouse (DWH)","text":"<ul> <li>Requisitos: Es necesario estar conectado a la VPN.</li> <li>Acceso:<ul> <li>Use SQL Server Management Studio 20 (versi\u00f3n 20.1.10.0 o posterior).</li> <li>Configure la conexi\u00f3n utilizando las instrucciones del archivo <code>\"02.ConfiguracionDWH\"</code>.</li> </ul> </li> <li>Credenciales:<ul> <li>Use las mismas credenciales configuradas para la VPN.</li> </ul> </li> </ul>"},{"location":"Conexiones_BD/#2-q10","title":"2. Q10","text":"<p>El acceso a Q10 no requiere conexi\u00f3n VPN. Siga las instrucciones seg\u00fan el portal espec\u00edfico:</p> <ul> <li> <p>Q10 Cedesarrollo:</p> <ul> <li>URL: https://site.q10.com/login?ReturnUrl=%2F&amp;aplentId=8fa60f3a-1a89-4048-a798-afd5cda72549</li> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxxxxxxx</code></li> </ul> </li> <li> <p>Q10 Desarrollo Empresarial:</p> <ul> <li>URL: https://site.q10.com/login?ReturnUrl=%2F&amp;aplentId=da5db6b7-bead-4cee-b8d0-6503733312d6</li> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxx</code></li> </ul> </li> </ul>"},{"location":"Conexiones_BD/#3-c4c","title":"3. C4C","text":"<ul> <li>Requisitos: Se requiere conexi\u00f3n previa a la VPN para acceder.</li> <li> <p>Acceso:</p> <ul> <li>Ingrese con las siguientes credenciales:</li> <li>Usuario: <code>xxxxxx</code></li> <li>Contrase\u00f1a: <code>xxxxxxxxxxxx</code></li> <li>URL: https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime</li> </ul> </li> </ul>"},{"location":"Conexiones_BD/#notas-importantes","title":"Notas Importantes","text":"<ul> <li> <p>Licencias</p> <ul> <li><code>Q10</code> requiere licencia para el m\u00f3dulo de <code>cedesarrollo</code> y otra licencia para el m\u00f3dulo <code>desarrollo empresarial</code></li> <li><code>C4C</code> requiere licencia vinculada a <code>SAP</code> </li> </ul> </li> <li> <p>VPN:</p> <ul> <li>La conexi\u00f3n VPN es esencial para el acceso a DWH y C4C, pero no se requiere para Q10.</li> <li>Aseg\u00farese de mantener la VPN activa durante toda la sesi\u00f3n de trabajo.</li> </ul> </li> <li> <p>Seguridad:</p> <ul> <li>Evite compartir las credenciales de acceso.</li> <li>Cierre la sesi\u00f3n despu\u00e9s de utilizar las plataformas.</li> </ul> </li> <li> <p>Soporte:</p> <ul> <li>Para problemas de conexi\u00f3n o configuraci\u00f3n, comun\u00edquese con el equipo de TI o consulte los videos de referencia en los documentos de configuraci\u00f3n.</li> </ul> </li> </ul> <p>Esta gu\u00eda asegura un acceso seguro y estructurado a las fuentes de datos clave del proyecto.</p>"},{"location":"about/","title":"Acerca de este proyecto","text":"<p>Este proyecto tiene como objetivo proporcionar una soluci\u00f3n eficiente y f\u00e1cil de usar para [describir el prop\u00f3sito del proyecto]. </p>"},{"location":"about/#proposito","title":"Prop\u00f3sito","text":"<p>El prop\u00f3sito de este proyecto es [especificar el prop\u00f3sito del proyecto, por ejemplo, facilitar la edici\u00f3n de documentos, mejorar la colaboraci\u00f3n, etc.].</p>"},{"location":"about/#caracteristicas","title":"Caracter\u00edsticas","text":"<ul> <li>Caracter\u00edstica 1: [Descripci\u00f3n de la caracter\u00edstica 1]</li> <li>Caracter\u00edstica 2: [Descripci\u00f3n de la caracter\u00edstica 2]</li> <li>Caracter\u00edstica 3: [Descripci\u00f3n de la caracter\u00edstica 3]</li> </ul>"},{"location":"about/#detalles-relevantes","title":"Detalles relevantes","text":"<p>Para m\u00e1s informaci\u00f3n sobre c\u00f3mo contribuir o utilizar este proyecto, consulte la documentaci\u00f3n en [enlace a la documentaci\u00f3n o repositorio].</p>"},{"location":"buenaspracticas/","title":"Buenas Pr\u00e1cticas Implementadas en el Proyecto Comfenalco","text":""},{"location":"buenaspracticas/#buenas-practicas-implementadas-en-el-proyecto-comfenalco","title":"Buenas Pr\u00e1cticas Implementadas en el Proyecto Comfenalco","text":"<p>El proyecto Comfenalco adopta una serie de buenas pr\u00e1cticas para garantizar la eficiencia, escalabilidad, calidad y mantenibilidad de los procesos y el Data Warehouse (DWH). A continuaci\u00f3n, se destacan las principales buenas pr\u00e1cticas identificadas y aplicadas en el proyecto, con el an\u00e1lisis adicional del archivo <code>Funciones.py</code>.</p>"},{"location":"buenaspracticas/#1-modelado-dimensional","title":"1. Modelado Dimensional","text":"<p>Descripci\u00f3n: El uso de un modelo dimensional permite organizar los datos en tablas de dimensiones y hechos, optimizando las consultas y an\u00e1lisis. Esto asegura un dise\u00f1o eficiente y escalable.</p> <p>Ejemplos: - Tablas <code>DIM_TIEMPO</code>, <code>DIM_ESTUDIANTES</code> y <code>FACT_NOTAS</code> para an\u00e1lisis temporal y acad\u00e9mico. - Separaci\u00f3n clara entre datos descriptivos (dimensiones) y m\u00e9tricas (hechos), como en los m\u00f3dulos <code>Cedesarrollo</code>, <code>Protecci\u00f3n</code> y <code>Colegio</code>.</p> <p>Beneficios: - Eficiencia en las consultas. - Flexibilidad para agregar nuevas dimensiones y hechos.</p>"},{"location":"buenaspracticas/#2-integridad-referencial","title":"2. Integridad Referencial","text":"<p>Descripci\u00f3n: El uso de claves primarias y for\u00e1neas en todas las relaciones asegura la consistencia de los datos entre tablas.</p> <p>Ejemplos: - Relaciones entre <code>DIM_ESTUDIANTES</code>, <code>DIM_PROGRAMA</code> y <code>FACT_MATRICULAS</code>. - Implementaci\u00f3n de restricciones <code>FOREIGN KEY</code> en m\u00f3dulos como <code>Transversal</code> y <code>Cedesarrollo</code>.</p> <p>Beneficios: - Evita inconsistencias y errores en los datos. - Garantiza la coherencia de las relaciones.</p>"},{"location":"buenaspracticas/#3-automatizacion-y-modularidad-en-el-etl","title":"3. Automatizaci\u00f3n y Modularidad en el ETL","text":"<p>Descripci\u00f3n: El proyecto utiliza un flujo ETL modular y automatizado para facilitar la extracci\u00f3n, transformaci\u00f3n y carga de datos.</p> <p>Ejemplos: - Uso de decoradores para registrar eventos y tiempos en funciones clave como <code>process_files_from_folder</code>. - Dise\u00f1o modular mediante funciones espec\u00edficas como <code>guardar_en_dwh</code>, <code>obtener_conexion</code> y <code>limpiar_html</code>.</p> <p>Beneficios: - Reutilizaci\u00f3n de c\u00f3digo. - Facilidad para realizar ajustes y escalabilidad.</p>"},{"location":"buenaspracticas/#4-gestion-de-credenciales-segura","title":"4. Gesti\u00f3n de Credenciales Segura","text":"<p>Descripci\u00f3n: Las credenciales se gestionan de forma centralizada y segura mediante archivos de configuraci\u00f3n externos y bibliotecas como <code>configparser</code>.</p> <p>Ejemplos: - Funci\u00f3n <code>credenciales</code> para obtener credenciales de plataformas espec\u00edficas. - Uso de archivos <code>.env</code> para almacenar credenciales sensibles.</p> <p>Beneficios: - Mejora la seguridad al evitar exposici\u00f3n directa de credenciales en el c\u00f3digo. - Facilita la configuraci\u00f3n de m\u00faltiples entornos.</p>"},{"location":"buenaspracticas/#5-registro-detallado-con-logging","title":"5. Registro Detallado con Logging","text":"<p>Descripci\u00f3n: El uso del m\u00f3dulo <code>logging</code> asegura el registro detallado de eventos, errores y tiempos de procesamiento.</p> <p>Ejemplos: - Decorador <code>log_step_decorator</code> para registrar el inicio, finalizaci\u00f3n y duraci\u00f3n de procesos. - Configuraci\u00f3n de logs personalizados para registrar eventos a nivel de consola y archivo.</p> <p>Beneficios: - Facilita la depuraci\u00f3n y el monitoreo de procesos. - Proporciona trazabilidad completa de las operaciones realizadas.</p>"},{"location":"buenaspracticas/#6-gestion-de-archivos-automatizada","title":"6. Gesti\u00f3n de Archivos Automatizada","text":"<p>Descripci\u00f3n: El proyecto incluye funciones avanzadas para procesar, descargar, renombrar y cargar archivos de forma automatizada.</p> <p>Ejemplos: - Funci\u00f3n <code>process_files_from_folder</code> para procesar archivos en una carpeta espec\u00edfica. - <code>upload_file_to_sharepoint</code> para subir archivos autom\u00e1ticamente a SharePoint.</p> <p>Beneficios: - Ahorro de tiempo y reducci\u00f3n de errores manuales. - Consistencia en la gesti\u00f3n de archivos.</p>"},{"location":"buenaspracticas/#7-limpieza-y-normalizacion-de-datos","title":"7. Limpieza y Normalizaci\u00f3n de Datos","text":"<p>Descripci\u00f3n: Se asegura la calidad de los datos mediante funciones dedicadas a la limpieza y estandarizaci\u00f3n.</p> <p>Ejemplos: - <code>limpiar_columnas</code> para eliminar columnas innecesarias y renombrar columnas clave. - <code>replace_values_df</code> para reemplazar valores basados en un diccionario.</p> <p>Beneficios: - Datos m\u00e1s precisos y consistentes. - Menor riesgo de errores en an\u00e1lisis y reportes.</p>"},{"location":"buenaspracticas/#8-escalabilidad-y-modularidad","title":"8. Escalabilidad y Modularidad","text":"<p>Descripci\u00f3n: El dise\u00f1o modular permite incorporar nuevas funciones sin afectar el flujo existente.</p> <p>Ejemplos: - Funciones espec\u00edficas para operaciones como <code>procesar_excel_con_hojas</code>, <code>Combine_and_store</code>, y <code>setup_driver</code>. - Uso de decoradores para extender la funcionalidad sin alterar el c\u00f3digo base.</p> <p>Beneficios: - Reducci\u00f3n de tiempos de implementaci\u00f3n para nuevos requerimientos. - Facilita el mantenimiento y la expansi\u00f3n del sistema.</p>"},{"location":"buenaspracticas/#9-buenas-practicas-de-programacion-en-python","title":"9. Buenas Pr\u00e1cticas de Programaci\u00f3n en Python","text":"<p>Descripci\u00f3n: El c\u00f3digo sigue las buenas pr\u00e1cticas de Python, como modularidad, uso de decoradores, y manejo seguro de excepciones.</p> <p>Ejemplos: - Decoradores como <code>log_step_decorator</code> para mejorar la legibilidad y reutilizaci\u00f3n del c\u00f3digo. - Manejo robusto de excepciones en funciones cr\u00edticas como <code>procesar</code>, <code>descargar_archivos</code> y <code>setup_logger</code>.</p> <p>Beneficios: - Mejora la mantenibilidad del c\u00f3digo. - Reduce errores inesperados durante la ejecuci\u00f3n.</p>"},{"location":"buenaspracticas/#10-uso-de-selenium-para-automatizacion-de-navegacion-web","title":"10. Uso de Selenium para Automatizaci\u00f3n de Navegaci\u00f3n Web","text":"<p>Descripci\u00f3n: Se utiliza Selenium para realizar automatizaci\u00f3n avanzada de navegaci\u00f3n web y manipulaci\u00f3n de interfaces web.</p> <p>Ejemplos: - Funci\u00f3n <code>setup_driver</code> para configurar un entorno de Selenium optimizado. - Operaciones complejas en men\u00fas desplegables y modales mediante funciones como <code>seleccionar_opcion_custom_dropdown</code>.</p> <p>Beneficios: - Automatizaci\u00f3n de tareas repetitivas. - Mayor precisi\u00f3n en la interacci\u00f3n con plataformas web.</p>"},{"location":"buenaspracticas/#11-control-de-versiones-en-descargas","title":"11. Control de Versiones en Descargas","text":"<p>Descripci\u00f3n: Las descargas y sus versiones se manejan de manera efectiva para evitar conflictos de nombres y redundancias.</p> <p>Ejemplos: - Uso de <code>corregir_nombre_archivo</code> para generar nombres \u00fanicos y manejables. - Verificaci\u00f3n de archivos existentes antes de sobrescribir.</p> <p>Beneficios: - Evita p\u00e9rdida de datos por sobrescritura accidental. - Proporciona una estructura clara para las versiones de archivos.</p>"},{"location":"buenaspracticas/#12-facilidad-para-actualizar-credenciales-de-sharepoint","title":"12. Facilidad para Actualizar Credenciales de SharePoint","text":"<p>Descripci\u00f3n: El proyecto Comfenalco incluye una implementaci\u00f3n que permite cambiar las credenciales de SharePoint de manera centralizada y sencilla sin necesidad de modificar el c\u00f3digo fuente del proyecto. Esto se logra utilizando un archivo de configuraci\u00f3n (<code>credenciales.env</code>) para almacenar las credenciales de manera externa.</p> <p>Ejemplo de Implementaci\u00f3n:</p> <ol> <li> <p>Gesti\u00f3n Centralizada de Credenciales:     Las credenciales de SharePoint se almacenan en un archivo llamado <code>credenciales.env</code> ubicado en el directorio del proyecto:</p> <pre><code>client_id = \"nuevo_client_id\"\ncert_thumbprint = \"nueva_cert_thumbprint\"\ntenant_id = \"nuevo_tenant_id\"\nscopes_sharepoint_online = \"https://new.scope.url/.default\"\nsharepoint_base_url = \"https://new.sharepoint.url\"\n</code></pre> </li> <li> <p>Carga Din\u00e1mica de Credenciales:     En el c\u00f3digo, la funci\u00f3n <code>credenciales</code> se encarga de leer este archivo y devolver las credenciales necesarias para conectarse a SharePoint:</p> <pre><code>def credenciales():\n    original_dir = os.getcwd()\n    try:\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        os.chdir(script_dir)\n\n        # Leer las credenciales desde el archivo credenciales.env\n        with open('credenciales.env', 'r') as key_file:\n            lines = key_file.readlines()\n\n        keys = {}\n        for line in lines:\n            key, value = line.strip().split(\" = \")\n            keys[key] = value.strip('\"')\n\n        return keys\n    finally:\n        os.chdir(original_dir)\n</code></pre> </li> <li> <p>Uso en el Proyecto:     Las credenciales cargadas din\u00e1micamente se utilizan para configurar la conexi\u00f3n a SharePoint sin necesidad de modificaciones adicionales en el proyecto:</p> <pre><code>keys = credenciales()\n\nmsal_app = ConfidentialClientApplication(\n    client_id=keys.get(\"client_id\"),\n    authority=f\"https://login.microsoftonline.com/{keys.get('tenant_id')}\",\n    client_credential={\n        \"private_key\": open('key.pem').read(),\n        \"thumbprint\": keys.get(\"cert_thumbprint\")\n    },\n)\n\nheaders = {\n    \"Authorization\": f\"Bearer {msal_app.acquire_token_for_client([keys.get('scopes_sharepoint_online')])['access_token']}\",\n    \"Accept\": \"application/json;odata=verbose\",\n    \"Content-Type\": \"application/json\",\n}\n</code></pre> </li> <li> <p>Cambio de Credenciales en Tiempo de Ejecuci\u00f3n:     Para actualizar las credenciales, solo se necesita modificar el archivo <code>credenciales.env</code> con los nuevos valores. No es necesario cambiar el c\u00f3digo ni reiniciar el proyecto.</p> </li> </ol> <p>Ventajas:</p> <ul> <li>Centralizaci\u00f3n: Permite un \u00fanico punto de administraci\u00f3n de credenciales.</li> <li>Seguridad: Mantiene las credenciales fuera del c\u00f3digo fuente, reduciendo riesgos de exposici\u00f3n.</li> <li>Flexibilidad: Facilita actualizaciones r\u00e1pidas en entornos de desarrollo, pruebas y producci\u00f3n.</li> <li>Escalabilidad: Compatible con m\u00faltiples entornos sin necesidad de cambios en el c\u00f3digo.</li> </ul>"},{"location":"buenaspracticas/#conclusion","title":"Conclusi\u00f3n","text":"<p>Las pr\u00e1cticas implementadas en el proyecto Comfenalco no solo garantizan la eficiencia y la escalabilidad t\u00e9cnica, sino que tambi\u00e9n aseguran la calidad y la seguridad de los procesos. Este enfoque integral establece una base s\u00f3lida para la sostenibilidad y expansi\u00f3n del sistema.</p>"},{"location":"instalacion/","title":"INSTALACI\u00d3N Y CONFIGURACI\u00d3N","text":""},{"location":"instalacion/#instalacion-y-configuracion-del-entorno-para-el-proyecto-comfenalco","title":"Instalaci\u00f3n y Configuraci\u00f3n del Entorno para el Proyecto Comfenalco","text":"<p>Este apartado detalla los pasos necesarios para configurar un entorno funcional que permita la implementaci\u00f3n y ejecuci\u00f3n de los procesos de carga, transformaci\u00f3n y an\u00e1lisis de datos utilizados en el proyecto de Comfenalco. El objetivo principal es garantizar una instalaci\u00f3n uniforme de herramientas y dependencias, configurar correctamente las conexiones a las bases de datos y estructurar el entorno para el \u00f3ptimo funcionamiento del Data Warehouse (DWH).</p>"},{"location":"instalacion/#pasos-para-la-configuracion-del-entorno","title":"Pasos para la Configuraci\u00f3n del Entorno","text":""},{"location":"instalacion/#1-instalacion-de-herramientas-necesarias","title":"1. Instalaci\u00f3n de Herramientas Necesarias","text":""},{"location":"instalacion/#versionamiento-de-herramientas","title":"Versionamiento de Herramientas","text":"<p>Los paquetes ETL del proyecto Comfenalco se desarrollaron originalmente utilizando Visual Studio Community 2022, seg\u00fan las definiciones establecidas en la fase 1 del proyecto. Posteriormente, en la entrega del proyecto, Comfenalco degrada a la versi\u00f3n Visual Studio Professional 2019 para garantizar compatibilidad con los est\u00e1ndares de la organizaci\u00f3n.</p> <p>Entre el 14 y el 17 de enero de 2025, se llevaron a cabo mesas de trabajo conjuntas con el equipo de Comfenalco. Durante estas sesiones, se validaron los paquetes y se realiz\u00f3 la migraci\u00f3n al servidor de pruebas, asegurando el correcto funcionamiento en el entorno de la organizaci\u00f3n. </p>"},{"location":"instalacion/#11-sql-server-management-studio-ssms","title":"1.1 SQL Server Management Studio (SSMS)","text":"<p>Requisitos:</p> <ul> <li>Versi\u00f3n 20.1.10.0 o posterior.</li> <li>Disponible en el siguiente enlace: Descargar SSMS.</li> </ul>"},{"location":"instalacion/#12-visual-studio","title":"1.2 Visual Studio","text":"<p>Versi\u00f3n:</p> <ul> <li>Comfenalco utiliza Visual Studio Profesional 2019 (paga).</li> <li>Para desarrollo, se utiliza Visual Studio Community 2022 (gratuita), versi\u00f3n 17.11.5.</li> <li>Disponible en el siguiente enlace: Descargar Visual Studio Community.</li> </ul>"},{"location":"instalacion/#13-integration-services-ssis","title":"1.3 Integration Services (SSIS)","text":"<p>Pasos de Instalaci\u00f3n:</p> <ol> <li>Crear un proyecto en blanco en Visual Studio.</li> <li>Ir a la pesta\u00f1a Extensiones \u2192 Administrar Extensiones.</li> <li>Buscar Integration Services e instalar la versi\u00f3n 1.3.2 (compatibilidad con Visual Studio 17.11.5).</li> </ol>"},{"location":"instalacion/#14-analysis-services-ssas","title":"1.4 Analysis Services (SSAS)","text":"<p>Pasos de Instalaci\u00f3n:</p> <ol> <li>Crear un proyecto en blanco en Visual Studio.</li> <li>Ir a la pesta\u00f1a Extensiones \u2192 Administrar Extensiones.</li> <li>Buscar Analysis Services e instalar la versi\u00f3n m\u00e1s reciente.</li> <li>Validar que no presente problemas de compatibilidad.</li> </ol>"},{"location":"instalacion/#recomendaciones","title":"Recomendaciones:","text":"<p>Se recomienda dejar las mismas estructuras. La actualizaci\u00f3n de datos de consultas y web scraping es autom\u00e1tica. Y la de archivos corresponde a los propietarios de la informaci\u00f3n.</p>"},{"location":"instalacion/#2-creacion-del-entorno-virtual","title":"2. Creaci\u00f3n del Entorno Virtual","text":"<p>Un entorno virtual permite organizar y aislar las dependencias necesarias para este proyecto. Siga estos pasos:</p> <p>1. Cree un entorno virtual ejecutando el siguiente comando:</p> <pre><code>python -m venv comfenalco_env\n</code></pre> <p>2. Active el entorno virtual:</p> <p>En Windows:</p> <pre><code>comfenalco_env\\Scripts\\activate\n</code></pre> <p>En Linux/macOS:</p> <pre><code>source comfenalco_env/bin/activate\n</code></pre>"},{"location":"instalacion/#3-instalacion-de-dependencias","title":"3. Instalaci\u00f3n de Dependencias","text":"<p>Una vez activado el entorno virtual, instale las librer\u00edas necesarias:</p> <pre><code>pip install sqlalchemy pandas beautifulsoup4 numpy logging python-dateutil concurrent.futures\n</code></pre>"},{"location":"instalacion/#configuracion-inicial-del-proyecto","title":"Configuraci\u00f3n Inicial del Proyecto","text":""},{"location":"instalacion/#1-creacion-de-conexiones","title":"1. Creaci\u00f3n de Conexiones","text":"<p>1. Configuraci\u00f3n en SSIS:</p> <ul> <li>Use el administrador de conexiones ADO.NET.</li> <li>Cree las siguientes conexiones:<ul> <li><code>DWH_COMFENALCO</code></li> <li><code>STAGE_AREA</code></li> <li><code>SAP_ERP</code></li> </ul> </li> <li>Es importante tener activa la VPN al configurar las conexiones.</li> </ul> <p>2. Configuraci\u00f3n Local:</p> <ul> <li>Cree una base de datos local en SQL Server Management Studio llamada <code>DWH_COMFENALCO_local</code> para realizar pruebas.</li> <li>Cree una conexi\u00f3n a esta base local.</li> </ul> <p>3. Parametrizaci\u00f3n de Conexiones:</p> <ul> <li>Configure las variables <code>ConnectionString</code> y <code>Password</code> en el proyecto de SSIS para cada conexi\u00f3n.</li> <li>Consulte el siguiente video (minuto 11 en adelante).</li> </ul> <p>4. Referencia de Proyecto:</p> <ul> <li>Abra el proyecto de referencia disponible en: Proyecto SSIS.</li> </ul>"},{"location":"instalacion/#funciones-principales-del-proyecto","title":"Funciones Principales del Proyecto","text":""},{"location":"instalacion/#1-configuracion-del-logger","title":"1. Configuraci\u00f3n del Logger","text":"<p>Para garantizar un registro de eventos y errores, utilice la funci\u00f3n <code>setup_logger</code>:</p> <pre><code>from Funciones import setup_logger\nimport logging\n\nlogger = setup_logger(log_filename='etl.log', log_level=logging.INFO)\nlogger.info(\"Proceso de configuraci\u00f3n iniciado.\")\n</code></pre>"},{"location":"instalacion/#2-conexion-a-la-base-de-datos","title":"2. Conexi\u00f3n a la Base de Datos","text":"<p>Configure la conexi\u00f3n a las bases de datos con la funci\u00f3n <code>obtener_conexion</code> y el uso de SQLAlchemy:</p> <pre><code>from Funciones import obtener_conexion\nfrom sqlalchemy import create_engine\n\ncadena_conexion = obtener_conexion('nombre_base_datos')\nmotor = create_engine(cadena_conexion)\n</code></pre>"},{"location":"instalacion/#3-funciones-de-procesamiento","title":"3. Funciones de Procesamiento","text":""},{"location":"instalacion/#31-guardar_en_dwh","title":"3.1 <code>guardar_en_dwh</code>","text":"<ul> <li>Prop\u00f3sito: Guarda un <code>DataFrame</code> en una tabla espec\u00edfica del DWH.</li> <li>Uso:</li> </ul> <pre><code>from Funciones import guardar_en_dwh\n\nguardar_en_dwh(df, 'nombre_tabla', logger, multiple=False, if_exists='replace')\n</code></pre>"},{"location":"instalacion/#32-limpiar_html","title":"3.2 <code>limpiar_html</code>","text":"<ul> <li>Prop\u00f3sito: Limpia el contenido de texto con etiquetas HTML.</li> <li>Uso:</li> </ul> <pre><code>from Funciones import limpiar_html\n\ntexto_limpio = limpiar_html(\"&lt;p&gt;Ejemplo&lt;/p&gt;\")\nprint(texto_limpio)  # Salida: Ejemplo\n</code></pre>"},{"location":"instalacion/#33-storeduplicated","title":"3.3 <code>StoreDuplicated</code>","text":"<ul> <li>Prop\u00f3sito: Guarda registros duplicados para an\u00e1lisis posterior.</li> <li>Uso:</li> </ul> <pre><code>from Funciones import StoreDuplicated\n\nStoreDuplicated(\"duplicados.xlsx\", ['columna1', 'columna2'], df, './output')\n</code></pre>"},{"location":"instalacion/#creacion-del-cubo","title":"Creaci\u00f3n del Cubo","text":"<p>1. Configuraci\u00f3n del Cubo:</p> <ul> <li>Use Analysis Services para crear un cubo que contenga las medidas y KPIs necesarios.</li> <li>Incluya esquemas de datos de <code>Transversal</code>, <code>Colegio</code>, <code>Cedesarrollo</code> y <code>Protecci\u00f3n</code>.</li> </ul> <p>2. Poblaci\u00f3n de Tablas:</p> <ul> <li>Llene primero las tablas Dim y posteriormente las tablas Fact.</li> <li>Aseg\u00farese de que las tablas de DWH est\u00e9n vac\u00edas antes de iniciar el proceso de carga.</li> </ul> <p>3. Consumo en Power BI:</p> <ul> <li>Todas las medidas deben estar definidas en el cubo, ya que Power BI no permite la creaci\u00f3n de medidas en tiempo de consulta.</li> </ul> <p>4. Referencias:</p> <ul> <li>Creaci\u00f3n del Cubo 1.</li> <li>Creaci\u00f3n del Cubo 2.</li> </ul>"},{"location":"instalacion/#ejemplo-de-flujo-etl","title":"Ejemplo de Flujo ETL","text":"<pre><code>from Funciones import obtener_conexion, guardar_en_dwh, setup_logger\nimport pandas as pd\nfrom sqlalchemy import create_engine\n\n# Configurar logger\nlogger = setup_logger(log_filename='etl_proceso.log', log_level=logging.INFO)\n\n# Conectar a la base de datos\ncadena_conexion = obtener_conexion('dwh_comfenalco')\nmotor = create_engine(cadena_conexion)\n\n# Leer datos de origen\ndf_origen = pd.read_sql_query(\"SELECT * FROM tabla_origen\", motor)\n\n# Transformaciones necesarias\ndf_origen['nueva_columna'] = df_origen['columna_existente'] * 2\n\n# Cargar datos transformados al DWH\nguardar_en_dwh(df_origen, 'tabla_destino', logger, multiple=False, if_exists='append')\n</code></pre>"},{"location":"instalacion/#conclusion","title":"Conclusi\u00f3n","text":"<p>Con estos pasos, el entorno estar\u00e1 listo para manejar los procesos ETL del proyecto Comfenalco. Al seguir este flujo, se asegura una configuraci\u00f3n consistente, se minimizan errores y se facilita la integraci\u00f3n de nuevos m\u00f3dulos o expansiones del DWH.</p>"},{"location":"00.etl/00.etl_00.Introduccion/","title":"Introducci\u00f3n","text":""},{"location":"00.etl/00.etl_00.Introduccion/#introduccion-a-los-procesos-etl-basados-en-webscraping-para-educacion-tecnica-y-continua","title":"Introducci\u00f3n a los Procesos ETL Basados en Webscraping para Educaci\u00f3n T\u00e9cnica y Continua","text":"<p>La Educaci\u00f3n T\u00e9cnica y Continua exige sistemas robustos y automatizados para gestionar la creciente cantidad de datos acad\u00e9micos y administrativos. Los procesos ETL (Extract, Transform, Load), fundamentados en t\u00e9cnicas avanzadas de webscraping, aseguran la extracci\u00f3n eficiente, la transformaci\u00f3n precisa y la carga estructurada de datos desde diversas fuentes en l\u00ednea. Este enfoque permite consolidar la informaci\u00f3n en tiempo real, optimizando la toma de decisiones y fomentando la colaboraci\u00f3n a trav\u00e9s de plataformas como SharePoint y C4C.</p>"},{"location":"00.etl/00.etl_00.Introduccion/#01-q10","title":"01. Q10","text":"<p>Los flujos ETL asociados a Q10 se dividen en Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua, cada uno dise\u00f1ado para garantizar la calidad, organizaci\u00f3n y accesibilidad de la informaci\u00f3n. La metodolog\u00eda de webscraping permite extraer datos en tiempo real de sistemas acad\u00e9micos, procesarlos autom\u00e1ticamente y presentarlos de manera estructurada.</p> <ul> <li> <p>Educaci\u00f3n T\u00e9cnica:</p> <ul> <li>Docentes Cedesarrollo: Automatiza la recopilaci\u00f3n de informaci\u00f3n docente para su integraci\u00f3n en sistemas acad\u00e9micos. Ver detalle</li> <li>Dise\u00f1o Curricular: Extrae datos de planes de estudio publicados en plataformas digitales. Ver detalle</li> <li>Listado Matr\u00edculas: Captura y procesa datos de matr\u00edculas de estudiantes desde fuentes en l\u00ednea. Ver detalle</li> <li>Ingresos: Estandariza y organiza datos financieros relacionados con estudiantes. Ver detalle</li> <li>Hist\u00f3rico Notas: Recupera y ordena registros de calificaciones hist\u00f3ricos. Ver detalle</li> <li>Egresados: Automatiza el registro y consolidaci\u00f3n de datos de graduados. Ver detalle</li> <li>Desertores: Identifica y categoriza patrones de deserci\u00f3n estudiantil mediante la extracci\u00f3n de datos en l\u00ednea. Ver detalle</li> </ul> </li> <li> <p>Educaci\u00f3n Continua:</p> <ul> <li>Docentes Desarrollo Empresarial: Consolida informaci\u00f3n de instructores provenientes de plataformas empresariales. Ver detalle</li> <li>Preinscritos: Automatiza la captura y organizaci\u00f3n de registros de preinscripci\u00f3n. Ver detalle</li> <li>Listado Matr\u00edculas Empresarial: Procesa matr\u00edculas de estudiantes en el contexto empresarial. Ver detalle</li> <li>Consolidado Inasistencias: Identifica y resume patrones de inasistencias. Ver detalle</li> <li>Estudiantes Inasistencias: Procesa informaci\u00f3n de estudiantes con ausencias frecuentes. Ver detalle</li> <li>Egresados Graduados Empresarial: Establece registros detallados de egresados empresariales desde fuentes remotas. Ver detalle</li> </ul> </li> </ul>"},{"location":"00.etl/00.etl_00.Introduccion/#02-sharepoint-q10","title":"02. SharePoint Q10","text":"<p>La integraci\u00f3n de SharePoint con Q10 potencia la colaboraci\u00f3n y el acceso en tiempo real a los datos extra\u00eddos mediante webscraping. Esta integraci\u00f3n permite una gesti\u00f3n optimizada y compartida de informaci\u00f3n clave.</p> <ul> <li> <p>Cedesarrollo:</p> <ul> <li>Automatiza la extracci\u00f3n y consolidaci\u00f3n de datos sobre docentes, dise\u00f1o curricular, matr\u00edculas, ingresos y registros hist\u00f3ricos, asegurando su disponibilidad en SharePoint.</li> </ul> </li> <li> <p>Desarrollo Empresarial:</p> <ul> <li>Implementa procesos adaptados al \u00e1mbito empresarial, facilitando la gesti\u00f3n de docentes, matr\u00edculas y otros aspectos relevantes.</li> </ul> </li> </ul>"},{"location":"00.etl/00.etl_00.Introduccion/#03-c4c","title":"03. C4C","text":"<p>Los procesos ETL de C4C integran t\u00e9cnicas avanzadas de webscraping para capturar informaci\u00f3n directamente desde sitios web, proporcionando datos din\u00e1micos y de referencia hist\u00f3rica.</p> <ul> <li>Webscraping Actualizable: Captura datos din\u00e1micos que requieren actualizaciones frecuentes.</li> <li>Webscraping Hist\u00f3rico: Archiva y organiza informaci\u00f3n hist\u00f3rica para an\u00e1lisis comparativos y toma de decisiones estrat\u00e9gicas.</li> </ul>"},{"location":"00.etl/00.etl_00.Introduccion/#beneficios-del-enfoque-basado-en-webscraping","title":"Beneficios del Enfoque Basado en Webscraping","text":"<p>Este marco de procesos ETL garantiza:</p> <ul> <li>Eficiencia: Automatizaci\u00f3n de tareas repetitivas y consumo de datos en tiempo real.</li> <li>Calidad de los Datos: Transformaciones y validaciones en cada etapa del flujo.</li> <li>Accesibilidad: Integraci\u00f3n con plataformas como SharePoint y sistemas externos para compartir informaci\u00f3n.</li> <li>Toma de Decisiones Informada: Disponibilidad de datos actualizados y estructurados para an\u00e1lisis estrat\u00e9gicos.</li> </ul>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/00.Procesar_manual/","title":"00.Procesar manual","text":"<pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    procesar\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\n# Si el logger ya tiene manejadores, limpiarlos\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Crear un formateador para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Crear un manejador de archivo para guardar los logs en un archivo\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)  # Asignar el formateador al manejador de archivo\nlogger.addHandler(file_handler)  # Agregar el manejador de archivo al logger\n\n# Crear un manejador de consola para mostrar los logs en la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)  # Asignar el formateador al manejador de consola\nlogger.addHandler(console_handler)  # Agregar el manejador de consola al logger\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\nlogging.info(\"Inicio del proceso principal\")\ntry:\n    # Definir la subcarpeta de descarga\n    subcarpeta_descarga = \"Graduados\"\n    base_dir = os.path.dirname(os.path.dirname(os.getcwd()))  # Subir un nivel desde el directorio actual\n    # Llamar a setup_driver una vez con la subcarpeta deseada para definir el entorno del navegador\n    DOWNLOAD_DIR = os.path.join(base_dir, \"01.Q10\", \"Procesados\", subcarpeta_descarga) \n    # Procesar todos los informes descargados\n    procesar(\"emp_Egresados_Graduados\",DOWNLOAD_DIR)\n    logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\nfinally:\n    logging.info(\"Fin del proceso principal\")\n</code></pre> <pre><code>2024-12-27 20:36:22,094 - INFO - Inicio del proceso principal\n\n\nProcesando archivo: Graduados_Diciembre 2021.xlsx\nArchivo procesado y guardado como: Graduados_Diciembre 2021_27_12_2024.xlsx\nProcesando archivo: Graduados_Noviembre 2024.xlsx\nArchivo procesado y guardado como: Graduados_Noviembre 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2024.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2024.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2024.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Julio 2024.xlsx\nArchivo procesado y guardado como: Graduados_Julio 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Junio 2024.xlsx\nArchivo procesado y guardado como: Graduados_Junio 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Mayo 2024.xlsx\nArchivo procesado y guardado como: Graduados_Mayo 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Abril 2024.xlsx\nArchivo procesado y guardado como: Graduados_Abril 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Marzo 2024.xlsx\nArchivo procesado y guardado como: Graduados_Marzo 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Febrero 2024.xlsx\nArchivo procesado y guardado como: Graduados_Febrero 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Enero 2024.xlsx\nArchivo procesado y guardado como: Graduados_Enero 2024_27_12_2024.xlsx\nProcesando archivo: Graduados_Diciembre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Diciembre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Noviembre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Noviembre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2023.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2023.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Julio 2023.xlsx\nArchivo procesado y guardado como: Graduados_Julio 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Junio 2023.xlsx\nArchivo procesado y guardado como: Graduados_Junio 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Mayo 2023.xlsx\nArchivo procesado y guardado como: Graduados_Mayo 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Abril 2023.xlsx\nArchivo procesado y guardado como: Graduados_Abril 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Marzo 2023.xlsx\nArchivo procesado y guardado como: Graduados_Marzo 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Febrero 2023.xlsx\nArchivo procesado y guardado como: Graduados_Febrero 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Enero 2023.xlsx\nArchivo procesado y guardado como: Graduados_Enero 2023_27_12_2024.xlsx\nProcesando archivo: Graduados_Diciembre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Diciembre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Noviembre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Noviembre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2022.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2022.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Julio 2022.xlsx\nArchivo procesado y guardado como: Graduados_Julio 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Junio 2022.xlsx\nArchivo procesado y guardado como: Graduados_Junio 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Mayo 2022.xlsx\nArchivo procesado y guardado como: Graduados_Mayo 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Abril 2022.xlsx\nArchivo procesado y guardado como: Graduados_Abril 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Marzo 2022.xlsx\nArchivo procesado y guardado como: Graduados_Marzo 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Febrero 2022.xlsx\nArchivo procesado y guardado como: Graduados_Febrero 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Enero 2022.xlsx\nArchivo procesado y guardado como: Graduados_Enero 2022_27_12_2024.xlsx\nProcesando archivo: Graduados_Agosto 2021.xlsx\nArchivo procesado y guardado como: Graduados_Agosto 2021_27_12_2024.xlsx\nProcesando archivo: Graduados_Octubre 2021.xlsx\nArchivo procesado y guardado como: Graduados_Octubre 2021_27_12_2024.xlsx\nProcesando archivo: Graduados_Septiembre 2021.xlsx\nArchivo procesado y guardado como: Graduados_Septiembre 2021_27_12_2024.xlsx\n\n\n2024-12-27 20:39:24,133 - ERROR - Error al subir el archivo Graduados_Diciembre 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2021_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2021.xlsx\n\n\n2024-12-27 20:39:27,544 - ERROR - Error al subir el archivo Graduados_Noviembre 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2024.xlsx\n\n\n2024-12-27 20:39:31,126 - ERROR - Error al subir el archivo Graduados_Octubre 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2024.xlsx\n\n\n2024-12-27 20:39:34,588 - ERROR - Error al subir el archivo Graduados_Septiembre 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2024.xlsx\n\n\n2024-12-27 20:39:38,070 - ERROR - Error al subir el archivo Graduados_Agosto 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2024.xlsx\n\n\n2024-12-27 20:39:41,622 - ERROR - Error al subir el archivo Graduados_Julio 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2024.xlsx\n\n\n2024-12-27 20:39:45,165 - ERROR - Error al subir el archivo Graduados_Junio 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2024.xlsx\n\n\n2024-12-27 20:39:48,702 - ERROR - Error al subir el archivo Graduados_Mayo 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2024.xlsx\n\n\n2024-12-27 20:39:52,235 - ERROR - Error al subir el archivo Graduados_Abril 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2024.xlsx\n\n\n2024-12-27 20:39:55,767 - ERROR - Error al subir el archivo Graduados_Marzo 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2024.xlsx\n\n\n2024-12-27 20:39:59,245 - ERROR - Error al subir el archivo Graduados_Febrero 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2024.xlsx\n\n\n2024-12-27 20:40:02,708 - ERROR - Error al subir el archivo Graduados_Enero 2024_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2024_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2024.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2024.xlsx\n\n\n2024-12-27 20:40:06,252 - ERROR - Error al subir el archivo Graduados_Diciembre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2023.xlsx\n\n\n2024-12-27 20:40:09,955 - ERROR - Error al subir el archivo Graduados_Noviembre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2023.xlsx\n\n\n2024-12-27 20:40:13,505 - ERROR - Error al subir el archivo Graduados_Octubre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2023.xlsx\n\n\n2024-12-27 20:40:17,034 - ERROR - Error al subir el archivo Graduados_Septiembre 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2023.xlsx\n\n\n2024-12-27 20:40:20,564 - ERROR - Error al subir el archivo Graduados_Agosto 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2023.xlsx\n\n\n2024-12-27 20:40:24,026 - ERROR - Error al subir el archivo Graduados_Julio 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2023.xlsx\n\n\n2024-12-27 20:40:27,668 - ERROR - Error al subir el archivo Graduados_Junio 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2023.xlsx\n\n\n2024-12-27 20:40:31,261 - ERROR - Error al subir el archivo Graduados_Mayo 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2023.xlsx\n\n\n2024-12-27 20:40:34,829 - ERROR - Error al subir el archivo Graduados_Abril 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2023.xlsx\n\n\n2024-12-27 20:40:38,378 - ERROR - Error al subir el archivo Graduados_Marzo 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2023.xlsx\n\n\n2024-12-27 20:40:41,798 - ERROR - Error al subir el archivo Graduados_Febrero 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2023.xlsx\n\n\n2024-12-27 20:40:45,253 - ERROR - Error al subir el archivo Graduados_Enero 2023_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2023_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2023.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2023.xlsx\n\n\n2024-12-27 20:40:48,678 - ERROR - Error al subir el archivo Graduados_Diciembre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Diciembre 2022.xlsx\n\n\n2024-12-27 20:40:52,215 - ERROR - Error al subir el archivo Graduados_Noviembre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Noviembre 2022.xlsx\n\n\n2024-12-27 20:40:55,747 - ERROR - Error al subir el archivo Graduados_Octubre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2022.xlsx\n\n\n2024-12-27 20:40:59,443 - ERROR - Error al subir el archivo Graduados_Septiembre 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2022.xlsx\n\n\n2024-12-27 20:41:02,934 - ERROR - Error al subir el archivo Graduados_Agosto 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2022.xlsx\n\n\n2024-12-27 20:41:06,541 - ERROR - Error al subir el archivo Graduados_Julio 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Julio 2022.xlsx\n\n\n2024-12-27 20:41:09,995 - ERROR - Error al subir el archivo Graduados_Junio 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Junio 2022.xlsx\n\n\n2024-12-27 20:41:13,458 - ERROR - Error al subir el archivo Graduados_Mayo 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Mayo 2022.xlsx\n\n\n2024-12-27 20:41:16,902 - ERROR - Error al subir el archivo Graduados_Abril 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Abril 2022.xlsx\n\n\n2024-12-27 20:41:20,401 - ERROR - Error al subir el archivo Graduados_Marzo 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Marzo 2022.xlsx\n\n\n2024-12-27 20:41:23,881 - ERROR - Error al subir el archivo Graduados_Febrero 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Febrero 2022.xlsx\n\n\n2024-12-27 20:41:27,299 - ERROR - Error al subir el archivo Graduados_Enero 2022_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2022_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2022.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Enero 2022.xlsx\n\n\n2024-12-27 20:41:30,710 - ERROR - Error al subir el archivo Graduados_Agosto 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2021_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Agosto 2021.xlsx\n\n\n2024-12-27 20:41:34,138 - ERROR - Error al subir el archivo Graduados_Octubre 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2021_27_12_2024.xlsx\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Octubre 2021.xlsx\n\n\n2024-12-27 20:41:37,540 - ERROR - Error al subir el archivo Graduados_Septiembre 2021_27_12_2024.xlsx. C\u00f3digo de estado: 401\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2021_27_12_2024.xlsx\n\n\n2024-12-27 20:41:40,550 - INFO - Procesamiento de periodos, jornadas y programas completado.\n2024-12-27 20:41:40,551 - INFO - Fin del proceso principal\n\n\nArchivo subido a SharePoint: COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2021.xlsx\n--Archivo COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Procesados\\Graduados\\Graduados_Septiembre 2021.xlsx\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/","title":"0.1. Docentes Cedesarrollo.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code> y <code>warnings</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <pre><code>import logging\nimport time\nimport os\nimport sys\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n# Importar funciones personalizadas desde Utils.Funciones\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, _descargar, close_driver, hacer_clic, procesar,\n    configurar_pasos_autenticacion_cedesarrollo, eliminar_archivos_anteriores\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\nlogging.basicConfig(level=logging.INFO)\n\n# Limpiar manejadores existentes si los hay\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Formateador para los logs\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Manejador para archivo de log\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n\n# Manejador para la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/#automatizacion-de-descarga-y-procesamiento-del-reporte-docentes","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Docentes\"","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/01.Docentes_Cedesarrollo/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Docentes\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>DOWNLOAD_DIR</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_cedesarrollo</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Ingresos detallados por producto\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Este enfoque modular y estructurado facilita la depuraci\u00f3n, escalabilidad y mantenimiento del flujo automatizado.</p> <pre><code>@log_step_decorator(\"Docentes Cedesarrollo\")\ndef main():\n    # Inicia el proceso principal con un mensaje en el log\n    logging.info(\"Inicio del proceso principal\")\n    driver = None  # Inicializa el objeto driver como None para asegurar que est\u00e9 definido\n\n    try:\n        # Define la subcarpeta donde se almacenar\u00e1n las descargas\n        subcarpeta_descarga = \"Docentes\"\n\n        # Configura el driver para la automatizaci\u00f3n del navegador, incluyendo la carpeta de descargas\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configura los pasos de autenticaci\u00f3n requeridos\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n        # Elimina archivos previos que podr\u00edan interferir con las descargas actuales\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        eliminar_archivos_anteriores(nombre_archivo=\"Cedesarrollo_DocenteS\", download_dir=DOWNLOAD_DIR)\n\n        # Define los pasos para la automatizaci\u00f3n del proceso\n        step_1 = pasos_autenticacion + [\n            # Paso: enviar formulario\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n\n            # Paso: acceder a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), \n            {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n\n            # Paso: seleccionar el informe de ingresos detallados por producto\n            (\"clic_Ingresos_detallados_por_producto\", log_step_decorator(\"clic_Ingresos_detallados_por_producto\")(hacer_clic), \n            {'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[5]/div[2]/div[1]/div[2]/a', 'wait_time': 5}),\n\n            # Paso: abrir el selector de fechas\n            (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), \n            {'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n\n            # Paso: descargar el archivo con el informe\n            (\"descargar_archivo\", log_step_decorator(\"descargar_archivo\")(_descargar), \n            {'driver': driver, 'xpath': '//*[@id=\"generar-reporte-btn\"]', \n            'download_dir': DOWNLOAD_DIR, \n            'archivo': f\"Cedesarrollo_Docentes_{time.strftime('%Y_%m_%d')}\", 'wait_time': 10}),\n\n            # Paso: hacer clic en el usuario\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), \n            {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', 'wait_time': 5}),\n\n            # Paso: cerrar sesi\u00f3n\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), \n            {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', 'wait_time': 5}),\n        ]\n\n        # Ejecuta todos los pasos definidos, registrando el progreso en el log\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        # Procesa los datos descargados\n        procesar('cede_Docentes', DOWNLOAD_DIR)\n\n    finally:\n        # Asegura que el driver se cierre correctamente al finalizar el proceso\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\nif __name__ == \"__main__\":\n    # Inicia el script si se ejecuta directamente\n    main()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/","title":"0.2. Dise\u00f1o Curricular.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el flujo de trabajo. Finalmente, se ajustan los niveles de registro de otros loggers configurados en el entorno para mantener la coherencia en el nivel de detalle de los logs.</p> <pre><code>import logging  # Importa el m\u00f3dulo de logging para registrar eventos\nimport os       # Permite interactuar con el sistema operativo (rutas, archivos)\nimport sys      # Proporciona acceso a variables y funciones del sistema\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\n# Esto permite importar m\u00f3dulos definidos en directorios superiores\nsys.path.append(os.path.abspath(\"../../\"))\n\n\n# Importaci\u00f3n de funciones y herramientas necesarias desde el m\u00f3dulo `Utils.Funciones`\nfrom Utils.Funciones import (\n    log_step_decorator,       # Decorador para registrar pasos en el log\n    setup_driver,             # Configura el navegador para la automatizaci\u00f3n\n    procesar,                 # Procesa archivos descargados\n    close_driver,             # Cierra el navegador de forma segura\n    hacer_clic,               # Realiza clics en elementos de la interfaz web\n    configurar_pasos_autenticacion_cedesarrollo,  # Configura pasos de autenticaci\u00f3n\n    procesar_reporte_modal,     # Maneja y valida reportes descargados\n    log_tiempo,                 # Calcula y registra el tiempo de ejecuci\u00f3n    \n)\n\n# Configuraci\u00f3n del sistema de logging\nlogger = logging.getLogger(__name__)  # Crea un logger con el nombre del m\u00f3dulo actual\nlogger.setLevel(logging.INFO)         # Define el nivel de registro como INFO\n\n# Evita duplicar manejadores si ya se han configurado previamente\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Configura el formato est\u00e1ndar para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Manejador para registrar los mensajes en un archivo de log\nfile_handler = logging.FileHandler(\"scraper.log\")  # Define el archivo de salida\nfile_handler.setFormatter(formatter)              # Aplica el formato al manejador\nlogger.addHandler(file_handler)                   # Agrega el manejador al logger\n\n# Manejador para registrar los mensajes en la consola\nconsole_handler = logging.StreamHandler()         # Define la salida por consola\nconsole_handler.setFormatter(formatter)           # Aplica el formato al manejador\nlogger.addHandler(console_handler)                # Agrega el manejador al logger\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/#automatizacion-de-descarga-y-procesamiento-del-reporte-diseno-curricular","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Dise\u00f1o Curricular\"","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/02.Disenio_curricular/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Dise\u00f1o Curricular\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>download_dir</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_cedesarrollo</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Dise\u00f1o Curricular\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar_reporte_modal</code> y <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Este enfoque modular y estructurado facilita la depuraci\u00f3n, escalabilidad y mantenimiento del flujo automatizado.</p> <pre><code>@log_step_decorator(\"Dise\u00f1o Curricular\")\ndef main():\n    # Registra el inicio del proceso en el log\n    driver = None  # Inicializa el driver como None\n\n    try:\n        # Define la subcarpeta para descargas y configura el driver\n        subcarpeta_descarga = \"Dise\u00f1o_curricular\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configura los elementos clave del proceso\n        xpath_boton = '//*[@id=\"formReportes\"]/div[1]/div[3]/div/button'  # XPath del bot\u00f3n de opciones\n        xpath_contenedor_opciones = '//*[@id=\"formReportes\"]/div[1]/div[3]/div/div/ul'  # XPath del contenedor de opciones\n        excluir_opciones = {}  # Diccionario para excluir opciones, si corresponde\n\n        id_descargar = 'generar-reporte-btn'  # ID del bot\u00f3n para generar el reporte\n        nombre_archivo = 'Dise\u00f1o_curricular'  # Nombre base del archivo\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'  # Nombre completo con extensi\u00f3n\n\n        # Configura los pasos de autenticaci\u00f3n necesarios para acceder al sistema\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n        # Define los pasos del flujo de trabajo, incluyendo autenticaci\u00f3n, navegaci\u00f3n y generaci\u00f3n del reporte\n        step_1 = pasos_autenticacion + [\n            # Paso: Enviar formulario de autenticaci\u00f3n\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n            }),\n            # Paso: Entrar a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5\n            }),\n            # Paso: Seleccionar el reporte \"Dise\u00f1o Curricular\"\n            (\"dise\u00f1o_curricular\", log_step_decorator(\"dise\u00f1o_curricular\")(hacer_clic), {\n                'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[4]/div[2]/a', 'wait_time': 5\n            }),\n            # Paso: Generar el reporte\n            (\"clic_generar_reporte\", log_step_decorator(\"clic_generar_reporte\")(hacer_clic), {\n                'driver': driver, 'id': id_descargar, 'wait_time': 30\n            }),\n            # Paso: Procesar el reporte generado\n            (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {\n                'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo\n            })\n        ]\n\n        # Ejecuta los pasos del flujo, registrando el progreso en el log\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        # Procesa los datos descargados del reporte\n        procesar('cede_Dise\u00f1o_Curricular', download_dir)\n\n    finally:\n        # Cierra el driver al finalizar, garantizando que los recursos se liberen\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    # Inicia la ejecuci\u00f3n del script si es ejecutado directamente\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/","title":"0.3. Listado Matr\u00edculas.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code> y <code>argparse</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Finalmente, se ajustan los niveles de registro de otros loggers configurados en el entorno para mantener la coherencia en el nivel de detalle de los logs.</p> <pre><code>import logging, os, sys, time, argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\n# Importar funciones espec\u00edficas del m\u00f3dulo Utils.Funciones\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, generar_fechas,\n    close_driver, hacer_clic, configurar_pasos_autenticacion_cedesarrollo, procesar_reporte_modal\n)\n\n# Configuraci\u00f3n del logger\nlogger = logging.getLogger(__name__)  # Crear un logger con el nombre del m\u00f3dulo actual\nlogger.setLevel(logging.INFO)  # Establecer el nivel de registro en INFO\n\n# Limpiar los manejadores existentes si los hay\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Crear un formateador para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Crear un manejador de archivo para registrar los logs en un archivo\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)  # Asignar el formateador al manejador de archivo\nlogger.addHandler(file_handler)  # Agregar el manejador de archivo al logger\n\n# Crear un manejador de consola para mostrar los logs en la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)  # Asignar el formateador al manejador de consola\nlogger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/#automatizacion-de-descarga-de-listados-de-matriculas-por-ano","title":"Automatizaci\u00f3n de Descarga de Listados de Matr\u00edculas por A\u00f1o","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/03.Listado_matriculas/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Listado_matriculas\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los rangos de fechas por a\u00f1o. Cada iteraci\u00f3n del bucle configura un rango de fechas personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar fechas y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos obligatorios: <code>--start-year</code> y <code>--end-year</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los listados de matr\u00edculas desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Listado de matr\u00edculas\")\ndef main(fechas):\n    # Registra el inicio del proceso en el log\n    driver = None  # Inicializa el driver como None para su manejo seguro\n\n    try:\n        # Define la subcarpeta para las descargas y configura el navegador\n        subcarpeta_descarga = \"Listado_matriculas\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        nombre_archivo = 'Listado_matriculas2024'  # Nombre base del archivo\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'  # Nombre completo con extensi\u00f3n\n\n        # Configura los pasos de autenticaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n        # Pasos iniciales: autenticarse y navegar al listado de matr\u00edculas\n        step_1 = pasos_autenticacion + [\n            # Enviar formulario de autenticaci\u00f3n\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n            }),\n            # Entrar a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5\n            }),\n            # Seleccionar el listado de matr\u00edculas\n            (\"listado\", log_step_decorator(\"listado\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[1]/div[2]/div[3]/div[2]/div[9]/div[1]/a', 'wait_time': 5\n            })\n        ]\n\n        # Ejecuta los pasos iniciales\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)        \n\n        # Itera por cada rango de fechas para configurar y descargar el reporte\n        for fecha in fechas:\n            logging.info(f\"Fecha: {fecha}\")\n            logging.info(f\"Desde {fechas[fecha]['desde']} hasta {fechas[fecha]['hasta']}\")\n\n            # Pasos para configurar el rango de fechas y descargar el reporte\n            step_2 = [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), {\n                    'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3\n                }),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[9]/div[3]/ul/li[7]', 'wait_time': 3\n                }),\n                (\"entrar_en_fecha1\", log_step_decorator(\"entrar_en_fecha1\")(hacer_clic), {\n                    'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', \n                    'value': fechas[fecha]['desde'], \n                    'driver': driver, 'wait_time': 3\n                }),\n                (\"entrar_en_fecha2\", log_step_decorator(\"entrar_en_fecha2\")(hacer_clic), {\n                    'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', \n                    'value': fechas[fecha]['hasta'], \n                    'driver': driver, 'wait_time': 3\n                }),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 3\n                }),\n                (\"descargar\", log_step_decorator(\"descargar\")(hacer_clic), {\n                    'driver': driver, 'xpath': '//*[@id=\"generar-reporte-btn\"]', 'wait_time': 3\n                }),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {\n                    'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo\n                })\n            ]\n            # Ejecuta los pasos del flujo para el rango de fechas actual\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                time.sleep(5)  # Pausa breve para evitar problemas de sincronizaci\u00f3n\n\n    finally:\n        # Asegura que el navegador se cierre correctamente\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n        # Procesa los datos descargados tras la finalizaci\u00f3n del flujo\n        time.sleep(5)\n        procesar(\"cede_Listado_Matriculas\", download_dir)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/04.Ingresos/","title":"0.4. Ingresos.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/04.Ingresos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, y <code>argparse</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Todos los loggers configurados en el entorno tambi\u00e9n se ajustan al nivel <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <pre><code>import logging, os, sys, time,argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, generar_fechas, _descargar,procesar,\n    close_driver, hacer_clic, configurar_pasos_autenticacion_cedesarrollo, procesar_reporte_modal,seleccionar_opcion_custom_dropdown\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/04.Ingresos/#automatizacion-de-descarga-de-ingresos","title":"Automatizaci\u00f3n de Descarga de Ingresos","text":"<p>Este script automatiza la descarga y procesamiento de listados de ingresos correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Ingresos\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los periodos por a\u00f1o generados din\u00e1micamente seg\u00fan los argumentos proporcionados. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del ultimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el ultimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Ingresos\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    # Genera el diccionario de fechas para el semestre cuando se deja semestre = True, de lo contrario hace el diccionario de acuerdo a los a\u00f1os inicio y fin\n    nombre_archivo = 'Ingresos'\n    subcarpeta_descarga = \"Ingresos\"\n    nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n\n    for fecha in fechas:\n        logging.info(f\"Fecha: {fecha}\")\n        logging.info(f\"Desde {fechas[fecha]['desde']} hasta {fechas[fecha]['hasta']}\")\n        driver = None\n        try:\n            driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n            pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n\n            step_1 = [\n                (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                    'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n                }),\n                (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5\n                }),\n                (\"Ingresos\", log_step_decorator(\"Ingresos\")(hacer_clic), {\n                    'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[5]/div[2]/a', 'wait_time': 3\n                }),\n                (\"descartar\", log_step_decorator(\"descartar0\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[3]/button', 'wait_time': 3\n                }),            \n                (\"descartar\", log_step_decorator(\"descartar1\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[1]/div[2]/div/button/span', 'wait_time': 3\n                }),            \n                (\"descartar1\", log_step_decorator(\"descartar2\")(hacer_clic), {\n                    'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[3]/button', 'wait_time': 3\n                })                             \n            ]\n\n\n\n            step_2 =pasos_autenticacion + step_1 + [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[10]/div[3]/ul/li[7]', 'wait_time': 3}),\n                # (\"entrar_en_personalizado_2\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[12]/div[3]/ul/li[7]', 'wait_time': 5}),   \n                (\"entrar_en_fecha1\",log_step_decorator(\"entrar_en_fecha1\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', 'value': fechas[fecha]['desde'], 'driver': driver,'wait_time': 5}),\n                (\"entrar_en_fecha2\",log_step_decorator(\"entrar_en_fecha2\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[2]/input','value': fechas[fecha]['hasta'],'driver': driver,'wait_time': 5}),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 5}),\n                (\"programar-reporte-btn\", log_step_decorator(\"descargar\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"programar-reporte-btn\"]', 'wait_time': 80}), \n                (\"abrir-reporte\", log_step_decorator(\"descargar1\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"abrir-reporte\"]', 'wait_time': 5}),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo}),\n                (\"descartar\", log_step_decorator(\"descartar\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/div[3]/button', 'wait_time': 10})\n                ]\n\n            ultimo=0\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                if step_name==\"programar-reporte-btn\":\n                    time.sleep(80)\n                time.sleep(5)\n            procesar(\"cede_Ingresos\", download_dir)\n\n\n        finally:\n            if driver:\n                close_driver(driver)\n            logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular ultimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/05.Historico_notas_Cedesarrollo/","title":"0.5. Hist\u00f3rico notas.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/05.Historico_notas_Cedesarrollo/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>argparse</code> y <code>warnings</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>eliminar_archivos_anteriores</code> para gestionar los archivos descargados previamente.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Finalmente, se ajustan los niveles de otros loggers configurados para mantener la coherencia en el registro de eventos.</p> <pre><code>import logging, time, os, sys, argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar_reporte_modal, obtener_elementos_dropdown, \n    hacer_clic, procesar, seleccionar_opcion_con_js, guardar_diccionario,\n    configurar_pasos_autenticacion_cedesarrollo, eliminar_archivos_anteriores, ejecutar_pasos\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\n# Si el logger ya tiene manejadores, limpiarlos\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Crear un formateador para los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Crear un manejador de archivo para guardar los logs en un archivo\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)  # Asignar el formateador al manejador de archivo\nlogger.addHandler(file_handler)  # Agregar el manejador de archivo al logger\n\n# Crear un manejador de consola para mostrar los logs en la consola\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)  # Asignar el formateador al manejador de consola\nlogger.addHandler(console_handler)  # Agregar el manejador de consola al logger\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/05.Historico_notas_Cedesarrollo/#automatizacion-de-descarga-de-historico-notas","title":"Automatizaci\u00f3n de Descarga de H\u00edstorico Notas","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Historico_notas\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un conjunto llamado <code>consulta</code>, que contiene los periodos por a\u00f1o desde el a\u00f1o inicial hasta el a\u00f1o final. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_1</code>. Adem\u00e1s, el script incluye un fragmento comentado para generar autom\u00e1ticamente este conjunto de periodos mediante una funci\u00f3n.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>driver.quit()</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Historico de Notas\")\ndef main(consulta):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Historico_notas\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada para definir el entorno del navegador\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones en la aplicaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n        step_1 = pasos_autenticacion + [\n            # Enviar formulario de autenticaci\u00f3n\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            # Navegar a la secci\u00f3n de informes\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n            # Hacer clic en el enlace de Hist\u00f3rico de Notas\n            (\"clic_historico_notas\",log_step_decorator(\"clic_historico_notas\")(hacer_clic), {'driver': driver, 'xpath': \n                '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[7]/div[2]/a',\n                'wait_time': 5}),\n        ]\n        # Ejecutar los pasos de autenticaci\u00f3n configurados\n        ejecutar_pasos(step_1)\n\n        # Definir los elementos de selecci\u00f3n del per\u00edodo (bot\u00f3n y lista desplegable)\n        _xpath_periodo  = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[1]/div[3]'\n        periodo_boton = f'{_xpath_periodo}/div/button'\n        periodo_list = f'{_xpath_periodo}/div/div/ul'        \n        nivel=1\n\n        # Obtener los periodos disponibles en el dropdown\n        _periodos = obtener_elementos_dropdown(driver, periodo_boton, periodo_list, nivel)\n\n        periodos_generados = [f\"{year}\" for year in consulta]\n\n        # Filtrar solo los per\u00edodos que comiencen con los valores generados\n        periodos = [\n            periodo for periodo in _periodos \n            if any(periodo.startswith(generado) for generado in periodos_generados)\n        ]\n\n        # Guardar los per\u00edodos seleccionados en un archivo para referencia\n        # guardar_diccionario(periodos, 'periodos')\n\n        # Eliminar archivos anteriores en la carpeta de descargas antes de procesar nuevos\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        # Procesar cada periodo seleccionado\n        if periodos:\n            for periodo in periodos:\n                # Seleccionar el per\u00edodo en el dropdown\n                hacer_clic(driver= driver, xpath=periodo_boton, wait_time= 1)\n                seleccionar_opcion_con_js(driver, periodo_boton, periodo)\n                logging.info(f\"Procesando periodo: {periodo}\")\n\n                # Obtener jornadas para el per\u00edodo seleccionado\n                xpath_jornada = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[2]/div[3]'\n                jornada_boton = f'{xpath_jornada}/div/button'\n                jornada_list = f'{xpath_jornada}/div/div/ul'\n                jornadas = obtener_elementos_dropdown(driver, jornada_boton, jornada_list, nivel=2)\n                excluir_jornadas = {'Seleccione'}\n                jornadas = [jornada for jornada in jornadas if jornada not in excluir_jornadas]                \n\n                # Procesar cada jornada seleccionada\n                if jornadas:\n                    for jornada in jornadas:\n                        # Seleccionar la jornada en el dropdown\n                        hacer_clic(driver= driver, xpath=jornada_boton, wait_time= 1)\n                        seleccionar_opcion_con_js(driver, jornada_boton, jornada)\n                        logging.info(f\"Procesando jornada: {jornada}\")\n\n                        # Obtener programas para la jornada seleccionada\n                        xpath_programa = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[3]/div[3]'\n                        programa_boton = f'{xpath_programa}/div/button'\n                        programa_list = f'{xpath_programa}/div/div/ul'\n                        programas = obtener_elementos_dropdown(driver, programa_boton, programa_list, nivel=3)\n                        excluir_opciones = {'Seleccione','Control de Calidad'}\n                        programas = [programa for programa in programas if programa not in excluir_opciones]\n\n                        # Procesar cada programa seleccionado\n                        if programas:\n                            for programa in programas:\n                                # Seleccionar el programa en el dropdown\n                                hacer_clic(driver= driver, xpath=programa_boton, wait_time= 1)\n                                seleccionar_opcion_con_js(driver, programa_boton, programa)\n                                logging.info(f\"Procesando programa: {programa}\")\n\n                                # Obtener m\u00f3dulos para el programa seleccionado\n                                xpath_modulo = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[4]/div[3]'\n                                modulo_boton = f'{xpath_modulo}/div/button'\n                                modulo_list = f'{xpath_modulo}/div/div/ul'\n                                modulos = obtener_elementos_dropdown(driver, modulo_boton, modulo_list, nivel=4)\n                                excluir_modulos = {'Seleccione'}\n                                modulos = [modulo for modulo in modulos if modulo not in excluir_modulos]\n\n                                # Procesar cada m\u00f3dulo seleccionado\n                                if modulos:\n                                    for modulo in modulos:\n                                        # Seleccionar el m\u00f3dulo en el dropdown\n                                        hacer_clic(driver= driver, xpath=modulo_boton, wait_time= 1)\n                                        seleccionar_opcion_con_js(driver, modulo_boton, modulo)\n                                        logging.info(f\"Procesando modulo: {modulo}\")\n\n                                        # Obtener cursos para el m\u00f3dulo seleccionado\n                                        xpath_curso = '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[5]/div[3]'\n                                        cursos_boton = f'{xpath_curso}/div/button'\n                                        cursos_list = f'{xpath_curso}/div/div/ul'\n                                        cursos = obtener_elementos_dropdown(driver, cursos_boton, cursos_list, nivel=5)\n                                        excluir_cursos = {'Seleccione'}\n                                        cursos = [curso for curso in cursos if curso not in excluir_cursos]\n\n                                        # Procesar cada curso seleccionado\n                                        if cursos:\n                                            for curso in cursos:\n                                                # Seleccionar el curso en el dropdown\n                                                seleccionar_opcion_con_js(driver, cursos_boton, curso)\n                                                # Hacer clic en el bot\u00f3n para descargar el informe\n                                                hacer_clic(driver= driver, xpath=\n                                                    '/html/body/div[3]/div/div[1]/div[2]/div[2]/div/div/div/div[2]/form/div[7]/button'\n                                                    , wait_time=5)\n                                                # Guardar el archivo descargado con un nombre significativo\n                                                archivo = f'Cede_{periodo}_{jornada}_{programa}_{modulo}_{curso}.xlsx'\n                                                procesar_reporte_modal(driver, DOWNLOAD_DIR, archivo)\n                                                # Esperar un poco entre descargas\n                                                time.sleep(5)\n                                else: continue\n                        else: continue\n                else: continue\n\n        # Procesar todos los informes descargados\n        procesar(\"cede_Historico_Notas\",DOWNLOAD_DIR)\n        logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\n    finally:\n        # Cerrar el driver para liberar recursos\n        if driver:\n            driver.quit()\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    consulta = {_inicio, _fin}\n    main(consulta=consulta)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/06.Egresados_graduados_Cedesarrollo/","title":"0.6. Egresados.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/06.Egresados_graduados_Cedesarrollo/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>argparse</code> y <code>time</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <pre><code>import logging\nimport time\nimport os\nimport sys,argparse\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic, generar_fechas, generar_periodos,\n    configurar_pasos_autenticacion_cedesarrollo, eliminar_archivos_anteriores, pre_procesamiento_periodo\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/06.Egresados_graduados_Cedesarrollo/#automatizacion-de-descarga","title":"Automatizaci\u00f3n de Descarga","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Graduados\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>periodos</code>, que contiene los periodos por a\u00f1o desde el a\u00f1o inicial hasta el a\u00f1o final especificados por el usuario. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_1</code>. Adem\u00e1s, el script incluye un fragmento comentado para generar autom\u00e1ticamente este diccionario de periodos mediante una funci\u00f3n.</p> <p>El diccionario <code>step_1</code> contiene una serie de pasos que se ejecutan secuencialmente para automatizar el proceso de scraping. Cada entrada en el diccionario es una tupla que incluye:</p> <ol> <li>Nombre del paso: Una cadena que describe la acci\u00f3n a realizar.</li> <li>Funci\u00f3n del paso: Una funci\u00f3n decorada con <code>log_step_decorator</code> que realiza la acci\u00f3n.</li> <li>Par\u00e1metros del paso: Un diccionario de par\u00e1metros que se pasan a la funci\u00f3n del paso.</li> </ol> <p>Por ejemplo, el paso <code>(\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10})</code> indica que se debe hacer clic en el bot\u00f3n de env\u00edo del formulario, utilizando el driver de Selenium y esperando hasta 10 segundos para que el elemento est\u00e9 disponible.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Graduados\")\ndef main(periodos):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Graduados\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Graduados'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n            (\"clic_egresados\", log_step_decorator(\"clic_egresados\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[5]/div[2]/div[1]/div[3]/a', \n                'wait_time': 5\n            }),\n            (\"seleccionar_tipo_graduado\", log_step_decorator(\"seleccionar_tipo_graduado\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[1]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"seleccionperiodos\", log_step_decorator(\"seleccionperiodos\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[2]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"pre_procesamiento_periodo\", log_step_decorator(\"pre_procesamiento\")(pre_procesamiento_periodo), {\n                'driver': driver,\n                'download_dir': DOWNLOAD_DIR,\n                'id_descargar': 'generar-reporte-btn',\n                'nombre_archivo': nombre_archivo,\n                'nombre_archivo_completo': nombre_archivo_completo,\n                'xpath_boton': '//*[@id=\"form0\"]/div[4]/div[3]/div/button',\n                'tipo':'normal',\n                'xpath_contenedor_opciones':  '//*[@id=\"form0\"]/div[4]/div[3]/div/div/ul',\n                'items_opciones':periodos\n            }),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', \n                'wait_time': 5\n            }),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', \n                'wait_time': 5\n            })\n        ]\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        procesar('cede_Egresados_Graduados', DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    periodos = generar_periodos(_inicio, _fin)\n    main(periodos)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/07.Desertores/","title":"0.7. Desertores.py","text":""},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/07.Desertores/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, y <code>time</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos, <code>configurar_pasos_autenticacion_cedesarrollo</code> para configurar los pasos de autenticaci\u00f3n, y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <pre><code>import logging\nimport os, time\nimport sys,argparse\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\"))\n\n# Importar funciones espec\u00edficas del m\u00f3dulo Utils.Funciones\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, generar_fechas, procesar,guardar_diccionario,\n    close_driver, hacer_clic, configurar_pasos_autenticacion_cedesarrollo, procesar_reporte_modal\n)\n\n# Obtener el logger con el nombre del m\u00f3dulo actual\nlogger = logging.getLogger(__name__)  \n\n# Establecer el nivel de registro a INFO\nlogger.setLevel(logging.INFO)\n\n# Limpiar los manejadores existentes si los hay\nif logger.hasHandlers():\n    logger.handlers.clear()\n\n# Formato de los mensajes de log\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n# Configuraci\u00f3n del manejador de archivos para el log\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\n\n# Configuraci\u00f3n del manejador de consola para el log\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_01.educaciontecnica/07.Desertores/#automatizacion-de-descarga","title":"Automatizaci\u00f3n de Descarga","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas correspondientes a distintos a\u00f1os desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes anuales.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Desertores\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los periodos definidos por el usuario. Cada iteraci\u00f3n del bucle configura un periodo personalizado en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar periodos y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El diccionario <code>step_1</code> contiene una serie de pasos que se ejecutan secuencialmente para automatizar el proceso de scraping. Cada entrada en el diccionario es una tupla que incluye:</p> <ol> <li>Nombre del paso: Una cadena que describe la acci\u00f3n a realizar.</li> <li>Funci\u00f3n del paso: Una funci\u00f3n decorada con <code>log_step_decorator</code> que realiza la acci\u00f3n.</li> <li>Par\u00e1metros del paso: Un diccionario de par\u00e1metros que se pasan a la funci\u00f3n del paso.</li> </ol> <p>Por ejemplo, el paso <code>(\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10})</code> indica que se debe hacer clic en el bot\u00f3n de env\u00edo del formulario, utilizando el driver de Selenium y esperando hasta 10 segundos para que el elemento est\u00e9 disponible.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Desertores\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        subcarpeta_descarga = \"Desertores\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Dise\u00f1o_curricular'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n        # Pasar driver al configurar pasos de autenticaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_cedesarrollo(driver)\n        # Definir los pasos de autenticaci\u00f3n y navegaci\u00f3n inicial\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[2]/a', 'wait_time': 5}),\n            (\"desertores\", log_step_decorator(\"desertores\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[3]/div[1]/a', 'wait_time': 5}),\n        ]\n\n        # Ejecutar los pasos de autenticaci\u00f3n y navegaci\u00f3n inicial\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n        guardar_diccionario(fechas, 'fechas')\n        for fecha in fechas:\n            logging.info(f\"Fecha: {fecha}\")\n\n            step_2 = [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/div[9]/div[3]/ul/li[7]', 'wait_time': 3}),\n                (\"entrar_en_fecha1\", log_step_decorator(\"entrar_en_fecha1\")(hacer_clic), {'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', 'value': fechas[fecha]['desde'], 'driver': driver, 'wait_time': 3}),\n                (\"entrar_en_fecha2\", log_step_decorator(\"entrar_en_fecha2\")(hacer_clic), {'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', 'value': fechas[fecha]['hasta'], 'driver': driver, 'wait_time': 3}),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 3}),\n                (\"descargar\", log_step_decorator(\"descargar\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"generar-reporte-btn\"]', 'wait_time': 5}),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo})\n            ]\n\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                time.sleep(5)\n\n        procesar('cede_Cancelados_Desertores',download_dir)\n\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/","title":"cede_01 procesar_docentes","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport re\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, extract_date, obtener_sharepoint,replace_values_df,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/#procesar_docentes","title":"procesar_docentes","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_01_procesar_docentes/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de docentes almacenados en SharePoint. Primero, se define una funci\u00f3n <code>obtener_sharepoint_docentes</code> que descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica el archivo m\u00e1s reciente basado en la fecha en su nombre, y elimina los archivos m\u00e1s antiguos. Luego, carga el archivo m\u00e1s reciente en un DataFrame de pandas y registra informaci\u00f3n sobre el archivo y su contenido.</p> <p>La funci\u00f3n <code>procesar_cede_Docentes</code> toma el DataFrame cargado y realiza varias transformaciones. Estas incluyen la limpieza de espacios en blanco en los nombres y apellidos, la concatenaci\u00f3n de estos en una nueva columna 'NOMBRE', y la eliminaci\u00f3n y renombrado de columnas seg\u00fan un diccionario de mapeo. Finalmente, selecciona y reordena las columnas del DataFrame para que coincidan con un formato espec\u00edfico.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se registran mensajes informativos, se obtienen y procesan los datos de SharePoint, se muestran las primeras filas del DataFrame procesado y se actualizan los datos procesados de vuelta en SharePoint.</p> <pre><code>@log_step_decorator('obtener_sharepoint_docentes')\ndef obtener_sharepoint_docentes():\n    # Obtiene la URL de la carpeta de SharePoint desde un diccionario `etl_to_folder_url`.\n    folder_url = etl_to_folder_url.get('cede_Docentes', \"URL por defecto si no se encuentra el valor de etl\")\n    # Llama a la funci\u00f3n `obtener_sharepoint` para descargar los archivos en la carpeta local `_folder`.\n    obtener_sharepoint(folder_url,_folder)\n\n    # Busca todos los archivos que coincidan con el patr\u00f3n \"Docentes_*.xlsx\" en la carpeta local.\n    files = glob.glob(os.path.join(_folder, \"Docentes_*.xlsx\"))\n\n    # Utiliza una expresi\u00f3n regular para extraer la fecha de los nombres de los archivos.\n    date_pattern = re.compile(r'Docentes_(\\d{2})_(\\d{2})_(\\d{4})\\.xlsx')\n\n    # Encuentra el archivo m\u00e1s reciente basado en la fecha extra\u00edda.\n    latest_file = max(files, key=lambda f: extract_date(f,date_pattern))\n\n    # Elimina todos los archivos excepto el m\u00e1s reciente.\n    for file in files:\n        if file != latest_file:\n            os.remove(file)\n\n    # Registra informaci\u00f3n sobre el archivo m\u00e1s reciente y su contenido.\n    logger.info(f\"El archivo m\u00e1s reciente es: {latest_file}\")\n\n    # Carga el archivo m\u00e1s reciente en un DataFrame de pandas.\n    df = pd.read_excel(latest_file)\n\n    # Registra informaci\u00f3n sobre el contenido del archivo m\u00e1s reciente.\n    logger.info(f\"Contenido del archivo {latest_file}:\")\n    return df\n\n\n@log_step_decorator('procesar_cede_Docentes')\ndef procesar_cede_Docentes(df):\n    # Reemplaza valores en el DataFrame seg\u00fan sea necesario.\n    df = replace_values_df(df)\n\n    # Elimina espacios en blanco de los nombres y apellidos.\n    df['Primer nombre'] = df['Primer nombre'].str.strip()\n    df['Segundo nombre'] = df['Segundo nombre'].str.strip()\n    df['Primer apellido'] = df['Primer apellido'].str.strip()\n    df['Segundo apellido'] = df['Segundo apellido'].str.strip()\n\n    # Concatena los nombres y apellidos en una sola columna 'NOMBRE', omitiendo los vac\u00edos.\n    df['NOMBRE'] = df[['Primer nombre', 'Segundo nombre', 'Primer apellido', 'Segundo apellido']].apply(lambda x: ' '.join(x.dropna().astype(str)).upper(), axis=1)\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = []\n    renombres = {\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'E-mail':'CORREO',\n        'Direcci\u00f3n':'DIRECCION',\n        'C\u00e9dula':'CEDULA',\n        'Municipio direcci\u00f3n':'CIUDAD',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n': 'DOCUMENTO',\n        'Fecha de nacimiento':'FECHA_NACIMIENTO',\n        'Sexo':'GENERO'\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n\n    # Selecciona y reordena las columnas del DataFrame.\n    df = df[[\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'NOMBRE',\n        'PRIMER NOMBRE',\n        'SEGUNDO NOMBRE',\n        'PRIMER APELLIDO',\n        'SEGUNDO APELLIDO',\n        'TELEFONO',\n        'CELULAR',\n        'CORREO',\n        'DIRECCION',\n        'CIUDAD',\n        'FECHA_NACIMIENTO',\n        'MUNICIPIO EXPEDICI\u00d3N',\n        'FECHA DE EXPEDICI\u00d3N',\n        'GENERO',\n        'MUNICIPIO NACIMIENTO',\n        'TIPO DE SANGRE',\n        'ESCALAF\u00d3N',\n        'ESTADO CIVIL',\n        'CALIDAD DE DESEMPE\u00d1O',\n        'ESTADO',\n        'FECHA DE INGRESO',\n        'TIEMPO LABORAL',\n        'TIPO DE VINCULACI\u00d3N',\n        'ORIGEN VINCULACI\u00d3N',\n        'NIVEL ACAD\u00c9MICO',\n        'ESPECIALIDAD',\n        'FUENTE DE RECURSOS',\n        'SALARIO',\n        'USUARIO',\n        ]]\n\n    # Retorna el DataFrame procesado.\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():\n    # Obtener los datos de SharePoint para los docentes\n    df_cede_Docentes = obtener_sharepoint_docentes()\n    # Procesar los datos obtenidos de SharePoint\n    df_cede_Docentes = procesar_cede_Docentes(df_cede_Docentes)\n    # Mostrar las primeras filas del DataFrame procesado\n    df_cede_Docentes.head()\n    # Actualizar los datos procesados de vuelta en SharePoint\n\n    # Decorar la funci\u00f3n `actualizar_sharepoint_procesado` con `log_step_decorator` para registrar el paso\n    actualizar_sharepoint_func = log_step_decorator('actualizar_sharepoint_procesado')(actualizar_sharepoint_procesado)\n\n    # Llamar a la funci\u00f3n decorada para actualizar los datos procesados en SharePoint\n    actualizar_sharepoint_func(df_cede_Docentes, 'cede_Docentes')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/","title":"cede_02 procesar_Dise\u00f1o_Curricular","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport re\nimport pandas as pd\nimport openpyxl\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, extract_date, obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/#procesar_diseno_curricular","title":"procesar_diseno_curricular","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_02_procesar_Dise%C3%B1o_Curricular/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de dise\u00f1o curricular almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. </p> <p>La funci\u00f3n <code>procesar_diseno_curricular</code> abre un archivo de Excel, procesa cada hoja del libro, identifica las tablas de datos basadas en un encabezado espec\u00edfico, y extrae las filas relevantes. Los datos extra\u00eddos se almacenan en un <code>DataFrame</code> de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_dise\u00f1o_curricular</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica el archivo m\u00e1s reciente basado en la fecha en su nombre, y elimina los archivos m\u00e1s antiguos. Luego, carga el archivo m\u00e1s reciente y lo procesa utilizando la funci\u00f3n  <code>procesar_diseno_curricular</code>. Se asegura de que no haya valores nulos en la columna <code>Nombre Modulo</code> antes de filtrar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Adem\u00e1s, se realiza una comprobaci\u00f3n temporal de la subida de archivos a una carpeta espec\u00edfica en SharePoint.</p> <pre><code>@log_step_decorator('procesar_cede_Dise\u00f1o_Curricular')\ndef procesar_diseno_curricular(file_path):\n    # Abrir el archivo de Excel con openpyxl\n    wb = openpyxl.load_workbook(file_path, data_only=True)\n    all_data = []\n\n    for sheet_name in wb.sheetnames:\n        sheet = wb[sheet_name]\n        sheet_data = []\n        header_row = None\n        registro_num = 0  # Contador para el n\u00famero de registro\n\n        for row_idx, row in enumerate(sheet.iter_rows(values_only=True), start=1):  # row_idx comienza en 1\n            if row[0] == \"C\u00f3digo \":  # Identificar el inicio de la tabla\n                header_row = row\n                header_info = sheet.cell(row=row_idx - 3, column=1).value  # Fila [C\u00f3digo - 2]\n                registro_num = 0  # Reiniciar el n\u00famero de registro\n                continue\n\n            empty_row_count = 0  # Contador de filas vac\u00edas consecutivas\n\n            if header_row and row[0] is None:\n                empty_row_count += 1\n                if empty_row_count &gt;= 10:  # Si hay 10 filas vac\u00edas consecutivas, hacer break\n                    break\n                continue\n            else:\n                empty_row_count = 0  # Reiniciar el contador si se encuentra una fila no vac\u00eda\n\n            if row[0] == \"C\u00f3digo \":  # Identificar el inicio de una nueva tabla\n                header_row = row\n                header_info = sheet.cell(row=row_idx - 3, column=1).value  # Fila [C\u00f3digo - 2]\n                registro_num = 0  # Reiniciar el n\u00famero de registro\n                continue\n\n            if header_row:\n                # Incrementar el n\u00famero de registro\n                registro_num += 1\n                # Seleccionar solo las columnas relevantes\n                data_row = {\n                    \"Registro\": registro_num,  # Agregar n\u00famero de registro\n                    \"Programa (Pensum)\": header_info, \n                    \"C\u00f3digo\": row[0],\n                    \"Nombre Modulo\": row[1],\n                    \"Abreviaci\u00f3n\": row[5],\n                    \"Nivel\": row[7],\n                    \"Intensidad Horaria\": row[9],\n                    \"Intensidad Horaria Semanal\": row[10],\n                    \"No Cr\u00e9ditos\": row[12],\n                }\n                sheet_data.append(data_row)\n\n        # Combinar los datos de cada hoja\n        if sheet_data:\n            all_data.extend(sheet_data)\n\n    # Crear un DataFrame final con todos los datos procesados\n    df = pd.DataFrame(all_data)\n    return df\n\n@log_step_decorator('obtener_sharepoint_dise\u00f1o_curricular')\ndef obtener_sharepoint_dise\u00f1o_curricular():\n    folder_url = etl_to_folder_url.get('cede_Dise\u00f1o_Curricular', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Dise\u00f1o_Curricular_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Dise\u00f1o_Curricular_*.xlsx' en la carpeta.\")\n        return None\n\n    # Expresi\u00f3n regular para extraer la fecha del nombre del archivo\n    date_pattern = re.compile(r'Dise\u00f1o_Curricular_(\\d{2})_(\\d{2})_(\\d{4})\\.xlsx')\n\n    # Encontrar el archivo con la fecha m\u00e1s reciente\n    try:\n        latest_file = max(files, key=lambda f: extract_date(f,date_pattern))\n    except ValueError:\n        logger.error(\"No se pudo encontrar un archivo con fecha v\u00e1lida.\")\n        return None\n\n    # Eliminar todos los archivos excepto el m\u00e1s reciente\n    for file in files:\n        if file != latest_file:\n            os.remove(file)\n\n    logger.info(f\"El archivo m\u00e1s reciente es: {latest_file}\")\n    # Ruta del archivo m\u00e1s reciente descargado\n    df = procesar_diseno_curricular(latest_file)\n\n    # Asegurar que no hay valores nulos en \"Nombre Modulo\" antes de filtrar\n    if \"Nombre Modulo\" in df.columns:\n        df = df.dropna(subset=[\"Nombre Modulo\"])\n    else:\n        logger.warning(\"La columna 'Nombre Modulo' no existe en el DataFrame procesado.\")\n\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = []\n    renombres = {\n            'Programa (Pensum)':'PROGRAMA',\n            'C\u00f3digo':'COD_MODULO',\n            'Nombre Modulo':'MODULO',\n            'Nivel':'SEMESTRE',\n            'Intensidad Horaria':'INTENSIDAD_HORARIA',\n            'Intensidad Horaria Semanal':'INTENSIDAD_HORARIA_SEMANAL',\n            'No Cr\u00e9ditos':'NO_CREDITOS'\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():\n    df_cede_Dise\u00f1o_Curricular = obtener_sharepoint_dise\u00f1o_curricular()\n    actualizar_sharepoint_procesado(df_cede_Dise\u00f1o_Curricular, 'cede_Dise\u00f1o_Curricular')\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/","title":"cede_03 procesar_listado_matriculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\nimport openpyxl\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/#procesar_listado_matriculas","title":"procesar_listado_matriculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_03_procesar_listado_matriculas/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de matr\u00edculas almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>procesar_listado_matriculas</code> abre un archivo de Excel, procesa cada hoja del libro, identifica las tablas de datos basadas en un encabezado espec\u00edfico, y extrae las filas relevantes. Los datos extra\u00eddos se almacenan en un <code>DataFrame</code> de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_listado_matriculas</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica el archivo m\u00e1s reciente basado en la fecha en su nombre, y elimina los archivos m\u00e1s antiguos. Luego, carga el archivo m\u00e1s reciente y lo procesa utilizando la funci\u00f3n <code>procesar_listado_matriculas</code>. Se asegura de que no haya valores nulos en la columna <code>Estudiante</code> antes de filtrar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Adem\u00e1s, se realiza una comprobaci\u00f3n temporal de la subida de archivos a una carpeta espec\u00edfica en SharePoint.</p> <pre><code>@log_step_decorator('procesar_listado_matriculas')\ndef procesar_listado_matriculas(file_path):\n    wb = openpyxl.load_workbook(file_path, data_only=True)\n    all_data = []\n\n    # Iterar sobre las hojas del archivo con \u00edndice\n    for sheet_idx, sheet_name in enumerate(wb.sheetnames):\n        sheet = wb[sheet_name]\n        sheet_data = []\n        header_row = None\n        registro_num = 0  # Contador para el n\u00famero de registro\n        empty_row_count = 0  # Contador de filas vac\u00edas consecutivas\n\n        for row_idx, row in enumerate(sheet.iter_rows(values_only=True), start=1):\n            if row[0] and row[0].strip() == \"Estudiante\":  # Detectar encabezado\n                header_row = row\n                _info = sheet.cell(row=row_idx - 3, column=1).value\n                if _info:\n                    header_info = _info\n                    registro_num = 0\n\n                # Analizar header_row y obtener los nombres de las columnas\n                if header_row:\n                    col_indices = {\n                        col_name.replace(\"\\n\", \" \"): idx\n                        for idx, col_name in enumerate(header_row)\n                        if col_name and col_name.replace(\"\\n\", \" \") in [\n                            \"Estudiante\", \"Identificaci\u00f3n\", \"Fecha Matr\u00edcula\",\n                            \"Tel\u00e9fono\", \"Celular\", \"Correo\", \"Nivel\", \"Estado\"\n                        ]\n                    }\n                continue\n\n            if header_row:\n                registro_num += 1                \n                # Validar si la fila tiene suficientes columnas\n                if row[0] is None:\n                    empty_row_count += 1\n                    if empty_row_count &gt;= 5:  \n                        break\n                    continue\n                elif row[0] == 'www.q10.com':\n                    break\n                else:\n                    empty_row_count = 0  # Reiniciar contador si se encuentra una fila v\u00e1lida\n\n                # Procesar datos\n\n                # Dividir la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n                identificacion = row[col_indices.get(\"Identificaci\u00f3n\", 1)]\n                tipo, numero = (None, None)  # Valores predeterminados en caso de error\n                if identificacion and \" \" in identificacion:\n                    tipo, numero = identificacion.split(\" \", 1)\n\n                data_row = {\n                    \"Hoja\": sheet_name,\n                    \"Registro\": registro_num,\n                    \"Sede - jornada - Programa\": header_info,\n                    \"Estudiante\": row[col_indices.get(\"Estudiante\", 0)],\n                    \"Tipo Identificaci\u00f3n\": tipo,\n                    \"Identificaci\u00f3n\": numero,\n                    \"Fecha Matr\u00edcula\": row[col_indices.get(\"Fecha Matr\u00edcula\", 2)],\n                    \"Tel\u00e9fono\": row[col_indices.get(\"Tel\u00e9fono\", 3)],\n                    \"Celular\": row[col_indices.get(\"Celular\", 4)],\n                    \"Correo\": row[col_indices.get(\"Correo\", 5)],\n                    \"Nivel\": row[col_indices.get(\"Nivel\", 6)],\n                    \"Estado\": row[col_indices.get(\"Estado\", 7)],\n                }\n                sheet_data.append(data_row)\n\n        # Combinar los datos de cada hoja\n        if sheet_data:\n            all_data.extend(sheet_data)\n\n    # Crear un DataFrame final con todos los datos procesados\n    df = pd.DataFrame(all_data)\n    df = df.dropna(subset=[\"Identificaci\u00f3n\"])  # Eliminar filas con identificaci\u00f3n nula\n    return df\n\n@log_step_decorator('obtener_sharepoint_listado_matriculas')\ndef obtener_sharepoint_listado_matriculas():\n    folder_url = etl_to_folder_url.get('cede_Listado_Matriculas', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Listado_Matriculas_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Listado_Matriculas_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        df_temp = procesar_listado_matriculas(file)\n        all_dfs.append(df_temp)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = ['Hoja','Registro']\n    #    'Sede - jornada - Programa',\n    renombres = {\n        'Estudiante': 'NOMBRE_ESTUDIANTE',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO',\n        'Identificaci\u00f3n':'DOCUMENTO_ESTUDIANTE',\n        'Fecha Matr\u00edcula':'FECHA_MATRICULA',\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'Correo':'CORREO',\n        'Nivel':'SEMESTRE',\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    # Remove dots from TIPO_DOCUMENTO\n    df['TIPO_DOCUMENTO'] = df['TIPO_DOCUMENTO'].str.replace('.', '', regex=False)\n\n    # Split column into SEDE, JORNADA, and PROGRAMA\n    df[['SEDE', 'JORNADA', 'PROGRAMA']] = df['SEDE - JORNADA - PROGRAMA'].str.extract(r'(\\w+ \\w+) (\\w+) - (.+)')\n\n    # Eliminar columna: 'SEDE - JORNADA - PROGRAMA'\n    df = df.drop(columns=['SEDE - JORNADA - PROGRAMA'])\n\n    #elimina de df los duplicados por las columnas 'Fecha Matr\u00edcula' y 'Identificaci\u00f3n'\n    df = df.drop_duplicates(subset=['FECHA_MATRICULA', 'DOCUMENTO_ESTUDIANTE'])\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Listado_Matriculas = obtener_sharepoint_listado_matriculas()\n    actualizar_sharepoint_procesado(df_cede_Listado_Matriculas, 'cede_Listado_Matriculas')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/","title":"cede_04 procesar_Ingresos","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado,get_data_range\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/#procesar_cede_ingresos","title":"procesar_cede_Ingresos","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_04_procesar_cede_Ingresos/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de ingresos almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>procesar_cede_Ingresos</code>abre un archivo de Excel, procesa los datos eliminando filas y columnas innecesarias, y transforma los datos en un formato adecuado para su an\u00e1lisis. Los datos procesados se almacenan en un DataFrame de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_cede_Ingresos</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Ingresos_*.xlsx', y procesa cada archivo utilizando la funci\u00f3n <code>procesar_cede_Ingresos</code>. Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan y renombran columnas espec\u00edficas para limpiar y estandarizar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Este proceso asegura que los datos de ingresos est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>@log_step_decorator('procesar_cede_Ingresos')\ndef procesar_cede_Ingresos(file_path):\n\n    # Obtener rango de datos\n    try:\n        data = get_data_range(file_path, 0)\n    except Exception as e:\n        print(f\"Error: {e}\")\n\n    df_range = pd.DataFrame(data)\n    # Variable cargada \"df_range\" del estado del Kernel\n\n    # Remove rows from 0 to 8\n    df_range = df_range.drop(index=range(0, 9))\n\n    # Drop columns with all missing values\n    df_range = df_range.dropna(axis=1, how='all')\n    # Mostrar las primeras filas del DataFrame para verificar el contenido\n\n\n    df_range.reset_index(drop=True, inplace=True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    # Fill NaN in row 0 with values from row 2\n    df_range.iloc[0] = df_range.iloc[0].fillna(df_range.iloc[2])\n\n    #elimina las columnas 17,22,23\n    df_range = df_range.drop(columns=[17, 22, 23])\n\n\n    # Set first row as column names, enumerate duplicates\n    df_range.columns = df_range.iloc[0]\n    df_range = df_range[1:]\n\n    # Rename the second 'Valor' column to 'Valor_1'\n    df_range.columns = ['Valor_1' if (col == 'Valor' and idx == 1) else col for idx, col in enumerate(df_range.columns)]\n\n    # Filter column 'N\u00b0 Recibo' to keep non-null values\n    df_range = df_range[df_range['N\u00b0 Recibo'].notna()]\n\n    # Crear un diccionario para rastrear las columnas duplicadas y renombrarlas\n    columns = pd.Series(df_range.columns)\n    duplicates = columns[columns.duplicated()].unique()\n\n    # Crea un diccionario para rastrear las columnas duplicadas y renombrarlas adecuadamente\n    for dup in duplicates:\n        dup_indices = columns[columns == dup].index\n        for i, idx in enumerate(dup_indices):\n            if i != 0:\n                columns[idx] = f\"{dup}_{i}\"\n\n    # Asignar las nuevas columnas al DataFrame\n    df_range.columns = columns\n\n    # Reinicia el \u00edndice nuevamente\n    df_range.reset_index(drop=True, inplace=True)        \n\n    # Separar la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n    df_range[['Tipo Identificaci\u00f3n', 'Identificaci\u00f3n']] = df_range['Identificaci\u00f3n'].str.split(' ', expand=True)\n\n    # Separar la columna \"Concepto\" por \" - \"\n    df_range[['C\u00f3digo Concepto', 'Concepto']] = df_range['Concepto'].str.split(' - ', n=1, expand=True)    \n\n    df_range = df_range[['N\u00b0 Recibo', 'Fecha', 'Pagado por', 'Tipo Identificaci\u00f3n', 'Identificaci\u00f3n', 'Cajero', 'C\u00f3digo Concepto', 'Concepto', 'Valor', 'Nombre', 'Valor_1', 'Total Pagado']]\n\n    # Remove rows with None in 'Fecha' column\n    df_range = df_range[df_range['Fecha'].notna()]\n\n    return df_range\n\n\n@log_step_decorator('obtener_sharepoint_cede_Ingresos')\ndef obtener_sharepoint_cede_Ingresos():\n    folder_url = etl_to_folder_url.get('cede_Ingresos', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Ingresos_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Ingresos_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        df_temp = procesar_cede_Ingresos(file)\n        all_dfs.append(df_temp)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n\n    columnas_a_eliminar = ['Hoja','Registro']\n\n    renombres = {\n        'N\u00b0 Recibo':'NO_RECIBO',\n        'Fecha':'FECHA_CONTABLE',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO_PAGO',\n        'Identificaci\u00f3n':'DOCUMENTO_PAGO',\n        'C\u00f3digo Concepto':'ID_CONCEPTO',\n        'Valor':'VALOR_FACTURADO',\n        'Pagado por':'PAGADO_POR',\n        'Total Pagado':'VALOR_PAGADO'}\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n    # Variable cargada \"df\" del estado del Kernel\n    df['TIPO_DOCUMENTO_PAGO'] = df['TIPO_DOCUMENTO_PAGO'].str.replace('.', '', regex=False)\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_cede_Ingresos = obtener_sharepoint_cede_Ingresos()\n    actualizar_sharepoint_procesado(df_cede_cede_Ingresos, 'cede_Ingresos')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/","title":"cede_05 cede_Historico_Notas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado,procesar_excel_con_hojas\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/#cede_historico_notas","title":"cede_Historico_Notas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_05_cede_Historico_Notas/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de notas hist\u00f3ricas almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>procesar_periodos</code> abre un archivo de Excel, procesa los datos eliminando filas y columnas innecesarias, y transforma los datos en un formato adecuado para su an\u00e1lisis. Los datos procesados se almacenan en un DataFrame de pandas.</p> <p>La funci\u00f3n <code>obtener_sharepoint_cede_Historico_Notas</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Historico_Notas_*.xlsx', y procesa cada archivo utilizando la funci\u00f3n <code>procesar_periodos</code>. Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan y renombran columnas espec\u00edficas para limpiar y estandarizar los datos.</p> <p>El bloque de c\u00f3digo principal controla la ejecuci\u00f3n del proceso de ETL mediante una variable booleana <code>ejecutar</code>. Si esta variable est\u00e1 activada, se obtienen y procesan los datos de SharePoint, y se actualizan los datos procesados de vuelta en SharePoint. Este proceso asegura que los datos de notas hist\u00f3ricas est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>@log_step_decorator('procesar_cede_Historico_Notas')\ndef procesar_corte(df, corte_nombre, columnas_a_eliminar, renombres):\n    df_corte = df[df['corte'] == corte_nombre].copy()\n    df_corte.reset_index(drop=True, inplace=True)\n    if not df_corte.empty:\n        df_corte = df_corte.drop(0).reset_index(drop=True)\n        df_corte.columns = [value if str(value).startswith('C') else col for col, value in zip(df_corte.columns, df_corte.iloc[0])]\n        df_corte = df_corte.drop(0).reset_index(drop=True)\n    df_corte = limpiar_columnas(df_corte, columnas_a_eliminar, renombres)\n    return df_corte\n\n@log_step_decorator('procesar_periodos')\ndef procesar_periodos(file_path):\n    resultado_df = procesar_excel_con_hojas(file_path)\n    df = resultado_df.copy()\n\n    # Crear diccionarios desde filas espec\u00edficas\n    _encabezados = resultado_df.iloc[3:7, [0, 2]].set_index(resultado_df.columns[0]).to_dict()[resultado_df.columns[2]]\n    dic_tempB = resultado_df.iloc[3:7, [7, 9]].set_index(resultado_df.columns[7]).to_dict()[resultado_df.columns[9]]\n    _encabezados.update(dic_tempB)\n\n    # Limpieza inicial del DataFrame\n    columnas_a_eliminar = ['Unnamed: 0', 'Cedesarrollo - Comfenalco']\n    renombres_iniciales = {'Unnamed: 1': 'Estudiante', 'Unnamed: 3': 'referencia'}\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres_iniciales)\n\n    # Crear columna 'corte' con valores que contienen 'Corte'\n    df['corte'] = df['referencia'].apply(lambda x: x if 'Corte' in str(x) else None).ffill()\n\n    # Procesar Primer y Tercer Corte\n    columnas_a_eliminar_corte = ['Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12']\n    df_tercer_corte = procesar_corte(df, 'Tercer Corte', columnas_a_eliminar_corte, {'Unnamed: 7': 'Nota Acum.', 'Unnamed: 8': 'Inasis Acum.'})\n    df_primer_corte = procesar_corte(df, 'Primer Corte', columnas_a_eliminar_corte, {})\n\n    # Unir Primer y Tercer Corte por 'Estudiante'\n    df_merged = pd.merge(df_primer_corte, df_tercer_corte, on='Estudiante', how='inner')\n\n    # Agregar columnas con el diccionario _encabezados\n    for key, value in _encabezados.items():\n        df_merged[key] = value\n\n    return df_merged\n\n\n@log_step_decorator('obtener_sharepoint_cede_Historico_Notas')\ndef obtener_sharepoint_cede_Historico_Notas():\n    folder_url = etl_to_folder_url.get('cede_Historico_Notas', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Historico_Notas_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Historico_Notas_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [procesar_periodos(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # Variable cargada \"df_cede_Historico_Notas\" del estado del Kernel\n\n    # Filtrar filas seg\u00fan la columna: 'Estudiante'\n    df = df[df['Estudiante'].notna()]\n\n    # Reset index of DataFrame\n    df = df.reset_index(drop=True)\n\n    # Eliminate columns with all NaN values\n    df = df.dropna(axis=1, how='all')\n\n    # Split \"Sede - jornada:\" into \"SEDE\" and \"JORNADA\"\n    df[['SEDE', 'JORNADA']] = df['Sede - jornada: '].str.split(' - ', expand=True)\n    campos = df.columns.tolist()\n    # guardar_diccionario(campos,'campos')\n    renombrar = {\n        'Estudiante':'NOMBRE_ESTUDIANTE',\n        'referencia':'PRIMER_CORTE',\n        'CP C1-E1':'PRIMER_CORTE_CP1',\n        'CP C1-E2':'PRIMER_CORTE_CP2',\n        'CT C1-E1':'PRIMER_CORTE_CT1',\n        'CT C1-E2':'PRIMER_CORTE_CT2',\n        'Unnamed: 8':'SEGUNDO_CORTE',\n        'CP C2-E1':'SEGUNDO_CORTE_CP1',\n        'CP C2-E2':'SEGUNDO_CORTE_CP2',\n        'CT C2-E1':'SEGUNDO_CORTE_CT1',\n        'CT C2-E2':'SEGUNDO_CORTE_CT2',\n        'Unnamed: 13_x':'TERCER_CORTE',\n        'CP C3-E1':'TERCER_CORTE_CP1',\n        'CP C3-E2':'TERCER_CORTE_CP2',\n        'CT C3-E1':'TERCER_CORTE_CT1',\n        'CT C3-E2':'TERCER_CORTE_CT2',\n        'Nota Acum.':'NOTA_FINAL',\n        'M\u00f3dulo: ':'MODULO',\n        'Curso: ':'CURSO',\n        'Fecha inicio: ':'FECHA_INICIO',\n        'Per\u00edodo: ':'PERIODO_ACADEMICO',\n        'Programa: ':'PROGRAMA_ACADEMICO',\n        'Docente: ':'NOMBRE_DOCENTE',\n        'Inasis Acum.':'INASISTENCIAS_ACUMULADAS',\n        'Fecha fin: ':'FECHA_FIN',\n    }\n    eliminar = ['Sede - jornada: ','corte_x','corte_y']\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Historico_Notas = obtener_sharepoint_cede_Historico_Notas()\n    actualizar_sharepoint_procesado(df_cede_Historico_Notas, 'cede_Historico_Notas')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/","title":"cede_06 cede_Egresados_Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,replace_values_df,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/#cede_egresados_graduados","title":"cede_Egresados_Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_06_cede_Egresados_Graduados/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de egresados y graduados almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n </p> <p>obtener_sharepoint_cede_Egresados_Graduados</p> <p>descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Graduados_*.xlsx', y procesa cada archivo utilizando pandas para leer los datos.</p> <p>Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan columnas espec\u00edficas y se reemplazan valores en el DataFrame. Finalmente, se renombran las columnas para limpiar y estandarizar los datos.</p> <p>Este proceso asegura que los datos de egresados y graduados est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_cede_Egresados_Graduados():\n    folder_url = etl_to_folder_url.get('cede_Egresados_Graduados', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Graduados_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Graduados_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # Eliminar columna: 'Grupo'\n    df = df.drop(columns=['Grupo'])\n    df = replace_values_df(df)\n    renombrar = {\n        'C\u00f3digo de matr\u00edcula':'ID_MATRICULA',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n':'DOCUMENTO',\n        'Grupo Sisben':'GRUPO',\n        'Nivel de formaci\u00f3n':'NIVEL_FORMACION',\n        'Ocupaci\u00f3n':'OCUPACION',\n        'Sede':'SEDE',\n        'Jornada':'JORNADA',\n        'Programa':'PROGRAMA',\n        'Per\u00edodo':'PERIODO_ACADEMICO',\n        'Nivel':'SEMESTRE',\n        'Fecha graduado':'FECHA_GRADUADO',\n        'Acta graduado':'ACTA_GRADUADO',\n        'Folio graduado':'FOLIO_GRADUADO',\n        'Diploma graduado':'DIPLOMA_GRADUADO'    \n    }\n    eliminar = []\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    df = df[['ID_MATRICULA',\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'GRUPO',\n        'NIVEL_FORMACION',\n        'OCUPACION',\n        'SEDE',\n        'JORNADA',\n        'PROGRAMA',\n        'PERIODO_ACADEMICO',\n        'SEMESTRE',\n        'FECHA_GRADUADO',\n        'ACTA_GRADUADO',\n        'FOLIO_GRADUADO',\n        'DIPLOMA_GRADUADO',\n        'ZONA',\n        '\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N']]\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Egresados_Graduados = log_step_decorator(\"Obtener y procesar Egresados Graduados\")(obtener_sharepoint_cede_Egresados_Graduados)()    \n    actualizar_sharepoint_procesado(df_cede_Egresados_Graduados, 'cede_Egresados_Graduados')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/","title":"cede_07 Cancelados Desertores","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code>, <code>procesar_excel_con_hojas</code>, <code>limpiar_columnas</code>, <code>get_data_range</code>, <code>extract_date</code>, <code>obtener_sharepoint</code>, <code>download_all_files_from_sharepoint</code>, <code>limpiar_carpeta</code>, <code>replace_values_df</code>, <code>upload_file_to_sharepoint</code> y <code>actualizar_sharepoint_procesado</code>.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator, limpiar_columnas, obtener_sharepoint,actualizar_sharepoint_procesado,procesar_excel_con_hojas,actualizar_columna_programa\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/#obtener_sharepoint_cede_cancelados_desertores","title":"obtener_sharepoint_cede_Cancelados_Desertores","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/cede_07_Cancelados_Desertores/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de cancelados y desertores almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_cede_Cancelados_Desertores</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Cancelados_*.xlsx', y procesa cada archivo utilizando pandas para leer los datos.</p> <p>Los datos de todos los archivos se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan columnas espec\u00edficas y se reemplazan valores en el DataFrame. Finalmente, se renombran las columnas para limpiar y estandarizar los datos.</p> <p>Este proceso asegura que los datos de cancelados y desertores est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_cede_Cancelados_Desertores():\n    folder_url = etl_to_folder_url.get('cede_Cancelados_Desertores', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Cancelados_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Cancelados_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        _df = procesar_excel_con_hojas(file)\n        all_dfs.append(_df)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n    return df\n\n@log_step_decorator(\"Procesar Cancelados Desertores\")\ndef procesar_Cancelados_Desertores(df_cede_Cancelados_Desertores):\n    # Variable cargada \"df_cede_Cancelados_Desertores\" del estado del Kernel\n\n    df_cede_Cancelados_Desertores.columns = [f'Columna_{i}' for i in range(len(df_cede_Cancelados_Desertores.columns))]\n\n\n    # Iterate over Columna_11 from row 8\n    for index, row in df_cede_Cancelados_Desertores.iloc[8:].iterrows():\n        if pd.isna(row['Columna_11']):\n            if not pd.isna(row['Columna_12']):\n                df_cede_Cancelados_Desertores.at[index, 'Columna_11'] = row['Columna_12']\n                df_cede_Cancelados_Desertores.at[index, 'Columna_12'] = row['Columna_14']\n\n    df_cede_Cancelados_Desertores['Columna_5'] = df_cede_Cancelados_Desertores['Columna_5'].combine_first(df_cede_Cancelados_Desertores['Columna_6'])\n    df_cede_Cancelados_Desertores['Columna_7'] = df_cede_Cancelados_Desertores['Columna_7'].combine_first(df_cede_Cancelados_Desertores['Columna_8'])\n    df_cede_Cancelados_Desertores['Columna_9'] = df_cede_Cancelados_Desertores['Columna_9'].combine_first(df_cede_Cancelados_Desertores['Columna_10'])\n\n\n    df_cede_Cancelados_Desertores = actualizar_columna_programa(\n        df_cede_Cancelados_Desertores, \n        columna_condicional='Columna_0', \n        columna_origen='Columna_0', \n        columna_destino='Sede',\n        texto_filtro='Sede'\n    )\n\n    # Variable cargada \"df_cede_Cancelados_Desertores\" del estado del Kernel\n\n    # Filtrar filas seg\u00fan la columna: 'Columna_0'\n    df_cede_Cancelados_Desertores = df_cede_Cancelados_Desertores[df_cede_Cancelados_Desertores['Columna_0'].notna()]\n\n    # Filtrar filas seg\u00fan la columna: 'Columna_3'\n    df_cede_Cancelados_Desertores = df_cede_Cancelados_Desertores[df_cede_Cancelados_Desertores['Columna_3'].notna()]\n\n    # Fill empty Columna_12 with Columna_13 values\n    df_cede_Cancelados_Desertores['Columna_12'] = df_cede_Cancelados_Desertores['Columna_12'].fillna(df_cede_Cancelados_Desertores['Columna_13'])\n\n    # Separar la columna \"Sede\" en SEDE y JORNADA\n    df_cede_Cancelados_Desertores[['SEDE', 'JORNADA']] = df_cede_Cancelados_Desertores['Sede'].str.split(' - ', expand=True)\n\n    # Filtrar filas seg\u00fan la columna: 'PROGRAMA'\n    df_cede_Cancelados_Desertores = df_cede_Cancelados_Desertores[df_cede_Cancelados_Desertores['Columna_0'] != \"Programa\"]\n\n\n    eliminar = [\n        'Columna_2',\n        'Columna_4',\n        'Columna_6',\n        'Columna_8',\n        'Columna_10',\n        'Columna_13',\n        'Columna_14',\n        'Columna_15',\n        'Sede',\n        'Columna_1',\n        'Columna_5'\n    ]\n    renombrar = {\n        'Columna_0':'PROGRAMA',\n        'Columna_3':'NOMBRE_ESTUDIANTE',\n        'Columna_7':'FECHA',\n        'Columna_9':'TIPO',\n        'Columna_11':'CAUSA',\n        'Columna_12':'OBSERVACIONES',\n        'Columna_5':'SEDE',\n    }\n    df_cede_Cancelados_Desertores = limpiar_columnas(df_cede_Cancelados_Desertores, eliminar, renombrar,True)\n\n\n    return df_cede_Cancelados_Desertores\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_cede_Cancelados_Desertores = log_step_decorator(\"Obtener Cancelados Desertores\")(obtener_sharepoint_cede_Cancelados_Desertores)()    \n    df_cede_Cancelados_Desertores = procesar_Cancelados_Desertores(df_cede_Cancelados_Desertores)    \n    actualizar_sharepoint_procesado(df_cede_Cancelados_Desertores, 'cede_Cancelados_Desertores')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/","title":"emp_01 Docentes Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\n\nimport logging\nimport os\nimport sys\nimport glob\nimport re\nimport datetime\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,replace_values_df,limpiar_carpeta, obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/#obtener_sharepoint_docentes","title":"obtener_sharepoint_docentes","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_01_Docentes/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de docentes almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_docentes</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Docentes_*.xlsx', y selecciona el archivo m\u00e1s reciente basado en la fecha incluida en el nombre del archivo.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia. Luego, descarga los archivos desde SharePoint y filtra el archivo m\u00e1s reciente utilizando una expresi\u00f3n regular para extraer la fecha del nombre del archivo. Los archivos m\u00e1s antiguos se eliminan para mantener la carpeta organizada.</p> <p>El archivo m\u00e1s reciente se lee en un <code>DataFrame</code> de pandas, y se registra el contenido del archivo para su seguimiento. La funci\u00f3n <code>procesar_cede_Docentes</code> se encarga de reemplazar valores en el DataFrame y eliminar espacios en blanco de los nombres y apellidos, asegurando que los datos est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_docentes():\n    folder_url = etl_to_folder_url.get('emp_Docentes', \"URL por defecto si no se encuentra el valor de etl\")\n    if not os.path.exists(_folder):\n        os.makedirs(_folder)\n    else:\n        limpiar_carpeta(_folder)\n\n    obtener_sharepoint(folder_url,_folder)\n    files = glob.glob(os.path.join(_folder, \"Docentes_*.xlsx\"))\n\n    date_pattern = re.compile(r'Docentes_(\\d{2})_(\\d{2})_(\\d{4})\\.xlsx')\n\n    def extract_date(file_name):\n        match = date_pattern.search(file_name)\n        if match:\n            day, month, year = map(int, match.groups())\n            return datetime.date(year, month, day)\n        return None\n    latest_file = max(files, key=lambda f: extract_date(f))\n\n    for file in files:\n        if file != latest_file:\n            os.remove(file)\n\n    logger.info(f\"El archivo m\u00e1s reciente es: {latest_file}\")\n\n\n    df = pd.read_excel(latest_file)\n\n    logger.info(f\"Contenido del archivo {latest_file}:\")\n    return df\n\n\n@log_step_decorator('procesar_cede_Docentes')\ndef procesar_cede_Docentes(df):\n    # Reemplaza valores en el DataFrame seg\u00fan sea necesario.\n    df = replace_values_df(df)\n\n    # Elimina espacios en blanco de los nombres y apellidos.\n    df['Primer nombre'] = df['Primer nombre'].str.strip()\n    df['Segundo nombre'] = df['Segundo nombre'].str.strip()\n    df['Primer apellido'] = df['Primer apellido'].str.strip()\n    df['Segundo apellido'] = df['Segundo apellido'].str.strip()\n\n    # Concatena los nombres y apellidos en una sola columna 'NOMBRE', omitiendo los vac\u00edos.\n    df['NOMBRE'] = df[['Primer nombre', 'Segundo nombre', 'Primer apellido', 'Segundo apellido']].apply(lambda x: ' '.join(x.dropna().astype(str)).upper(), axis=1)\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = []\n    renombres = {\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'E-mail':'CORREO',\n        'Direcci\u00f3n':'DIRECCION',\n        'C\u00e9dula':'CEDULA',\n        'Municipio direcci\u00f3n':'CIUDAD',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n': 'DOCUMENTO',\n        'Fecha de nacimiento':'FECHA_NACIMIENTO',\n        'Sexo':'GENERO'\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)\n\n    # Selecciona y reordena las columnas del DataFrame.\n    df = df[[\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'NOMBRE',\n        'PRIMER NOMBRE',\n        'SEGUNDO NOMBRE',\n        'PRIMER APELLIDO',\n        'SEGUNDO APELLIDO',\n        'TELEFONO',\n        'CELULAR',\n        'CORREO',\n        'DIRECCION',\n        'CIUDAD',\n        'FECHA_NACIMIENTO',\n        'MUNICIPIO EXPEDICI\u00d3N',\n        'FECHA DE EXPEDICI\u00d3N',\n        'GENERO',\n        'MUNICIPIO NACIMIENTO',\n        'TIPO DE SANGRE',\n        'ESCALAF\u00d3N',\n        'ESTADO CIVIL',\n        'CALIDAD DE DESEMPE\u00d1O',\n        'ESTADO',\n        'FECHA DE INGRESO',\n        'TIEMPO LABORAL',\n        'TIPO DE VINCULACI\u00d3N',\n        'ORIGEN VINCULACI\u00d3N',\n        'NIVEL ACAD\u00c9MICO',\n        'ESPECIALIDAD',\n        'FUENTE DE RECURSOS',\n        'SALARIO',\n        'USUARIO',\n        ]]\n\n    # Retorna el DataFrame procesado.\n    # Remove empty columns\n    df = df.dropna(axis=1, how='all')\n    return df\n\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Docentes = obtener_sharepoint_docentes()\n    df_emp_Docentes = procesar_cede_Docentes(df_emp_Docentes)\n    actualizar_sharepoint_procesado(df_emp_Docentes, 'emp_Docentes')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/","title":"emp_02 Listado Matr\u00edculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\nimport openpyxl\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/#obtener_sharepoint_listado_matriculas","title":"obtener_sharepoint_listado_matriculas","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_02_listado_matriculas/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de matr\u00edculas almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_listado_matriculas</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Listado_Matriculas_*.xlsx', y selecciona el archivo m\u00e1s reciente basado en la fecha incluida en el nombre del archivo.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia. Luego, descarga los archivos desde SharePoint y filtra el archivo m\u00e1s reciente utilizando una expresi\u00f3n regular para extraer la fecha del nombre del archivo. Los archivos m\u00e1s antiguos se eliminan para mantener la carpeta organizada.</p> <p>El archivo m\u00e1s reciente se lee en un <code>DataFrame</code> de pandas, y se registran las columnas del archivo para su seguimiento. La funci\u00f3n <code>limpiar_columnas</code> se encarga de eliminar y renombrar columnas espec\u00edficas para limpiar y estandarizar los datos. Adem\u00e1s, se eliminan los puntos de la columna <code>TIPO_DOCUMENTO</code>, se dividen los valores de la columna <code>SEDE - JORNADA - PROGRAMA</code> en tres columnas separadas (<code>SEDE</code>, <code>JORNADA</code> y <code>PROGRAMA</code>), y se eliminan duplicados basados en las columnas <code>FECHA_MATRICULA</code> y <code>DOCUMENTO_ESTUDIANTE</code>.</p> <p>Finalmente, si la variable de control <code>ejecutar</code> est\u00e1 activada, se llama a la funci\u00f3n <code>actualizar_sharepoint_procesado</code> para actualizar los datos procesados de vuelta en SharePoint, asegurando que los datos de matr\u00edculas est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def procesar_listado_matriculas(file_path):\n    wb = openpyxl.load_workbook(file_path, data_only=True)\n    all_data = []\n\n    # Iterar sobre las hojas del archivo con \u00edndice\n    for sheet_idx, sheet_name in enumerate(wb.sheetnames):\n        sheet = wb[sheet_name]\n        sheet_data = []\n        header_row = None\n        registro_num = 0  # Contador para el n\u00famero de registro\n        empty_row_count = 0  # Contador de filas vac\u00edas consecutivas\n\n        for row_idx, row in enumerate(sheet.iter_rows(values_only=True), start=1):\n            if row[0] and row[0].strip() == \"Estudiante\":  # Detectar encabezado\n                header_row = row\n                _info = sheet.cell(row=row_idx - 3, column=1).value\n                if _info:\n                    header_info = _info\n                    registro_num = 0\n\n                # Analizar header_row y obtener los nombres de las columnas\n                if header_row:\n                    col_indices = {\n                        col_name.replace(\"\\n\", \" \"): idx\n                        for idx, col_name in enumerate(header_row)\n                        if col_name and col_name.replace(\"\\n\", \" \") in [\n                            \"Estudiante\", \"Identificaci\u00f3n\", \"Fecha Matr\u00edcula\",\n                            \"Tel\u00e9fono\", \"Celular\", \"Correo\", \"Nivel\", \"Estado\"\n                        ]\n                    }\n                continue\n\n            if header_row:\n                registro_num += 1                \n                # Validar si la fila tiene suficientes columnas\n                if row[0] is None:\n                    empty_row_count += 1\n                    if empty_row_count &gt;= 5:  \n                        break\n                    continue\n                elif row[0] == 'www.q10.com':\n                    break\n                else:\n                    empty_row_count = 0  # Reiniciar contador si se encuentra una fila v\u00e1lida\n\n                # Procesar datos\n\n                # Dividir la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n                identificacion = row[col_indices.get(\"Identificaci\u00f3n\", 1)]\n                tipo, numero = (None, None)  # Valores predeterminados en caso de error\n                if identificacion and \" \" in identificacion:\n                    tipo, numero = identificacion.split(\" \", 1)\n\n                data_row = {\n                    \"Hoja\": sheet_name,\n                    \"Registro\": registro_num,\n                    \"Sede - jornada - Programa\": header_info,\n                    \"Estudiante\": row[col_indices.get(\"Estudiante\", 0)],\n                    \"Tipo Identificaci\u00f3n\": tipo,\n                    \"Identificaci\u00f3n\": numero,\n                    \"Fecha Matr\u00edcula\": row[col_indices.get(\"Fecha Matr\u00edcula\", 2)],\n                    \"Tel\u00e9fono\": row[col_indices.get(\"Tel\u00e9fono\", 3)],\n                    \"Celular\": row[col_indices.get(\"Celular\", 4)],\n                    \"Correo\": row[col_indices.get(\"Correo\", 5)],\n                    \"Nivel\": row[col_indices.get(\"Nivel\", 6)],\n                    \"Estado\": row[col_indices.get(\"Estado\", 7)],\n                }\n                sheet_data.append(data_row)\n\n        # Combinar los datos de cada hoja\n        if sheet_data:\n            all_data.extend(sheet_data)\n\n    # Crear un DataFrame final con todos los datos procesados\n    df = pd.DataFrame(all_data)\n    df = df.dropna(subset=[\"Identificaci\u00f3n\"])  # Eliminar filas con identificaci\u00f3n nula\n    return df\n\n@log_step_decorator(\"obtener_sharepoint_listado_matriculas\")\ndef obtener_sharepoint_listado_matriculas():\n    folder_url = etl_to_folder_url.get('emp_Listado_Matriculas', \"URL por defecto si no se encuentra el valor de etl\")\n    # obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Listado_Matriculas_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Listado_Matriculas_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = []\n    for file in files:\n        df_temp = log_step_decorator(f\"Procesando {file}\")(procesar_listado_matriculas)(file)\n        all_dfs.append(df_temp)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = ['Hoja','Registro']\n    #    'Sede - jornada - Programa',\n    renombres = {\n        'Estudiante': 'NOMBRE_ESTUDIANTE',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO',\n        'Identificaci\u00f3n':'DOCUMENTO_ESTUDIANTE',\n        'Fecha Matr\u00edcula':'FECHA_MATRICULA',\n        'Tel\u00e9fono':'TELEFONO',\n        'Celular':'CELULAR',\n        'Correo':'CORREO',\n        'Nivel':'SEMESTRE',\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres, True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    # Remove dots from TIPO_DOCUMENTO\n    df['TIPO_DOCUMENTO'] = df['TIPO_DOCUMENTO'].str.replace('.', '', regex=False)\n\n    # Split column into SEDE, JORNADA, and PROGRAMA\n    df[['SEDE', 'JORNADA', 'PROGRAMA']] = df['SEDE - JORNADA - PROGRAMA'].str.extract(r'(\\w+ \\w+) (\\w+) - (.+)')\n\n    # Eliminar columna: 'SEDE - JORNADA - PROGRAMA'\n    df = df.drop(columns=['SEDE - JORNADA - PROGRAMA'])\n\n    #elimina de df los duplicados por las columnas 'Fecha Matr\u00edcula' y 'Identificaci\u00f3n'\n    df = df.drop_duplicates(subset=['FECHA_MATRICULA', 'DOCUMENTO_ESTUDIANTE'])\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_listado_matriculas = obtener_sharepoint_listado_matriculas()\n    if df_listado_matriculas is not None:\n        # elimina de df los duplicados por las columnas 'Fecha Matr\u00edcula' y 'Identificaci\u00f3n'\n        actualizar_sharepoint_procesado(df_listado_matriculas, 'emp_Listado_Matriculas')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/","title":"emp_03 Preinscritos Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\n\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/#procesar_preinscritos","title":"procesar_preinscritos","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_03_preinscritos/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de preinscritos almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Preinscritos</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Preinscritos_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan las filas duplicadas basadas en las columnas <code>N\u00famero de identificaci\u00f3n</code> y <code>Fecha</code>, asegurando que los datos est\u00e9n limpios y estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <p>La funci\u00f3n <code>procesar_preinscritos</code> se encarga de limpiar y transformar los datos. Primero, elimina los espacios en blanco de los nombres y apellidos. Luego, concatena los nombres y apellidos en una sola columna <code>NOMBRE</code>, omitiendo los valores vac\u00edos y convirtiendo todo a may\u00fasculas. Adem\u00e1s, divide la columna <code>Sede - jornada</code> en dos columnas separadas (<code>SEDE</code> y <code>JORNADA</code>). Finalmente, define las columnas a eliminar para limpiar y estandarizar los datos.</p> <pre><code>def obtener_sharepoint_emp_Preinscritos():\n    folder_url = etl_to_folder_url.get('emp_Preinscritos', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Preinscritos_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Preinscritos_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # elimina las filas duplicadas por 'N\u00famero de identificaci\u00f3n' y Fecha\n    df = df.drop_duplicates(subset=['N\u00famero de identificaci\u00f3n', 'Fecha'])\n    return df\n\ndef procesar_preinscritos(df):\n    # Elimina espacios en blanco de los nombres y apellidos.\n    df['Primer nombre'] = df['Primer nombre'].str.strip()\n    df['Segundo nombre'] = df['Segundo nombre'].str.strip()\n    df['Primer apellido'] = df['Primer apellido'].str.strip()\n    df['Segundo apellido'] = df['Segundo apellido'].str.strip()\n\n    # Concatena los nombres y apellidos en una sola columna 'NOMBRE', omitiendo los vac\u00edos.\n    df['NOMBRE'] = df[['Primer nombre', 'Segundo nombre', 'Primer apellido', 'Segundo apellido']].apply(lambda x: ' '.join(x.dropna().astype(str)).upper(), axis=1)\n    # Split column into SEDE and JORNADA\n    df[['SEDE', 'JORNADA']] = df['Sede - jornada'].str.extract(r'(.+) - (.+)')\n    # Define las columnas a eliminar y los nuevos nombres de las columnas.\n    columnas_a_eliminar = [\n        'Primer nombre',\n        'Segundo nombre',\n        'Primer apellido',\n        'Segundo apellido',\n        'Sexo',\n        'Tel\u00e9fono',\n        'Celular',\n        'Correo electr\u00f3nico',\n        'Fecha de nacimiento',\n        'Direcci\u00f3n',\n        'Lugar de residencia',\n        'Sede - jornada',\n        'Barrio',    ]\n    renombres = {\n        'N\u00famero de identificaci\u00f3n':'DOCUMENTO_ESTUDIANTE',\n        'C\u00f3digo de referencia':'REFERENCIA',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        }\n\n    # Limpia las columnas del DataFrame, eliminando y renombrando seg\u00fan sea necesario.\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres,True)    \n    # Remove dots from TIPO_DOCUMENTO\n    df['TIPO_DOCUMENTO'] = df['TIPO_DOCUMENTO'].str.replace('.', '', regex=False)\n    return df\n\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Preinscritos = obtener_sharepoint_emp_Preinscritos()\n    df_emp_Preinscritos = procesar_preinscritos(df_emp_Preinscritos)\n    actualizar_sharepoint_procesado(df_emp_Preinscritos, 'emp_Preinscritos')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/","title":"emp_04 Egresados Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,replace_values_df,obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/#obtener_sharepoint_emp_egresados_graduados","title":"obtener_sharepoint_emp_Egresados_Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_04_egresados_Graduados/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de egresados y graduados almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Egresados_Graduados</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Graduados_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se elimina la columna <code>Grupo</code> y se reemplazan valores en el <code>DataFrame</code> utilizando la funci\u00f3n <code>replace_values_df</code>. Finalmente, se renombran las columnas para limpiar y estandarizar los datos utilizando la funci\u00f3n <code>limpiar_columnas</code>, asegurando que los datos est\u00e9n estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_emp_Egresados_Graduados():\n    folder_url = etl_to_folder_url.get('emp_Egresados_Graduados', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Graduados_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Graduados_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n    # Eliminar columna: 'Grupo'\n    df = df.drop(columns=['Grupo'])\n    df = replace_values_df(df)\n    renombrar = {\n        'C\u00f3digo de matr\u00edcula':'ID_MATRICULA',\n        'Tipo de documento':'TIPO_DOCUMENTO',\n        'N\u00famero de identificaci\u00f3n':'DOCUMENTO',\n        'Grupo Sisben':'GRUPO',\n        'Nivel de formaci\u00f3n':'NIVEL_FORMACION',\n        'Ocupaci\u00f3n':'OCUPACION',\n        'Sede':'SEDE',\n        'Jornada':'JORNADA',\n        'Programa':'PROGRAMA',\n        'Per\u00edodo':'PERIODO_ACADEMICO',\n        'Nivel':'SEMESTRE',\n        'Fecha graduado':'FECHA_GRADUADO',\n        'Acta graduado':'ACTA_GRADUADO',\n        'Folio graduado':'FOLIO_GRADUADO',\n        'Diploma graduado':'DIPLOMA_GRADUADO'    \n    }\n    eliminar = []\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n    df = df[['ID_MATRICULA',\n        'TIPO_DOCUMENTO',\n        'DOCUMENTO',\n        'GRUPO',\n        'NIVEL_FORMACION',\n        'OCUPACION',\n        'SEDE',\n        'JORNADA',\n        'PROGRAMA',\n        'PERIODO_ACADEMICO',\n        'SEMESTRE',\n        'FECHA_GRADUADO',\n        'ACTA_GRADUADO',\n        'FOLIO_GRADUADO',\n        'DIPLOMA_GRADUADO',\n        'ZONA',\n        '\u00daLTIMA FECHA DE ACTUALIZACI\u00d3N']]\n\n    # Remove empty columns\n    df = df.dropna(axis=1, how='all')\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Egresados_Graduados = obtener_sharepoint_emp_Egresados_Graduados()\n    actualizar_sharepoint_procesado(df_emp_Egresados_Graduados, 'emp_Egresados_Graduados')\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>2024-12-08 21:02:57,281 - INFO - \u001b[92mIniciando: ETL\u001b[0m\n2024-12-08 21:02:57,287 - INFO - \u001b[92mIniciando: Limpiar carpeta de descargas\u001b[0m\n2024-12-08 21:02:57,299 - INFO - Archivo eliminado: Graduados_Junio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,307 - INFO - Archivo eliminado: Graduados_Julio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,316 - INFO - Archivo eliminado: Graduados_Septiembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,325 - INFO - Archivo eliminado: Graduados_Abril 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,332 - INFO - Archivo eliminado: Graduados_Octubre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,337 - INFO - Archivo eliminado: Graduados_Marzo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,357 - INFO - Archivo eliminado: Graduados_Diciembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,366 - INFO - Archivo eliminado: Graduados_Junio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,371 - INFO - Archivo eliminado: Graduados_Noviembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,380 - INFO - Archivo eliminado: Graduados_Octubre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,386 - INFO - Archivo eliminado: Graduados_Julio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,394 - INFO - Archivo eliminado: Graduados_Octubre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,403 - INFO - Archivo eliminado: Graduados_Septiembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,411 - INFO - Archivo eliminado: Graduados_Septiembre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,418 - INFO - Archivo eliminado: Graduados_Enero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,425 - INFO - Archivo eliminado: Graduados_Agosto 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,432 - INFO - Archivo eliminado: Graduados_Agosto 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,440 - INFO - Archivo eliminado: Graduados_Noviembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,448 - INFO - Archivo eliminado: Graduados_Mayo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,455 - INFO - Archivo eliminado: Graduados_Enero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,464 - INFO - Archivo eliminado: Graduados_Abril 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,470 - INFO - Archivo eliminado: Graduados_Abril 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,478 - INFO - Archivo eliminado: Graduados_Mayo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,485 - INFO - Archivo eliminado: Graduados_Septiembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,492 - INFO - Archivo eliminado: Graduados_Enero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,500 - INFO - Archivo eliminado: Graduados_Marzo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,506 - INFO - Archivo eliminado: Graduados_Diciembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,515 - INFO - Archivo eliminado: Graduados_Diciembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,524 - INFO - Archivo eliminado: Graduados_Febrero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,532 - INFO - Archivo eliminado: Graduados_Agosto 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,538 - INFO - Archivo eliminado: Graduados_Julio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,546 - INFO - Archivo eliminado: Graduados_Febrero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,553 - INFO - Archivo eliminado: Graduados_Octubre 2019_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,561 - INFO - Archivo eliminado: Graduados_Marzo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,568 - INFO - Archivo eliminado: Graduados_Agosto 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,575 - INFO - Archivo eliminado: Graduados_Febrero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,583 - INFO - Archivo eliminado: Graduados_Octubre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,589 - INFO - Archivo eliminado: Graduados_Mayo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,596 - INFO - Archivo eliminado: Graduados_Junio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 21:02:57,598 - INFO - \u001b[92mProceso 'Limpiar carpeta de descargas' completado exitosamente en 0.31 segundos.\u001b[0m\n2024-12-08 21:02:57,599 - INFO - \u001b[92mIniciando: Descargar archivos de SharePoint\u001b[0m\n2024-12-08 21:02:58,772 - INFO - Archivo descargado: Graduados_Junio 2023_21_11_2024.xlsx\n2024-12-08 21:03:00,128 - INFO - Archivo descargado: Graduados_Julio 2024_21_11_2024.xlsx\n2024-12-08 21:03:01,439 - INFO - Archivo descargado: Graduados_Septiembre 2022_21_11_2024.xlsx\n2024-12-08 21:03:02,793 - INFO - Archivo descargado: Graduados_Abril 2023_21_11_2024.xlsx\n2024-12-08 21:03:04,293 - INFO - Archivo descargado: Graduados_Octubre 2023_21_11_2024.xlsx\n2024-12-08 21:03:05,531 - INFO - Archivo descargado: Graduados_Marzo 2022_21_11_2024.xlsx\n2024-12-08 21:03:06,757 - INFO - Archivo descargado: Graduados_Diciembre 2022_21_11_2024.xlsx\n2024-12-08 21:03:08,140 - INFO - Archivo descargado: Graduados_Junio 2024_21_11_2024.xlsx\n2024-12-08 21:03:09,507 - INFO - Archivo descargado: Graduados_Noviembre 2022_21_11_2024.xlsx\n2024-12-08 21:03:10,785 - INFO - Archivo descargado: Graduados_Octubre 2024_21_11_2024.xlsx\n2024-12-08 21:03:12,150 - INFO - Archivo descargado: Graduados_Julio 2023_21_11_2024.xlsx\n2024-12-08 21:03:13,729 - INFO - Archivo descargado: Graduados_Octubre 2022_21_11_2024.xlsx\n2024-12-08 21:03:14,966 - INFO - Archivo descargado: Graduados_Septiembre 2021_21_11_2024.xlsx\n2024-12-08 21:03:16,188 - INFO - Archivo descargado: Graduados_Septiembre 2024_21_11_2024.xlsx\n2024-12-08 21:03:17,471 - INFO - Archivo descargado: Graduados_Enero 2023_21_11_2024.xlsx\n2024-12-08 21:03:18,876 - INFO - Archivo descargado: Graduados_Agosto 2024_21_11_2024.xlsx\n2024-12-08 21:03:20,304 - INFO - Archivo descargado: Graduados_Agosto 2022_21_11_2024.xlsx\n2024-12-08 21:03:22,227 - INFO - Archivo descargado: Graduados_Noviembre 2023_21_11_2024.xlsx\n2024-12-08 21:03:23,650 - INFO - Archivo descargado: Graduados_Mayo 2022_21_11_2024.xlsx\n2024-12-08 21:03:25,017 - INFO - Archivo descargado: Graduados_Enero 2024_21_11_2024.xlsx\n2024-12-08 21:03:26,300 - INFO - Archivo descargado: Graduados_Abril 2022_21_11_2024.xlsx\n2024-12-08 21:03:27,795 - INFO - Archivo descargado: Graduados_Abril 2024_21_11_2024.xlsx\n2024-12-08 21:03:29,145 - INFO - Archivo descargado: Graduados_Mayo 2023_21_11_2024.xlsx\n2024-12-08 21:03:30,567 - INFO - Archivo descargado: Graduados_Septiembre 2023_21_11_2024.xlsx\n2024-12-08 21:03:31,793 - INFO - Archivo descargado: Graduados_Enero 2022_21_11_2024.xlsx\n2024-12-08 21:03:33,260 - INFO - Archivo descargado: Graduados_Marzo 2024_21_11_2024.xlsx\n2024-12-08 21:03:34,704 - INFO - Archivo descargado: Graduados_Diciembre 2023_21_11_2024.xlsx\n2024-12-08 21:03:35,986 - INFO - Archivo descargado: Graduados_Diciembre 2021_21_11_2024.xlsx\n2024-12-08 21:03:37,264 - INFO - Archivo descargado: Graduados_Febrero 2023_21_11_2024.xlsx\n2024-12-08 21:03:38,677 - INFO - Archivo descargado: Graduados_Agosto 2023_21_11_2024.xlsx\n2024-12-08 21:03:40,022 - INFO - Archivo descargado: Graduados_Julio 2022_21_11_2024.xlsx\n2024-12-08 21:03:41,313 - INFO - Archivo descargado: Graduados_Febrero 2022_21_11_2024.xlsx\n2024-12-08 21:03:42,530 - INFO - Archivo descargado: Graduados_Octubre 2019_21_11_2024.xlsx\n2024-12-08 21:03:44,019 - INFO - Archivo descargado: Graduados_Marzo 2023_21_11_2024.xlsx\n2024-12-08 21:03:45,303 - INFO - Archivo descargado: Graduados_Agosto 2021_21_11_2024.xlsx\n2024-12-08 21:03:46,667 - INFO - Archivo descargado: Graduados_Febrero 2024_21_11_2024.xlsx\n2024-12-08 21:03:47,884 - INFO - Archivo descargado: Graduados_Octubre 2021_21_11_2024.xlsx\n2024-12-08 21:03:49,438 - INFO - Archivo descargado: Graduados_Mayo 2024_21_11_2024.xlsx\n2024-12-08 21:03:50,790 - INFO - Archivo descargado: Graduados_Junio 2022_21_11_2024.xlsx\n2024-12-08 21:03:51,792 - INFO - \u001b[92mProceso 'Descargar archivos de SharePoint' completado exitosamente en 54.19 segundos.\u001b[0m\n2024-12-08 21:04:05,897 - INFO - Archivo procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx subido exitosamente a SharePoint.\n\n\nArchivo subido a SharePoint: procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx, folder_url: Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/06.Egresados_Graduados\n\n\n2024-12-08 21:04:06,408 - INFO - \u001b[92mProceso 'ETL' completado exitosamente en 1.15 minutos.\u001b[0m\n\n\nArchivo original eliminado: procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/","title":"emp_05 Estudiantes Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,procesar_excel_con_hojas,limpiar_columnas,concatenar_dataframes,\n    obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/#emp_estudiantes_inasistencias","title":"emp_Estudiantes_inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_05_Estudiantes_inasistencias/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de estudiantes con inasistencias almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Estudiantes_inasistencias</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'emp_Estudiantes_inasistencias_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan las columnas innecesarias y se renombran las columnas para limpiar y estandarizar los datos utilizando la funci\u00f3n <code>limpiar_columnas</code>. Adem\u00e1s, se actualizan las columnas de programa, sede y per\u00edodo utilizando la funci\u00f3n <code>actualizar_columna_programa</code>. Finalmente, se separa la columna <code>Identificaci\u00f3n</code> en tipo y n\u00famero, y se filtran las filas seg\u00fan la columna <code>Sede - jornada</code>, asegurando que los datos est\u00e9n estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def procesar_inasistencias(file_path):\n    df=procesar_excel_con_hojas(file_path)\n    df.columns = [f'Columna_{i}' for i in range(len(df.columns))]\n\n\n    # Split column into SEDE and JORNADA\n    df[['SEDE', 'JORNADA']] = df['Columna_0'].str.extract(r'(.+) - (.+)')\n    df = df.drop(df.index[:8])\n    df_emp_Estudiantes_inasistencias =  df\n    elimina = {'Columna_1'}\n\n    # Fill empty values in Columna_12 with values from Columna_13\n    df_emp_Estudiantes_inasistencias['Columna_12'] = df_emp_Estudiantes_inasistencias['Columna_12'].fillna(df_emp_Estudiantes_inasistencias['Columna_13'])\n\n    # Asumiendo que df_emp_Estudiantes_inasistencias ya existe\n    df = df_emp_Estudiantes_inasistencias\n    # Variables para controlar el estado\n    found_porcentaje = False\n    found_creditos = False\n    # Funci\u00f3n para procesar cada fila\n    def process_row(row):\n        global found_porcentaje, found_creditos\n        if isinstance(row['Columna_15'], str) and 'Porcentaje' in row['Columna_15']:\n            found_porcentaje = True\n            found_creditos = False\n        elif row['Columna_15'] == 'Creditos':\n            found_creditos = True\n            found_porcentaje = False\n        if found_porcentaje:\n            row['Columna_16'] = row['Columna_15']\n        elif found_creditos:\n            row['Columna_14'] = row['Columna_15']\n        return row\n    # Aplicar la funci\u00f3n a cada fila del DataFrame\n    df = df.apply(process_row, axis=1)\n    # Asignar el resultado de vuelta a df_emp_Estudiantes_inasistencias\n    df_emp_Estudiantes_inasistencias = df\n\n    df = df_emp_Estudiantes_inasistencias\n    # Extraer los valores en las columnas 'Tipo Identificacion' e 'Identificacion'\n\n    # Eliminar los puntos de la columna 'Columna_7'\n    df['Columna_7'] = df['Columna_7'].str.replace('.', '', regex=False)\n\n    df[['Tipo_documento', 'Identificacion']] = df['Columna_7'].str.extract(r'(.+?)\\s+(.+)')\n\n\n    df = df.dropna(axis=1, how='all')\n\n    renombrar = {\n    }\n    eliminar = ['Columna_11',\n                'Columna_7',\n                'Columna_0',\n                'Columna_13',\n                'Columna_15',\n                ]\n    df = limpiar_columnas(df, eliminar, renombrar,True)\n\n    # Restablecer el \u00edndice antes de renombrar las columnas\n    df = df.reset_index(drop=True)\n\n    # Rename columns starting with 'Columna_' using row 0 values in uppercase\n    df.columns = [\n        str(df.iloc[0][col]).upper() if col.startswith('COLUMNA_') else col\n        for col in df.columns\n    ]\n    df = df.drop(0).reset_index(drop=True)\n\n    # Filtrar filas seg\u00fan la columna: 'ESTUDIANTE'\n    df = df[df['ESTUDIANTE'].notna()]\n\n    # Filtrar filas seg\u00fan la columna: 'PROGRAMA'\n    df = df[df['PROGRAMA'] != \"Programa\"]\n\n    renombrar={\n        'ESTUDIANTE': 'NOMBRE_ESTUDIANTE',\n        'IDENTIFICACION': 'DOCUMENTO_ESTUDIANTE',\n        'NIVEL': 'SEMESTRE',\n        'M\u00d3DULO': 'MODULO'        \n    }\n    eliminar = []\n    df = limpiar_columnas(df, eliminar, renombrar,True)        \n    return df\n\ndef obtener_sharepoint_emp_Estudiantes_inasistencias():\n    folder_url = etl_to_folder_url.get('emp_Estudiantes_inasistencias', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"emp_Estudiantes_inasistencias_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'emp_Estudiantes_inasistencias_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [procesar_inasistencias(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    # df = pd.concat(all_dfs, ignore_index=True)\n\n    # Concatenar todos los DataFrames en uno solo\n    df = concatenar_dataframes(all_dfs)\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Estudiantes_inasistencias = obtener_sharepoint_emp_Estudiantes_inasistencias()\n    actualizar_sharepoint_procesado(df_emp_Estudiantes_inasistencias, 'emp_Estudiantes_inasistencias')\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>2024-12-08 20:56:25,939 - INFO - \u001b[92mIniciando: ETL\u001b[0m\n2024-12-08 20:56:25,945 - INFO - \u001b[92mIniciando: Limpiar carpeta de descargas\u001b[0m\n2024-12-08 20:56:25,958 - INFO - Archivo eliminado: Graduados_Junio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,966 - INFO - Archivo eliminado: Graduados_Julio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,974 - INFO - Archivo eliminado: Graduados_Septiembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,982 - INFO - Archivo eliminado: Graduados_Abril 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,991 - INFO - Archivo eliminado: Graduados_Octubre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:25,998 - INFO - Archivo eliminado: Graduados_Marzo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,007 - INFO - Archivo eliminado: Graduados_Diciembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,014 - INFO - Archivo eliminado: Graduados_Junio 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,022 - INFO - Archivo eliminado: Graduados_Noviembre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,030 - INFO - Archivo eliminado: Graduados_Octubre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,037 - INFO - Archivo eliminado: Graduados_Julio 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,044 - INFO - Archivo eliminado: Graduados_Octubre 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,050 - INFO - Archivo eliminado: Graduados_Septiembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,059 - INFO - Archivo eliminado: Graduados_Septiembre 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,065 - INFO - Archivo eliminado: Graduados_Enero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,073 - INFO - Archivo eliminado: Graduados_Agosto 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,079 - INFO - Archivo eliminado: Graduados_Agosto 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,085 - INFO - Archivo eliminado: Graduados_Noviembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,091 - INFO - Archivo eliminado: Graduados_Mayo 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,096 - INFO - Archivo eliminado: Graduados_Enero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,102 - INFO - Archivo eliminado: Graduados_Abril 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,108 - INFO - Archivo eliminado: Graduados_Abril 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,114 - INFO - Archivo eliminado: Graduados_Mayo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,120 - INFO - Archivo eliminado: Graduados_Septiembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,125 - INFO - Archivo eliminado: Graduados_Enero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,132 - INFO - Archivo eliminado: Graduados_Marzo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,138 - INFO - Archivo eliminado: Graduados_Diciembre 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,144 - INFO - Archivo eliminado: Graduados_Diciembre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,150 - INFO - Archivo eliminado: Graduados_Febrero 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,156 - INFO - Archivo eliminado: Graduados_Agosto 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,165 - INFO - Archivo eliminado: Graduados_Julio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,172 - INFO - Archivo eliminado: Graduados_Febrero 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,199 - INFO - Archivo eliminado: Graduados_Octubre 2019_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,204 - INFO - Archivo eliminado: Graduados_Marzo 2023_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,210 - INFO - Archivo eliminado: Graduados_Agosto 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,215 - INFO - Archivo eliminado: Graduados_Febrero 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,223 - INFO - Archivo eliminado: Graduados_Octubre 2021_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,229 - INFO - Archivo eliminado: Graduados_Mayo 2024_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,239 - INFO - Archivo eliminado: Graduados_Junio 2022_21_11_2024.xlsx en ../Procesados/Temporal/\n2024-12-08 20:56:26,241 - INFO - \u001b[92mProceso 'Limpiar carpeta de descargas' completado exitosamente en 0.30 segundos.\u001b[0m\n2024-12-08 20:56:26,243 - INFO - \u001b[92mIniciando: Descargar archivos de SharePoint\u001b[0m\n2024-12-08 20:56:27,449 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Diciembre 2023.xlsx\n2024-12-08 20:56:28,866 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Septiembre 2023.xlsx\n2024-12-08 20:56:30,203 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2023.xlsx\n2024-12-08 20:56:31,566 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2024.xlsx\n2024-12-08 20:56:33,015 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2024.xlsx\n2024-12-08 20:56:34,433 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2023.xlsx\n2024-12-08 20:56:35,815 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2024.xlsx\n2024-12-08 20:56:37,379 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2023.xlsx\n2024-12-08 20:56:38,773 - INFO - Archivo descargado: emp_Estudiantes_inasistencias_Per\u00edodo Julio 2024.xlsx\n2024-12-08 20:56:39,775 - INFO - \u001b[92mProceso 'Descargar archivos de SharePoint' completado exitosamente en 13.53 segundos.\u001b[0m\n2024-12-08 20:56:41,711 - INFO - Archivo procesado_emp_Estudiantes_inasistencias_08_12_2024_20_56.xlsx subido exitosamente a SharePoint.\n\n\nArchivo subido a SharePoint: procesado_emp_Estudiantes_inasistencias_08_12_2024_20_56.xlsx, folder_url: Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/05.Estudiantes_cancelados_por_inasistencias\n\n\n2024-12-08 20:56:42,221 - INFO - \u001b[92mProceso 'ETL' completado exitosamente en 16.28 segundos.\u001b[0m\n\n\nArchivo original eliminado: procesado_emp_Estudiantes_inasistencias_08_12_2024_20_56.xlsx\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/","title":"emp_06 Consolidado Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>glob</code>, <code>re</code>, <code>datetime</code>, <code>pandas</code> y <code>openpyxl</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>log_step_decorator</code> <code>download_all_files_from_sharepoint</code> y <code>limpiar_carpeta</code>.El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Este c\u00f3digo asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport logging\nimport os\nimport sys\nimport glob\nimport pandas as pd\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\n\n\nfrom Utils.Funciones import (\n    log_step_decorator,limpiar_columnas,actualizar_columna_programa,obtener_sharepoint,actualizar_sharepoint_procesado\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n    # Configurar el formato del logger\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n\n    # Crear un manejador de archivos para guardar los logs en un archivo\n    file_handler = logging.FileHandler(\"scraper.log\")\n    file_handler.setFormatter(formatter)  # Asignar el formato al manejador de archivos\n    logger.addHandler(file_handler)  # Agregar el manejador de archivos al logger\n\n    # Crear un manejador de consola para mostrar los logs en la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)  # Asignar el formato al manejador de consola\n    logger.addHandler(console_handler)  # Agregar el manejador de consola al logger\n\n\n# Diccionario que mapea nombres de carpetas a sus respectivas URLs en SharePoint\netl_to_folder_url = {\n    \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n    \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n    \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n    \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n    \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n    \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n    \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n    \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n    \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n    \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n    \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n    \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n    \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'    \n    }\n\n\n# Configurar logger\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n\n\n# Folder para procesar archivos temporales\n_folder = '../Procesados/Temporal/'\n</code></pre> <pre><code>&lt;IPython.core.display.Javascript object&gt;\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/#consolidado_inasistencias","title":"consolidado_Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.Sharepoint/emp_06_consolidado_Inasistencias/#automatizacion","title":"Automatizaci\u00f3n","text":"<p>El c\u00f3digo realiza un proceso de ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) para los datos de estudiantes con inasistencias almacenados en SharePoint. Utiliza decoradores para registrar los pasos del proceso, lo que facilita el seguimiento y la depuraci\u00f3n. La funci\u00f3n <code>obtener_sharepoint_emp_Consolidado_inasistenciass</code> descarga los archivos de Excel desde una carpeta espec\u00edfica en SharePoint, identifica los archivos que cumplen con el patr\u00f3n 'Consolidado_inasistencias_*.xlsx', y procesa cada archivo utilizando <code>pandas</code> para leer los datos.</p> <p>Primero, se asegura de que la carpeta de destino exista y est\u00e9 limpia mediante la funci\u00f3n <code>obtener_sharepoint</code>. Luego, descarga los archivos desde SharePoint y verifica si la lista de archivos est\u00e1 vac\u00eda. Si no se encuentran archivos, se registra un error.</p> <p>Los datos de todos los archivos se leen en <code>DataFrames</code> de <code>pandas</code> y se concatenan en un \u00fanico <code>DataFrame</code>. Luego, se eliminan las columnas innecesarias y se renombran las columnas para limpiar y estandarizar los datos utilizando la funci\u00f3n <code>limpiar_columnas</code>. Adem\u00e1s, se actualizan las columnas de programa, sede y per\u00edodo utilizando la funci\u00f3n <code>actualizar_columna_programa</code>. Finalmente, se separa la columna <code>Identificaci\u00f3n</code> en tipo y n\u00famero, y se filtran las filas seg\u00fan la columna <code>Sede - jornada</code>, asegurando que los datos est\u00e9n estructurados adecuadamente para su posterior an\u00e1lisis o carga en un sistema de almacenamiento de datos.</p> <pre><code>def obtener_sharepoint_emp_Consolidado_inasistenciass():\n    folder_url = etl_to_folder_url.get('emp_Consolidado_inasistencias', \"URL por defecto si no se encuentra el valor de etl\")\n    obtener_sharepoint(folder_url,_folder)\n\n    # Obtener todos los archivos en la carpeta\n    files = glob.glob(os.path.join(_folder, \"Consolidado_inasistencias_*.xlsx\"))\n\n    # Verificar si la lista de archivos est\u00e1 vac\u00eda\n    if not files:\n        logger.error(\"No se encontraron archivos con el patr\u00f3n 'Consolidado_inasistencias_*.xlsx' en la carpeta.\")\n        return None\n\n    # Procesar todos los archivos y acumular los datos en un DataFrame\n    all_dfs = [pd.read_excel(file) for file in files]\n\n    # Concatenar todos los DataFrames en uno solo\n    df = pd.concat(all_dfs, ignore_index=True)\n\n\n    return df\n\n\ndef procesar_inasistencias(df):\n\n    df.columns = [f'Columna_{i}' for i in range(len(df.columns))]\n\n    df = actualizar_columna_programa(\n        df, \n        columna_condicional='Columna_4', \n        columna_origen='Columna_5', \n        columna_destino='Programa',\n        texto_filtro='Programa'\n    )\n\n    df = actualizar_columna_programa(\n        df, \n        columna_condicional='Columna_1', \n        columna_origen='Columna_3', \n        columna_destino='Sede',\n        texto_filtro='Sede'\n    )\n\n    df = actualizar_columna_programa(\n        df, \n        columna_condicional='Columna_11', \n        columna_origen='Columna_12', \n        columna_destino='Per\u00edodo',\n        texto_filtro='Per\u00edodo'\n    )\n\n\n    columnas_a_eliminar = ['Columna_4','Columna_11','Columna_0','Columna_1','Columna_8','Columna_9','Columna_10','Columna_12']\n    renombres = {'Columna_2': 'Identificaci\u00f3n', 'Columna_3': 'Apellidos y Nombres', 'Columna_5': 'Nivel', 'Columna_6': 'Area', 'Columna_7': 'Total'}\n    df = limpiar_columnas(df, columnas_a_eliminar, renombres)\n\n    # Filtrar filas seg\u00fan la columna: 'Identificaci\u00f3n'\n    df = df[df['Identificaci\u00f3n'].notna()]\n\n    # Eliminar espacios adicionales en la columna 'Identificaci\u00f3n'\n    df['Identificaci\u00f3n'] = df['Identificaci\u00f3n'].str.strip()\n\n\n    # Separar la columna \"Identificaci\u00f3n\" en tipo y n\u00famero\n    df[['Tipo Identificaci\u00f3n', 'Identificaci\u00f3n']] = df['Identificaci\u00f3n'].str.split(' ', expand=True)\n    df['Tipo Identificaci\u00f3n'] = df['Tipo Identificaci\u00f3n'].apply(lambda x: str(x).replace('.', ''))\n\n\n    #filtra Identificaci\u00f3n y elimina todas las filas que contentan Identificaci\u00f3n\n    df = df[df['Identificaci\u00f3n'].str.contains('Identificaci\u00f3n')==False]\n\n    df = df[[\n        'Identificaci\u00f3n',\n        'Tipo Identificaci\u00f3n',\n        'Apellidos y Nombres',\n        'Nivel',\n        'Area',\n        'Total',\n        'Programa',\n        'Sede',\n        'Per\u00edodo'\n        ]]\n    df.to_excel(\"emp_Consolidado_inasistencias.xlsx\", index=False)\n\n    df[['SEDE', 'JORNADA']] = df['Sede'].str.extract(r'(.+) - (.+)')\n    #ELIMINA COLUMNA Sede\n    df.drop(columns=['Sede'], inplace=True)\n\n    renombres = {\n        'Identificaci\u00f3n':'DOCUMENTO',\n        'Tipo Identificaci\u00f3n':'TIPO_DOCUMENTO',\n        'Apellidos y Nombres':'ESTUDIANTE',\n        'Nivel':'SEMESTRE',\n        'Total':'TOTAL_INASISTENCIA',\n        'Programa':'CURSO',\n        'Per\u00edodo':'PERIODO_ACADEMICO'\n    }\n\n    eliminar = [\n                ]\n\n    df = limpiar_columnas(df, eliminar, renombres,True)\n\n\n    return df\n\n@log_step_decorator(\"ETL\")\ndef main():    \n    df_emp_Consolidado_inasistencias = obtener_sharepoint_emp_Consolidado_inasistenciass()\n    df_emp_Consolidado_inasistencias = procesar_inasistencias(df_emp_Consolidado_inasistencias)\n    actualizar_sharepoint_procesado(df_emp_Consolidado_inasistencias, 'emp_Consolidado_inasistencias')\n\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/","title":"0.1. Docentes Desarrollo Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code> y <code>sys</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se ignoran advertencias espec\u00edficas para evitar distracciones innecesarias durante la ejecuci\u00f3n del script. Si hay otros loggers configurados, tambi\u00e9n se ajusta su nivel de detalle a <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport logging\nimport time\nimport os\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, _descargar, close_driver, hacer_clic, procesar,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/#automatizacion-de-descarga-y-procesamiento-del-reporte-docentes","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Docentes\"","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/01.Docentes_desarrollo_empresarial/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Docentes\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>DOWNLOAD_DIR</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_des_empresarial</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Docentes\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Este enfoque modular y estructurado facilita la depuraci\u00f3n, escalabilidad y mantenimiento del flujo automatizado.</p> <pre><code>@log_step_decorator(\"Docentes desarrollo empresarial\")\ndef main():\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Docentes\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"clic_docentes\",log_step_decorator(\"clic_docentes\")(hacer_clic), {'driver': driver, 'xpath': \n                '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[1]/div[1]/a',\n                'wait_time': 5}),\n            (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), {'driver': driver, 'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n            (\"descargar_archivo\", log_step_decorator(\"descargar_archivo\")(_descargar), {'driver': driver, 'xpath': \n                '//*[@id=\"generar-reporte-btn\"]','download_dir': DOWNLOAD_DIR,\n                'archivo':  f\"Desarrollo_Docentes_{time.strftime('%Y_%m_%d')}\", 'wait_time': 10}),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', 'wait_time': 5}),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', 'wait_time': 5}),\n        ]\n\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        procesar('emp_Docentes', DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/","title":"0.2. Preinscritos","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>time</code>, <code>sys</code>, <code>json</code>, <code>warnings</code> y <code>datetime</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos, <code>close_driver</code> para cerrar el navegador de forma segura, <code>generar_fechas</code> para generar rangos de fechas, <code>configurar_pasos_autenticacion_des_empresarial</code> para configurar los pasos de autenticaci\u00f3n y <code>eliminar_archivos_anteriores</code> para limpiar archivos previos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con la ejecuci\u00f3n del script. Tambi\u00e9n se ajustan los niveles de detalle de otros loggers configurados en el entorno para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging, os, time, sys\nfrom datetime import datetime\nimport json\nfrom dateutil.relativedelta import relativedelta\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic,generar_fechas,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/#automatizacion-de-descarga-y-procesamiento-del-reporte-preinscritos","title":"Automatizaci\u00f3n de Descarga y Procesamiento del Reporte \"Preinscritos\"","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/02.Preinscritos/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script implementa un flujo de trabajo automatizado para descargar y procesar un reporte llamado \"Preinscritos\" desde una plataforma web. Utiliza un navegador configurado din\u00e1micamente a trav\u00e9s de Selenium y organiza las acciones en pasos definidos, cada uno decorado para registrar su ejecuci\u00f3n en el sistema de logging.</p> <p>El proceso inicia configurando el entorno de trabajo mediante <code>setup_driver</code>, que prepara el navegador y define un directorio espec\u00edfico de descargas (<code>DOWNLOAD_DIR</code>). Se establecen par\u00e1metros clave, como la subcarpeta de descargas y las rutas XPath para interactuar con los elementos de la interfaz de usuario. Adem\u00e1s, se configuran pasos de autenticaci\u00f3n con <code>configurar_pasos_autenticacion_des_empresarial</code>, garantizando acceso al sistema.</p> <p>El flujo de trabajo principal se define en una lista de tuplas, donde cada paso incluye: - Un nombre descriptivo. - Una funci\u00f3n decorada con <code>log_step_decorator</code> para registrar su inicio y fin. - Par\u00e1metros espec\u00edficos para ejecutar la acci\u00f3n, como el <code>driver</code>, identificadores XPath o IDs, y tiempos de espera.</p> <p>Las acciones automatizadas incluyen la autenticaci\u00f3n, navegaci\u00f3n al m\u00f3dulo de informes, selecci\u00f3n del reporte \"Preinscritos\", generaci\u00f3n del archivo y su procesamiento. Una vez descargado, el reporte es validado y analizado mediante <code>procesar</code>.</p> <p>El script maneja recursos de manera segura utilizando un bloque <code>try-finally</code>, que asegura el cierre adecuado del navegador (<code>close_driver</code>) incluso si ocurren errores durante la ejecuci\u00f3n. La trazabilidad del proceso est\u00e1 garantizada gracias al registro de cada paso en el sistema de logging.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>def guardar_json(diccionario, nombre_archivo):\n    with open(nombre_archivo, 'w') as archivo:\n        json.dump(diccionario, archivo)\n\n@log_step_decorator(\"Preinscritos\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Preinscritos\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        _eleccion = 1\n        _desde = fechas[_eleccion][\"desde\"]\n        _hasta = fechas[_eleccion][\"hasta\"]\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"clic_preinscritos\", log_step_decorator(\"clic_preinscritos\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[2]/div/a', \n                'wait_time': 5\n            }),\n            (\"abrir_fecha\", log_step_decorator(\"abrir_fecha\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '//*[@id=\"rangoFechas\"]/a/div[1]', \n                'wait_time': 3\n            }),\n            (\"seleccionar_rango_personalizado\", log_step_decorator(\"seleccionar_rango_personalizado\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/ul/li[7]', \n                'wait_time': 3\n            }),\n            (\"ingresar_fecha_inicial\", log_step_decorator(\"ingresar_fecha_inicial\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/div/div[1]/input', \n                'value': _desde, \n                'wait_time': 3\n            }),\n            (\"ingresar_fecha_final\", log_step_decorator(\"ingresar_fecha_final\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', \n                'value': _hasta,  \n                'wait_time': 3\n            }),\n            (\"aceptar_fechas\", log_step_decorator(\"aceptar_fechas\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/div[9]/div[3]/div/button[1]', \n                'wait_time': 3\n            }),\n            (\"generar_reporte\", log_step_decorator(\"generar_reporte\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '//*[@id=\"generar-reporte-btn\"]', \n                'wait_time': 10\n            }),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', \n                'wait_time': 5\n            }),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {\n                'driver': driver,\n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', \n                'wait_time': 5\n            })\n        ]\n\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)  # Aqu\u00ed no se pasa `driver` directamente, solo los par\u00e1metros en `params`\n        procesar(\"emp_Preinscritos\",DOWNLOAD_DIR)\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_fechas(inicio=_inicio,fin=_fin, semestre=_semestre)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/","title":"0.3. Listado Matr\u00edculas Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>random</code>, <code>logging</code>, <code>os</code>, <code>sys</code> y <code>time</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>close_driver</code> para cerrar el navegador de forma segura.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se importan y configuran advertencias para ignorar aquellas espec\u00edficas que no son relevantes para el proceso actual. Esto asegura que el entorno est\u00e9 completamente preparado antes de ejecutar el proceso principal de scraping, proporcionando trazabilidad, modularidad y flexibilidad para manejar diferentes flujos de trabajo automatizados.</p> <pre><code># pylint: disable=all\nimport argparse, random\nimport logging, os, sys, time\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n#importaa json\nimport json\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic, configurar_pasos_autenticacion_des_empresarial, \n    procesar_reporte_modal, generar_periodos,generar_fechas, generar_periodos_cortes\n)\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/#automatizacion-de-descarga-de-listados-de-matriculas-empresarial","title":"Automatizaci\u00f3n de Descarga de Listados de Matr\u00edculas Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/03.Listado_matriculas_emp/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de listados de matr\u00edculas empresariales desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar rangos de fechas y descargar reportes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Listado_matriculas_emp\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el listado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja un diccionario llamado <code>fechas</code>, que contiene los rangos de fechas personalizados. Cada iteraci\u00f3n del bucle configura un rango de fechas en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar fechas y descargar el archivo, est\u00e1n definidos en <code>step_2</code>.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Listado de matr\u00edculas empresarial\")\ndef main(fechas):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        subcarpeta_descarga = \"Listado_matriculas_emp\"\n        driver, download_dir = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Listado_matriculas_emp'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n        # Pasar driver al configurar pasos de autenticaci\u00f3n\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {\n                'driver': driver, 'id': 'submit-btn', 'wait_time': 10\n            }),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {\n                'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5\n            }),\n            (\"listado\", log_step_decorator(\"listado\")(hacer_clic), {\n                'driver': driver, 'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[4]/div[2]/a', 'wait_time': 5\n            }),\n        ]\n\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n\n\n        for fecha in fechas:\n            logging.info(f\"Fecha: {fecha}\")\n            _hash = f\"{random.randint(1000, 9999)}\"\n            nombre_archivo_completo = f'{nombre_archivo}_{_hash}.xlsx'\n\n            step_2 = [\n                (\"entrar_en_fecha\", log_step_decorator(\"entrar_en_fecha\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"rangoFechas\"]/a', 'wait_time': 3}),\n                (\"entrar_en_personalizado\", log_step_decorator(\"entrar_en_personalizado\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[9]/div[3]/ul/li[7]', 'wait_time': 3}),\n                (\"entrar_en_fecha1\",log_step_decorator(\"entrar_en_fecha1\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[1]/input','value': fechas[fecha]['desde'],'driver': driver,'wait_time': 3}),\n                (\"entrar_en_fecha2\",log_step_decorator(\"entrar_en_fecha2\")(hacer_clic),{'xpath': '/html/body/div[9]/div[3]/div/div[2]/input', 'value': fechas[fecha]['hasta'],'driver': driver,'wait_time': 3}),\n                (\"aceptar_fecha\", log_step_decorator(\"aceptar_fecha\")(hacer_clic), { 'driver': driver,'xpath': '/html/body/div[9]/div[3]/div/button[1]', 'wait_time': 3}),\n                (\"descargar\", log_step_decorator(\"descargar\")(hacer_clic), { 'driver': driver,'xpath': '//*[@id=\"generar-reporte-btn\"]', 'wait_time': 60}),\n                (\"procesar_reporte\", log_step_decorator(\"procesar_reporte\")(procesar_reporte_modal), {'driver': driver, 'download_dir': download_dir, 'archivo': nombre_archivo_completo})]\n            for step_name, step_function, params in step_2:\n                logging.info(f\"Ejecutando el paso: {step_name}\")\n                step_function(**params)\n                time.sleep(5)\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n        procesar(\"emp_Listado_Matriculas\",download_dir)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    _semestre = args.semestre if args.semestre else False  # Valor manual\n    fechas = generar_periodos_cortes(anio_inicio=_inicio, anio_fin=_fin, tipo=4)\n    main(fechas)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/","title":"0.4. Consolidado Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>warnings</code>, <code>pandas</code> y <code>selenium.webdriver.common.by.By</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code> y <code>procesar_reporte_modal</code>, para manejar los datos descargados, y <code>hacer_clic</code>, una funci\u00f3n gen\u00e9rica para interactuar con elementos de la interfaz web. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos y <code>ejecutar_pasos</code> para ejecutar una serie de acciones de forma secuencial.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging\nimport time\nimport os\nimport sys\nimport pandas as pd\nfrom selenium.webdriver.common.by import By\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar_reporte_modal, obtener_elementos_dropdown, \n    hacer_clic, elemento_disponible, seleccionar_opcion_con_js, procesar, guardar_diccionario,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores,ejecutar_pasos\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/#automatizacion-de-descarga-de-consolidado-de-inasistencias","title":"Automatizaci\u00f3n de Descarga de Consolidado de Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/04.Consolidado_inasistencias/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de consolidado de inasistencias desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar periodos, jornadas, programas, m\u00f3dulos y cursos, y descargar los reportes correspondientes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Consolidado_inasistencias\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el consolidado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja la selecci\u00f3n de periodos, jornadas, programas, m\u00f3dulos y cursos. Cada iteraci\u00f3n del bucle configura estos par\u00e1metros en la interfaz de la web, genera el reporte y procesa los datos descargados. Adem\u00e1s, el script incluye la eliminaci\u00f3n de archivos anteriores en la carpeta de descargas antes de procesar nuevos.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>driver.quit()</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema, adenas tiene un argumento <code>--semestre</code> que en caso de ser <code>True</code> omitir\u00e1 los dem\u00e1s argumentos y tomar\u00e1 los valores del \u00faltimo semestre.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>En caso de solicitar el \u00faltimo semestre</p> <pre><code>python nombre_archivo.py --semestre True\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Consolidado_inasistencias\")\ndef main(consulta):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Consolidado_inasistencias\"\n        generar = False\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"consolidado\",log_step_decorator(\"consolidado\")(hacer_clic), {'driver': driver, 'xpath': \n                '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[1]/div[2]/a',\n                'wait_time': 5}),\n        ]\n\n        ejecutar_pasos(step_1)\n        # time.sleep(100)   \n\n\n        _xpath_periodo  = '//*[@id=\"form0\"]/div[1]/div[3]'\n        periodo_boton = f'{_xpath_periodo}/div/button'\n        periodo_list = f'{_xpath_periodo}/div/div/ul'\n        nivel = 1\n\n        # Obtener los periodos disponibles en el dropdown\n        _periodos = obtener_elementos_dropdown(driver, periodo_boton, periodo_list, nivel)\n\n        periodos_generados = [f\"{year}\" for year in consulta]\n        #elimina repetidos de periodos_generados        \n        periodos_generados = list(set(periodos_generados))\n        # Filtrar solo los per\u00edodos que comiencen con los valores generados\n        periodos = [\n            periodo for periodo in _periodos \n            if any(generado in periodo for generado in periodos_generados)\n        ]\n        # Guardar los per\u00edodos seleccionados en un archivo para referencia\n        guardar_diccionario(periodos, 'periodos')\n\n        # Eliminar archivos anteriores en la carpeta de descargas antes de procesar nuevos\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        # Procesar cada periodo seleccionado\n\n        if periodos:\n\n            for periodo in periodos:\n                # Seleccionar el periodo\n                hacer_clic(driver= driver, xpath=periodo_boton, wait_time= 1)\n                # seleccionar_opcion_custom_dropdown(driver=driver, xpath=periodo_boton, option=periodo, wait_time=1)\n                seleccionar_opcion_con_js(driver, periodo_boton, periodo)\n                logging.info(f\"Procesando periodo: {periodo}\")\n\n                # Obtener jornadas para el periodo seleccionado\n                xpath_jornada = '//*[@id=\"form0\"]/div[2]/div[3]'\n                jornada_boton = f'{xpath_jornada}/div/button'\n                jornada_list = f'{xpath_jornada}/div/div/ul'\n                jornadas = obtener_elementos_dropdown(driver, jornada_boton, jornada_list, nivel=2)\n                excluir_jornadas = {'Seleccione'}\n                jornadas = [jornada for jornada in jornadas if jornada not in excluir_jornadas]\n                jornadas = {'Programa'}\n                if jornadas:                    \n\n                    for jornada in jornadas:\n                        hacer_clic(driver= driver, xpath=jornada_boton, wait_time= 1)\n                        # Seleccionar la jornada\n                        seleccionar_opcion_con_js(driver, jornada_boton, jornada)\n                        time.sleep(4)\n                        logging.info(f\"Procesando jornada: {jornada}\")\n\n                        # Obtener programas para la jornada seleccionada\n                        if jornada == 'Curso':\n                            xpath_programa = '//*[@id=\"form0\"]/div[6]/div[3]'\n                        else:\n                            xpath_programa = '//*[@id=\"form0\"]/div[3]/div[3]' \n                        programa_boton = f'{xpath_programa}/div/button'\n                        programa_list = f'{xpath_programa}/div/div/ul'\n                        programas = obtener_elementos_dropdown(driver, programa_boton, programa_list, nivel=3)\n                        excluir_opciones = {'Seleccione'}\n                        programas = [programa for programa in programas if programa not in excluir_opciones]\n                        if programas:\n\n                            for programa in programas:\n                                hacer_clic(driver= driver, xpath=programa_boton, wait_time= 1)\n                                # Seleccionar el programa\n                                seleccionar_opcion_con_js(driver, programa_boton, programa)\n                                logging.info(f\"Procesando programa: {programa}\")\n                                # Obtener modulo para el programa seleccionado\n                                if jornada == 'Curso':\n                                    xpath_modulo = '//*[@id=\"form0\"]/div[7]/div[3]' \n                                else:\n                                    xpath_modulo = '//*[@id=\"form0\"]/div[4]/div[3]'\n                                modulo_boton = f'{xpath_modulo}/div/button'\n                                modulo_list = f'{xpath_modulo}/div/div/ul'\n                                modulos = obtener_elementos_dropdown(driver, modulo_boton, modulo_list, nivel=4)\n                                excluir_modulos = {'Seleccione'}\n                                modulo = [modulo for modulo in modulos if modulo not in excluir_modulos]\n                                if modulos:\n                                    for modulo in modulos:\n                                        hacer_clic(driver= driver, xpath=modulo_boton, wait_time= 1)\n                                        seleccionar_opcion_con_js(driver, modulo_boton, modulo)\n                                        logging.info(f\"Procesando modulo: {modulo}\")\n                                        # obtener modulo\n                                        if jornada == 'Curso':\n                                            xpath_modulo = '//*[@id=\"form0\"]/div[8]/div[3]'\n                                        else:\n                                            xpath_curso = '//*[@id=\"form0\"]/div[5]/div[3]'\n                                        cursos_boton = f'{xpath_curso}/div/button'\n                                        cursos_list = f'{xpath_curso}/div/div/ul'\n                                        cursos = obtener_elementos_dropdown(driver, cursos_boton, cursos_list, nivel=5)\n                                        excluir_cursos = {'Seleccione'}\n                                        curso = [curso for curso in cursos if curso not in excluir_cursos]\n                                        if cursos:\n                                            for curso in cursos:\n\n                                                seleccionar_opcion_con_js(driver, cursos_boton, curso)\n                                                hacer_clic(driver= driver, xpath=\n                                                    '//*[@id=\"generar-reporte-btn\"]'\n                                                    , wait_time=5)\n                                                #define la variable archivo uniendo periodo, jornada, programa y modulo\n                                                archivo = f'Cede_{periodo}_{jornada}_{programa}_{modulo}_{curso}.xlsx'\n                                                modal = elemento_disponible(driver, By.ID, \"master-modal\", timeout=10)\n                                                if modal:\n                                                    procesar_reporte_modal(driver, DOWNLOAD_DIR, archivo)\n                                                    time.sleep(5)\n                                else: continue\n                        else: continue\n                else: continue\n\n\n            procesar('emp_Consolidado_inasistencias',DOWNLOAD_DIR)\n            logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\n        #Eliminar esta linea en produccion \n        # procesar('emp_Consolidado_inasistencias',DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            # Cerrar el navegador\n            driver.quit()\n        logging.info(\"Fin del proceso principal\")\n\nif __name__ == \"__main__\":\n    # Generar lista de periodos de consulta (2019, 2020)\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--semestre\", type=bool, help=\"Calcular \u00faltimo semestre.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    consulta = {_inicio, _fin}\n    main(consulta)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/","title":"0.5. Estudiantes Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>warnings</code> y <code>pandas</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, <code>procesar_reporte_modal</code>, <code>hacer_clic</code>, <code>obtener_elementos_dropdown</code>, <code>seleccionar_opcion_con_js</code>, <code>guardar_diccionario</code>, <code>configurar_pasos_autenticacion_des_empresarial</code>, <code>eliminar_archivos_anteriores</code> y <code>ejecutar_pasos</code>. Tambi\u00e9n se incluyen herramientas adicionales como <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging\nimport time\nimport os\nimport sys\nimport pandas as pd\n\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar_reporte_modal, obtener_elementos_dropdown, \n    hacer_clic, procesar, seleccionar_opcion_con_js, guardar_diccionario,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores,ejecutar_pasos\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/#automatizacion-de-descarga-de-consolidado-de-inasistencias","title":"Automatizaci\u00f3n de Descarga de Consolidado de Inasistencias","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/05.Estudiantes_inasistencias/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de consolidado de inasistencias desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un bucle para configurar periodos y descargar los reportes correspondientes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Estudiantes_inasistencias\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el consolidado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>La segunda etapa maneja la selecci\u00f3n de periodos. Cada iteraci\u00f3n del bucle configura estos par\u00e1metros en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar opciones en dropdowns y descargar el archivo, est\u00e1n definidos en el c\u00f3digo. Adem\u00e1s, el script incluye la eliminaci\u00f3n de archivos anteriores en la carpeta de descargas antes de procesar nuevos.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>procesar_reporte_modal</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>driver.quit()</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos periodos con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <p>El script utiliza un sistema de logging bien estructurado para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code>@log_step_decorator(\"Estudiantes inasistencias\")\ndef main(consulta):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Estudiantes_inasistencias\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 20}),\n            (\"Estudiantes_inasistencias\",log_step_decorator(\"Estudiantes_inasistencias\")(hacer_clic), {'driver': driver, 'xpath':\n                '//*[@id=\"contenedor-lista\"]/div[2]/div[3]/div[2]/div[2]/div[2]/a',\n                'wait_time': 5}),\n            # (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', 'wait_time': 5}),\n            # (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', 'wait_time': 5}),\n        ]\n\n        ejecutar_pasos(step_1)\n\n\n        _xpath_periodo  = '//*[@id=\"formReportes\"]/div/div[3]'\n        periodo_boton = f'{_xpath_periodo}/div/button'\n        periodo_list = f'{_xpath_periodo}/div/div/ul'        \n        nivel=1\n        # Obtener los periodos disponibles en el dropdown\n        _periodos = obtener_elementos_dropdown(driver, periodo_boton, periodo_list, nivel)        \n        periodos_generados = [f\"{year}\" for year in consulta]\n        #elimina repetidos de periodos_generados        \n        periodos_generados = list(set(periodos_generados))\n        # Filtrar solo los per\u00edodos que comiencen con los valores generados\n        periodos = [\n            periodo for periodo in _periodos \n            if any(generado in periodo for generado in periodos_generados)\n        ]\n        # Guardar los per\u00edodos seleccionados en un archivo para referencia\n        guardar_diccionario(periodos, 'periodos')\n\n        # Eliminar archivos anteriores en la carpeta de descargas antes de procesar nuevos\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n        if periodos:\n            for periodo in periodos:\n                # Seleccionar el periodo\n                hacer_clic(driver= driver, xpath=periodo_boton, wait_time= 1)\n                seleccionar_opcion_con_js(driver, periodo_boton, periodo)\n                logging.info(f\"Procesando periodo: {periodo}\")\n                hacer_clic(driver= driver, xpath= '//*[@id=\"generar-reporte-btn\"]', wait_time=5)\n                #define la variable archivo uniendo periodo, jornada, programa y modulo\n                archivo = f'Cede_{periodo}.xlsx'\n                procesar_reporte_modal(driver, DOWNLOAD_DIR, archivo)\n                time.sleep(5)\n            logging.info(\"Procesamiento de periodos, jornadas y programas completado.\")\n\n\n\n    finally:\n        if driver:\n            driver.quit\n        logging.info(\"Fin del proceso principal\")\n        procesar('emp_Estudiantes_inasistencias', DOWNLOAD_DIR)\n\n\nif __name__ == \"__main__\":\n    # Generar lista de periodos de consulta (2019, 2020)\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    consulta = {_inicio, _fin}\n    main(consulta)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/","title":"0.6. Egresados Graduados Empresarial","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>argparse</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code> y <code>warnings</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_driver</code>, para configurar el navegador, <code>procesar</code>, <code>hacer_clic</code>, <code>configurar_pasos_autenticacion_des_empresarial</code>, <code>eliminar_archivos_anteriores</code>, <code>pre_procesamiento</code> y <code>obtener_elementos_dropdown</code>. Tambi\u00e9n se incluye <code>log_step_decorator</code> para registrar la ejecuci\u00f3n de los pasos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se configuran advertencias espec\u00edficas para ser ignoradas, asegurando que no interfieran con el proceso de scraping. Tambi\u00e9n se ajustan los niveles de otros loggers configurados para mantener la consistencia en el registro de eventos.</p> <pre><code># pylint: disable=all\nimport argparse\nimport logging\nimport time\nimport os\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../../\")) \n\n\nfrom Utils.Funciones import (\n    log_step_decorator, setup_driver, procesar, close_driver, hacer_clic,generar_periodos,\n    configurar_pasos_autenticacion_des_empresarial, eliminar_archivos_anteriores,pre_procesamiento,obtener_elementos_dropdown\n)\n\n\n# Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n\nif logger.hasHandlers():\n    logger.handlers.clear()\n\nformatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\nimport warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n\n# Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre>"},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/#automatizacion-de-descarga-de-consolidado-de-graduados","title":"Automatizaci\u00f3n de Descarga de Consolidado de Graduados","text":""},{"location":"00.etl/00.etl_01.q10_02.educacioncontinua/06.Egresados_graduados_empresarial/#explicacion-tecnica-del-codigo","title":"Explicaci\u00f3n T\u00e9cnica del C\u00f3digo","text":"<p>Este script automatiza la descarga y procesamiento de consolidado de graduados desde una plataforma web. La estructura se basa en Selenium y organiza las tareas en dos bloques principales: autenticaci\u00f3n y selecci\u00f3n inicial, seguidos de un conjunto de pasos para configurar opciones y descargar los reportes correspondientes.</p> <p>En la primera etapa, el script configura el entorno del navegador utilizando <code>setup_driver</code>, definiendo una subcarpeta de descargas llamada <code>\"Graduados\"</code>. Los pasos iniciales incluyen autenticarse y navegar a la secci\u00f3n de informes, donde se selecciona el consolidado correspondiente. Estas acciones est\u00e1n encapsuladas en la lista <code>step_1</code>, con decoradores que registran cada paso en el log.</p> <p>El script maneja la selecci\u00f3n de opciones espec\u00edficas para el tipo de graduado y el periodo. Cada paso configura estos par\u00e1metros en la interfaz de la web, genera el reporte y procesa el archivo descargado. Los pasos espec\u00edficos, como seleccionar opciones en dropdowns y descargar el archivo, est\u00e1n definidos en el c\u00f3digo. Adem\u00e1s, el script incluye la eliminaci\u00f3n de archivos anteriores en la carpeta de descargas antes de procesar nuevos.</p> <p>El c\u00f3digo est\u00e1 dise\u00f1ado para asegurar que cada archivo descargado sea procesado inmediatamente tras su descarga, utilizando funciones como <code>pre_procesamiento</code>. Por \u00faltimo, todos los recursos son liberados de manera segura con <code>close_driver(driver)</code>, y el script asegura que los datos descargados sean gestionados adecuadamente mediante la funci\u00f3n <code>procesar</code>.</p> <p>Esta automatizaci\u00f3n es modular y adaptable, capaz de manejar nuevos rangos de fechas con facilidad y registrar todos los eventos clave para monitoreo y depuraci\u00f3n. La inclusi\u00f3n de <code>argparse</code> mejora significativamente la flexibilidad del script, permitiendo especificar los a\u00f1os de inter\u00e9s directamente desde la l\u00ednea de comandos. </p> <p>El uso de <code>argparse</code> permite que el script reciba par\u00e1metros externos sin necesidad de modificar el c\u00f3digo fuente. En este caso, se definen dos argumentos: <code>--inicio</code> y <code>--fin</code>, que representan el a\u00f1o de inicio y fin para la descarga de los datos, respectivamente. Estos argumentos son parseados y utilizados dentro del script para determinar el rango de a\u00f1os a procesar. En caso de omitirlos tomar\u00e1 el a\u00f1o actual del sistema.</p> <p>Por ejemplo, al ejecutar el script desde la l\u00ednea de comandos con los siguientes argumentos:</p> <pre><code>python nombre_archivo.py --inicio 2020 --fin 2024\n</code></pre> <p>El script descargar\u00e1 y procesar\u00e1 los rangos desde el a\u00f1o 2020 hasta el 2024. Esto permite una gran flexibilidad, ya que el usuario puede ajustar los a\u00f1os de inter\u00e9s sin necesidad de modificar el c\u00f3digo, simplemente cambiando los par\u00e1metros en la l\u00ednea de comandos.</p> <p>Adem\u00e1s, esta modularidad facilita la integraci\u00f3n del script en otros sistemas o pipelines de automatizaci\u00f3n, donde los par\u00e1metros pueden ser definidos din\u00e1micamente en funci\u00f3n de las necesidades del momento. La capacidad de registrar todos los eventos clave mediante decoradores asegura que cada paso del proceso sea monitoreado y registrado, lo que es crucial para la depuraci\u00f3n y el mantenimiento del sistema.</p> <p>En resumen, la combinaci\u00f3n de una estructura modular, el uso de <code>argparse</code> para la flexibilidad de par\u00e1metros y la capacidad de registro detallado de eventos hace que este script sea una herramienta poderosa y adaptable para la automatizaci\u00f3n de la descarga y procesamiento de listados de matr\u00edculas.</p> <pre><code>@log_step_decorator(\"Graduados\")\ndef main(periodo):\n    logging.info(\"Inicio del proceso principal\")\n    driver = None\n    try:\n        # Definir la subcarpeta de descarga\n        subcarpeta_descarga = \"Graduados\"\n\n        # Llamar a setup_driver una vez con la subcarpeta deseada\n        driver, DOWNLOAD_DIR = setup_driver(subcarpeta=subcarpeta_descarga)\n        nombre_archivo = 'Graduados'\n        nombre_archivo_completo = f'{nombre_archivo}.xlsx'\n\n        # Configurar los pasos de autenticaci\u00f3n y otras acciones\n        pasos_autenticacion = configurar_pasos_autenticacion_des_empresarial(driver)\n        eliminar_archivos_anteriores(nombre_archivo=subcarpeta_descarga, download_dir=DOWNLOAD_DIR)\n\n\n\n        step_1 = pasos_autenticacion + [\n            (\"enviar_formulario\", log_step_decorator(\"enviar_formulario\")(hacer_clic), {'driver': driver, 'id': 'submit-btn', 'wait_time': 10}),\n            (\"entrar_en_informes\", log_step_decorator(\"entrar_en_informes\")(hacer_clic), {'driver': driver, 'xpath': '/html/body/nav/div[2]/ul[1]/li[3]/a', 'wait_time': 5}),\n            (\"clic_egresados\", log_step_decorator(\"clic_egresados\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"contenedor-lista\"]/div[2]/div[4]/div[2]/div[1]/div[2]/a', \n                'wait_time': 5\n            }),\n            (\"seleccionar_tipo_graduado\", log_step_decorator(\"seleccionar_tipo_graduado\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[1]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"seleccionperiodos\", log_step_decorator(\"seleccionperiodos\")(hacer_clic), {'driver': driver, \n                'xpath': '//*[@id=\"form0\"]/div[2]/div[3]/div/div/label[2]', \n                'wait_time': 3\n            }),\n            (\"pre_procesamiento\", log_step_decorator(\"pre_procesamiento\")(pre_procesamiento), {\n                'driver': driver,\n                'download_dir': DOWNLOAD_DIR,\n                'id_descargar': 'generar-reporte-btn',\n                'nombre_archivo': nombre_archivo,\n                'nombre_archivo_completo': nombre_archivo_completo,\n                'xpath_boton': '//*[@id=\"form0\"]/div[4]/div[3]/div/button',\n                'tipo':'normal',\n                'xpath_contenedor_opciones':  '//*[@id=\"form0\"]/div[4]/div[3]/div/div/ul',\n                'excluir_opciones': periodos\n            }),\n            (\"clic_usuario\", log_step_decorator(\"clic_usuario\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/a', \n                'wait_time': 5\n            }),\n            (\"cerrar_sesion\", log_step_decorator(\"cerrar_sesion\")(hacer_clic), {'driver': driver, \n                'xpath': '/html/body/nav/div[2]/ul[2]/li[3]/ul/li[6]/a', \n                'wait_time': 5\n            })\n        ]\n\n        # Ejecutar cada uno de los pasos definidos en el diccionario \n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n        procesar('emp_Egresados_Graduados', DOWNLOAD_DIR)\n\n    finally:\n        if driver:\n            close_driver(driver)\n        logging.info(\"Fin del proceso principal\")\n\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Descargar archivos desde SharePoint usando una clave de carpeta.\")\n    parser.add_argument(\"--inicio\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n    parser.add_argument(\"--fin\", type=int, help=\"Fecha inicial para la descarga de archivos.\")\n\n    # Parsear argumentos\n    args = parser.parse_args()\n\n    # Verificar si se pasa un argumento o usar un valor por defecto\n    _inicio = args.inicio if args.inicio else time.localtime().tm_year\n    _fin = args.fin if args.fin else time.localtime().tm_year\n    periodos = generar_periodos(_inicio, _fin)\n    main(periodos)\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/","title":"3.1. Webscraping Actualizable","text":""},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code> y <code>dateutil.relativedelta</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_logger</code>, para configurar el sistema de logging, <code>log_tiempo</code>, para registrar el tiempo de ejecuci\u00f3n, y <code>download_file_between_dates</code>, para manejar la descarga de archivos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se ignoran advertencias espec\u00edficas para evitar distracciones innecesarias durante la ejecuci\u00f3n del script. Si hay otros loggers configurados, tambi\u00e9n se ajusta su nivel de detalle a <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <ol> <li>Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping: Configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</li> <li>Importaci\u00f3n de Librer\u00edas: Importa las librer\u00edas necesarias como <code>selenium</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code>, y <code>dateutil.relativedelta</code>. Tambi\u00e9n se agrega la ruta de la carpeta <code>Funciones</code> al <code>sys.path</code> y se importan funciones espec\u00edficas.</li> <li>Definici\u00f3n de Selectores XPath: Define un diccionario <code>_dict</code> que contiene los selectores XPath necesarios para interactuar con los elementos de la p\u00e1gina web.</li> <li>Inicio del Proceso ETL: Registra el tiempo de inicio y configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n y Formateo de Fechas: Calcula el primer y \u00faltimo d\u00eda del mes anterior y los formatea en el formato 'dd/MM/yyyy'.</li> <li>Automatizaci\u00f3n de la Descarga de Archivos: Utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. Se inicializa el WebDriver, se abre la URL, y se llama a la funci\u00f3n <code>download_file_between_dates()</code> para realizar la descarga.</li> <li>Registro de Informaci\u00f3n y C\u00e1lculo del Tiempo: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga y calcula el tiempo total del proceso ETL.</li> </ol> <pre><code>## Import libraries\nfrom selenium import webdriver                                          ### selenium version 4.25.0\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n#from time import datetime\nimport time\nimport datetime\nimport os\nimport logging\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../\")) \n\nfrom Utils.Funciones import (\n    setup_logger,log_tiempo,download_file_between_dates\n)\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/#diccionario-de-pasos","title":"Diccionario de pasos","text":"<pre><code>_dict = {\n    \"Ticket_button\" : '//*[@id=\"__button12-img\"]',\n    \"Filter_button\" : '//*[@id=\"findformpaneLkIKPWD61a2ejhlWKfn3Bm_151-img\"]',\n    \"Dates\" : '//*[@id=\"__button51-inner\"]',\n    \"Menu\" :'//*[@id=\"__box4-arrow\"]',\n    \"Entre\" : '//*[@id=\"__item154-content\"]/div/div',\n    \"initial_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_532-datePicker-inner',\n    \"final_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_534-datePicker-inner',\n    \"Aceptar\" : '//*[@id=\"__button77-BDI-content\"]',\n    \"Categoria\" : '//*[@id=\"objectvalueselectorPbJLA_soJqak9j9Ey7mLqvW_346-inputField-vhi\"]',\n    \"Educacion\" : '//*[@id=\"statictextm9D_2UNbhq6mK7P6aHrdQ0_559-listdefintion_O68bB2vS4gwMYerXwebjm_556-9\"]',\n    \"Go_button\" : '//*[@id=\"findformpaneGLsDRJxMiqEpkW0gKJRoAW_152-goButton-BDI-content\"]',\n    \"Plus_botton\" : '//*[@id=\"actionbuttonmenuCTxPLT0i_qoT0xcR7Kdqnm_131-button-BDI-content\"]',\n    \"Export_button\" : '//*[@id=\"navigationitemQQFWfu3deac0r5R10TiQ10_144-BDI-content\"]',\n    \"Download_button\" : '//*[@id=\"__button97-content\"]' \n}\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/01.C4C_webscraping_v4_Actualizable/#etl","title":"ETL","text":"<ol> <li>Inicio del Proceso ETL: Registra el tiempo de inicio.</li> <li>Configuraci\u00f3n del Logger: Configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n de Fechas: Calcula el primer y \u00faltimo d\u00eda del mes anterior.</li> <li>Formateo de Fechas: Formatea las fechas calculadas en el formato 'dd/MM/yyyy'.</li> <li>Registro de Fechas: (Comentado) Registra las fechas calculadas.</li> </ol> <p>El c\u00f3digo configura un proceso ETL, calcula fechas relevantes y utiliza un logger para monitorear el proceso.</p> <pre><code>inicio_etl = time.time()\n#---------------------------------------------\nlogger = setup_logger(log_filename='scraper.log', log_level=logging.INFO)  # Cambiado a logging.INFO\nlogger.info('COMIENZO ETL')\n\n\n# Obtener la fecha actual\ncurrent_date = datetime.now()\n\n# Calcular el primer d\u00eda del mes anterior\nfirst_day_previous_month = (current_date.replace(day=1) - relativedelta(months=1)).replace(day=1)\n\n# Calcular el \u00faltimo d\u00eda del mes anterior\nlast_day_previous_month = current_date.replace(day=1) - relativedelta(days=1)\n\n# Formatear las fechas como texto en formato 'dd/MM/yyyy'\nstart_date = first_day_previous_month.strftime('%m/%d/%Y')\nend_date = last_day_previous_month.strftime('%m/%d/%Y')\n\n# Imprimir las fechas\n#logger.info(\"Primer d\u00eda del mes anterior:\", start_date)\n#logger.info(\"\u00daltimo d\u00eda del mes anterior:\", end_date)\n</code></pre> <pre><code>#Fecha_inicial\n#initial_date = '07/01/2017'\n#Fecha_final\n#final_date = '10/01/2017'\n</code></pre> <pre><code>#time.sleep(4)\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. A continuaci\u00f3n, se explica cada parte del c\u00f3digo en detalle:</p> <p>Primero, se define la ruta al ejecutable de ChromeDriver y se establece en la variable de entorno <code>webdriver.chrome.driver</code>. Esto es necesario para que Selenium pueda controlar el navegador Chrome. Luego, se inicializan las variables <code>initial_date</code> y <code>final_date</code> con los valores de <code>start_date</code> y <code>end_date</code>, respectivamente.</p> <p>Se crea una instancia de <code>webdriver.Chrome()</code> para iniciar una sesi\u00f3n de navegador Chrome. No es necesario proporcionar el argumento <code>executable_path</code> ya que la ruta se ha configurado previamente en las variables de entorno. A continuaci\u00f3n, se maximiza la ventana del navegador utilizando el m\u00e9todo <code>maximize_window()</code>.</p> <p>El navegador se dirige a la URL especificada mediante el m\u00e9todo <code>get()</code>. Esta URL parece ser una p\u00e1gina de inicio de sesi\u00f3n de un sistema CRM basado en SAP. Se registra un mensaje informativo indicando el rango de fechas para la descarga utilizando el m\u00e9todo <code>info()</code> del logger.</p> <p>La funci\u00f3n <code>download_file_between_dates()</code> se llama con las fechas inicial y final, as\u00ed como el controlador del navegador. Esta funci\u00f3n se encarga de conectar al sistema C4C, iterar sobre las opciones en un diccionario <code>_dict</code>, y realizar las acciones necesarias para configurar las fechas y descargar el archivo. Se incluye un tiempo de espera para asegurar que la descarga se complete antes de cerrar el navegador.</p> <p>Finalmente, se registra un mensaje informativo indicando que la descarga se ha completado y se cierra la sesi\u00f3n del navegador con <code>driver.quit()</code>. Este script automatiza el proceso de descarga de archivos, lo que puede ser \u00fatil para tareas repetitivas y ahorrar tiempo en la gesti\u00f3n de datos.</p> <pre><code># Replace with the actual path to your ChromeDriver executable\nCHROME_DRIVER_PATH = \"C:\\\\Program Files (x86)\\\\chromedriver.exe\"\nos.environ[\"webdriver.chrome.driver\"] = CHROME_DRIVER_PATH\n\n##Descargar Educacion\ninitial_date = start_date\nfinal_date = end_date\ndriver = webdriver.Chrome()  # No need for executable_path argument\n# Maximizar la ventana del navegador \ndriver.maximize_window()\ndriver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\nlogger.info(f\"Descargando archivo entre {initial_date} y {final_date}\")\ndownload_file_between_dates(initial_date, final_date, driver, _dict)\nlogger.info(f\"Descarga completa entre {initial_date} y {final_date}\")\n\nlogger.info(\"Descargas completadas.\")\n</code></pre> <pre><code>#Descargar Proteccion\n_dict = {\n    \"Ticket_button\" : '//*[@id=\"__button12-img\"]',\n    \"Filter_button\" : '//*[@id=\"findformpaneLkIKPWD61a2ejhlWKfn3Bm_151-img\"]',\n    \"Dates\" : '//*[@id=\"__button51-inner\"]',\n    \"Menu\" :'//*[@id=\"__box4-arrow\"]',\n    \"Entre\" : '//*[@id=\"__item154-content\"]/div/div',\n    \"initial_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_532-datePicker-inner',\n    \"final_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_534-datePicker-inner',\n    \"Aceptar\" : '//*[@id=\"__button77-BDI-content\"]',\n    \"Categoria\" : '//*[@id=\"objectvalueselectorPbJLA_soJqak9j9Ey7mLqvW_346-inputField-vhi\"]',\n    \"Proteccion\" : '//*[@id=\"statictextm9D_2UNbhq6mK7P6aHrdQ0_559-listdefintion_O68bB2vS4gwMYerXwebjm_556-11\"]',\n    \"Go_button\" : '//*[@id=\"findformpaneGLsDRJxMiqEpkW0gKJRoAW_152-goButton-BDI-content\"]',\n    \"Plus_botton\" : '//*[@id=\"actionbuttonmenuCTxPLT0i_qoT0xcR7Kdqnm_131-button-BDI-content\"]',\n    \"Export_button\" : '//*[@id=\"navigationitemQQFWfu3deac0r5R10TiQ10_144-BDI-content\"]',\n    \"Download_button\" : '//*[@id=\"__button97-content\"]' \n}\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde una p\u00e1gina web. Aqu\u00ed est\u00e1 el resumen:</p> <ol> <li>Inicializaci\u00f3n de Fechas: Asigna las fechas de inicio y fin para la descarga.</li> <li>Inicializaci\u00f3n del WebDriver: Inicia el WebDriver de Chrome y maximiza la ventana del navegador.</li> <li>Carga de la URL: Abre la p\u00e1gina web desde la cual se descargar\u00e1 el archivo.</li> <li>Registro de Informaci\u00f3n: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga.</li> <li>Descarga del Archivo: Llama a una funci\u00f3n para descargar el archivo entre las fechas especificadas.</li> <li>C\u00e1lculo del Tiempo: Calcula y registra el tiempo total del proceso ETL.</li> </ol> <pre><code>initial_date = start_date\nfinal_date = end_date\n#driver = webdriver.Chrome()  # Inicializar el WebDriver\ndriver = webdriver.Chrome()  # No need for executable_path argument\n# Maximizar la ventana del navegador \ndriver.maximize_window()\ndriver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\nlogger.info(f\"Descargando archivo entre {initial_date} y {final_date}\")\ndownload_file_between_dates(initial_date, final_date, driver, _dict)\nlogger.info(f\"Descarga completa entre {initial_date} y {final_date}\")\n\n\n\ntiempo_total = time.time() - inicio_etl\nlog_tiempo(logger, f'FINAL ETL --- ', tiempo_total)\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/02.C4C_webscraping_v4_Historico/","title":"3.2. Webscraping Hist\u00f3rico","text":""},{"location":"00.etl/00.etl_02.C4C/02.C4C_webscraping_v4_Historico/#configuracion-del-entorno-para-la-automatizacion-del-proceso-de-scraping","title":"Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping","text":"<p>Este bloque de c\u00f3digo configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</p> <p>Primero, se importan los m\u00f3dulos b\u00e1sicos de Python como <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code> y <code>dateutil.relativedelta</code>, esenciales para la configuraci\u00f3n del entorno. Tambi\u00e9n se agrega al <code>sys.path</code> la ruta de una carpeta superior que contiene el m\u00f3dulo <code>Utils.Funciones</code>. Esto permite organizar el proyecto en m\u00f3dulos reutilizables y facilita la importaci\u00f3n de funciones espec\u00edficas. Entre las funciones importadas destacan <code>setup_logger</code>, para configurar el sistema de logging, <code>log_tiempo</code>, para registrar el tiempo de ejecuci\u00f3n, y <code>download_file_between_dates</code>, para manejar la descarga de archivos.</p> <p>El sistema de logging se configura para registrar eventos clave del proceso. Un logger identificado por el nombre del m\u00f3dulo (<code>__name__</code>) se establece con un nivel de detalle <code>INFO</code>, suficiente para capturar informaci\u00f3n relevante y errores cr\u00edticos. Los mensajes se registran en dos destinos: un archivo llamado <code>scraper.log</code> para el seguimiento a largo plazo y la consola para monitoreo en tiempo real. Ambos manejadores comparten un formato estandarizado que incluye la hora, el nivel de registro y el mensaje, lo que facilita la depuraci\u00f3n y el an\u00e1lisis.</p> <p>Adem\u00e1s, se ignoran advertencias espec\u00edficas para evitar distracciones innecesarias durante la ejecuci\u00f3n del script. Si hay otros loggers configurados, tambi\u00e9n se ajusta su nivel de detalle a <code>INFO</code> para mantener la coherencia en el registro de eventos.</p> <ol> <li>Configuraci\u00f3n del Entorno para la Automatizaci\u00f3n del Proceso de Scraping: Configura el entorno necesario para llevar a cabo un proceso de scraping automatizado utilizando herramientas modulares y un sistema de logging bien estructurado.</li> <li>Importaci\u00f3n de Librer\u00edas: Importa las librer\u00edas necesarias como <code>selenium</code>, <code>logging</code>, <code>os</code>, <code>sys</code>, <code>time</code>, <code>datetime</code>, y <code>dateutil.relativedelta</code>. Tambi\u00e9n se agrega la ruta de la carpeta <code>Funciones</code> al <code>sys.path</code> y se importan funciones espec\u00edficas.</li> <li>Definici\u00f3n de Selectores XPath: Define un diccionario <code>_dict</code> que contiene los selectores XPath necesarios para interactuar con los elementos de la p\u00e1gina web.</li> <li>Inicio del Proceso ETL: Registra el tiempo de inicio y configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n y Formateo de Fechas: Calcula la lista de fechas cada tres meses desde el 06/01/2017 hasta el 06/01/2024 y las formatea en el formato 'mm/dd/yyyy'.</li> <li>Automatizaci\u00f3n de la Descarga de Archivos: Utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. Se inicializa el WebDriver, se abre la URL, y se llama a la funci\u00f3n <code>download_file_between_dates()</code> para realizar la descarga.</li> <li>Registro de Informaci\u00f3n y C\u00e1lculo del Tiempo: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga y calcula el tiempo total del proceso ETL.</li> </ol> <pre><code>## Import libraries\nfrom selenium import webdriver                                          ### selenium version 4.25.0\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\n#from time import datetime\nimport time\nimport datetime\nimport os\nimport logging\nfrom datetime import datetime, timedelta\nfrom dateutil.relativedelta import relativedelta\nimport sys\n\n# Agregar la ruta de la carpeta `Funciones` al sys.path\nsys.path.append(os.path.abspath(\"../\")) \n\nfrom Utils.Funciones import (\n    setup_logger,log_tiempo,download_file_between_dates\n)\n</code></pre> <pre><code>_dict = {\n    \"Ticket_button\" : '//*[@id=\"__button12-img\"]',\n    \"Filter_button\" : '//*[@id=\"findformpaneLkIKPWD61a2ejhlWKfn3Bm_151-img\"]',\n    \"Dates\" : '//*[@id=\"__button51-inner\"]',\n    \"Menu\" :'//*[@id=\"__box4-arrow\"]',\n    \"Entre\" : '//*[@id=\"__item154-content\"]/div/div',\n    \"initial_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_532-datePicker-inner',\n    \"final_date\" : 'inputfieldtjJN2G5do4MoalJz47l3Q0_534-datePicker-inner',\n    \"Aceptar\" : '//*[@id=\"__button77-BDI-content\"]',\n    \"Categoria\" : '//*[@id=\"objectvalueselectorPbJLA_soJqak9j9Ey7mLqvW_346-inputField-vhi\"]',\n    \"Educacion\" : '//*[@id=\"statictextm9D_2UNbhq6mK7P6aHrdQ0_559-listdefintion_O68bB2vS4gwMYerXwebjm_556-9\"]',\n    \"Go_button\" : '//*[@id=\"findformpaneGLsDRJxMiqEpkW0gKJRoAW_152-goButton-BDI-content\"]',\n    \"Plus_botton\" : '//*[@id=\"actionbuttonmenuCTxPLT0i_qoT0xcR7Kdqnm_131-button-BDI-content\"]',\n    \"Export_button\" : '//*[@id=\"navigationitemQQFWfu3deac0r5R10TiQ10_144-BDI-content\"]',\n    \"Download_button\" : '//*[@id=\"__button97-content\"]' \n}\n</code></pre>"},{"location":"00.etl/00.etl_02.C4C/02.C4C_webscraping_v4_Historico/#etl","title":"ETL","text":"<ol> <li>Inicio del Proceso ETL: Registra el tiempo de inicio.</li> <li>Configuraci\u00f3n del Logger: Configura un logger para registrar mensajes en un archivo y en la consola.</li> <li>Obtenci\u00f3n de Fechas: Calcula la lista de fechas cada tres meses desde el 06/01/2017 hasta el 06/01/2024.</li> <li>Formateo de Fechas: Formatea las fechas calculadas en el formato 'mm/dd/yyyy'.</li> <li>Registro de Fechas: (Comentado) Registra las fechas calculadas.</li> </ol> <p>El c\u00f3digo configura un proceso ETL, calcula fechas relevantes y utiliza un logger para monitorear el proceso.</p> <pre><code>inicio_etl = time.time()\n#---------------------------------------------\nlogger = setup_logger(log_filename='scraper.log', log_level=logging.INFO)  # Cambiado a logging.INFO\nlogger.info('COMIENZO ETL')\n\n\n# Fecha de inicio y fecha de fin\nstart_date = datetime.strptime('06/01/2017', '%m/%d/%Y')\nend_date = datetime.strptime('06/01/2024', '%m/%d/%Y')\n\n# Generar la lista de fechas cada tres meses\ndate_list = []\ncurrent_date = start_date\nwhile current_date &lt;= end_date:\n    date_list.append(current_date.strftime('%m/%d/%Y'))\n    current_date += relativedelta(months=3)\n\n# Imprimir la lista de fechas\n#for date in date_list:\n    #print(date)\n#date_list\n</code></pre> <pre><code>#Fecha_inicial\n#initial_date = '07/01/2017'\n#Fecha_final\n#final_date = '10/01/2017'\n</code></pre> <pre><code>#time.sleep(4)\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde un sitio web espec\u00edfico. A continuaci\u00f3n, se explica cada parte del c\u00f3digo en detalle:</p> <p>Primero, se define la ruta al ejecutable de ChromeDriver y se establece en la variable de entorno <code>webdriver.chrome.driver</code>. Esto es necesario para que Selenium pueda controlar el navegador Chrome. Luego, se itera sobre los pares de fechas consecutivas generadas previamente en <code>date_list</code>.</p> <p>Se crea una instancia de <code>webdriver.Chrome()</code> para iniciar una sesi\u00f3n de navegador Chrome. No es necesario proporcionar el argumento <code>executable_path</code> ya que la ruta se ha configurado previamente en las variables de entorno. A continuaci\u00f3n, se maximiza la ventana del navegador utilizando el m\u00e9todo <code>maximize_window()</code>.</p> <p>El navegador se dirige a la URL especificada mediante el m\u00e9todo <code>get()</code>. Esta URL parece ser una p\u00e1gina de inicio de sesi\u00f3n de un sistema CRM basado en SAP. Se imprime un mensaje indicando el rango de fechas para la descarga.</p> <p>La funci\u00f3n <code>download_file_between_dates()</code> se llama con las fechas inicial y final, as\u00ed como el controlador del navegador. Esta funci\u00f3n se encarga de conectar al sistema C4C, iterar sobre las opciones en un diccionario <code>_dict</code>, y realizar las acciones necesarias para configurar las fechas y descargar el archivo.</p> <p>Finalmente, se imprime un mensaje indicando que la descarga se ha completado. Este script automatiza el proceso de descarga de archivos, lo que puede ser \u00fatil para tareas repetitivas y ahorrar tiempo en la gesti\u00f3n de datos.</p> <pre><code># Replace with the actual path to your ChromeDriver executable\nCHROME_DRIVER_PATH = \"C:\\\\Program Files (x86)\\\\chromedriver.exe\"\nos.environ[\"webdriver.chrome.driver\"] = CHROME_DRIVER_PATH\n\n# Iterar sobre los pares de fechas consecutivas y ejecutar la funci\u00f3n\n#for i in range(len(date_list[0:3]) - 1): #---Pruebas\nfor i in range(len(date_list) - 1): #--- Historico Total\n    initial_date = date_list[i]\n    final_date = (datetime.strptime(date_list[i + 1], '%m/%d/%Y') - timedelta(days=1)).strftime('%m/%d/%Y')\n    #driver = webdriver.Chrome()  # Inicializar el WebDriver\n    driver = webdriver.Chrome()  # No need for executable_path argument\n    # Maximizar la ventana del navegador \n    driver.maximize_window()\n    driver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\n    print(f\"Descargando archivo entre {initial_date} y {final_date}\")\n    download_file_between_dates(initial_date, final_date, driver, _dict)\n    print(f\"Descarga completa entre {initial_date} y {final_date}\")\n\nprint(\"Descargas completadas.\")\n</code></pre> <p>El siguiente c\u00f3digo utiliza Selenium WebDriver para automatizar la descarga de archivos desde una p\u00e1gina web. Aqu\u00ed est\u00e1 el resumen:</p> <ol> <li>Inicializaci\u00f3n de Fechas: Asigna las fechas de inicio y fin para la descarga.</li> <li>Inicializaci\u00f3n del WebDriver: Inicia el WebDriver de Chrome y maximiza la ventana del navegador.</li> <li>Carga de la URL: Abre la p\u00e1gina web desde la cual se descargar\u00e1 el archivo.</li> <li>Registro de Informaci\u00f3n: Registra mensajes informativos sobre el inicio y la finalizaci\u00f3n de la descarga.</li> <li>Descarga del Archivo: Llama a una funci\u00f3n para descargar el archivo entre las fechas especificadas.</li> <li>C\u00e1lculo del Tiempo: Calcula y registra el tiempo total del proceso ETL.</li> <li>Protecci\u00f3n de Datos: Utiliza un diccionario actualizado para seleccionar la categor\u00eda de protecci\u00f3n de datos.</li> </ol> <pre><code>initial_date = start_date.strftime('%m/%d/%Y')\nfinal_date = (end_date - timedelta(days=1)).strftime('%m/%d/%Y')\n#driver = webdriver.Chrome()  # Inicializar el WebDriver\ndriver = webdriver.Chrome()  # No need for executable_path argument\n# Maximizar la ventana del navegador \ndriver.maximize_window()\ndriver.get(\"https://my330781.crm.ondemand.com/sap/ap/ui/clogin?saml2=disabled&amp;app.component=/SAP_UI_CT/Main/root.uiccwoc&amp;rootWindow=X&amp;redirectUrl=/sap/public/byd/runtime\")\nprint(f\"Descargando archivo entre {initial_date} y {final_date}\")\ndownload_file_between_dates(initial_date, final_date, driver,_dict)\nprint(f\"Descarga completa entre {initial_date} y {final_date}\")\n\ntiempo_total = time.time() - inicio_etl\nlog_tiempo(logger, f'FINAL ETL --- ', tiempo_total)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/","title":"Funciones.py","text":"<p>Este archivo contiene una serie de funciones automatizadas desarrolladas para gestionar tareas comunes en la manipulaci\u00f3n de datos y la interacci\u00f3n con sistemas externos. Las funciones descritas est\u00e1n dise\u00f1adas principalmente para automatizar procesos en plataformas como SharePoint y sistemas como C4C, as\u00ed como para facilitar el procesamiento de datos utilizando herramientas como Selenium, pandas y xlwings.</p> <p>Las funciones cubren una variedad de tareas, incluyendo:</p> <ol> <li> <p>Autenticaci\u00f3n y acceso a plataformas externas:</p> <ul> <li>Funciones que automatizan el proceso de inicio de sesi\u00f3n y la autenticaci\u00f3n en plataformas como C4C y SharePoint.</li> </ul> </li> <li> <p>Interacci\u00f3n con men\u00fas desplegables y formularios web:</p> <ul> <li>Herramientas para manejar men\u00fas desplegables personalizados y formularios en p\u00e1ginas web, facilitando la automatizaci\u00f3n de interacciones con elementos HTML mediante Selenium.</li> </ul> </li> <li> <p>Descarga y procesamiento de datos:</p> <ul> <li>Funciones que permiten la descarga de archivos desde plataformas externas basadas en fechas, as\u00ed como la transformaci\u00f3n y organizaci\u00f3n de los datos descargados en un formato adecuado para an\u00e1lisis.</li> </ul> </li> <li> <p>Manejo de archivos y directorios:</p> <ul> <li>Funciones que facilitan la gesti\u00f3n de archivos en el sistema de archivos local y en plataformas como SharePoint, incluyendo el renombrado, carga y descarga de archivos.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n de datos:</p> <ul> <li>Funciones espec\u00edficas para preprocesar, normalizar y limpiar los datos antes de ser utilizados o almacenados, asegurando que la informaci\u00f3n est\u00e9 en el formato adecuado para su posterior an\u00e1lisis.</li> </ul> </li> </ol> <p>Este conjunto de herramientas es esencial para mejorar la eficiencia en tareas repetitivas, reduciendo la necesidad de intervenci\u00f3n manual y permitiendo una integraci\u00f3n m\u00e1s fluida entre los sistemas externos y el entorno de trabajo. La automatizaci\u00f3n de estos procesos optimiza el flujo de trabajo y facilita la administraci\u00f3n y procesamiento de grandes vol\u00famenes de datos.</p>"},{"location":"00.etl/Utils/Funciones/#configuracion-e-import-de-librerias","title":"Configuracion e import de Librerias","text":"<p>Este bloque de c\u00f3digo configura el entorno de trabajo importando todas las librer\u00edas necesarias para manipulaci\u00f3n de datos, automatizaci\u00f3n de Excel, autenticaci\u00f3n y automatizaci\u00f3n de navegadores web. <code>Funciones.py</code> importa varias librer\u00edas est\u00e1ndar y externas necesarias para el funcionamiento del script. </p>"},{"location":"00.etl/Utils/Funciones/#librerias-estandar","title":"Librer\u00edas est\u00e1ndar","text":"<ul> <li><code>calendar</code>: Funciones de calendario.</li> <li><code>configparser</code>: Manejo de archivos de configuraci\u00f3n.</li> <li><code>hashlib</code>: Funciones hash seguras.</li> <li><code>json</code>: Trabajo con datos JSON.</li> <li><code>logging</code>: Registro de mensajes.</li> <li><code>os</code>: Interacci\u00f3n con el sistema operativo.</li> <li><code>re</code>: Expresiones regulares.</li> <li><code>time</code>: Funciones relacionadas con el tiempo.</li> <li><code>unicodedata</code>: Manipulaci\u00f3n de datos Unicode.</li> <li><code>datetime</code>: Manejo de fechas y horas.</li> <li><code>timedelta</code>: Diferencia entre fechas o tiempos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#librerias-externas","title":"Librer\u00edas externas","text":"<ul> <li><code>numpy (np)</code>: Computaci\u00f3n num\u00e9rica.</li> <li><code>pandas (pd)</code>: Manipulaci\u00f3n y an\u00e1lisis de datos.</li> <li><code>requests</code>: Solicitudes HTTP.</li> <li><code>xlwings (xw)</code>: Automatizaci\u00f3n de Excel.</li> <li><code>msal</code>: Autenticaci\u00f3n de Microsoft.</li> <li><code>openpyxl</code>: Lectura y escritura de archivos de Excel.</li> <li><code>selenium</code>: Automatizaci\u00f3n de navegadores web.</li> </ul> <p>Dentro de <code>selenium</code>, se importan excepciones y m\u00f3dulos espec\u00edficos para manejar errores y realizar acciones complejas en el navegador.</p> <pre><code># pylint: disable=all\n# Librer\u00edas est\u00e1ndar\nimport calendar\nimport configparser\nimport hashlib\nimport json\nimport logging\nimport os\nimport re\nimport time\nimport unicodedata\nfrom datetime import datetime, timedelta\n\n# Librer\u00edas externas\nimport numpy as np\nimport pandas as pd\nimport requests\nimport xlwings as xw\nfrom msal import ConfidentialClientApplication\nfrom openpyxl import load_workbook\nfrom selenium import webdriver\nfrom selenium.common.exceptions import (\n    ElementNotInteractableException, NoSuchElementException, StaleElementReferenceException, \n    TimeoutException, WebDriverException\n)\nfrom selenium.webdriver.common.action_chains import ActionChains\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.support.ui import Select, WebDriverWait\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#autenticacion-y-configuracion-sharepoint","title":"Autenticacion y Configuracion Sharepoint","text":"<p>Este c\u00f3digo realiza varias tareas relacionadas con la autenticaci\u00f3n y configuraci\u00f3n para procesar archivos en SharePoint. A continuaci\u00f3n, se detalla cada parte del c\u00f3digo:</p> <ol> <li> <p>Inicializaci\u00f3n de Variables:</p> <ul> <li><code>csv_files</code>: Lista de archivos CSV a procesar.</li> <li><code>original_dir</code>: Guarda el directorio de trabajo actual.</li> </ul> </li> <li> <p>Cambio de Directorio:</p> <ul> <li>Guarda el directorio de trabajo actual y cambia al directorio del script.</li> </ul> </li> <li> <p>Lectura de Credenciales:</p> <ul> <li>Lee las credenciales desde un archivo <code>credenciales.env</code>.</li> <li>Procesa las claves y las almacena en un diccionario <code>keys</code>.</li> </ul> </li> <li> <p>Configuraci\u00f3n de MSAL:</p> <ul> <li>Configura la autenticaci\u00f3n usando <code>msal</code> con las credenciales le\u00eddas.</li> <li>Lee la clave privada desde un archivo <code>key.pem</code>.</li> <li>Configura la aplicaci\u00f3n <code>msal</code> con el <code>client_id</code>, <code>authority</code> y <code>client_credential</code>.</li> <li>Adquiere un token de acceso para SharePoint Online.</li> <li>Configura los encabezados de autorizaci\u00f3n para las solicitudes HTTP.</li> </ul> </li> <li> <p>Lectura de Configuraci\u00f3n Adicional:</p> <ul> <li>Lee m\u00e1s credenciales desde un archivo <code>scraping.env</code>.</li> <li>Almacena las credenciales en variables para diferentes servicios.</li> </ul> </li> <li> <p>Restauraci\u00f3n del Directorio Original:</p> <ul> <li>Restaura el directorio de trabajo original.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#resumen","title":"Resumen","text":"<p>Este c\u00f3digo realiza las siguientes tareas:</p> <ol> <li>Guarda y cambia el directorio de trabajo.</li> <li>Lee credenciales desde archivos de configuraci\u00f3n.</li> <li>Configura la autenticaci\u00f3n con MSAL para acceder a SharePoint.</li> <li>Lee configuraciones adicionales para otros servicios.</li> <li>Restaura el directorio de trabajo original.</li> </ol> <p>Este proceso es esencial para asegurar que las credenciales y configuraciones necesarias est\u00e9n disponibles y seguras para el procesamiento de archivos en SharePoint y otros servicios relacionados.</p> <pre><code>#Determina si un archivo es un archivo de Excel o csv para los procesados en Sharepoint\n#csv_files = [\"cede_Listado_Matriculas\",\"emp_Listado_Matriculas\"]\ncsv_files = []\n\n# Guardar el directorio de trabajo actual\noriginal_dir = os.getcwd()\ntry:\n    # Cambiar el directorio de trabajo al directorio del script\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    os.chdir(script_dir)\n\n    # Leer la clave privada desde el archivo key.pem\n    with open('credenciales.env', 'r') as key_file:\n        lines = key_file.readlines()\n\n    # Procesar las claves\n    keys = {}\n    for line in lines:\n        key, value = line.strip().split(\" = \")\n        keys[key] = value.strip('\"')\n\n    client_id = keys.get(\"client_id\")\n    cert_thumbprint = keys.get(\"cert_thumbprint\")\n    tenant_id = keys.get(\"tenant_id\")\n\n    authority = f\"https://login.microsoftonline.com/{tenant_id}\"\n\n    # Leer la clave privada desde el archivo key.pem\n    with open('key.pem', 'r') as key_file:\n        private_key = key_file.read()\n\n    cert = {\n        \"private_key\": private_key,\n        \"thumbprint\": cert_thumbprint,\n    }\n\n    msal_app = ConfidentialClientApplication(\n        client_id=client_id,\n        authority=authority,\n        client_credential=cert,\n    )\n\n    scopes_sharepoint_online = [keys.get(\"scopes_sharepoint_online\")]\n\n    results = msal_app.acquire_token_for_client(scopes_sharepoint_online)\n\n    if \"access_token\" in results:\n        access_token = results.get(\"access_token\")\n\n    headers = {\n        \"Authorization\": f\"Bearer {access_token}\",\n        \"Accept\": \"application/json;odata=verbose\",\n        \"Content-Type\": \"application/json\",\n    }\n\n    sharepoint_base_url = keys.get(\"sharepoint_base_url\")\n\n\n\n    # Leer las credenciales desde el archivo credenciales.env\n    config = configparser.ConfigParser(interpolation=None)\n    config.read('scraping.env')\n\n    # Almacenar las credenciales en variables\n    desarrollo_empresarial_url = config['desarrollo_empresarial']['url'].strip('\"')\n    desarrollo_empresarial_username = config['desarrollo_empresarial']['username'].strip('\"')\n    desarrollo_empresarial_password = config['desarrollo_empresarial']['password'].strip('\"')\n\n    cedesarrollo_url = config['cedesarrollo']['url'].strip('\"')\n    cedesarrollo_username = config['cedesarrollo']['username'].strip('\"')\n    cedesarrollo_password = config['cedesarrollo']['password'].strip('\"')\n\n    C4C_username = config['C4C']['username'].strip('\"')\n    C4C_password = config['C4C']['password'].strip('\"')\nfinally:\n    # Restaurar el directorio de trabajo original\n    os.chdir(original_dir)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-credenciales","title":"Funci\u00f3n <code>credenciales</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito","title":"Prop\u00f3sito","text":"<p>La funci\u00f3n <code>credenciales</code> se utiliza para recuperar las credenciales almacenadas en un archivo de configuraci\u00f3n (<code>scraping.env</code>) seg\u00fan la plataforma especificada. Las credenciales se procesan eliminando cualquier comilla circundante en los valores.</p>"},{"location":"00.etl/Utils/Funciones/#entradas","title":"Entradas","text":"<ul> <li><code>plataforma</code> (str): El nombre de la plataforma para la cual se necesitan las credenciales. Las opciones v\u00e1lidas son:</li> <li><code>\"desarrollo_empresarial\"</code></li> <li><code>\"cedesarrollo\"</code></li> <li><code>\"C4C\"</code></li> </ul>"},{"location":"00.etl/Utils/Funciones/#salidas","title":"Salidas","text":"<p>Dependiendo de la plataforma solicitada:</p> <ul> <li><code>desarrollo_empresarial</code>:<ul> <li>URL</li> <li>Nombre de usuario</li> <li>Contrase\u00f1a</li> </ul> </li> <li><code>cedesarrollo</code>:<ul> <li>URL</li> <li>Nombre de usuario</li> <li>Contrase\u00f1a</li> </ul> </li> <li><code>C4C</code>:<ul> <li>Nombre de usuario</li> <li>Contrase\u00f1a</li> </ul> </li> </ul>"},{"location":"00.etl/Utils/Funciones/#detalles-de-implementacion","title":"Detalles de implementaci\u00f3n","text":"<ol> <li> <p>Cambio temporal del directorio:</p> <ul> <li>Guarda el directorio actual (<code>os.getcwd</code>) y cambia al directorio donde se encuentra el archivo de script (<code>__file__</code>). Esto asegura que <code>scraping.env</code> sea accesible incluso si el script se ejecuta desde un directorio diferente.</li> </ul> </li> <li> <p>Lectura del archivo de configuraci\u00f3n:</p> <ul> <li>Utiliza <code>configparser.ConfigParser</code> con <code>interpolation=None</code> para cargar los valores directamente sin interpolaci\u00f3n.</li> </ul> </li> <li> <p>Eliminaci\u00f3n de comillas:</p> <ul> <li>Se usa la funci\u00f3n <code>remove_quotes</code> para eliminar comillas simples y dobles de los valores cargados.</li> </ul> </li> <li> <p>Restauraci\u00f3n del directorio original:</p> <ul> <li>Una vez procesadas las credenciales, se restaura el directorio original, garantizando que no haya efectos secundarios en otros procesos que utilicen el directorio de trabajo actual.</li> </ul> </li> </ol> <pre><code># Funci\u00f3n para eliminar las comillas del valor\ndef remove_quotes(value):\n    return value.strip('\"').strip(\"'\")\n\ndef credenciales(plataforma):\n    # Guardar el directorio de trabajo actual\n    original_dir = os.getcwd()\n    try:\n        # Cambiar el directorio de trabajo al directorio del script\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        os.chdir(script_dir)\n        # Leer las credenciales desde el archivo scraping.env\n        config = configparser.ConfigParser(interpolation=None)\n        config.read('scraping.env')\n        # Almacenar las credenciales en variables\n        if plataforma == \"desarrollo_empresarial\":\n            desarrollo_empresarial_url = remove_quotes(config['desarrollo_empresarial']['url'])\n            desarrollo_empresarial_username = remove_quotes(config['desarrollo_empresarial']['username'])\n            desarrollo_empresarial_password = remove_quotes(config['desarrollo_empresarial']['password'])\n            return desarrollo_empresarial_url, desarrollo_empresarial_username, desarrollo_empresarial_password\n        elif plataforma == \"cedesarrollo\":\n            cedesarrollo_url = remove_quotes(config['cedesarrollo']['url'])\n            cedesarrollo_username = remove_quotes(config['cedesarrollo']['username'])\n            cedesarrollo_password = remove_quotes(config['cedesarrollo']['password'])\n            return cedesarrollo_url, cedesarrollo_username, cedesarrollo_password\n        elif plataforma == \"C4C\":\n            C4C_username = remove_quotes(config['C4C']['username'])\n            C4C_password = remove_quotes(config['C4C']['password'])\n            return C4C_username, C4C_password\n\n    finally:\n        # Restaurar el directorio de trabajo original\n        os.chdir(original_dir)\n</code></pre> <p><code>generar_periodos</code> crea un conjunto de a\u00f1os desde el a\u00f1o inicial (<code>inicio</code>) hasta el a\u00f1o final (<code>fin</code>), incluyendo ambos extremos. Devuelve un conjunto de enteros \u00fanicos representando los a\u00f1os en el rango especificado.</p> <pre><code>def generar_periodos(inicio, fin):\n    return {year for year in range(inicio, fin + 1)}\n</code></pre> <p><code>dias_del_mes</code> devuelve el n\u00famero de d\u00edas de un mes espec\u00edfico en un a\u00f1o determinado, teniendo en cuenta si el a\u00f1o es bisiesto.</p> <pre><code>def dias_del_mes(mes, anio):\n    \"\"\"Devuelve el n\u00famero de d\u00edas en un mes dado, considerando a\u00f1os bisiestos.\"\"\"\n    return calendar.monthrange(anio, mes)[1]\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-setup_logger","title":"Funci\u00f3n <code>setup_logger</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_1","title":"Prop\u00f3sito","text":"<p>Configura un logger para manejar y formatear mensajes de registro, permitiendo guardar los logs en un archivo y mostrarlos en la consola.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_1","title":"Entradas","text":"<ul> <li><code>log_filename</code> (str): Nombre del archivo donde se almacenar\u00e1n los logs (por defecto, <code>scraper.log</code>).</li> <li><code>log_level</code> (nivel de log): Nivel de severidad de los mensajes registrados (por defecto, <code>logging.DEBUG</code>).</li> <li><code>log_format</code> (str): Formato de los mensajes de log (por defecto, <code>'%(asctime)s - %(levelname)s - %(message)s'</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#salida","title":"Salida","text":"<ul> <li><code>logger</code> (logging.Logger): Objeto configurado para registrar mensajes con los manejadores y formato especificados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#detalles","title":"Detalles","text":"<ol> <li>Configura un logger con el nivel deseado.</li> <li>Define manejadores para archivo y consola.</li> <li>Establece un formato uniforme para los logs.</li> <li>Elimina manejadores existentes en caso de configuraci\u00f3n previa, evitando duplicados.</li> <li>Retorna el logger configurado.</li> </ol> <pre><code>def setup_logger(log_filename='scraper.log', log_level=logging.DEBUG, log_format='%(asctime)s - %(levelname)s - %(message)s'):\n    # Crea un logger con el nivel especificado\n    logger = logging.getLogger()\n    logger.setLevel(log_level)\n\n    # Crea un manejador para el archivo de log\n    file_handler = logging.FileHandler(log_filename)\n    file_handler.setLevel(log_level)\n\n    # Crea un manejador para la consola\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(log_level)\n\n    # Crea un formato para los logs\n    formatter = logging.Formatter(log_format)\n    file_handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n\n    # Si el logger ya tiene manejadores, eliminar todos para evitar duplicados\n    if logger.hasHandlers():\n        logger.handlers.clear()\n\n    # A\u00f1adir los manejadores al logger\n    logger.addHandler(file_handler)\n    logger.addHandler(console_handler)\n\n    return logger\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-log_step_decorator","title":"Funci\u00f3n <code>log_step_decorator</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_2","title":"Prop\u00f3sito","text":"<p>Decora una funci\u00f3n para registrar informaci\u00f3n sobre su ejecuci\u00f3n, incluyendo inicio, finalizaci\u00f3n exitosa o errores, as\u00ed como la duraci\u00f3n del proceso.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_2","title":"Entradas","text":"<ul> <li><code>step_name</code> (str): Nombre descriptivo del paso que se est\u00e1 decorando, utilizado para identificar los registros.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento","title":"Funcionamiento","text":"<ul> <li>Inicio: Registra un mensaje indicando el inicio del paso.</li> <li>Finalizaci\u00f3n exitosa:<ul> <li>Calcula y registra la duraci\u00f3n del paso en segundos o minutos.</li> </ul> </li> <li>Error:<ul> <li>Registra un mensaje de error con la duraci\u00f3n transcurrida y el detalle de la excepci\u00f3n.</li> </ul> </li> <li>Formato: Los mensajes se registran con colores en consola (<code>\\033[92m</code> para \u00e9xito y <code>\\033[91m</code> para errores).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#salida_1","title":"Salida","text":"<ul> <li>Devuelve un decorador que envuelve la funci\u00f3n original, a\u00f1adiendo la funcionalidad de registro.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#detalles-adicionales","title":"Detalles adicionales","text":"<ul> <li>Utiliza un logger configurado previamente para registrar los eventos.</li> <li>Maneja tanto procesos exitosos como excepciones, asegurando que los logs sean informativos.</li> </ul> <pre><code>logger = setup_logger(\"scraper.log\")\ndef log_step_decorator(step_name):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            start_time = time.time()\n            logger.info(f\"\\033[92mIniciando: {step_name}\\033[0m\")\n            try:\n                result = func(*args, **kwargs)\n                duration = time.time() - start_time\n                if duration &gt;= 60:\n                    duration_minutes = duration / 60\n                    logger.info(f\"\"\"\\033[92mProceso '{step_name}' \n                                completado exitosamente en {duration_minutes:.2f} minutos.\\033[0m\"\"\")\n                else:\n                    logger.info(f\"\"\"\\033[92mProceso '{step_name}' \n                                completado exitosamente en {duration:.2f} segundos.\\033[0m\"\"\")\n                return result\n            except Exception as e:\n                duration = time.time() - start_time\n                if duration &gt;= 60:\n                    duration_minutes = duration / 60\n                    logger.error(f\"\\033[91mError en el paso '{step_name}' despu\u00e9s de {duration_minutes:.2f} minutos: {e}\\033[0m\")\n                else:\n                    logger.error(f\"\\033[91mError en el paso '{step_name}' despu\u00e9s de {duration:.2f} segundos: {e}\\033[0m\")\n                raise\n        return wrapper\n    return decorator\n</code></pre> <p><code>log_tiempo</code> registra un mensaje en el logger indicando el tiempo transcurrido, mostrando minutos si supera los 60 segundos. Toma tres par\u00e1metros: <code>logger</code> para manejar el registro, <code>message</code> como texto base y <code>tiempo_transcurrido</code> como duraci\u00f3n en segundos.</p> <pre><code>def log_tiempo(logger, message, tiempo_transcurrido):\n    \"\"\"\n    Funci\u00f3n para registrar tiempo en el logger, mostrando en minutos si es mayor a 60 segundos.\n    Par\u00e1metros:\n     - logger: instancia del logger\n     - message: mensaje base a mostrar\n     - tiempo_transcurrido: tiempo transcurrido en segundos\n    \"\"\"\n    if tiempo_transcurrido &gt;= 60:\n        tiempo_minutos = tiempo_transcurrido / 60\n        logger.info(f'{message} --- {tiempo_minutos:.2f} minutes ---')\n    else:\n        logger.info(f'{message} --- {tiempo_transcurrido:.2f} seconds ---')\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-process_files_from_folder","title":"Funci\u00f3n <code>process_files_from_folder</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_3","title":"Prop\u00f3sito","text":"<p>Procesa archivos de una carpeta de SharePoint que han sido modificados en los \u00faltimos seis meses, almacenando los datos en una lista de DataFrames.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_3","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL de la carpeta en SharePoint desde donde se obtendr\u00e1n los archivos.</li> <li><code>dfs</code> (list): Lista utilizada para almacenar los DataFrames procesados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_1","title":"Funcionamiento","text":"<ol> <li>Listar archivos: Obtiene la lista de archivos en la carpeta de SharePoint.</li> <li>Filtrar por fecha: Identifica archivos modificados en los \u00faltimos seis meses.</li> <li>Procesar archivos:<ul> <li>Recupera el contenido de los archivos seleccionados desde SharePoint.</li> <li>Lee el contenido de los archivos como DataFrames utilizando <code>pandas</code>.</li> <li>Registra informaci\u00f3n sobre el contenido y lo almacena en la lista <code>dfs</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_2","title":"Salida","text":"<ul> <li>No retorna ning\u00fan valor. Modifica la lista <code>dfs</code> proporcionada al agregar los DataFrames procesados.</li> </ul> <pre><code>@log_step_decorator(\"Procesar archivos de una carpeta de SharePoint\")\ndef process_files_from_folder(folder_url, dfs):\n    \"\"\"\n    Procesa los archivos en una carpeta de SharePoint que han sido modificados en los \u00faltimos seis meses.\n\n    Args:\n        folder_url (str): La URL de la carpeta en SharePoint.\n        dfs (list): Una lista para almacenar los DataFrames procesados.\n\n    Returns:\n        None\n    \"\"\"\n    files = list_files_from_sharepoint(folder_url)\n    six_months_ago = datetime.now() - timedelta(days=180)\n\n    for file in files:\n        file_name = file['Name']\n        file_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n        modified_date_str = file['TimeLastModified']\n        modified_date = datetime.strptime(modified_date_str, '%Y-%m-%dT%H:%M:%SZ')\n\n        if modified_date &gt;= six_months_ago:\n            # Obtener el archivo de SharePoint\n            file_content = get_file_from_sharepoint(file_url)\n\n            if file_content:\n                # Leer el archivo Excel sin descargar\n                df = pd.read_excel(file_content)\n                logger.info(\"Contenido de {}:\\n{}\".format(file_name, df.head()))\n                dfs.append(df)\n</code></pre> <p><code>list_files_from_sharepoint</code> obtiene una lista de archivos presentes en una carpeta de SharePoint indicada por la URL proporcionada. Recibe como entrada <code>folder_url</code> (str), que especifica la ubicaci\u00f3n de la carpeta, y devuelve una lista de archivos si la solicitud es exitosa o una lista vac\u00eda en caso de fallo. Tambi\u00e9n registra advertencias en caso de errores durante la solicitud.</p> <pre><code>@log_step_decorator(\"Listar archivos de SharePoint\")\ndef list_files_from_sharepoint(folder_url):\n    \"\"\"\n    Lista los archivos en una carpeta de SharePoint.\n\n    Args:\n        folder_url (str): La URL de la carpeta en SharePoint.\n\n    Returns:\n        list: Una lista de archivos en la carpeta si la solicitud es exitosa.\n        list: Una lista vac\u00eda si la solicitud falla.\n    \"\"\"\n    list_files_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n    response = requests.get(list_files_url, headers=headers)\n\n    if response.status_code == 200:\n        files = response.json()['d']['results']\n        return files\n    else:\n        logger.warning(f\"Error al listar los archivos. C\u00f3digo de estado: {response.status_code}\")\n        return []\n</code></pre> <p><code>get_file_from_sharepoint</code> descarga un archivo desde SharePoint utilizando su URL. Recibe como entrada <code>file_url</code> (str), que especifica la ubicaci\u00f3n del archivo, y devuelve el contenido del archivo como bytes si la solicitud es exitosa. En caso de error, retorna <code>None</code> y registra una advertencia con el c\u00f3digo de estado de la respuesta.</p> <pre><code>@log_step_decorator(\"Obtener archivo de SharePoint\")\ndef get_file_from_sharepoint(file_url):\n    \"\"\"\n    Descarga un archivo desde SharePoint dado su URL.\n\n    Args:\n        file_url (str): La URL del archivo en SharePoint.\n\n    Returns:\n        bytes: El contenido del archivo si la solicitud es exitosa.\n        None: Si la solicitud falla.\n    \"\"\"\n    response = requests.get(file_url, headers=headers)\n    logger.info(f\"Response Status Code: {response.status_code}\")\n\n    if response.status_code == 200:\n        return response.content\n    else:\n        logger.warning(f\"Error al acceder al archivo. C\u00f3digo de estado: {response.status_code}\")\n        return None\n</code></pre> <p><code>_extract_date</code> convierte una fecha extra\u00edda de un nombre de archivo en un objeto <code>datetime.date</code>. Recibe como entrada <code>file_name</code> (str), que contiene la fecha incrustada, y <code>date_pattern</code>, un patr\u00f3n de expresi\u00f3n regular para buscar la fecha. Si encuentra coincidencias, devuelve un objeto <code>datetime.date</code>; de lo contrario, retorna <code>None</code>.</p> <pre><code># Funci\u00f3n para convertir la fecha extra\u00edda en un objeto datetime\ndef _extract_date(file_name,date_pattern):\n    match = date_pattern.search(file_name)\n    if match:\n        day, month, year = map(int, match.groups())\n        return datetime.date(year, month, day)\n    return None\n</code></pre> <p><code>obtener_sharepoint</code> limpia una carpeta local especificada y descarga todos los archivos desde una carpeta de SharePoint hacia esa ubicaci\u00f3n. Recibe como entradas <code>folder_url</code> (str), que indica la URL de la carpeta de SharePoint, y <code>_folder</code> (str), la ruta de la carpeta local donde se guardar\u00e1n los archivos.</p> <pre><code>def obtener_sharepoint(folder_url,_folder):\n    limpiar_carpeta(_folder)\n    download_all_files_from_sharepoint(folder_url, _folder)\n</code></pre> <p>Funci\u00f3n <code>extract_date</code> para convertir la fecha extra\u00edda en un objeto datetime</p> <pre><code>def extract_date(file_name, date_pattern):\n    match = date_pattern.search(file_name)\n    if match:\n        day, month, year = map(int, match.groups())\n        return datetime(year, month, day)  # Usar datetime en lugar de date\n    return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-upload_file_to_sharepoint","title":"Funci\u00f3n <code>upload_file_to_sharepoint</code>","text":"<p>Sube un archivo local a una carpeta de SharePoint especificada. Recibe como entradas:</p> <ul> <li><code>file_path</code> (str): Ruta local del archivo que se desea subir.</li> <li><code>folder_url</code> (str): URL de la carpeta de destino en SharePoint.</li> </ul> <p>Funcionamiento: 1. Validaci\u00f3n de existencia: Verifica que el archivo local exista. 2. Lectura del archivo: Abre el archivo en modo binario y lee su contenido. 3. Preparaci\u00f3n de la URL: Construye la URL para la subida en SharePoint. 4. Encabezados: Configura el encabezado <code>Content-Length</code> con el tama\u00f1o del archivo. 5. Subida: Realiza una solicitud POST para subir el archivo a SharePoint. 6. Logs:     - Registra un mensaje de \u00e9xito si el archivo se sube correctamente (excepto si es un archivo codificado con nombre MD5).     - Registra un error si la subida falla, indicando el c\u00f3digo de estado.</p> <p>Salidas: - No retorna ning\u00fan valor; realiza acciones y registra logs seg\u00fan el resultado.</p> <pre><code>def upload_file_to_sharepoint(file_path, folder_url):\n    if not os.path.exists(file_path):\n        # logging.error(f\"Archivo no encontrado: {file_path}. No se puede subir a SharePoint.\")\n        return\n\n    with open(file_path, \"rb\") as file:\n        file_content = file.read()\n\n    file_name = os.path.basename(file_path)\n    upload_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files/add(url='{file_name}',overwrite=true)\"\n\n    headers['Content-Length'] = str(len(file_content))  # A\u00f1adir encabezado para la longitud del contenido\n\n    response = requests.post(url=upload_url, headers=headers, data=file_content)\n\n    if response.status_code == 200:\n        if re.match(r'^[a-f0-9]{32}\\.xlsx$', file_name):\n            # Archivo codificado, no hacer logging\n            pass\n        else:\n            logging.info(f\"Archivo {file_name} subido exitosamente a SharePoint.\")\n    else:\n        logging.error(f\"Error al subir el archivo {file_name}. C\u00f3digo de estado: {response.status_code}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-actualizar_sharepoint_procesado","title":"Funci\u00f3n <code>actualizar_sharepoint_procesado</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_4","title":"Prop\u00f3sito","text":"<p>Sube un archivo procesado (en formato Excel o CSV) a una carpeta espec\u00edfica en SharePoint, determinada por un identificador ETL. El archivo se genera a partir de un DataFrame proporcionado.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_4","title":"Entradas","text":"<ul> <li><code>df</code> (pandas.DataFrame): Datos procesados que se guardar\u00e1n y subir\u00e1n como archivo.</li> <li><code>etl</code> (str): Identificador del tipo de proceso ETL, utilizado para determinar la carpeta de destino en SharePoint.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_2","title":"Funcionamiento","text":"<ol> <li>Mapeo de ETL a carpeta: Determina la URL de destino en SharePoint seg\u00fan el identificador <code>etl</code> usando el diccionario <code>etl_to_folder_url</code>.</li> <li>Generaci\u00f3n de archivo temporal:<ul> <li>Crea un archivo Excel (<code>.xlsx</code>) o CSV (<code>.csv</code>) a partir del DataFrame.</li> <li>El formato depende de si <code>etl</code> est\u00e1 presente en <code>csv_files</code>.</li> <li>El archivo incluye un timestamp en el nombre para garantizar unicidad.</li> </ul> </li> <li>Subida a SharePoint: Llama a <code>upload_file_to_sharepoint</code> para subir el archivo temporal a la URL correspondiente.</li> <li>Manejo de errores: Si ocurre un error durante la subida, registra un mensaje de error.</li> <li>Limpieza: Elimina el archivo temporal despu\u00e9s de subirlo, asegurando que no queden residuos en el sistema local.</li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_3","title":"Salida","text":"<ul> <li>No retorna valores. Realiza acciones y muestra mensajes en consola para registrar el \u00e9xito o errores durante el proceso.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#excepciones","title":"Excepciones","text":"<ul> <li>Maneja excepciones relacionadas con la subida a SharePoint e informa del error en consola. Limpia siempre los archivos temporales, incluso si ocurre un error.</li> </ul> <pre><code>def actualizar_sharepoint_procesado(df,etl):   \n\n    etl_to_folder_url = {\n        \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/01.Docentes',\n        \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/02.Disenio_Curricular',\n        \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/03.Listado_Matriculas',\n        \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/04.Ingresos',\n        \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/05.Historico_Notas',\n        \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/06.Egresados_Graduados',\n        \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/Procesados/07.Cancelados_Desertores',\n        \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/01.Docentes',\n        \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/02.Preinscritos',\n        \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/03.Listado_Matriculas',\n        \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/04.Consolidado_inasistencias',\n        \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/05.Estudiantes_cancelados_por_inasistencias',\n        \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/Procesados/06.Egresados_Graduados'    \n        }\n    # \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados'\n    folder_url = etl_to_folder_url.get(etl, \"URL por defecto si no se encuentra el valor de etl\")\n    # Guardar en un archivo Excel temporal del df recibido\n    hoy = datetime.now().strftime(\"%d_%m_%Y_%H_%M\")\n\n    #si etl no esta en csv_files\n    if etl not in csv_files:\n        archivo_temporal = f\"procesado_{etl}_{hoy}.xlsx\"\n        df.to_excel(archivo_temporal, index=False)\n    else:\n        archivo_temporal = f\"procesado_{etl}_{hoy}.csv\"\n        #utf-8-sig para evitar problemas con caracteres especiales\n        df.to_csv(archivo_temporal, index=False, encoding='utf-8-sig')\n    try:\n        upload_file_to_sharepoint(file_path=archivo_temporal, folder_url=folder_url)\n        print(f\"Archivo subido a SharePoint: {archivo_temporal}, folder_url: {folder_url}\")\n    except Exception as e:\n        print(f\"Error al subir el archivo {archivo_temporal} a SharePoint: {e}\")\n    finally:\n        # cerrar el archivo temporal\n        # Eliminar el archivo original despu\u00e9s de procesarlo\n        time.sleep(0.5)  # Pausa de 500ms\n        os.remove(archivo_temporal)\n        print(f\"Archivo original eliminado: {archivo_temporal}\")\n</code></pre> <p><code>actualizar_columna_programa</code> actualiza una columna de destino en un DataFrame bas\u00e1ndose en condiciones de otra columna. Si la columna condicional no es nula y contiene un texto espec\u00edfico (si se proporciona), el valor de una columna origen se copia a la columna destino. Posteriormente, los valores nulos en la columna destino se rellenan usando el m\u00e9todo forward fill. Devuelve el DataFrame actualizado.</p> <pre><code>def actualizar_columna_programa(df, columna_condicional, columna_origen, columna_destino, texto_filtro=None):\n    \"\"\"\n    Actualiza una columna destino en un DataFrame en base a una condici\u00f3n de otra columna.\n    Si el valor en columna_condicional no es nulo y contiene un texto espec\u00edfico (opcional),\n    se copia el valor de columna_origen a columna_destino.\n    Luego, los valores nulos en columna_destino se rellenan usando el m\u00e9todo forward fill.\n\n    :param df: DataFrame a procesar.\n    :param columna_condicional: Nombre de la columna para evaluar la condici\u00f3n.\n    :param columna_origen: Nombre de la columna de donde copiar el valor.\n    :param columna_destino: Nombre de la columna destino que ser\u00e1 actualizada.\n    :param texto_filtro: Texto que debe estar presente en la columna_condicional (opcional).\n    :return: DataFrame actualizado.\n    \"\"\"\n    df[columna_destino] = df.apply(\n        lambda row: row[columna_origen]\n        if pd.notnull(row[columna_condicional]) and \n            (texto_filtro in str(row[columna_condicional]) if texto_filtro else True)\n        else None, \n        axis=1\n    )\n    df[columna_destino] = df[columna_destino].ffill()\n    return df\n</code></pre> <p><code>concatenar_dataframes</code> combina m\u00faltiples DataFrames en uno solo, ignorando los \u00edndices originales. Filtra y excluye DataFrames vac\u00edos o aquellos cuyos valores sean completamente nulos antes de la concatenaci\u00f3n. Si no hay DataFrames v\u00e1lidos, retorna un DataFrame vac\u00edo.</p> <pre><code>def concatenar_dataframes(dataframes):\n    # Filtrar DataFrames vac\u00edos o con todos los valores como NA\n    dataframes = [df for df in dataframes if not df.empty and not df.isna().all().all()]\n    if dataframes:\n        return pd.concat(dataframes, ignore_index=True)\n    else:\n        return pd.DataFrame()\n</code></pre> <p><code>process_row</code> procesa una fila de un DataFrame modificando columnas espec\u00edficas en funci\u00f3n del contenido de la columna <code>'Columna_15'</code>. Tambi\u00e9n actualiza dos indicadores booleanos, <code>found_porcentaje</code> y <code>found_creditos</code>, que rastrean si se encontraron palabras clave espec\u00edficas:</p> <ul> <li> <p>Condiciones:</p> <ul> <li>Si <code>'Columna_15'</code> es una cadena que contiene \"Porcentaje\", activa <code>found_porcentaje</code> y desactiva <code>found_creditos</code>.</li> <li>Si <code>'Columna_15'</code> es \"Creditos\", activa <code>found_creditos</code> y desactiva <code>found_porcentaje</code>.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Si <code>found_porcentaje</code> es <code>True</code>, copia el valor de <code>'Columna_15'</code> en <code>'Columna_16'</code>.</li> <li>Si <code>found_creditos</code> es <code>True</code>, copia el valor de <code>'Columna_15'</code> en <code>'Columna_14'</code>.</li> </ul> </li> </ul> <p>Devuelve la fila actualizada junto con los valores actualizados de <code>found_porcentaje</code> y <code>found_creditos</code>.</p> <pre><code>def process_row(row, found_porcentaje, found_creditos):\n    if isinstance(row['Columna_15'], str) and 'Porcentaje' in row['Columna_15']:\n        found_porcentaje = True\n        found_creditos = False\n    elif row['Columna_15'] == 'Creditos':\n        found_creditos = True\n        found_porcentaje = False\n    if found_porcentaje:\n        row['Columna_16'] = row['Columna_15']\n    elif found_creditos:\n        row['Columna_14'] = row['Columna_15']\n    return row, found_porcentaje, found_creditos\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar_excel_con_hojas","title":"Funci\u00f3n <code>procesar_excel_con_hojas</code>","text":"<p>Procesa un archivo Excel con m\u00faltiples hojas, combinando los datos seg\u00fan reglas espec\u00edficas:</p> <ol> <li> <p>Lectura inicial:</p> <ul> <li>Carga todas las hojas del archivo Excel.</li> <li>Procesa la primera hoja directamente.</li> </ul> </li> <li> <p>Procesamiento de hojas restantes:</p> <ul> <li>Identifica el inicio de los datos en cada hoja mediante la primera fila no nula de la columna A.</li> <li>Si los datos de la hoja comienzan con \"1\" en la columna A, combina alineando por esta columna usando un merge.</li> <li>Si no comienzan con \"1\", concatena los datos al final, continuando el listado.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve un \u00fanico DataFrame que combina los datos procesados de todas las hojas seg\u00fan las reglas descritas.</li> </ul> </li> </ol> <pre><code>def procesar_excel_con_hojas(file_path):\n    # Leer todas las hojas\n    excel_data = pd.ExcelFile(file_path)\n    hojas = excel_data.sheet_names\n\n    # Procesar la primera hoja directamente\n    hoja1 = pd.read_excel(file_path, sheet_name=hojas[0])\n\n    # Procesar las dem\u00e1s hojas\n    for sheet_name in hojas[1:]:\n        hoja_actual = pd.read_excel(file_path, sheet_name=sheet_name)\n\n        # Identificar d\u00f3nde empiezan los datos en la columna A\n        inicio_datos = hoja_actual[hoja_actual.iloc[:, 0].notna()].index[0]\n        hoja_actual = hoja_actual.iloc[inicio_datos:].reset_index(drop=True)\n\n        # Verificar si la columna A comienza con 1\n        if hoja_actual.iloc[0, 0] == 1:\n            # Combinar alineando por la columna A\n            hoja1 = pd.merge(\n                hoja1,\n                hoja_actual,\n                left_on=hoja1.columns[0],\n                right_on=hoja_actual.columns[0],\n                how=\"left\",\n            )\n        else:\n            # Agregar datos debajo continuando el listado\n\n            if not hoja_actual.empty:\n                hoja1 = pd.concat([hoja1, hoja_actual], ignore_index=True)\n\n    return hoja1\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-limpiar_columnas","title":"Funci\u00f3n <code>limpiar_columnas</code>","text":"<p>Realiza tareas de limpieza y transformaci\u00f3n en un DataFrame:</p> <ol> <li> <p>Eliminaci\u00f3n de columnas:</p> <ul> <li>Elimina las columnas especificadas en <code>columnas_a_eliminar</code> si existen en el DataFrame.</li> </ul> </li> <li> <p>Renombrado de columnas:</p> <ul> <li>Renombra columnas seg\u00fan el mapeo proporcionado en el diccionario <code>renombres</code>.</li> </ul> </li> <li> <p>Conversi\u00f3n a may\u00fasculas:</p> <ul> <li>Convierte todos los nombres de columnas a may\u00fasculas si se proporciona <code>columnas_a_mayusculas</code>.</li> </ul> </li> </ol> <p>Par\u00e1metros: - <code>df</code>: DataFrame a procesar. - <code>columnas_a_eliminar</code> (list): Lista de nombres de columnas a eliminar. - <code>renombres</code> (dict): Diccionario de renombramiento <code>{nombre_actual: nuevo_nombre}</code>. - <code>columnas_a_mayusculas</code> (bool, opcional): Si se proporciona, convierte los nombres de todas las columnas a may\u00fasculas.</p> <p>Salida: Devuelve el DataFrame transformado.</p> <pre><code>def limpiar_columnas(df, columnas_a_eliminar, renombres, columnas_a_mayusculas=None):\n    df = df.drop(columns=[col for col in columnas_a_eliminar if col in df.columns], errors='ignore')\n    df = df.rename(columns=renombres)\n    # COLOCAR TODAS LAS COLUMNAS EN MAY\u00daSCULAS\n    if columnas_a_mayusculas:\n        df.columns = df.columns.str.upper()\n    return df\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-replace_values_df","title":"Funci\u00f3n <code>replace_values_df</code>","text":"<p>Reemplaza valores en un DataFrame bas\u00e1ndose en un diccionario de sustituciones. Si no se especifica un diccionario <code>replacements</code>, utiliza uno predeterminado donde la columna <code>'Tipo de documento'</code> mapea valores largos como <code>'C\u00e9dula de Ciudadan\u00eda'</code> a formas abreviadas como <code>'CC'</code>. Itera por las columnas del diccionario y aplica los cambios definidos, devolviendo el DataFrame actualizado.</p> <p><code>_dict</code> contiene las claves y valores para reemplazar los tipos de documentos en espa\u00f1ol con sus correspondientes abreviaturas:</p> <ul> <li>C\u00e9dula de Ciudadan\u00eda: 'CC'</li> <li>Tarjeta de Identidad: 'TI'</li> <li>Registro Civil de Nacimiento: 'RC'</li> <li>C\u00e9dula \u00f3 Identificaci\u00f3n de Extranjer\u00eda: 'CE'</li> <li>Permiso de Protecci\u00f3n Temporal: 'PPT'</li> <li>Permiso Especial de Permanencia: 'PEP'</li> <li>N\u00famero de Identificaci\u00f3n Tributaria: 'NIT'</li> <li>C\u00f3digo NES: 'NES'</li> <li>Pasaporte: 'PA'</li> <li>Otros: 'OTRO' <pre><code>```python\n# Define the dictionary with the replacements\n_dict = {\n            'C\u00e9dula de Ciudadan\u00eda': 'CC',\n            'Tarjeta de Identidad': 'TI',\n            'Registro Civil de Nacimiento': 'RC',\n            'C\u00e9dula \u00f3 Identificaci\u00f3n de Extranjer\u00eda': 'CE',\n            'Permiso de Protecci\u00f3n Temporal': 'PPT',\n            'Permiso Especial de Permanencia': 'PEP',\n            'N\u00famero de Identificaci\u00f3n Tributaria': 'NIT',\n            'C\u00f3digo NES': 'NES',\n            'Pasaporte': 'PA',\n            'Otros': 'OTRO',\n            }\n\n# Define the function to replace values based on a dictionary\ndef replace_values_df(df, replacements=None):\n    if replacements is None:\n        replacements = {'Tipo de documento': _dict}\n\n    for column, changes in replacements.items():\n        df[column] = df[column].replace(changes)\n    return df\n</code></pre></li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcion-download_all_files_from_sharepoint","title":"Funci\u00f3n <code>download_all_files_from_sharepoint</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_5","title":"Prop\u00f3sito","text":"<p>Descarga todos los archivos de una carpeta de SharePoint a un directorio local especificado, asegurando que el directorio local sea creado o limpiado antes de la descarga.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_5","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL relativa de la carpeta en SharePoint.</li> <li><code>local_folder_path</code> (str): Ruta local donde se descargar\u00e1n los archivos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_3","title":"Funcionamiento","text":"<ol> <li> <p>Preparaci\u00f3n del directorio local:</p> <ul> <li>Verifica si el directorio existe:</li> <li>Si existe, elimina los archivos existentes.</li> <li>Si no existe, lo crea.</li> </ul> </li> <li> <p>Listado de archivos en SharePoint:</p> <ul> <li>Env\u00eda una solicitud HTTP para obtener la lista de archivos en la carpeta especificada.</li> <li>Procesa la respuesta JSON para obtener los detalles de los archivos.</li> </ul> </li> <li> <p>Descarga de archivos:</p> <ul> <li>Itera sobre la lista de archivos.</li> <li>Descarga cada archivo desde SharePoint y lo guarda en el directorio local.</li> <li>Registra informaci\u00f3n sobre cada archivo descargado o errores si ocurren durante la descarga.</li> </ul> </li> <li> <p>Manejo de sesiones HTTP:</p> <ul> <li>Utiliza una sesi\u00f3n HTTP para realizar las solicitudes.</li> <li>Configura un timeout para prevenir bloqueos.</li> <li>Cierra la sesi\u00f3n al finalizar.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_4","title":"Salida","text":"<ul> <li>No retorna valores. Registra los eventos relacionados con la limpieza del directorio, descarga de archivos y manejo de errores en el logger configurado.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#manejo-de-errores","title":"Manejo de errores","text":"<ul> <li>Registra errores en:</li> <li>Listado de archivos (problemas de red, tiempo de espera, etc.).</li> <li>Descarga de archivos individuales (problemas con la conexi\u00f3n o permisos).</li> <li>Asegura la limpieza del directorio local y el cierre de la sesi\u00f3n HTTP incluso en caso de errores.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones","title":"Consideraciones","text":"<ul> <li>La funci\u00f3n utiliza un decorador <code>log_step_decorator</code> para registrar el inicio, \u00e9xito o error del proceso completo.</li> </ul> <pre><code># Funci\u00f3n para descargar todos los archivos de una carpeta en SharePoint\n@log_step_decorator(\"Descargar archivos de SharePoint\")\ndef download_all_files_from_sharepoint(folder_url, local_folder_path):\n    # Asegurarnos de que el directorio local existe y limpiarlo\n    if os.path.exists(local_folder_path):\n        for file in os.listdir(local_folder_path):\n            file_path = os.path.join(local_folder_path, file)\n            try:\n                os.remove(file_path)\n                logger.info(f\"Archivo eliminado: {file}\")\n            except Exception as e:\n                logger.error(f\"No se pudo eliminar el archivo {file}. Error: {e}\")\n    else:\n        os.makedirs(local_folder_path)\n\n    # Crear una sesi\u00f3n para manejar las solicitudes HTTP\n    session = requests.Session()\n    session.headers.update(headers)  # Asegurar que los encabezados est\u00e1n configurados\n\n    # URL para listar los archivos de la carpeta en SharePoint\n    list_files_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n\n    try:\n        # Solicitud para obtener la lista de archivos\n        response = session.get(list_files_url, timeout=30)  # Configurar un timeout para evitar bloqueos\n        response.raise_for_status()  # Levantar un error si el c\u00f3digo de estado no es 200\n    except requests.exceptions.RequestException as e:\n        logger.error(f\"Error al listar los archivos de la carpeta. Detalles: {e}\")\n        session.close()\n        return\n\n    # Procesar la respuesta JSON\n    files = response.json().get('d', {}).get('results', [])\n    if not files:\n        logger.info(\"No hay archivos en la carpeta especificada.\")\n        session.close()\n        return\n\n    # Descargar cada archivo\n    for file in files:\n        file_name = file['Name']\n        file_url = file['ServerRelativeUrl']\n        download_url = f\"{sharepoint_base_url}/_api/web/GetFileByServerRelativeUrl('{file_url}')/$value\"\n        local_file_path = os.path.join(local_folder_path, file_name)\n\n        try:\n            file_response = session.get(download_url, timeout=30)  # Configurar timeout para cada descarga\n            file_response.raise_for_status()\n            with open(local_file_path, \"wb\") as local_file:\n                local_file.write(file_response.content)\n            logger.info(f\"Archivo descargado: {file_name}\")\n        except requests.exceptions.RequestException as e:\n            logger.error(f\"Error al descargar el archivo {file_name}. Detalles: {e}\")\n        time.sleep(1)  # A\u00f1adir un peque\u00f1o retraso entre descargas para evitar saturar el servidor\n\n    # Cerrar la sesi\u00f3n HTTP\n    session.close()\n</code></pre> <p><code>corregir_nombre_archivo</code> ajusta un nombre de archivo para cumplir con las restricciones del sistema de archivos. Reemplaza caracteres prohibidos (<code>\\ / : * ? \" &lt; &gt; |</code>) con guiones bajos, elimina guiones bajos consecutivos, y asegura que la longitud total no exceda los 255 caracteres. Retorna el nombre corregido.</p> <pre><code>def corregir_nombre_archivo(nuevo_nombre):\n    # Reemplazar caracteres prohibidos por un guion bajo\n    nuevo_nombre = re.sub(r'[\\\\/:*?\"&lt;&gt;|]', '_', nuevo_nombre)\n\n    # Reemplazar m\u00faltiples guiones bajos consecutivos por uno solo\n    nuevo_nombre = re.sub(r'_+', '_', nuevo_nombre)\n\n    # Limitar la longitud total a 255 caracteres\n    base_name, extension = os.path.splitext(nuevo_nombre)\n    if len(base_name) + len(extension) &gt; 255:\n        base_name = base_name[:127] + base_name[-(127 - len(extension)):]\n\n    # Retornar nombre corregido\n    return base_name + extension\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar","title":"Funci\u00f3n <code>procesar</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_6","title":"Prop\u00f3sito","text":"<p>Gestiona el procesamiento y renombrado de archivos en un directorio de descargas basado en un tipo de proceso ETL especificado. Los archivos se renombran seg\u00fan reglas espec\u00edficas y se cargan en una ubicaci\u00f3n correspondiente en SharePoint.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_6","title":"Entradas","text":"<ul> <li><code>etl</code> (str): Identificador del tipo de proceso ETL que determina las reglas de procesamiento y el destino en SharePoint.</li> <li><code>download_dir</code> (str): Ruta del directorio donde se encuentran los archivos a procesar.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_4","title":"Funcionamiento","text":"<ol> <li> <p>Iteraci\u00f3n sobre archivos:</p> <ul> <li>Procesa \u00fanicamente archivos con la extensi\u00f3n <code>.xlsx</code>.</li> <li>Intenta cargar y analizar cada archivo usando <code>openpyxl</code>.</li> </ul> </li> <li> <p>Reglas de procesamiento espec\u00edficas por ETL:</p> <ul> <li>Renombra los archivos bas\u00e1ndose en contenido de celdas espec\u00edficas o estructuras predefinidas.</li> <li>Aplica reglas personalizadas seg\u00fan el tipo de ETL, como extracci\u00f3n de fechas, nombres descriptivos o combinaci\u00f3n de valores en celdas.</li> </ul> </li> <li> <p>Renombrado de archivos:</p> <ul> <li>Genera nombres corregidos que cumplen con las restricciones del sistema de archivos.</li> <li>Verifica la existencia del archivo renombrado antes de continuar.</li> </ul> </li> <li> <p>Subida a SharePoint:</p> <ul> <li>Determina la carpeta de destino en SharePoint seg\u00fan el identificador ETL.</li> <li>Sube los archivos procesados a la carpeta correspondiente.</li> </ul> </li> <li> <p>Limpieza:</p> <ul> <li>Elimina archivos originales y temporales despu\u00e9s del procesamiento o subida.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_5","title":"Salida","text":"<ul> <li>No retorna valores. Registra mensajes en consola sobre el estado del procesamiento, subida o errores encontrados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#manejo-de-errores_1","title":"Manejo de errores","text":"<ul> <li>Captura y maneja excepciones en:</li> <li>Lectura y procesamiento de archivos.</li> <li>Renombrado de archivos.</li> <li>Subida a SharePoint.</li> <li>Registra detalles del error o marca archivos omitidos para su posterior revisi\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_1","title":"Consideraciones","text":"<ul> <li>Las reglas espec\u00edficas por ETL permiten flexibilidad para distintos tipos de procesamiento.</li> </ul> <pre><code>def procesar(etl, download_dir):\n    # Lista para almacenar las rutas completas de los archivos procesados y originales\n    archivos_a_subir = []\n\n    # Iterar sobre todos los archivos en el directorio de descargas\n    for archivo in os.listdir(download_dir):\n        if archivo.endswith('.xlsx'):  # Procesar solo archivos Excel\n            archivo_path = os.path.join(download_dir, archivo)\n            print(f\"Procesando archivo: {archivo}\")\n            # Intentar cargar el archivo Excel\n            try:\n                wb = load_workbook(archivo_path,data_only=True)\n                try:\n                    ws = wb.active\n                    fecha = datetime.now().strftime(\"%d_%m_%Y\")\n                    match etl:\n                        case \"C4C\":\n                            nuevo_nombre = f\"archivo_{fecha}.xlsx\"\n                            nuevo_path = os.path.join(download_dir, nuevo_nombre)\n                            os.makedirs(os.path.dirname(nuevo_path), exist_ok=True)  # Ensure directory exists\n\n                        case \"emp_Consolidado_inasistencias\":\n                            sede_jornada = ws['D6'].value.strip() if ws['D6'].value else \"SIN_SEDE\"\n                            curso = ws['F6'].value.strip() if ws['F6'].value else \"SIN_CURSO\"\n                            periodo = ws['M6'].value.strip() if ws['M6'].value else \"SIN_PERIODO\"\n\n                            nuevo_nombre = f\"Inasistencias_{sede_jornada}_{curso}_{periodo}_{fecha}.xlsx\"\n                            nuevo_path = os.path.join(download_dir, nuevo_nombre)\n                            os.makedirs(os.path.dirname(nuevo_path), exist_ok=True)  # Ensure directory exists\n\n                            if \"SIN\" in [sede_jornada, curso, periodo]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue\n\n                        case \"cede_Cancelados_Desertores\":\n                            # Filtrar y limpiar las fechas\n                            filtro_fechas = [cell.value for cell in ws['I'] if cell.value is not None and cell.value != 'Fecha']\n                            # Eliminar el primer valor si existe\n                            if filtro_fechas:\n                                filtro_fechas.pop(0)\n                            if not filtro_fechas:\n                                filtro_fechas = [cell.value for cell in ws['H'] if cell.value is not None and cell.value != 'Fecha']\n                            # Convertir todas las fechas a objetos datetime\n                            fechas = []\n                            for fecha in filtro_fechas:\n                                try:\n                                    if isinstance(fecha, str):\n                                        fechas.append(datetime.strptime(fecha, \"%d/%m/%Y\"))\n                                    elif isinstance(fecha, datetime):\n                                        fechas.append(fecha)\n                                except ValueError:\n                                    continue\n\n                            if fechas:\n                                fecha_inicio = min(fechas).strftime(\"%d_%m_%Y\")\n                                fecha_fin = max(fechas).strftime(\"%d_%m_%Y\")\n                                nuevo_nombre = f\"Cancelados_desertores_{fecha_inicio}_{fecha_fin}.xlsx\"\n                            else:\n                                fecha = datetime.now().strftime(\"%d_%m_%Y\")\n                                nuevo_nombre = f\"Cancelados_desertores_{fecha}.xlsx\"\n\n\n\n                        case \"cede_Dise\u00f1o_Curricular\":\n                            nuevo_nombre = f\"Dise\u00f1o_Curricular_{fecha}.xlsx\"\n\n\n                        case \"cede_Docentes\" | \"emp_Docentes\":\n                            nuevo_nombre = f\"Docentes_{fecha}.xlsx\"\n\n\n                        case \"cede_Egresados_Graduados\" | \"emp_Egresados_Graduados\":\n                            archivo_sin_ext = os.path.splitext(archivo)[0]\n                            nuevo_nombre = f\"{archivo_sin_ext}_{fecha}.xlsx\"\n\n                        case \"emp_Estudiantes_inasistencias\":\n                            periodo = ws['A7'].value.strip() if ws['A7'].value else \"SIN_DPTO\"\n                            periodo = periodo.replace(\":\", \"\").strip()\n                            nuevo_nombre = f\"emp_Estudiantes_inasistencias_{periodo}.xlsx\"\n\n\n                            if \"SIN_DPTO\" in [periodo]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue\n                        case \"cede_Historico_Notas\":\n                            periodo = ws['J5'].value.strip() if ws['J5'].value else \"SIN_CURSO\"\n                            nuevo_nombre = f\"Historico_Notas_{periodo}\"\n                            #elimina cualquier espacio en nuevo_nombre\n                            nuevo_nombre = nuevo_nombre.replace(\" \", \"\").replace(\"/\", \"_\").replace(\"-\", \"_\")\n                            #agrega un hash al final del nombre del archivo para que no se repitan\n                            nuevo_nombre = f\"{nuevo_nombre}_{os.urandom(4).hex()}_{fecha}.xlsx\"\n                            if \"SIN_CURSO\" in [periodo]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue\n                        case \"cede_Ingresos\":\n                            # nombre = \"Cajero: Todos  |  Desde: 01/01/2020  |  Hasta: 31/01/2020\"\n                            #estraer de nombre Todos_01_01_2020_31_01_2020\n                            nombre = ws['A7'].value.strip() if ws['A7'].value else \"SIN_CURSO\"\n                            nombre = nombre.replace(\"Cajero: \", \"\")\n                            nombre = nombre.replace(\"Todos\", \"Ingresos\")\n                            nombre = nombre.replace(\"  |  Desde: \", \"_\")\n                            nombre = nombre.replace(\"  |  Hasta: \", \"_\")\n                            nombre = nombre.replace(\"/\", \"_\")\n                            nombre = nombre.replace(\" \", \"\")\n\n                            nuevo_nombre = f\"{nombre}_{fecha}.xlsx\"\n\n\n                            if \"SIN_CURSO\" in [nombre]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue                            \n                            nuevo_nombre\n                        case \"cede_Listado_Matriculas\" | \"emp_Listado_Matriculas\":\n                            nombre = ws['A7'].value.strip() if ws['A7'].value else \"SIN_CURSO\"\n                            # texto de la celda Estado: Todos  |  Desde: 01/01/2016  |  Hasta: 31/12/2016\n                            #nombre final del archivo Listado_Matriculas_01_01_2016_31_12_2016\n                            nombre = nombre.replace(\"Estado: \", \"\")\n                            nombre = nombre.replace(\"Todos\", \"Listado_Matriculas\")                            \n                            nombre = nombre.replace(\"  |  Desde: \", \"_\")\n                            nombre = nombre.replace(\"  |  Hasta: \", \"_\")\n                            nombre = nombre.replace(\"/\", \"_\")\n                            nombre = nombre.replace(\" \", \"\")\n\n                            nuevo_nombre = f\"{nombre}_Act_{fecha}.xlsx\"\n\n\n                            if \"SIN_CURSO\" in [nombre]:\n                                print(f\"Archivo {archivo} omitido para procesamiento debido a datos incompletos.\")\n                                archivos_a_subir.append(archivo_path)\n                                continue                            \n\n                        case \"emp_Preinscritos\":\n                            archivo_sin_ext = os.path.splitext(archivo)[0]\n                            nuevo_nombre = f\"{archivo_sin_ext}_{fecha}.xlsx\"                           \n                        case _:\n                            print(\"ETL no reconocido, se omite procesamiento.\")\n                            continue\n                except Exception as e:\n                    print(f\"Error al procesar el archivo {archivo}: {e}\")\n                    wb.close() \n                    continue\n                finally:\n                    wb.close()\n                nuevo_nombre = corregir_nombre_archivo(nuevo_nombre)\n                nuevo_path = os.path.join(download_dir, nuevo_nombre)\n                os.makedirs(os.path.dirname(nuevo_path), exist_ok=True)                \n                time.sleep(1)\n                if os.path.exists(nuevo_path):\n                    os.remove(nuevo_path)\n                time.sleep(1.5)  \n\n                # Intentar renombrar el archivo\n                try:\n                    os.rename(archivo_path, nuevo_path)\n                except Exception as e:\n                    print(f\"Error al renombrar el archivo: {e}\")\n                    # input(\"Presione Enter para continuar...\")\n\n                #Verificar que existe el nuevo archivo nuevo_nombre\n                if not os.path.exists(nuevo_path):\n                    print(f\"Error al procesar el archivo {nuevo_nombre}\")\n                    #pausa de teclado\n                    # input(\"Presione Enter para continuar...\")\n                else:\n                    print(f\"Archivo procesado y guardado como: {nuevo_nombre}\")\n                    archivos_a_subir.append(nuevo_path)\n                    # Eliminar el archivo original despu\u00e9s de procesarlo\n                    time.sleep(1)  # Pausa de 500ms\n                    os.remove(archivo_path)\n\n                print(f\"Archivo original eliminado: {archivo}\")\n\n            except Exception as e:\n                if not \"WinError 2\" in str(e):\n                    print(f\"Error al procesar el archivo {archivo}: {e}\")\n                # Agregar el archivo original a la lista de subida incluso si no se proces\u00f3\n                archivos_a_subir.append(archivo_path)\n            time.sleep(1)  # Pausa de 1 segundo entre archivos\n\n    etl_to_folder_url = {\n        \"cede_Docentes\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/01.Docentes',\n        \"cede_Dise\u00f1o_Curricular\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/02.Disenio_Curricular',\n        \"cede_Listado_Matriculas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/03.Listado_Matriculas',\n        \"cede_Ingresos\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/04.Ingresos',\n        \"cede_Historico_Notas\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/05.Historico_Notas',\n        \"cede_Egresados_Graduados\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/06.Egresados_Graduados',\n        \"cede_Cancelados_Desertores\":'Documentos compartidos/01.Q10/01.Educacion_Tecnica/07.Cancelados_Desertores',\n        \"emp_Docentes\":'Documentos compartidos/01.Q10/02.Educacion_Continua/01.Docentes',\n        \"emp_Preinscritos\":'Documentos compartidos/01.Q10/02.Educacion_Continua/02.Preinscritos',\n        \"emp_Listado_Matriculas\":'Documentos compartidos/01.Q10/02.Educacion_Continua/03.Listado_Matriculas',\n        \"emp_Consolidado_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/04.Consolidado_inasistencias',\n        \"emp_Estudiantes_inasistencias\":'Documentos compartidos/01.Q10/02.Educacion_Continua/05.Estudiantes_cancelados_por_inasistencias',\n        \"emp_Egresados_Graduados\":'Documentos compartidos/01.Q10/02.Educacion_Continua/06.Egresados_Graduados',\n        \"C4C\":'Documentos compartidos/02.C4C'   \n        }\n\n    folder_url = etl_to_folder_url.get(etl, \"URL por defecto si no se encuentra el valor de etl\")\n\n    for archivo in archivos_a_subir:\n        try:\n            upload_file_to_sharepoint(file_path=archivo, folder_url=folder_url)\n            time.sleep(1)  # Esperar 1 segundo \n            #pausa de teclado\n            # input(\"Presione Enter para continuar...\")\n            print(f\"Archivo subido a SharePoint: {archivo}\")\n            os.remove(archivo)\n            time.sleep(1)  # Esperar 1 segundo \n        except Exception as e:\n            if re.match(r'^[a-f0-9]{32}\\.xlsx$', archivo):\n                # Archivo codificado, no hacer logging\n                pass\n            else:        \n                print(f\"--Archivo {archivo}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-seleccionar_opcion_con_js","title":"Funci\u00f3n <code>seleccionar_opcion_con_js</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_7","title":"Prop\u00f3sito","text":"<p>Selecciona una opci\u00f3n en un men\u00fa desplegable (dropdown) utilizando JavaScript, lo que permite forzar la interacci\u00f3n en casos donde los m\u00e9todos est\u00e1ndar de Selenium pueden fallar.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_7","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador de Selenium para manejar el navegador.</li> <li><code>xpath_dropdown</code> (str): XPath del bot\u00f3n del dropdown que se desea abrir.</li> <li><code>opcion</code> (str): Texto exacto de la opci\u00f3n que se desea seleccionar en el men\u00fa desplegable.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_5","title":"Funcionamiento","text":"<ol> <li> <p>Abrir el dropdown:</p> <ul> <li>Localiza el elemento del dropdown mediante su XPath.</li> <li>Usa JavaScript para forzar la apertura del men\u00fa desplegable.</li> </ul> </li> <li> <p>Seleccionar la opci\u00f3n:</p> <ul> <li>Busca la opci\u00f3n deseada dentro del men\u00fa desplegable usando su texto.</li> <li>Utiliza JavaScript para hacer clic en la opci\u00f3n seleccionada.</li> </ul> </li> <li> <p>Manejo de tiempos:</p> <ul> <li>Incluye pausas breves entre las acciones para asegurar que los elementos se carguen correctamente.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li><code>TimeoutException</code>: Si el elemento tarda demasiado en cargarse.</li> <li><code>NoSuchElementException</code>: Si no se encuentra la opci\u00f3n especificada.</li> <li><code>Exception</code>: Captura cualquier otro error inesperado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_6","title":"Salida","text":"<ul> <li>No retorna valores. Registra en el log el estado del proceso, incluyendo \u00e9xito o errores. </li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_2","title":"Consideraciones","text":"<ul> <li>Es \u00fatil para casos donde los men\u00fas desplegables tienen comportamientos din\u00e1micos que dificultan su manejo con clics est\u00e1ndar de Selenium.</li> </ul> <pre><code>def seleccionar_opcion_con_js(driver, xpath_dropdown, opcion):\n    \"\"\"\n    Selecciona una opci\u00f3n en un dropdown utilizando JavaScript para forzar el cambio.\n\n    Args:\n        driver: Instancia del controlador de Selenium.\n        xpath_dropdown: XPath del bot\u00f3n del dropdown.\n        opcion: Texto de la opci\u00f3n a seleccionar.\n    \"\"\"\n    try:\n        # Encontrar el elemento dropdown\n        dropdown = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, xpath_dropdown)))\n\n        # Ejecutar JavaScript para abrir el dropdown\n        logging.info(f\"Abriendo dropdown ubicado en: {xpath_dropdown}\")\n        driver.execute_script(\"arguments[0].click();\", dropdown)\n        time.sleep(1)  # Breve pausa para permitir que el dropdown se abra\n\n        # Localizar la opci\u00f3n deseada en el men\u00fa desplegable\n        opcion_xpath = f\"//ul[contains(@class, 'dropdown-menu')]//span[text()='{opcion}']\"\n        opcion_elemento = WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.XPATH, opcion_xpath))\n        )\n\n        # Ejecutar JavaScript para hacer clic en la opci\u00f3n\n        logging.info(f\"Seleccionando opci\u00f3n: {opcion}\")\n        driver.execute_script(\"arguments[0].click();\", opcion_elemento)\n        time.sleep(5)  # Breve pausa para permitir que la opci\u00f3n se seleccione\n        logging.info(f\"Opci\u00f3n '{opcion}' seleccionada correctamente.\")\n    except TimeoutException as e:\n        logging.error(f\"Timeout al intentar seleccionar la opci\u00f3n '{opcion}' en el dropdown: {e}\")\n    except NoSuchElementException as e:\n        logging.error(f\"No se encontr\u00f3 la opci\u00f3n '{opcion}' en el dropdown: {e}\")\n    except Exception as e:\n        logging.error(f\"Error al seleccionar la opci\u00f3n '{opcion}': {e}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-configurar_pasos_autenticacion_des_empresarial","title":"Funci\u00f3n <code>configurar_pasos_autenticacion_des_empresarial</code>","text":"<p>Configura y devuelve una lista de pasos necesarios para autenticar al usuario en el sistema de Desarrollo Empresarial. </p> <p>Funcionamiento:</p> <ol> <li>Obtenci\u00f3n de credenciales: Recupera la URL, el nombre de usuario y la contrase\u00f1a mediante la funci\u00f3n <code>credenciales</code>.</li> <li>Definici\u00f3n de pasos:<ul> <li>Cada paso est\u00e1 representado como una tupla con:<ul> <li>Nombre del paso: Identificador descriptivo del paso.</li> <li>Funci\u00f3n decorada: Acci\u00f3n espec\u00edfica asociada al paso, como abrir la p\u00e1gina de inicio de sesi\u00f3n o ingresar credenciales.</li> <li>Par\u00e1metros: Diccionario con los argumentos requeridos por cada funci\u00f3n.</li> </ul> </li> </ul> </li> <li>Devoluci\u00f3n: Retorna una lista con los pasos configurados, lista para ejecutarse en un flujo de autenticaci\u00f3n.</li> </ol> <pre><code>def configurar_pasos_autenticacion_des_empresarial(driver):\n    \"\"\"\n    Configura y devuelve los pasos de autenticaci\u00f3n para acceder al sistema.\n    \"\"\"\n    # Configuraci\u00f3n de credenciales y URL de autenticaci\u00f3n\n    url, username, password = credenciales(\"desarrollo_empresarial\")\n    pasos_autenticacion = [\n        (\"abrir_pagina\", \n            log_step_decorator(\"abrir_pagina\")(open_login_page), \n            {\n                'driver': driver,\n                'url': url,\n                'wait_time': 10\n            }\n        ),\n        (\"ingresar_credenciales\", \n            log_step_decorator(\"ingresar_credenciales\")(enter_credentials), \n            {\n                'driver': driver,\n                'username': username,\n                'password': password,\n                'wait_time': 10\n            }\n        )\n    ]\n    return pasos_autenticacion\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-configurar_pasos_autenticacion_cedesarrollo","title":"Funci\u00f3n <code>configurar_pasos_autenticacion_cedesarrollo</code>","text":"<p>Configura y devuelve los pasos necesarios para autenticar al usuario en el sistema de Cedesarrollo.</p> <p>Funcionamiento:</p> <ol> <li>Obtenci\u00f3n de credenciales: Recupera la URL, el nombre de usuario y la contrase\u00f1a utilizando la funci\u00f3n <code>credenciales</code> con el identificador <code>\"cedesarrollo\"</code>.</li> <li>Definici\u00f3n de pasos: <ul> <li>Abrir p\u00e1gina: Usa <code>open_login_page</code> para cargar la URL del sistema.</li> <li>Ingresar credenciales: Utiliza <code>enter_credentials</code> para completar los campos de inicio de sesi\u00f3n con el nombre de usuario y la contrase\u00f1a.</li> <li>Cada paso incluye su nombre, la funci\u00f3n asociada decorada con <code>log_step_decorator</code>, y los par\u00e1metros requeridos.</li> </ul> </li> <li>Registro de informaci\u00f3n: Registra la URL utilizada en el log.</li> <li>Salida: Devuelve una lista de pasos configurados para ejecutar el flujo de autenticaci\u00f3n.</li> </ol> <pre><code>def configurar_pasos_autenticacion_cedesarrollo(driver):\n    \"\"\"\n    Configura y devuelve los pasos de autenticaci\u00f3n para acceder al sistema.\n    \"\"\"\n\n    # Configuraci\u00f3n de credenciales y URL de autenticaci\u00f3n\n    url, username, password = credenciales(\"cedesarrollo\")\n    # url = f\"https://site.q10.com/login?ReturnUrl=%2F&amp;aplentId=8fa60f3a-1a89-4048-a798-afd5cda72549\"\n    logging.info(f\"URL: {url}\")\n    pasos_autenticacion = [\n        (\"abrir_pagina\", \n            log_step_decorator(\"abrir_pagina\")(open_login_page), \n            {\n                'driver': driver,\n                'url': url,\n                'wait_time': 10\n            }\n        ),\n        (\"ingresar_credenciales\", \n            log_step_decorator(\"ingresar_credenciales\")(enter_credentials), \n            {\n                'driver': driver,\n                'username': username,\n                'password': password,\n                'wait_time': 10\n            }\n        )\n    ]\n    return pasos_autenticacion\n</code></pre> <p><code>esperar_y_renombrar_archivo</code> monitorea un directorio de descargas para detectar la aparici\u00f3n de un nuevo archivo, esperando hasta 10 segundos, y lo renombra con un nombre base especificado.</p> <p>Funcionamiento:</p> <ol> <li>Detecci\u00f3n de nuevos archivos:     -Obtiene la lista de archivos antes y despu\u00e9s de la espera.     -Identifica los archivos nuevos comparando ambas listas.</li> <li>Renombrar archivo:     -Si se encuentra un archivo nuevo, selecciona el m\u00e1s reciente seg\u00fan la fecha de creaci\u00f3n.     -Renombra el archivo con el nombre base y extensi\u00f3n proporcionados.</li> <li>Manejo de tiempos:     -Espera hasta 10 segundos, verificando cada segundo si hay un archivo nuevo.</li> <li>Resultados:     -Devuelve <code>True</code> si el archivo fue renombrado exitosamente.     -Devuelve <code>False</code> si no se encuentra un nuevo archivo dentro del tiempo l\u00edmite.</li> </ol> <p>Entradas: - <code>download_dir</code> (str): Ruta al directorio donde se espera el archivo. - <code>archivo</code> (str): Nombre base del archivo para renombrar.</p> <p>Salida: - <code>bool</code>: Indica si el renombrado fue exitoso (<code>True</code>) o no (<code>False</code>).</p> <pre><code>def esperar_y_renombrar_archivo(download_dir, archivo):\n    \"\"\"\n    Espera a que un archivo nuevo aparezca en el directorio de descargas y lo renombra.\n\n    Args:\n        download_dir (str): Directorio de descargas.\n        archivo (str): Nombre base del archivo.\n        opcion (str): Opci\u00f3n para renombrar el archivo.\n\n    Returns:\n        bool: True si el archivo fue renombrado exitosamente, False en caso contrario.\n    \"\"\"\n    archivos_antes = set(os.listdir(download_dir))\n\n    # Esperar a que un archivo nuevo aparezca en el directorio\n    for _ in range(10):\n        archivos_despues = set(os.listdir(download_dir))\n        archivos_nuevos = archivos_despues - archivos_antes  # Detectar nuevos archivos\n        if archivos_nuevos:\n            # Obtener el archivo nuevo m\u00e1s reciente\n            latest_file = max(archivos_nuevos, key=lambda f: os.path.getctime(os.path.join(download_dir, f)))\n            latest_file_path = os.path.join(download_dir, latest_file)\n\n            # Renombrar el archivo descargado\n            base_name, extension = os.path.splitext(archivo)\n            new_file_path = os.path.join(download_dir, f'{base_name}{extension}')\n            os.rename(latest_file_path, new_file_path)\n            logging.info(f\"Archivo renombrado a: {new_file_path}\")\n            return True\n        logging.info(\"Esperando que la descarga se complete...\")\n        time.sleep(1)\n\n    logging.error(\"No se encontr\u00f3 un archivo nuevo en el tiempo esperado.\")\n    return False\n</code></pre> <p><code>elemento_disponible</code> verifica si un elemento en el DOM es clickeable dentro de un tiempo de espera especificado. Recibe como argumentos el controlador de Selenium (<code>driver</code>), el tipo de localizador (<code>by</code>), el valor del localizador (<code>value</code>), y un tiempo m\u00e1ximo de espera (<code>timeout</code>). Retorna el elemento web si est\u00e1 disponible, o <code>None</code> en caso de que no sea clickeable en el tiempo especificado, registrando una advertencia en el log.</p> <pre><code>def elemento_disponible(driver, by, value, timeout=5):\n    \"\"\"\n    Verifica si un elemento est\u00e1 presente y es clickeable en el DOM dentro del tiempo especificado.\n\n    Args:\n        driver: Instancia del controlador de Selenium.\n        by: Tipo de localizaci\u00f3n (By.ID, By.XPATH, etc.).\n        value: Valor del localizador.\n        timeout: Tiempo m\u00e1ximo de espera (en segundos).\n\n    Returns:\n        WebElement si el elemento est\u00e1 disponible, None en caso contrario.\n    \"\"\"\n    try:\n        return WebDriverWait(driver, timeout).until(EC.element_to_be_clickable((by, value)))\n    except TimeoutException:\n        logging.warning(f\"Elemento no disponible: {value}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar_reporte_modal","title":"Funci\u00f3n <code>procesar_reporte_modal</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_8","title":"Prop\u00f3sito","text":"<p>Gestiona la exportaci\u00f3n de un reporte desde un modal con un <code>iframe</code>, descargando el archivo en formato <code>XLSX</code>, verificando su aparici\u00f3n en el directorio de descargas y renombr\u00e1ndolo con un nombre espec\u00edfico.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_8","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>download_dir</code> (str): Ruta del directorio de descargas donde se guardar\u00e1 el archivo.</li> <li><code>archivo</code> (str): Nombre con el que se renombrar\u00e1 el archivo descargado.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_6","title":"Funcionamiento","text":"<ol> <li> <p>Acceso al modal:</p> <ul> <li>Espera a que el modal sea visible y cambia al contexto del <code>iframe</code>.</li> </ul> </li> <li> <p>Interacci\u00f3n con el men\u00fa de exportaci\u00f3n:</p> <ul> <li>Hace clic en el elemento <code>exportSelect</code>.</li> <li>Intenta seleccionar la opci\u00f3n <code>XLSX</code>:</li> <li>Navega mediante teclas (flechas y Enter).</li> <li>Alternativamente, utiliza JavaScript para forzar la selecci\u00f3n.</li> </ul> </li> <li> <p>Gesti\u00f3n del archivo descargado:</p> <ul> <li>Verifica la aparici\u00f3n de nuevos archivos en el directorio de descargas.</li> <li>Renombra el archivo m\u00e1s reciente al nombre especificado (<code>archivo</code>).</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera o problemas al interactuar con elementos.</li> <li>Intenta cerrar el modal si ocurre un error.</li> </ul> </li> <li> <p>Finalizaci\u00f3n:</p> <ul> <li>Cierra el modal y regresa al contexto principal del navegador.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_7","title":"Salida","text":"<ul> <li>No retorna valores. Registra eventos y errores en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#manejo-de-errores_2","title":"Manejo de errores","text":"<ul> <li><code>TimeoutException</code>: Si un elemento no est\u00e1 disponible dentro del tiempo l\u00edmite.</li> <li><code>Exception</code>: Captura otros errores inesperados e intenta cerrar el modal.</li> </ul> <pre><code>def procesar_reporte_modal(driver, download_dir, archivo):\n    try:\n        # Esperar hasta que el modal est\u00e9 visible\n        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.ID, \"master-modal\")))\n\n        # Cambiar al contexto del `iframe` dentro del modal\n        WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.ID, \"report\")))\n\n        # Esperar hasta que el elemento 'exportSelect' est\u00e9 visible y hacer clic en \u00e9l\n        export_select = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"exportSelect\")))\n        export_select.click()\n        logging.info(\"Elemento exportSelect clickeado exitosamente.\")\n\n        # Espera adicional para que el men\u00fa de exportaci\u00f3n se despliegue\n        time.sleep(2)\n\n        # Intento 1: Navegar con teclas para seleccionar XLSX\n        export_select.send_keys(Keys.ARROW_DOWN)  # Baja una vez en el men\u00fa\n        export_select.send_keys(Keys.ARROW_DOWN)  # Baja dos veces (ajustar seg\u00fan sea necesario)\n        export_select.send_keys(Keys.ENTER)  # Seleccionar\n\n        logging.info(\"Intento de seleccionar XLSX usando teclas.\")\n\n        # Esperar unos segundos para que el efecto del clic se procese\n        time.sleep(2)\n\n        # Intento 2: Forzar clic en la opci\u00f3n 'XLSX' mediante JavaScript\n        try:\n            xlsx_option_js = driver.find_element(By.XPATH, \"//li[text()='XLSX']\")\n            driver.execute_script(\"arguments[0].click();\", xlsx_option_js)\n            logging.info(\"Opci\u00f3n XLSX seleccionada exitosamente mediante JavaScript.\")\n            time.sleep(2)\n\n\n            # Espera adicional para asegurar el procesamiento del cierre\n            time.sleep(2)\n\n            export_select.send_keys(Keys.ESCAPE)  # Baja una vez en el men\u00fa\n\n\n        except Exception as e:\n            logging.error(f\"No se pudo seleccionar la opci\u00f3n XLSX con JavaScript:\")\n\n        time.sleep(2)\n\n        # Verificar y renombrar el archivo\n        archivos_antes = set(os.listdir(download_dir))\n\n        #eliminar archivo anterior\n        # Eliminar solo el archivo espec\u00edfico si existe\n        file_path = os.path.join(download_dir, archivo)\n        if os.path.exists(file_path):\n            os.remove(file_path)\n            logging.info(f\"Archivo {archivo} eliminado correctamente\")\n\n        for _ in range(2):  # Reducir el tiempo de espera a m\u00e1ximo 5 segundos\n            time.sleep(1)  # Intervalos m\u00e1s cortos\n            archivos_despues = set(os.listdir(download_dir))\n            archivos_nuevos = archivos_despues - archivos_antes\n\n            if archivos_nuevos:\n                # Detectar el archivo m\u00e1s reciente\n                latest_file = max(\n                    archivos_nuevos,\n                    key=lambda f: os.path.getctime(os.path.join(download_dir, f))\n                )\n                latest_file_path = os.path.join(download_dir, latest_file)\n\n                # Renombrar el archivo descargado\n                base_name, extension = os.path.splitext(archivo)\n                new_file_path = os.path.join(download_dir, f'{base_name}{extension or \".xlsx\"}')\n\n                os.rename(latest_file_path, new_file_path)\n                logging.info(f\"Archivo renombrado a: {new_file_path}\")\n                break # Salir del bucle si se renombr\u00f3 correctamente\n        logging.warning(\"No se detect\u00f3 un nuevo archivo en el tiempo l\u00edmite.\")        \n        # Espera adicional para asegurar el procesamiento de la selecci\u00f3n\n        time.sleep(2)\n    except TimeoutException as te:\n        logging.error(f\"Tiempo de espera excedido al procesar el reporte: {te}\")\n    except Exception as e:\n        logging.error(f\"Error al procesar el reporte en el iframe: {e}\")\n        # Esperar hasta que el elemento 'exportSelect' est\u00e9 visible y hacer clic en \u00e9l\n        export_select = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"close\")))\n        export_select.click()\n    finally:\n        # Esperar hasta que el elemento 'exportSelect' est\u00e9 visible y hacer clic en \u00e9l\n        export_select = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"close\")))\n        export_select.click()\n        # Regresar al contexto principal si necesitas realizar m\u00e1s acciones fuera del iframe\n        driver.switch_to.default_content()\n</code></pre> <p><code>normalizar_texto</code> elimina tildes y caracteres especiales de un texto dado. Utiliza <code>unicodedata.normalize</code> para convertir caracteres Unicode a una representaci\u00f3n compatible con ASCII, eliminando acentos y caracteres no est\u00e1ndar. Retorna el texto normalizado.</p> <pre><code>def normalizar_texto(texto):\n    \"\"\"\n    Normaliza un texto eliminando tildes y caracteres especiales.\n    \"\"\"\n    return unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n</code></pre> <p><code>ejecutar_pasos</code> ejecuta de forma secuencial una lista de pasos definidos. Cada paso es una tupla que contiene el nombre del paso (<code>step_name</code>), la funci\u00f3n a ejecutar (<code>step_function</code>), y un diccionario de par\u00e1metros (<code>params</code>). Registra el nombre de cada paso antes de ejecutarlo y llama a la funci\u00f3n correspondiente con los par\u00e1metros proporcionados.</p> <pre><code>\"\"\"\n        # Ejecutar cada uno de los pasos definidos en el diccionario\n        for step_name, step_function, params in step_1:\n            logging.info(f\"Ejecutando el paso: {step_name}\")\n            step_function(**params)\n\n\"\"\"\n        # Ejecutar cada uno de los pasos definidos en el diccionario\ndef ejecutar_pasos(pasos):\n    for step_name, step_function, params in pasos:\n        logging.info(f\"Ejecutando el paso: {step_name}\")\n        step_function(**params)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-procesar_opciones_descarga","title":"Funci\u00f3n <code>procesar_opciones_descarga</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_9","title":"Prop\u00f3sito","text":"<p>Automatiza la selecci\u00f3n de opciones en un men\u00fa desplegable (dropdown), descarga los archivos correspondientes y los renombra con base en las opciones seleccionadas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_9","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Controlador de Selenium para manejar el navegador.</li> <li><code>opciones</code> (list): Lista de opciones del dropdown.</li> <li><code>xpath_boton</code> (str): XPath del bot\u00f3n para abrir el dropdown.</li> <li><code>id_descargar</code> (str): ID del bot\u00f3n de descarga.</li> <li><code>nombre_archivo</code> (str): Nombre base del archivo para el renombrado.</li> <li><code>nombre_archivo_completo</code> (str): Nombre completo del archivo descargado.</li> <li><code>download_dir</code> (str): Directorio donde se guardan las descargas.</li> <li><code>wait_time</code> (int): Tiempo de espera despu\u00e9s de cada acci\u00f3n (por defecto 2 segundos).</li> <li><code>xpath_omitir</code> (str, opcional): XPath para omitir popups opcionales.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_7","title":"Funcionamiento","text":"<ol> <li> <p>Preparaci\u00f3n inicial:</p> <ul> <li>Llama a <code>eliminar_archivos_anteriores</code> para limpiar descargas previas en el directorio.</li> </ul> </li> <li> <p>Interacci\u00f3n con el dropdown:</p> <ul> <li>Hace clic en el bot\u00f3n del dropdown para abrirlo.</li> <li>Itera sobre las opciones de la lista:</li> <li>Selecciona una opci\u00f3n usando <code>seleccionar_opcion_custom_dropdown</code>.</li> </ul> </li> <li> <p>Descarga de archivos:</p> <ul> <li>Para cada opci\u00f3n seleccionada:</li> <li>Si el tipo es <code>\"modal\"</code>, procesa la descarga mediante <code>procesar_reporte_modal</code>.</li> <li>En otros casos, utiliza <code>cola_descargar</code> para manejar la descarga y verificarla.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_8","title":"Salida","text":"<ul> <li>No retorna valores. Realiza acciones relacionadas con selecci\u00f3n, descarga y renombrado de archivos.</li> </ul> <pre><code>def procesar_opciones_descarga(driver, opciones, xpath_boton, id_descargar, nombre_archivo, tipo, nombre_archivo_completo, download_dir, wait_time=2, xpath_omitir=None):\n    \"\"\"\n    Itera sobre las opciones de un dropdown, selecciona cada opci\u00f3n, descarga el archivo\n    y renombra el archivo descargado con la opci\u00f3n seleccionada.\n\n    Args:\n        driver (WebDriver): El controlador de Selenium.\n        opciones (list): Lista de opciones del dropdown.\n        xpath_boton (str): XPath del bot\u00f3n para abrir el dropdown.\n        id_descargar (str): ID del bot\u00f3n de descarga.\n        nombre_archivo (str): Nombre base del archivo para renombrar.\n        nombre_archivo_completo (str): Nombre completo del archivo descargado.\n        download_dir (str): Directorio donde se guardan las descargas.\n        wait_time (int): Tiempo de espera despu\u00e9s de cada acci\u00f3n.\n        xpath_omitir (str): XPath opcional para omitir un popup.\n    \"\"\"\n    # Llamada a eliminar archivos anteriores usando el directorio especificado\n    eliminar_archivos_anteriores(nombre_archivo_completo, download_dir=download_dir)\n\n    # Clic en el bot\u00f3n de apertura del dropdown\n    hacer_clic(driver=driver, xpath=xpath_boton, wait_time=5)\n\n    # Itera sobre las opciones para seleccionar y descargar\n    for opcion in opciones:\n        seleccionar_opcion_custom_dropdown(driver=driver, xpath=xpath_boton, option=opcion, wait_time=wait_time)\n\n        # Descargar el archivo\n        if tipo == \"modal\":\n            procesar_reporte_modal(driver)\n        else:\n            se_descargo = cola_descargar(opcion=opcion,download_dir= download_dir,driver=driver, id=id_descargar, archivo=nombre_archivo_completo, wait_time=15, xpath_omitir=xpath_omitir)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-setup_driver","title":"Funci\u00f3n <code>setup_driver</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_10","title":"Prop\u00f3sito","text":"<p>Configura un controlador de Selenium con opciones personalizadas, estableciendo un directorio espec\u00edfico para las descargas de archivos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_10","title":"Entradas","text":"<ul> <li><code>subcarpeta</code> (str): Nombre de la subcarpeta dentro del directorio de descargas base donde se guardar\u00e1n los archivos (por defecto: <code>\"default\"</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_8","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n del directorio de descargas:</p> <ul> <li>Construye la ruta completa para las descargas en la subcarpeta especificada, ubicada dentro de <code>01.Q10/Procesados</code>.</li> <li>Crea el directorio si no existe y registra su creaci\u00f3n o existencia en el log.</li> </ul> </li> <li> <p>Configuraci\u00f3n de Chrome:</p> <ul> <li>Define preferencias espec\u00edficas para descargas:</li> <li>Descargas autom\u00e1ticas sin confirmaci\u00f3n.</li> <li>Actualizaci\u00f3n del directorio de descargas.</li> <li>Habilitaci\u00f3n de la navegaci\u00f3n segura.</li> <li>A\u00f1ade configuraciones para optimizar el navegador:</li> <li>Maximizaci\u00f3n de ventana.</li> <li>Deshabilitaci\u00f3n de caracter\u00edsticas innecesarias y controles autom\u00e1ticos.</li> </ul> </li> <li> <p>Inicia el controlador de Selenium:</p> <ul> <li>Configura un tiempo de espera para la carga de p\u00e1ginas (30 segundos).</li> <li>Registra la configuraci\u00f3n del controlador y la ruta de descargas en el log.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Retorna la instancia del controlador <code>driver</code> y la ruta completa del directorio de descargas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_9","title":"Salida","text":"<ul> <li><code>driver</code> (WebDriver): Instancia configurada del controlador de Selenium.</li> <li><code>download_dir</code> (str): Ruta absoluta del directorio de descargas configurado.</li> </ul> <pre><code>DOWNLOAD_DIR = os.path.join(os.path.abspath(os.getcwd()), \"Procesados\")\n\ndef setup_driver(subcarpeta=\"default\"):\n    \"\"\"\n    Configura el controlador de Selenium y crea la ruta de descargas en la subcarpeta especificada.\n    \"\"\"\n    # Define la ruta completa de descarga en la subcarpeta especificada\n    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # Subir un nivel desde `Codigos`\n    download_dir = os.path.join(base_dir, \"01.Q10\", \"Procesados\", subcarpeta)  # Ruta hacia `01.Q10\\Procesados`\n\n    # Crear el directorio si no existe\n    if not os.path.exists(download_dir):\n        os.makedirs(download_dir)\n        logging.info(f\"Directorio de descargas creado en: {download_dir}\")\n    else:\n        logging.info(f\"Directorio de descargas ya existe: {download_dir}\")\n\n    # Configura las preferencias de Chrome para las descargas\n    chrome_options = webdriver.ChromeOptions()\n    prefs = {\n        \"download.default_directory\": download_dir,\n        \"download.prompt_for_download\": False,\n        \"download.directory_upgrade\": True,\n        \"safebrowsing.enabled\": True\n    }\n    chrome_options.add_experimental_option(\"prefs\", prefs)\n    chrome_options.add_argument('--disable-gpu')\n    chrome_options.add_argument('--no-sandbox')\n    chrome_options.add_argument('--disable-dev-shm-usage')\n    chrome_options.add_argument('--window-size=1920x1080')\n    chrome_options.add_argument('--ignore-certificate-errors')\n    chrome_options.add_argument('--disable-extensions')\n    chrome_options.add_argument('--disable-infobars')\n    chrome_options.add_argument('--start-maximized')\n    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n\n    # Inicia el controlador\n    driver = webdriver.Chrome(options=chrome_options)\n    driver.set_page_load_timeout(30)\n    logging.info(f\"Controlador de Selenium configurado con el directorio de descargas en: {download_dir}\")\n\n    # Retorna el controlador y la ruta de descarga\n    return driver, download_dir\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-setup_driver_c4c","title":"Funci\u00f3n <code>setup_driver_C4C</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_11","title":"Prop\u00f3sito","text":"<p>Configura un controlador de Selenium para automatizaciones en el entorno C4C, estableciendo un directorio espec\u00edfico para descargas en una subcarpeta determinada.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_11","title":"Entradas","text":"<ul> <li><code>subcarpeta</code> (str): Nombre de la subcarpeta dentro del directorio base de descargas, donde se almacenar\u00e1n los archivos (por defecto: <code>\"default\"</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_9","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n del directorio de descargas:</p> <ul> <li>Construye la ruta completa del directorio de descargas en <code>02.C4C/Procesados</code>.</li> <li>Crea el directorio si no existe y registra el resultado en el log.</li> </ul> </li> <li> <p>Configuraci\u00f3n del navegador Chrome:</p> <ul> <li>Define preferencias para la gesti\u00f3n autom\u00e1tica de descargas:</li> <li>Descargas sin solicitud de confirmaci\u00f3n.</li> <li>Navegaci\u00f3n segura habilitada.</li> <li>Actualizaci\u00f3n autom\u00e1tica del directorio de descargas.</li> <li>Configura argumentos adicionales para optimizar el rendimiento y la experiencia del navegador:</li> <li>Maximiza la ventana y deshabilita extensiones y notificaciones innecesarias.</li> </ul> </li> <li> <p>Inicia el controlador de Selenium:</p> <ul> <li>Configura un tiempo de espera m\u00e1ximo para la carga de p\u00e1ginas (30 segundos).</li> <li>Registra en el log la ruta de descargas y la configuraci\u00f3n del controlador.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Retorna el controlador <code>driver</code> y la ruta absoluta del directorio de descargas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_10","title":"Salida","text":"<ul> <li><code>driver</code> (WebDriver): Instancia configurada del controlador de Selenium.</li> <li><code>download_dir</code> (str): Ruta completa del directorio de descargas configurado.</li> </ul> <pre><code># En Funciones.py\ndef setup_driver_C4C(subcarpeta=\"default\"):\n    \"\"\"\n    Configura el controlador de Selenium y crea la ruta de descargas en la subcarpeta especificada.\n    \"\"\"\n    # Define la ruta completa de descarga en la subcarpeta especificada\n    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # Subir un nivel desde `Codigos`\n    download_dir = os.path.join(base_dir, \"02.C4C\", \"Procesados\", subcarpeta)  # Ruta hacia `01.Q10\\Procesados`\n\n    # Crear el directorio si no existe\n    if not os.path.exists(download_dir):\n        os.makedirs(download_dir)\n        logging.info(f\"Directorio de descargas creado en: {download_dir}\")\n    else:\n        logging.info(f\"Directorio de descargas ya existe: {download_dir}\")\n\n    # Configura las preferencias de Chrome para las descargas\n    chrome_options = webdriver.ChromeOptions()\n    prefs = {\n        \"download.default_directory\": download_dir,\n        \"download.prompt_for_download\": False,\n        \"download.directory_upgrade\": True,\n        \"safebrowsing.enabled\": True\n    }\n    chrome_options.add_experimental_option(\"prefs\", prefs)\n    chrome_options.add_argument('--disable-gpu')\n    chrome_options.add_argument('--no-sandbox')\n    chrome_options.add_argument('--disable-dev-shm-usage')\n    chrome_options.add_argument('--window-size=1920x1080')\n    chrome_options.add_argument('--ignore-certificate-errors')\n    chrome_options.add_argument('--disable-extensions')\n    chrome_options.add_argument('--disable-infobars')\n    chrome_options.add_argument('--start-maximized')\n    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n\n    # Inicia el controlador\n    driver = webdriver.Chrome(options=chrome_options)\n    driver.set_page_load_timeout(30)\n    logging.info(f\"Controlador de Selenium configurado con el directorio de descargas en: {download_dir}\")\n\n    # Retorna el controlador y la ruta de descarga\n    return driver, download_dir\n</code></pre> <p><code>open_login_page</code> abre una p\u00e1gina de inicio de sesi\u00f3n en un navegador controlado por Selenium y espera a que el cuerpo de la p\u00e1gina se cargue completamente. Recibe el controlador (<code>driver</code>), la URL de la p\u00e1gina a abrir (<code>url</code>) y un tiempo de espera opcional (<code>wait_time</code>). Registra en el log tanto el inicio como la confirmaci\u00f3n de que la p\u00e1gina se ha abierto correctamente.</p> <pre><code>def open_login_page(driver, url, wait_time=2):\n    logger.info(f\"Abriendo la p\u00e1gina de inicio de sesi\u00f3n: {url}\")\n    driver.get(url)\n    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n    logger.info(f\"P\u00e1gina de inicio de sesi\u00f3n abierta: {url}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-enter_credentials","title":"Funci\u00f3n <code>enter_credentials</code>","text":"<p>Automatiza el ingreso de credenciales en una p\u00e1gina de inicio de sesi\u00f3n controlada por Selenium. </p> <p>Funcionamiento:</p> <ol> <li> <p>Ingreso del nombre de usuario:</p> <ul> <li>Espera hasta que el campo de entrada de usuario est\u00e9 presente (<code>NombreUsuario</code>).</li> <li>Ingresa el valor proporcionado en <code>username</code>.</li> </ul> </li> <li> <p>Ingreso de la contrase\u00f1a:</p> <ul> <li>Espera hasta que el campo de entrada de contrase\u00f1a est\u00e9 presente (<code>Contrasena</code>).</li> <li>Ingresa el valor proporcionado en <code>password</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas, y registra el error en el log antes de lanzarlo nuevamente.</li> </ul> </li> </ol> <p>Entradas:</p> <ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>username</code> (str): Nombre de usuario a ingresar.</li> <li><code>password</code> (str): Contrase\u00f1a asociada al usuario.</li> <li><code>wait_time</code> (int, opcional): Tiempo de espera entre interacciones (por defecto, 1 segundo).</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Realiza acciones y registra eventos o errores en el log.</li> </ul> <pre><code>def enter_credentials(driver, username, password, wait_time=1):\n    # Ingresa las credenciales de usuario en los campos correspondientes\n    try:\n        logging.info(\"Ingresando usuario\")\n        # Esperar hasta que el campo de nombre de usuario est\u00e9 presente y luego ingresar el nombre de usuario\n        username_field = WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.NAME, 'NombreUsuario'))\n        )\n        username_field.send_keys(username)\n        logging.info(\"Nombre de usuario ingresado correctamente\")\n\n        logging.info(\"Ingresando contrase\u00f1a\")\n        # Esperar hasta que el campo de contrase\u00f1a est\u00e9 presente y luego ingresar la contrase\u00f1a\n        password_field = WebDriverWait(driver, 10).until(\n            EC.presence_of_element_located((By.NAME, 'Contrasena'))\n        )\n        password_field.send_keys(password)\n        logging.info(\"Credenciales ingresadas correctamente\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error durante el ingreso de credenciales: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-submit_login","title":"Funci\u00f3n <code>submit_login</code>","text":"<p>Env\u00eda el formulario de inicio de sesi\u00f3n en una p\u00e1gina web controlada por Selenium y verifica que el inicio de sesi\u00f3n haya sido exitoso.</p> <p>Funcionamiento:</p> <ol> <li> <p>Interacci\u00f3n con el bot\u00f3n de inicio de sesi\u00f3n:</p> <ul> <li>Espera hasta que el bot\u00f3n del formulario est\u00e9 presente y sea clickeable (<code>//button[@type=\"submit\"]</code>).</li> <li>Hace clic en el bot\u00f3n para enviar el formulario.</li> </ul> </li> <li> <p>Verificaci\u00f3n del inicio de sesi\u00f3n:</p> <ul> <li>Espera a que un elemento indicativo del post-login (<code>elemento_post_login</code>) est\u00e9 presente para confirmar el \u00e9xito.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o no interactuables, registra el error en el log y lanza nuevamente la excepci\u00f3n.</li> </ul> </li> </ol> <p>Entradas:</p> <ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>wait_time</code> (int, opcional): Tiempo de espera entre interacciones (por defecto, 3 segundos).</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Realiza acciones en la p\u00e1gina y registra en el log el estado del proceso o errores.</li> </ul> <pre><code>def submit_login(driver, wait_time=3):\n    # Env\u00eda el formulario de inicio de sesi\u00f3n\n    try:\n        logging.info(\"Enviando formulario de inicio de sesi\u00f3n\")\n        # Esperar hasta que el bot\u00f3n de inicio de sesi\u00f3n est\u00e9 presente y luego hacer clic\n        login_button = WebDriverWait(driver, 10).until(\n            EC.element_to_be_clickable((By.XPATH, '//button[@type=\"submit\"]'))\n        )\n        login_button.click()\n        # Esperar hasta que un elemento post-login est\u00e9 presente para confirmar el \u00e9xito del inicio de sesi\u00f3n\n        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'elemento_post_login')))\n        logging.info(\"Formulario de inicio de sesi\u00f3n enviado\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException) as e:\n        logging.error(f\"Error al enviar el formulario de inicio de sesi\u00f3n: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-close_driver","title":"Funci\u00f3n <code>close_driver</code>","text":"<p>Cierra de manera segura el navegador controlado por Selenium.</p> <p>Funcionamiento:</p> <ol> <li> <p>Cierre del navegador:</p> <ul> <li>Intenta cerrar la instancia del controlador mediante <code>driver.quit()</code>.</li> <li>Registra en el log que el navegador se cerr\u00f3 correctamente.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura posibles excepciones (<code>WebDriverException</code>) durante el cierre y registra el error en el log.</li> </ul> </li> </ol> <p>Entradas:</p> <ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium que se desea cerrar.</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Realiza la acci\u00f3n de cierre y registra el estado del proceso en el log.</li> </ul> <pre><code>def close_driver(driver):\n    # Cierra el navegador de manera segura\n    logging.info(\"Cerrando el navegador\")\n    try:\n        driver.quit()\n        logging.info(\"Navegador cerrado correctamente\")\n    except WebDriverException as e:\n        logging.error(f\"Error al cerrar el navegador: {e}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-seleccionar_dropdown","title":"Funci\u00f3n <code>seleccionar_dropdown</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_12","title":"Prop\u00f3sito","text":"<p>Selecciona una opci\u00f3n de un men\u00fa desplegable (<code>dropdown</code>) en una p\u00e1gina web controlada por Selenium, utilizando diversos identificadores de localizaci\u00f3n.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_12","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para configurar la selecci\u00f3n:</li> <li><code>option</code> (str): Texto visible de la opci\u00f3n a seleccionar.</li> <li><code>n_option</code> (int): \u00cdndice de la opci\u00f3n a seleccionar.</li> <li><code>wait_time</code> (int, opcional): Tiempo en segundos para esperar despu\u00e9s de realizar la selecci\u00f3n (por defecto: <code>0</code>).</li> <li>Localizadores: Uno de los siguientes:<ul> <li><code>xpath</code> (str): Localizaci\u00f3n del dropdown usando XPath.</li> <li><code>id</code> (str): Identificaci\u00f3n del elemento.</li> <li><code>name</code> (str): Nombre del elemento.</li> <li><code>class_name</code> (str): Clase del elemento.</li> <li><code>css_selector</code> (str): Selector CSS.</li> </ul> </li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_10","title":"Funcionamiento","text":"<ol> <li> <p>Localizaci\u00f3n del dropdown:</p> <ul> <li>Determina el tipo de localizador (<code>id</code>, <code>xpath</code>, etc.) y su valor.</li> <li>Encuentra el elemento correspondiente en el DOM usando <code>WebDriverWait</code>.</li> </ul> </li> <li> <p>Selecci\u00f3n de la opci\u00f3n:</p> <ul> <li>Si se proporciona <code>option</code>, selecciona la opci\u00f3n por texto visible.</li> <li>Si se proporciona <code>n_option</code>, selecciona la opci\u00f3n por \u00edndice.</li> <li>Lanza un error si no se proporciona ninguna opci\u00f3n v\u00e1lida.</li> </ul> </li> <li> <p>Espera opcional:</p> <ul> <li>Realiza una pausa tras la selecci\u00f3n si se especifica <code>wait_time</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas.</li> <li>Registra el error en el log y lanza la excepci\u00f3n.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_11","title":"Salida","text":"<ul> <li>No retorna valores. Realiza la selecci\u00f3n en el dropdown y registra el estado del proceso en el log.</li> </ul> <pre><code>def seleccionar_dropdown(driver, **kwargs):\n    try:\n        logging.info(f\"Seleccionando opci\u00f3n del dropdown especificado\")\n\n        # Recoger 'wait_time' de kwargs o establecer un valor por defecto\n        wait_time = kwargs.get('wait_time', 0)\n\n        # Recorrer las posibles opciones de identificador y localizar el elemento\n        locator_type, locator_value, option_value, n_option = None, None, None, None\n        for key, value in kwargs.items():\n            if key == 'option':\n                option_value = value\n            elif key == 'n_option':\n                n_option = value\n            elif value is not None and key != 'wait_time':\n                locator_type = key\n                locator_value = value\n\n        # Verificar si se proporcion\u00f3 un localizador v\u00e1lido\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar una ubicaci\u00f3n v\u00e1lida para seleccionar un dropdown\")\n\n        # Convertir el identificador a By adecuado\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR\n        }\n        dropdown_element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((by_mapping[locator_type], locator_value)))\n        select = Select(dropdown_element)\n\n        # Seleccionar la opci\u00f3n por texto visible o por \u00edndice\n        if option_value is not None:\n            select.select_by_visible_text(option_value)\n            logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente en el dropdown\")\n        elif n_option is not None:\n            select.select_by_index(n_option)\n            logging.info(f\"Opci\u00f3n en el \u00edndice '{n_option}' seleccionada correctamente en el dropdown\")\n        else:\n            raise ValueError(\"Debe proporcionar un valor v\u00e1lido para seleccionar una opci\u00f3n en el dropdown\")\n\n        # Esperar el tiempo especificado si se proporcion\u00f3\n        if wait_time &gt; 0:\n            time.sleep(wait_time)\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al seleccionar la opci\u00f3n del dropdown: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-hacer_clic","title":"Funci\u00f3n <code>hacer_clic</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_13","title":"Prop\u00f3sito","text":"<p>Localiza un elemento en una p\u00e1gina web mediante un tipo de localizador, realiza clic en \u00e9l y, opcionalmente, interact\u00faa con un campo de entrada configurando un valor.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_13","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para la operaci\u00f3n:</li> <li>Localizadores (uno obligatorio):<ul> <li><code>xpath</code> (str): Localizaci\u00f3n del elemento mediante XPath.</li> <li><code>id</code> (str): Identificaci\u00f3n del elemento.</li> <li><code>name</code> (str): Nombre del elemento.</li> <li><code>class_name</code> (str): Clase CSS del elemento.</li> <li><code>css_selector</code> (str): Selector CSS del elemento.</li> <li><code>link_text</code> (str): Texto completo del enlace.</li> <li><code>partial_link_text</code> (str): Texto parcial del enlace.</li> <li><code>tag_name</code> (str): Nombre de la etiqueta del elemento.</li> </ul> </li> <li><code>value</code> (opcional): Valor para ingresar en un campo de entrada.</li> <li><code>wait_time</code> (int, opcional): Tiempo de espera despu\u00e9s de realizar la acci\u00f3n (por defecto: 2 segundos).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_11","title":"Funcionamiento","text":"<ol> <li> <p>Identificaci\u00f3n del elemento:</p> <ul> <li>Determina el tipo y valor del localizador (<code>locator_type</code> y <code>locator_value</code>) a partir de los argumentos proporcionados.</li> <li>Utiliza <code>WebDriverWait</code> para esperar hasta que el elemento sea clickeable.</li> <li>Si no se encuentra el elemento, registra una advertencia en el log y retorna <code>None</code>.</li> </ul> </li> <li> <p>Clic en el elemento:</p> <ul> <li>Realiza clic en el elemento localizado y espera el tiempo especificado (<code>wait_time</code>).</li> </ul> </li> <li> <p>Interacci\u00f3n con campos de entrada:</p> <ul> <li>Si el elemento es un campo de entrada (<code>&lt;input&gt;</code>) y se proporciona un valor (<code>value</code>):</li> <li>Si el valor es un objeto <code>datetime</code>, lo formatea como cadena (<code>'%d/%m/%Y'</code>).</li> <li>Limpia el campo, establece el valor, y registra la acci\u00f3n en el log.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas.</li> <li>Registra los errores en el log y retorna sin lanzar la excepci\u00f3n.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_12","title":"Salida","text":"<ul> <li><code>None</code>: Si el elemento no se encuentra o hay un error durante la operaci\u00f3n.</li> <li>Registra en el log el estado del proceso (clic o interacci\u00f3n con el campo de entrada).</li> </ul> <pre><code>def hacer_clic(driver, **kwargs):\n    try:\n        locator_type = None\n        locator_value = None\n        input_value = kwargs.get('value')\n        wait_time = kwargs.get('wait_time', 2)  # Manejar 'wait_time' con valor por defecto\n\n        for key, value in kwargs.items():\n            if key == 'value':\n                continue  # Ya se maneja 'value' arriba\n            elif key in ['xpath', 'id', 'name', 'class_name', 'css_selector', 'link_text', 'partial_link_text', 'tag_name']:\n                locator_type = key\n                locator_value = value\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos\")\n\n        # Convertir el identificador a By adecuado\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n        try:\n            elemento = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((by_mapping[locator_type], locator_value)))\n        except TimeoutException:\n            elemento = None\n            logging.warning(f\"Elemento no encontrado: {locator_type} = {locator_value}\")\n            #FINALIZAR retornando error\n            return None\n\n        logging.info(f\"Elemento localizado, realizando clic en {locator_type}: {locator_value}\")\n        elemento.click()\n        time.sleep(wait_time)\n        logging.info(f\"Clic realizado correctamente en {locator_type}: {locator_value}\")\n\n        # Si el elemento es un input y se proporcion\u00f3 un valor de fecha, formatear correctamente\n        if elemento.tag_name == 'input' and input_value is not None:\n            if isinstance(input_value, datetime):\n                input_value = input_value.strftime('%d/%m/%Y')  # Convertir datetime a cadena de texto\n\n            elemento.clear()\n            elemento.send_keys(input_value)\n            logging.info(f\"Valor '{input_value}' establecido en el elemento input correctamente\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        # logging.error(f\"Error al intentar hacer clic en el elemento con {locator_type}: {locator_value} - Detalles: {e}\")\n        logging.error(f\"Error al intentar hacer clic en el elemento con {locator_type}: {locator_value} \")\n        #raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-hacer_clic_modal","title":"Funci\u00f3n <code>hacer_clic_modal</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_14","title":"Prop\u00f3sito","text":"<p>Interact\u00faa con un modal en una p\u00e1gina web controlada por Selenium, localizando y haciendo clic en un elemento dentro del modal. Opcionalmente, permite realizar acciones adicionales dentro del modal y gestionar cambios de contexto hacia y desde un <code>iframe</code>.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_14","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Par\u00e1metros clave para la operaci\u00f3n:</li> <li><code>xpath_modal</code> (str, requerido): Localizador del modal usando XPath.</li> <li><code>iframe</code> (str, opcional): Nombre del iframe al que cambiar el contexto.</li> <li><code>elementos</code> (list, opcional): Lista de pasos adicionales a ejecutar dentro del modal. Cada paso debe estar definido como una tupla <code>(nombre_paso, funci\u00f3n, par\u00e1metros)</code>.</li> <li>Localizadores: <ul> <li><code>xpath</code> (str): XPath del elemento a interactuar.</li> <li><code>id</code>, <code>name</code>, <code>class_name</code>, <code>css_selector</code>, <code>link_text</code>, <code>partial_link_text</code>, <code>tag_name</code> (str): Alternativas de localizaci\u00f3n del elemento.</li> </ul> </li> <li><code>wait_time</code> (int, opcional): Tiempo de espera en segundos tras realizar la acci\u00f3n (por defecto: <code>2</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_12","title":"Funcionamiento","text":"<ol> <li> <p>Cambio al <code>iframe</code> (opcional):</p> <ul> <li>Si se proporciona un <code>iframe</code>, cambia al contexto del iframe indicado antes de realizar otras operaciones.</li> </ul> </li> <li> <p>Localizaci\u00f3n del modal:</p> <ul> <li>Espera hasta que el modal especificado por <code>xpath_modal</code> sea visible en el DOM.</li> </ul> </li> <li> <p>Interacci\u00f3n con el elemento:</p> <ul> <li>Localiza y verifica la clicabilidad del elemento especificado.</li> <li>Intenta realizar clic est\u00e1ndar. Si no es posible, utiliza JavaScript como alternativa.</li> </ul> </li> <li> <p>Ejecuci\u00f3n de pasos adicionales (opcional):</p> <ul> <li>Si se proporcionan pasos adicionales, los ejecuta dentro del contexto del modal.</li> </ul> </li> <li> <p>Cambio de regreso al contexto principal (si aplica):</p> <ul> <li>Regresa al contenido principal si se cambi\u00f3 previamente al <code>iframe</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura y registra excepciones relacionadas con tiempo de espera, elementos no interactuables o referencias obsoletas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_13","title":"Salida","text":"<ul> <li>No retorna valores. Realiza las acciones en el modal y registra el estado del proceso en el log.</li> </ul> <pre><code>def hacer_clic_modal(driver, **kwargs):\n    try:\n        modal_locator_type = None\n        modal_locator_value = kwargs.get('xpath_modal')\n        iframe_name = kwargs.get('iframe')\n        locator_type = None\n        locator_value = None\n        wait_time = kwargs.get('wait_time', 2)\n        elementos = kwargs.get('elementos', [])\n\n        if iframe_name:\n            try:\n                logging.info(f\"Cambiando al iframe con nombre: {iframe_name}\")\n                WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.NAME, iframe_name)))\n                logging.info(\"Cambio al iframe exitoso\")\n            except TimeoutException:\n                logging.error(f\"No se pudo cambiar al iframe '{iframe_name}' dentro del tiempo l\u00edmite.\")\n                raise\n\n        for key, value in kwargs.items():\n            if key in ['xpath_modal', 'iframe', 'elementos']:\n                continue\n            elif value is not None and key in ['xpath', 'id', 'name', 'class_name', 'css_selector', 'link_text', 'partial_link_text', 'tag_name']:\n                locator_type = key\n                locator_value = value\n\n        if not modal_locator_value:\n            raise ValueError(\"Debe proporcionar un localizador v\u00e1lido para el modal (por ejemplo, 'xpath_modal')\")\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos para el elemento de clic\")\n\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n\n        logging.info(f\"Esperando la visibilidad del modal con xpath: {modal_locator_value}\")\n        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, modal_locator_value)))\n        logging.info(f\"Modal localizado y visible: {modal_locator_value}\")\n\n        elemento = WebDriverWait(driver, 20).until(EC.visibility_of_element_located((by_mapping[locator_type], locator_value)))\n        WebDriverWait(driver, 20).until(EC.element_to_be_clickable((by_mapping[locator_type], locator_value)))\n        logging.info(f\"Elemento localizado dentro del modal, realizando clic en {locator_type}: {locator_value}\")\n\n        try:\n            elemento.click()\n        except ElementNotInteractableException:\n            logging.warning(f\"No se pudo hacer clic en {locator_type}: {locator_value} con el m\u00e9todo est\u00e1ndar, intentando con JavaScript\")\n            driver.execute_script(\"arguments[0].click();\", elemento)\n\n        time.sleep(wait_time)\n        logging.info(f\"Clic realizado correctamente en {locator_type}: {locator_value}\")\n\n        if elementos:\n            for step_name, step_function, params in elementos:\n                logging.info(f\"Ejecutando el paso adicional dentro del modal: {step_name}\")\n                step_function(driver=driver, **params)\n\n        if iframe_name:\n            driver.switch_to.default_content()\n            logging.info(\"Cambio de regreso al contenido principal realizado\")\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al intentar hacer clic en el elemento dentro del modal con {locator_type}: {locator_value} - Detalles: {e}\")\n        raise\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-hacer_clic_por_coordenadas","title":"Funci\u00f3n <code>hacer_clic_por_coordenadas</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_15","title":"Prop\u00f3sito","text":"<p>Realiza un clic en un elemento ubicado en una p\u00e1gina web controlada por Selenium utilizando sus coordenadas. Es \u00fatil cuando los clics tradicionales no son efectivos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_15","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para configurar la operaci\u00f3n:</li> <li>Localizadores (uno obligatorio):<ul> <li><code>xpath</code> (str): Localizador del elemento mediante XPath.</li> <li><code>id</code>, <code>name</code>, <code>class_name</code>, <code>css_selector</code>, <code>link_text</code>, <code>partial_link_text</code>, <code>tag_name</code> (str): Alternativas de localizaci\u00f3n del elemento.</li> </ul> </li> <li><code>iframe</code> (str, opcional): Nombre del iframe para cambiar el contexto antes de la operaci\u00f3n.</li> <li><code>wait_time</code> (int, opcional): Tiempo en segundos para esperar despu\u00e9s del clic (por defecto: <code>2</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_13","title":"Funcionamiento","text":"<ol> <li> <p>Cambio de contexto al iframe (opcional):</p> <ul> <li>Cambia al contexto del iframe especificado, si se proporciona.</li> </ul> </li> <li> <p>Localizaci\u00f3n del elemento:</p> <ul> <li>Encuentra el elemento utilizando el tipo y valor del localizador proporcionado.</li> <li>Asegura que el elemento est\u00e9 visible en la ventana mediante <code>scrollIntoView</code>.</li> </ul> </li> <li> <p>Obtenci\u00f3n de coordenadas:</p> <ul> <li>Calcula las coordenadas centrales del elemento (<code>x</code> y <code>y</code>) usando su posici\u00f3n y tama\u00f1o.</li> </ul> </li> <li> <p>Clic en las coordenadas:</p> <ul> <li>Usa <code>ActionChains</code> para mover el puntero a las coordenadas calculadas y realizar el clic.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o referencias obsoletas, registrando el error en el log.</li> </ul> </li> <li> <p>Restauraci\u00f3n del contexto principal:</p> <ul> <li>Si se cambi\u00f3 al iframe, regresa al contexto principal al finalizar.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_14","title":"Salida","text":"<ul> <li>No retorna valores. Realiza el clic en las coordenadas especificadas y registra en el log el estado del proceso.</li> </ul> <pre><code>def hacer_clic_por_coordenadas(driver, **kwargs):\n    try:\n        logging.info(\"Iniciando el proceso de clic por coordenadas\")\n\n        locator_type = None\n        locator_value = None\n        iframe = kwargs.get('iframe')  # Nombre del iframe si es necesario cambiar de contexto\n        wait_time = kwargs.get('wait_time', 2)  # Manejar 'wait_time' con valor por defecto\n\n        # Obtener el localizador del elemento de clic\n        for key, value in kwargs.items():\n            if key in ['iframe', 'wait_time']:\n                continue  # Omitir estos par\u00e1metros\n            elif value is not None and key in ['xpath', 'id', 'name', 'class_name', 'css_selector', 'link_text', 'partial_link_text', 'tag_name']:\n                locator_type = key\n                locator_value = value\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos\")\n\n        # Cambiar al contexto del iframe si se proporciona\n        if iframe:\n            logging.info(f\"Cambiando al contexto del iframe: {iframe}\")\n            WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it((By.NAME, iframe)))\n            logging.info(\"Cambio al contexto del iframe completado\")\n\n        # Convertir el identificador a By adecuado\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n\n        logging.info(f\"Esperando la presencia del elemento {locator_type}: {locator_value}\")\n        elemento = WebDriverWait(driver, 10).until(EC.presence_of_element_located((by_mapping[locator_type], locator_value)))\n        logging.info(f\"Elemento encontrado: {locator_type} = {locator_value}\")\n\n        driver.execute_script(\"arguments[0].scrollIntoView(true);\", elemento)  # Asegurarse de que el elemento est\u00e9 visible en la ventana\n        logging.info(\"Elemento desplazado a la vista\")\n\n        # Obtener las coordenadas del elemento\n        location = elemento.location\n        size = elemento.size\n        x, y = location['x'] + (size['width'] / 2), location['y'] + (size['height'] / 2)\n\n        logging.info(f\"Coordenadas obtenidas - X: {x}, Y: {y}\")\n\n        # Hacer clic en las coordenadas usando ActionChains\n        action = ActionChains(driver)\n        action.move_by_offset(x, y).click().perform()\n\n        logging.info(\"Clic realizado en las coordenadas especificadas\")\n        time.sleep(wait_time)\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al intentar hacer clic en el elemento por coordenadas: {e}\")\n        raise\n    finally:\n        # Volver al contexto principal si se cambi\u00f3 al iframe\n        if iframe:\n            driver.switch_to.default_content()\n            logging.info(\"Cambio al contexto principal despu\u00e9s de la operaci\u00f3n en el iframe\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funciones-actualizar_nombre_archivo-y-verificar_descarga","title":"Funciones <code>actualizar_nombre_archivo</code> y <code>verificar_descarga</code>","text":""},{"location":"00.etl/Utils/Funciones/#funcion-actualizar_nombre_archivo","title":"Funci\u00f3n <code>actualizar_nombre_archivo</code>","text":"<p>Prop\u00f3sito:</p> <p>Actualiza el objeto global <code>proceso_info</code> con el nombre del archivo procesado.</p> <p>Entradas:</p> <ul> <li><code>nombre_archivo</code> (str): Nombre del archivo descargado.</li> </ul> <p>Funcionamiento:</p> <ul> <li>Establece el valor de <code>'nombre_archivo'</code> en el objeto global <code>proceso_info</code>.</li> <li>Registra en el log el nombre actualizado.</li> </ul> <p>Salida:</p> <ul> <li>No retorna valores. Actualiza el objeto global y registra el cambio.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcion-verificar_descarga","title":"Funci\u00f3n <code>verificar_descarga</code>","text":"<p>Prop\u00f3sito:</p> <p>Verifica si un archivo espec\u00edfico se ha descargado correctamente dentro de un tiempo de espera m\u00e1ximo.</p> <p>Entradas:</p> <ul> <li><code>nombre_archivo</code> (str): Nombre del archivo a verificar.</li> <li><code>download_dir</code> (str, opcional): Directorio de descargas donde se busca el archivo (por defecto: <code>DOWNLOAD_DIR</code>).</li> <li><code>timeout</code> (int, opcional): Tiempo m\u00e1ximo de espera en segundos (por defecto: <code>10</code>).</li> </ul> <p>Funcionamiento:</p> <ol> <li>Construye la ruta completa del archivo a partir del nombre y el directorio de descargas.</li> <li>Monitorea la existencia del archivo en el sistema de archivos:<ul> <li>Si el archivo no se encuentra dentro del tiempo especificado, devuelve <code>False</code>.</li> <li>Si el archivo aparece, registra el \u00e9xito y devuelve <code>True</code>.</li> </ul> </li> </ol> <p>Salida:</p> <ul> <li><code>True</code>: Si el archivo se descarg\u00f3 correctamente.</li> <li><code>False</code>: Si el archivo no se descarg\u00f3 dentro del tiempo especificado.</li> </ul> <pre><code># Objeto global para almacenar detalles del proceso\nproceso_info = {\n    'nombre_archivo': None\n}\n\n# Funci\u00f3n que actualiza el objeto con el nombre del archivo descargado\ndef actualizar_nombre_archivo(nombre_archivo):\n    proceso_info['nombre_archivo'] = nombre_archivo\n    logging.info(f\"Nombre del archivo actualizado en el objeto: {nombre_archivo}\")\n\n\ndef verificar_descarga(nombre_archivo, download_dir=DOWNLOAD_DIR, timeout=10):\n    \"\"\"\n    Verifica que un archivo con el nombre especificado se descargue correctamente en el \n    directorio de descargas, con un tiempo de espera m\u00e1ximo.\n    \"\"\"\n    file_path = os.path.join(download_dir, nombre_archivo)\n    logging.info(f\"Verificando la presencia del archivo: {nombre_archivo}\")\n\n    start_time = time.time()\n    while not os.path.exists(file_path):\n        if time.time() - start_time &gt; timeout:\n            # logging.warning(f\"Tiempo de espera agotado para la descarga del archivo: {nombre_archivo}\")\n            return False  # Indica que el archivo no se descarg\u00f3 en el tiempo dado\n        logging.info(\"Esperando la descarga...\")\n        time.sleep(1)\n\n    logging.info(f\"Archivo {nombre_archivo} descargado correctamente.\")\n    return True  # Indica que el archivo se descarg\u00f3 con \u00e9xito\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-cargar_archivo_excel","title":"Funci\u00f3n <code>cargar_archivo_excel</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_16","title":"Prop\u00f3sito","text":"<p>Carga un archivo Excel desde el directorio de descargas y lo convierte en un DataFrame de pandas. Utiliza el nombre del archivo almacenado en el objeto global <code>proceso_info</code>.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_16","title":"Entradas","text":"<ul> <li>No recibe argumentos. Utiliza el nombre del archivo desde el objeto global <code>proceso_info</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_14","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n del nombre del archivo:</p> <ul> <li>Recupera el nombre del archivo desde <code>proceso_info['nombre_archivo']</code>.</li> <li>Si el nombre no est\u00e1 definido, registra una advertencia y retorna <code>None</code>.</li> </ul> </li> <li> <p>Cargado del archivo:</p> <ul> <li>Construye la ruta completa del archivo a partir del nombre y el directorio <code>DOWNLOAD_DIR</code>.</li> <li>Verifica si el archivo existe en la ruta:</li> <li>Si existe, lo carga en un DataFrame de pandas.</li> <li>Si no existe, registra una advertencia y retorna <code>None</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones durante la carga y registra el error en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_15","title":"Salida","text":"<ul> <li><code>pandas.DataFrame</code>: DataFrame cargado desde el archivo Excel si la operaci\u00f3n es exitosa.</li> <li><code>None</code>: Si el archivo no se encuentra o ocurre un error.</li> </ul> <pre><code>def cargar_archivo_excel():\n    \"\"\"\n    Carga un archivo de Excel desde el directorio de descargas en un DataFrame de pandas.\n    Utiliza el nombre del archivo almacenado en el objeto global.\n    \"\"\"\n    nombre_archivo = proceso_info.get('nombre_archivo')\n    if not nombre_archivo:\n        logging.warning(\"El nombre del archivo no se ha registrado en el objeto global.\")\n        return None\n\n    file_path = os.path.join(DOWNLOAD_DIR, nombre_archivo)\n    try:\n        if os.path.exists(file_path):\n            logging.info(f\"Cargando archivo {nombre_archivo} en DataFrame.\")\n            return pd.read_excel(file_path)\n        else:\n            logging.warning(f\"Archivo {nombre_archivo} no encontrado.\")\n            return None\n    except Exception as e:\n        logging.error(f\"Error al cargar el archivo {nombre_archivo} en DataFrame: {e}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-generar_fechas","title":"Funci\u00f3n <code>generar_fechas</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_17","title":"Prop\u00f3sito","text":"<p>Genera un diccionario con rangos de fechas por a\u00f1o o semestre, seg\u00fan los par\u00e1metros proporcionados.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_17","title":"Entradas","text":"<ul> <li><code>inicio</code> (int, opcional): A\u00f1o inicial del rango (requerido si <code>semestre</code> es <code>False</code>).</li> <li><code>fin</code> (int, opcional): A\u00f1o final del rango (requerido si <code>semestre</code> es <code>False</code>).</li> <li><code>semestre</code> (bool, opcional): Si es <code>True</code>, genera fechas del semestre anterior basado en la fecha actual (por defecto: <code>False</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_15","title":"Funcionamiento","text":"<ol> <li> <p>Generaci\u00f3n basada en semestres:</p> <ul> <li>Si <code>semestre</code> es <code>True</code>:</li> <li>Determina el semestre anterior con base en el mes actual:<ul> <li>Enero a junio: Devuelve el rango del segundo semestre del a\u00f1o anterior.</li> <li>Julio a diciembre: Devuelve el rango del primer semestre del a\u00f1o actual.</li> </ul> </li> <li>Retorna un diccionario con un \u00fanico rango de fechas.</li> </ul> </li> <li> <p>Generaci\u00f3n por a\u00f1os:</p> <ul> <li>Si <code>semestre</code> es <code>False</code>:</li> <li>Itera desde el a\u00f1o <code>inicio</code> hasta el a\u00f1o <code>fin</code> (inclusive).</li> <li>Genera un diccionario donde cada clave es el \u00edndice del a\u00f1o en el rango, y los valores son los rangos de fechas para todo el a\u00f1o.</li> </ul> </li> <li> <p>Registro de informaci\u00f3n:</p> <ul> <li>Registra en el log los rangos generados.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_16","title":"Salida","text":"<ul> <li><code>dict</code>: Diccionario con rangos de fechas. Formato:<ul> <li>Por semestre: <code>{1: {'desde': 'fecha_inicio', 'hasta': 'fecha_fin'}}</code></li> <li>Por a\u00f1os: <code>{\u00edndice: {'desde': '01-01-a\u00f1o', 'hasta': '12-31-a\u00f1o'}}</code></li> </ul> </li> </ul> <pre><code># Funci\u00f3n para generar el diccionario de fechas entre dos a\u00f1os dados\ndef generar_fechas(inicio=None, fin=None, semestre=False):\n\n    if semestre:\n        # Verificar si se solicita el semestre\n        #mes fecha actual\n        mes = datetime.now().month\n        #a\u00f1o fecha actual\n        a\u00f1o = datetime.now().year\n\n        if mes &lt;= 6:\n            # Primer semestre: el semestre anterior es el segundo semestre del a\u00f1o anterior\n            return {\n                1: {'desde': f'07-01-{a\u00f1o-1}', 'hasta': f'12-31-{a\u00f1o-1}'}\n            }\n        else:\n            # Segundo semestre: el semestre anterior es el primer semestre del mismo a\u00f1o\n            return {\n                1: {'desde': f'01-01-{a\u00f1o}', 'hasta': f'06-30-{a\u00f1o}'}\n            }\n\n\n    fechas = {}\n    for a\u00f1o in range(inicio, fin + 1):\n        fechas[a\u00f1o - inicio + 1] = {'desde': f'01-01-{a\u00f1o}', 'hasta': f'12-31-{a\u00f1o}'}\n    logging.info(f\"fechas: {json.dumps(fechas, indent=4)}\")\n    # input(\"Presione Enter para continuar...\")\n    return fechas\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-generar_periodos_cortes","title":"Funci\u00f3n <code>generar_periodos_cortes</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_18","title":"Prop\u00f3sito","text":"<p>Genera un diccionario que contiene periodos de tiempo divididos en cortes mensuales dentro de un rango de a\u00f1os.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_18","title":"Entradas","text":"<ul> <li><code>anio_inicio</code> (int): A\u00f1o inicial del rango.</li> <li><code>anio_fin</code> (int): A\u00f1o final del rango.</li> <li><code>tipo</code> (int, opcional): N\u00famero de cortes por a\u00f1o (por defecto: <code>2</code>). Debe estar entre <code>1</code> y <code>12</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_16","title":"Funcionamiento","text":"<ol> <li> <p>Validaci\u00f3n del par\u00e1metro <code>tipo</code>:</p> <ul> <li>Asegura que el valor de <code>tipo</code> sea un n\u00famero entre 1 y 12.</li> <li>Lanza un <code>ValueError</code> si el valor est\u00e1 fuera del rango.</li> </ul> </li> <li> <p>C\u00e1lculo de periodos:</p> <ul> <li>Divide los meses del a\u00f1o en cortes iguales seg\u00fan el valor de <code>tipo</code>:</li> <li>Calcula la cantidad de meses por periodo: <code>meses_por_periodo = 12 // tipo</code>.</li> <li>Itera sobre los a\u00f1os entre <code>anio_inicio</code> y <code>anio_fin</code> (inclusive).</li> <li>Dentro de cada a\u00f1o:</li> <li>Calcula el mes de inicio y el mes final de cada periodo.</li> <li>Genera los rangos de fechas, considerando el \u00faltimo d\u00eda del mes (<code>dias_del_mes</code>).</li> </ul> </li> <li> <p>Estructura del diccionario:</p> <ul> <li>Cada clave es un n\u00famero de periodo incremental.</li> <li>Cada valor es un rango de fechas con formato:</li> <li><code>desde</code> (str): Fecha de inicio del periodo (formato <code>MM-DD-AAAA</code>).</li> <li><code>hasta</code> (str): Fecha de fin del periodo (formato <code>MM-DD-AAAA</code>).</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Registra en el log los periodos generados.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_17","title":"Salida","text":"<ul> <li><code>dict</code>: Diccionario con los periodos generados. Ejemplo:   <pre><code>{\n    1: {'desde': '01-01-2023', 'hasta': '06-30-2023'},\n    2: {'desde': '07-01-2023', 'hasta': '12-31-2023'}\n}\n</code></pre></li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_3","title":"Consideraciones","text":"<ul> <li>La funci\u00f3n usa <code>dias_del_mes</code> para calcular correctamente el \u00faltimo d\u00eda de cada mes.</li> </ul> <pre><code>def generar_periodos_cortes(anio_inicio=None, anio_fin=None, tipo=2):\n    if tipo &lt; 1 or tipo &gt; 12:\n        raise ValueError(\"El par\u00e1metro 'tipo' debe ser un n\u00famero entre 1 y 12.\")\n\n    fechas = {}\n    periodo = 1\n    meses_por_periodo = 12 // tipo\n\n    for anio in range(anio_inicio, anio_fin + 1):\n        for i in range(tipo):\n            mes_inicio = i * meses_por_periodo + 1\n            mes_fin = (i + 1) * meses_por_periodo\n            fechas[periodo] = {\n                'desde': f\"{mes_inicio:02d}-01-{anio}\",\n                'hasta': f\"{mes_fin:02d}-{dias_del_mes(mes_fin, anio):02d}-{anio}\"\n            }\n            periodo += 1\n    logging.info(f\"fechas: {json.dumps(fechas, indent=4)}\")\n    return fechas\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-cola_descargar","title":"Funci\u00f3n <code>cola_descargar</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_19","title":"Prop\u00f3sito","text":"<p>Inicia la descarga de un archivo desde un bot\u00f3n en una p\u00e1gina web, espera la finalizaci\u00f3n de la descarga, y renombra el archivo m\u00e1s reciente en el directorio de descargas con un nombre basado en una opci\u00f3n especificada.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_19","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>archivo</code> (str): Nombre base para renombrar el archivo descargado.</li> <li><code>download_dir</code> (str): Ruta del directorio donde se descargan los archivos.</li> <li><code>opcion</code> (str): Valor adicional que se a\u00f1adir\u00e1 al nombre del archivo al renombrarlo.</li> <li><code>kwargs</code> (dict, opcional): Argumentos adicionales:</li> <li><code>wait_time</code> (int): Tiempo de espera en segundos para la descarga (por defecto: <code>10</code>).</li> <li><code>xpath_omitir</code> (str): XPath de un bot\u00f3n opcional para omitir antes de iniciar la descarga.</li> <li>Localizadores del bot\u00f3n de descarga (<code>xpath</code>, <code>id</code>, <code>name</code>, etc.).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_17","title":"Funcionamiento","text":"<ol> <li> <p>Omisi\u00f3n de popups:</p> <ul> <li>Si se proporciona <code>xpath_omitir</code>, busca el elemento correspondiente y hace clic en \u00e9l si est\u00e1 presente.</li> </ul> </li> <li> <p>Configuraci\u00f3n del bot\u00f3n de descarga:</p> <ul> <li>Determina el tipo y valor del localizador para identificar el bot\u00f3n de descarga.</li> <li>Espera hasta que el bot\u00f3n sea clickeable y realiza clic.</li> </ul> </li> <li> <p>Monitoreo del directorio de descargas:</p> <ul> <li>Compara el estado del directorio antes y despu\u00e9s de la descarga.</li> <li>Espera hasta 10 segundos para detectar un nuevo archivo.</li> </ul> </li> <li> <p>Renombrar archivo descargado:</p> <ul> <li>Identifica el archivo nuevo m\u00e1s reciente en el directorio.</li> <li>Renombra el archivo con el formato: <code>nombre_base_opcion.extension</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o no interactuables, y registra el error en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_18","title":"Salida","text":"<ul> <li><code>True</code>: Si el archivo se descarg\u00f3 y renombr\u00f3 correctamente.</li> <li><code>False</code>: Si no se detect\u00f3 el archivo dentro del tiempo especificado o hubo un error durante el proceso.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_4","title":"Consideraciones","text":"<ul> <li>Aseg\u00farese de proporcionar un localizador v\u00e1lido (<code>locator_type</code> y <code>locator_value</code>) para identificar el bot\u00f3n de descarga.</li> <li>La funci\u00f3n maneja escenarios donde puede ser necesario omitir popups antes de descargar.</li> <li>Dise\u00f1ada para flujos de automatizaci\u00f3n que requieren monitorear y renombrar archivos descargados din\u00e1micamente.</li> </ul> <pre><code>def cola_descargar(driver, archivo, download_dir, opcion, **kwargs):\n    \"\"\"\n    Inicia la descarga de un archivo, espera el tiempo especificado y renombra\n    el archivo m\u00e1s reciente en la carpeta de descargas con el nombre y la opci\u00f3n especificados.\n    \"\"\"\n    try:\n        # Verificar si se pasa un 'xpath_omitir' y, en caso afirmativo, si el elemento existe\n        xpath_omitir = kwargs.get('xpath_omitir')\n        if xpath_omitir:\n            try:\n                omitir_button = driver.find_element(By.XPATH, xpath_omitir)\n                omitir_button.click()\n                logging.info(f\"Omitido el clic en el bot\u00f3n de descarga: {xpath_omitir}\")\n                return True\n            except NoSuchElementException:\n                logging.info(f\"Elemento con xpath_omitir '{xpath_omitir}' no encontrado, continuando con la descarga\")\n\n        # Configuraci\u00f3n de los par\u00e1metros de localizaci\u00f3n del bot\u00f3n de descarga\n        locator_type = None\n        locator_value = None\n        wait_time = kwargs.get('wait_time', 10)\n\n        for key, value in kwargs.items():\n            if key not in {'wait_time', 'archivo', 'xpath_omitir'} and value:\n                locator_type = key\n                locator_value = value\n\n        if not locator_type or not locator_value:\n            raise ValueError(\"Debe proporcionar un 'locator_type' y un 'locator_value' v\u00e1lidos\")\n\n        by_mapping = {\n            'xpath': By.XPATH,\n            'id': By.ID,\n            'name': By.NAME,\n            'class_name': By.CLASS_NAME,\n            'css_selector': By.CSS_SELECTOR,\n            'link_text': By.LINK_TEXT,\n            'partial_link_text': By.PARTIAL_LINK_TEXT,\n            'tag_name': By.TAG_NAME\n        }\n        # Obtener el n\u00famero de archivos antes de la descarga\n        archivos_antes = set(os.listdir(download_dir))\n\n        logging.info(f\"Esperando la presencia del elemento {locator_type}: {locator_value}\")\n        download_button = WebDriverWait(driver, 10).until(\n            EC.element_to_be_clickable((by_mapping[locator_type], locator_value))\n        )\n        download_button.click()\n        logging.info(f\"Bot\u00f3n de descarga clickeado, esperando {wait_time} segundos para la descarga\")\n        time.sleep(10)\n\n        # Esperar a que un archivo nuevo aparezca en el directorio\n        for _ in range(10):\n            archivos_despues = set(os.listdir(download_dir))\n            archivos_nuevos = archivos_despues - archivos_antes  # Detectar nuevos archivos\n            if archivos_nuevos:\n                # Obtener el archivo nuevo m\u00e1s reciente\n                latest_file = max(archivos_nuevos, key=lambda f: os.path.getctime(os.path.join(download_dir, f)))\n                latest_file_path = os.path.join(download_dir, latest_file)\n\n                # Renombrar el archivo descargado\n                base_name, extension = os.path.splitext(archivo)\n                new_file_path = os.path.join(download_dir, f'{base_name}_{opcion}{extension}')\n                os.rename(latest_file_path, new_file_path)\n                logging.info(f\"Archivo renombrado a: {new_file_path}\")\n                return True\n            logging.info(\"Esperando que la descarga se complete...\")\n            time.sleep(1)\n\n        logging.error(\"No se encontr\u00f3 el archivo descargado.\")\n        return False\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al intentar descargar el archivo con {locator_type}: {locator_value} - Detalles: {e}\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-seleccionar_opcion_custom_dropdown","title":"Funci\u00f3n <code>seleccionar_opcion_custom_dropdown</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_20","title":"Prop\u00f3sito","text":"<p>Selecciona una opci\u00f3n espec\u00edfica en un men\u00fa desplegable personalizado (custom dropdown) en una p\u00e1gina web controlada por Selenium.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_20","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>kwargs</code> (dict): Argumentos clave para configurar la operaci\u00f3n:</li> <li><code>xpath</code> (str): Localizaci\u00f3n del bot\u00f3n del men\u00fa desplegable.</li> <li><code>option</code> (str): Texto de la opci\u00f3n que se desea seleccionar.</li> <li><code>wait_time</code> (int, opcional): Tiempo en segundos para esperar despu\u00e9s de desplegar el men\u00fa (por defecto: <code>2</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_18","title":"Funcionamiento","text":"<ol> <li> <p>Verificaci\u00f3n de par\u00e1metros:</p> <ul> <li>Verifica que se hayan proporcionado un <code>xpath</code> v\u00e1lido para el bot\u00f3n del dropdown y un <code>option</code> para seleccionar.</li> </ul> </li> <li> <p>Desplegar el men\u00fa:</p> <ul> <li>Localiza el bot\u00f3n del men\u00fa usando <code>xpath</code>.</li> <li>Hace clic para desplegar el men\u00fa.</li> </ul> </li> <li> <p>Seleccionar la opci\u00f3n:</p> <ul> <li>Intenta localizar y seleccionar la opci\u00f3n utilizando texto exacto.</li> <li>Si no encuentra la opci\u00f3n, intenta con una b\u00fasqueda flexible que utiliza <code>contains</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones relacionadas con tiempo de espera, elementos no encontrados o no interactuables, y registra el error en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_19","title":"Salida","text":"<ul> <li>No retorna valores. Realiza la acci\u00f3n en el men\u00fa desplegable y registra el estado del proceso en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_5","title":"Consideraciones","text":"<ul> <li>Dise\u00f1ada para trabajar con men\u00fas desplegables personalizados que contienen opciones identificadas por texto.</li> <li>Incluye una l\u00f3gica de respaldo para localizar opciones cuando no se encuentran con texto exacto.</li> </ul> <pre><code>def seleccionar_opcion_custom_dropdown(driver, **kwargs):\n    try:\n        logging.info(\"Seleccionando opci\u00f3n en un men\u00fa desplegable personalizado\")\n        xpath_boton = kwargs.get('xpath')\n        option_value = kwargs.get('option')\n        wait_time = kwargs.get('wait_time', 2)  # Manejar 'wait_time' con valor por defecto\n\n        if not xpath_boton or not option_value:\n            raise ValueError(\"Debe proporcionar 'xpath' y 'option' v\u00e1lidos\")\n\n        # Hacer clic en el bot\u00f3n para desplegar el men\u00fa\n        logging.info(f\"Haciendo clic en el men\u00fa desplegable con xpath: {xpath_boton}\")\n        dropdown = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath_boton)))\n        dropdown.click()\n        time.sleep(2)  # Pausa breve para que el men\u00fa se despliegue completamente\n\n        try:\n            # Seleccionar la opci\u00f3n del men\u00fa desplegable\n            logging.info(f\"Seleccionando la opci\u00f3n '{option_value}' en el men\u00fa desplegable\")\n\n            # Intentar buscar la opci\u00f3n con texto exacto\n            opcion = WebDriverWait(driver, 10).until(\n                EC.element_to_be_clickable((By.XPATH, f\"//ul[contains(@class, 'dropdown-menu')]//span[text()='{option_value}']\"))\n            )\n            opcion.click()\n            logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente.\")\n        except TimeoutException:\n            logging.warning(f\"No se encontr\u00f3 la opci\u00f3n '{option_value}' con texto exacto. Intentando con b\u00fasqueda flexible...\")\n            try:\n                # Intentar con b\u00fasqueda m\u00e1s flexible usando `contains`\n                opcion = WebDriverWait(driver, 10).until(\n                    EC.element_to_be_clickable((By.XPATH, f\"//ul[contains(@class, 'dropdown-menu')]//span[contains(normalize-space(text()), '{option_value}')]\"))\n                )\n                opcion.click()\n                logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente usando b\u00fasqueda flexible.\")\n            except Exception as e:\n                logging.error(f\"Error al seleccionar la opci\u00f3n '{option_value}': {e}\")\n        logging.info(f\"Opci\u00f3n '{option_value}' seleccionada correctamente en el men\u00fa desplegable\")\n\n    except (TimeoutException, NoSuchElementException, ElementNotInteractableException, StaleElementReferenceException) as e:\n        logging.error(f\"Error al seleccionar la opci\u00f3n en el men\u00fa desplegable personalizado: {e}\")\n        #raise\n</code></pre> <p><code>listar_archivos_descargados</code> lista y registra los nombres de los archivos presentes en el directorio de descargas especificado.</p> <pre><code>def listar_archivos_descargados():\n    archivos = os.listdir(DOWNLOAD_DIR)\n    logging.info(f\"Archivos en la carpeta '{DOWNLOAD_DIR}': {archivos}\")\n    return archivos\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-obtener_elementos_dropdown","title":"Funci\u00f3n <code>obtener_elementos_dropdown</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_21","title":"Prop\u00f3sito","text":"<p>Extrae las opciones disponibles en un men\u00fa desplegable (<code>dropdown</code>) en una p\u00e1gina web controlada por Selenium.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_21","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia del controlador Selenium.</li> <li><code>boton_xpath</code> (str): XPath del bot\u00f3n para abrir el men\u00fa desplegable.</li> <li><code>elementos_xpath</code> (str): XPath del contenedor que contiene las opciones del men\u00fa.</li> <li><code>nivel</code> (int): Nivel o jerarqu\u00eda del dropdown para fines de registro y depuraci\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_19","title":"Funcionamiento","text":"<ol> <li> <p>Interacci\u00f3n con el bot\u00f3n del dropdown:</p> <ul> <li>Espera hasta que el bot\u00f3n est\u00e9 visible y clickeable.</li> <li>Hace scroll para asegurar que el bot\u00f3n est\u00e9 en la vista.</li> <li>Usa JavaScript para forzar el clic en caso necesario.</li> </ul> </li> <li> <p>Extracci\u00f3n de opciones:</p> <ul> <li>Espera a que el contenedor de opciones est\u00e9 visible.</li> <li>Encuentra todos los elementos <code>&lt;li&gt;</code> dentro del contenedor <code>&lt;ul&gt;</code>.</li> <li>Para cada elemento:</li> <li>Obtiene el texto de la opci\u00f3n.</li> <li>Filtra opciones vac\u00edas o con texto no deseado como \"Seleccione\".</li> <li>Agrega el texto al resultado.</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Registra en el log el nivel del dropdown y las opciones extra\u00eddas.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura excepciones por tiempo de espera o errores generales, las registra y devuelve una lista vac\u00eda.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_20","title":"Salida","text":"<ul> <li><code>list</code>: Lista de textos de las opciones extra\u00eddas del men\u00fa desplegable.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_6","title":"Consideraciones","text":"<ul> <li>Excluye opciones con texto vac\u00edo o \"Seleccione\".</li> <li>Dise\u00f1ada para manejar men\u00fas desplegables con opciones representadas como elementos <code>&lt;li&gt;</code>.</li> <li>El par\u00e1metro <code>nivel</code> permite rastrear jerarqu\u00edas de dropdowns en procesos complejos.</li> </ul> <pre><code>@log_step_decorator(\"Obtener elementos dropdown\")\ndef obtener_elementos_dropdown(driver, boton_xpath, elementos_xpath, nivel):\n\n    opciones = []\n    try:\n        logging.info(f\"[Nivel {nivel}] Intentando abrir dropdown en: {boton_xpath}\")\n\n        # Esperar hasta que el bot\u00f3n est\u00e9 habilitado y visible en la pantalla\n        boton_dropdown = WebDriverWait(driver, 15).until(\n            EC.element_to_be_clickable((By.XPATH, boton_xpath))\n        )\n\n        # Intentar hacer scroll para que el bot\u00f3n sea visible\n        driver.execute_script(\"arguments[0].scrollIntoView();\", boton_dropdown)\n\n        # Usar JavaScript para forzar el clic si es necesario\n        driver.execute_script(\"arguments[0].click();\", boton_dropdown)\n        time.sleep(1)  # Pausa breve para permitir la expansi\u00f3n completa del dropdown\n\n        # Esperar a que el contenedor de opciones del dropdown est\u00e9 visible\n        elementos_ul = WebDriverWait(driver, 15).until(\n            EC.visibility_of_element_located((By.XPATH, elementos_xpath))\n        )\n\n        # Obtener todos los elementos &lt;li&gt; visibles dentro de `ul`\n        elementos_li = elementos_ul.find_elements(By.XPATH, \"./li\")\n\n        # Extraer y almacenar el texto y XPath de cada opci\u00f3n en el dropdown\n        for index, elemento in enumerate(elementos_li):\n            try:\n                # Obtener el texto de la opci\u00f3n\n                texto_opcion = elemento.find_element(By.XPATH, \".//span[@class='text']\").text.strip()\n\n                if texto_opcion and texto_opcion != \"Seleccione\":  # Excluir texto vac\u00edo y \"Seleccione\"\n                    # Construir un XPath \u00fanico para el elemento basado en su posici\u00f3n (index)\n                    xpath_opcion = f\"{elementos_xpath}/li[{index + 1}]/a\"  # Ejemplo de XPath con \u00edndice\n\n                    # Agregar el texto y el XPath al resultado\n                    opciones.append(texto_opcion)                    \n                    # _opciones.append({\"text\": texto_opcion,\"xpath\": xpath_opcion})\n            except Exception as inner_e:\n                logging.warning(f\"[Nivel {nivel}] No se pudo obtener el texto de una opci\u00f3n: {inner_e}\")\n\n        logging.info(f\"[Nivel {nivel}] Opciones obtenidas: {opciones}\")\n        return opciones\n\n    except TimeoutException:\n        logging.error(f\"[Nivel {nivel}] El dropdown no se pudo abrir debido a un Timeout.\")\n        return []\n    except Exception as e:\n        logging.error(f\"[Nivel {nivel}] Error al obtener elementos del dropdown: {e}\")\n        return []\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-eliminar_archivos_anteriores","title":"Funci\u00f3n <code>eliminar_archivos_anteriores</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_22","title":"Prop\u00f3sito","text":"<p>Elimina todos los archivos en un directorio de descargas que coincidan con un nombre base especificado, incluyendo variantes como <code>'Nombre'</code>, <code>'Nombre (1)'</code>, <code>'Nombre (2)'</code>, etc.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_22","title":"Entradas","text":"<ul> <li><code>nombre_archivo</code> (str): Nombre base del archivo cuyos duplicados o variantes deben ser eliminados.</li> <li><code>download_dir</code> (str): Ruta del directorio donde se buscar\u00e1n los archivos a eliminar.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_20","title":"Funcionamiento","text":"<ol> <li> <p>Construcci\u00f3n del patr\u00f3n de coincidencia:</p> <ul> <li>Extrae el nombre base del archivo sin extensi\u00f3n.</li> <li>Crea un patr\u00f3n de expresi\u00f3n regular que coincida con el nombre base seguido de cualquier texto adicional (como <code>' (1)'</code>) y cualquier extensi\u00f3n.</li> </ul> </li> <li> <p>B\u00fasqueda y eliminaci\u00f3n de archivos:</p> <ul> <li>Itera sobre los archivos en el directorio especificado.</li> <li>Si un archivo coincide con el patr\u00f3n, lo elimina y registra la acci\u00f3n en el log.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_21","title":"Salida","text":"<ul> <li>No retorna valores. Realiza acciones directamente en el sistema de archivos y registra los archivos eliminados en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#consideraciones_7","title":"Consideraciones","text":"<ul> <li>Dise\u00f1ada para gestionar directorios de descargas en flujos automatizados, asegurando que no queden residuos de ejecuciones anteriores.</li> <li>Verifica patrones de archivos con extensiones gen\u00e9ricas (<code>.txt</code>, <code>.xlsx</code>, etc.). Si se espera un tipo espec\u00edfico, aseg\u00farese de que el nombre y patr\u00f3n sean precisos.</li> </ul> <pre><code>def eliminar_archivos_anteriores(nombre_archivo, download_dir):\n    \"\"\"\n    Elimina todos los archivos en el directorio de descargas que coincidan con el nombre\n    especificado o patrones como 'Nombre', 'Nombre (1)', 'Nombre (2)', etc.\n\n    Args:\n        nombre_archivo (str): El nombre base del archivo a eliminar.\n        download_dir (str): El directorio donde se buscar\u00e1n los archivos.\n    \"\"\"\n    nombre_base = os.path.splitext(nombre_archivo)[0]  # Remueve la extensi\u00f3n del archivo\n    patron = re.compile(rf\"^{re.escape(nombre_base)}.*\\.[a-zA-Z0-9]+$\")  # Coincidir con cualquier extensi\u00f3n de archivo\n\n    for archivo in os.listdir(download_dir):\n        if patron.match(archivo):\n            os.remove(os.path.join(download_dir, archivo))\n            logging.info(f\"Archivo eliminado: {archivo} en {download_dir}\")\n</code></pre> <p><code>limpiar_carpeta</code> elimina todos los archivos con extensiones <code>.csv</code>, <code>.xls</code> y <code>.xlsx</code> del directorio de descargas especificado (<code>download_dir</code>). Utiliza un decorador para registrar el inicio y finalizaci\u00f3n del proceso, adem\u00e1s de registrar cada archivo eliminado en el log.</p> <pre><code>@log_step_decorator(\"Limpiar carpeta de descargas\")\ndef limpiar_carpeta(download_dir):\n    #Eliminar todos los archivos (scv,xls,xlsx) de la carpeta \n    for archivo in os.listdir(download_dir):\n        if archivo.endswith(\".csv\") or archivo.endswith(\".xls\") or archivo.endswith(\".xlsx\"):\n            os.remove(os.path.join(download_dir, archivo))\n            logging.info(f\"Archivo eliminado: {archivo} en {download_dir}\")    \n</code></pre> <p><code>verificar_y_hacer_clic</code> localiza un elemento en la p\u00e1gina mediante un XPath proporcionado, realiza un clic en \u00e9l y env\u00eda un texto seguido de la tecla Enter. Si el elemento no se encuentra, captura la excepci\u00f3n y contin\u00faa sin interrupciones. Retorna <code>True</code> si la acci\u00f3n fue exitosa; de lo contrario, no retorna valor.</p> <pre><code>def verificar_y_hacer_clic(driver, xpath, wait_time=2):\n    \"\"\"\n    Verifica si un elemento con el XPath especificado existe.\n    Si existe, hace clic en \u00e9l.\n\n    :param driver: instancia del controlador de Selenium.\n    :param xpath: cadena XPath del elemento a verificar y hacer clic.\n    :param wait_time: tiempo opcional para esperar despu\u00e9s del clic.\n    \"\"\"\n    try:\n        elemento = driver.find_element(By.XPATH, xpath)\n        elemento.click()\n        elemento.send_keys(\"texto para enviar\" + Keys.ENTER)        \n        print(f\"Elemento encontrado y clic realizado en el XPath: {xpath}\")\n        time.sleep(wait_time)\n        return True\n    except NoSuchElementException:\n        print(f\"Elemento no encontrado en el XPath: {xpath}, continuando.\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-pre_procesamiento","title":"Funci\u00f3n <code>pre_procesamiento</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_23","title":"Prop\u00f3sito","text":"<p>Automatiza la selecci\u00f3n de opciones en un men\u00fa desplegable, filtra opciones no deseadas y gestiona las descargas asociadas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_23","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Controlador Selenium utilizado para interactuar con la p\u00e1gina.</li> <li><code>download_dir</code> (str): Ruta al directorio donde se guardan las descargas.</li> <li><code>id_descargar</code> (str): ID del bot\u00f3n que inicia la descarga.</li> <li><code>nombre_archivo</code> (str): Nombre base para los archivos descargados.</li> <li><code>nombre_archivo_completo</code> (str): Nombre completo esperado del archivo descargado.</li> <li><code>xpath_boton</code> (str): XPath del bot\u00f3n para desplegar el men\u00fa.</li> <li><code>xpath_contenedor_opciones</code> (str): XPath del contenedor que contiene las opciones del men\u00fa.</li> <li><code>tipo</code> (str): Tipo de descarga:</li> <li><code>modal</code>: Descargas que requieren interacci\u00f3n con un modal.</li> <li><code>directa</code>: Descargas iniciadas directamente desde el men\u00fa desplegable.</li> <li><code>excluir_opciones</code> (list): Lista de opciones que no deben ser procesadas.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_21","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n de opciones:</p> <ul> <li>Utiliza la funci\u00f3n <code>obtener_elementos_dropdown</code> para extraer todas las opciones visibles en el men\u00fa desplegable.</li> </ul> </li> <li> <p>Filtrado de opciones:</p> <ul> <li>Excluye las opciones especificadas en <code>excluir_opciones</code>.</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Registra las opciones finales que ser\u00e1n procesadas en el log para facilitar la depuraci\u00f3n.</li> </ul> </li> <li> <p>Procesamiento de cada opci\u00f3n:</p> <ul> <li>Itera sobre las opciones filtradas y llama a la funci\u00f3n <code>procesar_opciones_descarga</code>:</li> <li>Gestiona la interacci\u00f3n con el men\u00fa desplegable.</li> <li>Inicia las descargas seg\u00fan el tipo especificado (<code>modal</code> o <code>directa</code>).</li> <li>Asegura el manejo adecuado de archivos en el directorio de descargas.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_22","title":"Salida","text":"<ul> <li>No retorna valores. Realiza las acciones de selecci\u00f3n, exclusi\u00f3n y descarga autom\u00e1ticamente.</li> </ul> <pre><code>def pre_procesamiento(driver, \n                download_dir,\n                id_descargar,\n                nombre_archivo,\n                nombre_archivo_completo,\n                xpath_boton,\n                xpath_contenedor_opciones,\n                tipo,\n                excluir_opciones):\n\n    opciones = obtener_elementos_dropdown(driver, xpath_boton, xpath_contenedor_opciones, nivel=1)\n    opciones = [opcion for opcion in opciones if opcion not in excluir_opciones]\n    logging.info(f\"Opciones a seleccionar: {opciones}\")\n\n    procesar_opciones_descarga(\n        driver=driver,\n        opciones=opciones,\n        xpath_boton=xpath_boton,\n        id_descargar=id_descargar,\n        nombre_archivo=nombre_archivo,\n        nombre_archivo_completo=nombre_archivo_completo,\n        download_dir=download_dir,\n        wait_time=2,\n        tipo=tipo,\n        xpath_omitir='/html/body/div[10]'\n    )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-pre_procesamiento_periodo","title":"Funci\u00f3n <code>pre_procesamiento_periodo</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_24","title":"Prop\u00f3sito","text":"<p>Automatiza la selecci\u00f3n de per\u00edodos espec\u00edficos desde un men\u00fa desplegable, filtra los per\u00edodos disponibles en funci\u00f3n de un conjunto de a\u00f1os, y gestiona las descargas asociadas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_24","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Controlador Selenium para manejar la interacci\u00f3n con la p\u00e1gina.</li> <li><code>download_dir</code> (str): Directorio donde se guardar\u00e1n las descargas.</li> <li><code>id_descargar</code> (str): ID del bot\u00f3n de descarga.</li> <li><code>nombre_archivo</code> (str): Nombre base del archivo descargado.</li> <li><code>nombre_archivo_completo</code> (str): Nombre completo esperado del archivo descargado.</li> <li><code>xpath_boton</code> (str): XPath del bot\u00f3n para desplegar el men\u00fa de per\u00edodos.</li> <li><code>xpath_contenedor_opciones</code> (str): XPath del contenedor de opciones del men\u00fa desplegable.</li> <li><code>tipo</code> (str): Tipo de descarga:</li> <li><code>modal</code>: Descargas que requieren interacci\u00f3n con un modal.</li> <li><code>directa</code>: Descargas iniciadas directamente desde el men\u00fa desplegable.</li> <li><code>items_opciones</code> (list): Lista de a\u00f1os a generar como per\u00edodos para consulta (e.g., <code>[2019, 2020]</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_22","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n de opciones del dropdown:</p> <ul> <li>Llama a <code>obtener_elementos_dropdown</code> para extraer todas las opciones disponibles en el men\u00fa desplegable.</li> </ul> </li> <li> <p>Generaci\u00f3n de per\u00edodos de consulta:</p> <ul> <li>Genera una lista de per\u00edodos en formato de cadena (<code>\"2019\"</code>, <code>\"2020\"</code>) a partir de los a\u00f1os en <code>items_opciones</code>.</li> <li>Guarda los per\u00edodos generados en un diccionario para registro y depuraci\u00f3n.</li> </ul> </li> <li> <p>Filtrado de per\u00edodos:</p> <ul> <li>Filtra las opciones del dropdown, reteniendo \u00fanicamente aquellas que comiencen con los per\u00edodos generados.</li> </ul> </li> <li> <p>Registro de opciones:</p> <ul> <li>Guarda las opciones filtradas en un diccionario y las registra en el log.</li> </ul> </li> <li> <p>Procesamiento de opciones:</p> <ul> <li>Llama a <code>procesar_opciones_descarga</code> para gestionar la interacci\u00f3n con el dropdown y realizar las descargas para cada per\u00edodo filtrado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_23","title":"Salida","text":"<ul> <li>No retorna valores. Realiza las acciones de selecci\u00f3n, filtrado y descarga autom\u00e1ticamente.</li> </ul> <pre><code>def pre_procesamiento_periodo(driver, \n                download_dir,\n                id_descargar,\n                nombre_archivo,\n                nombre_archivo_completo,\n                xpath_boton,\n                xpath_contenedor_opciones,\n                tipo,\n                items_opciones):\n\n    opciones = obtener_elementos_dropdown(driver, xpath_boton, xpath_contenedor_opciones, nivel=1)\n\n    # Obtener los periodos disponibles en el dropdown\n    _periodos = opciones\n\n    # Generar lista de periodos de consulta (2019, 2020)\n    consulta = items_opciones\n    periodos_generados = [f\"{year}\" for year in consulta]\n    guardar_diccionario(periodos_generados, 'periodos_generados')\n    # Filtrar solo los per\u00edodos que comiencen con los valores generados\n    opciones = [\n        periodo for periodo in _periodos \n        if any(periodo.startswith(generado) for generado in periodos_generados)\n    ]\n    guardar_diccionario(opciones, 'opciones')    \n    logging.info(f\"Opciones a seleccionar: {opciones}\")\n\n    procesar_opciones_descarga(\n        driver=driver,\n        opciones=opciones,\n        xpath_boton=xpath_boton,\n        id_descargar=id_descargar,\n        nombre_archivo=nombre_archivo,\n        nombre_archivo_completo=nombre_archivo_completo,\n        download_dir=download_dir,\n        wait_time=2,\n        tipo=tipo,\n        xpath_omitir='/html/body/div[10]'\n    )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-get_data_range","title":"Funci\u00f3n <code>get_data_range</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_25","title":"Prop\u00f3sito","text":"<p>Obtiene un rango de datos de una hoja de un archivo Excel y devuelve los valores contenidos en ese rango.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_25","title":"Entradas","text":"<ul> <li><code>file_path</code> (str): Ruta del archivo Excel a procesar.</li> <li><code>sheet_index</code> (int): \u00cdndice de la hoja en el archivo Excel de donde se extraer\u00e1n los datos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_23","title":"Funcionamiento","text":"<ol> <li> <p>Carga del archivo:</p> <ul> <li>Abre el archivo Excel en modo de solo lectura (<code>data_only=True</code>).</li> </ul> </li> <li> <p>Validaci\u00f3n del \u00edndice de la hoja:</p> <ul> <li>Verifica que el \u00edndice proporcionado est\u00e9 dentro del rango v\u00e1lido de hojas disponibles.</li> <li>Lanza un <code>IndexError</code> si el \u00edndice no es v\u00e1lido.</li> </ul> </li> <li> <p>Detecci\u00f3n del rango de datos:</p> <ul> <li>Itera sobre las celdas de la hoja para identificar los l\u00edmites m\u00ednimos y m\u00e1ximos (filas y columnas) donde existen valores no vac\u00edos.</li> </ul> </li> <li> <p>Extracci\u00f3n de datos:</p> <ul> <li>Con los l\u00edmites detectados (<code>min_row</code>, <code>min_col</code>, <code>max_row</code>, <code>max_col</code>), se genera un rango.</li> <li>Crea un iterador con los valores dentro del rango utilizando <code>sheet.iter_rows</code> con <code>values_only=True</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_24","title":"Salida","text":"<ul> <li><code>data</code> (iterable): Valores contenidos en el rango detectado de la hoja Excel.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-rango-detectado","title":"Ejemplo de rango detectado","text":"<p>Si el rango de datos encontrado es: - Desde la fila 2, columna 1 - Hasta la fila 10, columna 5</p> <p>El rango corresponde a las celdas <code>A2:E10</code> en el archivo Excel.</p> <pre><code>def get_data_range(file_path, sheet_index):\n    # Cargar el archivo de Excel\n    workbook = load_workbook(file_path, data_only=True)\n\n    # Verificar si el \u00edndice de la hoja es v\u00e1lido\n    if sheet_index &lt; 0 or sheet_index &gt;= len(workbook.sheetnames):\n        raise IndexError(f\"\u00cdndice de hoja inv\u00e1lido. Hay {len(workbook.sheetnames)} hojas disponibles.\")\n\n    # Obtener la hoja por \u00edndice\n    sheet_name = workbook.sheetnames[sheet_index]\n    sheet = workbook[sheet_name]\n\n    # Variables para rastrear los l\u00edmites del rango\n    min_row, min_col = None, None\n    max_row, max_col = None, None\n\n    # Recorrer las celdas para encontrar el rango de datos\n    for row in sheet.iter_rows():\n        for cell in row:\n            if cell.value is not None:\n                if min_row is None or cell.row &lt; min_row:\n                    min_row = cell.row\n                if max_row is None or cell.row &gt; max_row:\n                    max_row = cell.row\n                if min_col is None or cell.column &lt; min_col:\n                    min_col = cell.column\n                if max_col is None or cell.column &gt; max_col:\n                    max_col = cell.column\n\n    # return min_row, min_col, max_row, max_col\n    sheet_index = 0  # \u00cdndice de la hoja (empezando en 0)\n\n    print(f\"Rango de datos: Desde la fila {min_row}, columna {min_col} hasta la fila {max_row}, columna {max_col}\")\n    # Crear un DataFrame con el rango de datos obtenido\n    workbook = load_workbook(file_path, data_only=True)\n    sheet = workbook[workbook.sheetnames[sheet_index]]\n    data = sheet.iter_rows(min_row=min_row, max_row=max_row, min_col=min_col, max_col=max_col, values_only=True)\n    return data\n</code></pre> <p><code>guardar_diccionario</code> Guarda los valores de un diccionario o lista en un archivo CSV, creando una columna llamada Item para almacenar los datos.</p> <pre><code>def guardar_diccionario(diccionario, nombre_archivo):\n    # Almacenar periodos en un Archivo, en modo de pruebas\n    df = pd.DataFrame(diccionario, columns=['Item'])\n    df.to_csv(f'{nombre_archivo}.csv', index=False)\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-crea_dataframes","title":"Funci\u00f3n <code>crea_dataframes</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_26","title":"Prop\u00f3sito","text":"<p>Procesa una lista de archivos Excel desde una carpeta, carg\u00e1ndolos en pandas DataFrames, y aplica renombramientos espec\u00edficos de columnas para cada archivo.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_26","title":"Entradas","text":"<ul> <li><code>files</code> (list): Lista de nombres de archivos Excel a procesar.</li> <li><code>upload_folder</code> (str): Ruta de la carpeta donde se encuentran los archivos Excel.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_24","title":"Funcionamiento","text":"<ol> <li> <p>Carga de archivos Excel:</p> <ul> <li>Itera sobre los nombres de los archivos en <code>files</code>.</li> <li>Carga cada archivo Excel desde la carpeta especificada (<code>upload_folder</code>) en un DataFrame y lo almacena en el diccionario <code>data_frames</code>, donde la clave es el nombre del archivo.</li> </ul> </li> <li> <p>Renombramiento de columnas:</p> <ul> <li>Aplica renombramientos espec\u00edficos para las columnas de cada archivo:</li> <li>Estandariza los nombres de columnas relevantes como <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>FECHA</code>, y otros campos seg\u00fan la estructura particular de cada archivo.</li> <li>Se realiza un mapeo detallado de las columnas para cada archivo en <code>files[0]</code>, <code>files[1]</code>, <code>files[2]</code> y <code>files[3]</code>.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve un diccionario <code>data_frames</code> donde:</li> <li>Las claves son los nombres de los archivos.</li> <li>Los valores son los DataFrames procesados.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_25","title":"Salida","text":"<ul> <li><code>data_frames</code> (dict): Diccionario con los DataFrames procesados y renombrados.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-estructura-de-salida","title":"Ejemplo de estructura de salida","text":"<p>Si <code>files</code> contiene: <pre><code>['archivo1.xlsx', 'archivo2.xlsx']\n</code></pre> El diccionario <code>data_frames</code> tendr\u00e1: <pre><code>{\n    'archivo1.xlsx': DataFrame con columnas renombradas,\n    'archivo2.xlsx': DataFrame con columnas renombradas\n}\n</code></pre></p> <pre><code>################################################################################################################################\n@log_step_decorator(\"Procesar dataframes\")\ndef crea_dataframes(files, upload_folder):\n    data_frames = {}\n    for file in files:\n        data_frames[file] = pd.read_excel( upload_folder + \"\\\\\" + file )\n        #columnsTotal = columnsTotal + data_frames[file].columns.tolist()\n\n\n\n    data_frames[files[0]] = data_frames[files[0]].rename(columns={'TIPO DE IDENTIFICACION': 'TIPO_DOCUMENTO',\n                                                                'IDENTIFICACION': 'DOCUMENTO',\n                                                                'FECHA DEL PRODUCTO O SERVICIO PRESTADO': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO'})\n    data_frames[files[1]] = data_frames[files[1]].rename(columns={'TIPO DE IDENTIFICACION': 'TIPO_DOCUMENTO',\n                                                                'IDENTIFICACION': 'DOCUMENTO',\n                                                                'FECHA DEL PRODUCTO O SERVICIO PRESTADO': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO',\n                                                                'TELEFONO CELULAR':'TELEFONO'})\n    data_frames[files[2]] = data_frames[files[2]].rename(columns={'TIPO DE IDENTIFICACION DEL BENEFICIARIO': 'TIPO_DOCUMENTO',\n                                                                'IDENTIFICACION DEL BENEFICIARIO': 'DOCUMENTO',\n                                                                'FECHA DEL PRODUCTO O SERVICIO PRESTADO': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL NINIO O NINIA BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO',\n                                                                'PRIMER NOMBRE DEL BENEFICIARIO':'PRIMER NOMBRE',\n                                                                'PRIMER APELLIDO DEL BENEFICIARIO':'PRIMER APELLIDO',\n                                                                'SEGUNDO NOMBRE DEL BENEFICIARIO':'SEGUNDO NOMBRE',\n                                                                'SEGUNDO APELLIDO DEL BENEFICIARIO':'SEGUNDO APELLIDO',\n                                                                'PRIMER NOMBRE PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'PRIMER NOMBRE DEL ACUDIENTE', \n                                                                'SEGUNDO NOMBRE PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'SEGUNDO NOMBRE DEL ACUDIENTE',\n                                                                'PRIMER APELLIDO PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'PRIMER APELLIDO DEL ACUDIENTE',\n                                                                'SEGUNDO APELLIDO PADRE/MADRE  RESPONSABLE DEL BENEFICIARIO':'SEGUNDO APELLIDO DEL ACUDIENTE',\n                                                                'EDAD DEL BENEFICIARIO':'EDAD',\n                                                                'TELEFONO\\xa0DEL ESTUDIANTE':'TELEFONO',\n                                                                'UBICACION DEL\\xa0 ESTABLECIMIENTO EDUCATIVO DEL ESTUDIANTE':'UBICACION DEL ESTABLECIMIENTO EDUCATIVO DEL ESTUDIANTE'})\n    data_frames[files[3]] = data_frames[files[3]].rename(columns={'TIPO DE IDENTIFICACION DEL BENEFICIARIO': 'TIPO_DOCUMENTO',\n                                                                'NUMERODEIDENTIFICACION': 'DOCUMENTO',\n                                                                'FECHA DE VINCULACION A PAIN': 'FECHA',\n                                                                'GRUPO ETNICO A QUE PERTENECE EL NINIO O NINIA BENEFICIARIO (A)':'GRUPO ETNICO BENEFICIARIO',\n                                                                'FECHA DE NACIMIENTO(DD/MM/AAAA)':'FECHA NACIMIENTO',\n                                                                'SEGUNDO\\xa0APELLIDO DEL ACUDIENTE':'SEGUNDO APELLIDO DEL ACUDIENTE',\n                                                                'SEGUNDO\\xa0NOMBRE DEL ACUDIENTE':'SEGUNDO NOMBRE DEL ACUDIENTE',\n                                                                'UBICACION DEL\\xa0 ESTABLECIMIENTO EDUCATIVO DEL BENEFICIARIO':'UBICACION DEL ESTABLECIMIENTO EDUCATIVO DEL BENEFICIARIO'})\n    return data_frames\n</code></pre> <p><code>normalize</code> elimina las tildes de un texto, reemplaz\u00e1ndolas por sus versiones sin acento, tanto en min\u00fasculas como en may\u00fasculas.</p> <pre><code>def normalize(s):\n    replacements = (\n        (\"\u00e1\", \"a\"),\n        (\"\u00e9\", \"e\"),\n        (\"\u00ed\", \"i\"),\n        (\"\u00f3\", \"o\"),\n        (\"\u00fa\", \"u\"),\n    )\n    for a, b in replacements:\n        s = s.replace(a, b).replace(a.upper(), b.upper())\n    return s\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-presave","title":"Funci\u00f3n <code>PreSave</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_27","title":"Prop\u00f3sito","text":"<p>Realiza un preprocesamiento de columnas en un DataFrame, limpiando y normalizando valores textuales, y opcionalmente eliminando signos de puntuaci\u00f3n espec\u00edficos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_27","title":"Entradas","text":"<ul> <li><code>df</code> (DataFrame): DataFrame original que se desea procesar.</li> <li><code>columnList</code> (list): Lista de columnas del DataFrame que ser\u00e1n procesadas.</li> <li><code>signs</code> (bool, opcional): Si es <code>True</code>, elimina signos de puntuaci\u00f3n como <code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code> de las columnas. Por defecto: <code>False</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_25","title":"Funcionamiento","text":"<ol> <li> <p>Copiar el DataFrame:</p> <ul> <li>Crea una copia del DataFrame original para evitar modificaciones en el objeto original.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n:</p> <ul> <li>Reemplazos espec\u00edficos:<ul> <li>Convierte <code>\\xf1</code> a <code>ni</code> (e.g., \"\u00f1\" a \"ni\").</li> <li>Convierte <code>\\xD1</code> a <code>NI</code> (e.g., \"\u00d1\" a \"NI\").</li> <li>Sustituye caracteres no rompibles (<code>\\u00A0</code>) por espacios.</li> </ul> </li> <li>Eliminaci\u00f3n de espacios:<ul> <li>Reemplaza espacios dobles por simples.</li> <li>Elimina espacios al inicio y final de las cadenas.</li> </ul> </li> <li>Normalizaci\u00f3n de texto:<ul> <li>Convierte los valores a cadenas en may\u00fasculas.</li> <li>Aplica la funci\u00f3n <code>normalize</code> para eliminar tildes.</li> <li>Reemplaza comas por espacios.</li> </ul> </li> <li>Gesti\u00f3n de valores nulos:<ul> <li>Sustituye valores <code>\"NAN\"</code> por <code>np.nan</code>.</li> </ul> </li> </ul> </li> <li> <p>Eliminaci\u00f3n de signos (opcional):</p> <ul> <li>Si <code>signs=True</code>, elimina signos de puntuaci\u00f3n (<code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code>) utilizando expresiones regulares.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_26","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame con las columnas especificadas procesadas y normalizadas.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-uso","title":"Ejemplo de uso","text":"<p>Si la entrada es: <pre><code>df = pd.DataFrame({'col1': ['\u00a1Hola, mundo!', '\u00bfQu\u00e9 tal?']})\nPreSave(df, ['col1'], signs=True)\n</code></pre></p> <p>La salida ser\u00e1: <pre><code>      col1\n0    HOLA MUNDO\n1    QUE TAL\n</code></pre></p> <pre><code>def PreSave(df , columnList, signs = False):\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xf1', 'ni'))\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xD1', 'NI'))\n\n    datfra = df.copy()\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xf1', 'ni'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xD1', 'NI'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('\\u00A0', ' '))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('  ', ' '))\n    datfra[columnList] = datfra[columnList].astype(str)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.strip())\n    datfra[columnList] = datfra[columnList].map(normalize)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.upper())\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(',', ' '))\n    datfra[columnList] = datfra[columnList].replace('NAN', np.nan)\n\n    if signs == True:\n        for col in columnList:\n            try:\n                datfra[col] = datfra[col].apply(lambda x: re.sub(r'[\u00a1!?\u00bf]', '', x) )\n            except:\n                print('Not Signs fixed for '+ col)\n\n    return datfra\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funciones-sorted_answer-y-fix_table_answers","title":"Funciones <code>Sorted_Answer</code> y <code>Fix_Table_Answers</code>","text":""},{"location":"00.etl/Utils/Funciones/#funcion-sorted_answer","title":"Funci\u00f3n <code>Sorted_Answer</code>","text":"<p>Prop\u00f3sito: Ordena alfab\u00e9ticamente las respuestas separadas por punto y coma (<code>;</code>) dentro de una cadena. Elimina valores vac\u00edos si existen.</p> <p>Entradas:</p> <ul> <li><code>x</code> (str o NaN): Cadena de texto con respuestas separadas por punto y coma o un valor nulo.</li> </ul> <p>Funcionamiento:</p> <ol> <li>Verifica si la entrada es nula (<code>NaN</code>). Si es as\u00ed, retorna la entrada sin cambios.</li> <li>Divide la cadena en una lista utilizando <code>split(';')</code>.</li> <li>Si hay m\u00e1s de una respuesta:<ul> <li>Ordena alfab\u00e9ticamente la lista.</li> <li>Elimina entradas vac\u00edas si est\u00e1n presentes.</li> <li>Reconstruye la cadena uniendo los valores con <code>;</code>.</li> </ul> </li> <li>Retorna la cadena ordenada o la entrada original si no se cumplen las condiciones.</li> </ol> <p>Salida:</p> <ul> <li><code>str</code> o <code>NaN</code>: Cadena con las respuestas ordenadas alfab\u00e9ticamente o valor original si no hay cambios.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcion-fix_table_answers","title":"Funci\u00f3n <code>Fix_Table_Answers</code>","text":"<p>Prop\u00f3sito:</p> <p>Aplica la funci\u00f3n <code>Sorted_Answer</code> a una columna espec\u00edfica de un DataFrame, actualizando la columna con las respuestas ordenadas.</p> <pre><code>def Sorted_Answer(x):\n    if pd.isnull(x):\n        return x\n    p =  x.split(';') \n    if len(p) &gt; 1:\n        p = sorted(p)\n        p.remove('')\n        p = ';'.join(p)\n        return p\n    return x\n\n\ndef Fix_Table_Answers( table , column_name ):\n    table['RESPUESTA_LIST'] = table[column_name].apply( lambda x: Sorted_Answer(x) )\n    table = table.drop([ column_name ], axis=1)\n    table = table.rename(columns={'RESPUESTA_LIST': column_name})\n\n    return table\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-fix_id_type_caract","title":"Funci\u00f3n <code>Fix_Id_Type_Caract</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_28","title":"Prop\u00f3sito","text":"<p>Estandariza y transforma diferentes representaciones de tipos de identificaci\u00f3n en c\u00f3digos abreviados predefinidos.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_28","title":"Entradas","text":"<ul> <li><code>id_type</code> (str): Cadena de texto que representa un tipo de identificaci\u00f3n, como \"CEDULA DE CIUDADANIA\" o \"TARJETA DE IDENTIDAD\".</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_26","title":"Funcionamiento","text":"<ol> <li>Utiliza una estructura <code>match-case</code> para comparar el valor de <code>id_type</code> con diferentes representaciones conocidas.</li> <li>Devuelve el c\u00f3digo abreviado correspondiente:<ul> <li><code>CC</code>: C\u00e9dula de ciudadan\u00eda.</li> <li><code>TI</code>: Tarjeta de identidad.</li> <li><code>RC</code>: Registro civil.</li> <li><code>PE</code>: Permiso especial de permanencia.</li> <li><code>PPT</code>: Permiso especial de permanencia temporal.</li> <li><code>PA</code>: Pasaporte.</li> <li><code>CE</code>: Identificaci\u00f3n extranjera.</li> <li><code>NI</code>: NIT.</li> <li><code>NA</code>: No aplica o no reconocido.</li> </ul> </li> <li>Si no encuentra una coincidencia, devuelve el valor por defecto <code>NA</code>.</li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_27","title":"Salida","text":"<ul> <li><code>str</code>: C\u00f3digo abreviado del tipo de identificaci\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#ejemplo-de-uso_1","title":"Ejemplo de uso","text":"<p>Entrada: <pre><code>Fix_Id_Type_Caract('CEDULA DE CIUDADANIA')\n</code></pre></p> <p>Salida: <pre><code>'CC'\n</code></pre></p> <pre><code>def Fix_Id_Type_Caract(id_type):\n    match id_type:\n        case '1.CEDULA DE CIUDADANIA':\n             return 'CC'\n        case '2.TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3.REGISTRO CIVIL':\n             return 'RC'\n        case '1. CEDULA':\n             return 'CC'\n        case 'TARJETA DE IDENTIDAD':\n             return 'TI'\n        case 'CEDULA DE CIUDADANIA':\n             return 'CC'\n        case 'REGISTRO CIVIL':\n             return 'RC'\n        case '2. TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3. REGISTRO CIVIL':\n             return 'RC'\n        case '9. PERMISO ESPECIAL DE PERMANENCIA (P.E.P)':\n             return 'PE'\n        case '15. PERMISO ESPECIAL DE PERMANENCIA TEMPORAL':\n             return 'PPT'\n        case '11.\\xa0 IDENTIFICACION DADA POR LA SECRETARIA DE EDUCACION':\n             return 'NA'\n        case '14. ID EXTRANJEROS DIFERENTE A LA CEDULA DE EXTRANJERIA (SOLO PARA FONINIEZ)':\n             return 'C1X'\n        case '6. PASAPORTE':\n             return 'PA'\n        case '5. NUIP':\n             return 'NA'\n        case 'CERTIFICADO DE NACIMIENTO':\n             return 'RC'\n        case 'ID EXTRANJERO':\n             return 'CE'   \n        case 'NIT':\n             return 'NI' \n        case 'NONE':\n             return 'NA'         \n        case _:\n            return 'NA'\n\n    return 'NA'\n</code></pre> <p><code>Fix_Id_Type</code> aplica la transformaci\u00f3n de tipos de identificaci\u00f3n en una columna espec\u00edfica de una tabla si el nombre de la tabla es <code>\"CARACTERIZACION\"</code>.</p> <p><code>Truncate_Column</code> trunca el contenido de las columnas especificadas a un m\u00e1ximo de 255 caracteres. Por otro lado, <code>Fix_Datetime</code> convierte valores tipo <code>NaT</code> a un valor predeterminado (<code>2009-01-01 00:00:00</code>) y agrega la hora inicial a fechas v\u00e1lidas. </p> <p>Finalmente, <code>Fix_DatetimeFinal</code> normaliza una columna de fechas en un DataFrame, convirti\u00e9ndolas a formato <code>datetime</code>, estableciendo la hora como 00:00:00, y manejando errores de conversi\u00f3n de forma segura.</p> <pre><code>def Fix_Id_Type( table , typeIdColumn , tableName ):\n    if tableName == 'CARACTERIZACION':\n        table[typeIdColumn] = table[typeIdColumn].apply( Fix_Id_Type_Caract )\n\ndef Truncate_Column( table , columnsToTruncate ):\n    table[columnsToTruncate] = table[columnsToTruncate].astype(str).apply(lambda x: x.str[:255])\n\n\ndef Fix_Datetime(x):\n    if x == 'NaT':\n        return '2009-01-01 00:00:00'    \n    return x + ' 00:00:00'\n\ndef Fix_DatetimeFinal(table, columnName):\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = pd.to_datetime(table[columnName], format='%Y-%m-%d %H:%M:%S', errors='coerce',dayfirst=True)\n    table[columnName] = table[columnName].apply(lambda x: x.replace(hour=0, minute=0, second=0))\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = table[columnName].apply(lambda x: Fix_Datetime(x)   )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-fix_questions","title":"Funci\u00f3n <code>Fix_Questions</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_29","title":"Prop\u00f3sito","text":"<p>Transforma y organiza un DataFrame de respuestas de encuestas, estructur\u00e1ndolo para an\u00e1lisis, incluyendo la identificaci\u00f3n de preguntas relacionadas con NPS (Net Promoter Score).</p>"},{"location":"00.etl/Utils/Funciones/#entradas_29","title":"Entradas","text":"<ul> <li><code>data</code> (DataFrame): DataFrame original con datos de encuestas.</li> <li><code>servicio</code> (str): Nombre del servicio asociado a las encuestas.</li> <li><code>nps</code> (dict): Diccionario que mapea servicios a preguntas relacionadas con NPS.</li> <li><code>filename</code> (str): Nombre del archivo relacionado para fines de registro.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_27","title":"Funcionamiento","text":"<ol> <li> <p>Renombramiento de columnas:</p> <ul> <li>Cambia el nombre de las columnas <code>fecha</code> a <code>FECHA_ENCUESTA</code> y <code>identificacion</code> a <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas:</p> <ul> <li>Busca columnas cuyo nombre comience con <code>\"etapa3\"</code>, que representan preguntas con calificaci\u00f3n.</li> </ul> </li> <li> <p>Filtrado de columnas relevantes:</p> <ul> <li>Redefine el DataFrame para incluir solo las columnas: <code>FECHA_ENCUESTA</code>, <code>DOCUMENTO</code>, y las preguntas identificadas.</li> </ul> </li> <li> <p>Transformaci\u00f3n de datos:</p> <ul> <li>Transforma el DataFrame a un formato largo utilizando <code>melt</code>:<ul> <li><code>id_vars</code>: Columnas constantes (<code>FECHA_ENCUESTA</code> y <code>DOCUMENTO</code>).</li> <li><code>var_name</code>: Nombre de las columnas de preguntas (<code>PREGUNTA</code>).</li> <li><code>value_name</code>: Valores asociados a las preguntas (<code>CALIFICACION</code>).</li> </ul> </li> </ul> </li> <li> <p>Adici\u00f3n de columnas constantes:</p> <ul> <li>Agrega columnas adicionales:<ul> <li><code>SERVICIO</code>: Nombre del servicio.</li> <li><code>TIPO_DOCUMENTO</code>: Fijado como <code>'CC'</code>.</li> <li><code>NPS</code>: Inicializado como <code>'NO'</code>.</li> </ul> </li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas NPS:</p> <ul> <li>Actualiza la columna <code>NPS</code> a <code>'SI'</code> para las preguntas que coinciden con el servicio especificado en el diccionario <code>nps</code>.</li> </ul> </li> <li> <p>Salida del DataFrame:</p> <ul> <li>Registra el nombre del servicio y archivo procesado.</li> <li>Devuelve el DataFrame transformado.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>En caso de error, registra el servicio y archivo no procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_28","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame transformado en formato largo con las siguientes columnas:</li> <li><code>FECHA_ENCUESTA</code></li> <li><code>DOCUMENTO</code></li> <li><code>PREGUNTA</code></li> <li><code>CALIFICACION</code></li> <li><code>SERVICIO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NPS</code></li> </ul> <pre><code>def Fix_Questions( data , servicio , nps, filename):\n\n    try:\n        df = data  \n        #Modificaciones a columnas\n        df = df.rename(columns={'fecha': 'FECHA_ENCUESTA',\n                                'identificacion':'DOCUMENTO'\n                            })\n\n        #Buscar preguntas con nota\n        dfColumns = df.columns.tolist()\n        columnsWithObs = [val for val in dfColumns if val.startswith(\"etapa3\") ]\n\n        #Redefinir columna\n        df = df[['FECHA_ENCUESTA','DOCUMENTO']+columnsWithObs]\n\n        #Modificaciones y transpocision \n        df_unp = df.melt( id_vars = ['FECHA_ENCUESTA','DOCUMENTO'] , var_name=\"PREGUNTA\", value_name=\"CALIFICACION\")\n        df_unp['SERVICIO'] = servicio\n        df_unp['TIPO_DOCUMENTO'] = 'CC'\n        df_unp['NPS'] = 'NO'\n\n\n        df_unp.loc[df_unp[\"PREGUNTA\"] == nps[servicio], \"NPS\"] = 'SI'\n        print('Agregado: ' +  servicio + filename )\n        return df_unp\n    except:\n        print('Sin formato: ' +  servicio + filename )\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-charge_excel_fixed","title":"Funci\u00f3n <code>Charge_Excel_Fixed</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_30","title":"Prop\u00f3sito","text":"<p>Carga un archivo Excel utilizando <code>xlwings</code>, procesa los datos de la primera hoja, y los guarda en un DataFrame despu\u00e9s de limpiar filas y columnas vac\u00edas.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_30","title":"Entradas","text":"<ul> <li><code>ruta</code> (str): Ruta del archivo Excel a cargar.</li> <li><code>dfs</code> (dict): Diccionario donde se almacenar\u00e1 el DataFrame procesado, con el nombre del archivo como clave.</li> <li><code>file</code> (str): Nombre del archivo para usarlo como clave en el diccionario <code>dfs</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_28","title":"Funcionamiento","text":"<ol> <li> <p>Carga del archivo Excel:</p> <ul> <li>Utiliza <code>xlwings</code> para abrir el archivo Excel y seleccionar la primera hoja (<code>sheet[0]</code>).</li> </ul> </li> <li> <p>Lectura de datos:</p> <ul> <li>Lee todos los datos de la hoja utilizando <code>sheet.used_range.value</code>.</li> </ul> </li> <li> <p>Creaci\u00f3n del DataFrame:</p> <ul> <li>Convierte los datos le\u00eddos en un DataFrame de pandas.</li> </ul> </li> <li> <p>Limpieza de datos:</p> <ul> <li>Elimina filas y columnas que est\u00e9n completamente vac\u00edas utilizando <code>dropna()</code>.</li> <li>Resetea el \u00edndice del DataFrame con <code>reset_index(drop=True)</code>.</li> </ul> </li> <li> <p>Ajustes adicionales:</p> <ul> <li>Elimina las primeras dos filas (<code>df.drop([0, 1])</code>).</li> <li>Asigna la primera fila como los nombres de las columnas (<code>df.columns = df.iloc[0]</code>).</li> <li>Elimina la primera fila despu\u00e9s de asignarla como encabezado.</li> </ul> </li> <li> <p>Guardar el DataFrame:</p> <ul> <li>Guarda el DataFrame limpio en el diccionario <code>dfs</code> con el nombre del archivo como clave.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_29","title":"Salida","text":"<ul> <li>No retorna valores. El DataFrame limpio se almacena en el diccionario <code>dfs</code> bajo la clave <code>file</code>.</li> </ul> <pre><code>def Charge_Excel_Fixed( ruta , dfs , file ):\n    # Cargar el archivo Excel utilizando xlwings\n    wb = xw.Book(ruta)\n    sheet = wb.sheets[0]  # Seleccionar la primera hoja\n\n    # Leer todos los datos de la hoja\n    data = sheet.used_range.value\n\n    # Crear un DataFrame a partir de los datos le\u00eddos\n    df = pd.DataFrame(data)\n\n    # Eliminar filas completamente en blanco\n    df.dropna(how='all', inplace=True)\n\n    # Eliminar columnas completamente en blanco\n    df.dropna(axis=1, how='all', inplace=True)\n\n    wb.close()\n\n    df.reset_index(drop=True, inplace=True)\n    df = df.drop([0, 1])\n\n    df.columns = df.iloc[0]  \n    df = df[1:].reset_index(drop=True)  \n\n    dfs[file] = df\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funciones-combine_and_store_unparametro-y-combine_and_store","title":"Funciones <code>Combine_and_store_unparametro</code> y <code>Combine_and_store</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_31","title":"Prop\u00f3sito","text":"<p>Las funciones combinan m\u00faltiples archivos de una carpeta en un solo DataFrame, y opcionalmente, guardan el DataFrame combinado en un archivo Excel en una carpeta de destino especificada.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_31","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL de la carpeta que contiene los archivos a combinar.</li> <li><code>download_folder</code> (str, opcional): Ruta del directorio donde se guardar\u00e1 el archivo Excel combinado. Si es <code>None</code>, el DataFrame no se guarda.</li> <li><code>names_file</code> (str, opcional): Nombre del archivo donde se guardar\u00e1 el DataFrame combinado (solo si <code>download_folder</code> no es <code>None</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_29","title":"Funcionamiento","text":"<ol> <li> <p>Carga y procesamiento de archivos:</p> <ul> <li>Ambas funciones utilizan <code>process_files_from_folder</code> para procesar los archivos dentro de <code>folder_url</code>, almacenando los DataFrames en la lista <code>dfs</code>.</li> </ul> </li> <li> <p>Combinaci\u00f3n de DataFrames:</p> <ul> <li>Si se encontraron archivos, los DataFrames en <code>dfs</code> se combinan utilizando <code>pd.concat(dfs, ignore_index=True)</code>.</li> <li>El DataFrame combinado se registra en el log mostrando las primeras filas con <code>df_combined.head()</code>.</li> </ul> </li> <li> <p>Guardado del DataFrame combinado (si aplica):</p> <ul> <li>Si se proporciona <code>download_folder</code>, se verifica si la carpeta existe. Si no, se crea utilizando <code>os.makedirs()</code>.</li> <li>Luego, guarda el DataFrame combinado en un archivo Excel dentro de <code>download_folder</code> con el nombre especificado en <code>names_file</code>.</li> <li>Registra la ruta donde se guarda el archivo en el log.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Si <code>download_folder</code> es <code>None</code>, devuelve el DataFrame combinado.</li> <li>Si <code>download_folder</code> se especifica, guarda el archivo y no retorna nada.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_30","title":"Salida","text":"<ul> <li><code>DataFrame</code>: Si <code>download_folder</code> es <code>None</code>, retorna el DataFrame combinado.</li> <li><code>None</code>: Si se guarda el archivo Excel, no retorna ning\u00fan valor.</li> </ul> <pre><code># Funcion para almacenar los DataFrames &lt;-------------------------------------------\ndef Combine_and_store_unparametro(folder_url,download_folder =None, names_file=None):\n    dfs = []\n    process_files_from_folder(folder_url, dfs)\n    if dfs:\n        df_combined = pd.concat(dfs, ignore_index=True)\n        logger.info(\"Contenido combinado: \\n{}\".format(df_combined.head()))        \n        return df_combined\n\ndef Combine_and_store(folder_url,  download_folder =None , names_file =None):\n    dfs = []\n    process_files_from_folder(folder_url, dfs)\n    if dfs:\n        df_combined = pd.concat(dfs, ignore_index=True)\n        logger.info(\"Contenido combinado: \\n{}\".format(df_combined.head()))\n\n        # si download_folder no es None\n        if download_folder is not None:            \n            # Verificar si la carpeta de destino existe, si no, crearla\n            if not os.path.exists(download_folder):\n                os.makedirs(download_folder, exist_ok=True)\n\n            # Guardar el DataFrame combinado en un archivo Excel\n            output_path = os.path.join(download_folder, names_file)\n            df_combined.to_excel(output_path, index=False)\n            print(f\"Archivo guardado en {output_path}\")\n        else:\n            return df_combined\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-conection_to_c4c","title":"Funci\u00f3n <code>conection_to_C4C</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_32","title":"Prop\u00f3sito","text":"<p>Automatiza el proceso de inicio de sesi\u00f3n en la p\u00e1gina de C4C utilizando Selenium, ingresando las credenciales proporcionadas y haciendo clic en el bot\u00f3n de inicio de sesi\u00f3n.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_32","title":"Entradas","text":"<ul> <li><code>driver</code> (webdriver.Chrome): Instancia de Selenium WebDriver utilizada para interactuar con la p\u00e1gina web.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_30","title":"Funcionamiento","text":"<ol> <li> <p>Obtenci\u00f3n de credenciales:</p> <ul> <li>Recupera el nombre de usuario y la contrase\u00f1a para el inicio de sesi\u00f3n en C4C mediante la funci\u00f3n <code>credenciales(\"C4C\")</code>.</li> </ul> </li> <li> <p>Localizaci\u00f3n de los elementos de inicio de sesi\u00f3n:</p> <ul> <li>Utiliza <code>WebDriverWait</code> para esperar hasta que los elementos necesarios para el inicio de sesi\u00f3n (campos de usuario y contrase\u00f1a, y el bot\u00f3n de login) sean visibles y clickeables.</li> <li>Los elementos son localizados por sus identificadores (<code>USERNAME_FIELD-inner</code>, <code>PASSWORD_FIELD-inner</code>) y el bot\u00f3n de inicio de sesi\u00f3n por su XPath.</li> </ul> </li> <li> <p>Ingreso de credenciales:</p> <ul> <li>Escribe el nombre de usuario y la contrase\u00f1a en los campos correspondientes.</li> </ul> </li> <li> <p>Env\u00edo del formulario de inicio de sesi\u00f3n:</p> <ul> <li>Hace clic en el bot\u00f3n de inicio de sesi\u00f3n para completar el proceso de login.</li> </ul> </li> <li> <p>Registro:</p> <ul> <li>Si el inicio de sesi\u00f3n es exitoso, registra un mensaje en el log indicando que el login fue exitoso.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_31","title":"Salida","text":"<ul> <li>No retorna valores. Realiza el inicio de sesi\u00f3n y registra el resultado en el log.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#excepciones_1","title":"Excepciones","text":"<ul> <li><code>TimeoutException</code>: Si alguno de los elementos de la p\u00e1gina (campo de usuario, campo de contrase\u00f1a o bot\u00f3n de inicio de sesi\u00f3n) no se encuentra dentro del tiempo especificado.</li> </ul> <pre><code>def conection_to_C4C(driver):\n    username, password = credenciales(\"C4C\")\n\n    \"\"\"\n    Logs in to the C4C website using the provided credentials.\n\n    Args:\n        driver (webdriver.Chrome): The Selenium WebDriver instance.\n        username (str): The username for C4C login.\n        password (str): The password for C4C login.\n\n    Raises:\n        TimeoutException: If the login elements are not found within the timeout window.\n    \"\"\"\n\n    # Find login elements\n    username_field = WebDriverWait(driver, 10).until(\n        EC.presence_of_element_located((By.ID, \"USERNAME_FIELD-inner\"))\n    )\n    password_field = WebDriverWait(driver, 10).until(\n        EC.presence_of_element_located((By.ID, \"PASSWORD_FIELD-inner\"))\n    )\n    login_button = WebDriverWait(driver, 15).until(\n            EC.element_to_be_clickable((By.XPATH, \"//button[@type='submit']\"))\n    )\n\n    # Enter credentials and submit\n    username_field.send_keys(username)\n    password_field.send_keys(password)\n    login_button.click()\n\n    logging.info(\"Login Successful\")\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-download_file_between_dates","title":"Funci\u00f3n <code>download_file_between_dates</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_33","title":"Prop\u00f3sito","text":"<p>Automatiza el proceso de descargar un archivo de C4C entre dos fechas especificadas, interactuando con los campos de fecha y las opciones del formulario.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_33","title":"Entradas","text":"<ul> <li><code>initial_date</code> (str): Fecha de inicio en formato de texto (ej. <code>'01/01/2022'</code>).</li> <li><code>final_date</code> (str): Fecha de finalizaci\u00f3n en formato de texto (ej. <code>'12/31/2022'</code>).</li> <li><code>driver</code> (webdriver.Chrome): Instancia de Selenium WebDriver utilizada para interactuar con la p\u00e1gina de C4C.</li> <li><code>_dict</code> (dict): Diccionario que mapea nombres de campos de fecha y otras opciones a sus localizadores correspondientes (por ejemplo, <code>{'initial_date': 'field_id', 'final_date': 'field_id', 'option_1': 'option_xpath'}</code>).</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_31","title":"Funcionamiento","text":"<ol> <li> <p>Conexi\u00f3n a C4C:</p> <ul> <li>Llama a la funci\u00f3n <code>conection_to_C4C(driver)</code> para iniciar sesi\u00f3n en C4C utilizando las credenciales.</li> </ul> </li> <li> <p>Interacci\u00f3n con el formulario:</p> <ul> <li>Itera sobre las claves del diccionario <code>_dict</code>.</li> <li>Si la clave no es <code>'initial_date'</code> ni <code>'final_date'</code>, hace clic en el elemento correspondiente usando la funci\u00f3n <code>click_and_wait(driver, _dict[option])</code>.</li> <li>Si la clave es <code>'initial_date'</code>, ingresa la fecha de inicio en el campo correspondiente.</li> <li>Si la clave es <code>'final_date'</code>, ingresa la fecha de finalizaci\u00f3n en el campo correspondiente.</li> </ul> </li> <li> <p>Esperas:</p> <ul> <li>Se utiliza un <code>time.sleep(4)</code> despu\u00e9s de llenar las fechas para asegurarse de que los campos se actualicen correctamente.</li> <li>Se espera 40 segundos (<code>time.sleep(40)</code>) para dar tiempo a que la descarga se complete.</li> </ul> </li> <li> <p>Cierre del WebDriver:</p> <ul> <li>Despu\u00e9s de completar la acci\u00f3n, cierra el WebDriver con <code>driver.quit()</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_32","title":"Salida","text":"<ul> <li>No retorna valores. Realiza la descarga del archivo y cierra la sesi\u00f3n del WebDriver.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#excepciones_2","title":"Excepciones","text":"<ul> <li>Posibles excepciones de Selenium: Si los elementos no son encontrados, la funci\u00f3n podr\u00eda lanzar errores relacionados con la localizaci\u00f3n de elementos o interacci\u00f3n con los campos.</li> </ul> <pre><code>def download_file_between_dates(initial_date, final_date, driver,_dict):\n    # Conexi\u00f3n a C4C\n    conection_to_C4C(driver)\n    # Iterar sobre las opciones en el diccionario\n    for option in _dict:\n        if option not in (\"initial_date\", \"final_date\"):\n            click_and_wait(driver, _dict[option])\n        elif option == \"initial_date\":\n            date_input = driver.find_element(By.ID, _dict[option])\n            date_input.send_keys(initial_date)\n        elif option == \"final_date\":\n            date_input = driver.find_element(By.ID, _dict[option])\n            date_input.send_keys(final_date)\n        time.sleep(4)\n\n    # Tiempo de espera adicional para asegurarse de que la descarga se complete\n    time.sleep(40)  \n\n    # Cerrar el WebDriver\n    driver.quit()\n</code></pre>"},{"location":"00.etl/Utils/Funciones/#funcion-click_and_wait","title":"Funci\u00f3n <code>click_and_wait</code>","text":""},{"location":"00.etl/Utils/Funciones/#proposito_34","title":"Prop\u00f3sito","text":"<p>Hace clic en un elemento localizado mediante XPath y espera a que la p\u00e1gina se cargue o el elemento est\u00e9 listo para interactuar.</p>"},{"location":"00.etl/Utils/Funciones/#entradas_34","title":"Entradas","text":"<ul> <li><code>driver</code> (WebDriver): Instancia de Selenium WebDriver utilizada para interactuar con la p\u00e1gina.</li> <li><code>xpath</code> (str): Expresi\u00f3n XPath que localiza el elemento en el DOM.</li> <li><code>timeout</code> (int, opcional): Tiempo m\u00e1ximo en segundos para esperar a que el elemento sea clickeable. El valor predeterminado es <code>30</code> segundos.</li> </ul>"},{"location":"00.etl/Utils/Funciones/#funcionamiento_32","title":"Funcionamiento","text":"<ol> <li> <p>Esperar hasta que el elemento est\u00e9 clickeable:</p> <ul> <li>Utiliza <code>WebDriverWait</code> para esperar hasta que el elemento identificado por el XPath proporcionado est\u00e9 listo para ser clickeado.</li> </ul> </li> <li> <p>Clic en el elemento:</p> <ul> <li>Una vez que el elemento es clickeable, se realiza el clic en \u00e9l.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones/#salida_33","title":"Salida","text":"<ul> <li>No retorna valores. Realiza el clic en el elemento especificado y espera a que se cargue.</li> </ul> <pre><code>def click_and_wait(driver, xpath, timeout=30):\n    \"\"\"\n    Clicks on an element identified by xpath and waits for the page to load.\n\n    Args:\n        driver: The WebDriver instance.\n        xpath: The xpath expression to locate the element.\n        timeout: The maximum wait time in seconds (default: 20).\n    \"\"\"\n    link_to_click = WebDriverWait(driver, timeout).until(\n        EC.element_to_be_clickable((By.XPATH, xpath))\n    )\n    link_to_click.click()\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/","title":"Funciones_DM.py","text":"<p>Este archivo contiene una serie de funciones automatizadas desarrolladas para gestionar tareas comunes en la manipulaci\u00f3n de datos y la interacci\u00f3n con sistemas externos. Las funciones descritas est\u00e1n dise\u00f1adas principalmente para automatizar procesos en plataformas como SharePoint y sistemas como C4C, as\u00ed como para facilitar el procesamiento de datos utilizando herramientas como pandas y xlwings.</p> <p>Las funciones cubren una variedad de tareas, incluyendo:</p> <ol> <li> <p>Autenticaci\u00f3n y acceso a plataformas externas:</p> <ul> <li><code>get_file_from_sharepoint</code>: Automatiza la descarga de archivos desde SharePoint.</li> <li><code>list_files_from_sharepoint</code>: Lista archivos en una carpeta de SharePoint.</li> <li><code>process_files_from_folder</code>: Procesa archivos en una carpeta de SharePoint.</li> </ul> </li> <li> <p>Interacci\u00f3n con men\u00fas desplegables y formularios web:</p> <ul> <li>No se incluyen funciones espec\u00edficas para esta tarea en el c\u00f3digo proporcionado.</li> </ul> </li> <li> <p>Descarga y procesamiento de datos:</p> <ul> <li><code>get_file_from_sharepoint</code>: Descarga archivos desde SharePoint.</li> <li><code>process_files_from_folder</code>: Procesa y lee archivos Excel sin descargarlos.</li> </ul> </li> <li> <p>Manejo de archivos y directorios:</p> <ul> <li><code>Charge_Excel_Fixed</code>: Carga y procesa archivos Excel, incluso si est\u00e1n comprimidos en un archivo ZIP.</li> <li><code>_Charge_Excel_Fixed</code>: Carga archivos Excel utilizando xlwings.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n de datos:</p> <ul> <li><code>normalize</code>: Normaliza cadenas de texto.</li> <li><code>PreSave</code>: Preprocesa y limpia datos en un DataFrame.</li> <li><code>Sorted_Answer</code>: Ordena respuestas en una cadena separada por punto y coma.</li> <li><code>Fix_Table_Answers</code>: Ajusta respuestas en una tabla.</li> <li><code>Fix_Id_Type_Caract</code> y <code>Fix_Id_Type</code>: Normalizan tipos de identificaci\u00f3n.</li> <li><code>Truncate_Column</code>: Trunca columnas a una longitud espec\u00edfica.</li> <li><code>Fix_Datetime</code> y <code>Fix_DatetimeFinal</code>: Ajustan formatos de fecha y hora.</li> <li><code>Fix_Questions</code>: Modifica y transpone columnas de preguntas en un DataFrame.</li> </ul> </li> </ol> <p>Este conjunto de herramientas es esencial para mejorar la eficiencia en tareas repetitivas, reduciendo la necesidad de intervenci\u00f3n manual y permitiendo una integraci\u00f3n m\u00e1s fluida entre los sistemas externos y el entorno de trabajo. La automatizaci\u00f3n de estos procesos optimiza el flujo de trabajo y facilita la administraci\u00f3n y procesamiento de grandes vol\u00famenes de datos.</p>"},{"location":"00.etl/Utils/Funciones_DM/#configuracion-e-importacion-de-librerias","title":"Configuraci\u00f3n e importaci\u00f3n de Librer\u00edas","text":"<p>Este bloque de c\u00f3digo configura el entorno de trabajo importando todas las librer\u00edas necesarias para manipulaci\u00f3n de datos, automatizaci\u00f3n de Excel, autenticaci\u00f3n y automatizaci\u00f3n de navegadores web. <code>Funciones.py</code> importa varias librer\u00edas est\u00e1ndar y externas necesarias para el funcionamiento del script.</p>"},{"location":"00.etl/Utils/Funciones_DM/#librerias-estandar","title":"Librer\u00edas est\u00e1ndar","text":"<ul> <li><code>datetime</code></li> <li><code>json</code></li> <li><code>re</code></li> <li><code>requests</code></li> <li><code>timedelta</code></li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#librerias-externas","title":"Librer\u00edas externas","text":"<ul> <li><code>numpy</code></li> <li><code>pandas</code></li> <li><code>xlwings</code></li> <li><code>zipfile</code></li> <li><code>log_step_decorator</code> (de <code>Utils.Funciones</code>)</li> </ul> <pre><code># pylint: disable=all\n# import pandas lib as pd\nimport numpy as np\nimport pandas as pd\nimport re\nimport xlwings as xw\nimport json\nimport requests\nfrom datetime import datetime, timedelta\nfrom Utils.Funciones import log_step_decorator\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#get_file_from_sharepoint","title":"<code>get_file_from_sharepoint</code>","text":"<p>Descarga un archivo desde SharePoint utilizando su URL. Recibe como entrada <code>file_url</code> (str), que especifica la ubicaci\u00f3n del archivo, y devuelve el contenido del archivo como bytes si la solicitud es exitosa. En caso de error, retorna <code>None</code> y registra una advertencia con el c\u00f3digo de estado de la respuesta.</p> <pre><code>@log_step_decorator(\"Obtener archivo de SharePoint\")\ndef get_file_from_sharepoint(file_url, headers):\n    response = requests.get(file_url, headers=headers)\n    print(f\"Response Status Code: {response.status_code}\")\n\n    if response.status_code == 200:\n        return response.content\n    else:\n        print(f\"Error al acceder al archivo. C\u00f3digo de estado: {response.status_code}\")\n        return None\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#list_files_from_sharepoint","title":"<code>list_files_from_sharepoint</code>","text":"<p>Obtiene una lista de archivos presentes en una carpeta de SharePoint indicada por la URL proporcionada. Recibe como entrada <code>folder_url</code> (str), que especifica la ubicaci\u00f3n de la carpeta, y devuelve una lista de archivos si la solicitud es exitosa o una lista vac\u00eda en caso de fallo. Tambi\u00e9n registra advertencias en caso de errores durante la solicitud.</p> <pre><code>@log_step_decorator(\"Listar archivos de SharePoint\")\ndef list_files_from_sharepoint(folder_url,headers,sharepoint_base_url):\n    list_files_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n    response = requests.get(list_files_url, headers=headers)\n\n\n    if response.status_code == 200:\n        files = response.json()['d']['results']\n        return files\n    else:\n        print(f\"Error al listar los archivos. C\u00f3digo de estado: {response.status_code}\")\n        return []\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-process_files_from_folder","title":"Funci\u00f3n <code>process_files_from_folder</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito","title":"Prop\u00f3sito","text":"<p>Procesa archivos de una carpeta de SharePoint que han sido modificados en los \u00faltimos seis meses, almacenando los datos en una lista de DataFrames.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas","title":"Entradas","text":"<ul> <li><code>folder_url</code> (str): URL de la carpeta en SharePoint desde donde se obtendr\u00e1n los archivos.</li> <li><code>dfs</code> (list): Lista utilizada para almacenar los DataFrames procesados.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento","title":"Funcionamiento","text":"<ol> <li>Listar archivos: Obtiene la lista de archivos en la carpeta de SharePoint.</li> <li>Filtrar por fecha: Identifica archivos modificados en los \u00faltimos seis meses.</li> <li>Procesar archivos:<ul> <li>Recupera el contenido de los archivos seleccionados desde SharePoint.</li> <li>Lee el contenido de los archivos como DataFrames utilizando <code>pandas</code>.</li> <li>Registra informaci\u00f3n sobre el contenido y lo almacena en la lista <code>dfs</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida","title":"Salida","text":"<ul> <li>No retorna ning\u00fan valor. Modifica la lista <code>dfs</code> proporcionada al agregar los DataFrames procesados.</li> </ul> <pre><code>@log_step_decorator(\"Procesar archivos\")\ndef process_files_from_folder(folder_url, dfs,headers, sharepoint_base_url):\n\n    files = list_files_from_sharepoint(folder_url, headers, sharepoint_base_url)\n    six_months_ago = datetime.now() - timedelta(days=180)\n\n\n\n    for file in files:\n        file_name = file['Name']\n        file_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n        modified_date_str = file['TimeLastModified']\n        modified_date = datetime.strptime(modified_date_str, '%Y-%m-%dT%H:%M:%SZ')\n        print('MODIFY', modified_date)\n\n        if modified_date &gt;= six_months_ago:\n\n            # Obtener el archivo de SharePoint\n            file_content = get_file_from_sharepoint(file_url, headers)\n\n            if file_content:\n                # Leer el archivo Excel sin descargar\n                df = pd.read_excel(file_content)\n                print(f\"Contenido de {file_name}:\\n\", df.head())\n                dfs.append(df)\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#normalize","title":"<code>normalize</code>","text":"<p>Elimina las tildes de un texto, reemplaz\u00e1ndolas por sus versiones sin acento, tanto en min\u00fasculas como en may\u00fasculas.</p> <pre><code>def normalize(s):\n    replacements = (\n        (\"\u00e1\", \"a\"),\n        (\"\u00e9\", \"e\"),\n        (\"\u00ed\", \"i\"),\n        (\"\u00f3\", \"o\"),\n        (\"\u00fa\", \"u\"),\n    )\n    for a, b in replacements:\n        s = s.replace(a, b).replace(a.upper(), b.upper())\n    return s\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-presave","title":"Funci\u00f3n <code>PreSave</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_1","title":"Prop\u00f3sito","text":"<p>Realiza un preprocesamiento de columnas en un DataFrame, limpiando y normalizando valores textuales, y opcionalmente eliminando signos de puntuaci\u00f3n espec\u00edficos.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_1","title":"Entradas","text":"<ul> <li><code>df</code> (DataFrame): DataFrame original que se desea procesar.</li> <li><code>columnList</code> (list): Lista de columnas del DataFrame que ser\u00e1n procesadas.</li> <li><code>signs</code> (bool, opcional): Si es <code>True</code>, elimina signos de puntuaci\u00f3n como <code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code> de las columnas. Por defecto: <code>False</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_1","title":"Funcionamiento","text":"<ol> <li> <p>Copiar el DataFrame:</p> <ul> <li>Crea una copia del DataFrame original para evitar modificaciones en el objeto original.</li> </ul> </li> <li> <p>Limpieza y normalizaci\u00f3n:</p> <ul> <li>Reemplazos espec\u00edficos:<ul> <li>Convierte <code>\\xf1</code> a <code>ni</code> (e.g., \"\u00f1\" a \"ni\").</li> <li>Convierte <code>\\xD1</code> a <code>NI</code> (e.g., \"\u00d1\" a \"NI\").</li> <li>Sustituye caracteres no rompibles (<code>\\u00A0</code>) por espacios.</li> </ul> </li> <li>Eliminaci\u00f3n de espacios:<ul> <li>Reemplaza espacios dobles por simples.</li> <li>Elimina espacios al inicio y final de las cadenas.</li> </ul> </li> <li>Normalizaci\u00f3n de texto:<ul> <li>Convierte los valores a cadenas en may\u00fasculas.</li> <li>Aplica la funci\u00f3n <code>normalize</code> para eliminar tildes.</li> <li>Reemplaza comas por espacios.</li> </ul> </li> <li>Gesti\u00f3n de valores nulos:<ul> <li>Sustituye valores <code>\"NAN\"</code> por <code>np.nan</code>.</li> </ul> </li> </ul> </li> <li> <p>Eliminaci\u00f3n de signos (opcional):</p> <ul> <li>Si <code>signs=True</code>, elimina signos de puntuaci\u00f3n (<code>\u00a1</code>, <code>!</code>, <code>?</code>, <code>\u00bf</code>) utilizando expresiones regulares.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_1","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame con las columnas especificadas procesadas y normalizadas.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#ejemplo-de-uso","title":"Ejemplo de uso","text":"<p>Si la entrada es: <pre><code>df = pd.DataFrame({'col1': ['\u00a1Hola, mundo!', '\u00bfQu\u00e9 tal?']})\nPreSave(df, ['col1'], signs=True)\n</code></pre></p> <p>La salida ser\u00e1: <pre><code>      col1\n0    HOLA MUNDO\n1    QUE TAL\n</code></pre></p> <pre><code>def PreSave(df , columnList, signs = False):\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xf1', 'ni'))\n    #datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.decode('utf-8').replace(u'\\xD1', 'NI'))\n\n    datfra = df.copy()\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xf1', 'ni'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(u'\\xD1', 'NI'))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('\\u00A0', ' '))\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace('  ', ' '))\n    datfra[columnList] = datfra[columnList].astype(str)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.strip())\n    datfra[columnList] = datfra[columnList].map(normalize)\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.upper())\n    datfra[columnList] = datfra[columnList].apply(lambda x: x.astype(str).str.replace(',', ' '))\n    datfra[columnList] = datfra[columnList].replace('NAN', np.nan)\n\n    if signs == True:\n        for col in columnList:\n            try:\n                datfra[col] = datfra[col].apply(lambda x: re.sub(r'[\u00a1!?\u00bf]', '', x) )\n            except:\n                print('Not Signs fixed for '+ col)\n\n    return datfra\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funciones-sorted_answer-y-fix_table_answers","title":"Funciones <code>Sorted_Answer</code> y <code>Fix_Table_Answers</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#funcion-sorted_answer","title":"Funci\u00f3n <code>Sorted_Answer</code>","text":"<p>Prop\u00f3sito: Ordena alfab\u00e9ticamente las respuestas separadas por punto y coma (<code>;</code>) dentro de una cadena. Elimina valores vac\u00edos si existen.</p> <p>Entradas:</p> <ul> <li><code>x</code> (str o NaN): Cadena de texto con respuestas separadas por punto y coma o un valor nulo.</li> </ul> <p>Funcionamiento:</p> <ol> <li>Verifica si la entrada es nula (<code>NaN</code>). Si es as\u00ed, retorna la entrada sin cambios.</li> <li>Divide la cadena en una lista utilizando <code>split(';')</code>.</li> <li>Si hay m\u00e1s de una respuesta:<ul> <li>Ordena alfab\u00e9ticamente la lista.</li> <li>Elimina entradas vac\u00edas si est\u00e1n presentes.</li> <li>Reconstruye la cadena uniendo los valores con <code>;</code>.</li> </ul> </li> <li>Retorna la cadena ordenada o la entrada original si no se cumplen las condiciones.</li> </ol> <p>Salida:</p> <ul> <li><code>str</code> o <code>NaN</code>: Cadena con las respuestas ordenadas alfab\u00e9ticamente o valor original si no hay cambios.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-fix_table_answers","title":"Funci\u00f3n <code>Fix_Table_Answers</code>","text":"<p>Prop\u00f3sito:</p> <p>Aplica la funci\u00f3n <code>Sorted_Answer</code> a una columna espec\u00edfica de un DataFrame, actualizando la columna con las respuestas ordenadas.</p> <pre><code>def Sorted_Answer(x):\n    if pd.isnull(x):\n        return x\n    p =  x.split(';') \n    if len(p) &gt; 1:\n        p = sorted(p)\n        p.remove('')\n        p = ';'.join(p)\n        return p\n    return x\n</code></pre> <pre><code>def Fix_Table_Answers( table , column_name ):\n    table['RESPUESTA_LIST'] = table[column_name].apply( lambda x: Sorted_Answer(x) )\n    table = table.drop([ column_name ], axis=1)\n    table = table.rename(columns={'RESPUESTA_LIST': column_name})\n\n    return table\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-fix_id_type_caract","title":"Funci\u00f3n <code>Fix_Id_Type_Caract</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_2","title":"Prop\u00f3sito","text":"<p>Estandariza y transforma diferentes representaciones de tipos de identificaci\u00f3n en c\u00f3digos abreviados predefinidos.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_2","title":"Entradas","text":"<ul> <li><code>id_type</code> (str): Cadena de texto que representa un tipo de identificaci\u00f3n, como \"CEDULA DE CIUDADANIA\" o \"TARJETA DE IDENTIDAD\".</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_2","title":"Funcionamiento","text":"<ol> <li>Utiliza una estructura <code>match-case</code> para comparar el valor de <code>id_type</code> con diferentes representaciones conocidas.</li> <li>Devuelve el c\u00f3digo abreviado correspondiente:<ul> <li><code>CC</code>: C\u00e9dula de ciudadan\u00eda.</li> <li><code>TI</code>: Tarjeta de identidad.</li> <li><code>RC</code>: Registro civil.</li> <li><code>PE</code>: Permiso especial de permanencia.</li> <li><code>PPT</code>: Permiso especial de permanencia temporal.</li> <li><code>PA</code>: Pasaporte.</li> <li><code>CE</code>: Identificaci\u00f3n extranjera.</li> <li><code>NI</code>: NIT.</li> <li><code>NA</code>: No aplica o no reconocido.</li> </ul> </li> <li>Si no encuentra una coincidencia, devuelve el valor por defecto <code>NA</code>.</li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_2","title":"Salida","text":"<ul> <li><code>str</code>: C\u00f3digo abreviado del tipo de identificaci\u00f3n.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#ejemplo-de-uso_1","title":"Ejemplo de uso","text":"<p>Entrada: <pre><code>Fix_Id_Type_Caract('CEDULA DE CIUDADANIA')\n</code></pre></p> <p>Salida: <pre><code>'CC'\n</code></pre></p> <p><pre><code>def Fix_Id_Type_Caract(id_type):\n    match id_type:\n        case '1.CEDULA DE CIUDADANIA':\n             return 'CC'\n        case '2.TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3.REGISTRO CIVIL':\n             return 'RC'\n        case '1. CEDULA':\n             return 'CC'\n        case 'TARJETA DE IDENTIDAD':\n             return 'TI'\n        case 'CEDULA DE CIUDADANIA':\n             return 'CC'\n        case 'REGISTRO CIVIL':\n             return 'RC'\n        case '2. TARJETA DE IDENTIDAD':\n             return 'TI'\n        case '3. REGISTRO CIVIL':\n             return 'RC'\n        case '9. PERMISO ESPECIAL DE PERMANENCIA (P.E.P)':\n             return 'PE'\n        case '15. PERMISO ESPECIAL DE PERMANENCIA TEMPORAL':\n             return 'PPT'\n        case '11.\\xa0 IDENTIFICACION DADA POR LA SECRETARIA DE EDUCACION':\n             return 'NA'\n        case '14. ID EXTRANJEROS DIFERENTE A LA CEDULA DE EXTRANJERIA (SOLO PARA FONINIEZ)':\n             return 'C1X'\n        case '6. PASAPORTE':\n             return 'PA'\n        case '5. NUIP':\n             return 'NA'\n        case 'CERTIFICADO DE NACIMIENTO':\n             return 'RC'\n        case 'ID EXTRANJERO':\n             return 'CE'   \n        case 'NIT':\n             return 'NI' \n        case 'NONE':\n             return 'NA'         \n        case _:\n            return 'NA'\n\n    return 'NA'\n</code></pre> <code>Fix_Id_Type</code> aplica la transformaci\u00f3n de tipos de identificaci\u00f3n en una columna espec\u00edfica de una tabla si el nombre de la tabla es <code>\"CARACTERIZACION\"</code>.</p> <p><code>Truncate_Column</code> trunca el contenido de las columnas especificadas a un m\u00e1ximo de 255 caracteres. Por otro lado, <code>Fix_Datetime</code> convierte valores tipo <code>NaT</code> a un valor predeterminado (<code>2009-01-01 00:00:00</code>) y agrega la hora inicial a fechas v\u00e1lidas. </p> <p>Finalmente, <code>Fix_DatetimeFinal</code> normaliza una columna de fechas en un DataFrame, convirti\u00e9ndolas a formato <code>datetime</code>, estableciendo la hora como 00:00:00, y manejando errores de conversi\u00f3n de forma segura.</p> <pre><code>def Fix_Id_Type( table , typeIdColumn , tableName ):\n    if tableName == 'CARACTERIZACION':\n        table[typeIdColumn] = table[typeIdColumn].apply( Fix_Id_Type_Caract )\n</code></pre> <pre><code>def Truncate_Column( table , columnsToTruncate ):\n    table[columnsToTruncate] = table[columnsToTruncate].astype(str).apply(lambda x: x.str[:255])\n</code></pre> <pre><code>def Fix_Datetime(x):\n    if x == 'NaT':\n        return '2009-01-01 00:00:00'    \n    return x + ' 00:00:00'\n</code></pre> <pre><code>def Fix_DatetimeFinal(table, columnName):\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = pd.to_datetime(table[columnName], format='%Y-%m-%d %H:%M:%S', errors='coerce',dayfirst=True)\n    table[columnName] = table[columnName].apply(lambda x: x.replace(hour=0, minute=0, second=0))\n    table[columnName] = table[columnName].astype(str)\n    table[columnName] = table[columnName].apply(lambda x: Fix_Datetime(x)   )\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-fix_questions","title":"Funci\u00f3n <code>Fix_Questions</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_3","title":"Prop\u00f3sito","text":"<p>Transforma y organiza un DataFrame de respuestas de encuestas, estructur\u00e1ndolo para an\u00e1lisis, incluyendo la identificaci\u00f3n de preguntas relacionadas con NPS (Net Promoter Score).</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_3","title":"Entradas","text":"<ul> <li><code>data</code> (DataFrame): DataFrame original con datos de encuestas.</li> <li><code>servicio</code> (str): Nombre del servicio asociado a las encuestas.</li> <li><code>nps</code> (dict): Diccionario que mapea servicios a preguntas relacionadas con NPS.</li> <li><code>filename</code> (str): Nombre del archivo relacionado para fines de registro.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_3","title":"Funcionamiento","text":"<ol> <li> <p>Renombramiento de columnas:</p> <ul> <li>Cambia el nombre de las columnas <code>fecha</code> a <code>FECHA_ENCUESTA</code> y <code>identificacion</code> a <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas:</p> <ul> <li>Busca columnas cuyo nombre comience con <code>\"etapa3\"</code>, que representan preguntas con calificaci\u00f3n.</li> </ul> </li> <li> <p>Filtrado de columnas relevantes:</p> <ul> <li>Redefine el DataFrame para incluir solo las columnas: <code>FECHA_ENCUESTA</code>, <code>DOCUMENTO</code>, y las preguntas identificadas.</li> </ul> </li> <li> <p>Transformaci\u00f3n de datos:</p> <ul> <li>Transforma el DataFrame a un formato largo utilizando <code>melt</code>:<ul> <li><code>id_vars</code>: Columnas constantes (<code>FECHA_ENCUESTA</code> y <code>DOCUMENTO</code>).</li> <li><code>var_name</code>: Nombre de las columnas de preguntas (<code>PREGUNTA</code>).</li> <li><code>value_name</code>: Valores asociados a las preguntas (<code>CALIFICACION</code>).</li> </ul> </li> </ul> </li> <li> <p>Adici\u00f3n de columnas constantes:</p> <ul> <li>Agrega columnas adicionales:<ul> <li><code>SERVICIO</code>: Nombre del servicio.</li> <li><code>TIPO_DOCUMENTO</code>: Fijado como <code>'CC'</code>.</li> <li><code>NPS</code>: Inicializado como <code>'NO'</code>.</li> </ul> </li> </ul> </li> <li> <p>Identificaci\u00f3n de preguntas NPS:</p> <ul> <li>Actualiza la columna <code>NPS</code> a <code>'SI'</code> para las preguntas que coinciden con el servicio especificado en el diccionario <code>nps</code>.</li> </ul> </li> <li> <p>Salida del DataFrame:</p> <ul> <li>Registra el nombre del servicio y archivo procesado.</li> <li>Devuelve el DataFrame transformado.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>En caso de error, registra el servicio y archivo no procesado.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_3","title":"Salida","text":"<ul> <li><code>DataFrame</code>: DataFrame transformado en formato largo con las siguientes columnas:</li> <li><code>FECHA_ENCUESTA</code></li> <li><code>DOCUMENTO</code></li> <li><code>PREGUNTA</code></li> <li><code>CALIFICACION</code></li> <li><code>SERVICIO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NPS</code></li> </ul> <pre><code>def Fix_Questions( data , servicio , nps, filename):\n\n    try:\n        df = data  \n        #Modificaciones a columnas\n        df = df.rename(columns={'fecha': 'FECHA_ENCUESTA',\n                                'identificacion':'DOCUMENTO'\n                            })\n\n        #Buscar preguntas con nota\n        dfColumns = df.columns.tolist()\n        columnsWithObs = [val for val in dfColumns if val.startswith(\"etapa3\") ]\n\n        #Redefinir columna\n        df = df[['FECHA_ENCUESTA','DOCUMENTO']+columnsWithObs]\n\n        #Modificaciones y transpocision \n        df_unp = df.melt( id_vars = ['FECHA_ENCUESTA','DOCUMENTO'] , var_name=\"PREGUNTA\", value_name=\"CALIFICACION\")\n        df_unp['SERVICIO'] = servicio\n        df_unp['TIPO_DOCUMENTO'] = 'CC'\n        df_unp['NPS'] = 'NO'\n\n\n        df_unp.loc[df_unp[\"PREGUNTA\"] == nps[servicio], \"NPS\"] = 'SI'\n        print('Agregado: ' +  servicio + filename )\n        return df_unp\n    except:\n        print('Sin formato: ' +  servicio + filename )\n</code></pre> <pre><code>import pandas as pd\nfrom zipfile import ZipFile\n</code></pre>"},{"location":"00.etl/Utils/Funciones_DM/#funcion-charge_excel_fixed","title":"Funci\u00f3n <code>Charge_Excel_Fixed</code>","text":""},{"location":"00.etl/Utils/Funciones_DM/#proposito_4","title":"Prop\u00f3sito","text":"<p>Carga un archivo Excel comprimido en formato ZIP, procesa los datos en un DataFrame de pandas, y lo limpia eliminando filas y columnas vac\u00edas antes de almacenarlo en un diccionario.</p>"},{"location":"00.etl/Utils/Funciones_DM/#entradas_4","title":"Entradas","text":"<ul> <li><code>ruta</code> (str): Ruta del archivo Excel, que puede estar comprimido en formato ZIP.</li> <li><code>dfs</code> (dict): Diccionario donde se almacenar\u00e1 el DataFrame procesado, con el nombre del archivo como clave.</li> <li><code>file</code> (str): Nombre del archivo para usarlo como clave en el diccionario <code>dfs</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#funcionamiento_4","title":"Funcionamiento","text":"<ol> <li> <p>Verificaci\u00f3n del archivo ZIP:</p> <ul> <li>Intenta abrir el archivo como un archivo ZIP utilizando <code>ZipFile</code>. Si es un archivo ZIP v\u00e1lido, continua con el procesamiento.</li> </ul> </li> <li> <p>Carga del archivo Excel:</p> <ul> <li>Intenta cargar el archivo Excel utilizando pandas (<code>pd.read_excel</code>) con el motor <code>openpyxl</code>.</li> <li>Si se encuentra alg\u00fan error en la carga, se captura y se registra un mensaje.</li> </ul> </li> <li> <p>Procesamiento y limpieza del DataFrame:</p> <ul> <li>Se crea un DataFrame a partir de los datos cargados.</li> <li>Se eliminan filas y columnas vac\u00edas con <code>dropna(how='all')</code> y <code>dropna(axis=1, how='all')</code>.</li> <li>Se restablece el \u00edndice del DataFrame y se asigna la primera fila como nombres de columna.</li> <li>Se elimina la primera fila (que ahora se utiliza como encabezado).</li> <li>El DataFrame limpio se guarda en el diccionario <code>dfs</code> con la clave proporcionada por <code>file</code>.</li> </ul> </li> <li> <p>Manejo de errores:</p> <ul> <li>Captura y registra cualquier error que ocurra durante la carga o el procesamiento del archivo.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/Funciones_DM/#salida_4","title":"Salida","text":"<ul> <li>No retorna valores. El DataFrame procesado se almacena en el diccionario <code>dfs</code> bajo la clave <code>file</code>.</li> </ul>"},{"location":"00.etl/Utils/Funciones_DM/#consideraciones","title":"Consideraciones","text":"<ul> <li>Se verifica si el archivo es un ZIP v\u00e1lido antes de intentar cargar el archivo Excel.</li> <li>El DataFrame es limpiado de cualquier fila o columna vac\u00eda antes de su procesamiento.</li> <li>Aseg\u00farese de que el archivo Excel est\u00e9 correctamente formateado para que las primeras filas contengan los encabezados.</li> </ul> <pre><code>def Charge_Excel_Fixed(ruta, dfs, file):\n    try:\n        # Verificar si es un archivo ZIP v\u00e1lido\n        with ZipFile(ruta, 'r'):\n            print(\"El archivo es un ZIP v\u00e1lido.\")\n\n        # Intentar cargar con pandas y openpyxl\n        data = pd.read_excel(ruta, engine='openpyxl')\n        print(\"Archivo cargado exitosamente con pandas y openpyxl.\")\n    except Exception as e:\n        print(f\"Error al cargar el archivo: {e}\")\n        return\n\n    # Procesar el DataFrame\n    try:\n        df = pd.DataFrame(data)\n        df.dropna(how='all', inplace=True)\n        df.dropna(axis=1, how='all', inplace=True)\n        df.reset_index(drop=True, inplace=True)\n        df.columns = df.iloc[0]\n        df = df[1:].reset_index(drop=True)\n        dfs[file] = df\n        print(\"Archivo procesado exitosamente.\")\n    except Exception as e:\n        print(f\"Error procesando el DataFrame: {e}\")\n</code></pre>"},{"location":"00.etl/Utils/c4c_from_sharepoint/","title":"c4c_from_sharepoint","text":"<p>Este script automatiza la descarga de archivos desde una carpeta de SharePoint utilizando el API de SharePoint y los m\u00f3dulos <code>requests</code> y <code>msal</code> para autenticar y obtener datos. El script tambi\u00e9n incluye funcionalidades de procesamiento de archivos, creaci\u00f3n de carpetas y manejo de archivos descargados. A continuaci\u00f3n, se describe el funcionamiento y prop\u00f3sito de cada componente y funci\u00f3n del script.</p>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#dependencias-y-configuracion","title":"Dependencias y configuraci\u00f3n","text":"<ol> <li> <p>Librer\u00edas:</p> <ul> <li>El script importa varias librer\u00edas como <code>argparse</code>, <code>io</code>, <code>logging</code>, <code>os</code>, <code>requests</code>, <code>pandas</code>, <code>msal</code>, entre otras, para realizar tareas de autenticaci\u00f3n, procesamiento de datos y manejo de archivos.</li> </ul> </li> <li> <p>Archivo <code>credenciales.env</code>:</p> <ul> <li>Se cargan las credenciales de acceso desde el archivo <code>credenciales.env</code>, que contiene las claves necesarias para autenticar la aplicaci\u00f3n en Microsoft Azure.</li> </ul> </li> <li> <p>Autenticaci\u00f3n en Microsoft Azure:</p> <ul> <li>Utiliza <code>msal</code> para obtener un token de acceso que se usar\u00e1 en las solicitudes de la API de SharePoint.</li> </ul> </li> <li> <p>Configuraci\u00f3n de logging:</p> <ul> <li>Se configura un logger para registrar los eventos en un archivo <code>scraper_SSIS.log</code> y en la consola. Esto permite el monitoreo del proceso de descarga y cualquier error que pueda ocurrir.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#funciones-principales","title":"Funciones principales","text":"<ol> <li> <p><code>download_file_from_sharepoint</code>:</p> <ul> <li>Esta funci\u00f3n se encarga de descargar un archivo desde SharePoint utilizando la URL del archivo y el token de autenticaci\u00f3n.</li> <li>La funci\u00f3n recibe el nombre del archivo, la URL de la carpeta de SharePoint y la ruta de destino para guardar el archivo descargado.</li> <li>Si la solicitud es exitosa (<code>status_code == 200</code>), guarda el archivo en el directorio indicado.</li> </ul> </li> <li> <p><code>download_all_files_from_sharepoint</code>:</p> <ul> <li>Descarga todos los archivos de una carpeta espec\u00edfica en SharePoint.</li> <li>Llama a la API de SharePoint para obtener la lista de archivos en la carpeta especificada.</li> <li>Filtra los archivos que coinciden con un modelo de archivo (por ejemplo, <code>Listadesolicitudesdeservicio__ES.xlsx</code>) y descarga cada uno de ellos utilizando la funci\u00f3n <code>download_file_from_sharepoint</code>.</li> </ul> </li> <li> <p><code>run_etl</code>:</p> <ul> <li>Esta funci\u00f3n envuelve el proceso de descarga de archivos de SharePoint, llamando a <code>download_all_files_from_sharepoint</code> con la URL de la carpeta y el directorio de destino.</li> </ul> </li> <li> <p>Autenticaci\u00f3n con <code>msal</code>:</p> <ul> <li>El script usa la librer\u00eda <code>msal</code> para obtener un token de acceso mediante las credenciales proporcionadas en el archivo <code>credenciales.env</code>. Este token se usa para autorizar las solicitudes a la API de SharePoint.</li> </ul> </li> <li> <p>Ejecuci\u00f3n del proceso de descarga:</p> <ul> <li>Dentro de la funci\u00f3n <code>run_etl</code>, se configuran los par\u00e1metros de carpeta y directorio de destino, y se inicia el proceso de descarga de los archivos de SharePoint.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#flujo-del-script","title":"Flujo del script","text":"<ol> <li> <p>Autenticaci\u00f3n:</p> <ul> <li>Se obtienen las credenciales y el token de acceso a la API de SharePoint utilizando <code>msal</code> con las credenciales proporcionadas en el archivo <code>credenciales.env</code>.</li> </ul> </li> <li> <p>Obtenci\u00f3n y descarga de archivos:</p> <ul> <li>El script obtiene los archivos de SharePoint desde la carpeta especificada (<code>folder_url</code>), filtra los archivos relevantes y los descarga al directorio de destino.</li> </ul> </li> <li> <p>Proceso ETL:</p> <ul> <li>El proceso ETL se lleva a cabo con el decorador <code>log_step_decorator</code>, lo que permite registrar el avance de cada paso en el proceso de descarga.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/c4c_from_sharepoint/#consideraciones","title":"Consideraciones","text":"<ul> <li>Dependencias: Es necesario tener las librer\u00edas <code>msal</code>, <code>pandas</code>, <code>requests</code>, y <code>xlwings</code> instaladas para que el script funcione correctamente.</li> <li>Carpetas de destino: El script crea el directorio de descarga si no existe previamente, asegurando que los archivos descargados se almacenen en la ubicaci\u00f3n correcta.</li> <li>Manejo de errores: Se incluye un manejo b\u00e1sico de errores a trav\u00e9s del registro en logs para que cualquier error durante la descarga sea f\u00e1cilmente rastreable.</li> </ul> <p>Este script facilita la integraci\u00f3n y automatizaci\u00f3n del proceso de descarga de archivos C4C desde SharePoint, ideal para sistemas de gesti\u00f3n de archivos y procesamiento de datos.</p> <pre><code>import argparse\nimport io\nimport logging\nimport os\nimport re\nimport requests\nimport time\nfrom datetime import datetime\nimport pandas as pd\nfrom msal import ConfidentialClientApplication\n</code></pre> <pre><code>from Funciones import (\n    log_step_decorator, csv_files\n)\n</code></pre> <pre><code># Cambiar el directorio de trabajo al directorio del script\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nos.chdir(script_dir)\n</code></pre> <pre><code># Leer la clave privada desde el archivo key.pem\nwith open('credenciales.env', 'r') as key_file:\n    lines = key_file.readlines()\n</code></pre> <pre><code># Procesar las claves\nkeys = {}\nfor line in lines:\n    key, value = line.strip().split(\" = \")\n    keys[key] = value.strip('\"')\n</code></pre> <pre><code>client_id = keys.get(\"client_id\")\ncert_thumbprint = keys.get(\"cert_thumbprint\")\ntenant_id = keys.get(\"tenant_id\")\n</code></pre> <pre><code>authority = f\"https://login.microsoftonline.com/{tenant_id}\"\n</code></pre> <pre><code># Leer la clave privada desde el archivo key.pem\nwith open('key.pem', 'r') as key_file:\n    private_key = key_file.read()\n</code></pre> <pre><code>cert = {\n    \"private_key\": private_key,\n    \"thumbprint\": cert_thumbprint,\n}\n</code></pre> <pre><code>msal_app = ConfidentialClientApplication(\n    client_id=client_id,\n    authority=authority,\n    client_credential=cert,\n)\n</code></pre> <pre><code>scopes_sharepoint_online = [keys.get(\"scopes_sharepoint_online\")]\n</code></pre> <pre><code>results = msal_app.acquire_token_for_client(scopes_sharepoint_online)\n</code></pre> <pre><code>if \"access_token\" in results:\n    access_token = results.get(\"access_token\")\n</code></pre> <pre><code>headers = {\n    \"Authorization\": f\"Bearer {access_token}\",\n    \"Accept\": \"application/json;odata=verbose\",\n    \"Content-Type\": \"application/json\",\n}\n</code></pre> <pre><code>sharepoint_base_url = keys.get(\"sharepoint_base_url\")\n</code></pre> <pre><code># Configuraci\u00f3n de logging y directorio de descargas\nlogger = logging.getLogger(__name__)  # Usa un logger con nombre\nlogger.setLevel(logging.INFO)\n</code></pre> <pre><code>if logger.hasHandlers():\n    logger.handlers.clear()\n</code></pre> <pre><code>formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler = logging.FileHandler(\"scraper_SSIS.log\")\nfile_handler.setFormatter(formatter)\nlogger.addHandler(file_handler)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n</code></pre> <pre><code>import warnings\n# Ignorar advertencias espec\u00edficas\nwarnings.filterwarnings(\"ignore\")\n</code></pre> <pre><code># Si hay otros loggers configurados, aseg\u00farate de ajustar su nivel tambi\u00e9n\nfor logger_name in logging.root.manager.loggerDict:\n    logging.getLogger(logger_name).setLevel(logging.INFO)\n</code></pre> <pre><code>@log_step_decorator(\"Descargar archivo de SharePoint\")\ndef download_file_from_sharepoint(file_name, folder_url, download_path):\n    # Crear las carpetas si no existen\n    if not os.path.exists(os.path.dirname(download_path)):\n        os.makedirs(os.path.dirname(download_path))\n        logging.info(f\"Carpeta creada: {os.path.dirname(download_path)}\")\n\n    # Ruta completa del archivo en SharePoint\n    logging.info(f\"Ruta completa del archivo a descargar: {download_path}\")\n\n    download_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files('{file_name}')/$value\"\n    response = requests.get(download_url, headers=headers)\n\n    if response.status_code == 200:\n        # Eliminar la marca de fecha y hora del nombre del archivo\n        clean_file_name = file_name\n        clean_download_path = os.path.join(os.path.dirname(download_path), clean_file_name)\n\n        # Guardar el archivo descargado con el nuevo nombre\n        with open(clean_download_path, \"wb\") as file:\n            file.write(response.content)\n        logging.info(f\"Archivo descargado exitosamente como: {clean_file_name}\")\n    else:\n        logging.info(f\"Error al descargar el archivo. C\u00f3digo de estado: {response.status_code}\")\n        logging.info(f\"Error: {response.text}\")\n</code></pre> <pre><code># @log_step_decorator(\"ETL\")\ndef download_all_files_from_sharepoint(folder_url, download_directory):\n    # Construye la URL para acceder a los archivos de una carpeta espec\u00edfica en SharePoint\n    folder_api_url = f\"{sharepoint_base_url}/_api/web/GetFolderByServerRelativeUrl('{folder_url}')/Files\"\n\n    # Realiza una solicitud GET a la URL de la API de SharePoint para obtener los archivos de la carpeta\n    response = requests.get(folder_api_url, headers=headers)\n    # Imprime la URL a la que se est\u00e1 conectando\n    logging.info(f\"Conectando a {folder_api_url}\")\n    # Imprime el estado de la respuesta de la solicitud\n    logging.info(f\"Estado de la respuesta: {response.status_code}\")\n\n    if response.status_code == 200:\n        # Extrae la lista de archivos de la respuesta JSON de la solicitud GET\n        files = response.json().get('d', {}).get('results', [])\n        logging.info(f\"Se encontraron {len(files)} archivos en la carpeta especificada.\")        \n        if not files:\n            logging.info(\"No se encontraron archivos en la carpeta especificada.\")\n            return\n\n        if key in csv_files:\n            extension = \"csv\"\n        else:\n            extension = \"xlsx\"\n\n        # Obtiene el nombre del archivo sin la extensi\u00f3n\n        archivo = \"Listadesolicitudesdeservicio__ES.xlsx\"\n        if archivo:\n            archivo_modelo = os.path.splitext(archivo)[0]\n            # filtra todos los archivos que inicien con archivo_modelo sin extencion y los guarda en una lista \n            files = [file for file in files if file.get('Name').startswith(archivo_modelo)]    \n            logging.info(f\"Se encontraron {len(files)} archivos que coinciden con el modelo de archivo: {archivo_modelo}\")\n        else:\n            logging.info(f\"Se encontraron {len(files)} archivos\")\n            archivo = f\"procesado_{key}.{extension}\"\n\n\n        # Itera sobre la lista de archivos y descarga cada uno\n        for file in files:\n            file_name = file.get('Name')\n            download_path = os.path.join(download_directory, file_name)\n            download_file_from_sharepoint(file_name, folder_url, download_path)\n</code></pre> <pre><code>if __name__ == \"__main__\":\n    logging.info(f'Procesando Sharepoint C4C')\n    # Actualizar root_directory para que etl_destino lo asigne\n    root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n    destino = '02.Archivos/01.Transversal/PQRs'\n    root_directory = os.path.abspath(os.path.join(root_directory1, destino))\n    logging.info(root_directory + \" \\n \" + destino)\n    # Obtener la carpeta desde la clave proporcionada\n    folder_url = 'Documentos compartidos/02.C4C'\n\n    # Descargar archivos\n    @log_step_decorator(f\"ETL Sharepoint C4C\")\n    def run_etl():\n        download_all_files_from_sharepoint(folder_url, root_directory)\n\n    run_etl()\n</code></pre>"},{"location":"00.etl/Utils/dim_Estudiantes/","title":"dim_Estudiantes","text":"<p>Este script realiza las siguientes acciones:</p> <ol> <li> <p>Carga y concatena los archivos:</p> <ul> <li><code>procesado_cede_Listado_Matriculas.xlsx</code> ubicado en <code>02.Archivos/02.Cedesarrollo/01/03.Listado_Matriculas</code>.</li> <li><code>procesado_emp_Listado_Matriculas.xlsx</code> ubicado en <code>02.Archivos/02.Cedesarrollo/02/03.Listado_Matriculas</code>.</li> </ul> </li> <li> <p>Selecciona ciertas columnas espec\u00edficas de los archivos concatenados </p> <ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO_ESTUDIANTE</code></li> <li><code>NOMBRE_ESTUDIANTE</code></li> </ul> </li> <li> <p>Guarda el resultado como <code>dim_Estudiantes.xlsx</code> en el directorio <code>02.Archivos/02.Cedesarrollo</code>.</p> </li> </ol> <p>El directorio de destino se construye din\u00e1micamente utilizando <code>os.path.join</code> y <code>os.path.abspath</code> para asegurar que la ruta sea correcta y compatible con el sistema operativo. Si el directorio no existe, el script lo crea antes de guardar el archivo <code>dim_Estudiantes.xlsx</code>.</p>"},{"location":"00.etl/Utils/dim_Estudiantes/#resumen-del-script","title":"Resumen del Script","text":"<ol> <li> <p>Importaci\u00f3n de M\u00f3dulos:</p> <ul> <li><code>os</code>: Para manejar rutas y directorios.</li> <li><code>pandas</code>: Para manipulaci\u00f3n y procesamiento de datos.</li> </ul> </li> <li> <p>Funci\u00f3n <code>genera</code>:</p> <ul> <li>Verifica si un archivo existe en una ruta espec\u00edfica.</li> <li>Lee un archivo Excel utilizando <code>pandas.read_excel</code>.</li> </ul> </li> <li> <p>Construcci\u00f3n de Directorios:</p> <ul> <li>Usa <code>os.path.join</code> para crear rutas relativas para archivos y carpetas.</li> </ul> </li> <li> <p>Concatenaci\u00f3n de Archivos:</p> <ul> <li>Concatena dos DataFrames obtenidos de los archivos Excel especificados.</li> <li>Filtra las columnas <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO_ESTUDIANTE</code>, y <code>NOMBRE_ESTUDIANTE</code>.</li> </ul> </li> <li> <p>Exportaci\u00f3n del Resultado:</p> <ul> <li>Guarda el DataFrame resultante como un archivo Excel en el directorio especificado.</li> <li>Crea el directorio si no existe.</li> </ul> </li> </ol> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo, value):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede,2)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"02\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'procesado_emp_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp,3)\n</code></pre> <pre><code>#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n# Variable cargada \"df\" del estado del Kernel\n</code></pre> <pre><code># Keep only TIPO_DOCUMENTO and DOCUMENTO columns\ndf = df[['TIPO_DOCUMENTO', 'DOCUMENTO_ESTUDIANTE','NOMBRE_ESTUDIANTE']]\nroot_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'dim_Estudiantes.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/dim_periodo_academico/","title":"dim_periodo_academico","text":"<p>Este script procesa dos archivos de excel <code>procesado_cede_Listado_Matriculas</code> y <code>procesado_emp_Listado_Matriculas</code>, genera un DataFrame con informaci\u00f3n de periodos acad\u00e9micos y lo guarda en <code>dim_periodo_academico.xlsx</code>. A continuaci\u00f3n, se desgloza las secciones m\u00e1s importantes del c\u00f3digo:</p>"},{"location":"00.etl/Utils/dim_periodo_academico/#flujo-del-script","title":"Flujo del Script","text":"<ol> <li> <p>Importaci\u00f3n de M\u00f3dulos:</p> <ul> <li><code>os</code>: Para manejar rutas de directorios.</li> <li><code>pandas</code>: Para procesar datos.</li> </ul> </li> <li> <p>Funci\u00f3n <code>genera</code>:</p> <ul> <li>Lee un archivo Excel desde una ruta especificada.</li> <li>Extrae y procesa el a\u00f1o desde la columna <code>FECHA_MATRICULA</code>.</li> <li>Duplica las filas para generar los semestres acad\u00e9micos (<code>-1</code> y <code>-2</code>).</li> <li>A\u00f1ade una columna <code>ID_UNIDAD</code> con el valor recibido como par\u00e1metro.</li> </ul> <p>Comentarios:     - Utiliza pandas para transformar fechas y manejar valores \u00fanicos.     - Crea semestres autom\u00e1ticamente con l\u00f3gica de repetici\u00f3n y sufijos.</p> </li> <li> <p>Procesamiento de Archivos:</p> <ul> <li>Carga dos archivos de Excel (<code>procesado_cede_Listado_Matriculas.xlsx</code> y <code>procesado_emp_Listado_Matriculas.xlsx</code>).</li> <li>Concatena ambos DataFrames en uno solo.</li> </ul> </li> <li> <p>C\u00e1lculo de Fechas de Inicio y Fin:</p> <ul> <li>Divide la columna <code>PERIODO</code> en <code>YEAR</code> y <code>PERIOD</code>.</li> <li>Genera <code>FECHA_INICIO</code> y <code>FECHA_FIN</code> para cada semestre:<ul> <li><code>FECHA_INICIO</code>: Calcula el primer d\u00eda del semestre.</li> <li><code>FECHA_FIN</code>: Calcula el \u00faltimo d\u00eda del semestre.</li> </ul> </li> </ul> <p>L\u00f3gica:</p> <ul> <li><code>PERIOD</code> se usa para determinar el semestre: <code>-1</code> (Enero-Junio) y <code>-2</code> (Julio-Diciembre).</li> <li>Usa <code>DateOffset</code> para sumar meses y restar d\u00edas.</li> </ul> </li> <li> <p>Exportaci\u00f3n del Resultado:</p> <ul> <li>Crea un directorio de destino si no existe.</li> <li>Guarda el DataFrame resultante en un archivo Excel llamado <code>dim_periodo_academico.xlsx</code>.</li> </ul> </li> </ol> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo, value):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    # Imprimir los nombres de las columnas\n    df = df[['FECHA_MATRICULA']]\n    # Extraer el a\u00f1o de la columna FECHA_MATRICULA\n    df['PERIODO'] = df['FECHA_MATRICULA'].dt.year\n    # Eliminar columna: 'FECHA_MATRICULA'\n    df = df.drop(columns=['FECHA_MATRICULA'])\n\n    # Dejar solo los valores \u00fanicos en df\n    df = df.drop_duplicates()\n\n    # Crear dos valores por cada valor en PERIODO\n    df = df.loc[df.index.repeat(2)].reset_index(drop=True)\n\n\n    # Add \"-1\" and \"-2\" to each PERIODO value in the same column\n    df['PERIODO'] = df['PERIODO'].astype(str) + [\"-1\", \"-2\"] * (len(df) // 2)\n\n    # Add column ID_UNIDAD with value \n    df['ID_UNIDAD'] = value\n\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede,2)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"02\",\n        \"03.Listado_Matriculas\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'procesado_emp_Listado_Matriculas.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp,3)\n</code></pre> <pre><code>#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n</code></pre> <pre><code># Convert PERIODO to datetime range\ndf[['YEAR', 'PERIOD']] = df['PERIODO'].str.split('-', expand=True)\ndf['YEAR'] = df['YEAR'].astype(int)\ndf['PERIOD'] = df['PERIOD'].astype(int)\n# Define start and end dates\ndf['FECHA_INICIO'] = pd.to_datetime(df['YEAR'].astype(str) + '-' + ((df['PERIOD'] - 1) * 6 + 1).astype(str) + '-01')\ndf['FECHA_FIN'] = df['FECHA_INICIO'] + pd.DateOffset(months=6) - pd.DateOffset(days=1)\n# Drop temporary columns\ndf.drop(columns=['YEAR', 'PERIOD'], inplace=True)\n</code></pre> <pre><code>root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'dim_periodo_academico.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\nexit(0)\n</code></pre>"},{"location":"00.etl/Utils/fact_facturacion/","title":"fact_facturacion","text":"<p>El script procesa <code>procesado_cede_Ingresos.xlsx</code> y <code>EP-EPT-06.xlsx</code> provenientes de diferentes directorios, los limpia, los concatena, convierte una columna a formato de fecha y luego guarda el DataFrame combinado en un nuevo archivo Excel <code>fact_facturacion.xlsx</code>.</p>"},{"location":"00.etl/Utils/fact_facturacion/#funcionamiento","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n de la funci\u00f3n <code>genera</code>:</p> <ul> <li> <p>Entradas:</p> <ul> <li><code>root_directory</code> (str): Directorio base donde se encuentra el archivo.</li> <li><code>archivo</code> (str): Nombre del archivo Excel a procesar.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Verifica si el archivo existe en la ruta especificada.</li> <li>Lee el archivo Excel utilizando <code>pd.read_excel</code>.</li> <li>Elimina las columnas vac\u00edas utilizando <code>dropna(axis=1, how='all')</code>.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame del archivo procesado.</li> </ul> </li> </ul> </li> <li> <p>Lectura de archivos:</p> <ul> <li>Se leen dos archivos Excel: <code>procesado_cede_Ingresos.xlsx</code> y <code>EP-EPT-06.xlsx</code>, desde sus respectivas rutas base.</li> <li>La funci\u00f3n <code>genera</code> se aplica para procesar ambos archivos.</li> </ul> </li> <li> <p>Concatenaci\u00f3n de DataFrames:</p> <ul> <li>Los DataFrames obtenidos de ambos archivos se concatenan utilizando <code>pd.concat</code>, combinando las filas de ambos archivos.</li> </ul> </li> <li> <p>Conversi\u00f3n de tipo de datos:</p> <ul> <li>La columna <code>'FECHA_CONTABLE'</code> se convierte al tipo <code>datetime64[ns]</code> utilizando <code>df.astype({'FECHA_CONTABLE': 'datetime64[ns]'})</code>.</li> </ul> </li> <li> <p>Exportaci\u00f3n a Excel:</p> <ul> <li>El DataFrame combinado se guarda en un nuevo archivo Excel (<code>fact_facturacion.xlsx</code>) en el directorio de destino especificado, creando el directorio si no existe previamente.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/fact_facturacion/#entradas","title":"Entradas","text":"<ul> <li><code>root_directory</code>: Directorio base donde se encuentran los archivos a procesar.</li> <li><code>archivo</code>: Nombre del archivo Excel a procesar.</li> </ul>"},{"location":"00.etl/Utils/fact_facturacion/#salida","title":"Salida","text":"<ul> <li><code>df</code>: DataFrame combinado y procesado de los dos archivos.</li> <li>Archivo Excel exportado: El DataFrame procesado se guarda como <code>fact_facturacion.xlsx</code> en el directorio de destino.</li> </ul> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    #elimina las columnas vacias\n    df = df.dropna(axis=1, how='all')\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"04.Ingresos\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Ingresos.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'EP-EPT-06.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp)\n</code></pre> <pre><code>#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n</code></pre> <pre><code># Cambia el tipo de columna por datetime64[ns] para la columna: 'FECHA'\ndf = df.astype({'FECHA_CONTABLE': 'datetime64[ns]'})\n</code></pre> <pre><code>root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'fact_facturacion.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/fact_graduados/","title":"fact_graduados","text":"<p>Este script procesa y combina dos archivos Excel relacionados con egresados/graduados, les agrega una columna con un identificador de unidad, limpia columnas vac\u00edas, y guarda el resultado en un nuevo archivo Excel <code>fact_egresados.xlsx</code>. </p>"},{"location":"00.etl/Utils/fact_graduados/#funcionamiento","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n de la funci\u00f3n <code>genera</code>:</p> <ul> <li> <p>Entradas:</p> <ul> <li><code>root_directory</code> (str): Directorio base donde se encuentra el archivo.</li> <li><code>archivo</code> (str): Nombre del archivo Excel a procesar.</li> <li><code>value</code> (int): Valor que se asignar\u00e1 a la nueva columna <code>ID_UNIDAD</code> en el DataFrame.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Verifica si el archivo existe en la ruta especificada.</li> <li>Lee el archivo Excel utilizando <code>pd.read_excel</code>.</li> <li>Agrega una nueva columna <code>ID_UNIDAD</code> con el valor proporcionado.</li> <li>Elimina las columnas vac\u00edas con <code>dropna(axis=1, how='all')</code>.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame con la columna adicional y las columnas vac\u00edas eliminadas.</li> </ul> </li> </ul> </li> <li> <p>Lectura de archivos:</p> <ul> <li> <p>Se leen dos archivos Excel:</p> <ul> <li><code>procesado_cede_Egresados_Graduados.xlsx</code> desde el directorio <code>02.Archivos/02.Cedesarrollo/01/06.Egresados_Graduados</code>.</li> <li><code>procesado_emp_Egresados_Graduados.xlsx</code> desde el directorio <code>02.Archivos/02.Cedesarrollo/02/06.Egresados_Graduados</code>.</li> </ul> </li> <li> <p>Se aplica la funci\u00f3n <code>genera</code> a ambos archivos, agregando los valores de <code>ID_UNIDAD</code> como 2 y 3 respectivamente.</p> </li> </ul> </li> <li> <p>Modificaci\u00f3n de DataFrame:</p> <ul> <li>Se agrega una columna <code>DIPLOMA_GRADUADO</code> vac\u00eda al DataFrame <code>df_cede</code>.</li> </ul> </li> <li> <p>Concatenaci\u00f3n de DataFrames:</p> <ul> <li>Se concatenan los DataFrames <code>df_cede</code> y <code>df_emp</code> en un \u00fanico DataFrame.</li> </ul> </li> <li> <p>Exportaci\u00f3n a Excel:</p> <ul> <li>El DataFrame combinado se guarda en un archivo Excel llamado <code>fact_egresados.xlsx</code> en el directorio de destino <code>02.Archivos/02.Cedesarrollo</code>.</li> </ul> </li> <li> <p>Creaci\u00f3n del directorio de destino (si no existe):</p> <ul> <li>Si el directorio de destino no existe, se crea utilizando <code>os.makedirs()</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/fact_graduados/#entradas","title":"Entradas","text":"<ul> <li><code>root_directory</code>: Directorio base donde se encuentran los archivos a procesar.</li> <li><code>archivo</code>: Nombre del archivo Excel a procesar.</li> <li><code>value</code>: Valor para la columna <code>ID_UNIDAD</code>.</li> </ul>"},{"location":"00.etl/Utils/fact_graduados/#salida","title":"Salida","text":"<ul> <li><code>df</code>: DataFrame combinado y procesado de los dos archivos.</li> <li>Archivo Excel exportado: El DataFrame combinado se guarda como <code>fact_egresados.xlsx</code> en el directorio de destino.</li> </ul> <pre><code>import os\nimport pandas as pd\n# pylint: disable=all\n</code></pre> <pre><code>def genera(root_directory, archivo, value):\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    df = pd.read_excel(ruta_archivo)\n\n    # Add column ID_UNIDAD with value \n    df['ID_UNIDAD'] = value    \n    #elimina las columnas vacias\n    df = df.dropna(axis=1, how='all')\n    return df\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"01\",\n        \"06.Egresados_Graduados\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_cede = 'procesado_cede_Egresados_Graduados.xlsx'\n</code></pre> <pre><code>df_cede = genera(root_directory, archivo_cede,2)\n</code></pre> <pre><code>root_directory = os.path.abspath(\n    os.path.join(\n        os.getcwd(),\n        \"..\",\n        \"..\",\n        \"02.Archivos\",\n        \"02.Cedesarrollo\",\n        \"02\",\n        \"06.Egresados_Graduados\"\n    )\n)\n</code></pre> <pre><code># Nombre del archivo\narchivo_emp = 'procesado_emp_Egresados_Graduados.xlsx'\n</code></pre> <pre><code>df_emp = genera(root_directory, archivo_emp,3)\n</code></pre> <pre><code>df_cede['DIPLOMA_GRADUADO'] = ''\n#concatenar los df\ndf = pd.concat([df_cede, df_emp], ignore_index=True)\n</code></pre> <pre><code>root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n# Actualizar root_directory para que etl_destino lo asigne\ndestino = '02.Archivos/02.Cedesarrollo'\nroot_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n</code></pre> <pre><code># Crear el directorio si no existe\nif not os.path.exists(root_directory):\n    os.makedirs(root_directory)\n#guarda en excel \ndf.to_excel(os.path.join(root_directory, 'fact_egresados.xlsx'), index=False)\nprint(\"Exportaci\u00f3n exitosa\")\n</code></pre>"},{"location":"00.etl/Utils/fact_listado_matriculas/","title":"fact_listado_matriculas","text":"<p>Este script procesa dos archivos CSV relacionados con el listado de matr\u00edculas, les agrega una columna con un identificador de unidad, los concatena en un solo DataFrame y guarda el resultado en un nuevo archivo CSV <code>fact_listado_matriculas.csv</code>. </p>"},{"location":"00.etl/Utils/fact_listado_matriculas/#funcionamiento","title":"Funcionamiento","text":"<ol> <li> <p>Definici\u00f3n de la funci\u00f3n <code>genera</code>:</p> <ul> <li> <p>Entradas:</p> <ul> <li><code>root_directory</code> (str): Directorio base donde se encuentra el archivo.</li> <li><code>archivo</code> (str): Nombre del archivo CSV a procesar.</li> <li><code>value</code> (int): Valor que se asignar\u00e1 a la nueva columna <code>ID_UNIDAD</code> en el DataFrame.</li> </ul> </li> <li> <p>Acciones:</p> <ul> <li>Verifica si el archivo existe en la ruta especificada.</li> <li>Lee el archivo CSV utilizando <code>pd.read_csv</code>, con codificaci\u00f3n UTF-8.</li> <li>Agrega una nueva columna <code>ID_UNIDAD</code> con el valor proporcionado.</li> </ul> </li> <li> <p>Salida:</p> <ul> <li>Devuelve el DataFrame con la columna adicional <code>ID_UNIDAD</code>.</li> </ul> </li> </ul> </li> <li> <p>Lectura de archivos:</p> <ul> <li> <p>Se leen dos archivos CSV:</p> <ul> <li><code>procesado_cede_Listado_Matriculas.csv</code> desde el directorio <code>02.Archivos/02.Cedesarrollo/01/03.Listado_Matriculas</code>.</li> <li><code>procesado_emp_Listado_Matriculas.csv</code> desde el directorio <code>02.Archivos/02.Cedesarrollo/02/03.Listado_Matriculas</code>.</li> </ul> </li> <li> <p>Se aplica la funci\u00f3n <code>genera</code> a ambos archivos, agregando los valores de <code>ID_UNIDAD</code> como 2 y 3 respectivamente.</p> </li> </ul> </li> <li> <p>Concatenaci\u00f3n de DataFrames:</p> <ul> <li>Los DataFrames <code>df_cede</code> y <code>df_emp</code> se concatenan en un \u00fanico DataFrame (<code>df</code>).</li> </ul> </li> <li> <p>Exportaci\u00f3n a CSV:</p> <ul> <li>El DataFrame combinado se guarda en un nuevo archivo CSV llamado <code>fact_listado_matriculas.csv</code> en el directorio de destino <code>02.Archivos/02.Cedesarrollo</code>.</li> </ul> </li> <li> <p>Creaci\u00f3n del directorio de destino (si no existe):</p> <ul> <li>Si el directorio de destino no existe, se crea utilizando <code>os.makedirs()</code>.</li> </ul> </li> </ol>"},{"location":"00.etl/Utils/fact_listado_matriculas/#entradas","title":"Entradas","text":"<ul> <li><code>root_directory</code>: Directorio base donde se encuentran los archivos a procesar.</li> <li><code>archivo</code>: Nombre del archivo CSV a procesar.</li> <li><code>value</code>: Valor para la columna <code>ID_UNIDAD</code>.</li> </ul>"},{"location":"00.etl/Utils/fact_listado_matriculas/#salida","title":"Salida","text":"<ul> <li><code>df</code>: DataFrame combinado y procesado de los dos archivos.</li> <li>Archivo CSV exportado: El DataFrame combinado se guarda como <code>fact_listado_matriculas.csv</code> en el directorio de destino.</li> </ul> <pre><code># pylint: disable=all\nimport os\nimport pandas as pd\nfrom Funciones import log_step_decorator\n</code></pre> <pre><code>@log_step_decorator(\"Generando el DataFrame a partir del archivo...\")\ndef genera(root_directory, archivo, value):\n    print(f\"Generando el DataFrame a partir del archivo '{archivo}'...\")\n    # Definir el directorio ra\u00edz\n    # Construir la ruta completa\n    ruta_archivo = os.path.join(root_directory, archivo)\n\n    # Verificar si el archivo existe\n    if not os.path.exists(ruta_archivo):\n        raise FileNotFoundError(f\"El archivo '{archivo}' no se encuentra en la ruta especificada: {ruta_archivo}\")\n\n    # Leer el archivo Excel\n    # df = pd.read_excel(ruta_archivo)\n\n    # Leer el archivo csv\n    df = pd.read_csv(ruta_archivo, sep=',', encoding='utf-8')\n\n    #agrega ID_UNIDAD al df con valor value\n    df['ID_UNIDAD'] = value\n\n    print(\"El DataFrame ha sido generado exitosamente. No de registros cargados: \", len(df))\n\n    return df\n</code></pre> <pre><code>@log_step_decorator(\"Procesando Listado Matriculas emp y cede\")\ndef main():\n    root_directory = os.path.abspath(\n        os.path.join(\n            os.getcwd(),\n            \"..\",\n            \"..\",\n            \"02.Archivos\",\n            \"02.Cedesarrollo\",\n            \"01\",\n            \"03.Listado_Matriculas\"\n        )\n    )\n\n    # Nombre del archivo\n    archivo_cede = 'procesado_cede_Listado_Matriculas.csv'\n\n    df_cede = genera(root_directory, archivo_cede,2)\n\n    root_directory = os.path.abspath(\n        os.path.join(\n            os.getcwd(),\n            \"..\",\n            \"..\",\n            \"02.Archivos\",\n            \"02.Cedesarrollo\",\n            \"02\",\n            \"03.Listado_Matriculas\"\n        )\n    )\n\n\n    # Nombre del archivo\n    archivo_emp = 'procesado_emp_Listado_Matriculas.csv'\n\n    df_emp = genera(root_directory, archivo_emp,3)\n\n    #concatenar los df\n    print(\"Concatenando los DataFrames...\")\n    df = pd.concat([df_cede, df_emp], ignore_index=True)\n    # Variable cargada \"df\" del estado del Kernel\n\n    print(\"El DataFrame ha sido concatenado exitosamente. No de registros cargados: \", len(df))\n\n    root_directory1 = os.path.join(os.getcwd(), \"..\", \"..\")\n    # Actualizar root_directory para que etl_destino lo asigne\n    destino = '02.Archivos/02.Cedesarrollo'\n    root_directory = os.path.abspath(os.path.join(root_directory1, destino.replace(\"/\", os.sep)))\n\n    # Crear el directorio si no existe\n    if not os.path.exists(root_directory):\n        os.makedirs(root_directory)\n    #guarda en excel \n    df.to_csv(os.path.join(root_directory, 'fact_listado_matriculas.csv'), index=False, encoding='utf-8')\n</code></pre> <pre><code>if __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/","title":"00.DimTiempo","text":""},{"location":"01.scripts/00.DimTiempo/#documentacion-del-script-sql-para-el-esquema-dimensiones-tiempo","title":"Documentaci\u00f3n del Script SQL para el Esquema <code>Dimensiones Tiempo</code>","text":""},{"location":"01.scripts/00.DimTiempo/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL pertenece a un sistema de manejo de datos en un Data Warehouse, espec\u00edficamente en el esquema <code>Dwh</code>. Su prop\u00f3sito es eliminar restricciones de claves for\u00e1neas en las tablas del esquema, eliminar las tablas y el esquema, y luego crear el esquema y la tabla <code>DIM_TIEMPO</code>. A continuaci\u00f3n, se detallan las secciones del c\u00f3digo.</p>"},{"location":"01.scripts/00.DimTiempo/#descripcion-del-codigo","title":"Descripci\u00f3n del C\u00f3digo","text":""},{"location":"01.scripts/00.DimTiempo/#1-contexto-inicial","title":"1. Contexto Inicial","text":"<p>El script comienza seleccionando la base de datos <code>DWH_COMFENALCO</code> y establece configuraciones iniciales como <code>ANSI_NULLS</code> y <code>QUOTED_IDENTIFIER</code> para asegurar el comportamiento est\u00e1ndar de SQL Server.</p> <pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n</code></pre> <ul> <li><code>USE DWH_COMFENALCO</code>: Cambia el contexto de ejecuci\u00f3n a la base de datos <code>DWH_COMFENALCO</code>.</li> <li><code>SET ANSI_NULLS ON</code>: Habilita el tratamiento est\u00e1ndar de valores <code>NULL</code> en operaciones comparativas.</li> <li><code>SET QUOTED_IDENTIFIER ON</code>: Permite usar nombres de identificadores entre comillas dobles.</li> </ul>"},{"location":"01.scripts/00.DimTiempo/#2-eliminar-restricciones-de-claves-foraneas","title":"2. Eliminar Restricciones de Claves For\u00e1neas","text":"<p>Se utiliza un procedimiento din\u00e1mico para eliminar todas las restricciones de claves for\u00e1neas asociadas al esquema <code>Dwh</code>.</p> <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Dwh';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/#desglose","title":"Desglose:","text":"<ol> <li><code>sys.foreign_keys</code>: Obtiene informaci\u00f3n de todas las claves for\u00e1neas en las tablas.</li> <li><code>sys.tables</code> y <code>sys.schemas</code>: Se utiliza para vincular las tablas a sus esquemas.</li> <li>Construcci\u00f3n din\u00e1mica: El c\u00f3digo genera comandos <code>ALTER TABLE</code> para eliminar cada restricci\u00f3n.</li> <li><code>EXEC sp_executesql</code>: Ejecuta los comandos generados din\u00e1micamente.</li> </ol> <p>Motivaci\u00f3n: Esto es \u00fatil para realizar cambios en las estructuras de las tablas sin conflictos con dependencias existentes.</p>"},{"location":"01.scripts/00.DimTiempo/#3-eliminar-tablas-y-esquema","title":"3. Eliminar Tablas y Esquema","text":"<p>El script elimina todas las tablas del esquema <code>Dwh</code> y luego elimina el esquema.</p> <pre><code>-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Dwh';\nEXEC sp_executesql @sql;\n\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Dwh')\nBEGIN\n    DROP SCHEMA Dwh;\nEND\nGO\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/#desglose_1","title":"Desglose:","text":"<ol> <li>Eliminar tablas: Genera y ejecuta comandos <code>DROP TABLE</code> para eliminar todas las tablas del esquema <code>Dwh</code>.</li> <li>Eliminar esquema: Verifica si el esquema <code>Dwh</code> existe y lo elimina si es as\u00ed.</li> </ol> <p>Motivaci\u00f3n: Esto asegura que el esquema <code>Dwh</code> y sus tablas sean eliminados antes de recrearlos.</p>"},{"location":"01.scripts/00.DimTiempo/#4-crear-esquema-y-tabla-dim_tiempo","title":"4. Crear Esquema y Tabla <code>DIM_TIEMPO</code>","text":"<p>El script crea el esquema <code>Dwh</code> y la tabla <code>DIM_TIEMPO</code> con sus respectivas columnas.</p> <pre><code>-- Crear el esquema Dwh\nCREATE SCHEMA Dwh;\nGO\n\n-- Crear DIM_TIEMPO\nCREATE TABLE [Dwh].[DIM_TIEMPO](\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NULL,\n    [DESC_FECHA] [varchar](50) NULL,\n    [ID_SEMANA] [int] NULL,\n    [DESC_SEMANA] [varchar](50) NULL,\n    [ID_NO_MES] [int] NULL,\n    [DESC_NO_MES] [varchar](50) NULL,\n    [ID_MES] [int] NULL,\n    [DESC_MES] [varchar](50) NULL,\n    [DESC_MES_CORTA] [varchar](50) NULL,\n    [ID_BIMESTRE] [int] NULL,\n    [DESC_BIMESTRE] [varchar](50) NULL,\n    [ID_TRIMESTRE] [int] NULL,\n    [DESC_TRIMESTRE] [varchar](50) NULL,\n    [ID_CUATRIMESTRE] [int] NULL,\n    [DESC_CUATRIMESTRE] [varchar](50) NULL\n);\nGO\n</code></pre>"},{"location":"01.scripts/00.DimTiempo/#desglose_2","title":"Desglose:","text":"<ol> <li>Crear esquema: Crea el esquema <code>Dwh</code>.</li> <li>Crear tabla <code>DIM_TIEMPO</code>: Define la tabla <code>DIM_TIEMPO</code> con sus columnas y tipos de datos.</li> </ol> <p>Motivaci\u00f3n: Esto establece la estructura necesaria para almacenar datos de tiempo en el esquema <code>Dwh</code>.</p>"},{"location":"01.scripts/00.DimTiempo/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li> <p>Uso de Restricciones de Integridad:</p> <ul> <li>La eliminaci\u00f3n y recreaci\u00f3n de restricciones asegura la integridad de los datos.</li> </ul> </li> <li> <p>Automatizaci\u00f3n en la Eliminaci\u00f3n de Restricciones:</p> <ul> <li>Permite realizar modificaciones estructurales masivas sin errores manuales.</li> </ul> </li> <li> <p>Configuraciones Iniciales:</p> <ul> <li>Se asegura un comportamiento est\u00e1ndar al trabajar con valores <code>NULL</code> y nombres de columnas.</li> </ul> </li> <li> <p>Modularidad y Dinamismo:</p> <ul> <li>El script est\u00e1 dise\u00f1ado para ser modular y din\u00e1mico, facilitando modificaciones estructurales complejas.</li> </ul> </li> <li> <p>Uso de Procedimientos Din\u00e1micos:</p> <ul> <li>La construcci\u00f3n din\u00e1mica de comandos SQL permite una mayor flexibilidad y adaptabilidad.</li> </ul> </li> <li> <p>Definici\u00f3n Clara de Esquemas:</p> <ul> <li>Las tablas y sus relaciones est\u00e1n claramente definidas, lo que mejora la comprensi\u00f3n y mantenimiento del c\u00f3digo.</li> </ul> </li> </ol>"},{"location":"01.scripts/00.DimTiempo/#diagrama-de-relacion-de-tablas","title":"Diagrama de Relaci\u00f3n de Tablas","text":"<pre><code>erDiagram\n    DIM_TIEMPO {\n        int ID_FECHA PK\n        datetime FECHA\n        varchar(50) DESC_FECHA\n        int ID_SEMANA\n        varchar(50) DESC_SEMANA\n        int ID_NO_MES\n        varchar(50) DESC_NO_MES\n        int ID_MES\n        varchar(50) DESC_MES\n        varchar(50) DESC_MES_CORTA\n        int ID_BIMESTRE\n        varchar(50) DESC_BIMESTRE\n        int ID_TRIMESTRE\n        varchar(50) DESC_TRIMESTRE\n        int ID_CUATRIMESTRE\n        varchar(50) DESC_CUATRIMESTRE\n    }</code></pre>"},{"location":"01.scripts/00.DimTiempo/#conclusion","title":"Conclusi\u00f3n","text":"<p>Este script SQL est\u00e1 dise\u00f1ado para gestionar de manera eficiente la eliminaci\u00f3n y creaci\u00f3n de estructuras de datos en el esquema <code>Dwh</code>. La automatizaci\u00f3n y modularidad implementadas aseguran que las operaciones se realicen de manera consistente y sin errores, facilitando el mantenimiento y la evoluci\u00f3n del Data Warehouse.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/","title":"00.DimensionesColegio a local","text":""},{"location":"01.scripts/00.DimensionesColegio_a_local/#documentacion-del-script-sql-para-el-esquema-dimensiones-colegio","title":"Documentaci\u00f3n del Script SQL para el Esquema <code>Dimensiones Colegio</code>","text":""},{"location":"01.scripts/00.DimensionesColegio_a_local/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL pertenece a un sistema de manejo de datos en un Data Warehouse, espec\u00edficamente en el esquema <code>Colegio</code>. Su prop\u00f3sito es eliminar restricciones de claves for\u00e1neas en las tablas del esquema, y luego realizar configuraciones de integridad referencial mediante la definici\u00f3n de claves primarias. A continuaci\u00f3n, se detallan las secciones del c\u00f3digo.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#descripcion-del-codigo","title":"Descripci\u00f3n del C\u00f3digo","text":""},{"location":"01.scripts/00.DimensionesColegio_a_local/#1-contexto-inicial","title":"1. Contexto Inicial","text":"<p>El script comienza seleccionando la base de datos <code>DWH_COMFENALCO</code> y establece configuraciones iniciales como <code>ANSI_NULLS</code> y <code>QUOTED_IDENTIFIER</code> para asegurar el comportamiento est\u00e1ndar de SQL Server.</p> <pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n</code></pre> <ul> <li><code>USE DWH_COMFENALCO</code>: Cambia el contexto de ejecuci\u00f3n a la base de datos <code>DWH_COMFENALCO</code>.</li> <li><code>SET ANSI_NULLS ON</code>: Habilita el tratamiento est\u00e1ndar de valores <code>NULL</code> en operaciones comparativas.</li> <li><code>SET QUOTED_IDENTIFIER ON</code>: Permite usar nombres de identificadores entre comillas dobles.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#2-eliminar-restricciones-de-claves-foraneas","title":"2. Eliminar Restricciones de Claves For\u00e1neas","text":"<p>Se utiliza un procedimiento din\u00e1mico para eliminar todas las restricciones de claves for\u00e1neas asociadas al esquema <code>Colegio</code>.</p> <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Colegio';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#desglose","title":"Desglose:","text":"<ol> <li><code>sys.foreign_keys</code>: Obtiene informaci\u00f3n de todas las claves for\u00e1neas en las tablas.</li> <li><code>sys.tables</code> y <code>sys.schemas</code>: Se utiliza para vincular las tablas a sus esquemas.</li> <li>Construcci\u00f3n din\u00e1mica: El c\u00f3digo genera comandos <code>ALTER TABLE</code> para eliminar cada restricci\u00f3n.</li> <li><code>EXEC sp_executesql</code>: Ejecuta los comandos generados din\u00e1micamente.</li> </ol> <p>Motivaci\u00f3n: Esto es \u00fatil para realizar cambios en las estructuras de las tablas sin conflictos con dependencias existentes.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#3-creacion-de-tablas-comentarios","title":"3. Creaci\u00f3n de Tablas (Comentarios)","text":"<p>Las tablas <code>DIM_CURSO</code>, <code>DIM_GRADO</code> y <code>DIM_POBLACION_MATRICULA</code> est\u00e1n definidas en comentarios como referencia.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#definicion-de-la-tablas","title":"Definici\u00f3n de la tablas","text":"<pre><code>CREATE TABLE [Colegio].[DIM_CURSO](\n    [ID_CURSO] [int] NOT NULL,\n    [DESC_CURSO] [nvarchar](100) NULL,\n    [FECHA_CREACION] [date] NULL,\n    [ESTADO_REGISTRO] [nvarchar](20) NULL\n) ON [PRIMARY]\n\nCREATE TABLE [Colegio].[DIM_GRADO](\n    [ID_GRADO] [int] IDENTITY(1,1) NOT NULL,\n    [DESC_GRADO] [nvarchar](100) NULL,\n    [FECHA_CREACION] [date] NULL,\n    [ESTADO_REGISTRO] [nvarchar](20) NULL\n) ON [PRIMARY]\n\nCREATE TABLE [Colegio].[DIM_POBLACION_MATRICULA](\n    [ID_POBLACION_MATRICULA] [int] IDENTITY(1,1) NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [NOMBRE_COMPLETO] [nvarchar](4000) NULL,\n    [GENERO] [varchar](20) NULL,\n    [DIRECCION] [nvarchar](300) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [CORREO] [nvarchar](250) NULL,\n    [FECHA_NACIMIENTO] [int] NULL\n) ON [PRIMARY]\n</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#campos-de-la-tabla-dim_curso","title":"Campos de la Tabla <code>DIM_CURSO</code>","text":"<ul> <li><code>ID_CURSO</code>: Identificador \u00fanico de la tabla <code>DIM_CURSO</code> (clave primaria).</li> <li><code>DESC_CURSO</code>: Descripci\u00f3n del curso en la tabla <code>DIM_CURSO</code>.</li> <li><code>FECHA_CREACION</code>: Fecha en que se cre\u00f3 el curso en la tabla <code>DIM_CURSO</code>.</li> <li><code>ESTADO_REGISTRO</code>: Indica si el registro est\u00e1 activo o inactivo en la tabla <code>DIM_CURSO</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#campos-de-la-tabla-dim_grado","title":"Campos de la Tabla <code>DIM_GRADO</code>","text":"<ul> <li><code>ID_GRADO</code>: Identificador \u00fanico de la tabla <code>DIM_GRADO</code> (clave primaria).</li> <li><code>DESC_GRADO</code>: Descripci\u00f3n del grado en la tabla <code>DIM_GRADO</code>.</li> <li><code>FECHA_CREACION</code>: Fecha en que se cre\u00f3 el grado en la tabla <code>DIM_GRADO</code>.</li> <li><code>ESTADO_REGISTRO</code>: Indica si el registro est\u00e1 activo o inactivo en la tabla <code>DIM_GRADO</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#campos-de-la-tabla-dim_poblacion_matricula","title":"Campos de la Tabla <code>DIM_POBLACION_MATRICULA</code>","text":"<ul> <li><code>ID_POBLACION_MATRICULA</code>: Identificador \u00fanico de la tabla <code>DIM_POBLACION_MATRICULA</code> (clave primaria).</li> <li><code>PARTNER</code>: Identificador del socio en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>TIPO_DOCUMENTO</code>: Tipo de documento en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>DOCUMENTO</code>: N\u00famero de documento en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>NOMBRE_COMPLETO</code>: Nombre completo del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>GENERO</code>: G\u00e9nero del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>DIRECCION</code>: Direcci\u00f3n del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>TELEFONO</code>: Tel\u00e9fono del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>CORREO</code>: Correo electr\u00f3nico del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li><code>FECHA_NACIMIENTO</code>: Fecha de nacimiento del individuo en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#4-definicion-de-claves-primarias","title":"4. Definici\u00f3n de Claves Primarias","text":"<p>El script define claves primarias para las tablas <code>DIM_POBLACION_MATRICULA</code>, <code>DIM_CURSO</code> y <code>DIM_GRADO</code>.</p>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#claves-primarias","title":"Claves primarias","text":"<pre><code>ALTER TABLE [Colegio].[DIM_POBLACION_MATRICULA]  WITH NOCHECK ADD  CONSTRAINT [PK_DIM_POBLACION_MATRICULA] PRIMARY KEY CLUSTERED ([ID_POBLACION_MATRICULA])\n\nALTER TABLE [Colegio].[DIM_CURSO]  WITH NOCHECK ADD  CONSTRAINT [PK_DIM_CURSO] PRIMARY KEY CLUSTERED ([ID_CURSO])\n\nALTER TABLE [Colegio].[DIM_GRADO]  WITH NOCHECK ADD  CONSTRAINT [PK_DIM_GRADO] PRIMARY KEY CLUSTERED ([ID_GRADO])\n</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#detalles","title":"Detalles:","text":"<ul> <li><code>WITH NOCHECK</code>: No verifica los datos existentes en la tabla antes de aplicar la restricci\u00f3n.</li> <li><code>PRIMARY KEY CLUSTERED</code>: Define una clave primaria con un \u00edndice cl\u00fasterado basado en <code>ID_POBLACION_MATRICULA</code>.</li> </ul>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#claves-primarias-definidas","title":"Claves Primarias Definidas:","text":"Tabla Clave Primaria <code>DIM_POBLACION_MATRICULA</code> <code>ID_POBLACION_MATRICULA</code> <code>DIM_CURSO</code> <code>ID_CURSO</code> <code>DIM_GRADO</code> <code>ID_GRADO</code>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#diagrama-de-relacion-de-tablas","title":"Diagrama de Relaci\u00f3n de Tablas","text":"<pre><code>erDiagram\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION_MATRICULA PK\n        nvarchar(10) PARTNER\n        nvarchar(4) TIPO_DOCUMENTO\n        nvarchar(20) DOCUMENTO\n        nvarchar(4000) NOMBRE_COMPLETO\n        varchar(20) GENERO\n        nvarchar(300) DIRECCION\n        nvarchar(30) TELEFONO\n        nvarchar(250) CORREO\n        int FECHA_NACIMIENTO\n    }\n\n    DIM_CURSO {\n        int ID_CURSO PK\n        nvarchar(100) DESC_CURSO\n        date FECHA_CREACION\n        nvarchar(20) ESTADO_REGISTRO\n    }\n\n    DIM_GRADO {\n        int ID_GRADO PK\n        nvarchar(100) DESC_GRADO\n        date FECHA_CREACION\n        nvarchar(20) ESTADO_REGISTRO\n    }</code></pre>"},{"location":"01.scripts/00.DimensionesColegio_a_local/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li> <p>Uso de Restricciones de Integridad:</p> <ul> <li>Claves primarias garantizan la unicidad de registros y optimizan las consultas.</li> </ul> </li> <li> <p>Automatizaci\u00f3n en la Eliminaci\u00f3n de Restricciones:</p> <ul> <li>Permite realizar modificaciones estructurales masivas sin errores manuales.</li> </ul> </li> <li> <p>Comentarios:</p> <ul> <li>Las definiciones de tablas est\u00e1n comentadas como referencia.</li> </ul> </li> <li> <p>Configuraciones Iniciales:</p> <ul> <li>Se asegura un comportamiento est\u00e1ndar al trabajar con valores <code>NULL</code> y nombres de columnas.</li> </ul> </li> <li> <p>Modularidad y Dinamismo:</p> <ul> <li>El script est\u00e1 dise\u00f1ado para ser modular y din\u00e1mico, facilitando modificaciones estructurales complejas.</li> </ul> </li> <li> <p>Uso de Procedimientos Din\u00e1micos:</p> <ul> <li>La construcci\u00f3n din\u00e1mica de comandos SQL permite una mayor flexibilidad y adaptabilidad.</li> </ul> </li> <li> <p>Definici\u00f3n Clara de Esquemas:</p> <ul> <li>Las tablas y sus relaciones est\u00e1n claramente definidas, lo que mejora la comprensi\u00f3n y mantenimiento del c\u00f3digo.</li> </ul> </li> <li> <p>Garant\u00eda de Integridad Referencial:</p> <ul> <li>La definici\u00f3n de claves primarias y la eliminaci\u00f3n controlada de restricciones aseguran la integridad referencial del esquema.</li> </ul> </li> </ol>"},{"location":"01.scripts/00.Eliminar_todo/","title":"00. Eliminar Todo","text":""},{"location":"01.scripts/00.Eliminar_todo/#eliminar-todo","title":"Eliminar Todo","text":""},{"location":"01.scripts/00.Eliminar_todo/#descripcion-del-script","title":"Descripci\u00f3n del Script","text":"<p>El prop\u00f3sito del script SQL proporcionado es realizar una limpieza completa de los esquemas en una base de datos denominada <code>DWH_COMFENALCO</code>. Incluye la eliminaci\u00f3n de restricciones, tablas y esquemas espec\u00edficos para preparar la base de datos para un nuevo esquema o estructura de datos. A continuaci\u00f3n, se detalla el proceso ejecutado:</p>"},{"location":"01.scripts/00.Eliminar_todo/#componentes-y-pasos-del-script","title":"Componentes y Pasos del Script","text":""},{"location":"01.scripts/00.Eliminar_todo/#1-uso-del-contexto-de-la-base-de-datos","title":"1. Uso del Contexto de la Base de Datos","text":"<p><pre><code>USE DWH_COMFENALCO;\nGO\n</code></pre> Selecciona la base de datos <code>DWH_COMFENALCO</code> como contexto para las operaciones subsecuentes.</p>"},{"location":"01.scripts/00.Eliminar_todo/#2-configuraciones-iniciales","title":"2. Configuraciones Iniciales","text":"<p><pre><code>SET ANSI_NULLS ON;\nSET QUOTED_IDENTIFIER ON;\nGO\n</code></pre> Configura opciones para garantizar compatibilidad con valores nulos y el uso de identificadores entre comillas dobles en las consultas.</p>"},{"location":"01.scripts/00.Eliminar_todo/#3-eliminacion-de-restricciones-de-clave-foranea","title":"3. Eliminaci\u00f3n de Restricciones de Clave For\u00e1nea","text":"<p>Por cada esquema (<code>Colegio</code>, <code>Protecci\u00f3n</code>, <code>Cedesarrollo</code>, y <code>Transversal</code>), el script: 1. Busca las restricciones de clave for\u00e1nea. 2. Genera din\u00e1micamente comandos <code>ALTER TABLE ... DROP CONSTRAINT</code>. 3. Ejecuta estos comandos utilizando <code>sp_executesql</code>.</p> <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Colegio';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.Eliminar_todo/#4-eliminacion-de-tablas","title":"4. Eliminaci\u00f3n de Tablas","text":"<p>Una vez eliminadas las restricciones, el script elimina las tablas del esquema utilizando un proceso similar: 1. Genera comandos <code>DROP TABLE</code> din\u00e1micamente. 2. Ejecuta los comandos para cada tabla del esquema correspondiente.</p> <pre><code>SET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Proteccion';\nEXEC sp_executesql @sql;\n</code></pre>"},{"location":"01.scripts/00.Eliminar_todo/#5-eliminacion-de-esquemas","title":"5. Eliminaci\u00f3n de Esquemas","text":"<p>Si un esquema existe despu\u00e9s de la eliminaci\u00f3n de tablas, se elimina con <code>DROP SCHEMA</code>.</p> <pre><code>IF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Transversal')\nBEGIN\n    DROP SCHEMA Transversal;\nEND\n</code></pre>"},{"location":"01.scripts/00.Eliminar_todo/#6-esquemas-y-tablas-afectados","title":"6. Esquemas y Tablas Afectados","text":"Esquema Tablas Incluidas Colegio <code>FACT_LEGALIZACION</code>, <code>FACT_ENFERMERIA</code>, <code>FACT_NOTAS</code>, etc. Proteccion <code>FACT_PLAN_COBERTURA</code>, <code>FACT_DESERCION</code>, etc. Cedesarrollo <code>FACT_NOTAS</code>, <code>FACT_INASISTENCIAS</code>, etc. Transversal Todas las tablas asociadas."},{"location":"01.scripts/00.Eliminar_todo/#consideraciones","title":"Consideraciones","text":"<ol> <li>Impacto del Script:</li> <li>Elimina de manera irreversible todas las tablas, restricciones y esquemas mencionados.</li> <li> <p>Se debe realizar una copia de seguridad previa si se requiere preservar datos.</p> </li> <li> <p>Ejecutar con Precauci\u00f3n:</p> </li> <li>Valide que los esquemas y tablas ya no son necesarios antes de ejecutar el script.</li> <li> <p>Considere ambientes de desarrollo para pruebas iniciales.</p> </li> <li> <p>Optimizaci\u00f3n del Proceso:</p> </li> <li>Los comandos din\u00e1micos utilizados son eficientes para manejar grandes cantidades de tablas y restricciones de forma automatizada.</li> </ol>"},{"location":"01.scripts/00.Eliminar_todo/#uso-sugerido","title":"Uso Sugerido","text":"<p>Este script es \u00fatil para: - Reiniciar un Data Warehouse antes de una nueva carga de datos. - Eliminar estructuras no necesarias en ambientes de desarrollo o pruebas.</p>"},{"location":"01.scripts/00.Inicio/","title":"Introducci\u00f3n","text":""},{"location":"01.scripts/00.Inicio/#documentacion-de-diseno-e-implementacion-del-data-warehouse-dwh_comfenalco","title":"Documentaci\u00f3n de Dise\u00f1o e Implementaci\u00f3n del Data Warehouse: <code>DWH_COMFENALCO</code>","text":""},{"location":"01.scripts/00.Inicio/#introduccion","title":"Introducci\u00f3n","text":"<p>El <code>DWH_COMFENALCO</code> es un Data Warehouse dise\u00f1ado para gestionar y analizar informaci\u00f3n relacionada con diversas \u00e1reas de la organizaci\u00f3n, como la educaci\u00f3n, bienestar social, protecci\u00f3n, y programas transversales. Este proyecto se estructura bajo un enfoque de modelado dimensional para optimizar la consulta y an\u00e1lisis de datos, y se apoya en una organizaci\u00f3n jer\u00e1rquica y relacional de tablas <code>dimensionales</code> y <code>hechos</code>.</p>"},{"location":"01.scripts/00.Inicio/#objetivos","title":"Objetivos","text":""},{"location":"01.scripts/00.Inicio/#objetivo-general","title":"Objetivo General","text":"<p>Crear una plataforma de datos robusta y optimizada que permita a las \u00e1reas interesadas acceder a informaci\u00f3n estrat\u00e9gica para la toma de decisiones basada en datos hist\u00f3ricos y actuales.</p>"},{"location":"01.scripts/00.Inicio/#objetivos-especificos","title":"Objetivos Espec\u00edficos","text":"<ol> <li>Estandarizar y centralizar la informaci\u00f3n proveniente de diferentes fuentes operativas.</li> <li>Dise\u00f1ar un esquema relacional que permita realizar an\u00e1lisis detallados por dimensiones clave (e.g., tiempo, poblaci\u00f3n, programas, etc.).</li> <li>Implementar \u00edndices y claves for\u00e1neas para optimizar el rendimiento de las consultas.</li> <li>Facilitar la integraci\u00f3n y an\u00e1lisis de informaci\u00f3n para \u00e1reas como colegios, protecci\u00f3n social y desarrollo acad\u00e9mico.</li> <li>Garantizar la escalabilidad para futuros m\u00f3dulos o esquemas.</li> </ol>"},{"location":"01.scripts/00.Inicio/#esquema-relacional","title":"Esquema Relacional","text":""},{"location":"01.scripts/00.Inicio/#arquitectura-general","title":"Arquitectura General","text":"<p>El Data Warehouse se organiza en m\u00f3dulos independientes que comparten dimensiones clave, cada uno enfocado en un \u00e1rea funcional:</p> <ol> <li>Dimensiones Comunes:</li> <li><code>DIM_TIEMPO</code>: Dimensi\u00f3n temporal que permite analizar datos por fechas espec\u00edficas.</li> <li> <p><code>DIM_PERSONAL</code>, <code>DIM_SERVICIOS</code>, y otras dimensiones transversales.</p> </li> <li> <p>M\u00f3dulos Espec\u00edficos:</p> </li> <li>Cedesarrollo: Datos relacionados con estudiantes, programas acad\u00e9micos y notas.</li> <li>Protecci\u00f3n: Informaci\u00f3n sobre caracterizaci\u00f3n, poblaci\u00f3n y planes de cobertura.</li> <li>Colegio: Gesti\u00f3n de notas, transporte, biblioteca y servicios sociales en colegios.</li> </ol>"},{"location":"01.scripts/00.Inicio/#esquema-relacional-simplificado","title":"Esquema Relacional Simplificado","text":"<pre><code>erDiagram\n    DIM_TIEMPO {\n        int ID_FECHA PK\n        date FECHA\n        varchar DIA_SEMANA\n        varchar MES\n        int ANIO\n    }\n\n    Transversal {\n        int ID_PERSONAL PK\n        int ID_SERVICIO PK\n        varchar NOMBRE_SERVICIO\n    }\n\n    Cedesarrollo {\n        int ID_ESTUDIANTE PK\n        int ID_PROGRAMA FK\n        int ID_PERIODO FK\n        decimal NOTA_FINAL\n    }\n\n    Proteccion {\n        int ID_POBLACION PK\n        int ID_PROGRAMA FK\n        int ID_FECHA FK\n    }\n\n    Colegio {\n        int ID_NOTA PK\n        int ID_POBLACION_MATRICULA FK\n        int ID_GRADO FK\n        int ID_CURSO FK\n        decimal NOTA_FINAL\n    }\n\n    DIM_TIEMPO ||--o{ Transversal: \"relaci\u00f3n temporal\"\n    DIM_TIEMPO ||--o{ Cedesarrollo: \"relaci\u00f3n temporal\"\n    DIM_TIEMPO ||--o{ Proteccion: \"relaci\u00f3n temporal\"\n    DIM_TIEMPO ||--o{ Colegio: \"relaci\u00f3n temporal\"\n    Transversal ||--o{ Cedesarrollo: \"uso compartido\"\n    Transversal ||--o{ Proteccion: \"uso compartido\"\n    Transversal ||--o{ Colegio: \"uso compartido\"</code></pre>"},{"location":"01.scripts/00.Inicio/#detalles-por-modulo","title":"Detalles por M\u00f3dulo","text":""},{"location":"01.scripts/00.Inicio/#1-dimensiones-comunes","title":"1. Dimensiones Comunes","text":"<p>Estas dimensiones son utilizadas transversalmente en todos los m\u00f3dulos:</p> <ul> <li><code>DIM_TIEMPO</code>: Estructura central para an\u00e1lisis temporal. Contiene informaci\u00f3n granular de fechas, d\u00edas de la semana, meses y a\u00f1os.</li> <li><code>DIM_SERVICIOS</code>: Identifica los servicios ofrecidos en diferentes programas.</li> <li><code>DIM_PERSONAL</code>: Informaci\u00f3n de personal administrativo y docente.</li> </ul>"},{"location":"01.scripts/00.Inicio/#2-cedesarrollo","title":"2. Cedesarrollo","text":"<p>Este m\u00f3dulo se enfoca en la informaci\u00f3n acad\u00e9mica de estudiantes:</p> <ul> <li>Tablas principales:</li> <li><code>DIM_ESTUDIANTES</code>: Informaci\u00f3n general de los estudiantes.</li> <li><code>DIM_PROGRAMA</code>: Datos de los programas acad\u00e9micos.</li> <li><code>FACT_NOTAS</code>: Notas por m\u00f3dulo, estudiante y periodo acad\u00e9mico.</li> </ul>"},{"location":"01.scripts/00.Inicio/#3-proteccion","title":"3. Protecci\u00f3n","text":"<p>M\u00f3dulo que gestiona informaci\u00f3n de poblaci\u00f3n vulnerable y programas sociales:</p> <ul> <li>Tablas principales:</li> <li><code>DIM_POBLACION</code>: Identificaci\u00f3n de beneficiarios de programas.</li> <li><code>FACT_CARACTERIZACION</code>: Caracterizaci\u00f3n de poblaciones seg\u00fan criterios.</li> <li><code>FACT_PLAN_COBERTURA</code>: Proyecciones y coberturas de programas sociales.</li> </ul>"},{"location":"01.scripts/00.Inicio/#4-colegio","title":"4. Colegio","text":"<p>Dise\u00f1ado para gestionar datos operativos y acad\u00e9micos en colegios:</p> <ul> <li>Tablas principales:</li> <li><code>DIM_PLAN_CURRICULAR</code>: Estructura acad\u00e9mica por asignaturas y cursos.</li> <li><code>FACT_NOTAS</code>: Notas obtenidas por estudiantes en diversas materias.</li> <li><code>FACT_BIBLIOTECA</code>: Registro de pr\u00e9stamos en bibliotecas f\u00edsicas y virtuales.</li> </ul>"},{"location":"01.scripts/00.Inicio/#nota","title":"Nota","text":"<ul> <li>La creaci\u00f3n de tablas se hace desde los scritps SQL. Incluidos en esta secci\u00f3n.</li> <li>Las funciones se encuentran en los scritps de Python y la explicaci\u00f3n de los paquetes.</li> <li>El unico procedimiento almacenado se ejecuta en el paquete 3 para calcular <code>FACT_RETIROS</code></li> <li>Parametros de SSIS. Se explican en la introducci\u00f3n de SSIS.</li> </ul>"},{"location":"01.scripts/00.Inicio/#conclusion","title":"Conclusi\u00f3n","text":"<p>El <code>DWH_COMFENALCO</code> es una herramienta poderosa y escalable que permite a los usuarios finales obtener insights r\u00e1pidos y precisos a trav\u00e9s de la integraci\u00f3n y an\u00e1lisis de datos en m\u00faltiples dominios. Con un dise\u00f1o modular y el uso eficiente de dimensiones compartidas, este Data Warehouse est\u00e1 preparado para soportar el crecimiento futuro y nuevos requisitos de an\u00e1lisis.</p>"},{"location":"01.scripts/00.Inicio/#pagina-principal","title":"P\u00e1gina Principal","text":"<p>Bienvenido a la documentaci\u00f3n.</p>"},{"location":"01.scripts/00.Inicio/#indice","title":"\u00cdndice","text":"<p>{{ pagetree }}</p>"},{"location":"01.scripts/01.Transversal%20copy/","title":"Documentaci\u00f3n SQL para el Esquema <code>Transversal</code>","text":""},{"location":"01.scripts/01.Transversal%20copy/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL est\u00e1 dise\u00f1ado para gestionar el esquema <code>Transversal</code> dentro de un Data Warehouse (DWH). Implementa una arquitectura dimensional compuesta por tablas de dimensiones y tablas de hechos, siguiendo las mejores pr\u00e1cticas de modelado dimensional.</p>"},{"location":"01.scripts/01.Transversal%20copy/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li>Eliminaci\u00f3n y Creaci\u00f3n del Esquema:</li> <li>Limpieza del esquema existente <code>Transversal</code> eliminando restricciones de claves for\u00e1neas, tablas y el esquema en s\u00ed.</li> <li> <p>Reinstalaci\u00f3n del esquema <code>Transversal</code> desde cero.</p> </li> <li> <p>Creaci\u00f3n de Tablas Dimensionales y de Hechos:</p> </li> <li>Tablas de Dimensiones (<code>DIM</code>): Contienen atributos descriptivos y categ\u00f3ricos relacionados con empresas, afiliados, beneficiarios, aportantes no afiliados, entre otros.</li> <li> <p>Tablas de Hechos (<code>FACT</code>): Contienen m\u00e9tricas y claves for\u00e1neas que conectan con las dimensiones, facilitando an\u00e1lisis transaccionales y operativos.</p> </li> <li> <p>Relaciones entre Tablas:</p> </li> <li>Configuraci\u00f3n de restricciones <code>FOREIGN KEY</code> para garantizar integridad referencial.</li> </ol>"},{"location":"01.scripts/01.Transversal%20copy/#detalle-de-las-tablas-y-relacion-dimensional","title":"Detalle de las Tablas y Relaci\u00f3n Dimensional","text":""},{"location":"01.scripts/01.Transversal%20copy/#tablas-dimensionales","title":"Tablas Dimensionales","text":""},{"location":"01.scripts/01.Transversal%20copy/#1-dim_empresas","title":"1. DIM_EMPRESAS","text":"<p>Contiene informaci\u00f3n b\u00e1sica sobre empresas, incluyendo tipo de documento, raz\u00f3n social, sector y estado.</p> Columna Tipo Descripci\u00f3n <code>ID_EMPRESA</code> <code>int</code> Identificador \u00fanico de la empresa. <code>RAZON_SOCIAL</code> <code>nvarchar</code> Nombre de la empresa. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento (NIT, CC). <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero del documento."},{"location":"01.scripts/01.Transversal%20copy/#2-dim_afiliados","title":"2. DIM_AFILIADOS","text":"<p>Contiene datos de los afiliados como nombre, g\u00e9nero, estado civil, y afiliaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_AFILIADO</code> <code>int</code> Identificador \u00fanico del afiliado. <code>NOMBRE_COMPLETO</code> <code>nvarchar</code> Nombre completo del afiliado. <code>GENERO</code> <code>nvarchar</code> G\u00e9nero del afiliado. <code>FECHA_AFILIACION</code> <code>nvarchar</code> Fecha de afiliaci\u00f3n."},{"location":"01.scripts/01.Transversal%20copy/#3-dim_beneficiarios","title":"3. DIM_BENEFICIARIOS","text":"<p>Contiene informaci\u00f3n de los beneficiarios relacionados con los afiliados.</p> Columna Tipo Descripci\u00f3n <code>ID_BENEFICIARIO</code> <code>int</code> Identificador \u00fanico del beneficiario. <code>NOMBRE_COMPLETO</code> <code>nvarchar</code> Nombre completo del beneficiario. <code>PARENTESCO</code> <code>nvarchar</code> Relaci\u00f3n del beneficiario con el titular."},{"location":"01.scripts/01.Transversal%20copy/#diagrama-de-las-tablas-dimensionales","title":"Diagrama de las Tablas Dimensionales","text":"<pre><code>erDiagram\n    DIM_EMPRESAS {\n        int ID_EMPRESA PK\n        nvarchar RAZON_SOCIAL\n        nvarchar TIPO_DOCUMENTO\n        nvarchar DOCUMENTO\n    }\n\n    DIM_AFILIADOS {\n        int ID_AFILIADO PK\n        nvarchar NOMBRE_COMPLETO\n        nvarchar GENERO\n        nvarchar FECHA_AFILIACION\n    }\n    DIM_BENEFICIARIOS {\n        int ID_BENEFICIARIO PK\n        nvarchar NOMBRE_COMPLETO\n        nvarchar PARENTESCO\n    }\n\n    DIM_EMPRESAS ||--o{ DIM_AFILIADOS : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ DIM_BENEFICIARIOS : \"ID_AFILIADO\"</code></pre>"},{"location":"01.scripts/01.Transversal%20copy/#tablas-de-hechos","title":"Tablas de Hechos","text":""},{"location":"01.scripts/01.Transversal%20copy/#1-fact_aportes_shr_det","title":"1. FACT_APORTES_SHR_DET","text":"<p>Registra detalles financieros de aportes realizados por empresas y afiliados.</p> Columna Tipo Descripci\u00f3n <code>ID_EMPRESA</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_EMPRESAS</code>. <code>ID_AFILIADO</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_AFILIADOS</code>. <code>PERIODO</code> <code>varchar</code> Per\u00edodo de los aportes. <code>APORTE_NUEVO</code> <code>numeric</code> Monto del aporte registrado."},{"location":"01.scripts/01.Transversal%20copy/#2-fact_detalle_contable","title":"2. FACT_DETALLE_CONTABLE","text":"<p>Registra operaciones contables como ingresos, gastos y resultados financieros.</p> Columna Tipo Descripci\u00f3n <code>ID_CEBE</code> <code>bigint</code> Relaci\u00f3n con la tabla <code>DIM_UNIDADES_ORGANIZATIVAS</code>. <code>ID_CUENTA</code> <code>bigint</code> Relaci\u00f3n con la tabla <code>DIM_CUENTA_CONTABLE</code>. <code>IMPORTE</code> <code>decimal</code> Importe de la operaci\u00f3n contable."},{"location":"01.scripts/01.Transversal%20copy/#3-fact_encuestas","title":"3. FACT_ENCUESTAS","text":"<p>Registra resultados de encuestas relacionadas con servicios y satisfacci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_UNIDAD</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_UNIDAD</code>. <code>SERVICIO</code> <code>nvarchar</code> Servicio evaluado en la encuesta. <code>CALIFICACION</code> <code>nvarchar</code> Puntuaci\u00f3n otorgada en la encuesta."},{"location":"01.scripts/01.Transversal%20copy/#diagrama-de-las-tablas-de-hechos","title":"Diagrama de las Tablas de Hechos","text":"<pre><code>erDiagram\n    FACT_APORTES_SHR_DET {\n        int ID_EMPRESA FK\n        int ID_AFILIADO FK\n        varchar PERIODO\n        numeric APORTE_NUEVO\n    }\n\n    FACT_DETALLE_CONTABLE {\n        bigint ID_CEBE FK\n        bigint ID_CUENTA FK\n        decimal IMPORTE\n    }\n\n    FACT_ENCUESTAS {\n        int ID_UNIDAD FK\n        nvarchar SERVICIO\n        nvarchar CALIFICACION\n    }\n\n    DIM_EMPRESAS ||--o{ FACT_APORTES_SHR_DET : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ FACT_APORTES_SHR_DET : \"ID_AFILIADO\"\n    DIM_UNIDADES_ORGANIZATIVAS ||--o{ FACT_DETALLE_CONTABLE : \"ID_CEBE\"\n    DIM_CUENTA_CONTABLE ||--o{ FACT_DETALLE_CONTABLE : \"ID_CUENTA\"\n    DIM_UNIDAD ||--o{ FACT_ENCUESTAS : \"ID_UNIDAD\"</code></pre>"},{"location":"01.scripts/01.Transversal%20copy/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li>Integridad Referencial:</li> <li> <p>Uso de claves for\u00e1neas para garantizar relaciones consistentes entre dimensiones y hechos.</p> </li> <li> <p>Arquitectura Modular:</p> </li> <li> <p>Separaci\u00f3n de tablas <code>DIM</code> y <code>FACT</code> para optimizar consultas y mantener un dise\u00f1o limpio.</p> </li> <li> <p>Documentaci\u00f3n:</p> </li> <li>Las descripciones de columnas y relaciones facilitan el entendimiento del modelo.</li> </ol>"},{"location":"01.scripts/01.Transversal%20copy/#conclusion","title":"Conclusi\u00f3n","text":"<p>El script implementa un esquema <code>Transversal</code> eficiente para an\u00e1lisis en un Data Warehouse. Las tablas de dimensiones proporcionan atributos descriptivos, mientras que las tablas de hechos registran transacciones y m\u00e9tricas clave. Este modelo es escalable y adaptable a m\u00faltiples casos de uso anal\u00edtico.</p>"},{"location":"01.scripts/01.Transversal/","title":"01. Transversal","text":""},{"location":"01.scripts/01.Transversal/#documentacion-del-esquema-transversal-en-sql","title":"Documentaci\u00f3n del Esquema <code>Transversal</code> en SQL","text":""},{"location":"01.scripts/01.Transversal/#1-introduccion","title":"1. Introducci\u00f3n","text":"<p>El esquema <code>Transversal</code> es un componente cr\u00edtico de un Data Warehouse (DWH) dise\u00f1ado para integrar datos de m\u00faltiples fuentes y facilitar an\u00e1lisis multidimensionales. Este manual detalla su estructura, tablas, relaciones y buenas pr\u00e1cticas.</p>"},{"location":"01.scripts/01.Transversal/#2-objetivos-del-esquema","title":"2. Objetivos del Esquema","text":"<ul> <li>Integraci\u00f3n: Consolidar datos de empresas, afiliados, transacciones financieras, encuestas y m\u00e1s.</li> <li>An\u00e1lisis: Habilitar consultas complejas para m\u00e9tricas como aportes, presupuestos, satisfacci\u00f3n de usuarios y PQRS.</li> <li>Escalabilidad: Dise\u00f1o modular para incorporar nuevas tablas sin afectar la estructura existente.</li> </ul>"},{"location":"01.scripts/01.Transversal/#3-arquitectura-del-esquema","title":"3. Arquitectura del Esquema","text":""},{"location":"01.scripts/01.Transversal/#31-componentes-principales","title":"3.1. Componentes Principales","text":"<ul> <li>Tablas de Dimensiones (<code>DIM_*</code>): Almacenan entidades descriptivas (empresas, afiliados, cuentas contables).</li> <li>Tablas de Hechos (<code>FACT_*</code>): Registran eventos transaccionales (aportes, movimientos contables, encuestas).</li> <li>Relaciones: Claves for\u00e1neas para garantizar integridad referencial.</li> </ul>"},{"location":"01.scripts/01.Transversal/#32-diagrama-general","title":"3.2. Diagrama General","text":"<pre><code>erDiagram\n    DIM_EMPRESAS ||--o{ DIM_AFILIADOS : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ DIM_BENEFICIARIOS : \"ID_AFILIADO\"\n    DIM_EMPRESAS ||--o{ FACT_APORTES_SHR_DET : \"ID_EMPRESA\"\n    DIM_AFILIADOS ||--o{ FACT_APORTES_SHR_DET : \"ID_AFILIADO\"\n    DIM_CUENTA_CONTABLE ||--o{ FACT_DETALLE_CONTABLE : \"ID_CUENTA\"\n    DIM_UNIDADES_ORGANIZATIVAS ||--o{ FACT_DETALLE_CONTABLE : \"ID_CEBE\"\n    DIM_UNIDAD ||--o{ FACT_ENCUESTAS : \"ID_UNIDAD\"</code></pre>"},{"location":"01.scripts/01.Transversal/#4-tablas-clave-y-descripcion-detallada","title":"4. Tablas Clave y Descripci\u00f3n Detallada","text":""},{"location":"01.scripts/01.Transversal/#41-dimensiones-principales","title":"4.1. Dimensiones Principales","text":""},{"location":"01.scripts/01.Transversal/#dim_empresas","title":"DIM_EMPRESAS","text":"<ul> <li>Prop\u00f3sito: Datos maestros de empresas aportantes.</li> <li>Columnas Relevantes:<ul> <li><code>ID_EMPRESA</code> (PK): Identificador \u00fanico.</li> <li><code>RAZON_SOCIAL</code>: Nombre legal.</li> <li><code>TIPO_DOCUMENTO</code>: NIT, CC, etc.</li> <li><code>ESTADO</code>: Activa, inactiva, retirada.</li> </ul> </li> <li>Relaciones: Relacionada con <code>DIM_AFILIADOS</code> y <code>FACT_APORTES_SHR_DET</code>.</li> </ul>"},{"location":"01.scripts/01.Transversal/#dim_afiliados","title":"DIM_AFILIADOS","text":"<ul> <li>Prop\u00f3sito: Informaci\u00f3n demogr\u00e1fica y laboral de afiliados.</li> <li>Columnas Relevantes:<ul> <li><code>ID_AFILIADO</code> (PK): Identificador \u00fanico.</li> <li><code>NOMBRE_COMPLETO</code>: Nombre del afiliado.</li> <li><code>FECHA_AFILIACION</code>: Fecha de registro en el sistema.</li> <li><code>ID_EMPRESA</code> (FK): Empresa asociada.</li> </ul> </li> <li>Relaciones: Vinculada a <code>DIM_BENEFICIARIOS</code> y <code>FACT_APORTES_SHR_DET</code>.</li> </ul>"},{"location":"01.scripts/01.Transversal/#dim_beneficiarios","title":"DIM_BENEFICIARIOS","text":"<ul> <li>Prop\u00f3sito: Beneficiarios vinculados a afiliados (familiares).</li> <li>Columnas Clave:<ul> <li><code>ID_BENEFICIARIO</code> (PK): Identificador \u00fanico.</li> <li><code>PARENTESCO</code>: Relaci\u00f3n con el afiliado (hijo, c\u00f3nyuge).</li> <li><code>ID_AFILIADO</code> (FK): Afiliado titular.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#42-tablas-de-hechos","title":"4.2. Tablas de Hechos","text":""},{"location":"01.scripts/01.Transversal/#fact_aportes_shr_det","title":"FACT_APORTES_SHR_DET","text":"<ul> <li>Prop\u00f3sito: Detalle de aportes financieros.</li> <li>M\u00e9tricas:<ul> <li><code>APORTE_NUEVO</code>: Monto del aporte.</li> <li><code>PERIODO</code>: Per\u00edodo contable (ej. <code>2023M01</code>).</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_EMPRESA</code> (FK): Empresa que realiza el aporte.</li> <li><code>ID_AFILIADO</code> (FK): Afiliado beneficiario.</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#fact_detalle_contable","title":"FACT_DETALLE_CONTABLE","text":"<ul> <li>Prop\u00f3sito: Movimientos contables (ingresos, gastos).</li> <li>M\u00e9tricas:<ul> <li><code>IMPORTE</code>: Valor total de la transacci\u00f3n.</li> <li><code>INGRESOS_OPERACIONALES</code>: Ingresos core del negocio.</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_CUENTA</code> (FK): Cuenta contable (<code>DIM_CUENTA_CONTABLE</code>).</li> <li><code>ID_CEBE</code> (FK): Unidad organizativa (<code>DIM_UNIDADES_ORGANIZATIVAS</code>).</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#fact_encuestas","title":"FACT_ENCUESTAS","text":"<ul> <li>Prop\u00f3sito: Resultados de encuestas de satisfacci\u00f3n.</li> <li>M\u00e9tricas:<ul> <li><code>CALIFICACION</code>: Puntuaci\u00f3n del servicio (ej. 1-5).</li> <li><code>SERVICIO</code>: Tipo de servicio evaluado.</li> </ul> </li> <li>Relaciones:<ul> <li><code>ID_UNIDAD</code> (FK): Unidad responsable (<code>DIM_UNIDAD</code>).</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#5-relaciones-y-dependencias","title":"5. Relaciones y Dependencias","text":""},{"location":"01.scripts/01.Transversal/#51-reglas-de-integridad","title":"5.1. Reglas de Integridad","text":"<ul> <li>Claves For\u00e1neas: Todas las tablas de hechos incluyen FK a dimensiones.</li> <li>Valores por Defecto: <ul> <li><code>-1</code> para indicar \"No aplica\" o datos faltantes (ej. <code>ID_EMPRESA</code> en <code>FACT_ENCUESTAS</code>).</li> <li><code>20090101</code> para fechas m\u00ednimas (ej. <code>ID_FECHA</code> en <code>FACT_APORTES_SHR_DET</code>).</li> </ul> </li> </ul>"},{"location":"01.scripts/01.Transversal/#52-script","title":"5.2. Script","text":"<pre><code>USE DWH_COMFENALCO\nGO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- Eliminar restricciones de clave for\u00e1nea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Transversal')\nBEGIN\n    DROP SCHEMA Transversal;\nEND\nGO\n-- Crear el esquema Transversal\nCREATE SCHEMA Transversal;\nGO\n-- Crear DIM_EMPRESAS\nCREATE TABLE [Transversal].[DIM_EMPRESAS](\n    [ID_EMPRESA] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [RAZON_SOCIAL] [nvarchar](300) NULL,\n    [ID_ESTADO] [nvarchar](2) NULL,\n    [ESTADO] [nvarchar](40) NULL,\n    [ID_SECTOR] [nvarchar](2) NULL,\n    [SECTOR] [nvarchar](40) NULL,\n    [ID_CLASE] [nvarchar](2) NULL,\n    [CLASE] [nvarchar](40) NULL,\n    [ID_ACT_ECONOMICA] [nvarchar](4) NULL,\n    [ACT_ECONOMICA] [nvarchar](200) NULL,\n    [ES_NUEVO] [int] NULL,\n    [ID_TIPO_APORTANTE] [nvarchar](2) NULL,\n    [TIPO_APORTANTE] [nvarchar](40) NULL,\n    [FECHA_AFILIACION] [datetime] NULL,\n    [FECHA_FUNDACION] [nvarchar](50) NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_MOTIVO_RETIRO] [int] NULL,\n    [MOTIVO_RETIRO] [nvarchar](80) NULL,\n    [FECHA_DESDE] [datetime] NULL,\n    [FECHA_HASTA] [datetime] NULL,\n    [DIRECCION] [nvarchar](300) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [COD_CIUDAD] [nvarchar](5) NULL,\n    [NUMERO_PROCESO_SQL] [bigint] NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [ESTADOREGISTRO] [nvarchar](10) NULL,\n    [CORREO] [nvarchar](200) NULL,\n    [TIPO_PERSONA] [nvarchar](1) NULL,\n    [PRIMER_NOMBRE] [nvarchar](50) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](50) NULL,\n    [PRIMER_APELLIDO] [nvarchar](50) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](50) NULL,\n    [CONVENIO_LIB] [int] NULL,\n    [FECHA_PRIMER_APORTE] [int] NULL,\n    [DIGITO_VERIFICACON] [varchar](1) NULL,\n    [CAJA_COMPEN] [varchar](2) NULL,\n    [SITUACION_1429] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_1429] [nvarchar](10) NULL,\n    [SITUACION_590] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_590] [nvarchar](10) NULL,\n    [ORIGEN_EXTRACCION] [varchar](50) NULL,\n    CONSTRAINT [PK_DIM_EMPRESAS] PRIMARY KEY CLUSTERED ([ID_EMPRESA])\n) ON [PRIMARY]\nGO\n-- Crear DIM_AFILIADOS\nCREATE TABLE [Transversal].[DIM_AFILIADOS](\n    [ID_AFILIADO] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [NUMERO_DOCUMENTO] [nvarchar](20) NULL,\n    [NOMBRE_COMPLETO] [nvarchar](200) NULL,\n    [PRIMER_APELLIDO] [nvarchar](50) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](50) NULL,\n    [PRIMER_NOMBRE] [nvarchar](50) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](50) NULL,\n    [ID_TIPO_AFILIADO] [nvarchar](2) NULL,\n    [TIPO_AFILIADO] [varchar](80) NULL,\n    [ID_CATEGORIA] [nvarchar](2) NULL,\n    [CATEGORIA] [nvarchar](10) NULL,\n    [ID_ESTADO_AFILIACION] [nvarchar](4) NULL,\n    [ESTADO_AFILIACION] [nvarchar](40) NULL,\n    [FECHA_AFILIACION] [nvarchar](50) NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_MOTIVORETIRO] [nvarchar](2) NULL,\n    [MOTIVORETIRO] [nvarchar](50) NULL,\n    [ID_NIVEL_EDUCATIVO] [nvarchar](2) NULL,\n    [NIVEL_EDUCATIVO] [varchar](50) NULL,\n    [ID_GENERO] [nvarchar](2) NULL,\n    [GENERO] [varchar](20) NULL,\n    [ID_ORIENTACION_SEXUAL] [nvarchar](2) NULL,\n    [ORIENTACION_SEXUAL] [nvarchar](40) NULL,\n    [ID_ESTADO_CIVIL] [nvarchar](2) NULL,\n    [ESTADO_CIVIL] [nvarchar](40) NULL,\n    [COD_OCUPACION] [nvarchar](4) NULL,\n    [OCUPACION] [nvarchar](100) NULL,\n    [ID_PERTENENCIA_ETNICA] [nvarchar](2) NULL,\n    [PERTENENCIA_ETNICA] [nvarchar](100) NULL,\n    [ID_FACTOR_VULNERABILIDAD] [nvarchar](2) NULL,\n    [FACTOR_VULNERABILIDAD] [nvarchar](50) NULL,\n    [CONDICION_ESPECIAL] [nvarchar](2) NULL,\n    [FECHA_NACIMIENTO] [nvarchar](10) NULL,\n    [DIRECCION] [nvarchar](60) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [BARRIO] [nvarchar](40) NULL,\n    [ESTRATO] [nvarchar](2) NULL,\n    [ID_CIUDAD] [nvarchar](5) NULL,\n    [ID_AREA_GEOGRAFICA] [nvarchar](2) NULL,\n    [AREA_GEOGRAFICA] [nvarchar](10) NULL,\n    [CORREO] [nvarchar](250) NULL,\n    [SALARIO_BASICO] [nvarchar](50) NULL,\n    [ES_NUEVO] [nvarchar](50) NULL,\n    [TIPO_SALARIO] [nvarchar](50) NULL,\n    [HORAS_LAB_MENSUAL] [nvarchar](50) NULL,\n    [TIPO_APORTANTE] [nvarchar](50) NOT NULL,\n    [APORTANTE] [nvarchar](10) NULL,\n    [FEC_DESDE] [datetime] NULL,\n    [FEC_HASTA] [datetime] NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [ESTADOREGISTRO] [nvarchar](20) NULL,\n    [ID_RESGUARDO] [int] NULL,\n    [RESGUARDO] [varchar](100) NULL,\n    [COD_PAIS_RESIDENCIA] [int] NULL,\n    [PAIS_RESIDENCIA] [varchar](100) NULL,\n    [COD_MUN_LABOR_DANE] [varchar](5) NULL,\n    [AREA_GEOGRA_LABOR] [varchar](2) NULL,\n    [FECHA_INGRESO_EMPRESA] [varchar](50) NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [EMPRESA_PRINCIPAL] [varchar](1) NULL,\n    [VALOR_SALARIO_UVT] [numeric](18, 2) NULL,\n    [ID_CATEGORIA_UVT] [varchar](2) NULL,\n    [CATEGORIA_UVT] [varchar](10) NULL,\n CONSTRAINT [PK_DIM_AFILIADOS] PRIMARY KEY CLUSTERED \n(\n    [ID_AFILIADO] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, FILLFACTOR = 100, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY],\nCONSTRAINT [FK_DIM_AFILIADOS_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA])\n) ON [PRIMARY]\nGO\n-- Crear DIM_BENEFICIARIOS\nCREATE TABLE [Transversal].[DIM_BENEFICIARIOS](\n    [ID_BENEFICIARIO] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [TITULAR] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [NUMERO_DOCUMENTO] [nvarchar](20) NULL,\n    [NOMBRE_COMPLETO] [nvarchar](81) NULL,\n    [PRIMER_APELLIDO] [nvarchar](40) NOT NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](40) NULL,\n    [PRIMER_NOMBRE] [nvarchar](40) NOT NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](40) NULL,\n    [ID_PARENTESCO] [nvarchar](8) NULL,\n    [PARENTESCO] [varchar](50) NULL,\n    [FECHA_AFILIACION] [nvarchar](50) NOT NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_GENERO] [varchar](1) NOT NULL,\n    [GENERO] [varchar](9) NOT NULL,\n    [ID_NIVEL_EDUCATIVO] [nvarchar](2) NULL,\n    [NIVEL_EDUCATIVO] [nvarchar](50) NULL,\n    [ID_ESTADO_CIVIL] [nvarchar](2) NULL,\n    [ESTADO_CIVIL] [nvarchar](40) NULL,\n    [DISCAPACIDAD] [nvarchar](1) NULL,\n    [FECHA_NACIMIENTO] [datetime] NOT NULL,\n    [DIRECCION] [nvarchar](60) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [BARRIO] [nvarchar](40) NULL,\n    [ESTRATO] [nvarchar](2) NULL,\n    [ID_CIUDAD] [nvarchar](5) NULL,\n    [ID_AREA_GEOGRAFICA] [nvarchar](2) NULL,\n    [AREA_GEOGRAFICA] [nvarchar](10) NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](40) NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [ESTADOREGISTRO] [nvarchar](10) NULL,\n    [ID_PARENT_SAP] [nvarchar](10) NULL,\n    [PARENT_SAP] [nvarchar](30) NULL,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [APORTANTE] [nvarchar](10) NULL,\n    [TIPO_AFILIADO] [nvarchar](50) NOT NULL,\n    [TIPO_APORTANTE] [nvarchar](50) NOT NULL,\n    [FEC_DESDE] [datetime] NULL,\n    [FEC_HASTA] [datetime] NULL,\n    [ESTADO_BEN] [int] NULL,\n    [FECHA_INGRESO_EMPRESA] [varchar](50) NULL,\n CONSTRAINT [PK_DIM_BENENEFICIARIOS] PRIMARY KEY CLUSTERED \n(\n    [ID_BENEFICIARIO] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, FILLFACTOR = 100, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY],\nCONSTRAINT [FK_DIM_BENEFICIARIOS_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO])\n) ON [PRIMARY]\nGO\n-- Crear DIM_APORTANTE_NOAFILIADO\nCREATE TABLE [Transversal].[DIM_APORTANTE_NOAFILIADO](\n    [ID_APORTANTE] [int] NOT NULL,\n    [PARTNER] [nvarchar](10) NOT NULL,\n    [ID_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [COD_TIPO_DOCUMENTO] [nvarchar](4) NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NULL,\n    [DOCUMENTO] [nvarchar](20) NULL,\n    [RAZON_SOCIAL] [nvarchar](300) NULL,\n    [ID_ESTADO] [nvarchar](2) NULL,\n    [ESTADO] [nvarchar](40) NULL,\n    [ID_SECTOR] [nvarchar](2) NULL,\n    [SECTOR] [nvarchar](40) NULL,\n    [ID_CLASE] [nvarchar](2) NULL,\n    [CLASE] [nvarchar](40) NULL,\n    [ID_ACT_ECONOMICA] [nvarchar](4) NULL,\n    [ACT_ECONOMICA] [nvarchar](200) NULL,\n    [ES_NUEVO] [int] NULL,\n    [ID_TIPO_APORTANTE] [nvarchar](2) NULL,\n    [TIPO_APORTANTE] [nvarchar](40) NULL,\n    [FECHA_AFILIACION] [datetime] NULL,\n    [FECHA_FUNDACION] [nvarchar](50) NULL,\n    [FECHA_RETIRO] [nvarchar](50) NULL,\n    [ID_MOTIVO_RETIRO] [int] NULL,\n    [MOTIVO_RETIRO] [nvarchar](80) NULL,\n    [FECHA_DESDE] [datetime] NULL,\n    [FECHA_HASTA] [datetime] NULL,\n    [DIRECCION] [nvarchar](300) NULL,\n    [TELEFONO] [nvarchar](30) NULL,\n    [COD_CIUDAD] [nvarchar](5) NULL,\n    [NUMERO_PROCESO_SQL] [bigint] NULL,\n    [FEC_CREACION] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [FEC_ACTUALIZACION] [datetime] NULL,\n    [ESTADOREGISTRO] [nvarchar](10) NULL,\n    [CORREO] [nvarchar](200) NULL,\n    [TIPO_PERSONA] [nvarchar](1) NULL,\n    [PRIMER_NOMBRE] [nvarchar](50) NULL,\n    [SEGUNDO_NOMBRE] [nvarchar](50) NULL,\n    [PRIMER_APELLIDO] [nvarchar](50) NULL,\n    [SEGUNDO_APELLIDO] [nvarchar](50) NULL,\n    [CONVENIO_LIB] [int] NULL,\n    [FECHA_PRIMER_APORTE] [int] NULL,\n    [DIGITO_VERIFICACON] [varchar](1) NULL,\n    [CAJA_COMPEN] [varchar](2) NULL,\n    [SITUACION_1429] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_1429] [nvarchar](10) NULL,\n    [SITUACION_590] [nvarchar](10) NULL,\n    [PROGRESIVIDAD_590] [nvarchar](10) NULL,\n    [FECHA_NACIMIENTO] [varchar](8) NULL,\n    [GENERO] [int] NULL,\n    CONSTRAINT [PK_DIM_APORTANTE_NOAFILIADO] PRIMARY KEY CLUSTERED ([ID_APORTANTE])\n) ON [PRIMARY]\nGO\n-- Crear FACT_APORTES_SHR_DET\nCREATE TABLE [Transversal].[FACT_APORTES_SHR_DET](\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [PERIODO] [varchar](10) NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [OPBEL] [varchar](50) NULL,\n    [BELNR] [varchar](50) NULL,\n    [MOVIMIENTO] [varchar](50) NULL,\n    [FECHA_CONTABLE] [int] NULL,\n    [NUM_CUENTA] [varchar](50) NULL,\n    [APORTE] [varchar](50) NULL,\n    [INTERES] [varchar](50) NULL,\n    [ESTADOREGISTRO] [varchar](50) NULL,\n    [FECHA_ACTUALIZACION] [datetime] NULL,\n    [DESDE] [datetime] NULL,\n    [HASTA] [datetime] NULL,\n    [PROCESO] [nvarchar](50) NULL,\n    [BP_EMPRESA] [varchar](10) NULL,\n    [BP_AFILIADO] [varchar](10) NULL,\n    [TIPO_APORTANTE] [int] NULL,\n    [SW_AJUSTE] [int] NULL,\n    [APORTE_NUEVO] [numeric](18, 0) NULL,\n    CONSTRAINT [FK_FACT_APORTES_SHR_DET_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_APORTES_SHR_DET_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_APORTES_SHR_DET_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n) ON [PRIMARY]\nGO\nALTER TABLE [Transversal].[FACT_APORTES_SHR_DET] ADD  DEFAULT ((0)) FOR [SW_AJUSTE]\nGO\nALTER TABLE [Transversal].[FACT_APORTES_SHR_DET] ADD  DEFAULT ((0)) FOR [APORTE_NUEVO]\nGO\nCREATE TABLE [Transversal].[DIM_CUENTA_CONTABLE](\n    [ID_CUENTA] [bigint] IDENTITY(1,1) NOT NULL,\n    [CUENTA_NUMERO] [bigint] NOT NULL,\n    [CUENTA] [nvarchar](10) NOT NULL,\n    [CUENTA_HOMOLOGA] [nvarchar](10) NOT NULL,\n    [DESCRIPCION] [nvarchar](50) NOT NULL,\n    [TIPO_CUENTA] [nvarchar](100) NOT NULL,\n    [TIPO_OPERACION] [nvarchar](100) NOT NULL,\n    [GRUPO_CUENTA] [nvarchar](100) NOT NULL,\n    [SUBGRUPO_CUENTA] [nvarchar](50) NOT NULL,\n    [GRUPO_OPERACION] [nvarchar](100) NOT NULL,\n    [FEC_PROCESO] [datetime] NOT NULL,\n    [UDATE] [datetime] NOT NULL,\n    [CUENTA_SSF] [int] NOT NULL,\n    [DESCRIPCION_SSF] [nvarchar](255) NOT NULL,\n    [CUENTA_DESCRIPCION]  AS (([CUENTA]+'-')+[DESCRIPCION]),\n    [CUENTA_DESCRIPCION_SSF]  AS ((rtrim(CONVERT([varchar],[CUENTA_SSF]))+'-')+[DESCRIPCION_SSF]),\n    [SIGNO_INGRESOS]  AS (case when [TIPO_CUENTA]='INGRESOS' then (1) else (0) end),\n    [NUMERO_PROCESO_SQL] [bigint] NOT NULL,\n    [CLASIFICACION] [int] NULL,\n    [USUARIO_PROCESO] [nvarchar](50) NOT NULL,\n    [ESTADO_REGISTRO] [nvarchar](10) NULL,\n    [NIVEL_1_TIPO_CUENTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(1))),\n    [DESC_NIVEL_1_TIPO_CUENTA]  AS ([TIPO_CUENTA]),\n    [NIVEL_2_TIPO_OPERAC]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(2))),\n    [DES_NIVEL_2_TIPO_OPERAC]  AS ([TIPO_OPERACION]),\n    [NIVEL_4_GRUPO_CTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(4))),\n    [DESC_NIVEL_4_GRUPO_CTA]  AS ([GRUPO_CUENTA]),\n    [NIVEL_6_SUBG_CTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(6))),\n    [DESC_NIVEL_6_SUBG_CTA]  AS ([SUBGRUPO_CUENTA]),\n    [NIVEL_8_GRUPO_OPERAC]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(8))),\n    [DESC_NIVEL_8_GRUPO_OPERAC]  AS ([GRUPO_OPERACION]),\n    [NIVEL_10_CUENTA]  AS (left(CONVERT([varchar](20),[CUENTA_NUMERO]),(10))),\n    [DESC_NIVEL_10_CUENTA_NUMERO]  AS ([DESCRIPCION]),\n    [ID_CUENTA_AUXILIAR] AS ([ID_CUENTA]),\n CONSTRAINT [PK_DIM_CUENTA_CONTABLE] PRIMARY KEY CLUSTERED \n(\n    [ID_CUENTA] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY]\n) ON [PRIMARY]\nGO\n-- Crear DIM_UNIDAD\n CREATE TABLE [Transversal].[DIM_UNIDAD] (\n    [ID_UNIDAD] [int] IDENTITY(1,1) NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    CONSTRAINT [PK_DIM_UNIDAD] PRIMARY KEY CLUSTERED ([ID_UNIDAD])\n)\nGO\n-- Crear DIM_UNIDADES_ORGANIZATIVAS\nCREATE TABLE [Transversal].[DIM_UNIDADES_ORGANIZATIVAS](\n    [ID_CEBE] [bigint] NOT NULL,\n    [CEBE] [varchar](10) NOT NULL,\n    [DESCRIPCION_BREVE] [varchar](50) NOT NULL,\n    [DESCRIPCION_COMPLETA] [varchar](100) NOT NULL,\n    [CEBE_DESCRIPCION]  AS ((rtrim(CONVERT([char],[CEBE]))+'-')+[DESCRIPCION_COMPLETA]),\n    [DEPARTAMENTO] [varchar](100) NOT NULL,\n    [AREA] [varchar](100) NOT NULL,\n    [SUBAREA] [varchar](100) NOT NULL,\n    [SEGMENTO] [bigint] NOT NULL,\n    [DESCRIPCION_SEGMENTO] [varchar](50) NOT NULL,\n    [SEGMENTO_DESCRIPCION]  AS ((rtrim(CONVERT([char],[SEGMENTO]))+'-')+[DESCRIPCION_SEGMENTO]),\n    [CODIGO_SSF] [int] NOT NULL,\n    [NOMBRE_SSF] [varchar](100) NOT NULL,\n    [CODIGO_NOMBRE_SSF]  AS ((rtrim(CONVERT([char],[CODIGO_SSF]))+'-')+[NOMBRE_SSF]),\n    [UDATE] [smalldatetime] NOT NULL,\n    [NUMERO_PROCESO_SQL] [bigint] NOT NULL,\n    [FEC_PROCESO] [datetime] NULL,\n    [USUARIO_PROCESO] [varchar](50) NULL,\n    [GRUPO_CEBE] [varchar](50) NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n CONSTRAINT [PK__DIM_UNIDADES_ORGANIZATIVAS] PRIMARY KEY CLUSTERED \n(\n    [ID_CEBE] ASC\n)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON, OPTIMIZE_FOR_SEQUENTIAL_KEY = OFF) ON [PRIMARY]\n) ON [PRIMARY]\nGO\nALTER TABLE [Transversal].[DIM_UNIDADES_ORGANIZATIVAS]  WITH NOCHECK ADD  CONSTRAINT [FK_DIM_UNIDADES_ORGANIZATIVAS_DIM_UNIDAD] FOREIGN KEY([ID_UNIDAD])\nREFERENCES [Transversal].[DIM_UNIDAD] ([ID_UNIDAD])\nGO\n-- FACT_DETALLE_CONTABLE\nCREATE TABLE [Transversal].[FACT_DETALLE_CONTABLE](\n    [ID_CEBE] [bigint] NOT NULL,\n    [ID_CUENTA] [bigint] NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [SEGMENT] [bigint] NOT NULL,\n    [IMPORTE] [decimal](28, 2),-- NOT NULL,\n    [INGRESOS] [decimal](28, 2) ,--NOT NULL,\n    [INGRESOS_OPERACIONALES] [decimal](28, 2),-- NOT NULL,\n    [GASTOS] [decimal](28, 2) ,--NOT NULL,\n    [GASTOS_OPERACIONALES] [decimal](28, 2),-- NOT NULL,\n    [GASTOS_OPERACIONALES_ADMIN] [decimal](28, 2),-- NOT NULL,\n    [RESULTADO_EJERCICIO] [decimal](28, 2),-- NOT NULL,\n    [COSTOS] [decimal](28, 2),-- NOT NULL,\n    [ACTIVO] [decimal](28, 2),-- NOT NULL,\n    [PASIVO] [decimal](28, 2),-- NOT NULL,\n    [PATRIMONIO] [decimal](28, 2),-- NOT NULL,\n    [GASTOS_CON_DISTRIBUCION] [decimal](28, 2),-- NOT NULL,\n    [GASTOS_SIN_DISTRIBUCION] [decimal](28, 2),-- NOT NULL,\n    [FECHA_REGISTRO_SAP] [datetime] NOT NULL,\n    [FECHA_PROCESO] [datetime] NOT NULL,\n    [USUARIO_PROCESO] [varchar](50) NOT NULL\n) ON [PRIMARY]\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_CUENTA_CONTABLE] FOREIGN KEY([ID_CUENTA])\nREFERENCES [Transversal].[DIM_CUENTA_CONTABLE] ([ID_CUENTA])\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE] CHECK CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_CUENTA_CONTABLE]\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_DETALLE_CONTABLE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA])\nREFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE] CHECK CONSTRAINT [FK_FACT_DETALLE_CONTABLE_Dim_TIEMPO]\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_UNIDADES_ORGANIZATIVAS] FOREIGN KEY([ID_CEBE])\nREFERENCES [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] ([ID_CEBE])\nGO\n\nALTER TABLE [Transversal].[FACT_DETALLE_CONTABLE] CHECK CONSTRAINT [FK_FACT_DETALLE_CONTABLE_DIM_UNIDADES_ORGANIZATIVAS]\nGO\n\n-- Crear FACT_PRESUPUESTO\nCREATE TABLE [Transversal].[FACT_PRESUPUESTO](\n    [ID_CEBE] [bigint] NOT NULL,\n    [ID_CUENTA] [bigint] NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [ID_TIPO_PRESUPUESTO] [int] NOT NULL,\n    [SEGMENT] [bigint] NOT NULL,\n    [VALOR] [decimal](28, 2) NOT NULL,\n    [INGRESOS] [decimal](28, 2) NOT NULL,\n    [INGRESOS_OPERACIONALES] [decimal](28, 2) NOT NULL,\n    [GASTOS] [decimal](28, 2) NOT NULL,\n    [GASTOS_OPERACIONALES] [decimal](28, 2) NOT NULL,\n    [GASTOS_OPERACIONALES_ADMIN] [decimal](28, 2) NOT NULL,\n    [COSTOS] [decimal](28, 2) NOT NULL,\n    [GASTOS_CON_DISTRIBUCION] [decimal](28, 2) NOT NULL,\n    [GASTOS_SIN_DISTRIBUCION] [decimal](28, 2) NOT NULL,\n    [FECHA_PROCESO] [datetime] NOT NULL,\n    [USUARIO_PROCESO] [varchar](50) NOT NULL\n) ON [PRIMARY]\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_CUENTA_CONTABLE] FOREIGN KEY([ID_CUENTA])\nREFERENCES [Transversal].[DIM_CUENTA_CONTABLE] ([ID_CUENTA])\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO] CHECK CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_CUENTA_CONTABLE]\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_PRESUPUESTO_Dim_TIEMPO] FOREIGN KEY([ID_FECHA])\nREFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO] CHECK CONSTRAINT [FK_FACT_PRESUPUESTO_Dim_TIEMPO]\nGO\n\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO]  WITH NOCHECK ADD  CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_UNIDADES_ORGANIZATIVAS] FOREIGN KEY([ID_CEBE])\nREFERENCES [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] ([ID_CEBE])\nGO\n\nALTER TABLE [Transversal].[FACT_PRESUPUESTO] CHECK CONSTRAINT [FK_FACT_PRESUPUESTO_DIM_UNIDADES_ORGANIZATIVAS]\nGO\n\n-- Crear DIM_SERVICIOS\n /*CREATE TABLE [Transversal].[DIM_SERVICIOS] (\n    [ID_SERVICIO] [int] IDENTITY(1,1) NOT NULL,\n    [SERVICIO] [nvarchar](40) NOT NULL,\n    [ID_UNIDAD] [int]  NOT NULL,\n    [CON_OBJETO_TARIFA] [nvarchar](40) NOT NULL,\n    [VAL_TARIFA] [decimal](28, 2) NOT NULL,\n    [COD_CATEGORIA] [nvarchar](40) NOT NULL,\n    [CATEGORIA] [nvarchar](40) NOT NULL,\n    [LINEA_INTERVENCION] [nvarchar](40),\n    [CUPOS_DISPONIBLES] [int] NOT NULL,\n    [ANIO_TARIFA] [varchar](10) NOT NULL,\n    [CIUDAD] [nvarchar](40) NOT NULL,\n    [ID_ESTABLECIMIENTO] [nvarchar](40) NOT NULL,\n    [NOMBRE_ESTABLECIMIENTO] [nvarchar](40) NOT NULL,\n    [SEDE_ESTABLECIMIENTO] [nvarchar](40) NOT NULL,\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](40) NOT NULL,\n    CONSTRAINT [PK_DIM_SERVICIOS] PRIMARY KEY CLUSTERED ([ID_SERVICIO]),\n    CONSTRAINT [FK_DIM_SERVICIOS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO*/\n\n-- Crear DIM_INFRAESTRUCTURA_CCF\n CREATE TABLE [Transversal].[DIM_INFRAESTRUCTURA_CCF] (\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](40) NOT NULL,\n    [DESCRIPCION] [nvarchar](40) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5,\n    CONSTRAINT [PK_DIM_INFRAESTRUCTURA_CCF] PRIMARY KEY CLUSTERED ([COD_INFRAESTRUCTURA_CCF]),\n    CONSTRAINT [FK_COD_INFRAESTRUCTURA_CCF_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO\n-- Crear DIM_CATEGORIA\n CREATE TABLE [Transversal].[DIM_CATEGORIA] (\n    [COD_CATEGORIA] [nvarchar](40) NOT NULL,\n    [DESCRIPCION] [nvarchar](40) NOT NULL,\n    CONSTRAINT [PK_DIM_CATEGORIA] PRIMARY KEY CLUSTERED ([COD_CATEGORIA])\n)\nGO\n\n-- Crear DIM_TARIFA_SERVICIOS\n CREATE TABLE [Transversal].[DIM_TARIFAS_SERVICIOS] (\n    [ID_TARIFA] [int] IDENTITY(1,1) NOT NULL,\n    [COD_SERVICIO] [int] NOT NULL,\n    [CON_OBJETO_TARIFA] [nvarchar](255) NOT NULL,\n    [COS_UNITARIO_CONCEPTO] [decimal](28, 2) NOT NULL,\n    [VAL_TARIFA] [decimal](28, 2) NOT NULL,\n    [COD_CATEGORIA] [nvarchar](40) NULL DEFAULT 3, -- Asignar valor por defecto de 3 categoria C,\n    [ANIO_TARIFA] [varchar](10) NOT NULL,\n    [COD_INFRAESTRUCTURA_CCF] [nvarchar](40) NOT NULL,\n    [ID_TARIFA_AUXILIAR] AS ( [ANIO_TARIFA] + '_' + [COD_INFRAESTRUCTURA_CCF] + '_' + CAST([COD_SERVICIO] AS NVARCHAR(10)) + '_' + [COD_CATEGORIA] ) PERSISTED,\n    CONSTRAINT [PK_DIM_TARIFA_SERVICIOS] PRIMARY KEY CLUSTERED ([ID_TARIFA]),\n    CONSTRAINT [FK_DIM_TARIFA_SERVICIOS_DIM_CATEGORIA] FOREIGN KEY ([COD_CATEGORIA]) REFERENCES [Transversal].[DIM_CATEGORIA]([COD_CATEGORIA]),\n    CONSTRAINT [FK_DIM_TARIFA_SERVICIOS_DIM_INFRAESTRUCTURA_CCF] FOREIGN KEY ([COD_INFRAESTRUCTURA_CCF]) REFERENCES [Transversal].[DIM_INFRAESTRUCTURA_CCF]([COD_INFRAESTRUCTURA_CCF])\n)\nGO\n\n-- Crear DIM_PERSONAL\n CREATE TABLE [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL] [int] IDENTITY(1,1) NOT NULL,\n    [COD_PERSONA_UNIDAD] [nvarchar](40),\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5,\n    [SERVICIO] [nvarchar](255),\n    [NOMBRE] [nvarchar](255),\n    [TELEFONO] [nvarchar](40),\n    [CELULAR] [nvarchar](40),\n    [CORREO] [nvarchar](255),\n    [DIRECCION] [nvarchar](300),\n    [CIUDAD] [nvarchar](255),\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [FECHA_NACIMIENTO] [datetime],\n    [GENERO] [nvarchar](40),\n    [HORAS_CONTRATADAS_MENSUAL] [decimal](18, 2) ,\n    [HORAS_CONTRATADAS_TOTALES] [decimal](18, 2) ,\n    [VALOR_TOTAL] [decimal](18, 2) ,\n    [TIPO_CONTRATACION] [nvarchar](40),\n    [FECHA_INICIO_CONTRATACION] [datetime],\n    [FECHA_FIN_CONTRATACION] [datetime],\n    [CAUSA_TERMINACION_CONTRATO] [nvarchar](40),\n    [PREGRADO] [nvarchar](255),\n    [POSGRADO_ESPECIALIDAD] [nvarchar](255),\n    [POSGRADO_MAESTRIA] [nvarchar](255),\n    [POSGRADO_DOCTORADO] [nvarchar](255),\n    [NIVEL_INGLES] [nvarchar](40),\n    [AREA] [nvarchar](255),\n    CONSTRAINT [PK_DIM_PERSONAL] PRIMARY KEY CLUSTERED ([ID_PERSONAL]),\n    CONSTRAINT [FK_DIM_PERSONAL_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO\n-- Crear FACT_ENCUESTAS\n CREATE TABLE [Transversal].[FACT_ENCUESTAS] (\n    [ID_ENCUESTA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [FECHA_ENCUESTA] [datetime] NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](40),\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [PREGUNTA] [nvarchar](255) NOT NULL,\n    [SERVICIO] [nvarchar](40) NOT NULL,\n    [NPS] [nvarchar](40) NOT NULL,\n    [CALIFICACION] [nvarchar](255) NOT NULL,\n    CONSTRAINT [PK_FACT_ENCUESTAS] PRIMARY KEY CLUSTERED ([ID_ENCUESTA]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear FACT_ENCUESTAS_PSR\n CREATE TABLE [Transversal].[FACT_ENCUESTAS_PSR] (\n    [ID_ENCUESTA_PSR] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [FECHA_ENCUESTA] [datetime] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [PROGRAMA] [nvarchar](40) NOT NULL,\n    [ACTIVIDAD_PREGUNTA] [nvarchar](255) NOT NULL,\n    [CALIFICACION] [nvarchar](40) NOT NULL,\n    CONSTRAINT [PK_FACT_ENCUESTAS_PSR] PRIMARY KEY CLUSTERED ([ID_ENCUESTA_PSR]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE]),\n    CONSTRAINT [FK_FACT_ENCUESTAS_PSR_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear DIM_SEDES\n CREATE TABLE [Transversal].[DIM_SEDES] (\n    [ID_SEDE] [int] IDENTITY(1,1) NOT NULL,\n    [SEDE] [nvarchar](60),\n    CONSTRAINT [PK_DIM_SEDES] PRIMARY KEY CLUSTERED ([ID_SEDE])\n)\nGO\n-- Crear DIM_CAPACIDAD_FISICA\n CREATE TABLE [Transversal].[DIM_CAPACIDAD_FISICA] (\n    [ID_CAPACIDAD] [int] IDENTITY(1,1) NOT NULL,\n    [ID_SALON] [nvarchar](10) NOT NULL,\n    [CAPACIDAD] [int] NOT NULL,\n    [DESCRIPCION_ESPACIO] [nvarchar](255),\n    [JORNADA] [nvarchar](40),\n    [BLOQUE] [nvarchar](40),\n    [GRUPO] [nvarchar](40),\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [ID_SEDE] [int] NOT NULL,\n    [SEDE] [nvarchar](40),\n    [ESTADO] [nvarchar](40),\n    [FECHA_ESTADO] [datetime] NOT NULL,\n    [ID_CAPACIDAD_AUXILIAR] AS ( [ID_SALON] + '_' + [JORNADA] + '_' + CAST([ID_UNIDAD] AS NVARCHAR(10)) ) PERSISTED,\n    CONSTRAINT [PK_DIM_CAPACIDAD_FISICA] PRIMARY KEY CLUSTERED ([ID_CAPACIDAD]),\n    CONSTRAINT [FK_DIM_CAPACIDAD_FISICA_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_DIM_CAPACIDAD_FISICA_DIM_SEDES] FOREIGN KEY ([ID_SEDE]) REFERENCES [Transversal].[DIM_SEDES]([ID_SEDE])\n)\nGO\n\n\n-- Crear FACT_INICIATIVAS\n CREATE TABLE [Transversal].[FACT_INICIATIVAS] (\n    [ID_INICIATIVA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [FECHA_INICIO] [datetime] NOT NULL,\n    [FECHA_FIN] [datetime] NOT NULL,\n    [NOMBRE_INICIATIVA] [nvarchar](255),\n    [DESCRIPCION_INICIATIVA] [nvarchar](255),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_FACT_INICIATIVAS] PRIMARY KEY CLUSTERED ([ID_INICIATIVA]),\n    CONSTRAINT [FK_FACT_INICIATIVAS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_INICIATIVAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear FACT_PQRS\n CREATE TABLE [Transversal].[FACT_PQRS] (\n    [ID_PQR] [nvarchar](40) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 5, -- Asignar valor por defecto de 5\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [ASUNTO] [nvarchar](255),\n    [CREADO_POR] [nvarchar](255),\n    [ASIGNADO_A] [nvarchar](255),\n    [ESTADO] [nvarchar](40),\n    [TIPO_DOCUMENTO] [nvarchar](40),\n    [DOCUMENTO] [nvarchar](20),\n    [NOMBRE] [nvarchar](255),\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [FECHA_CREACION] [datetime] NOT NULL,\n    [FECHA_RESOLUCION] [datetime] NOT NULL,\n    [FECHA_VENCIMIENTO] [datetime] NOT NULL,\n    [EQUIPO] [nvarchar](40),\n    [UNIDAD] [nvarchar](255),\n    [PROGRAMA_INCIDENTE] [nvarchar](255),\n    [ID_CAUSA] [nvarchar](40),\n    [CAUSA] [nvarchar](40),\n    [TIPO_PQRS] [nvarchar](40),\n    [TIPO_RESOLUCION] [nvarchar](40),\n    [UBICACION] [nvarchar](255),\n    CONSTRAINT [PK_FACT_PQRS] PRIMARY KEY CLUSTERED ([ID_PQR]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_FACT_PQRS_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE]),\n    CONSTRAINT [FK_FACT_PQRS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear FACT_CONVENIOS\n CREATE TABLE [Transversal].[FACT_CONVENIOS] (\n    [ID_CONVENIO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NULL DEFAULT 20090101, -- Asignar valor por defecto de 1 de enero de 2009,\n    [ID_UNIDAD] [int],-- NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    [PROGRAMA] [nvarchar](40),\n    [NOMBRE_CONVENIO] [nvarchar](255),\n    [IDENTIFICACION_ACTO_CONVENIO] [nvarchar](255),\n    [ENTIDAD_CONVENIO] [nvarchar](255),\n    [COD_MUNICIPIO] [nvarchar](40),\n    [VALOR_CONVENIO] [decimal](28, 2) NOT NULL,\n    [APORTE_COMFENALCO] [nvarchar](40),\n    [ESTADO_CONVENIO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NOT NULL,\n    [FECHA_FIN] [datetime] NOT NULL,\n    CONSTRAINT [PK_FACT_CONVENIOS] PRIMARY KEY CLUSTERED ([ID_CONVENIO]),\n    --CONSTRAINT [FK_FACT_CONVENIOS_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD]),\n    CONSTRAINT [FK_FACT_CONVENIOS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\n\nGO\n-- Tablas para el cubo\nCREATE TABLE [Transversal].[FACT_MINERIA](\n    [BP] [nvarchar](20) NULL,\n    [ID_FECHA_MENSUAL] [int] NULL,\n    [ID_ANIO_ACADEMICO] [nvarchar](4) NULL,\n    [ID_UNIDAD] [int] NULL,\n    [FECHA_INICIAL] [datetime] NULL,\n    [FECHA_FINAL] [datetime] NULL,\n    [ACTIVIDAD] [nvarchar](100) NULL,\n    [TIEMPO_SEGUNDOS] [int] NULL,\n    [VALOR_PAGADO] [int] NULL,\n    [ID_CATEGORIA] [int] NULL,\n    [ID_CURSO] [int] NULL,\n    [ID_TIPO_ESTUDIANTE] [int] NULL,\n    [ID_PROGRAMA] [int] NULL DEFAULT -1\n) ON [PRIMARY]\nGO\nCREATE TABLE [Transversal].[DIM_TIEMPO_MENSUAL](\n    [ID_FECHA] [int] NULL,\n    [FECHA] [datetime] NULL,\n    [DESC_FECHA] [nvarchar](50) NULL,\n    [ID_SEMANA] [int] NULL,\n    [DESC_SEMANA] [nvarchar](50) NULL,\n    [ID_NO_MES] [int] NULL,\n    [DESC_NO_MES] [nvarchar](50) NULL,\n    [ID_MES] [int] NULL,\n    [DESC_MES] [nvarchar](50) NULL,\n    [DESC_MES_CORTA] [nvarchar](50) NULL,\n    [ID_BIMESTRE] [int] NULL,\n    [DESC_BIMESTRE] [nvarchar](50) NULL,\n    [ID_TRIMESTRE] [int] NULL,\n    [DESC_TRIMESTRE] [nvarchar](50) NULL,\n    [ID_CUATRIMESTRE] [int] NULL,\n    [DESC_CUATRIMESTRE] [nvarchar](50) NULL,\n    [ID_SEMESTRE] [int] NULL,\n    [DESC_SEMESTRE] [nvarchar](50) NULL,\n    [ID_ANIO] [int] NULL,\n    [ID_ANIO_ANT] [int] NULL,\n    [NUM_DIA_SEMANA] [int] NULL,\n    [FESTIVO] [int] NULL,\n    [FECHA_CORTA] [date] NULL\n) ON [PRIMARY]\nGO\nCREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_UNIDADES] (\n    ID_CURSO INT,\n    GRADO VARCHAR(255),\n    ID_UNIDAD INT,\n    CATEGORIA VARCHAR(255),\n    ID_PLAN_COBERTURA INT,\n    ID_ESTABLECIMIENTO_EDUCATIVO VARCHAR(255),\n    ID_PROGRAMA INT,\n    ID_FECHA_MENSUAL INT,\n    POBLACION_PROYECTADA INT,\n    ORIGEN VARCHAR(255),\n    ACTIVIDAD VARCHAR(255),\n    RESULTADO VARCHAR(255),\n    CATEGORIA_SABER11 VARCHAR(255),\n    CAUSA VARCHAR(255),\n    NUM_POBLACION INT,\n    CALIFICACION VARCHAR(255),\n    DOCUMENTOS_COMPLETOS VARCHAR(255),\n    NUM_ESTUDIANTES INT,\n    NUM_MAYOR_250 INT,\n    TEMATICA VARCHAR(255)\n)\nGO\n CREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_PERSONAL] (\n    ID_FECHA INT NULL,\n    ID_PERSONAL INT NULL,\n    NOMBRE NVARCHAR(255) ,\n    CONCEPTO NVARCHAR(50) NULL,\n    DESCRIPCION NVARCHAR(255) ,\n    FECHA_FIN DATETIME ,\n    HORAS_CONTRATADAS_MENSUAL INT ,\n    ID_UNIDAD INT\n)\nGO\nCREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA] (\n    ID_FECHA INT NULL,\n    ID_ANIO INT NULL,\n    ID_MES INT NULL,\n    ID_CEBE NVARCHAR(40) ,\n    CEBE NVARCHAR(20) NULL,\n    DESCRIPCION_CEBE NVARCHAR(255) NULL,\n    DEPARTAMENTO NVARCHAR(100) NULL,\n    AREA NVARCHAR(100) NULL,\n    SUBAREA NVARCHAR(150) NULL,\n    SEGMENTO NVARCHAR(40) \n    ,DESCRIPCION_SEGMENTO NVARCHAR(150)\n    ,CODIGO_SSF INT\n    ,NOMBRE_SSF NVARCHAR(150)\n    ,ID_CUENTA NVARCHAR(50)\n    ,CUENTA NVARCHAR(50)\n    ,CUENTA_HOMOLOGA NVARCHAR(50)\n    ,DESCRIPCION NVARCHAR(255)\n    ,TIPO_CUENTA NVARCHAR(255)\n    ,TIPO_OPERACION NVARCHAR(255)\n    ,GRUPO_CUENTA NVARCHAR(255)\n    ,SUBGRUPO_CUENTA NVARCHAR(255)\n    ,GRUPO_OPERACION NVARCHAR(255)\n    ,CUENTA_SSF NVARCHAR(255)\n    ,DESCRIPCION_SSF NVARCHAR(255)\n    ,CUENTA_DESCRIPCION NVARCHAR(255)\n    ,CUENTA_DESCRIPCION_SSF NVARCHAR(255)\n    ,SIGNO_INGRESOS INT\n    ,CLASIFICACION INT\n    ,SEGMENT NVARCHAR(40)\n    ,IMPORTE BIGINT\n    ,INGRESOS INT\n    ,INGRESOS_OPERACIONALES INT\n    ,GASTOS INT\n    ,GASTOS_OPERACIONALES INT\n    ,GASTOS_OPERACIONALES_ADMIN INT\n    ,RESULTADO_EJERCICIO INT\n    ,COSTOS INT\n    ,ACTIVO BIGINT\n    ,PASIVO INT\n    ,PATRIMONIO INT\n    ,GASTOS_CON_DISTRIBUCION INT\n    ,GASTOS_SIN_DISTRIBUCION INT\n    ,[ACTIVIDAD] [nvarchar](255) NULL\n    ,ID_UNIDAD INT\n)\nGO\n CREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE] (\n PERIODO_ACADEMICO NVARCHAR(50)\n,ID_UNIDAD INT\n,ID_PERSONAL INT NULL\n,NOMBRE_DOCENTE NVARCHAR(255)\n,CALIFICACION_DEFINITIVA NVARCHAR(50)\n, ID_FECHA INT NULL\n)\nGO\nCREATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES] (\n    [ACTIVIDAD] NVARCHAR(255),\n    [ADEUDA] DECIMAL(18, 2) NULL,\n    [ANIO_ACADEMICO] INT NULL,\n    [CANTIDAD_MATERIAL] INT NULL,\n    [CALIFICACION] NVARCHAR(255) NULL,\n    [CAUSA] NVARCHAR(255) NULL,\n    [CATEGORIA_VENTA] NVARCHAR(255) NULL,\n    [COSTO] DECIMAL(18, 2) NULL,\n    [CURSO] NVARCHAR(255) NULL,\n    [DESCRIPCION] NVARCHAR(255) NULL,\n    [ESTADO] NVARCHAR(255) NULL,\n    [ESTADOREGISTRO] NVARCHAR(50),\n    [ESTADO_PAGO] NVARCHAR(255) NULL,\n    [ESTRATO] INT NULL,\n    [FECHA_AFILIACION] DATE NULL,\n    [FECHA_MENSUAL] DATE,\n    [FECHA_RETIRO] DATE NULL,\n    [FECHA_ADMISION] DATE NULL,\n    [ID_AFILIADO] INT NULL,\n    [ID_CATEGORIA] INT NULL,\n    [ID_CIUDAD] INT NULL,\n    [ID_CONCEPTO] INT NULL,\n    [ID_CURSO] INT NULL,\n    [ID_EMPRESA] INT NULL,\n    [ID_ESTADO_CIVIL] INT NULL,\n    [ID_ESTADO_GESTION] INT NULL,\n    [ID_FACTOR_VULNERABILIDAD] INT NULL,\n    [ID_FECHA] INT,\n    [ID_GENERO] INT NULL,\n    [ID_GRADO] INT NULL,\n    [ID_MATERIAL] INT NULL,\n    [ID_PERTENENCIA_ETNICA] INT NULL,\n    [ID_POBLACION] INT NULL,\n    [ID_PROGRAMA] INT NULL,\n    [ID_PREGUNTA] INT NULL,\n    [ID_TIPO_AFILIADO] INT NULL,\n    [ID_UNIDAD] INT NULL,\n    [NO_PRESTAMOS] INT NULL,\n    [NUMERO_APORTES] INT,\n    [PARTNER] NVARCHAR(50),\n    [PARTNER_AFILIADO] NVARCHAR(50) NULL,\n    [PARTNER_EMPRESA] NVARCHAR(50) NULL,\n    [RESPUESTA] NVARCHAR(255) NULL,\n    [SALARIO_BASICO] DECIMAL(18, 2) NULL,\n    [SERVICIO_TRANSPORTE] NVARCHAR(255) NULL,\n    [SUBSIDIO] DECIMAL(20, 2) NULL,\n    [TIPO_AFILIADO] NVARCHAR(255) NULL,\n    [TIPO_POBLACION] NVARCHAR(50),\n    [TOTAL_APORTES] DECIMAL(18, 2),\n    [VALOR_FACTURADO] DECIMAL(18, 2) NULL,\n    [VALOR_MATERIAL] DECIMAL(18, 2) NULL,\n    [VALOR_PAGADO] DECIMAL(18, 2) NULL,\n    [VALOR_PAGADO_SIN_IMP] DECIMAL(18, 2) NULL,\n    [POBLACION_EDUCACION] NVARCHAR(50) NULL,\n    [ID_PQR] [nvarchar](40) NULL DEFAULT -1,\n    [ESTADO_PQR] [nvarchar](40),\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1,\n    [CAUSA_PQR] [nvarchar](40),\n    [TIPO_PQRS] [nvarchar](40),\n    [ID_TARIFA] [int] NULL DEFAULT -1\n)\nGO\n\n-- Tabla DIM_GENERO\nCREATE TABLE [Transversal].[DIM_GENERO] (\n    [ID_GENERO] INT PRIMARY KEY,\n    [GENERO] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_GENERO] ([ID_GENERO], [GENERO])\nSELECT DISTINCT\n    [ID_GENERO],\n    [GENERO]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_ORIENTACION_SEXUAL\nCREATE TABLE [Transversal].[DIM_ORIENTACION_SEXUAL] (\n    [ID_ORIENTACION_SEXUAL] INT PRIMARY KEY,\n    [ORIENTACION_SEXUAL] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_ORIENTACION_SEXUAL] ([ID_ORIENTACION_SEXUAL], [ORIENTACION_SEXUAL])\nSELECT DISTINCT\n    [ID_ORIENTACION_SEXUAL],\n    [ORIENTACION_SEXUAL]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_ESTADO_CIVIL\nCREATE TABLE [Transversal].[DIM_ESTADO_CIVIL] (\n    [ID_ESTADO_CIVIL] INT PRIMARY KEY,\n    [ESTADO_CIVIL] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_ESTADO_CIVIL] ([ID_ESTADO_CIVIL], [ESTADO_CIVIL])\nSELECT DISTINCT\n    [ID_ESTADO_CIVIL],\n    [ESTADO_CIVIL]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_FACTOR_DE_VULNERABILIDAD\nCREATE TABLE [Transversal].[DIM_FACTOR_DE_VULNERABILIDAD] (\n    [ID_FACTOR_VULNERABILIDAD] INT PRIMARY KEY,\n    [FACTOR_VULNERABILIDAD] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_FACTOR_DE_VULNERABILIDAD] ([ID_FACTOR_VULNERABILIDAD], [FACTOR_VULNERABILIDAD])\nSELECT DISTINCT\n    [ID_FACTOR_VULNERABILIDAD],\n    [FACTOR_VULNERABILIDAD]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n\n-- Tabla DIM_PERTENENCIA_ETNICA\nCREATE TABLE [Transversal].[DIM_PERTENENCIA_ETNICA] (\n    [ID_PERTENENCIA_ETNICA] INT PRIMARY KEY,\n    [PERTENENCIA_ETNICA] NVARCHAR(50)\n);\n\nINSERT INTO [Transversal].[DIM_PERTENENCIA_ETNICA] ([ID_PERTENENCIA_ETNICA], [PERTENENCIA_ETNICA])\nSELECT DISTINCT\n    [ID_PERTENENCIA_ETNICA]\n      ,[PERTENENCIA_ETNICA]\nFROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS];\n</code></pre>"},{"location":"01.scripts/02.Cedesarrollo%20copy/","title":"Documentaci\u00f3n SQL para el Esquema <code>Cedesarrollo</code>","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL implementa el esquema <code>Cedesarrollo</code> dentro del Data Warehouse <code>DWH_COMFENALCO</code>. El modelo sigue las mejores pr\u00e1cticas de modelado dimensional, con tablas de dimensiones (<code>DIM</code>) y hechos (<code>FACT</code>) que permiten un an\u00e1lisis integral de datos relacionados con estudiantes, personal, programas acad\u00e9micos, y evaluaciones.</p>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li>Limpieza del Esquema:</li> <li> <p>Eliminaci\u00f3n de tablas, restricciones de claves for\u00e1neas y el esquema existente para asegurar una implementaci\u00f3n limpia.</p> </li> <li> <p>Creaci\u00f3n de un Modelo Dimensional:</p> </li> <li>Tablas de Dimensiones (<code>DIM</code>): Almacenan datos descriptivos y categorizados de estudiantes, programas, periodos acad\u00e9micos, etc.</li> <li> <p>Tablas de Hechos (<code>FACT</code>): Contienen m\u00e9tricas y relaciones con dimensiones, enfoc\u00e1ndose en datos transaccionales y anal\u00edticos.</p> </li> <li> <p>Integridad Referencial:</p> </li> <li>Relaciones estrictas mediante claves for\u00e1neas entre las dimensiones y los hechos.</li> </ol>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#tablas-dimensionales","title":"Tablas Dimensionales","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#1-dim_estudiantes","title":"1. DIM_ESTUDIANTES","text":"<p>Informaci\u00f3n b\u00e1sica de los estudiantes, como su tipo de documento y relaciones con otras dimensiones.</p> Columna Tipo Descripci\u00f3n <code>ID_ESTUDIANTE</code> <code>int</code> Identificador \u00fanico del estudiante. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento del estudiante. <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero de documento del estudiante. <code>ID_EMPRESA</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_EMPRESAS</code>. <code>ID_AFILIADO</code> <code>int</code> Relaci\u00f3n con la tabla <code>DIM_AFILIADOS</code>."},{"location":"01.scripts/02.Cedesarrollo%20copy/#2-dim_periodo_academico","title":"2. DIM_PERIODO_ACADEMICO","text":"<p>Define los periodos acad\u00e9micos asociados a programas y estudiantes.</p> Columna Tipo Descripci\u00f3n <code>ID_PERIODO</code> <code>int</code> Identificador \u00fanico del periodo acad\u00e9mico. <code>PERIODO_ACADEMICO</code> <code>nvarchar</code> Descripci\u00f3n del periodo acad\u00e9mico. <code>FECHA_INICIO</code> <code>datetime</code> Fecha de inicio del periodo acad\u00e9mico. <code>FECHA_FIN</code> <code>datetime</code> Fecha de finalizaci\u00f3n del periodo acad\u00e9mico."},{"location":"01.scripts/02.Cedesarrollo%20copy/#3-dim_programa","title":"3. DIM_PROGRAMA","text":"<p>Programas acad\u00e9micos asociados a estudiantes.</p> Columna Tipo Descripci\u00f3n <code>ID_PROGRAMA</code> <code>int</code> Identificador \u00fanico del programa. <code>PROGRAMA</code> <code>nvarchar</code> Nombre del programa."},{"location":"01.scripts/02.Cedesarrollo%20copy/#tablas-de-hechos","title":"Tablas de Hechos","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#1-fact_notas","title":"1. FACT_NOTAS","text":"<p>Registra las notas de estudiantes por periodos acad\u00e9micos y m\u00f3dulos.</p> Columna Tipo Descripci\u00f3n <code>ID_NOTA</code> <code>int</code> Identificador \u00fanico de la nota. <code>ID_ESTUDIANTE</code> <code>int</code> Relaci\u00f3n con <code>DIM_ESTUDIANTES</code>. <code>ID_PERIODO</code> <code>int</code> Relaci\u00f3n con <code>DIM_PERIODO_ACADEMICO</code>. <code>PRIMER_CORTE</code> <code>decimal</code> Nota del primer corte. <code>SEGUNDO_CORTE</code> <code>decimal</code> Nota del segundo corte. <code>TERCER_CORTE</code> <code>decimal</code> Nota del tercer corte. <code>NOTA_FINAL</code> <code>decimal</code> Nota final acumulada."},{"location":"01.scripts/02.Cedesarrollo%20copy/#2-fact_horario","title":"2. FACT_HORARIO","text":"<p>Registra los horarios acad\u00e9micos por estudiante y m\u00f3dulo.</p> Columna Tipo Descripci\u00f3n <code>ID_HORARIO</code> <code>int</code> Identificador \u00fanico del horario. <code>ID_MODULO</code> <code>int</code> Relaci\u00f3n con <code>DIM_PLAN_CURRICULAR</code>. <code>ID_JORNADA</code> <code>int</code> Relaci\u00f3n con <code>DIM_JORNADA</code>. <code>DIA</code> <code>nvarchar</code> D\u00eda de la clase. <code>HORA_INICIO</code> <code>nvarchar</code> Hora de inicio de la clase. <code>HORA_FIN</code> <code>nvarchar</code> Hora de fin de la clase."},{"location":"01.scripts/02.Cedesarrollo%20copy/#relaciones-dimensionales-y-tablas-de-hechos","title":"Relaciones Dimensionales y Tablas de Hechos","text":""},{"location":"01.scripts/02.Cedesarrollo%20copy/#diagrama-general-del-modelo","title":"Diagrama General del Modelo","text":"<pre><code>erDiagram\n    DIM_ESTUDIANTES {\n        int ID_ESTUDIANTE PK\n        nvarchar TIPO_DOCUMENTO\n        nvarchar DOCUMENTO\n    }\n\n    DIM_PROGRAMA {\n        int ID_PROGRAMA PK\n        nvarchar PROGRAMA\n    }\n\n    DIM_PERIODO_ACADEMICO {\n        int ID_PERIODO PK\n        nvarchar PERIODO_ACADEMICO\n        datetime FECHA_INICIO\n        datetime FECHA_FIN\n    }\n\n    DIM_JORNADA {\n        int ID_JORNADA PK\n        nvarchar JORNADA\n    }\n\n    DIM_PLAN_CURRICULAR {\n        int ID_MODULO PK\n        nvarchar MODULO\n    }\n\n    FACT_NOTAS {\n        int ID_NOTA PK\n        int ID_ESTUDIANTE FK\n        int ID_PERIODO FK\n        int ID_MODULO FK\n        decimal PRIMER_CORTE\n        decimal NOTA_FINAL\n    }\n\n    FACT_HORARIO {\n        int ID_HORARIO PK\n        int ID_PERIODO FK\n        int ID_MODULO FK\n        int ID_JORNADA FK\n    }\n\n    DIM_ESTUDIANTES ||--o{ FACT_NOTAS : \"ID_ESTUDIANTE\"\n    DIM_PERIODO_ACADEMICO ||--o{ FACT_NOTAS : \"ID_PERIODO\"\n    DIM_PLAN_CURRICULAR ||--o{ FACT_NOTAS : \"ID_MODULO\"\n    DIM_PLAN_CURRICULAR ||--o{ FACT_HORARIO : \"ID_MODULO\"\n    DIM_PERIODO_ACADEMICO ||--o{ FACT_HORARIO : \"ID_PERIODO\"\n    DIM_JORNADA ||--o{ FACT_HORARIO : \"ID_JORNADA\"</code></pre>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li>Integridad Referencial:</li> <li> <p>Uso de claves for\u00e1neas para mantener la consistencia entre dimensiones y hechos.</p> </li> <li> <p>Eficiencia del Modelo:</p> </li> <li>Modelado dimensional para facilitar consultas anal\u00edticas.</li> <li> <p>Separaci\u00f3n entre datos descriptivos (<code>DIM</code>) y m\u00e9tricas (<code>FACT</code>).</p> </li> <li> <p>Flexibilidad y Escalabilidad:</p> </li> <li> <p>Las tablas permiten agregar nuevas dimensiones y hechos sin afectar el esquema general.</p> </li> <li> <p>Normalizaci\u00f3n:</p> </li> <li>Uso de dimensiones comunes para evitar redundancia.</li> </ol>"},{"location":"01.scripts/02.Cedesarrollo%20copy/#conclusion","title":"Conclusi\u00f3n","text":"<p>El esquema <code>Cedesarrollo</code> ofrece un modelo integral y escalable para gestionar datos acad\u00e9micos y administrativos en un entorno anal\u00edtico. La estructura permite un an\u00e1lisis detallado de estudiantes, programas y resultados acad\u00e9micos, con un dise\u00f1o flexible para futuros requerimientos.</p>"},{"location":"01.scripts/02.Cedesarrollo/","title":"02. Cedesarrollo","text":""},{"location":"01.scripts/02.Cedesarrollo/#documentacion-del-esquema-cedesarrollo","title":"Documentaci\u00f3n del Esquema <code>Cedesarrollo</code>","text":""},{"location":"01.scripts/02.Cedesarrollo/#1-proposito-del-esquema","title":"1. Prop\u00f3sito del Esquema","text":"<p>El esquema <code>Cedesarrollo</code> est\u00e1 dise\u00f1ado para gestionar datos acad\u00e9micos y operativos de una instituci\u00f3n educativa dentro de un Data Warehouse. Su estructura dimensional facilita el an\u00e1lisis de:</p> <ul> <li>Rendimiento acad\u00e9mico (notas, asistencia, deserci\u00f3n).</li> <li>Gesti\u00f3n docente (ausentismo, evaluaci\u00f3n de desempe\u00f1o).</li> <li>Procesos administrativos (matr\u00edculas, facturaci\u00f3n, horarios).</li> <li>Planificaci\u00f3n curricular (programas, m\u00f3dulos, jornadas).</li> </ul>"},{"location":"01.scripts/02.Cedesarrollo/#2-estructura-del-esquema","title":"2. Estructura del Esquema","text":""},{"location":"01.scripts/02.Cedesarrollo/#21-tablas-de-dimensiones-dim_","title":"2.1. Tablas de Dimensiones (<code>DIM_*</code>)","text":"Tabla Descripci\u00f3n Columnas Clave Relaciones DIM_ESTUDIANTES Registra estudiantes y sus v\u00ednculos con entidades externas (empresas, afiliados). <code>ID_ESTUDIANTE</code> (PK) <code>DIM_EMPRESAS</code>, <code>DIM_AFILIADOS</code>, <code>DIM_BENEFICIARIOS</code>, <code>DIM_APORTANTE_NOAFILIADO</code> DIM_PERIODO_ACADEMICO Define per\u00edodos acad\u00e9micos (ej. semestres). <code>ID_PERIODO</code> (PK) <code>DIM_UNIDAD</code> DIM_PROGRAMA Cataloga programas acad\u00e9micos ofrecidos. <code>ID_PROGRAMA</code> (PK) - DIM_JORNADA Jornadas disponibles (diurna, nocturna). <code>ID_JORNADA</code> (PK) - DIM_PLAN_CURRICULAR Detalla m\u00f3dulos/cursos de cada programa. <code>ID_MODULO</code> (PK) <code>DIM_PROGRAMA</code>"},{"location":"01.scripts/02.Cedesarrollo/#22-tablas-de-hechos-fact_","title":"2.2. Tablas de Hechos (<code>FACT_*</code>)","text":"Tabla Descripci\u00f3n M\u00e9tricas Principales Relaciones FACT_NOTAS Calificaciones por m\u00f3dulo y per\u00edodo. <code>PRIMER_CORTE</code>, <code>NOTA_FINAL</code> <code>DIM_ESTUDIANTES</code>, <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PLAN_CURRICULAR</code> FACT_HORARIO Horarios de clases. <code>HORA_INICIO</code>, <code>HORA_FIN</code> <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_JORNADA</code> FACT_AUSENTISMO_DOCENTE Ausencias del personal docente. <code>AUSENCIA_HORAS</code>, <code>TIPO_AUSENCIA</code> <code>DIM_PERSONAL</code>, <code>DIM_PERIODO_ACADEMICO</code> FACT_DESERCION Deserci\u00f3n estudiantil. <code>TIPO</code>, <code>CAUSA</code> <code>DIM_ESTUDIANTES</code>, <code>DIM_PERIODO_ACADEMICO</code> FACT_FACTURACION Transacciones financieras (matr\u00edculas, pagos). <code>VALOR_FACTURADO</code>, <code>ADEUDA</code> <code>DIM_TARIFAS_SERVICIOS</code> FACT_DESEMPENHO_DOCENTE_DE Evaluaci\u00f3n docente por estudiantes. <code>CALIFICACION</code> <code>DIM_PERSONAL</code>, <code>DIM_PERIODO_ACADEMICO</code>"},{"location":"01.scripts/02.Cedesarrollo/#3-diagrama-de-relaciones-clave","title":"3. Diagrama de Relaciones Clave","text":"<pre><code>erDiagram\n    DIM_ESTUDIANTES ||--o{ FACT_NOTAS : \"ID_ESTUDIANTE\"\n    DIM_PERIODO_ACADEMICO ||--o{ FACT_NOTAS : \"ID_PERIODO\"\n    DIM_PLAN_CURRICULAR ||--o{ FACT_NOTAS : \"ID_MODULO\"\n    DIM_JORNADA ||--o{ FACT_HORARIO : \"ID_JORNADA\"\n    DIM_PROGRAMA ||--o{ DIM_PLAN_CURRICULAR : \"ID_PROGRAMA\"\n    DIM_PERSONAL ||--o{ FACT_AUSENTISMO_DOCENTE : \"ID_PERSONAL\"</code></pre>"},{"location":"01.scripts/02.Cedesarrollo/#4-buenas-practicas-implementadas","title":"4. Buenas Pr\u00e1cticas Implementadas","text":"<ul> <li>Valores por Defecto: <ul> <li><code>-1</code> para claves for\u00e1neas no definidas (ej. <code>ID_EMPRESA</code> en <code>DIM_ESTUDIANTES</code>).</li> <li>Registro <code>ID_ESTUDIANTE = -1</code> para casos de datos faltantes.</li> </ul> </li> <li>Integridad Referencial: <ul> <li>Claves for\u00e1neas en todas las tablas de hechos.</li> <li>Eliminaci\u00f3n segura del esquema previo (<code>DROP</code> de constraints antes de tablas).</li> </ul> </li> <li>Normalizaci\u00f3n: <ul> <li>Separaci\u00f3n clara entre dimensiones (entidades est\u00e1ticas) y hechos (eventos din\u00e1micos).</li> </ul> </li> </ul>"},{"location":"01.scripts/02.Cedesarrollo/#5-script","title":"5. Script","text":"<pre><code>USE DWH_COMFENALCO\nGO\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n-- Eliminar restricciones de clave for\u00e1nea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Cedesarrollo';\nEXEC sp_executesql @sql;\n-- Eliminar tablas\nSET @sql = '';\nSELECT @sql += 'DROP TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) + '; ' \nFROM sys.tables t\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Cedesarrollo';\nEXEC sp_executesql @sql;\n-- Eliminar el esquema\nIF EXISTS (SELECT * FROM sys.schemas WHERE name = 'Cedesarrollo')\nBEGIN\n    DROP SCHEMA Cedesarrollo;\nEND\nGO\n-- Crear el esquema Cedesarrollo\nCREATE SCHEMA Cedesarrollo;\nGO \n-- Crear Cedesarrollo.DIM_ESTUDIANTES\nCREATE TABLE [Cedesarrollo].[DIM_ESTUDIANTES] (\n    [ID_ESTUDIANTE] [int] IDENTITY(1,1) NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_EMPRESA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_AFILIADO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_BENEFICIARIO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [ID_APORTANTE] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    CONSTRAINT [PK_DIM_ESTUDIANTES] PRIMARY KEY CLUSTERED ([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_EMPRESAS] FOREIGN KEY ([ID_EMPRESA]) REFERENCES [Transversal].[DIM_EMPRESAS]([ID_EMPRESA]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_AFILIADOS] FOREIGN KEY ([ID_AFILIADO]) REFERENCES [Transversal].[DIM_AFILIADOS]([ID_AFILIADO]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_BENEFICIARIOS] FOREIGN KEY ([ID_BENEFICIARIO]) REFERENCES [Transversal].[DIM_BENEFICIARIOS]([ID_BENEFICIARIO]),\n    CONSTRAINT [FK_DIM_ESTUDIANTES_DIM_APORTANTE_NOAFILIADO] FOREIGN KEY ([ID_APORTANTE]) REFERENCES [Transversal].[DIM_APORTANTE_NOAFILIADO]([ID_APORTANTE])\n)\nGO\n-- Crear Cedesarrollo.DIM_PERIODO_ACADEMICO\nCREATE TABLE [Cedesarrollo].[DIM_PERIODO_ACADEMICO] (\n    [ID_PERIODO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [PERIODO_ACADEMICO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NULL, -- QUITE NOT\n    [FECHA_FIN] [datetime] NULL, -- QUITE NOT\n    CONSTRAINT [PK_DIM_PERIODO_ACADEMICO] PRIMARY KEY CLUSTERED ([ID_PERIODO]),\n    CONSTRAINT [FK_DIM_PERIODO_ACADEMICO_DIM_UNIDAD] FOREIGN KEY ([ID_UNIDAD]) REFERENCES [Transversal].[DIM_UNIDAD]([ID_UNIDAD])\n)\nGO\n-- Crear Cedesarrollo.DIM_PROGRAMA\nCREATE TABLE [Cedesarrollo].[DIM_PROGRAMA] (\n    [ID_PROGRAMA] [int] IDENTITY(1,1) NOT NULL,\n    [PROGRAMA] [nvarchar](255)\n    CONSTRAINT [PK_DIM_PROGRAMA] PRIMARY KEY CLUSTERED ([ID_PROGRAMA])\n)\nGO\n\n-- Crear Cedesarrollo.DIM_JORNADA\nCREATE TABLE [Cedesarrollo].[DIM_JORNADA] (\n    [ID_JORNADA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [JORNADA] [nvarchar](40),\n    CONSTRAINT [PK_DIM_JORNADA] PRIMARY KEY CLUSTERED ([ID_JORNADA])\n)\nGO\n\n-- Crear Cedesarrollo.DIM_PLAN_CURRICULAR\nCREATE TABLE [Cedesarrollo].[DIM_PLAN_CURRICULAR] (\n    [ID_MODULO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PROGRAMA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1,\n    [MODULO] [nvarchar](200), \n    --[ID_PERIODO] [int] NOT NULL,\n    [INTENSIDAD_HORARIA] [nvarchar](40),\n    [INTENSIDAD_HORARIA_SEMANAL] [nvarchar](40),\n    [NO_CREDITOS] [nvarchar](40),\n    [SEMESTRE] [nvarchar](40),\n    CONSTRAINT [PK_DIM_PLAN_CURRICULAR] PRIMARY KEY CLUSTERED ([ID_MODULO]),\n    CONSTRAINT [FK_DIM_PLAN_CURRICULAR_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_NOTAS\nCREATE TABLE [Cedesarrollo].[FACT_NOTAS] (\n    [ID_NOTA] [int] IDENTITY(1,1) NOT NULL,\n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NOT NULL,\n    [ID_MODULO] [int] NULL,  -- QUITE NULL\n    [CURSO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NULL, -- QUITE NULL\n    [ID_PERIODO] [int] NOT NULL,\n    --[PROGRAMA_ACADEMICO] [nvarchar](60),\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [FECHA_FIN] [datetime] NULL, -- QUITE NULL\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [NOMBRE_ESTUDIANTE] [nvarchar](200),\n    [PRIMER_CORTE] [decimal](10, 2),\n    [PRIMER_CORTE_CP1] [decimal](10, 2),\n    [PRIMER_CORTE_CP2] [decimal](10, 2),\n    [PRIMER_CORTE_CT1] [decimal](10, 2),\n    [PRIMER_CORTE_CT2] [decimal](10, 2),\n    [SEGUNDO_CORTE] [decimal](10, 2),\n    [SEGUNDO_CORTE_CP1] [decimal](10, 2),\n    [SEGUNDO_CORTE_CP2] [decimal](10, 2),\n    [SEGUNDO_CORTE_CT1] [decimal](10, 2),\n    [SEGUNDO_CORTE_CT2] [decimal](10, 2),\n    [TERCER_CORTE] [decimal](10, 2),\n    [TERCER_CORTE_CP1] [decimal](10, 2),\n    [TERCER_CORTE_CP2] [decimal](10, 2),\n    [TERCER_CORTE_CT1] [decimal](10, 2),\n    [TERCER_CORTE_CT2] [decimal](10, 2),\n    [NOTA_FINAL] [decimal](10, 2),\n    [PESO_CORTE] [decimal](10, 2),\n    CONSTRAINT [PK_FACT_NOTAS] PRIMARY KEY CLUSTERED ([ID_NOTA]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_PLAN_CURRICULAR] FOREIGN KEY ([ID_MODULO]) REFERENCES [Cedesarrollo].[DIM_PLAN_CURRICULAR]([ID_MODULO]),\n    CONSTRAINT [FK_FACT_NOTAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA])\n\n)\nGO\n\n-- Crear Cedesarrollo.FACT_HORARIO\nCREATE TABLE [Cedesarrollo].[FACT_HORARIO] (\n    [ID_HORARIO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [ID_MODULO] [int] NULL,\n    --[MODULO] [nvarchar](40),\n    [ID_JORNADA] [int] NULL,\n    --[JORNADA] [nvarchar](40),\n    [SEMESTRE] [nvarchar](40),\n    [GRUPO] [nvarchar](40),\n    [DIA] [nvarchar](40),\n    [SALON] [nvarchar](40),\n    [HORA_INICIO] [nvarchar](40),\n    [HORA_FIN] [nvarchar](40),\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [COD_ESTABLECIMIENTO] [nvarchar](40),\n    CONSTRAINT [PK_FACT_HORARIO] PRIMARY KEY CLUSTERED ([ID_HORARIO]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_PLAN_CURRICULAR] FOREIGN KEY ([ID_MODULO]) REFERENCES [Cedesarrollo].[DIM_PLAN_CURRICULAR]([ID_MODULO]),\n    CONSTRAINT [FK_FACT_HORARIO_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA])\n)\nGO\n\n\n\n-- Crear Cedesarrollo.FACT_AUSENTISMO_DOCENTE\nCREATE TABLE [Cedesarrollo].[FACT_AUSENTISMO_DOCENTE] (\n    [ID_AUSENTISMO_DOCENTE] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [FECHA] [datetime] NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [CARGO] [nvarchar](40),\n    [FECHA_INICIO] [datetime] NOT NULL,\n    [FECHA_FIN] [datetime] NOT NULL,\n    [AUSENCIA_HORAS] [nvarchar](40),\n    [AUSENCIA_DIAS] [nvarchar](40),\n    [TIPO_AUSENCIA] [nvarchar](40),\n    [PERMISO] [nvarchar](40),\n    [MOTIVO_AUSENCIA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_AUSENTISMO_DOCENTE] PRIMARY KEY CLUSTERED ([ID_AUSENTISMO_DOCENTE]),\n    CONSTRAINT [FK_FACT_AUSENTISMO_DOCENTE_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_AUSENTISMO_DOCENTE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_AUSENTISMO_DOCENTE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_PERMISO_ESTUDIANTE\nCREATE TABLE [Cedesarrollo].[FACT_PERMISO_ESTUDIANTE] (\n    [ID_PERMISO_ESTUDIANTE] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [MODULO] [nvarchar](40),\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [HORA] [nvarchar](40),\n    [MOTIVO_AUSENCIA] [nvarchar](40),\n    [SOPORTE_AUSENCIA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_PERMISO_ESTUDIANTE] PRIMARY KEY CLUSTERED ([ID_PERMISO_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_PERMISO_ESTUDIANTE_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_PERMISO_ESTUDIANTE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_PERMISO_ESTUDIANTE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_INASISTENCIAS\nCREATE TABLE [Cedesarrollo].[FACT_INASISTENCIAS] (\n    [ID_INASISTENCIAS] [int] IDENTITY(1,1) NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NOT NULL,\n    --[JORNADA] [nvarchar](40),\n    [ID_MODULO] [int] NULL, -- QUITE NOT\n    --[MODULO] [nvarchar](40),\n    [CURSO] [nvarchar](40) NULL,\n    [CORTE] [nvarchar](40) NULL,\n    [ID_FECHA] [int] NULL, -- QUITE NOT\n    [FECHA] [datetime] NULL, -- QUITE NOT\n    [HORA] [nvarchar](40) NULL,\n    [TOTAL_INASISTENCIA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_INASISTENCIAS] PRIMARY KEY CLUSTERED ([ID_INASISTENCIAS]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_PLAN_CURRICULAR] FOREIGN KEY ([ID_MODULO]) REFERENCES [Cedesarrollo].[DIM_PLAN_CURRICULAR]([ID_MODULO]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_INASISTENCIAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_DESERCION\nCREATE TABLE [Cedesarrollo].[FACT_DESERCION] (\n    [ID_DESERCION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL, /* NOT lo quite temporalmente ya que se llena posteriormente en la ETL*/\n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NULL, /* NOT lo quite temporalmente ya que se llena posteriormente en la ETL*/\n    --[JORNADA] [nvarchar](40),\n    --[PROGRAMA] [nvarchar](40),\n    [NOMBRE_ESTUDIANTE] [nvarchar](255),\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [GRUPO] [nvarchar](40),\n    --[MODULO] [nvarchar](40),\n    [SEMESTRE] [nvarchar](40),\n    [ID_FECHA] [int] NULL, /* NOT lo quite temporalmente*/\n    [FECHA] [datetime] NOT NULL,\n    [TIPO] [nvarchar](40),\n    [CAUSA] [nvarchar](40),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_FACT_DESERCION] PRIMARY KEY CLUSTERED ([ID_DESERCION]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_DESERCION_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_DESERCION_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_ESTADO_MATRICULAS\nCREATE TABLE [Cedesarrollo].[FACT_ESTADO_MATRICULAS] (\n    [ID_MATRICULA] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL,\n    [ID_PROGRAMA] [int] NULL, -- QUITE NOT  \n    [SEDE] [nvarchar](255),\n    [ID_JORNADA] [int] NULL, -- QUITE NOT  \n    --[JORNADA] [nvarchar](40),\n    [NOMBRE_ESTUDIANTE] [nvarchar](200),\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [ID_FECHA] [int] NULL, -- QUITE NOT  \n    [FECHA_MATRICULA] [datetime] NOT NULL,\n    [TELEFONO] [nvarchar](40),\n    [CELULAR] [nvarchar](40),\n    [CORREO] [nvarchar](200),\n    [FECHA_OPORTUNA] [datetime] NULL, -- QUITE NOT  \n    [FECHA_ACTUALIZACION] [datetime] NULL, -- QUITE NOT  \n    [DOCUMENTOS_COMPLETOS] [nvarchar](20) NULL, -- QUITE NOT  \n    [SEMESTRE] [nvarchar](40),\n    CONSTRAINT [PK_FACT_ESTADO_MATRICULAS] PRIMARY KEY CLUSTERED ([ID_MATRICULA]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_ESTADO_MATRICULAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_INSCRIPCION_MATRICULAS\nCREATE TABLE [Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] (\n    [ID_INSCRIPCION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NULL, -- QUITE NOT  \n    [ID_PROGRAMA] [int] NOT NULL,\n    --[TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    --[DOCUMENTO_ESTUDIANTE] [nvarchar](20) NOT NULL,\n    --[JORNADA] [nvarchar](40),\n    --[PROGRAMA] [nvarchar](40),\n    [ID_FECHA] [int] NULL, -- QUITE NOT  \n    [FECHA] [datetime] NOT NULL,\n    [ID_JORNADA] [int] NOT NULL,\n    [ESTADO] [nvarchar](40),\n    [TIPO_ESTUDIANTE] [nvarchar](40),\n    [CATEGORIA_COBERTURA] [nvarchar](40),\n    [CATEGORIA_SUBSIDIO] [nvarchar](40),\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    CONSTRAINT [PK_FACT_INSCRIPCION_MATRICULAS] PRIMARY KEY CLUSTERED ([ID_INSCRIPCION]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA]),\n    CONSTRAINT [FK_FACT_INSCRIPCION_MATRICULAS_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_FACTURACION\nCREATE TABLE [Cedesarrollo].[FACT_FACTURACION] (\n    [ID_FACTURACION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int]  NULL, -- NO HAY UN CAMPO ELEGIBLE\n    [TIPO_DOCUMENTO_PAGO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO_PAGO] [nvarchar](20) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA_CONTABLE] [datetime] NOT NULL,\n    [ID_TARIFA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_CONCEPTO] [int] NOT NULL,\n    [CONCEPTO] [nvarchar](255),\n    [VALOR_FACTURADO] [decimal](28, 2),\n    [SUBSIDIO] [decimal](28, 2),\n    [VALOR_PAGADO] [decimal](28, 2),\n    [ADEUDA] [nvarchar](40),\n    [ESTADO_PAGO] [nvarchar](40),\n    [FECHA_OPORTUNA_PAGO] [datetime] NULL,\n    [NO_RECIBO] [nvarchar](40),\n    [CATEGORIA] [nvarchar](40),\n    [FUENTE_RECURSOS] [nvarchar](40) NULL DEFAULT 'PROPIOS'\n    CONSTRAINT [PK_FACT_FACTURACION] PRIMARY KEY CLUSTERED ([ID_FACTURACION]),\n    --CONSTRAINT [FK_FACT_FACTURACION_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_FACTURACION_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n-- Crear Cedesarrollo.DIM_PREGUNTAS_COTIZACION\nCREATE TABLE [Cedesarrollo].[DIM_PREGUNTAS_COTIZACION] (\n    [ID_PREGUNTA] [int] IDENTITY(1,1) NOT NULL,\n    [PREGUNTA] [nvarchar](255),\n    [OBSERVACIONES] [nvarchar](255),\n    CONSTRAINT [PK_DIM_PREGUNTAS_COTIZACION] PRIMARY KEY CLUSTERED ([ID_PREGUNTA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_COTIZACIONES\nCREATE TABLE [Cedesarrollo].[FACT_COTIZACIONES] (\n    [ID_COTIZACION] [int] IDENTITY(1,1) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA_REGISTRO] [datetime] NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [NOMBRE] [nvarchar](200),\n    [ID_TARIFA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ESTADO_COTIZACION] [nvarchar](40),\n    [ID_PREGUNTA] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [RESPUESTA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_COTIZACIONES] PRIMARY KEY CLUSTERED ([ID_COTIZACION]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_DIM_PREGUNTAS_COTIZACION] FOREIGN KEY ([ID_PREGUNTA]) REFERENCES [Cedesarrollo].[DIM_PREGUNTAS_COTIZACION]([ID_PREGUNTA]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_DIM_TARIFAS_SERVICIOS] FOREIGN KEY ([ID_TARIFA]) REFERENCES [Transversal].[DIM_TARIFAS_SERVICIOS]([ID_TARIFA]),\n    CONSTRAINT [FK_FACT_COTIZACIONES_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n\n-- Crear Cedesarrollo.FACT_PLAN_COBERTURA\nCREATE TABLE [Cedesarrollo].[FACT_PLAN_COBERTURA] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    [MODALIDAD] [nvarchar](40),\n    [CATEGORIA] [nvarchar](40),\n    [ID_PROGRAMA] [int] NULL,\n    --[PROGRAMA] [nvarchar](40),\n    [USOS_PROYECTADOS] [nvarchar](40),\n    [USUARIOS_PROYECTADOS] [nvarchar](40),\n    CONSTRAINT [PK_FACT_PLAN_COBERTURA] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_PLAN_COBERTURA_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    --CONSTRAINT [FK_FACT_PLAN_COBERTURA_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE\nCREATE TABLE [Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_DE] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 3, -- Asignar valor por defecto de 3\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_PERIODO] [int] NOT NULL,\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [TIPO_DOCUMENTO_ENCUESTADO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO_ENCUESTADO] [nvarchar](20) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [PROGRAMA] [nvarchar](40),\n    [CALIFICACION] [nvarchar](40),\n    CONSTRAINT [PK_FACT_DESEMPENHO_DOCENTE_DE] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_DE_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_DE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_DE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE\nCREATE TABLE [Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_CE] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NULL DEFAULT 2, -- Asignar valor por defecto de 2\n    [ID_PERSONAL] [int] NULL DEFAULT -1, -- Asignar valor por defecto de -1\n    [ID_PERIODO] [int] NOT NULL,\n    [NOMBRE_DOCENTE] [nvarchar](200),\n    [TIPO_CONTRATACION] [nvarchar](40),\n    [CALIFICACION_ESTUDIANTES] [nvarchar](40),\n    [CALIFICACION_UNIDAD] [nvarchar](40),\n    [CALIFICACION_DOCENTE] [nvarchar](40),\n    [CALIFICACION_DEFINITIVA] [nvarchar](40),\n    CONSTRAINT [PK_FACT_DESEMPENHO_DOCENTE_CE] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_CE_DIM_PERSONAL] FOREIGN KEY ([ID_PERSONAL]) REFERENCES [Transversal].[DIM_PERSONAL]([ID_PERSONAL]),\n    CONSTRAINT [FK_FACT_DESEMPENHO_DOCENTE_CE_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_GRADUADOS\nCREATE TABLE [Cedesarrollo].[FACT_GRADUADOS] (\n    [ID_GRADUADO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_JORNADA] [int] NOT NULL,\n    [ID_PROGRAMA] [int] NOT NULL,\n    [GRUPO] [nvarchar](40),\n    [ESTADO] [nvarchar](40),\n    [ZONA] [nvarchar](40),\n    [NIVEL_FORMACION] [nvarchar](40),\n    [OCUPACION] [nvarchar](40),\n    [SEDE] [nvarchar](255),\n    [JORNADA] [nvarchar](40),\n    [PROGRAMA] [nvarchar](255),\n    [SEMESTRE] [nvarchar](40),\n    [FECHA_ACTUALIZACION] [datetime] NOT NULL,\n    [FECHA_GRADUADO] [datetime] NOT NULL,\n    [ACTA_GRADUADO] [nvarchar](40),\n    [FOLIO_GRADUADO] [nvarchar](40),\n    [DIPLOMA_GRADUADO] [nvarchar](40),\n    CONSTRAINT [PK_FACT_GRADUADOS] PRIMARY KEY CLUSTERED ([ID_GRADUADO]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_PROGRAMA] FOREIGN KEY ([ID_PROGRAMA]) REFERENCES [Cedesarrollo].[DIM_PROGRAMA]([ID_PROGRAMA]),\n    CONSTRAINT [FK_FACT_GRADUADOS_DIM_JORNADA] FOREIGN KEY ([ID_JORNADA]) REFERENCES [Cedesarrollo].[DIM_JORNADA]([ID_JORNADA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR\nCREATE TABLE [Cedesarrollo].[FACT_ASISTENCIA_ACT_BIENESTAR] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_PERIODO] [int] NOT NULL,\n    [ID_ESTUDIANTE] [int] NOT NULL,\n    [TIPO_DOCUMENTO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO] [nvarchar](20) NOT NULL,\n    [ID_FECHA] [int] NOT NULL,\n    [FECHA] [datetime] NOT NULL,\n    [ACTIVIDAD] [nvarchar](40),\n    [ASISTIO] [nvarchar](40),\n    CONSTRAINT [PK_FACT_ASISTENCIA_ACT_BIENESTAR] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_ASISTENCIA_ACT_BIENESTAR_DIM_ESTUDIANTES] FOREIGN KEY ([ID_ESTUDIANTE]) REFERENCES [Cedesarrollo].[DIM_ESTUDIANTES]([ID_ESTUDIANTE]),\n    CONSTRAINT [FK_FACT_ASISTENCIA_ACT_BIENESTAR_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO]),\n    CONSTRAINT [FK_FACT_ASISTENCIA_ACT_BIENESTAR_DE_Dim_TIEMPO] FOREIGN KEY([ID_FECHA]) REFERENCES [Dwh].[DIM_TIEMPO] ([ID_FECHA])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR\nCREATE TABLE [Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR] (\n    [ID_REGISTRO] [int] IDENTITY(1,1) NOT NULL,\n    [ID_UNIDAD] [int] NOT NULL,\n    [UNIDAD] [nvarchar](40),\n    [ID_PERIODO] [int] NOT NULL,\n    [CALIFICACION] [nvarchar](40),\n    [OBSERVACIONES] [nvarchar](40),\n    CONSTRAINT [PK_FACT_EVALUACION_PLAN_CURRICULAR] PRIMARY KEY CLUSTERED ([ID_REGISTRO]),\n    CONSTRAINT [FK_FACT_EVALUACION_PLAN_CURRICULAR_DIM_PERIODO_ACADEMICO] FOREIGN KEY ([ID_PERIODO]) REFERENCES [Cedesarrollo].[DIM_PERIODO_ACADEMICO]([ID_PERIODO])\n)\nGO\n\n-- Crear Cedesarrollo.FACT_EVALUACION_FORMACION\nCREATE TABLE [Cedesarrollo].[FACT_EVALUACION_FORMACION] (\n    [ID_EVALUACION_FORMACION] [int] IDENTITY(1,1) NOT NULL,\n    [TIPO_DOCUMENTO_ENCUESTADO] [nvarchar](40) NOT NULL,\n    [DOCUMENTO_ENCUESTADO] [nvarchar](20) NOT NULL,\n    [FECHA_REALIZACION_EVENTO] [datetime] NOT NULL,\n    [ASPECTO_1] [nvarchar](40),\n    [ASPECTO_2] [nvarchar](40),\n    [ASPECTO_3] [nvarchar](40),\n    [ASPECTO_4] [nvarchar](40),\n    [ASPECTO_5] [nvarchar](40),\n    [ASPECTO_6] [nvarchar](40),\n    [ASPECTO_7] [nvarchar](40),\n    [ASPECTO_8] [nvarchar](40),\n    [ASPECTO_9] [nvarchar](40),\n    CONSTRAINT [PK_FACT_EVALUACION_FORMACION] PRIMARY KEY CLUSTERED ([ID_EVALUACION_FORMACION]),\n)\nGO\n\n-- Disable identity insert to manually insert -1 in the identity column\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_ESTUDIANTES] ON;\n\nINSERT INTO [Cedesarrollo].[DIM_ESTUDIANTES] ([ID_ESTUDIANTE], [TIPO_DOCUMENTO], [DOCUMENTO], [ID_EMPRESA], [ID_AFILIADO], [ID_BENEFICIARIO], [ID_APORTANTE])\nVALUES (-1, 'N/A', 'N/A', -1, -1, -1, -1);\n\n-- Enable identity insert back\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_ESTUDIANTES] OFF;\n</code></pre>"},{"location":"01.scripts/03.Proteccion/","title":"Documentaci\u00f3n SQL para el Esquema <code>Protecci\u00f3n</code>","text":""},{"location":"01.scripts/03.Proteccion/#introduccion","title":"Introducci\u00f3n","text":"<p>El script SQL establece el esquema <code>Protecci\u00f3n</code> en el Data Warehouse <code>DWH_COMFENALCO</code>. Este esquema est\u00e1 dise\u00f1ado para gestionar informaci\u00f3n relacionada con poblaci\u00f3n, establecimientos educativos, programas, caracterizaci\u00f3n y actividades relacionadas con protecci\u00f3n y visitas.</p>"},{"location":"01.scripts/03.Proteccion/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li> <p>Limpieza del Esquema Existente:</p> <ul> <li>Elimina restricciones de claves for\u00e1neas, tablas y el esquema si ya existe, para permitir una implementaci\u00f3n limpia.</li> </ul> </li> <li> <p>Creaci\u00f3n de Estructuras Dimensionales:</p> <ul> <li>Tablas Dimensionales (<code>DIM</code>): Almacenan datos est\u00e1ticos o descriptivos relacionados con poblaci\u00f3n, programas, y caracter\u00edsticas.</li> <li>Tablas de Hechos (<code>FACT</code>): Contienen registros transaccionales y m\u00e9tricas relacionadas con actividades de protecci\u00f3n.</li> </ul> </li> <li> <p>Gesti\u00f3n de Integridad:</p> <ul> <li>Claves for\u00e1neas y primarias para garantizar relaciones consistentes entre dimensiones y hechos.</li> </ul> </li> </ol>"},{"location":"01.scripts/03.Proteccion/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/03.Proteccion/#tablas-dimensionales","title":"Tablas Dimensionales","text":""},{"location":"01.scripts/03.Proteccion/#1-dim_poblacion","title":"1. DIM_POBLACION","text":"<p>Contiene informaci\u00f3n b\u00e1sica de la poblaci\u00f3n objeto de an\u00e1lisis.</p> Columna Tipo Descripci\u00f3n <code>ID_POBLACION</code> <code>int</code> Identificador \u00fanico de la poblaci\u00f3n. <code>TIPO_DOCUMENTO</code> <code>nvarchar</code> Tipo de documento de identidad. <code>DOCUMENTO</code> <code>nvarchar</code> N\u00famero de documento de identidad. <code>ID_EMPRESA</code> <code>int</code> Relaci\u00f3n con empresas en otros esquemas."},{"location":"01.scripts/03.Proteccion/#2-dim_establecimiento_educativo","title":"2. DIM_ESTABLECIMIENTO_EDUCATIVO","text":"<p>Informaci\u00f3n sobre los establecimientos educativos vinculados al sistema.</p> Columna Tipo Descripci\u00f3n <code>ID_ESTABLECIMIENTO_EDUCATIVO</code> <code>int</code> Identificador \u00fanico del establecimiento. <code>NOMBRE_ESTABLECIMIENTO</code> <code>nvarchar</code> Nombre del establecimiento. <code>DIRECCION</code> <code>nvarchar</code> Direcci\u00f3n del establecimiento. <code>COD_CIUDAD</code> <code>nvarchar</code> C\u00f3digo de la ciudad."},{"location":"01.scripts/03.Proteccion/#3-dim_programa","title":"3. DIM_PROGRAMA","text":"<p>Programas asociados a actividades de protecci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_PROGRAMA</code> <code>int</code> Identificador \u00fanico del programa. <code>PROGRAMA</code> <code>nvarchar</code> Nombre del programa."},{"location":"01.scripts/03.Proteccion/#4-dim_campos_caract","title":"4. DIM_CAMPOS_CARACT","text":"<p>Contiene las preguntas utilizadas en caracterizaciones.</p> Columna Tipo Descripci\u00f3n <code>ID_PREGUNTA</code> <code>int</code> Identificador \u00fanico de la pregunta. <code>PREGUNTA</code> <code>nvarchar</code> Texto de la pregunta. <code>OBSERVACIONES</code> <code>nvarchar</code> Observaciones relacionadas con la pregunta."},{"location":"01.scripts/03.Proteccion/#tablas-de-hechos","title":"Tablas de Hechos","text":""},{"location":"01.scripts/03.Proteccion/#1-fact_caracterizacion","title":"1. FACT_CARACTERIZACION","text":"<p>Registra las respuestas y observaciones relacionadas con la caracterizaci\u00f3n de la poblaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_CARACTERIZACION</code> <code>int</code> Identificador \u00fanico del registro de caracterizaci\u00f3n. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO</code>). <code>ID_POBLACION</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de poblaci\u00f3n. <code>ID_PROGRAMA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de programas. <code>RESPUESTA</code> <code>nvarchar</code> Respuesta de la caracterizaci\u00f3n."},{"location":"01.scripts/03.Proteccion/#2-fact_venta","title":"2. FACT_VENTA","text":"<p>Registro de ventas asociadas a servicios y poblaci\u00f3n.</p> Columna Tipo Descripci\u00f3n <code>ID_VENTA</code> <code>int</code> Identificador \u00fanico de la venta. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo (<code>DIM_TIEMPO</code>). <code>ID_POBLACION</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de poblaci\u00f3n. <code>ID_SERVICIO</code> <code>int</code> Relaci\u00f3n con servicios (<code>DIM_SERVICIOS</code>). <code>COSTO</code> <code>decimal</code> Costo asociado al servicio."},{"location":"01.scripts/03.Proteccion/#3-fact_desercion","title":"3. FACT_DESERCION","text":"<p>Registra casos de deserci\u00f3n en establecimientos educativos.</p> Columna Tipo Descripci\u00f3n <code>ID_REGISTRO</code> <code>int</code> Identificador \u00fanico del registro de deserci\u00f3n. <code>ID_ESTABLECIMIENTO_EDUCATIVO</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de establecimientos educativos. <code>ID_POBLACION</code> <code>int</code> Relaci\u00f3n con la poblaci\u00f3n. <code>ANIO_ACADEMICO</code> <code>nvarchar</code> A\u00f1o acad\u00e9mico de la deserci\u00f3n. <code>CAUSA</code> <code>nvarchar</code> Causa de la deserci\u00f3n."},{"location":"01.scripts/03.Proteccion/#relaciones-dimensionales-y-tablas-de-hechos","title":"Relaciones Dimensionales y Tablas de Hechos","text":""},{"location":"01.scripts/03.Proteccion/#diagrama-general-del-modelo","title":"Diagrama General del Modelo","text":"<pre><code>erDiagram\n    DIM_POBLACION {\n        int ID_POBLACION PK\n        nvarchar TIPO_DOCUMENTO\n        nvarchar DOCUMENTO\n    }\n\n    DIM_ESTABLECIMIENTO_EDUCATIVO {\n        int ID_ESTABLECIMIENTO_EDUCATIVO PK\n        nvarchar NOMBRE_ESTABLECIMIENTO\n    }\n\n    DIM_PROGRAMA {\n        int ID_PROGRAMA PK\n        nvarchar PROGRAMA\n    }\n\n    DIM_CAMPOS_CARACT {\n        int ID_PREGUNTA PK\n        nvarchar PREGUNTA\n    }\n\n    FACT_CARACTERIZACION {\n        int ID_CARACTERIZACION PK\n        int ID_POBLACION FK\n        int ID_PROGRAMA FK\n        int ID_FECHA FK\n    }\n\n    FACT_DESERCION {\n        int ID_REGISTRO PK\n        int ID_ESTABLECIMIENTO_EDUCATIVO FK\n        int ID_POBLACION FK\n        int ID_PROGRAMA FK\n    }\n\n    FACT_VENTA {\n        int ID_VENTA PK\n        int ID_POBLACION FK\n        int ID_SERVICIO FK\n        int ID_FECHA FK\n    }\n\n    DIM_POBLACION ||--o{ FACT_CARACTERIZACION : \"ID_POBLACION\"\n    DIM_PROGRAMA ||--o{ FACT_CARACTERIZACION : \"ID_PROGRAMA\"\n    DIM_ESTABLECIMIENTO_EDUCATIVO ||--o{ FACT_DESERCION : \"ID_ESTABLECIMIENTO_EDUCATIVO\"\n    DIM_POBLACION ||--o{ FACT_DESERCION : \"ID_POBLACION\"\n    DIM_PROGRAMA ||--o{ FACT_DESERCION : \"ID_PROGRAMA\"\n    DIM_POBLACION ||--o{ FACT_VENTA : \"ID_POBLACION\"\n    DIM_PROGRAMA ||--o{ FACT_VENTA : \"ID_SERVICIO\"</code></pre>"},{"location":"01.scripts/03.Proteccion/#buenas-practicas-implementadas","title":"Buenas Pr\u00e1cticas Implementadas","text":"<ol> <li> <p>Modularidad:</p> <ul> <li>Separaci\u00f3n clara entre datos descriptivos (<code>DIM</code>) y registros transaccionales (<code>FACT</code>).</li> </ul> </li> <li> <p>Integridad Referencial:</p> <ul> <li>Uso de claves for\u00e1neas para garantizar la consistencia entre las tablas.</li> </ul> </li> <li> <p>Escalabilidad:</p> <ul> <li>Permite la adici\u00f3n de nuevas dimensiones y hechos sin impactar la estructura existente.</li> </ul> </li> <li> <p>Eficiencia:</p> <ul> <li>\u00cdndices primarios y relaciones bien definidas para optimizar las consultas.</li> </ul> </li> </ol>"},{"location":"01.scripts/03.Proteccion/#conclusion","title":"Conclusi\u00f3n","text":"<p>El esquema <code>Protecci\u00f3n</code> es una soluci\u00f3n integral para gestionar datos relacionados con actividades de protecci\u00f3n y caracterizaci\u00f3n. Su dise\u00f1o facilita el an\u00e1lisis y la generaci\u00f3n de reportes, asegurando integridad y eficiencia en el almacenamiento y consulta de datos.</p>"},{"location":"01.scripts/04.Colegio/","title":"Documentaci\u00f3n SQL para el Esquema <code>Colegio</code>","text":""},{"location":"01.scripts/04.Colegio/#introduccion","title":"Introducci\u00f3n","text":"<p>El script SQL crea un modelo de datos en el esquema <code>Colegio</code> dentro del Data Warehouse <code>DWH_COMFENALCO</code>. Este modelo est\u00e1 dise\u00f1ado para gestionar informaci\u00f3n educativa, incluyendo datos sobre matr\u00edcula, planes curriculares, evaluaciones, ausencias, bibliotecas, y resultados acad\u00e9micos.</p>"},{"location":"01.scripts/04.Colegio/#proposito-del-script","title":"Prop\u00f3sito del Script","text":"<ol> <li> <p>Eliminaci\u00f3n de estructuras previas:</p> <ul> <li>Limpia el esquema <code>Colegio</code> eliminando tablas y claves for\u00e1neas existentes si ya est\u00e1n definidas.</li> </ul> </li> <li> <p>Creaci\u00f3n del esquema <code>Colegio</code>:</p> <ul> <li>Construcci\u00f3n de un modelo dimensional con tablas de hechos (<code>FACT</code>) y dimensiones (<code>DIM</code>) para representar datos educativos.</li> </ul> </li> <li> <p>Establecimiento de relaciones:</p> <ul> <li>Configuraci\u00f3n de claves for\u00e1neas para garantizar la integridad referencial y las conexiones l\u00f3gicas entre entidades.</li> </ul> </li> </ol>"},{"location":"01.scripts/04.Colegio/#estructura-del-modelo","title":"Estructura del Modelo","text":""},{"location":"01.scripts/04.Colegio/#tablas-dimensionales-dim","title":"Tablas Dimensionales (<code>DIM</code>)","text":""},{"location":"01.scripts/04.Colegio/#1-dim_anio_academico","title":"1. DIM_ANIO_ACADEMICO","text":"<p>Registra los a\u00f1os acad\u00e9micos.</p> Columna Tipo Descripci\u00f3n <code>ANIO_ACADEMICO</code> <code>numeric(4,0)</code> A\u00f1o acad\u00e9mico (ejemplo: 2024)."},{"location":"01.scripts/04.Colegio/#2-dim_plan_curricular","title":"2. DIM_PLAN_CURRICULAR","text":"<p>Define las asignaturas ofrecidas en un curso espec\u00edfico.</p> Columna Tipo Descripci\u00f3n <code>ID_ASIGNATURA</code> <code>int</code> Identificador \u00fanico de la asignatura. <code>ID_CURSO</code> <code>int</code> Relaci\u00f3n con el curso. <code>ANIO_ACADEMICO</code> <code>numeric(4,0)</code> A\u00f1o acad\u00e9mico. <code>ASIGNATURA</code> <code>nvarchar</code> Nombre de la asignatura."},{"location":"01.scripts/04.Colegio/#3-dim_libros","title":"3. DIM_LIBROS","text":"<p>Informaci\u00f3n sobre libros disponibles en la biblioteca.</p> Columna Tipo Descripci\u00f3n <code>ID_LIBRO</code> <code>int</code> Identificador \u00fanico del libro. <code>NOMBRE_LIBRO</code> <code>nvarchar</code> T\u00edtulo del libro. <code>AUTOR</code> <code>nvarchar</code> Autor del libro."},{"location":"01.scripts/04.Colegio/#tablas-de-hechos-fact","title":"Tablas de Hechos (<code>FACT</code>)","text":""},{"location":"01.scripts/04.Colegio/#1-fact_legalizacion","title":"1. FACT_LEGALIZACION","text":"<p>Almacena informaci\u00f3n sobre procesos de legalizaci\u00f3n de instituciones educativas.</p> Columna Tipo Descripci\u00f3n <code>ID_LEGALIZACION</code> <code>int</code> Identificador \u00fanico del registro. <code>ID_FECHA</code> <code>int</code> Relaci\u00f3n con la dimensi\u00f3n de tiempo. <code>RAZON_SOCIAL</code> <code>nvarchar</code> Raz\u00f3n social de la instituci\u00f3n educativa."},{"location":"01.scripts/04.Colegio/#2-fact_transporte","title":"2. FACT_TRANSPORTE","text":"<p>Gesti\u00f3n del uso del transporte escolar.</p> Columna Tipo Descripci\u00f3n <code>ID_REGISTRO</code> <code>int</code> Identificador \u00fanico del registro. <code>ID_POBLACION_MATRICULA</code> <code>int</code> Relaci\u00f3n con la poblaci\u00f3n matriculada. <code>ANIO_ACADEMICO</code> <code>numeric(4,0)</code> A\u00f1o acad\u00e9mico relacionado."},{"location":"01.scripts/04.Colegio/#3-fact_notas","title":"3. FACT_NOTAS","text":"<p>Registra las calificaciones de los estudiantes.</p> Columna Tipo Descripci\u00f3n <code>ID_NOTA</code> <code>int</code> Identificador \u00fanico de la nota. <code>ID_ASIGNATURA</code> <code>int</code> Relaci\u00f3n con la asignatura. <code>NOTA_FINAL</code> <code>decimal</code> Nota final obtenida por el estudiante."},{"location":"01.scripts/04.Colegio/#4-fact_biblioteca","title":"4. FACT_BIBLIOTECA","text":"<p>Registra pr\u00e9stamos de libros en la biblioteca.</p> Columna Tipo Descripci\u00f3n <code>ID_REGISTRO</code> <code>int</code> Identificador \u00fanico del registro. <code>ID_LIBRO</code> <code>int</code> Relaci\u00f3n con la tabla de libros. <code>FECHA_PRESTAMO</code> <code>datetime</code> Fecha en que se realiz\u00f3 el pr\u00e9stamo."},{"location":"01.scripts/04.Colegio/#relaciones-entre-tablas","title":"Relaciones entre Tablas","text":""},{"location":"01.scripts/04.Colegio/#diagrama-relacional","title":"Diagrama Relacional","text":"<pre><code>erDiagram\n    DIM_ANIO_ACADEMICO {\n        numeric ANIO_ACADEMICO PK\n    }\n\n    DIM_PLAN_CURRICULAR {\n        int ID_ASIGNATURA PK\n        int ID_CURSO FK\n        numeric ANIO_ACADEMICO FK\n    }\n\n    DIM_LIBROS {\n        int ID_LIBRO PK\n        nvarchar NOMBRE_LIBRO\n        nvarchar AUTOR\n    }\n\n    FACT_TRANSPORTE {\n        int ID_REGISTRO PK\n        int ID_POBLACION_MATRICULA FK\n        numeric ANIO_ACADEMICO FK\n    }\n\n    FACT_NOTAS {\n        int ID_NOTA PK\n        int ID_ASIGNATURA FK\n        decimal NOTA_FINAL\n    }\n\n    FACT_BIBLIOTECA {\n        int ID_REGISTRO PK\n        int ID_LIBRO FK\n        datetime FECHA_PRESTAMO\n    }\n\n    DIM_ANIO_ACADEMICO ||--o{ DIM_PLAN_CURRICULAR : AnioAcademico\n    DIM_PLAN_CURRICULAR ||--o{ FACT_NOTAS : Asignatura\n    DIM_LIBROS ||--o{ FACT_BIBLIOTECA : Libro</code></pre>"},{"location":"01.scripts/04.Colegio/#consideraciones-tecnicas","title":"Consideraciones T\u00e9cnicas","text":"<ol> <li> <p>Integridad Referencial:</p> <ul> <li>Uso de claves for\u00e1neas para relacionar hechos con dimensiones.</li> </ul> </li> <li> <p>Eficiencia:</p> <ul> <li>\u00cdndices primarios en todas las tablas para optimizar consultas.</li> </ul> </li> <li> <p>Escalabilidad:</p> <ul> <li>Modelo adaptable para incluir nuevas dimensiones y hechos.</li> </ul> </li> <li> <p>Separaci\u00f3n L\u00f3gica:</p> <ul> <li>Diferenciaci\u00f3n clara entre tablas de hechos y dimensiones para an\u00e1lisis OLAP.</li> </ul> </li> </ol>"},{"location":"01.scripts/04.Colegio/#conclusion","title":"Conclusi\u00f3n","text":"<p>El esquema <code>Colegio</code> proporciona una estructura robusta para almacenar y analizar datos relacionados con la gesti\u00f3n escolar, facilitando la generaci\u00f3n de reportes y an\u00e1lisis avanzados de rendimiento acad\u00e9mico, recursos educativos y actividades administrativas.</p>"},{"location":"01.scripts/05.Index/","title":"05.Index","text":""},{"location":"01.scripts/05.Index/#documentacion-sql-indices-para-el-esquema","title":"Documentaci\u00f3n SQL: \u00cdndices para el Esquema","text":""},{"location":"01.scripts/05.Index/#introduccion","title":"Introducci\u00f3n","text":"<p>Este script SQL define la creaci\u00f3n de \u00edndices no agrupados (<code>NONCLUSTERED</code>) para optimizar el rendimiento de las consultas en las tablas del esquema <code>Colegio</code> dentro del Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"01.scripts/05.Index/#proposito-de-los-indices","title":"Prop\u00f3sito de los \u00cdndices","text":"<ol> <li> <p>Optimizaci\u00f3n de consultas:    Aceleraci\u00f3n de operaciones <code>SELECT</code> en columnas com\u00fanmente filtradas o buscadas.</p> </li> <li> <p>Integridad y organizaci\u00f3n:    Facilitar accesos r\u00e1pidos a los datos relacionados con fechas, poblaci\u00f3n matriculada, personal, entre otros.</p> </li> <li> <p>Mejoras en rendimiento general:    Disminuci\u00f3n de tiempos de respuesta en consultas anal\u00edticas.</p> </li> </ol>"},{"location":"01.scripts/05.Index/#indices-definidos","title":"\u00cdndices Definidos","text":""},{"location":"01.scripts/05.Index/#indices-por-tabla","title":"\u00cdndices por Tabla","text":""},{"location":"01.scripts/05.Index/#1-dim_anio_academico","title":"1. <code>DIM_ANIO_ACADEMICO</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_DIM_ANIO_ACADEMICO_ANIO</code> <code>ANIO_ACADEMICO</code> \u00cdndice \u00fanico para identificar a\u00f1os acad\u00e9micos."},{"location":"01.scripts/05.Index/#2-dim_plan_curricular","title":"2. <code>DIM_PLAN_CURRICULAR</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_DIM_PLAN_CURRICULAR_CURSO</code> <code>ID_CURSO</code> Filtrado r\u00e1pido por curso relacionado. <code>IX_DIM_PLAN_CURRICULAR_ANIO</code> <code>ANIO_ACADEMICO</code> Optimiza las consultas por a\u00f1o acad\u00e9mico."},{"location":"01.scripts/05.Index/#3-dim_libros","title":"3. <code>DIM_LIBROS</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_DIM_LIBROS_NOMBRE</code> <code>NOMBRE_LIBRO</code> B\u00fasquedas r\u00e1pidas por el nombre del libro."},{"location":"01.scripts/05.Index/#4-fact_legalizacion","title":"4. <code>FACT_LEGALIZACION</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_LEGALIZACION_FECHA</code> <code>ID_FECHA</code> Filtrado r\u00e1pido por fechas de registro. <code>IX_FACT_LEGALIZACION_DOCUMENTO</code> <code>DOCUMENTO_DE_IDENTIDAD</code> Identificaci\u00f3n \u00e1gil por documento."},{"location":"01.scripts/05.Index/#5-fact_transporte","title":"5. <code>FACT_TRANSPORTE</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_TRANSPORTE_FECHA</code> <code>ID_FECHA</code> Optimiza las b\u00fasquedas por fecha. <code>IX_FACT_TRANSPORTE_POBLACION</code> <code>ID_POBLACION_MATRICULA</code> Filtrado r\u00e1pido por poblaci\u00f3n matriculada."},{"location":"01.scripts/05.Index/#6-fact_reserva_espacios","title":"6. <code>FACT_RESERVA_ESPACIOS</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_RESERVA_ESPACIOS_FECHA</code> <code>ID_FECHA</code> Consultas eficientes por fecha. <code>IX_FACT_RESERVA_ESPACIOS_PERSONAL</code> <code>ID_PERSONAL</code> B\u00fasquedas r\u00e1pidas por personal."},{"location":"01.scripts/05.Index/#7-fact_enfermeria","title":"7. <code>FACT_ENFERMERIA</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_ENFERMERIA_FECHA</code> <code>ID_FECHA</code> Consultas eficientes por fecha. <code>IX_FACT_ENFERMERIA_POBLACION</code> <code>ID_POBLACION_MATRICULA</code> Filtrado r\u00e1pido por poblaci\u00f3n matriculada."},{"location":"01.scripts/05.Index/#8-fact_psicorientacion","title":"8. <code>FACT_PSICORIENTACION</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_PSICORIENTACION_FECHA</code> <code>ID_FECHA</code> Consultas eficientes por fecha. <code>IX_FACT_PSICORIENTACION_POBLACION</code> <code>ID_POBLACION_MATRICULA</code> Filtrado r\u00e1pido por poblaci\u00f3n matriculada."},{"location":"01.scripts/05.Index/#9-fact_notas","title":"9. <code>FACT_NOTAS</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_NOTAS_FECHA</code> <code>ID_FECHA</code> Optimiza consultas por fecha. <code>IX_FACT_NOTAS_POBLACION</code> <code>ID_POBLACION_MATRICULA</code> Filtrado r\u00e1pido por poblaci\u00f3n matriculada."},{"location":"01.scripts/05.Index/#10-fact_biblioteca","title":"10. <code>FACT_BIBLIOTECA</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_BIBLIOTECA_LIBRO</code> <code>ID_LIBRO</code> Consultas r\u00e1pidas por libros prestados."},{"location":"01.scripts/05.Index/#11-fact_desempenho_docente","title":"11. <code>FACT_DESEMPENHO_DOCENTE</code>","text":"Nombre del \u00cdndice Columnas Descripci\u00f3n <code>IX_FACT_DESEMPENHO_DOCENTE_PERSONAL</code> <code>ID_PERSONAL</code> Filtrado eficiente por docentes evaluados."},{"location":"01.scripts/06.Index_Cedesarrollo/","title":"06.Index Cedesarrollo","text":""},{"location":"01.scripts/06.Index_Cedesarrollo/#indices-cedesarrollo","title":"Indices Cedesarrollo","text":""},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_estudiantes","title":"DIM_ESTUDIANTES","text":"<ol> <li> <p>\u00cdndice \u00fanico no cl\u00faster en el campo <code>DOCUMENTO</code>:    Garantiza consultas r\u00e1pidas y \u00fanicas basadas en el n\u00famero de documento, generalmente usado para identificar estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_EMPRESA</code>:    Optimiza consultas relacionadas con empresas asociadas a los estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_AFILIADO</code>:    Mejora la eficiencia de las b\u00fasquedas relacionadas con afiliados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_BENEFICIARIO</code>:    Facilita las consultas relacionadas con beneficiarios de estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_APORTANTE</code>:    Aumenta la velocidad de las consultas que usan el campo de aportantes no afiliados.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster en <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Se orienta a optimizar b\u00fasquedas que combinen ambos campos, usados frecuentemente como filtro conjunto.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li>Eficiencia en consultas frecuentes: Los \u00edndices en campos individuales (<code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, etc.) y combinados (<code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>) aceleran las operaciones de b\u00fasqueda y filtros.</li> <li>Evitar redundancias: Los \u00edndices se dise\u00f1an para no replicar informaci\u00f3n ya cubierta por \u00edndices primarios o claves for\u00e1neas.</li> <li>Mejorar la unicidad: El \u00edndice \u00fanico en <code>DOCUMENTO</code> asegura que este campo no contenga duplicados, previniendo inconsistencias.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice \u00fanico no cl\u00faster en el campo DOCUMENTO\nCREATE UNIQUE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_DOCUMENTO\nON Cedesarrollo.DIM_ESTUDIANTES (DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_EMPRESA\nON Cedesarrollo.DIM_ESTUDIANTES (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_AFILIADO\nON Cedesarrollo.DIM_ESTUDIANTES (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_BENEFICIARIO\nON Cedesarrollo.DIM_ESTUDIANTES (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_APORTANTE\nON Cedesarrollo.DIM_ESTUDIANTES (ID_APORTANTE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster en TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTUDIANTES_TIPO_DOCUMENTO_DOCUMENTO\nON Cedesarrollo.DIM_ESTUDIANTES (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_jornada","title":"DIM_JORNADA","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Optimiza las b\u00fasquedas y filtros relacionados con la unidad asociada a la jornada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>JORNADA</code>:    Facilita y acelera las consultas basadas en el nombre de la jornada, como b\u00fasquedas por texto.</p> </li> </ol> <p>**Justificaci\u00f3nDIM_JORNADA</p> <ul> <li><code>ID_UNIDAD</code>: Este campo es clave para unir esta tabla con otras que dependan de la identificaci\u00f3n de la unidad. Las b\u00fasquedas frecuentes en relaciones o filtros sobre unidades se beneficiar\u00e1n de este \u00edndice.</li> <li><code>JORNADA</code>: Usualmente, las consultas por nombre son comunes y al tratarse de un campo <code>nvarchar</code>, un \u00edndice espec\u00edfico mejora significativamente el rendimiento en b\u00fasquedas textuales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_JORNADA_ID_UNIDAD\nON Cedesarrollo.DIM_JORNADA (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo JORNADA\nCREATE NONCLUSTERED INDEX IX_DIM_JORNADA_NOMBRE\nON Cedesarrollo.DIM_JORNADA (JORNADA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_periodo_academico","title":"DIM_PERIODO_ACADEMICO","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Mejora el rendimiento de consultas relacionadas con las unidades asociadas a los per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>PERIODO_ACADEMICO</code>:    Optimiza b\u00fasquedas y filtros basados en el nombre o descripci\u00f3n del per\u00edodo acad\u00e9mico.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Dise\u00f1ado para acelerar consultas relacionadas con rangos de fechas, como per\u00edodos activos o hist\u00f3ricos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>: Este campo es clave en las relaciones con la tabla [DIM_UNIDAD]. Un \u00edndice en esta columna agiliza consultas de uni\u00f3n o b\u00fasquedas relacionadas.</li> <li><code>PERIODO_ACADEMICO</code>: Al tratarse de un campo descriptivo, puede usarse com\u00fanmente en filtros por texto, por lo que un \u00edndice acelera estas b\u00fasquedas.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Al ser campos utilizados frecuentemente para filtrar per\u00edodos dentro de un rango de tiempo, el \u00edndice compuesto asegura eficiencia en este tipo de consultas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_PERIODO_ACADEMICO_ID_UNIDAD\nON Cedesarrollo.DIM_PERIODO_ACADEMICO (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PERIODO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_DIM_PERIODO_ACADEMICO_NOMBRE\nON Cedesarrollo.DIM_PERIODO_ACADEMICO (PERIODO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_DIM_PERIODO_ACADEMICO_FECHAS\nON Cedesarrollo.DIM_PERIODO_ACADEMICO (FECHA_INICIO, FECHA_FIN);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_plan_curricular","title":"DIM_PLAN_CURRICULAR","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Mejora las consultas y uniones relacionadas con los programas a los que pertenece cada m\u00f3dulo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MODULO</code>:    Optimiza las b\u00fasquedas de m\u00f3dulos espec\u00edficos por su nombre o descripci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Facilita la recuperaci\u00f3n de datos agrupados o filtrados por semestre.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>INTENSIDAD_HORARIA</code> y <code>INTENSIDAD_HORARIA_SEMANAL</code>:    Acelera las consultas que involucren filtros o an\u00e1lisis relacionados con las intensidades horarias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PROGRAMA</code>: Este campo es clave en la relaci\u00f3n con [DIM_PROGRAMA] y es com\u00fanmente utilizado en uniones o filtros.</li> <li><code>MODULO</code>: Al ser descriptivo, es probable que se utilice para b\u00fasquedas directas o comparativas.</li> <li><code>SEMESTRE</code>: Las consultas que involucren planes curriculares por semestre se beneficiar\u00e1n del \u00edndice en este campo.</li> <li><code>INTENSIDAD_HORARIA</code> y <code>INTENSIDAD_HORARIA_SEMANAL</code>: Un \u00edndice compuesto en estos campos es \u00fatil para an\u00e1lisis o filtros relacionados con la carga horaria de los m\u00f3dulos.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_ID_PROGRAMA\nON Cedesarrollo.DIM_PLAN_CURRICULAR (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MODULO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_MODULO\nON Cedesarrollo.DIM_PLAN_CURRICULAR (MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_SEMESTRE\nON Cedesarrollo.DIM_PLAN_CURRICULAR (SEMESTRE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos INTENSIDAD_HORARIA y INTENSIDAD_HORARIA_SEMANAL\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_INTENSIDADES\nON Cedesarrollo.DIM_PLAN_CURRICULAR (INTENSIDAD_HORARIA, INTENSIDAD_HORARIA_SEMANAL);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_preguntas_cotizacion","title":"DIM_PREGUNTAS_COTIZACION","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>PREGUNTA</code>:    Facilita b\u00fasquedas y filtros basados en el texto de las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>OBSERVACIONES</code>:    Optimiza consultas que necesiten filtrar o analizar observaciones relacionadas con las preguntas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>PREGUNTA</code>: Este campo, al ser descriptivo, es probable que se utilice en consultas textuales para b\u00fasquedas directas o parciales de preguntas.</li> <li><code>OBSERVACIONES</code>: Aunque menos com\u00fan, este campo puede ser relevante en an\u00e1lisis que requieran obtener detalles adicionales relacionados con las preguntas, como comentarios o especificaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_COTIZACION_PREGUNTA\nON Cedesarrollo.DIM_PREGUNTAS_COTIZACION (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_COTIZACION_OBSERVACIONES\nON Cedesarrollo.DIM_PREGUNTAS_COTIZACION (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#dim_programa","title":"DIM_PROGRAMA","text":"<ol> <li>\u00cdndice no cl\u00faster para el campo <code>PROGRAMA</code>:    Optimiza las b\u00fasquedas y filtros basados en el nombre o descripci\u00f3n del programa.</li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>PROGRAMA</code>: Al ser un campo descriptivo, es utilizado frecuentemente en b\u00fasquedas textuales o filtros para identificar programas espec\u00edficos.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PROGRAMA_NOMBRE\nON Cedesarrollo.DIM_PROGRAMA (PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_asistencia_act_bienestar","title":"FACT_ASISTENCIA_ACT_BIENESTAR","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza las consultas que involucren filtros o uniones basadas en fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora el rendimiento en consultas relacionadas con la asistencia de estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Dise\u00f1ado para b\u00fasquedas y filtros que combinen ambos campos como identificadores \u00fanicos del estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ACTIVIDAD</code>:    Facilita consultas y filtros basados en actividades espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ASISTIO</code>:    \u00datil para consultas relacionadas con el registro de asistencia.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>, <code>ID_ESTUDIANTE</code>, <code>ID_PERIODO</code>: Estos campos est\u00e1n com\u00fanmente relacionados con uniones y filtros en tablas de dimensi\u00f3n, optimizando las consultas frecuentes.</li> <li><code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>: Este \u00edndice compuesto permite b\u00fasquedas r\u00e1pidas utilizando estos identificadores \u00fanicos de los estudiantes.</li> <li><code>ACTIVIDAD</code> y <code>ASISTIO</code>: Estos \u00edndices optimizan an\u00e1lisis relacionados con las actividades y asistencia registrada en las mismas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ID_FECHA\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ID_ESTUDIANTE\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ID_PERIODO\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_TIPO_DOCUMENTO_DOCUMENTO\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ACTIVIDAD\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ACTIVIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ASISTIO\nCREATE NONCLUSTERED INDEX IX_FACT_ASISTENCIA_ACT_BIENESTAR_ASISTIO\nON Cedesarrollo.FACT_ASISTENCIA_ACT_BIENESTAR (ASISTIO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_ausentismo_docente","title":"FACT_AUSENTISMO_DOCENTE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora la eficiencia de las consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con el personal docente afectado por ausentismo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Dise\u00f1ado para mejorar el rendimiento en b\u00fasquedas por rangos de fechas relacionadas con ausencias.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO_AUSENCIA</code>:    Facilita consultas y an\u00e1lisis basados en el tipo de ausencia registrada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MOTIVO_AUSENCIA</code>:    Acelera consultas relacionadas con los motivos espec\u00edficos de las ausencias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_PERSONAL</code>, <code>ID_FECHA</code>: Estos campos son claves en uniones con tablas de dimensi\u00f3n y filtros comunes.</li> <li><code>FECHA_INICIO</code>, <code>FECHA_FIN</code>: Un \u00edndice compuesto en estos campos es crucial para b\u00fasquedas por rangos de fechas de ausencias.</li> <li><code>TIPO_AUSENCIA</code> y <code>MOTIVO_AUSENCIA</code>: Estos campos son \u00fatiles en an\u00e1lisis descriptivos o consultas sobre ausencias espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_PERIODO\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_PERSONAL\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_FECHA\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_FECHAS\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_TIPO_AUSENCIA\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (TIPO_AUSENCIA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_MOTIVO_AUSENCIA\nON Cedesarrollo.FACT_AUSENTISMO_DOCENTE (MOTIVO_AUSENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_cotizaciones","title":"FACT_COTIZACIONES","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza las consultas basadas en fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Dise\u00f1ado para b\u00fasquedas r\u00e1pidas de cotizaciones basadas en la identificaci\u00f3n del estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora la eficiencia de consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_SERVICIO</code>:    Acelera consultas relacionadas con servicios espec\u00edficos asociados a las cotizaciones.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PREGUNTA</code>:    Facilita las b\u00fasquedas y an\u00e1lisis de cotizaciones basados en preguntas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO_COTIZACION</code>:    Mejora consultas relacionadas con los estados de las cotizaciones.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Campo clave en consultas basadas en tiempo y filtros por fechas.</li> <li><code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>: La identificaci\u00f3n compuesta de los estudiantes permite b\u00fasquedas precisas y r\u00e1pidas.</li> <li><code>ID_ESTUDIANTE</code>: Es esencial para relaciones y filtros basados en estudiantes espec\u00edficos.</li> <li><code>ID_SERVICIO</code>: Las consultas sobre servicios ofrecidos est\u00e1n directamente optimizadas con este \u00edndice.</li> <li><code>ID_PREGUNTA</code>: Facilita an\u00e1lisis espec\u00edficos relacionados con preguntas asociadas a cotizaciones.</li> <li><code>ESTADO_COTIZACION</code>: \u00datil para analizar y filtrar cotizaciones por sus estados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_FECHA\nON Cedesarrollo.FACT_COTIZACIONES (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_TIPO_DOCUMENTO_DOCUMENTO\nON Cedesarrollo.FACT_COTIZACIONES (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_ESTUDIANTE\nON Cedesarrollo.FACT_COTIZACIONES (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_SERVICIO\nON Cedesarrollo.FACT_COTIZACIONES (ID_SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ID_PREGUNTA\nON Cedesarrollo.FACT_COTIZACIONES (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO_COTIZACION\nCREATE NONCLUSTERED INDEX IX_FACT_COTIZACIONES_ESTADO_COTIZACION\nON Cedesarrollo.FACT_COTIZACIONES (ESTADO_COTIZACION);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_desempenho_docente_ce","title":"FACT_DESEMPENHO_DOCENTE_CE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Mejora la eficiencia de consultas relacionadas con las unidades acad\u00e9micas asociadas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Optimiza las consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>CALIFICACION_ESTUDIANTES</code>, <code>CALIFICACION_UNIDAD</code> y <code>CALIFICACION_DOCENTE</code>:    Mejora el rendimiento en an\u00e1lisis relacionados con las calificaciones en los diferentes niveles.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO_CONTRATACION</code>:    Facilita las consultas basadas en el tipo de contrataci\u00f3n del personal docente.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>, <code>ID_PERSONAL</code>, <code>ID_PERIODO</code>: Estos campos son clave en uniones y filtros comunes en consultas relacionadas con dimensiones acad\u00e9micas y personal docente.</li> <li><code>CALIFICACION_ESTUDIANTES</code>, <code>CALIFICACION_UNIDAD</code>, <code>CALIFICACION_DOCENTE</code>: Este \u00edndice compuesto agiliza consultas anal\u00edticas y comparativas de calificaciones en diferentes categor\u00edas.</li> <li><code>TIPO_CONTRATACION</code>: \u00datil para an\u00e1lisis espec\u00edficos o filtros relacionados con las modalidades de contrataci\u00f3n.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_ID_UNIDAD\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_ID_PERSONAL\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_ID_PERIODO\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CALIFICACION_ESTUDIANTES, CALIFICACION_UNIDAD y CALIFICACION_DOCENTE\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_CALIFICACIONES\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (CALIFICACION_ESTUDIANTES, CALIFICACION_UNIDAD, CALIFICACION_DOCENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_CONTRATACION\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_CE_TIPO_CONTRATACION\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_CE (TIPO_CONTRATACION);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_desempenho_docente_de","title":"FACT_DESEMPENHO_DOCENTE_DE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Optimiza consultas relacionadas con las unidades acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Mejora b\u00fasquedas relacionadas con el desempe\u00f1o de docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>:    Optimiza b\u00fasquedas que combinen ambos campos para identificar encuestados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora el rendimiento en consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>PROGRAMA</code>:    Facilita b\u00fasquedas y an\u00e1lisis basados en programas acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CALIFICACION</code>:    Acelera consultas relacionadas con el an\u00e1lisis de calificaciones.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>, <code>ID_PERSONAL</code>, <code>ID_PERIODO</code>: Son claves en consultas relacionadas con las dimensiones acad\u00e9micas y personal docente.</li> <li><code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>: Un \u00edndice compuesto asegura b\u00fasquedas r\u00e1pidas y precisas de encuestados.</li> <li><code>ID_FECHA</code>: Este \u00edndice es esencial para optimizar consultas relacionadas con tiempo y filtros por fechas.</li> <li><code>PROGRAMA</code> y <code>CALIFICACION</code>: Estos \u00edndices mejoran el an\u00e1lisis y filtrado por programas y desempe\u00f1o en las evaluaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_UNIDAD\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_PERSONAL\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_PERIODO\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO_ENCUESTADO y DOCUMENTO_ENCUESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_DOCUMENTO_ENCUESTADO\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (TIPO_DOCUMENTO_ENCUESTADO, DOCUMENTO_ENCUESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_ID_FECHA\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_PROGRAMA\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_DE_CALIFICACION\nON Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE (CALIFICACION);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_desercion","title":"FACT_DESERCION","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera consultas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Optimiza el rendimiento en consultas basadas en fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO</code>:    Facilita consultas y an\u00e1lisis relacionados con el tipo de deserci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CAUSA</code>:    Acelera b\u00fasquedas relacionadas con las causas de deserci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Mejora consultas relacionadas con los semestres afectados por la deserci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_JORNADA</code>, <code>ID_ESTUDIANTE</code>, <code>ID_FECHA</code>: Estos campos son claves en consultas comunes relacionadas con per\u00edodos, jornadas, estudiantes y fechas.</li> <li><code>TIPO</code> y <code>CAUSA</code>: Son fundamentales para an\u00e1lisis descriptivos y consultas relacionadas con categor\u00edas de deserci\u00f3n.</li> <li><code>SEMESTRE</code>: Optimiza consultas espec\u00edficas sobre semestres impactados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_PERIODO\nON Cedesarrollo.FACT_DESERCION (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_JORNADA\nON Cedesarrollo.FACT_DESERCION (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_ESTUDIANTE\nON Cedesarrollo.FACT_DESERCION (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_FECHA\nON Cedesarrollo.FACT_DESERCION (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_TIPO\nON Cedesarrollo.FACT_DESERCION (TIPO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CAUSA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_CAUSA\nON Cedesarrollo.FACT_DESERCION (CAUSA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_SEMESTRE\nON Cedesarrollo.FACT_DESERCION (SEMESTRE);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_estado_matriculas","title":"FACT_ESTADO_MATRICULAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora consultas relacionadas con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Optimiza las b\u00fasquedas relacionadas con programas acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera consultas basadas en jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Facilita b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora el rendimiento en consultas relacionadas con fechas de matr\u00edcula.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TELEFONO</code>, <code>CELULAR</code> y <code>CORREO</code>:    Acelera b\u00fasquedas o filtros relacionados con informaci\u00f3n de contacto.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Facilita consultas basadas en el semestre acad\u00e9mico.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>DOCUMENTOS_COMPLETOS</code>:    Mejora b\u00fasquedas relacionadas con el estado de documentaci\u00f3n de los estudiantes.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_PROGRAMA</code>, <code>ID_JORNADA</code>, <code>ID_ESTUDIANTE</code>, <code>ID_FECHA</code>: Campos clave para uniones y filtros en consultas frecuentes relacionadas con dimensiones acad\u00e9micas y estudiantes.</li> <li><code>TELEFONO</code>, <code>CELULAR</code>, <code>CORREO</code>: Facilitan an\u00e1lisis y consultas basadas en datos de contacto de los estudiantes.</li> <li><code>SEMESTRE</code> y <code>DOCUMENTOS_COMPLETOS</code>: Optimizan an\u00e1lisis espec\u00edficos de estado y organizaci\u00f3n acad\u00e9mica.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_PERIODO\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_PROGRAMA\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_JORNADA\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_ID_FECHA\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TELEFONO, CELULAR y CORREO\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_CONTACTO\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (TELEFONO, CELULAR, CORREO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_SEMESTRE\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (SEMESTRE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTOS_COMPLETOS\nCREATE NONCLUSTERED INDEX IX_FACT_ESTADO_MATRICULAS_DOCUMENTOS_COMPLETOS\nON Cedesarrollo.FACT_ESTADO_MATRICULAS (DOCUMENTOS_COMPLETOS);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_evaluacion_formacion","title":"FACT_EVALUACION_FORMACION","text":"<ol> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>:    Mejora la eficiencia de b\u00fasquedas basadas en la identificaci\u00f3n del encuestado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_SERVICIO</code>:    Acelera consultas relacionadas con servicios espec\u00edficos evaluados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>FECHA_REALIZACION_EVENTO</code>:    Optimiza consultas basadas en la fecha de realizaci\u00f3n de los eventos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>ASPECTO_1</code> a <code>ASPECTO_9</code>:    Facilita an\u00e1lisis y b\u00fasquedas relacionadas con las evaluaciones de m\u00faltiples aspectos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>TIPO_DOCUMENTO_ENCUESTADO</code> y <code>DOCUMENTO_ENCUESTADO</code>: Permiten identificar de manera eficiente al encuestado en consultas combinadas.</li> <li><code>ID_SERVICIO</code>: Es clave para filtrar o analizar evaluaciones basadas en servicios espec\u00edficos.</li> <li><code>FECHA_REALIZACION_EVENTO</code>: Facilita consultas relacionadas con el an\u00e1lisis temporal de las evaluaciones.</li> <li><code>ASPECTO_1</code> a <code>ASPECTO_9</code>: Estos campos son cr\u00edticos para an\u00e1lisis descriptivos y de calidad en evaluaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO_ENCUESTADO y DOCUMENTO_ENCUESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_DOCUMENTO_ENCUESTADO\nON Cedesarrollo.FACT_EVALUACION_FORMACION (TIPO_DOCUMENTO_ENCUESTADO, DOCUMENTO_ENCUESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_ID_SERVICIO\nON Cedesarrollo.FACT_EVALUACION_FORMACION (ID_SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_REALIZACION_EVENTO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_FECHA_REALIZACION_EVENTO\nON Cedesarrollo.FACT_EVALUACION_FORMACION (FECHA_REALIZACION_EVENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ASPECTO_1 a ASPECTO_9\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_FORMACION_ASPECTOS\nON Cedesarrollo.FACT_EVALUACION_FORMACION (ASPECTO_1, ASPECTO_2, ASPECTO_3, ASPECTO_4, ASPECTO_5, ASPECTO_6, ASPECTO_7, ASPECTO_8, ASPECTO_9);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_evaluacion_plan_curricular","title":"FACT_EVALUACION_PLAN_CURRICULAR","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>:    Optimiza consultas relacionadas con unidades acad\u00e9micas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera b\u00fasquedas y an\u00e1lisis relacionados con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CALIFICACION</code>:    Mejora el rendimiento en consultas basadas en las calificaciones asignadas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>OBSERVACIONES</code>:    Facilita b\u00fasquedas relacionadas con comentarios o notas adicionales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_UNIDAD</code>: Este \u00edndice es esencial para optimizar consultas relacionadas con la evaluaci\u00f3n de unidades acad\u00e9micas espec\u00edficas.</li> <li><code>ID_PERIODO</code>: Clave en an\u00e1lisis temporales y filtros basados en per\u00edodos acad\u00e9micos.</li> <li><code>CALIFICACION</code>: Facilita consultas relacionadas con m\u00e9tricas de desempe\u00f1o o an\u00e1lisis de resultados.</li> <li><code>OBSERVACIONES</code>: \u00datil para b\u00fasquedas y an\u00e1lisis de comentarios asociados con las evaluaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_ID_UNIDAD\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_ID_PERIODO\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_CALIFICACION\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (CALIFICACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_FACT_EVALUACION_PLAN_CURRICULAR_OBSERVACIONES\nON Cedesarrollo.FACT_EVALUACION_PLAN_CURRICULAR (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_facturacion","title":"FACT_FACTURACION","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO_PAGO</code> y <code>DOCUMENTO_PAGO</code>:    Acelera b\u00fasquedas relacionadas con las identificaciones de los pagadores.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora consultas basadas en fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_SERVICIO</code>:    Facilita an\u00e1lisis relacionados con servicios facturados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_CONCEPTO</code>:    Optimiza consultas basadas en conceptos espec\u00edficos de facturaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO_PAGO</code>:    Mejora consultas relacionadas con el estado de los pagos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>NO_RECIBO</code>:    Facilita b\u00fasquedas espec\u00edficas por n\u00famero de recibo.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_FECHA</code>: Estos \u00edndices son esenciales para optimizar an\u00e1lisis temporales y b\u00fasquedas relacionadas con per\u00edodos y fechas espec\u00edficas.</li> <li><code>TIPO_DOCUMENTO_PAGO</code>, <code>DOCUMENTO_PAGO</code>: Permiten identificar de manera eficiente a los pagadores.</li> <li><code>ID_SERVICIO</code>, <code>ID_CONCEPTO</code>: Facilitan consultas espec\u00edficas sobre servicios y conceptos facturados.</li> <li><code>ESTADO_PAGO</code>, <code>NO_RECIBO</code>: Son claves para b\u00fasquedas relacionadas con el seguimiento de pagos y recibos.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_PERIODO\nON Cedesarrollo.FACT_FACTURACION (ID_PERIODO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO_PAGO y DOCUMENTO_PAGO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_DOCUMENTO_PAGO\nON Cedesarrollo.FACT_FACTURACION (TIPO_DOCUMENTO_PAGO, DOCUMENTO_PAGO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_FECHA\nON Cedesarrollo.FACT_FACTURACION (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_SERVICIO\nON Cedesarrollo.FACT_FACTURACION (ID_SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CONCEPTO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ID_CONCEPTO\nON Cedesarrollo.FACT_FACTURACION (ID_CONCEPTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO_PAGO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_ESTADO_PAGO\nON Cedesarrollo.FACT_FACTURACION (ESTADO_PAGO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NO_RECIBO\nCREATE NONCLUSTERED INDEX IX_FACT_FACTURACION_NO_RECIBO\nON Cedesarrollo.FACT_FACTURACION (NO_RECIBO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_graduados","title":"FACT_GRADUADOS","text":"<ol> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Optimiza b\u00fasquedas relacionadas con la identificaci\u00f3n de los graduados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Facilita b\u00fasquedas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Optimiza consultas basadas en programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>FECHA_GRADUADO</code>:    Mejora el rendimiento de consultas basadas en la fecha de graduaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO</code>:    Facilita an\u00e1lisis relacionados con el estado de los graduados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ZONA</code>:    Acelera b\u00fasquedas relacionadas con la zona geogr\u00e1fica de los graduados.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ID_ESTUDIANTE</code>: Claves esenciales para identificar y consultar informaci\u00f3n espec\u00edfica de los graduados.</li> <li><code>ID_PERIODO</code>, <code>ID_JORNADA</code>, <code>ID_PROGRAMA</code>: Estos \u00edndices optimizan consultas relacionadas con dimensiones acad\u00e9micas clave.</li> <li><code>FECHA_GRADUADO</code>: Facilita el an\u00e1lisis temporal de las graduaciones.</li> <li><code>ESTADO</code>, <code>ZONA</code>: Estos \u00edndices son \u00fatiles para an\u00e1lisis geogr\u00e1ficos y de estado del graduado.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_DOCUMENTO\nON Cedesarrollo.FACT_GRADUADOS (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_GRADUADOS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_PERIODO\nON Cedesarrollo.FACT_GRADUADOS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_JORNADA\nON Cedesarrollo.FACT_GRADUADOS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ID_PROGRAMA\nON Cedesarrollo.FACT_GRADUADOS (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_GRADUADO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_FECHA_GRADUADO\nON Cedesarrollo.FACT_GRADUADOS (FECHA_GRADUADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ESTADO\nON Cedesarrollo.FACT_GRADUADOS (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ZONA\nCREATE NONCLUSTERED INDEX IX_FACT_GRADUADOS_ZONA\nON Cedesarrollo.FACT_GRADUADOS (ZONA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_horario","title":"FACT_HORARIO","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora el rendimiento en consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_MODULO</code>:    Optimiza consultas relacionadas con m\u00f3dulos espec\u00edficos del plan curricular.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera b\u00fasquedas basadas en jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Facilita consultas relacionadas con docentes asignados al horario.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SEMESTRE</code>:    Optimiza an\u00e1lisis relacionados con horarios organizados por semestre.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>DIA</code>:    Mejora consultas relacionadas con horarios organizados por d\u00edas espec\u00edficos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>HORA_INICIO</code> y <code>HORA_FIN</code>:    Facilita an\u00e1lisis y consultas basadas en intervalos horarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>COD_ESTABLECIMIENTO</code>:    Acelera b\u00fasquedas espec\u00edficas por c\u00f3digo de establecimiento.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_MODULO</code>, <code>ID_JORNADA</code>, <code>ID_PERSONAL</code>: Estos campos son claves para optimizar consultas relacionadas con dimensiones acad\u00e9micas y personal.</li> <li><code>SEMESTRE</code>, <code>DIA</code>: Facilitan el an\u00e1lisis de horarios basados en organizaci\u00f3n acad\u00e9mica y d\u00edas espec\u00edficos.</li> <li><code>HORA_INICIO</code>, <code>HORA_FIN</code>: Un \u00edndice compuesto en estos campos mejora an\u00e1lisis de intervalos horarios.</li> <li><code>COD_ESTABLECIMIENTO</code>: Este \u00edndice permite b\u00fasquedas eficientes en consultas relacionadas con ubicaciones espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_PERIODO\nON Cedesarrollo.FACT_HORARIO (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_MODULO\nON Cedesarrollo.FACT_HORARIO (ID_MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_JORNADA\nON Cedesarrollo.FACT_HORARIO (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_ID_PERSONAL\nON Cedesarrollo.FACT_HORARIO (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SEMESTRE\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_SEMESTRE\nON Cedesarrollo.FACT_HORARIO (SEMESTRE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DIA\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_DIA\nON Cedesarrollo.FACT_HORARIO (DIA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos HORA_INICIO y HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_HORAS\nON Cedesarrollo.FACT_HORARIO (HORA_INICIO, HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_ESTABLECIMIENTO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_COD_ESTABLECIMIENTO\nON Cedesarrollo.FACT_HORARIO (COD_ESTABLECIMIENTO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_inasistencias","title":"FACT_INASISTENCIAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Optimiza consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Acelera b\u00fasquedas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>DOCUMENTO</code>:    Facilita b\u00fasquedas basadas en la identificaci\u00f3n del estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Mejora el rendimiento en consultas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_MODULO</code>:    Optimiza b\u00fasquedas relacionadas con m\u00f3dulos espec\u00edficos del plan curricular.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Mejora el rendimiento en consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>CURSO</code> y <code>CORTE</code>:    Facilita an\u00e1lisis y b\u00fasquedas relacionadas con cursos y cortes acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TOTAL_INASISTENCIA</code>:    Optimiza an\u00e1lisis basados en la cantidad total de inasistencias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTUDIANTE</code>, <code>DOCUMENTO</code>, <code>ID_PERIODO</code>: Claves principales para identificar estudiantes y sus per\u00edodos relacionados con inasistencias.</li> <li><code>ID_JORNADA</code>, <code>ID_MODULO</code>, <code>ID_FECHA</code>: Campos clave para consultas relacionadas con dimensiones acad\u00e9micas y temporales.</li> <li><code>CURSO</code>, <code>CORTE</code>: Un \u00edndice compuesto facilita b\u00fasquedas organizadas por estructura acad\u00e9mica.</li> <li><code>TOTAL_INASISTENCIA</code>: Es clave para an\u00e1lisis y m\u00e9tricas sobre inasistencias totales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_INASISTENCIAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_PERIODO\nON Cedesarrollo.FACT_INASISTENCIAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_DOCUMENTO\nON Cedesarrollo.FACT_INASISTENCIAS (DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_JORNADA\nON Cedesarrollo.FACT_INASISTENCIAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_MODULO\nON Cedesarrollo.FACT_INASISTENCIAS (ID_MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_ID_FECHA\nON Cedesarrollo.FACT_INASISTENCIAS (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CURSO y CORTE\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_CURSO_CORTE\nON Cedesarrollo.FACT_INASISTENCIAS (CURSO, CORTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TOTAL_INASISTENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_INASISTENCIAS_TOTAL_INASISTENCIA\nON Cedesarrollo.FACT_INASISTENCIAS (TOTAL_INASISTENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_inscripcion_matriculas","title":"FACT_INSCRIPCION_MATRICULAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora el rendimiento en consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>:    Optimiza b\u00fasquedas relacionadas con programas acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>:    Facilita an\u00e1lisis y b\u00fasquedas basadas en fechas de inscripci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Mejora consultas relacionadas con jornadas acad\u00e9micas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Acelera b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ESTADO</code>:    Facilita an\u00e1lisis y b\u00fasquedas relacionadas con el estado de las inscripciones.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>TIPO_ESTUDIANTE</code>:    Mejora el rendimiento de consultas basadas en las categor\u00edas de tipo de estudiante.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>CATEGORIA_COBERTURA</code> y <code>CATEGORIA_SUBSIDIO</code>:    Optimiza an\u00e1lisis y b\u00fasquedas relacionadas con la cobertura y subsidios.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_PROGRAMA</code>, <code>ID_FECHA</code>, <code>ID_JORNADA</code>, <code>ID_ESTUDIANTE</code>: Estos \u00edndices son claves para optimizar consultas frecuentes relacionadas con dimensiones acad\u00e9micas y temporales.</li> <li><code>ESTADO</code>, <code>TIPO_ESTUDIANTE</code>: Facilitan an\u00e1lisis descriptivos y filtros en el estado y tipo de estudiante inscrito.</li> <li><code>CATEGORIA_COBERTURA</code>, <code>CATEGORIA_SUBSIDIO</code>: Un \u00edndice compuesto mejora an\u00e1lisis detallados relacionados con subsidios y coberturas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_PERIODO\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_PROGRAMA\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_FECHA\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_JORNADA\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_ESTADO\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_TIPO_ESTUDIANTE\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (TIPO_ESTUDIANTE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CATEGORIA_COBERTURA y CATEGORIA_SUBSIDIO\nCREATE NONCLUSTERED INDEX IX_FACT_INSCRIPCION_MATRICULAS_CATEGORIAS\nON Cedesarrollo.FACT_INSCRIPCION_MATRICULAS (CATEGORIA_COBERTURA, CATEGORIA_SUBSIDIO);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_notas","title":"FACT_NOTAS","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>:    Mejora consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_JORNADA</code>:    Acelera b\u00fasquedas relacionadas con jornadas acad\u00e9micas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_MODULO</code>:    Optimiza consultas relacionadas con m\u00f3dulos del plan curricular.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>:    Mejora el rendimiento en consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERSONAL</code>:    Facilita an\u00e1lisis relacionados con docentes asignados a los cursos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Optimiza b\u00fasquedas basadas en intervalos temporales para analizar notas en per\u00edodos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>NOTA_FINAL</code>:    Mejora consultas relacionadas con an\u00e1lisis de desempe\u00f1o acad\u00e9mico.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>PRIMER_CORTE</code>, <code>SEGUNDO_CORTE</code> y <code>TERCER_CORTE</code>:    Facilita an\u00e1lisis detallados de las notas por cortes acad\u00e9micos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTUDIANTE</code>, <code>ID_JORNADA</code>, <code>ID_MODULO</code>, <code>ID_PERIODO</code>, <code>ID_PERSONAL</code>: Claves esenciales para optimizar consultas frecuentes relacionadas con dimensiones acad\u00e9micas y estudiantes.</li> <li><code>FECHA_INICIO</code>, <code>FECHA_FIN</code>: Cruciales para an\u00e1lisis temporales y segmentaci\u00f3n de notas.</li> <li><code>NOTA_FINAL</code>: Facilita an\u00e1lisis de resultados globales de los estudiantes.</li> <li><code>PRIMER_CORTE</code>, <code>SEGUNDO_CORTE</code>, <code>TERCER_CORTE</code>: Un \u00edndice compuesto mejora el an\u00e1lisis de desempe\u00f1o por cortes.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_ESTUDIANTE\nON Cedesarrollo.FACT_NOTAS (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_JORNADA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_JORNADA\nON Cedesarrollo.FACT_NOTAS (ID_JORNADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_MODULO\nON Cedesarrollo.FACT_NOTAS (ID_MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_PERIODO\nON Cedesarrollo.FACT_NOTAS (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_PERSONAL\nON Cedesarrollo.FACT_NOTAS (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_FECHAS\nON Cedesarrollo.FACT_NOTAS (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOTA_FINAL\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_NOTA_FINAL\nON Cedesarrollo.FACT_NOTAS (NOTA_FINAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_CORTE, SEGUNDO_CORTE y TERCER_CORTE\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_CORTES\nON Cedesarrollo.FACT_NOTAS (PRIMER_CORTE, SEGUNDO_CORTE, TERCER_CORTE);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_permiso_estudiante","title":"FACT_PERMISO_ESTUDIANTE","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_ESTUDIANTE</code>    Facilita las consultas y filtros relacionados con permisos de estudiantes espec\u00edficos, as\u00ed como uniones con la tabla de dimensiones [DIM_ESTUDIANTES].</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>    Optimiza el rendimiento en consultas que agrupan o filtran los datos por per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_FECHA</code>    Mejora el acceso a los registros relacionados con fechas espec\u00edficas, especialmente en an\u00e1lisis cronol\u00f3gicos o uniones con la tabla de dimensi\u00f3n [DIM_TIEMPO].</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MODULO</code>    Acelera las consultas que necesitan identificar m\u00f3dulos asociados con los permisos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MOTIVO_AUSENCIA</code>    Facilita el an\u00e1lisis y b\u00fasqueda de registros basados en las razones de ausencia.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>SOPORTE_AUSENCIA</code>    Optimiza las b\u00fasquedas relacionadas con documentos o justificaciones de las ausencias.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTUDIANTE</code>: Usualmente, las consultas incluyen uniones con la tabla de estudiantes o filtros para permisos espec\u00edficos de un estudiante.</li> <li><code>ID_PERIODO</code>: Este campo es clave para an\u00e1lisis por per\u00edodos acad\u00e9micos o tendencias relacionadas con ausencias en un per\u00edodo.</li> <li><code>ID_FECHA</code>: Al ser un campo relacionado con fechas, permite optimizar consultas que buscan patrones temporales o filtros de rangos.</li> <li><code>MODULO</code>: Las ausencias pueden ser analizadas en relaci\u00f3n con m\u00f3dulos espec\u00edficos, haciendo relevante este \u00edndice.</li> <li><code>MOTIVO_AUSENCIA</code>: Es \u00fatil para an\u00e1lisis descriptivos o categorizaci\u00f3n de razones de ausencias.</li> <li><code>SOPORTE_AUSENCIA</code>: Permite identificar r\u00e1pidamente los registros asociados con un tipo espec\u00edfico de soporte.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_ESTUDIANTE\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_ESTUDIANTE\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (ID_ESTUDIANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_PERIODO\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_FECHA\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MODULO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_MODULO\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (MODULO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_MOTIVO_AUSENCIA\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (MOTIVO_AUSENCIA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SOPORTE_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_SOPORTE_AUSENCIA\nON Cedesarrollo.FACT_PERMISO_ESTUDIANTE (SOPORTE_AUSENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/06.Index_Cedesarrollo/#fact_plan_cobertura","title":"FACT_PLAN_COBERTURA","text":"<ol> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PERIODO</code>    Optimiza consultas y an\u00e1lisis relacionados con per\u00edodos acad\u00e9micos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_UNIDAD</code>    Mejora el rendimiento de las consultas asociadas a las unidades que forman parte del plan de cobertura.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ID_PROGRAMA</code>    Facilita las b\u00fasquedas y uniones relacionadas con programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>MODALIDAD</code>    Acelera consultas que involucren an\u00e1lisis o filtrados por modalidades del plan.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CATEGORIA</code>    Optimiza b\u00fasquedas y agrupaciones relacionadas con categor\u00edas espec\u00edficas dentro del plan.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para los campos <code>USOS_PROYECTADOS</code> y <code>USUARIOS_PROYECTADOS</code>    Mejora el rendimiento de las consultas y an\u00e1lisis basados en las proyecciones de uso y usuarios.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERIODO</code>: Es clave en las relaciones con per\u00edodos acad\u00e9micos y permite optimizar consultas agrupadas o filtradas por per\u00edodos.</li> <li><code>ID_UNIDAD</code>: Asociado a las unidades del plan, es crucial para consultas sobre cobertura por unidad.</li> <li><code>ID_PROGRAMA</code>: Facilita las consultas relacionadas con los programas que componen el plan.</li> <li><code>MODALIDAD</code> y <code>CATEGORIA</code>: Campos descriptivos frecuentemente usados en filtros y an\u00e1lisis de agrupaci\u00f3n.</li> <li><code>USOS_PROYECTADOS</code> y <code>USUARIOS_PROYECTADOS</code>: Los \u00edndices compuestos en estos campos son \u00fatiles para an\u00e1lisis combinados de las proyecciones de uso y usuarios.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_PERIODO\nON Cedesarrollo.FACT_PLAN_COBERTURA (ID_PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_UNIDAD\nON Cedesarrollo.FACT_PLAN_COBERTURA (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_PROGRAMA\nON Cedesarrollo.FACT_PLAN_COBERTURA (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MODALIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_MODALIDAD\nON Cedesarrollo.FACT_PLAN_COBERTURA (MODALIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_CATEGORIA\nON Cedesarrollo.FACT_PLAN_COBERTURA (CATEGORIA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos USOS_PROYECTADOS y USUARIOS_PROYECTADOS\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_PROYECCIONES\nON Cedesarrollo.FACT_PLAN_COBERTURA (USOS_PROYECTADOS, USUARIOS_PROYECTADOS);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/","title":"07.Index Colegio","text":""},{"location":"01.scripts/07.Index_Colegio/#indices-colegio","title":"\u00cdndices Colegio","text":""},{"location":"01.scripts/07.Index_Colegio/#dim_anio_academico","title":"DIM_ANIO_ACADEMICO","text":"<ol> <li>\u00cdndice cl\u00faster existente para <code>ANIO_ACADEMICO</code> (PRIMARY KEY):    Este \u00edndice asegura acceso eficiente y ordenado mediante el identificador \u00fanico de cada a\u00f1o acad\u00e9mico.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ANIO_ACADEMICO\n-- (No requiere creaci\u00f3n adicional)\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_curso","title":"DIM_CURSO","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CURSO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de cada curso.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DESC_CURSO</code>:    Facilita b\u00fasquedas relacionadas con descripciones de cursos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>:    Optimiza consultas relacionadas con el estado de los cursos y su fecha de creaci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CURSO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>DESC_CURSO</code>: Mejora el rendimiento en b\u00fasquedas textuales.</li> <li><code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>: Mejora an\u00e1lisis combinados por estado y fecha.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CURSO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DESC_CURSO\nCREATE NONCLUSTERED INDEX IX_DIM_CURSO_DESC_CURSO\nON [Colegio].[DIM_CURSO] (DESC_CURSO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para ESTADO_REGISTRO y FECHA_CREACION\nCREATE NONCLUSTERED INDEX IX_DIM_CURSO_ESTADO_FECHA\nON [Colegio].[DIM_CURSO] (ESTADO_REGISTRO, FECHA_CREACION);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_grado","title":"DIM_GRADO","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_GRADO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DESC_GRADO</code>:    Facilita b\u00fasquedas relacionadas con descripciones de grados.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>:    Optimiza consultas combinadas por estado y fecha.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_GRADO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>DESC_GRADO</code>: Mejora el rendimiento en b\u00fasquedas textuales.</li> <li><code>ESTADO_REGISTRO</code> y <code>FECHA_CREACION</code>: Mejora an\u00e1lisis combinados por estado y fecha.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_GRADO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DESC_GRADO\nCREATE NONCLUSTERED INDEX IX_DIM_GRADO_DESC_GRADO\nON [Colegio].[DIM_GRADO] (DESC_GRADO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para ESTADO_REGISTRO y FECHA_CREACION\nCREATE NONCLUSTERED INDEX IX_DIM_GRADO_ESTADO_FECHA\nON [Colegio].[DIM_GRADO] (ESTADO_REGISTRO, FECHA_CREACION);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_libros","title":"DIM_LIBROS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_LIBRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_LIBRO</code>:    Mejora b\u00fasquedas relacionadas con el nombre del libro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>AUTOR</code>:    Optimiza consultas relacionadas con autores.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>NOMBRE_LIBRO</code> y <code>AUTOR</code>:    Mejora b\u00fasquedas combinadas por nombre y autor.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_LIBRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>NOMBRE_LIBRO</code>: Mejora b\u00fasquedas textuales relacionadas con los libros.</li> <li><code>AUTOR</code>: Optimiza b\u00fasquedas textuales relacionadas con autores.</li> <li><code>NOMBRE_LIBRO</code> y <code>AUTOR</code>: Mejora an\u00e1lisis combinados por nombre y autor.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_LIBRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_LIBRO\nCREATE NONCLUSTERED INDEX IX_DIM_LIBROS_NOMBRE_LIBRO\nON [Colegio].[DIM_LIBROS] (NOMBRE_LIBRO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo AUTOR\nCREATE NONCLUSTERED INDEX IX_DIM_LIBROS_AUTOR\nON [Colegio].[DIM_LIBROS] (AUTOR);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para NOMBRE_LIBRO y AUTOR\nCREATE NONCLUSTERED INDEX IX_DIM_LIBROS_NOMBRE_AUTOR\nON [Colegio].[DIM_LIBROS] (NOMBRE_LIBRO, AUTOR);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_plan_curricular","title":"DIM_PLAN_CURRICULAR","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_ASIGNATURA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de las asignaturas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Optimiza b\u00fasquedas relacionadas con cursos y uniones con la tabla [DIM_CURSO].</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos y uniones con la tabla [DIM_ANIO_ACADEMICO].</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PERIODO</code> y <code>GRADO</code>:    Facilita an\u00e1lisis combinados por per\u00edodo y grado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>INTENSIDAD_HORARIA</code>:    Mejora consultas relacionadas con la intensidad horaria de las asignaturas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ASIGNATURA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_CURSO</code>: Optimiza consultas relacionadas con los cursos.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en consultas por a\u00f1os acad\u00e9micos.</li> <li><code>PERIODO</code> y <code>GRADO</code>: Facilita an\u00e1lisis combinados relacionados con per\u00edodos y grados.</li> <li><code>INTENSIDAD_HORARIA</code>: Acelera b\u00fasquedas relacionadas con este atributo.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_ASIGNATURA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_ID_CURSO\nON [Colegio].[DIM_PLAN_CURRICULAR] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_ANIO_ACADEMICO\nON [Colegio].[DIM_PLAN_CURRICULAR] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para PERIODO y GRADO\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_PERIODO_GRADO\nON [Colegio].[DIM_PLAN_CURRICULAR] (PERIODO, GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo INTENSIDAD_HORARIA\nCREATE NONCLUSTERED INDEX IX_DIM_PLAN_CURRICULAR_INTENSIDAD\nON [Colegio].[DIM_PLAN_CURRICULAR] (INTENSIDAD_HORARIA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#dim_poblacion_matricula","title":"DIM_POBLACION_MATRICULA","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_POBLACION_MATRICULA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de la poblaci\u00f3n matriculada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PARTNER</code>:    Optimiza b\u00fasquedas relacionadas con socios o identificadores externos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code>:    Mejora b\u00fasquedas relacionadas con documentos de identificaci\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>GENERO</code> y <code>FECHA_NACIMIENTO</code>:    Facilita an\u00e1lisis demogr\u00e1ficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code>:    Mejora consultas relacionadas con direcciones de correo electr\u00f3nico.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_POBLACION_MATRICULA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>PARTNER</code>: Mejora b\u00fasquedas relacionadas con identificadores externos.</li> <li><code>DOCUMENTO</code>: Optimiza consultas relacionadas con identificadores \u00fanicos de estudiantes.</li> <li><code>GENERO</code> y <code>FECHA_NACIMIENTO</code>: Facilita an\u00e1lisis demogr\u00e1ficos y de grupos etarios.</li> <li><code>CORREO</code>: Acelera b\u00fasquedas relacionadas con direcciones de correo.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_POBLACION_MATRICULA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PARTNER\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_PARTNER\nON [Colegio].[DIM_POBLACION_MATRICULA] (PARTNER);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_DOCUMENTO\nON [Colegio].[DIM_POBLACION_MATRICULA] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para GENERO y FECHA_NACIMIENTO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_GENERO_FECHA\nON [Colegio].[DIM_POBLACION_MATRICULA] (GENERO, FECHA_NACIMIENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_MATRICULA_CORREO\nON [Colegio].[DIM_POBLACION_MATRICULA] (CORREO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_ausentismo_docente","title":"FACT_AUSENTISMO_DOCENTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_AUSENTISMO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado a trav\u00e9s del identificador \u00fanico de cada registro de ausentismo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Mejora consultas relacionadas con docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza b\u00fasquedas por a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Mejora consultas relacionadas con per\u00edodos de ausencia.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_AUSENCIA</code>:    Acelera b\u00fasquedas relacionadas con tipos espec\u00edficos de ausencia.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_AUSENTISMO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_PERSONAL</code>: Facilita b\u00fasquedas por docente.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_FECHA</code>: Optimiza consultas espec\u00edficas por fechas.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Facilita an\u00e1lisis por rangos de fechas.</li> <li><code>TIPO_AUSENCIA</code>: Mejora b\u00fasquedas categ\u00f3ricas por tipo de ausencia.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_AUSENTISMO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_PERSONAL\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ANIO_ACADEMICO\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_ID_FECHA\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_FECHAS\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_AUSENCIA\nCREATE NONCLUSTERED INDEX IX_FACT_AUSENTISMO_DOCENTE_TIPO_AUSENCIA\nON [Colegio].[FACT_AUSENTISMO_DOCENTE] (TIPO_AUSENCIA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_biblioteca","title":"FACT_BIBLIOTECA","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de biblioteca.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Mejora consultas relacionadas con personal asociado a registros de biblioteca.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_LIBRO</code>:    Facilita b\u00fasquedas relacionadas con libros espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza consultas por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_PRESTAMO</code>, <code>FECHA_VENCIMIENTO</code> y <code>FECHA_ENTREGA</code>:    Mejora an\u00e1lisis relacionados con el ciclo de pr\u00e9stamo de libros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>BIBLIOTECA</code>:    Mejora consultas relacionadas con nombres de bibliotecas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Optimiza uniones y consultas relacionadas con estudiantes.</li> <li><code>ID_PERSONAL</code>: Mejora b\u00fasquedas por personal responsable.</li> <li><code>ID_LIBRO</code>: Facilita consultas relacionadas con libros espec\u00edficos.</li> <li><code>ID_FECHA</code>: Acelera an\u00e1lisis por fechas.</li> <li><code>FECHA_PRESTAMO</code>, <code>FECHA_VENCIMIENTO</code> y <code>FECHA_ENTREGA</code>: Mejora rendimiento en an\u00e1lisis temporales de pr\u00e9stamos.</li> <li><code>BIBLIOTECA</code>: Acelera b\u00fasquedas categ\u00f3ricas por nombre de biblioteca.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_POBLACION\nON [Colegio].[FACT_BIBLIOTECA] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_PERSONAL\nON [Colegio].[FACT_BIBLIOTECA] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_LIBRO\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_LIBRO\nON [Colegio].[FACT_BIBLIOTECA] (ID_LIBRO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_ID_FECHA\nON [Colegio].[FACT_BIBLIOTECA] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_PRESTAMO, FECHA_VENCIMIENTO y FECHA_ENTREGA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_FECHAS\nON [Colegio].[FACT_BIBLIOTECA] (FECHA_PRESTAMO, FECHA_VENCIMIENTO, FECHA_ENTREGA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo BIBLIOTECA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_BIBLIOTECA\nON [Colegio].[FACT_BIBLIOTECA] (BIBLIOTECA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_biblioteca_virtual","title":"FACT_BIBLIOTECA_VIRTUAL","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de biblioteca virtual.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Mejora consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Optimiza b\u00fasquedas relacionadas con personal asociado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Optimiza consultas relacionadas con per\u00edodos de uso de la biblioteca virtual.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ACTIVIDAD</code>:    Mejora b\u00fasquedas relacionadas con actividades espec\u00edficas realizadas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita uniones con la dimensi\u00f3n de poblaci\u00f3n matriculada.</li> <li><code>ID_PERSONAL</code>: Mejora b\u00fasquedas relacionadas con personal responsable.</li> <li><code>ID_FECHA</code>: Acelera consultas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Facilita an\u00e1lisis temporales sobre per\u00edodos de uso.</li> <li><code>ACTIVIDAD</code>: Optimiza b\u00fasquedas relacionadas con actividades espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ID_POBLACION\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ID_PERSONAL\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ID_FECHA\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ANIO_ACADEMICO\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_FECHAS\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_BIBLIOTECA_VIRTUAL_ACTIVIDAD\nON [Colegio].[FACT_BIBLIOTECA_VIRTUAL] (ACTIVIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_desempenho_docente","title":"FACT_DESEMPENHO_DOCENTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de desempe\u00f1o docente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Optimiza b\u00fasquedas relacionadas con docentes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>ID_PERSONAL</code>:    Mejora b\u00fasquedas combinadas por fecha y docente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TOTAL_GENERAL</code>:    Optimiza consultas relacionadas con calificaciones totales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_PERSONAL</code>: Facilita b\u00fasquedas por docente.</li> <li><code>ANIO_ACADEMICO</code>: Mejora rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_FECHA</code>: Acelera an\u00e1lisis por fechas espec\u00edficas.</li> <li><code>FECHA</code> y <code>ID_PERSONAL</code>: Mejora an\u00e1lisis combinados por fecha y docente.</li> <li><code>TOTAL_GENERAL</code>: Optimiza b\u00fasquedas relacionadas con el desempe\u00f1o total.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_ID_PERSONAL\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_ANIO_ACADEMICO\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_ID_FECHA\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_FECHA_PERSONAL\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (FECHA, ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TOTAL_GENERAL\nCREATE NONCLUSTERED INDEX IX_FACT_DESEMPENHO_DOCENTE_TOTAL_GENERAL\nON [Colegio].[FACT_DESEMPENHO_DOCENTE] (TOTAL_GENERAL);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_enfermeria","title":"FACT_ENFERMERIA","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CASO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada caso de enfermer\u00eda.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Facilita an\u00e1lisis por fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>:    Optimiza b\u00fasquedas relacionadas con los rangos temporales de los casos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO</code>:    Acelera b\u00fasquedas relacionadas con estados espec\u00edficos del caso.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CAUSA_ACCIDENTE</code>:    Mejora consultas relacionadas con las causas de accidentes reportados.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CASO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita uniones y b\u00fasquedas relacionadas con estudiantes.</li> <li><code>ID_FECHA</code>: Mejora el rendimiento en an\u00e1lisis por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Optimiza b\u00fasquedas por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>: Acelera an\u00e1lisis relacionados con los per\u00edodos de atenci\u00f3n y soluci\u00f3n.</li> <li><code>ESTADO</code>: Facilita b\u00fasquedas por estado del caso.</li> <li><code>CAUSA_ACCIDENTE</code>: Mejora el rendimiento en an\u00e1lisis de causas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CASO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ID_POBLACION\nON [Colegio].[FACT_ENFERMERIA] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ID_FECHA\nON [Colegio].[FACT_ENFERMERIA] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ANIO_ACADEMICO\nON [Colegio].[FACT_ENFERMERIA] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_ATENCION y FECHA_SOLUCION\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_FECHAS\nON [Colegio].[FACT_ENFERMERIA] (FECHA_ATENCION, FECHA_SOLUCION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_ESTADO\nON [Colegio].[FACT_ENFERMERIA] (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CAUSA_ACCIDENTE\nCREATE NONCLUSTERED INDEX IX_FACT_ENFERMERIA_CAUSA_ACCIDENTE\nON [Colegio].[FACT_ENFERMERIA] (CAUSA_ACCIDENTE);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_horario_grupos","title":"FACT_HORARIO_GRUPOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_HORARIO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de horario de grupos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Optimiza b\u00fasquedas relacionadas con grados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Facilita consultas relacionadas con cursos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SALON</code>:    Mejora b\u00fasquedas relacionadas con salones.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>HORA_INICIO</code> y <code>HORA_FIN</code>:    Acelera b\u00fasquedas relacionadas con intervalos horarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Optimiza b\u00fasquedas relacionadas con docentes.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>NUMERO_DIA</code> y <code>BLOQUE_HORARIO</code>:    Mejora an\u00e1lisis relacionados con d\u00edas y bloques horarios.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_HORARIO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ANIO_ACADEMICO</code>: Facilita b\u00fasquedas y an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_GRADO</code>: Mejora consultas relacionadas con grados.</li> <li><code>ID_CURSO</code>: Acelera b\u00fasquedas espec\u00edficas por cursos.</li> <li><code>ID_SALON</code>: Mejora el rendimiento en consultas relacionadas con salones.</li> <li><code>HORA_INICIO</code> y <code>HORA_FIN</code>: Facilita an\u00e1lisis de horarios.</li> <li><code>ID_PERSONAL</code>: Optimiza consultas relacionadas con docentes espec\u00edficos.</li> <li><code>NUMERO_DIA</code> y <code>BLOQUE_HORARIO</code>: Mejora b\u00fasquedas relacionadas con d\u00edas espec\u00edficos y bloques horarios.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_HORARIO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ANIO_ACADEMICO\nON [Colegio].[FACT_HORARIO_GRUPOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_GRADO\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_CURSO\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SALON\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_SALON\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_SALON);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para HORA_INICIO y HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_HORAS\nON [Colegio].[FACT_HORARIO_GRUPOS] (HORA_INICIO, HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_ID_PERSONAL\nON [Colegio].[FACT_HORARIO_GRUPOS] (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para NUMERO_DIA y BLOQUE_HORARIO\nCREATE NONCLUSTERED INDEX IX_FACT_HORARIO_GRUPOS_BLOQUE_DIA\nON [Colegio].[FACT_HORARIO_GRUPOS] (NUMERO_DIA, BLOQUE_HORARIO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_legalizacion","title":"FACT_LEGALIZACION","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_LEGALIZACION</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de legalizaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO_DE_IDENTIDAD</code>:    Facilita b\u00fasquedas relacionadas con identificadores legales.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RAZON_SOCIAL</code>:    Optimiza b\u00fasquedas relacionadas con razones sociales espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>CODIGO_DANE</code>:    Acelera consultas relacionadas con fechas y c\u00f3digos institucionales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_LEGALIZACION</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_FECHA</code>: Facilita an\u00e1lisis por fechas.</li> <li><code>DOCUMENTO_DE_IDENTIDAD</code>: Mejora b\u00fasquedas relacionadas con identificaci\u00f3n de personas o instituciones.</li> <li><code>RAZON_SOCIAL</code>: Optimiza b\u00fasquedas por razones sociales.</li> <li><code>FECHA</code> y <code>CODIGO_DANE</code>: Mejora consultas combinadas relacionadas con fechas y c\u00f3digos institucionales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_LEGALIZACION\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_ID_FECHA\nON [Colegio].[FACT_LEGALIZACION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO_DE_IDENTIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_DOCUMENTO\nON [Colegio].[FACT_LEGALIZACION] (DOCUMENTO_DE_IDENTIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RAZON_SOCIAL\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_RAZON_SOCIAL\nON [Colegio].[FACT_LEGALIZACION] (RAZON_SOCIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y CODIGO_DANE\nCREATE NONCLUSTERED INDEX IX_FACT_LEGALIZACION_FECHA_DANE\nON [Colegio].[FACT_LEGALIZACION] (FECHA, CODIGO_DANE);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_notas","title":"FACT_NOTAS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_NOTA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada nota registrada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Facilita an\u00e1lisis por estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Mejora b\u00fasquedas relacionadas con cursos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Optimiza consultas relacionadas con grados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ASIGNATURA</code>:    Mejora b\u00fasquedas relacionadas con asignaturas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_LOGRO</code>:    Facilita consultas relacionadas con logros acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PERIODO</code> y <code>NOTA_FINAL</code>:    Acelera b\u00fasquedas relacionadas con per\u00edodos y calificaciones finales.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_NOTA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_FECHA</code>: Mejora b\u00fasquedas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita consultas agrupadas por a\u00f1os acad\u00e9micos.</li> <li><code>ID_POBLACION_MATRICULA</code>: Optimiza an\u00e1lisis relacionados con estudiantes.</li> <li><code>ID_CURSO</code>: Mejora el rendimiento de b\u00fasquedas por cursos.</li> <li><code>ID_GRADO</code>: Acelera b\u00fasquedas relacionadas con grados.</li> <li><code>ID_ASIGNATURA</code>: Facilita consultas por asignaturas espec\u00edficas.</li> <li><code>ID_LOGRO</code>: Mejora b\u00fasquedas relacionadas con logros.</li> <li><code>PERIODO</code> y <code>NOTA_FINAL</code>: Optimiza consultas de an\u00e1lisis por per\u00edodo y resultados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_NOTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_FECHA\nON [Colegio].[FACT_NOTAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ANIO_ACADEMICO\nON [Colegio].[FACT_NOTAS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_POBLACION\nON [Colegio].[FACT_NOTAS] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_CURSO\nON [Colegio].[FACT_NOTAS] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_GRADO\nON [Colegio].[FACT_NOTAS] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ASIGNATURA\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_ASIGNATURA\nON [Colegio].[FACT_NOTAS] (ID_ASIGNATURA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_LOGRO\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_ID_LOGRO\nON [Colegio].[FACT_NOTAS] (ID_LOGRO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para PERIODO y NOTA_FINAL\nCREATE NONCLUSTERED INDEX IX_FACT_NOTAS_PERIODO_NOTA\nON [Colegio].[FACT_NOTAS] (PERIODO, NOTA_FINAL);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_permiso_estudiante","title":"FACT_PERMISO_ESTUDIANTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PERMISO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada permiso de estudiante.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Mejora b\u00fasquedas relacionadas con grados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Facilita an\u00e1lisis por cursos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza b\u00fasquedas por a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>HORA</code>:    Acelera b\u00fasquedas relacionadas con registros de permisos en momentos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO_ACUDIENTE</code>:    Mejora consultas relacionadas con documentos de acudientes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>MOTIVO_SALIDA</code>:    Facilita b\u00fasquedas relacionadas con motivos de salida.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PERMISO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora el rendimiento en b\u00fasquedas relacionadas con estudiantes.</li> <li><code>ID_GRADO</code>: Optimiza b\u00fasquedas relacionadas con grados espec\u00edficos.</li> <li><code>ID_CURSO</code>: Facilita consultas por cursos.</li> <li><code>ID_FECHA</code>: Acelera b\u00fasquedas relacionadas con fechas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA</code> y <code>HORA</code>: Mejora consultas relacionadas con horarios de permisos.</li> <li><code>DOCUMENTO_ACUDIENTE</code>: Optimiza b\u00fasquedas relacionadas con acudientes.</li> <li><code>MOTIVO_SALIDA</code>: Acelera b\u00fasquedas por motivos de salida.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PERMISO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_POBLACION\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_GRADO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_CURSO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ID_FECHA\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_ANIO_ACADEMICO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y HORA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_FECHA_HORA\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (FECHA, HORA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO_ACUDIENTE\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_DOCUMENTO_ACUDIENTE\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (DOCUMENTO_ACUDIENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_SALIDA\nCREATE NONCLUSTERED INDEX IX_FACT_PERMISO_ESTUDIANTE_MOTIVO\nON [Colegio].[FACT_PERMISO_ESTUDIANTE] (MOTIVO_SALIDA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_psicorientacion","title":"FACT_PSICORIENTACION","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CASO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada caso de psicorientaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Facilita b\u00fasquedas agrupadas por a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>:    Acelera an\u00e1lisis relacionados con per\u00edodos de atenci\u00f3n y soluci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO</code>:    Mejora b\u00fasquedas relacionadas con estados espec\u00edficos del caso.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>MOTIVO_ATENCION</code>:    Facilita b\u00fasquedas relacionadas con motivos de atenci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CASO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita uniones y consultas relacionadas con estudiantes.</li> <li><code>ID_FECHA</code>: Optimiza b\u00fasquedas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>FECHA_ATENCION</code> y <code>FECHA_SOLUCION</code>: Acelera consultas relacionadas con per\u00edodos temporales.</li> <li><code>ESTADO</code>: Facilita an\u00e1lisis y filtros relacionados con estados de los casos.</li> <li><code>MOTIVO_ATENCION</code>: Mejora b\u00fasquedas relacionadas con motivos espec\u00edficos de atenci\u00f3n.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CASO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ID_POBLACION\nON [Colegio].[FACT_PSICORIENTACION] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ID_FECHA\nON [Colegio].[FACT_PSICORIENTACION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ANIO_ACADEMICO\nON [Colegio].[FACT_PSICORIENTACION] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_ATENCION y FECHA_SOLUCION\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_FECHAS\nON [Colegio].[FACT_PSICORIENTACION] (FECHA_ATENCION, FECHA_SOLUCION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_ESTADO\nON [Colegio].[FACT_PSICORIENTACION] (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo MOTIVO_ATENCION\nCREATE NONCLUSTERED INDEX IX_FACT_PSICORIENTACION_MOTIVO\nON [Colegio].[FACT_PSICORIENTACION] (MOTIVO_ATENCION);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_reemplazo_docente","title":"FACT_REEMPLAZO_DOCENTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REEMPLAZO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de reemplazo docente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL_AUSENTE</code>:    Mejora b\u00fasquedas relacionadas con docentes ausentes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL_REEMPLAZA</code>:    Optimiza b\u00fasquedas relacionadas con docentes reemplazantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Acelera consultas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Facilita b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_GRADO</code> y <code>ID_CURSO</code>:    Mejora consultas relacionadas con grados y cursos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>BLOQUE_HORARIO</code>:    Optimiza an\u00e1lisis relacionados con fechas y bloques horarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCENTE_AUSENTE</code>:    Facilita b\u00fasquedas relacionadas con nombres de docentes ausentes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCENTE_REEMPLAZA</code>:    Mejora b\u00fasquedas relacionadas con nombres de docentes que reemplazan.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REEMPLAZO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_PERSONAL_AUSENTE</code>: Facilita an\u00e1lisis por docentes ausentes.</li> <li><code>ID_PERSONAL_REEMPLAZA</code>: Mejora b\u00fasquedas relacionadas con reemplazos.</li> <li><code>ID_FECHA</code>: Acelera b\u00fasquedas relacionadas con fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora el rendimiento en an\u00e1lisis por a\u00f1os acad\u00e9micos.</li> <li><code>ID_GRADO</code> y <code>ID_CURSO</code>: Optimiza consultas combinadas relacionadas con grados y cursos.</li> <li><code>FECHA</code> y <code>BLOQUE_HORARIO</code>: Facilita an\u00e1lisis de bloques horarios por fechas espec\u00edficas.</li> <li><code>DOCENTE_AUSENTE</code>: Acelera b\u00fasquedas relacionadas con los nombres de docentes ausentes.</li> <li><code>DOCENTE_REEMPLAZA</code>: Mejora consultas relacionadas con docentes que reemplazan.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REEMPLAZO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL_AUSENTE\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_PERSONAL_AUSENTE\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_PERSONAL_AUSENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL_REEMPLAZA\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_PERSONAL_REEMPLAZA\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_PERSONAL_REEMPLAZA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_ID_FECHA\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_ANIO_ACADEMICO\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para ID_GRADO y ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_GRADO_CURSO\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (ID_GRADO, ID_CURSO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y BLOQUE_HORARIO\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_FECHA_BLOQUE\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (FECHA, BLOQUE_HORARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCENTE_AUSENTE\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_DOCENTE_AUSENTE\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (DOCENTE_AUSENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCENTE_REEMPLAZA\nCREATE NONCLUSTERED INDEX IX_FACT_REEMPLAZO_DOCENTE_DOCENTE_REEMPLAZA\nON [Colegio].[FACT_REEMPLAZO_DOCENTE] (DOCENTE_REEMPLAZA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_reserva_espacios","title":"FACT_RESERVA_ESPACIOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESERVA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro de reserva.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_SOLICITUD</code> y <code>FECHA_RESERVA</code>:    Facilita an\u00e1lisis relacionados con el tiempo de solicitud y la reserva.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RECURSO_RESERVA</code>:    Mejora b\u00fasquedas relacionadas con recursos espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con los responsables de la reserva.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>HORA_INICIO</code> y <code>HORA_FIN</code>:    Optimiza consultas relacionadas con intervalos de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO_DOCENTE</code>:    Facilita an\u00e1lisis por correos electr\u00f3nicos de los docentes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ACTIVIDAD_PLANEADA</code>:    Mejora b\u00fasquedas relacionadas con actividades espec\u00edficas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESERVA</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_FECHA</code>: Mejora el rendimiento de b\u00fasquedas relacionadas con fechas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita consultas relacionadas con agrupaciones por a\u00f1os.</li> <li><code>FECHA_SOLICITUD</code> y <code>FECHA_RESERVA</code>: Optimiza el an\u00e1lisis de tiempos entre solicitud y ejecuci\u00f3n.</li> <li><code>RECURSO_RESERVA</code>: Mejora b\u00fasquedas relacionadas con recursos espec\u00edficos.</li> <li><code>ID_PERSONAL</code>: Acelera consultas relacionadas con responsables de la reserva.</li> <li><code>HORA_INICIO</code> y <code>HORA_FIN</code>: Facilita an\u00e1lisis relacionados con horarios espec\u00edficos.</li> <li><code>CORREO_DOCENTE</code>: Optimiza b\u00fasquedas por docentes en funci\u00f3n de sus correos electr\u00f3nicos.</li> <li><code>ACTIVIDAD_PLANEADA</code>: Mejora consultas relacionadas con actividades registradas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESERVA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ID_FECHA\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ANIO_ACADEMICO\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_SOLICITUD y FECHA_RESERVA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_FECHAS\nON [Colegio].[FACT_RESERVA_ESPACIOS] (FECHA_SOLICITUD, FECHA_RESERVA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RECURSO_RESERVA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_RECURSO\nON [Colegio].[FACT_RESERVA_ESPACIOS] (RECURSO_RESERVA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ID_PERSONAL\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para HORA_INICIO y HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_HORAS\nON [Colegio].[FACT_RESERVA_ESPACIOS] (HORA_INICIO, HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO_DOCENTE\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_CORREO\nON [Colegio].[FACT_RESERVA_ESPACIOS] (CORREO_DOCENTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD_PLANEADA\nCREATE NONCLUSTERED INDEX IX_FACT_RESERVA_ESPACIOS_ACTIVIDAD\nON [Colegio].[FACT_RESERVA_ESPACIOS] (ACTIVIDAD_PLANEADA);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_resultados","title":"FACT_RESULTADOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESULTADO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada resultado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Facilita an\u00e1lisis relacionados con cursos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Acelera b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA</code> y <code>RESULTADO</code>:    Mejora an\u00e1lisis relacionados con resultados y fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GRADUADO</code>:    Optimiza b\u00fasquedas relacionadas con el estado de graduaci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESULTADO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ANIO_ACADEMICO</code>: Facilita agrupaciones y consultas por a\u00f1os.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora an\u00e1lisis relacionados con estudiantes.</li> <li><code>ID_CURSO</code>: Optimiza consultas relacionadas con cursos espec\u00edficos.</li> <li><code>ID_FECHA</code>: Acelera b\u00fasquedas por fechas de registro.</li> <li><code>FECHA</code> y <code>RESULTADO</code>: Facilita an\u00e1lisis de tendencias y resultados por fechas.</li> <li><code>GRADUADO</code>: Mejora b\u00fasquedas relacionadas con estados de graduaci\u00f3n.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESULTADO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ANIO_ACADEMICO\nON [Colegio].[FACT_RESULTADOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ID_POBLACION\nON [Colegio].[FACT_RESULTADOS] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ID_CURSO\nON [Colegio].[FACT_RESULTADOS] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_ID_FECHA\nON [Colegio].[FACT_RESULTADOS] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA y RESULTADO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_FECHA_RESULTADO\nON [Colegio].[FACT_RESULTADOS] (FECHA, RESULTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GRADUADO\nCREATE NONCLUSTERED INDEX IX_FACT_RESULTADOS_GRADUADO\nON [Colegio].[FACT_RESULTADOS] (GRADUADO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_servicio_social","title":"FACT_SERVICIO_SOCIAL","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Mejora b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Optimiza consultas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_GRADO</code>:    Facilita b\u00fasquedas relacionadas con grados acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CURSO</code>:    Mejora an\u00e1lisis relacionados con cursos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>HORARIO</code>:    Acelera b\u00fasquedas relacionadas con horarios asignados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PROYECTO</code>:    Optimiza b\u00fasquedas relacionadas con proyectos asociados al servicio social.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PAZ_Y_SALVO</code>:    Mejora an\u00e1lisis relacionados con el estado del estudiante respecto a sus requisitos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>HORAS_EJECUTADAS</code>:    Acelera consultas relacionadas con las horas acumuladas en el servicio social.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ANIO_ACADEMICO</code>: Facilita an\u00e1lisis por per\u00edodos acad\u00e9micos.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora b\u00fasquedas por estudiantes espec\u00edficos.</li> <li><code>ID_GRADO</code>: Optimiza an\u00e1lisis relacionados con niveles educativos.</li> <li><code>ID_CURSO</code>: Mejora b\u00fasquedas por grupos acad\u00e9micos.</li> <li><code>HORARIO</code>: Facilita consultas relacionadas con la asignaci\u00f3n de horarios.</li> <li><code>PROYECTO</code>: Mejora an\u00e1lisis por proyectos espec\u00edficos del servicio social.</li> <li><code>PAZ_Y_SALVO</code>: Acelera b\u00fasquedas relacionadas con el cumplimiento de requisitos.</li> <li><code>HORAS_EJECUTADAS</code>: Optimiza el an\u00e1lisis de acumulaci\u00f3n de horas en el servicio social.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ANIO_ACADEMICO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ID_POBLACION\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_GRADO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ID_GRADO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ID_GRADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CURSO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_ID_CURSO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (ID_CURSO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo HORARIO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_HORARIO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (HORARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PROYECTO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_PROYECTO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (PROYECTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PAZ_Y_SALVO\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_PAZ_Y_SALVO\nON [Colegio].[FACT_SERVICIO_SOCIAL] (PAZ_Y_SALVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo HORAS_EJECUTADAS\nCREATE NONCLUSTERED INDEX IX_FACT_SERVICIO_SOCIAL_HORAS\nON [Colegio].[FACT_SERVICIO_SOCIAL] (HORAS_EJECUTADAS);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_transporte","title":"FACT_TRANSPORTE","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Mejora b\u00fasquedas relacionadas con estudiantes espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza consultas relacionadas con fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Facilita b\u00fasquedas relacionadas con a\u00f1os acad\u00e9micos.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code>:    Mejora an\u00e1lisis relacionados con rangos de fechas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SERVICIO_TRANSPORTE</code>:    Acelera consultas relacionadas con tipos de transporte.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SERVICIO</code>:    Facilita b\u00fasquedas relacionadas con identificadores de servicios espec\u00edficos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura un acceso r\u00e1pido.</li> <li><code>ID_POBLACION_MATRICULA</code>: Mejora b\u00fasquedas por estudiantes.</li> <li><code>ID_FECHA</code>: Optimiza an\u00e1lisis por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Facilita agrupaciones por per\u00edodos acad\u00e9micos.</li> <li><code>FECHA_INICIO</code> y <code>FECHA_FIN</code>: Acelera b\u00fasquedas por rangos de fechas.</li> <li><code>SERVICIO_TRANSPORTE</code>: Mejora b\u00fasquedas relacionadas con tipos de servicios.</li> <li><code>ID_SERVICIO</code>: Facilita an\u00e1lisis por identificadores de servicios.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ID_POBLACION\nON [Colegio].[FACT_TRANSPORTE] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ID_FECHA\nON [Colegio].[FACT_TRANSPORTE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ANIO_ACADEMICO\nON [Colegio].[FACT_TRANSPORTE] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_FECHAS\nON [Colegio].[FACT_TRANSPORTE] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SERVICIO_TRANSPORTE\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_SERVICIO\nON [Colegio].[FACT_TRANSPORTE] (SERVICIO_TRANSPORTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_TRANSPORTE_ID_SERVICIO\nON [Colegio].[FACT_TRANSPORTE] (ID_SERVICIO);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_saber11_colegios","title":"FACT_SABER11_COLEGIOS","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>COD_ESTABLECIMIENTO_EDUCATIVO</code>:    Facilita b\u00fasquedas relacionadas con el c\u00f3digo del establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_EE</code>:    Acelera b\u00fasquedas por el nombre del establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESULTADO</code>:    Optimiza consultas relacionadas con los resultados espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CATEGORIA_SABER11</code>:    Mejora an\u00e1lisis relacionados con las categor\u00edas asignadas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura acceso eficiente.</li> <li><code>ID_FECHA</code>: Optimiza b\u00fasquedas por fechas espec\u00edficas en an\u00e1lisis temporales.</li> <li><code>ANIO_ACADEMICO</code>: Mejora agrupaciones por per\u00edodos acad\u00e9micos.</li> <li><code>COD_ESTABLECIMIENTO_EDUCATIVO</code>: Facilita consultas relacionadas con c\u00f3digos de instituciones.</li> <li><code>NOMBRE_EE</code>: Acelera b\u00fasquedas relacionadas con nombres de instituciones educativas.</li> <li><code>RESULTADO</code>: Mejora an\u00e1lisis y agrupaciones por resultados obtenidos.</li> <li><code>CATEGORIA_SABER11</code>: Optimiza b\u00fasquedas relacionadas con las clasificaciones.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_ID_FECHA\nON [Colegio].[FACT_SABER11_COLEGIOS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_ANIO_ACADEMICO\nON [Colegio].[FACT_SABER11_COLEGIOS] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_COD_ESTABLECIMIENTO\nON [Colegio].[FACT_SABER11_COLEGIOS] (COD_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_EE\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_NOMBRE_EE\nON [Colegio].[FACT_SABER11_COLEGIOS] (NOMBRE_EE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RESULTADO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_RESULTADO\nON [Colegio].[FACT_SABER11_COLEGIOS] (RESULTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA_SABER11\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_COLEGIOS_CATEGORIA\nON [Colegio].[FACT_SABER11_COLEGIOS] (CATEGORIA_SABER11);\nGO\n</code></pre>"},{"location":"01.scripts/07.Index_Colegio/#fact_saber11_individual","title":"FACT_SABER11_INDIVIDUAL","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora b\u00fasquedas relacionadas con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ANIO_ACADEMICO</code>:    Optimiza consultas relacionadas con per\u00edodos acad\u00e9micos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION_MATRICULA</code>:    Facilita b\u00fasquedas relacionadas con los estudiantes.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TEMATICA</code>:    Mejora an\u00e1lisis relacionados con tem\u00e1ticas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESULTADO</code>:    Optimiza b\u00fasquedas relacionadas con resultados obtenidos por los estudiantes.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_REGISTRO</code>: Clave primaria, asegura acceso eficiente.</li> <li><code>ID_FECHA</code>: Acelera consultas por fechas espec\u00edficas.</li> <li><code>ANIO_ACADEMICO</code>: Mejora an\u00e1lisis agrupados por per\u00edodos acad\u00e9micos.</li> <li><code>ID_POBLACION_MATRICULA</code>: Facilita b\u00fasquedas relacionadas con estudiantes individuales.</li> <li><code>TEMATICA</code>: Acelera an\u00e1lisis por \u00e1reas tem\u00e1ticas espec\u00edficas.</li> <li><code>RESULTADO</code>: Mejora consultas relacionadas con los puntajes individuales.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_ID_FECHA\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_ANIO_ACADEMICO\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION_MATRICULA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_ID_POBLACION\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (ID_POBLACION_MATRICULA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TEMATICA\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_TEMATICA\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (TEMATICA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RESULTADO\nCREATE NONCLUSTERED INDEX IX_FACT_SABER11_INDIVIDUAL_RESULTADO\nON [Colegio].[FACT_SABER11_INDIVIDUAL] (RESULTADO);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/","title":"08.Index Proteccion","text":""},{"location":"01.scripts/08.Index_Proteccion/#indices-proteccion","title":"Indices Protecci\u00f3n","text":""},{"location":"01.scripts/08.Index_Proteccion/#dim_campos_caract","title":"[DIM_CAMPOS_CARACT]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PREGUNTA</code> (PRIMARY KEY):    Asegura acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PREGUNTA</code>:    Optimiza b\u00fasquedas y filtros basados en el texto de la pregunta.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>OBSERVACIONES</code>:    Facilita b\u00fasquedas y consultas relacionadas con observaciones espec\u00edficas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PREGUNTA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>PREGUNTA</code>: Campo clave para b\u00fasquedas o filtros basados en el texto de la pregunta.</li> <li><code>OBSERVACIONES</code>: Mejora la velocidad de an\u00e1lisis y b\u00fasquedas cuando se necesitan filtros o an\u00e1lisis basados en observaciones espec\u00edficas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PREGUNTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_CAMPOS_CARACT_PREGUNTA\nON [Proteccion].[DIM_CAMPOS_CARACT] (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_DIM_CAMPOS_CARACT_OBSERVACIONES\nON [Proteccion].[DIM_CAMPOS_CARACT] (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_establecimiento_educativo","title":"[DIM_ESTABLECIMIENTO_EDUCATIVO]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>COD_ESTABLECIMIENTO_EDUCATIVO</code>:    Optimiza b\u00fasquedas relacionadas con el c\u00f3digo del establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_ESTABLECIMIENTO</code>:    Facilita b\u00fasquedas y filtros por el nombre del establecimiento.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code>:    Mejora consultas relacionadas con documentos espec\u00edficos de los establecimientos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>REPRESENTANTE_LEGAL</code>:    Acelera b\u00fasquedas relacionadas con los representantes legales de los establecimientos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>COD_CIUDAD</code>:    Optimiza an\u00e1lisis y filtros basados en la ciudad de ubicaci\u00f3n del establecimiento.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Clave primaria para garantizar un acceso r\u00e1pido y ordenado.</li> <li><code>COD_ESTABLECIMIENTO_EDUCATIVO</code>: Es un identificador alternativo usado frecuentemente en consultas.</li> <li><code>NOMBRE_ESTABLECIMIENTO</code>: Se utiliza para b\u00fasquedas textuales en an\u00e1lisis y reportes.</li> <li><code>DOCUMENTO</code>: Permite b\u00fasquedas espec\u00edficas para identificar establecimientos.</li> <li><code>REPRESENTANTE_LEGAL</code>: Optimiza consultas basadas en responsables legales.</li> <li><code>COD_CIUDAD</code>: Mejora an\u00e1lisis agrupados por ubicaci\u00f3n geogr\u00e1fica.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_ESTABLECIMIENTO_EDUCATIVO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo COD_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_COD_ESTABLECIMIENTO\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (COD_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_ESTABLECIMIENTO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_NOMBRE\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (NOMBRE_ESTABLECIMIENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_DOCUMENTO\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo REPRESENTANTE_LEGAL\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_REPRESENTANTE\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (REPRESENTANTE_LEGAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_CIUDAD\nCREATE NONCLUSTERED INDEX IX_DIM_ESTABLECIMIENTO_EDUCATIVO_COD_CIUDAD\nON [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] (COD_CIUDAD);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_poblacion","title":"[DIM_POBLACION]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_POBLACION</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>:    Optimiza consultas basadas en la combinaci\u00f3n del tipo de documento y su n\u00famero.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code>:    Mejora b\u00fasquedas relacionadas con la empresa asociada.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_AFILIADO</code>:    Facilita consultas relacionadas con los afiliados.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_BENEFICIARIO</code>:    Acelera an\u00e1lisis relacionados con los beneficiarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_APORTANTE</code>:    Optimiza b\u00fasquedas relacionadas con aportantes espec\u00edficos.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_POBLACION</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>: La combinaci\u00f3n de estos campos permite b\u00fasquedas r\u00e1pidas de individuos espec\u00edficos.</li> <li><code>ID_EMPRESA</code>: Facilita el an\u00e1lisis de datos a nivel empresarial.</li> <li><code>ID_AFILIADO</code>: Optimiza consultas relacionadas con individuos afiliados.</li> <li><code>ID_BENEFICIARIO</code>: Mejora el acceso a datos de beneficiarios en reportes y an\u00e1lisis.</li> <li><code>ID_APORTANTE</code>: Permite b\u00fasquedas r\u00e1pidas relacionadas con quienes realizan aportes.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_POBLACION\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_TIPO_DOCUMENTO_DOCUMENTO\nON [Proteccion].[DIM_POBLACION] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_EMPRESA\nON [Proteccion].[DIM_POBLACION] (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_AFILIADO\nON [Proteccion].[DIM_POBLACION] (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_BENEFICIARIO\nON [Proteccion].[DIM_POBLACION] (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_DIM_POBLACION_ID_APORTANTE\nON [Proteccion].[DIM_POBLACION] (ID_APORTANTE);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_preguntas_ee_aipi","title":"[DIM_PREGUNTAS_EE_AIPI]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PREGUNTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PREGUNTA</code>:    Optimiza b\u00fasquedas basadas en el texto de las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Mejora la eficiencia de consultas relacionadas con programas espec\u00edficos, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PREGUNTA</code>: Es la clave primaria que asegura un acceso eficiente a cada registro de manera \u00fanica.</li> <li><code>PREGUNTA</code>: Este campo puede ser usado en b\u00fasquedas textuales o filtros en reportes.</li> <li><code>ID_PROGRAMA</code>: Como clave for\u00e1nea, se usa en uniones y an\u00e1lisis vinculados con programas, lo que justifica su \u00edndice para mejorar el rendimiento.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PREGUNTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_AIPI_PREGUNTA\nON [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_AIPI_ID_PROGRAMA\nON [Proteccion].[DIM_PREGUNTAS_EE_AIPI] (ID_PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_preguntas_ee_jec","title":"[DIM_PREGUNTAS_EE_JEC]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PREGUNTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PREGUNTA</code>:    Facilita b\u00fasquedas y an\u00e1lisis basados en el texto de las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Mejora la eficiencia de consultas relacionadas con programas espec\u00edficos, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PREGUNTA</code>: Es la clave primaria que asegura un acceso eficiente a cada registro de manera \u00fanica.</li> <li><code>PREGUNTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales y reportes relacionados con las preguntas.</li> <li><code>ID_PROGRAMA</code>: Como clave for\u00e1nea, este campo se utiliza para unir o filtrar datos basados en los programas asociados.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PREGUNTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_JEC_PREGUNTA\nON [Proteccion].[DIM_PREGUNTAS_EE_JEC] (PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PREGUNTAS_EE_JEC_ID_PROGRAMA\nON [Proteccion].[DIM_PREGUNTAS_EE_JEC] (ID_PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_programa","title":"[DIM_PROGRAMA]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PROGRAMA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PROGRAMA</code>:    Optimiza consultas relacionadas con el nombre o descripci\u00f3n de los programas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_PROGRAMA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>PROGRAMA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales, reportes y an\u00e1lisis relacionados con los programas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PROGRAMA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo PROGRAMA\nCREATE NONCLUSTERED INDEX IX_DIM_PROGRAMA_PROGRAMA\nON [Proteccion].[DIM_PROGRAMA] (PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_respuestas_ee_aipi","title":"[DIM_RESPUESTAS_EE_AIPI]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESPUESTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESPUESTA</code>:    Optimiza b\u00fasquedas relacionadas con el texto de las respuestas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de consultas que relacionan respuestas con preguntas espec\u00edficas, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESPUESTA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>RESPUESTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales y reportes relacionados con las respuestas.</li> <li><code>ID_PREGUNTA</code>: Como clave for\u00e1nea, es importante para unir o filtrar datos basados en preguntas asociadas a las respuestas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESPUESTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo RESPUESTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_AIPI_RESPUESTA\nON [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (RESPUESTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_AIPI_ID_PREGUNTA\nON [Proteccion].[DIM_RESPUESTAS_EE_AIPI] (ID_PREGUNTA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#dim_respuestas_ee_jec","title":"[DIM_RESPUESTAS_EE_JEC]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_RESPUESTA</code> (PRIMARY KEY):    Garantiza acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RESPUESTA</code>:    Optimiza b\u00fasquedas relacionadas con el texto de las respuestas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de consultas que relacionan respuestas con preguntas espec\u00edficas, especialmente por ser una clave for\u00e1nea.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_RESPUESTA</code>: Clave primaria que asegura un acceso eficiente al registro por su identificador \u00fanico.</li> <li><code>RESPUESTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales y an\u00e1lisis relacionados con las respuestas.</li> <li><code>ID_PREGUNTA</code>: Como clave for\u00e1nea, facilita uniones y filtros en consultas que relacionan respuestas con preguntas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_RESPUESTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo RESPUESTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_JEC_RESPUESTA\nON [Proteccion].[DIM_RESPUESTAS_EE_JEC] (RESPUESTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_DIM_RESPUESTAS_EE_JEC_ID_PREGUNTA\nON [Proteccion].[DIM_RESPUESTAS_EE_JEC] (ID_PREGUNTA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_caracterizacion","title":"[FACT_CARACTERIZACION]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CARACTERIZACION</code> (PRIMARY KEY):    Garantiza un acceso r\u00e1pido y ordenado mediante el identificador \u00fanico de cada registro.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora el rendimiento de consultas que utilizan la fecha para an\u00e1lisis o relaciones con otras tablas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code>:    Optimiza consultas relacionadas con la poblaci\u00f3n asociada a cada caracterizaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Acelera b\u00fasquedas y relaciones con programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de uniones o filtros relacionados con preguntas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>RESPUESTA</code>:    Optimiza b\u00fasquedas textuales relacionadas con las respuestas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_FECHA</code> y <code>ID_PROGRAMA</code>:    Dise\u00f1ado para consultas frecuentes que combinen fechas y programas en filtros o an\u00e1lisis.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_CARACTERIZACION</code>: Clave primaria que asegura un acceso eficiente y ordenado a los registros.</li> <li><code>ID_FECHA</code>: Frecuentemente utilizado para an\u00e1lisis basados en tiempo o relaciones con la tabla de tiempo.</li> <li><code>ID_POBLACION</code>: Como clave for\u00e1nea, se utiliza para uniones y an\u00e1lisis relacionados con datos de poblaci\u00f3n.</li> <li><code>ID_PROGRAMA</code>: Fundamental para consultas que filtran o agrupan por programas asociados.</li> <li><code>ID_PREGUNTA</code>: Importante para relacionar y analizar preguntas espec\u00edficas.</li> <li><code>RESPUESTA</code>: Este campo puede ser utilizado en b\u00fasquedas textuales o an\u00e1lisis relacionados con respuestas espec\u00edficas.</li> <li>\u00cdndice compuesto para <code>ID_FECHA</code> y <code>ID_PROGRAMA</code>: Facilita an\u00e1lisis multidimensionales en escenarios con m\u00faltiples dimensiones (fecha y programa).</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CARACTERIZACION\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_FECHA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_POBLACION\nON [Proteccion].[FACT_CARACTERIZACION] (ID_POBLACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_PROGRAMA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_ID_PREGUNTA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_RESPUESTA\nON [Proteccion].[FACT_CARACTERIZACION] (RESPUESTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_FECHA y ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_CARACTERIZACION_FECHA_PROGRAMA\nON [Proteccion].[FACT_CARACTERIZACION] (ID_FECHA, ID_PROGRAMA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_desercion","title":"[FACT_DESERCION]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Optimiza las consultas relacionadas con establecimientos educativos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code>:    Mejora el rendimiento de b\u00fasquedas o uniones relacionadas con poblaci\u00f3n.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Acelera las consultas relacionadas con programas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Mejora el rendimiento en an\u00e1lisis basados en tiempo y uniones con la tabla de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>ANIO_ACADEMICO</code>:    Optimiza consultas que analizan registros por a\u00f1o acad\u00e9mico.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CAUSA</code>:    Acelera b\u00fasquedas y agrupaciones relacionadas con las causas de deserci\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_FECHA</code> y <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Dise\u00f1ado para consultas que filtran por tiempo y establecimiento educativo.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code> y <code>ID_POBLACION</code>: Claves for\u00e1neas usadas frecuentemente en uniones y an\u00e1lisis relacionados con datos espec\u00edficos.</li> <li><code>ID_PROGRAMA</code>: Usado en consultas para agrupar o filtrar datos por programa.</li> <li><code>ID_FECHA</code>: Clave for\u00e1nea que permite uniones r\u00e1pidas con la dimensi\u00f3n de tiempo para an\u00e1lisis temporales.</li> <li><code>ANIO_ACADEMICO</code> y <code>CAUSA</code>: Campos comunes en an\u00e1lisis y agrupaciones espec\u00edficas sobre deserci\u00f3n.</li> <li>\u00cdndice compuesto para <code>ID_FECHA</code> y <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Acelera consultas multidimensionales que incluyen filtros por tiempo y establecimiento.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_DESERCION] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_POBLACION\nON [Proteccion].[FACT_DESERCION] (ID_POBLACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_PROGRAMA\nON [Proteccion].[FACT_DESERCION] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ID_FECHA\nON [Proteccion].[FACT_DESERCION] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ANIO_ACADEMICO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_ANIO_ACADEMICO\nON [Proteccion].[FACT_DESERCION] (ANIO_ACADEMICO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CAUSA\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_CAUSA\nON [Proteccion].[FACT_DESERCION] (CAUSA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_FECHA y ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DESERCION_FECHA_ESTABLECIMIENTO\nON [Proteccion].[FACT_DESERCION] (ID_FECHA, ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_diagnosticos_ee_aipi","title":"[FACT_DIAGNOSTICOS_EE_AIPI]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza las consultas relacionadas con el tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Acelera las b\u00fasquedas relacionadas con establecimientos educativos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento de consultas relacionadas con las preguntas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_RESPUESTA</code>:    Optimiza b\u00fasquedas o an\u00e1lisis relacionados con las respuestas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_FECHA</code> y <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Dise\u00f1ado para acelerar consultas que filtran por tiempo y establecimiento educativo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CIUDAD</code>:    Acelera b\u00fasquedas y agrupaciones por ciudad.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>:    Optimiza las consultas que cruzan las preguntas con sus respuestas.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Utilizado en uniones con la dimensi\u00f3n de tiempo para an\u00e1lisis temporales.</li> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Com\u00fan en uniones y an\u00e1lisis espec\u00edficos por establecimiento educativo.</li> <li><code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>: Claves for\u00e1neas para enlazar preguntas y respuestas, necesarias para an\u00e1lisis detallados.</li> <li><code>CIUDAD</code>: Campo usado en agrupaciones y an\u00e1lisis geogr\u00e1ficos.</li> <li>\u00cdndices compuestos: Aceleran consultas multidimensionales, como las que combinan fechas con establecimientos educativos o preguntas con respuestas.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_FECHA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_PREGUNTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_ID_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_RESPUESTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_FECHA y ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_FECHA_ESTABLECIMIENTO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_FECHA, ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CIUDAD\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_CIUDAD\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (CIUDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_PREGUNTA y ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_AIPI_PREGUNTA_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_AIPI] (ID_PREGUNTA, ID_RESPUESTA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_diagnosticos_ee_jec","title":"[FACT_DIAGNOSTICOS_EE_JEC]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_REGISTRO</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Acelera consultas relacionadas con la dimensi\u00f3n de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code>:    Optimiza b\u00fasquedas y uniones relacionadas con establecimientos educativos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PREGUNTA</code>:    Mejora el rendimiento en consultas relacionadas con preguntas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_RESPUESTA</code>:    Facilita el an\u00e1lisis y recuperaci\u00f3n de datos basados en respuestas espec\u00edficas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_HORA_INICIO</code> y <code>FECHA_HORA_FIN</code>:    Dise\u00f1ado para consultas que analizan rangos de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>CORREO_FUNCIONARIO</code>:    Acelera b\u00fasquedas espec\u00edficas relacionadas con el correo de los funcionarios.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>:    Optimiza el an\u00e1lisis cruzado de preguntas y respuestas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para el campo <code>RECTOR</code>:    Acelera consultas relacionadas con los rectores.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Utilizado para uniones con la dimensi\u00f3n de tiempo y an\u00e1lisis temporales.</li> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>: Com\u00fan en an\u00e1lisis espec\u00edficos por establecimiento educativo.</li> <li><code>ID_PREGUNTA</code> y <code>ID_RESPUESTA</code>: Campos esenciales para uniones y an\u00e1lisis cruzados entre preguntas y respuestas.</li> <li>Campos de tiempo (<code>FECHA_HORA_INICIO</code>, <code>FECHA_HORA_FIN</code>): Importantes para an\u00e1lisis basados en periodos.</li> <li>Campos relacionados con funcionarios (<code>CORREO_FUNCIONARIO</code>, <code>RECTOR</code>): \u00datiles para segmentaciones y an\u00e1lisis detallados por personal.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_REGISTRO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_FECHA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_PREGUNTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_PREGUNTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_ID_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_RESPUESTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_HORA_INICIO y FECHA_HORA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_FECHA_RANGO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (FECHA_HORA_INICIO, FECHA_HORA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO_FUNCIONARIO\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_CORREO_FUNCIONARIO\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (CORREO_FUNCIONARIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_PREGUNTA y ID_RESPUESTA\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_PREGUNTA_RESPUESTA\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (ID_PREGUNTA, ID_RESPUESTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RECTOR\nCREATE NONCLUSTERED INDEX IX_FACT_DIAGNOSTICOS_EE_JEC_RECTOR\nON [Proteccion].[FACT_DIAGNOSTICOS_EE_JEC] (RECTOR);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_entrega_material","title":"[FACT_ENTREGA_MATERIAL]","text":"<ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_ENTREGA</code> (PRIMARY KEY):    Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code>:    Optimiza uniones y consultas basadas en la dimensi\u00f3n de tiempo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code>:    Mejora el rendimiento de consultas relacionadas con programas espec\u00edficos.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code>:    Acelera b\u00fasquedas relacionadas con personal asignado.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_MATERIAL</code>:    Facilita b\u00fasquedas espec\u00edficas por material.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_MATERIAL</code> y <code>CANTIDAD_MATERIAL</code>:    Dise\u00f1ado para consultas que analizan tipos y cantidades de material.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>VALOR_MATERIAL</code> y <code>ID_FECHA</code>:    Mejora an\u00e1lisis financieros relacionados con fechas espec\u00edficas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code>:    Optimiza consultas y an\u00e1lisis centrados en poblaci\u00f3n.</p> </li> </ol> <p>Justificaci\u00f3n</p> <ul> <li><code>ID_FECHA</code>: Utilizado para uniones y an\u00e1lisis relacionados con periodos de tiempo.  </li> <li><code>ID_PROGRAMA</code> y <code>ID_PERSONAL</code>: Campos claves para an\u00e1lisis por programa y personal.  </li> <li><code>ID_MATERIAL</code>: Esencial para identificar materiales entregados.  </li> <li>Campos compuestos (<code>TIPO_MATERIAL</code>, <code>CANTIDAD_MATERIAL</code> y <code>VALOR_MATERIAL</code>): Relevantes para an\u00e1lisis detallados de distribuci\u00f3n y valor.  </li> <li><code>ID_POBLACION</code>: Clave en consultas relacionadas con la poblaci\u00f3n beneficiaria.</li> </ul> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_ENTREGA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_FECHA\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_PROGRAMA\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_PERSONAL\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_PERSONAL);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_MATERIAL\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_MATERIAL\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_MATERIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_MATERIAL y CANTIDAD_MATERIAL\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_TIPO_CANTIDAD\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (TIPO_MATERIAL, CANTIDAD_MATERIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos VALOR_MATERIAL y ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_VALOR_FECHA\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (VALOR_MATERIAL, ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_ENTREGA_MATERIAL_ID_POBLACION\nON [Proteccion].[FACT_ENTREGA_MATERIAL] (ID_POBLACION);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_plan_cobertura","title":"[FACT_PLAN_COBERTURA]","text":"<p>Justificaci\u00f3n</p> <ol> <li>\u00cdndice cl\u00faster existente para <code>ID_PLAN_COBERTURA</code></li> <li> <p>La clave primaria asegura acceso ordenado y r\u00e1pido a los registros mediante un \u00edndice cl\u00faster.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> </li> <li> <p>Mejora las consultas relacionadas con el tiempo y permite uniones r\u00e1pidas con la dimensi\u00f3n temporal.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTABLECIMIENTO_EDUCATIVO</code></p> </li> <li> <p>Optimiza consultas relacionadas con establecimientos educativos y permite uniones eficientes con la dimensi\u00f3n correspondiente.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code></p> </li> <li> <p>Facilita el acceso r\u00e1pido a los datos relacionados con programas espec\u00edficos y optimiza las uniones con su dimensi\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ZONA</code> y <code>MUNICIPIO</code></p> </li> <li> <p>Optimiza las consultas que analizan datos por zona y municipio.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>LINEA_INTERVENCION</code></p> </li> <li> <p>Mejora el rendimiento en consultas que filtran o agrupan datos por l\u00ednea de intervenci\u00f3n.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>SEDE</code> y <code>COBERTURA_PROYECTADA</code></p> </li> <li>Acelera las b\u00fasquedas y an\u00e1lisis relacionados con las sedes y su cobertura proyectada.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PLAN_COBERTURA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_FECHA\nON [Proteccion].[FACT_PLAN_COBERTURA] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ESTABLECIMIENTO_EDUCATIVO\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_ESTABLECIMIENTO\nON [Proteccion].[FACT_PLAN_COBERTURA] (ID_ESTABLECIMIENTO_EDUCATIVO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ID_PROGRAMA\nON [Proteccion].[FACT_PLAN_COBERTURA] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ZONA y MUNICIPIO\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_ZONA_MUNICIPIO\nON [Proteccion].[FACT_PLAN_COBERTURA] (ZONA, MUNICIPIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo LINEA_INTERVENCION\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_LINEA_INTERVENCION\nON [Proteccion].[FACT_PLAN_COBERTURA] (LINEA_INTERVENCION);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos SEDE y COBERTURA_PROYECTADA\nCREATE NONCLUSTERED INDEX IX_FACT_PLAN_COBERTURA_SEDE_COBERTURA\nON [Proteccion].[FACT_PLAN_COBERTURA] (SEDE, COBERTURA_PROYECTADA);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_venta","title":"[FACT_VENTA]","text":"<p>Justificaci\u00f3n</p> <ol> <li>\u00cdndice cl\u00faster existente para <code>ID_VENTA</code></li> <li> <p>Clave primaria que asegura acceso r\u00e1pido y ordenado a los registros.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> </li> <li> <p>Optimiza consultas relacionadas con el tiempo y permite uniones r\u00e1pidas con la dimensi\u00f3n temporal.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_POBLACION</code></p> </li> <li> <p>Mejora el rendimiento de consultas centradas en la poblaci\u00f3n objetivo.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SERVICIO</code></p> </li> <li> <p>Acelera b\u00fasquedas relacionadas con servicios y permite uniones r\u00e1pidas con la dimensi\u00f3n de servicios.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code></p> </li> <li> <p>Facilita b\u00fasquedas r\u00e1pidas basadas en documentos espec\u00edficos de usuarios.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CATEGORIA_VENTA</code></p> </li> <li> <p>Permite consultas eficientes sobre las categor\u00edas de ventas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>COSTO</code>, <code>SUBSIDIO</code>, y <code>VALOR_PAGADO_SIN_IMP</code></p> </li> <li>Optimiza an\u00e1lisis relacionados con valores econ\u00f3micos de las ventas.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_VENTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_ID_FECHA\nON [Proteccion].[FACT_VENTA] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_POBLACION\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_ID_POBLACION\nON [Proteccion].[FACT_VENTA] (ID_POBLACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_ID_SERVICIO\nON [Proteccion].[FACT_VENTA] (ID_SERVICIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_DOCUMENTOS\nON [Proteccion].[FACT_VENTA] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA_VENTA\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_CATEGORIA\nON [Proteccion].[FACT_VENTA] (CATEGORIA_VENTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos COSTO, SUBSIDIO, y VALOR_PAGADO_SIN_IMP\nCREATE NONCLUSTERED INDEX IX_FACT_VENTA_VALORES\nON [Proteccion].[FACT_VENTA] (COSTO, SUBSIDIO, VALOR_PAGADO_SIN_IMP);\nGO\n</code></pre>"},{"location":"01.scripts/08.Index_Proteccion/#fact_visitas","title":"[FACT_VISITAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li>\u00cdndice cl\u00faster existente para <code>ID_VISITA</code></li> <li> <p>La clave primaria asegura acceso ordenado y r\u00e1pido a los registros mediante un \u00edndice cl\u00faster.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> </li> <li> <p>Optimiza las consultas relacionadas con fechas y permite uniones eficientes con la dimensi\u00f3n temporal.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code></p> </li> <li> <p>Mejora el rendimiento en consultas que agrupan o filtran datos por programas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PERSONAL</code></p> </li> <li> <p>Acelera las b\u00fasquedas relacionadas con el personal involucrado en las visitas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>MUNICIPIO</code> y <code>LUGAR</code></p> </li> <li> <p>Facilita an\u00e1lisis y b\u00fasquedas basadas en la ubicaci\u00f3n de las visitas.</p> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_PLANEADA</code> y <code>FECHA_EJECUTADA</code></p> </li> <li> <p>Permite comparar las fechas planeadas con las ejecutadas, optimizando las consultas relacionadas con la ejecuci\u00f3n de visitas.</p> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ACTIVIDAD</code></p> </li> <li>Mejora el rendimiento de consultas que filtran o agrupan datos por actividades.</li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_VISITA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ID_FECHA\nON [Proteccion].[FACT_VISITAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ID_PROGRAMA\nON [Proteccion].[FACT_VISITAS] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PERSONAL\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ID_PERSONAL\nON [Proteccion].[FACT_VISITAS] (ID_PERSONAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos MUNICIPIO y LUGAR\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_MUNICIPIO_LUGAR\nON [Proteccion].[FACT_VISITAS] (MUNICIPIO, LUGAR);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_PLANEADA y FECHA_EJECUTADA\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_FECHAS\nON [Proteccion].[FACT_VISITAS] (FECHA_PLANEADA, FECHA_EJECUTADA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ACTIVIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_VISITAS_ACTIVIDAD\nON [Proteccion].[FACT_VISITAS] (ACTIVIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/","title":"09.Index Transversal","text":""},{"location":"01.scripts/09.Index_Transversal/#indices-transversal","title":"Indices Transversal","text":""},{"location":"01.scripts/09.Index_Transversal/#dim_afiliados","title":"[DIM_AFILIADOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_AFILIADO</code></p> <ul> <li>La clave primaria garantiza un acceso eficiente y ordenado a los registros.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NUMERO_DOCUMENTO</code></p> <ul> <li>Este \u00edndice es esencial para las b\u00fasquedas frecuentes por el n\u00famero de documento, ya que suele ser un identificador \u00fanico en sistemas de afiliados.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>NUMERO_DOCUMENTO</code></p> <ul> <li>Optimiza las consultas que combinan tipo y n\u00famero de documento para validar registros.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code></p> <ul> <li>Facilita las b\u00fasquedas y uniones con la dimensi\u00f3n de empresas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code></p> <ul> <li>Mejora las b\u00fasquedas por correo electr\u00f3nico, a menudo usado como identificador \u00fanico o para comunicaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PRIMER_APELLIDO</code> y <code>SEGUNDO_APELLIDO</code></p> <ul> <li>Optimiza las consultas de b\u00fasqueda y agrupaci\u00f3n por apellidos, comunes en an\u00e1lisis demogr\u00e1ficos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GENERO</code></p> <ul> <li>Mejora el rendimiento en an\u00e1lisis de g\u00e9nero, com\u00fan en reportes de afiliados.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_AFILIACION</code> y <code>FECHA_AFILIACION</code></p> <ul> <li>Facilita el an\u00e1lisis y la segmentaci\u00f3n por estado y fecha de afiliaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FEC_DESDE</code> y <code>FEC_HASTA</code></p> <ul> <li>Optimiza consultas de rangos temporales, como la validez de afiliaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADOREGISTRO</code></p> <ul> <li>Mejora el rendimiento de consultas que filtran registros activos o inactivos.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_AFILIADO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_NUMERO_DOCUMENTO\nON [Transversal].[DIM_AFILIADOS] (NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_TIPO_Y_DOCUMENTO\nON [Transversal].[DIM_AFILIADOS] (TIPO_DOCUMENTO, NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_ID_EMPRESA\nON [Transversal].[DIM_AFILIADOS] (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_CORREO\nON [Transversal].[DIM_AFILIADOS] (CORREO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_APELLIDO y SEGUNDO_APELLIDO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_APELLIDOS\nON [Transversal].[DIM_AFILIADOS] (PRIMER_APELLIDO, SEGUNDO_APELLIDO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GENERO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_GENERO\nON [Transversal].[DIM_AFILIADOS] (GENERO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ESTADO_AFILIACION y FECHA_AFILIACION\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_ESTADO_FECHA\nON [Transversal].[DIM_AFILIADOS] (ESTADO_AFILIACION, FECHA_AFILIACION);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FEC_DESDE y FEC_HASTA\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_FECHAS\nON [Transversal].[DIM_AFILIADOS] (FEC_DESDE, FEC_HASTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADOREGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_AFILIADOS_ESTADOREGISTRO\nON [Transversal].[DIM_AFILIADOS] (ESTADOREGISTRO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_aportante_noafiliado","title":"[DIM_APORTANTE_NOAFILIADO]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_APORTANTE</code> </p> <ul> <li>Clave primaria que garantiza un acceso r\u00e1pido y ordenado.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code> </p> <ul> <li>Optimiza b\u00fasquedas frecuentes por el documento, clave com\u00fan en registros de aportantes.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code> </p> <ul> <li>Mejora el rendimiento en validaciones combinadas por tipo y documento, frecuentemente usadas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>RAZON_SOCIAL</code> </p> <ul> <li>Facilita b\u00fasquedas por la raz\u00f3n social, \u00fatil para identificar aportantes empresariales.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ESTADO</code> y <code>ESTADO</code> </p> <ul> <li>Optimiza filtros por estado del aportante, comunes en an\u00e1lisis de activos/inactivos.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>SECTOR</code> y <code>CLASE</code> </p> <ul> <li>Mejora la eficiencia de consultas relacionadas con caracter\u00edsticas sectoriales y clasificaciones.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_DESDE</code> y <code>FECHA_HASTA</code> </p> <ul> <li>Facilita an\u00e1lisis y consultas en rangos temporales sobre periodos de validez.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code> </p> <ul> <li>Mejora el rendimiento de b\u00fasquedas por correo electr\u00f3nico.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PRIMER_APELLIDO</code> y <code>SEGUNDO_APELLIDO</code> </p> <ul> <li>\u00datil para b\u00fasquedas por nombres y apellidos en casos de aportantes individuales.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADOREGISTRO</code> </p> <ul> <li>Filtra registros seg\u00fan su estado actual, \u00fatil para segmentaciones de datos.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_APORTANTE\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_DOCUMENTO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_TIPO_Y_DOCUMENTO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo RAZON_SOCIAL\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_RAZON_SOCIAL\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (RAZON_SOCIAL);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_ESTADO y ESTADO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_ESTADO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (ID_ESTADO, ESTADO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos SECTOR y CLASE\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_SECTOR_CLASE\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (SECTOR, CLASE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_DESDE y FECHA_HASTA\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_FECHAS\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (FECHA_DESDE, FECHA_HASTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_CORREO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (CORREO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_APELLIDO y SEGUNDO_APELLIDO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_APELLIDOS\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (PRIMER_APELLIDO, SEGUNDO_APELLIDO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADOREGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_APORTANTE_NOAFILIADO_ESTADOREGISTRO\nON [Transversal].[DIM_APORTANTE_NOAFILIADO] (ESTADOREGISTRO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_beneficiarios","title":"[DIM_BENEFICIARIOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_BENEFICIARIO</code> </p> <ul> <li>Clave primaria que garantiza acceso r\u00e1pido a registros \u00fanicos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NUMERO_DOCUMENTO</code> </p> <ul> <li>Optimiza b\u00fasquedas frecuentes por el documento del beneficiario.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>NUMERO_DOCUMENTO</code> </p> <ul> <li>Mejora el rendimiento en consultas que combinan tipo y n\u00famero de documento.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_AFILIADO</code> </p> <ul> <li>Facilita consultas relacionadas con afiliados vinculados a beneficiarios.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>PRIMER_NOMBRE</code> y <code>PRIMER_APELLIDO</code> </p> <ul> <li>\u00datil en b\u00fasquedas por nombres y apellidos, especialmente en beneficiarios individuales.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_AFILIACION</code> y <code>FECHA_RETIRO</code> </p> <ul> <li>Mejora an\u00e1lisis temporales relacionados con la afiliaci\u00f3n y retiro de beneficiarios.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GENERO</code> </p> <ul> <li>Permite segmentar y filtrar beneficiarios por g\u00e9nero.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADOREGISTRO</code> </p> <ul> <li>Facilita la segmentaci\u00f3n y an\u00e1lisis por estado del registro.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FEC_DESDE</code> y <code>FEC_HASTA</code> </p> <ul> <li>Optimiza consultas en rangos temporales sobre la validez del beneficiario.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DIRECCION</code> </p> <ul> <li>Mejora b\u00fasquedas relacionadas con la localizaci\u00f3n de beneficiarios.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_BENEFICIARIO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_DOCUMENTO\nON [Transversal].[DIM_BENEFICIARIOS] (NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y NUMERO_DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_TIPO_Y_DOCUMENTO\nON [Transversal].[DIM_BENEFICIARIOS] (TIPO_DOCUMENTO, NUMERO_DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_AFILIADO\nON [Transversal].[DIM_BENEFICIARIOS] (ID_AFILIADO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos PRIMER_NOMBRE y PRIMER_APELLIDO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_NOMBRES\nON [Transversal].[DIM_BENEFICIARIOS] (PRIMER_NOMBRE, PRIMER_APELLIDO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_AFILIACION y FECHA_RETIRO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_FECHAS\nON [Transversal].[DIM_BENEFICIARIOS] (FECHA_AFILIACION, FECHA_RETIRO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GENERO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_GENERO\nON [Transversal].[DIM_BENEFICIARIOS] (GENERO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADOREGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_ESTADOREGISTRO\nON [Transversal].[DIM_BENEFICIARIOS] (ESTADOREGISTRO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FEC_DESDE y FEC_HASTA\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_FECHAS_VALIDACION\nON [Transversal].[DIM_BENEFICIARIOS] (FEC_DESDE, FEC_HASTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo DIRECCION\nCREATE NONCLUSTERED INDEX IX_DIM_BENEFICIARIOS_DIRECCION\nON [Transversal].[DIM_BENEFICIARIOS] (DIRECCION);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_capacidad_fisica","title":"[DIM_CAPACIDAD_FISICA]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_SALON</code> </p> <ul> <li>Clave primaria que asegura el acceso \u00fanico y r\u00e1pido a los registros de la tabla.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CAPACIDAD</code> </p> <ul> <li>Optimiza b\u00fasquedas y an\u00e1lisis basados en la capacidad f\u00edsica de los salones.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>JORNADA</code> y <code>BLOQUE_HORARIO</code> </p> <ul> <li>Facilita consultas relacionadas con horarios y turnos en una jornada espec\u00edfica.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>GRUPO</code> </p> <ul> <li>Mejora las consultas que filtran por el grupo asignado al sal\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_SEDE</code> </p> <ul> <li>Ayuda a optimizar las consultas relacionadas con sedes espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code> </p> <ul> <li>Mejora el rendimiento en consultas que relacionan las capacidades f\u00edsicas con unidades espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_SEDE</code> y <code>ID_UNIDAD</code> </p> <ul> <li>Permite consultas eficientes que cruzan datos de sedes y unidades.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_SALON\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo CAPACIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_CAPACIDAD\nON [Transversal].[DIM_CAPACIDAD_FISICA] (CAPACIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos JORNADA y BLOQUE_HORARIO\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_JORNADA_BLOQUE\nON [Transversal].[DIM_CAPACIDAD_FISICA] (JORNADA, BLOQUE_HORARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo GRUPO\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_GRUPO\nON [Transversal].[DIM_CAPACIDAD_FISICA] (GRUPO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_SEDE\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_ID_SEDE\nON [Transversal].[DIM_CAPACIDAD_FISICA] (ID_SEDE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_ID_UNIDAD\nON [Transversal].[DIM_CAPACIDAD_FISICA] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_SEDE y ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_CAPACIDAD_FISICA_SEDE_UNIDAD\nON [Transversal].[DIM_CAPACIDAD_FISICA] (ID_SEDE, ID_UNIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_cuenta_contable","title":"[DIM_CUENTA_CONTABLE]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CUENTA</code></p> <ul> <li>Es la clave primaria y asegura el acceso \u00fanico y eficiente a los registros.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CUENTA_NUMERO</code></p> <ul> <li>Optimiza consultas que filtran o agrupan por el n\u00famero de cuenta.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>CUENTA</code> y <code>CUENTA_HOMOLOGA</code></p> <ul> <li>Facilita b\u00fasquedas relacionadas con la cuenta y su homologaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_CUENTA</code></p> <ul> <li>Mejora el rendimiento de consultas que analizan o filtran cuentas por tipo.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>GRUPO_CUENTA</code> y <code>SUBGRUPO_CUENTA</code></p> <ul> <li>Acelera consultas que cruzan datos entre grupos y subgrupos de cuentas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO_REGISTRO</code></p> <ul> <li>Permite consultas r\u00e1pidas relacionadas con el estado de registro de las cuentas.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CUENTA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo CUENTA_NUMERO\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_CUENTA_NUMERO\nON [Transversal].[DIM_CUENTA_CONTABLE] (CUENTA_NUMERO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CUENTA y CUENTA_HOMOLOGA\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_CUENTA_HOMOLOGA\nON [Transversal].[DIM_CUENTA_CONTABLE] (CUENTA, CUENTA_HOMOLOGA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_CUENTA\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_TIPO_CUENTA\nON [Transversal].[DIM_CUENTA_CONTABLE] (TIPO_CUENTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos GRUPO_CUENTA y SUBGRUPO_CUENTA\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_GRUPO_SUBGRUPO\nON [Transversal].[DIM_CUENTA_CONTABLE] (GRUPO_CUENTA, SUBGRUPO_CUENTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO_REGISTRO\nCREATE NONCLUSTERED INDEX IX_DIM_CUENTA_CONTABLE_ESTADO_REGISTRO\nON [Transversal].[DIM_CUENTA_CONTABLE] (ESTADO_REGISTRO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_empresas","title":"[DIM_EMPRESAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_EMPRESA</code></p> <ul> <li>Es la clave primaria y permite b\u00fasquedas r\u00e1pidas por el identificador \u00fanico de empresa.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code></p> <ul> <li>Optimiza b\u00fasquedas y validaciones de empresas por n\u00famero de documento.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>RAZON_SOCIAL</code> y <code>SECTOR</code></p> <ul> <li>Facilita las b\u00fasquedas combinadas de empresas por raz\u00f3n social y sector.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>FECHA_AFILIACION</code></p> <ul> <li>Mejora el rendimiento en consultas relacionadas con la fecha de afiliaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADOREGISTRO</code> y <code>ESTADO</code></p> <ul> <li>Acelera consultas que filtran por el estado del registro y el estado de la empresa.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_ACT_ECONOMICA</code></p> <ul> <li>Permite b\u00fasquedas m\u00e1s eficientes al filtrar por actividad econ\u00f3mica.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_EMPRESA\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_DOCUMENTO\nON [Transversal].[DIM_EMPRESAS] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos RAZON_SOCIAL y SECTOR\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_RAZON_SOCIAL_SECTOR\nON [Transversal].[DIM_EMPRESAS] (RAZON_SOCIAL, SECTOR);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_AFILIACION\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_FECHA_AFILIACION\nON [Transversal].[DIM_EMPRESAS] (FECHA_AFILIACION);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ESTADOREGISTRO y ESTADO\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_ESTADO_REGISTRO_ESTADO\nON [Transversal].[DIM_EMPRESAS] (ESTADOREGISTRO, ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_ACT_ECONOMICA\nCREATE NONCLUSTERED INDEX IX_DIM_EMPRESAS_ID_ACT_ECONOMICA\nON [Transversal].[DIM_EMPRESAS] (ID_ACT_ECONOMICA);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_personal","title":"[DIM_PERSONAL]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_PERSONAL</code></p> <ul> <li>Es la clave primaria que permite b\u00fasquedas r\u00e1pidas por el identificador \u00fanico del personal.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DOCUMENTO</code></p> <ul> <li>Facilita b\u00fasquedas frecuentes por n\u00famero de documento, que es una consulta com\u00fan en sistemas de personal.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_UNIDAD</code> y <code>ID_SERVICIO</code></p> <ul> <li>Mejora la eficiencia de consultas relacionadas con la asignaci\u00f3n de personal a unidades y servicios.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO_CONTRATACION</code> y <code>FECHA_FIN_CONTRATACION</code></p> <ul> <li>Optimiza consultas que filtran registros por periodos de contrataci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CORREO</code></p> <ul> <li>Permite b\u00fasquedas r\u00e1pidas por correo electr\u00f3nico, \u00fatil en sistemas de contacto.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>GENERO</code> y <code>NIVEL_INGLES</code></p> <ul> <li>Acelera consultas relacionadas con la demograf\u00eda del personal y sus habilidades ling\u00fc\u00edsticas.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_PERSONAL\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_DOCUMENTO\nON [Transversal].[DIM_PERSONAL] (DOCUMENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_UNIDAD e ID_SERVICIO\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_ID_UNIDAD_ID_SERVICIO\nON [Transversal].[DIM_PERSONAL] (ID_UNIDAD, ID_SERVICIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO_CONTRATACION y FECHA_FIN_CONTRATACION\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_FECHA_CONTRATACION\nON [Transversal].[DIM_PERSONAL] (FECHA_INICIO_CONTRATACION, FECHA_FIN_CONTRATACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CORREO\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_CORREO\nON [Transversal].[DIM_PERSONAL] (CORREO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos GENERO y NIVEL_INGLES\nCREATE NONCLUSTERED INDEX IX_DIM_PERSONAL_GENERO_NIVEL_INGLES\nON [Transversal].[DIM_PERSONAL] (GENERO, NIVEL_INGLES);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_sedes","title":"[DIM_SEDES]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_SEDE</code></p> <ul> <li>Es la clave primaria que asegura la unicidad de cada sede y permite b\u00fasquedas r\u00e1pidas por su identificador.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SEDE</code></p> <ul> <li>Optimiza consultas que filtran o buscan registros por el nombre de la sede, lo cual es com\u00fan en reportes o visualizaciones.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_SEDE\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo SEDE\nCREATE NONCLUSTERED INDEX IX_DIM_SEDES_SEDE\nON [Transversal].[DIM_SEDES] (SEDE);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_servicios","title":"[DIM_SERVICIOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_SERVICIO</code></p> <ul> <li>Es la clave primaria que asegura la unicidad de cada servicio y permite b\u00fasquedas r\u00e1pidas por este identificador.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SERVICIO</code></p> <ul> <li>Optimiza consultas que buscan informaci\u00f3n espec\u00edfica por el nombre del servicio, com\u00fan en reportes y an\u00e1lisis.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CATEGORIA</code> y <code>COD_CATEGORIA</code></p> <ul> <li>Mejora el rendimiento de las consultas que agrupan o filtran servicios por categor\u00eda o c\u00f3digo de categor\u00eda.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ANIO_TARIFA</code> y <code>VAL_TARIFA</code></p> <ul> <li>Facilita las consultas que analizan las tarifas anuales de los servicios.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Permite relacionar eficientemente los servicios con su unidad correspondiente.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>CIUDAD</code> y <code>NOMBRE_ESTABLECIMIENTO</code></p> <ul> <li>Optimiza consultas relacionadas con la ubicaci\u00f3n y establecimiento del servicio.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_SERVICIO\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo SERVICIO\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_SERVICIO\nON [Transversal].[DIM_SERVICIOS] (SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CATEGORIA\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_CATEGORIA\nON [Transversal].[DIM_SERVICIOS] (CATEGORIA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo COD_CATEGORIA\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_COD_CATEGORIA\nON [Transversal].[DIM_SERVICIOS] (COD_CATEGORIA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ANIO_TARIFA y VAL_TARIFA\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_ANIO_VAL_TARIFA\nON [Transversal].[DIM_SERVICIOS] (ANIO_TARIFA, VAL_TARIFA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_ID_UNIDAD\nON [Transversal].[DIM_SERVICIOS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos CIUDAD y NOMBRE_ESTABLECIMIENTO\nCREATE NONCLUSTERED INDEX IX_DIM_SERVICIOS_CIUDAD_ESTABLECIMIENTO\nON [Transversal].[DIM_SERVICIOS] (CIUDAD, NOMBRE_ESTABLECIMIENTO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_unidad","title":"[DIM_UNIDAD]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_UNIDAD</code></p> <ul> <li>Es la clave primaria, garantiza la unicidad de cada unidad y optimiza las b\u00fasquedas por este identificador.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>UNIDAD</code></p> <ul> <li>Facilita las consultas que filtran o buscan datos espec\u00edficos por el nombre de la unidad, com\u00fan en reportes y an\u00e1lisis.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_UNIDAD\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo UNIDAD\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDAD_UNIDAD\nON [Transversal].[DIM_UNIDAD] (UNIDAD);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#dim_unidades_organizativas","title":"[DIM_UNIDADES_ORGANIZATIVAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice cl\u00faster existente para <code>ID_CEBE</code></p> <ul> <li>Es la clave primaria, asegura unicidad y optimiza b\u00fasquedas espec\u00edficas por el identificador de unidad organizativa.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CEBE</code></p> <ul> <li>Facilita b\u00fasquedas r\u00e1pidas y filtrados por el c\u00f3digo de la unidad organizativa (<code>CEBE</code>).</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>DESCRIPCION_BREVE</code> y <code>DESCRIPCION_COMPLETA</code></p> <ul> <li>Acelera las consultas que buscan por descripciones espec\u00edficas o detalladas de la unidad.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>DEPARTAMENTO</code>, <code>AREA</code>, y <code>SUBAREA</code></p> <ul> <li>Optimiza consultas relacionadas con la jerarqu\u00eda organizativa (departamentos, \u00e1reas, sub\u00e1reas).</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>SEGMENTO</code> y <code>DESCRIPCION_SEGMENTO</code></p> <ul> <li>Mejora el rendimiento de consultas segmentadas por estos campos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CODIGO_SSF</code> y <code>NOMBRE_SSF</code></p> <ul> <li>Soporta b\u00fasquedas relacionadas con los c\u00f3digos y nombres del sistema de soporte financiero.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice cl\u00faster ya existente para la clave primaria ID_CEBE\n-- (No requiere creaci\u00f3n adicional)\n\n-- \u00cdndice no cl\u00faster para el campo CEBE\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_CEBE\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (CEBE);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos DESCRIPCION_BREVE y DESCRIPCION_COMPLETA\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_DESCRIPCION\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (DESCRIPCION_BREVE, DESCRIPCION_COMPLETA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos DEPARTAMENTO, AREA y SUBAREA\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_DEPARTAMENTO_AREA\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (DEPARTAMENTO, AREA, SUBAREA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos SEGMENTO y DESCRIPCION_SEGMENTO\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_SEGMENTO\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (SEGMENTO, DESCRIPCION_SEGMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos CODIGO_SSF y NOMBRE_SSF\nCREATE NONCLUSTERED INDEX IX_DIM_UNIDADES_ORGANIZATIVAS_CODIGO_SSF\nON [Transversal].[DIM_UNIDADES_ORGANIZATIVAS] (CODIGO_SSF, NOMBRE_SSF);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_aportes_shr_det","title":"[FACT_APORTES_SHR_DET]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code> y <code>ID_AFILIADO</code></p> <ul> <li>Optimiza las b\u00fasquedas y relaciones con las tablas de dimensiones relacionadas como DIM_EMPRESAS y DIM_AFILIADOS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PERIODO</code></p> <ul> <li>Mejora las consultas que filtran o agrupan por periodos espec\u00edficos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Acelera las b\u00fasquedas y an\u00e1lisis de datos basados en fechas, que suelen ser comunes en tablas de hechos.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>OPBEL</code>, <code>BELNR</code> y <code>MOVIMIENTO</code></p> <ul> <li>Facilita la recuperaci\u00f3n de datos relacionados con transacciones espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_CONTABLE</code> y <code>NUM_CUENTA</code></p> <ul> <li>Optimiza consultas basadas en las cuentas contables y fechas asociadas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>APORTE</code> y <code>INTERES</code></p> <ul> <li>Acelera consultas que analizan montos de aportes e intereses.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>FECHA_ACTUALIZACION</code></p> <ul> <li>Mejora el rendimiento en la detecci\u00f3n de cambios recientes.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para los campos ID_EMPRESA y ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_EMPRESA_AFILIADO\nON [Transversal].[FACT_APORTES_SHR_DET] (ID_EMPRESA, ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo PERIODO\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_PERIODO\nON [Transversal].[FACT_APORTES_SHR_DET] (PERIODO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_FECHA\nON [Transversal].[FACT_APORTES_SHR_DET] (ID_FECHA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos OPBEL, BELNR y MOVIMIENTO\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_TRANSACCION\nON [Transversal].[FACT_APORTES_SHR_DET] (OPBEL, BELNR, MOVIMIENTO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_CONTABLE y NUM_CUENTA\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_CONTABLE_CUENTA\nON [Transversal].[FACT_APORTES_SHR_DET] (FECHA_CONTABLE, NUM_CUENTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos APORTE y INTERES\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_APORTE_INTERES\nON [Transversal].[FACT_APORTES_SHR_DET] (APORTE, INTERES);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo FECHA_ACTUALIZACION\nCREATE NONCLUSTERED INDEX IX_FACT_APORTES_SHR_DET_FECHA_ACTUALIZACION\nON [Transversal].[FACT_APORTES_SHR_DET] (FECHA_ACTUALIZACION);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_convenios","title":"[FACT_CONVENIOS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Acelera consultas basadas en fechas, especialmente aquellas relacionadas con la dimensi\u00f3n de tiempo.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza consultas que filtran por unidad, en relaci\u00f3n con la tabla de dimensi\u00f3n DIM_UNIDAD.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_PROGRAMA</code></p> <ul> <li>Mejora la eficiencia de b\u00fasquedas relacionadas con programas espec\u00edficos, permitiendo una mejor integraci\u00f3n con las consultas de an\u00e1lisis.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code></p> <ul> <li>Facilita consultas que involucren rangos de fechas, comunes en an\u00e1lisis de duraci\u00f3n de convenios.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>VALOR_CONVENIO</code></p> <ul> <li>Acelera consultas que analizan valores monetarios de los convenios.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ESTADO_CONVENIO</code> y <code>MUNICIPIO</code></p> <ul> <li>Permite consultas r\u00e1pidas que filtran por estado y ubicaci\u00f3n de los convenios.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_FECHA\nON [Transversal].[FACT_CONVENIOS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_UNIDAD\nON [Transversal].[FACT_CONVENIOS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_PROGRAMA\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_PROGRAMA\nON [Transversal].[FACT_CONVENIOS] (ID_PROGRAMA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_FECHAS\nON [Transversal].[FACT_CONVENIOS] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo VALOR_CONVENIO\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_VALOR\nON [Transversal].[FACT_CONVENIOS] (VALOR_CONVENIO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ESTADO_CONVENIO y MUNICIPIO\nCREATE NONCLUSTERED INDEX IX_FACT_CONVENIOS_ESTADO_MUNICIPIO\nON [Transversal].[FACT_CONVENIOS] (ESTADO_CONVENIO, MUNICIPIO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_detalle_contable","title":"[FACT_DETALLE_CONTABLE]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CUENTA</code></p> <ul> <li>Facilita consultas y uniones relacionadas con cuentas contables en la dimensi\u00f3n DIM_CUENTA_CONTABLE.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora la eficiencia de consultas relacionadas con la dimensi\u00f3n de tiempo para an\u00e1lisis contable por per\u00edodos.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CEBE</code></p> <ul> <li>Optimiza las b\u00fasquedas relacionadas con unidades organizativas en la dimensi\u00f3n DIM_UNIDADES_ORGANIZATIVAS.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_REGISTRO_SAP</code> y <code>FECHA_PROCESO</code></p> <ul> <li>Acelera las consultas que analizan registros por rangos de fechas o estados de proceso.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>IMPORTE</code> y <code>RESULTADO_EJERCICIO</code></p> <ul> <li>Mejora el rendimiento de an\u00e1lisis de resultados financieros y balances.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_CUENTA\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_ID_CUENTA\nON [Transversal].[FACT_DETALLE_CONTABLE] (ID_CUENTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_ID_FECHA\nON [Transversal].[FACT_DETALLE_CONTABLE] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CEBE\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_ID_CEBE\nON [Transversal].[FACT_DETALLE_CONTABLE] (ID_CEBE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_REGISTRO_SAP y FECHA_PROCESO\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_FECHAS\nON [Transversal].[FACT_DETALLE_CONTABLE] (FECHA_REGISTRO_SAP, FECHA_PROCESO);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos IMPORTE y RESULTADO_EJERCICIO\nCREATE NONCLUSTERED INDEX IX_FACT_DETALLE_CONTABLE_IMPORTE_RESULTADO\nON [Transversal].[FACT_DETALLE_CONTABLE] (IMPORTE, RESULTADO_EJERCICIO);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_encuestas","title":"[FACT_ENCUESTAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora el rendimiento en consultas relacionadas con an\u00e1lisis temporales y de periodos de encuestas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza las consultas relacionadas con unidades y servicios prestados.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_AFILIADO</code>, <code>ID_EMPRESA</code>, <code>ID_BENEFICIARIO</code>, y <code>ID_APORTANTE</code></p> <ul> <li>Cada uno mejora las b\u00fasquedas en las relaciones con las respectivas dimensiones.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code></p> <ul> <li>Acelera consultas espec\u00edficas por identificaci\u00f3n de los encuestados.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>SERVICIO</code> y <code>CALIFICACION</code></p> <ul> <li>Mejora el rendimiento en consultas anal\u00edticas sobre el servicio y su evaluaci\u00f3n.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_FECHA\nON [Transversal].[FACT_ENCUESTAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_UNIDAD\nON [Transversal].[FACT_ENCUESTAS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_AFILIADO\nON [Transversal].[FACT_ENCUESTAS] (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_EMPRESA\nON [Transversal].[FACT_ENCUESTAS] (ID_EMPRESA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_BENEFICIARIO\nON [Transversal].[FACT_ENCUESTAS] (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_ID_APORTANTE\nON [Transversal].[FACT_ENCUESTAS] (ID_APORTANTE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_TIPO_DOCUMENTO_DOCUMENTO\nON [Transversal].[FACT_ENCUESTAS] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo SERVICIO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_SERVICIO\nON [Transversal].[FACT_ENCUESTAS] (SERVICIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_CALIFICACION\nON [Transversal].[FACT_ENCUESTAS] (CALIFICACION);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_encuestas_psr","title":"[FACT_ENCUESTAS_PSR]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora el rendimiento de consultas por fechas y an\u00e1lisis temporales de encuestas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>PROGRAMA</code> y <code>ACTIVIDAD_PREGUNTA</code></p> <ul> <li>Optimiza las b\u00fasquedas y an\u00e1lisis por tipo de programa y actividades asociadas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code></p> <ul> <li>Acelera consultas espec\u00edficas por identificaci\u00f3n de los encuestados.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>CALIFICACION</code></p> <ul> <li>Mejora el rendimiento en consultas que analicen resultados por calificaci\u00f3n.</li> </ul> </li> <li> <p>\u00cdndices no cl\u00faster para <code>ID_AFILIADO</code>, <code>ID_BENEFICIARIO</code>, <code>ID_APORTANTE</code>, y <code>ID_EMPRESA</code></p> <ul> <li>Cada uno optimiza consultas que relacionen la tabla con sus dimensiones correspondientes.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_FECHA\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos PROGRAMA y ACTIVIDAD_PREGUNTA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_PROGRAMA_ACTIVIDAD\nON [Transversal].[FACT_ENCUESTAS_PSR] (PROGRAMA, ACTIVIDAD_PREGUNTA);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos TIPO_DOCUMENTO y DOCUMENTO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_TIPO_DOCUMENTO_DOCUMENTO\nON [Transversal].[FACT_ENCUESTAS_PSR] (TIPO_DOCUMENTO, DOCUMENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo CALIFICACION\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_CALIFICACION\nON [Transversal].[FACT_ENCUESTAS_PSR] (CALIFICACION);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_AFILIADO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_AFILIADO\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_AFILIADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_BENEFICIARIO\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_BENEFICIARIO\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_BENEFICIARIO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_APORTANTE\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_APORTANTE\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_APORTANTE);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_EMPRESA\nCREATE NONCLUSTERED INDEX IX_FACT_ENCUESTAS_PSR_ID_EMPRESA\nON [Transversal].[FACT_ENCUESTAS_PSR] (ID_EMPRESA);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_iniciativas","title":"[FACT_INICIATIVAS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora las consultas basadas en tiempo, como filtrados por fechas de inicio o fin de iniciativas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza las b\u00fasquedas y relaciones con la dimensi\u00f3n de unidades organizativas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_INICIO</code> y <code>FECHA_FIN</code></p> <ul> <li>Facilita las consultas basadas en rangos de fechas para iniciativas activas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>NOMBRE_INICIATIVA</code></p> <ul> <li>Mejora el rendimiento de b\u00fasquedas basadas en el nombre de iniciativas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>OBSERVACIONES</code></p> <ul> <li>Optimiza las b\u00fasquedas por notas o comentarios asociados a las iniciativas.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_ID_FECHA\nON [Transversal].[FACT_INICIATIVAS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_ID_UNIDAD\nON [Transversal].[FACT_INICIATIVAS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos FECHA_INICIO y FECHA_FIN\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_FECHA_INICIO_FIN\nON [Transversal].[FACT_INICIATIVAS] (FECHA_INICIO, FECHA_FIN);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo NOMBRE_INICIATIVA\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_NOMBRE_INICIATIVA\nON [Transversal].[FACT_INICIATIVAS] (NOMBRE_INICIATIVA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo OBSERVACIONES\nCREATE NONCLUSTERED INDEX IX_FACT_INICIATIVAS_OBSERVACIONES\nON [Transversal].[FACT_INICIATIVAS] (OBSERVACIONES);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_pqrs","title":"[FACT_PQRS]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora las consultas basadas en tiempo, como filtros por fechas de creaci\u00f3n, resoluci\u00f3n o vencimiento.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_UNIDAD</code></p> <ul> <li>Optimiza las b\u00fasquedas relacionadas con unidades espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>FECHA_CREACION</code>, <code>FECHA_RESOLUCION</code> y <code>FECHA_VENCIMIENTO</code></p> <ul> <li>Acelera las consultas que involucran rangos de fechas para seguimiento de PQRS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ESTADO</code></p> <ul> <li>Incrementa la eficiencia en consultas relacionadas con el estado de las PQRS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>TIPO_PQRS</code></p> <ul> <li>Facilita la b\u00fasqueda y clasificaci\u00f3n por tipo de PQRS.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>ID_BENEFICIARIO</code>, <code>ID_APORTANTE</code></p> <ul> <li>Optimiza las relaciones con dimensiones relacionadas para an\u00e1lisis detallados.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_ID_FECHA\nON [Transversal].[FACT_PQRS] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_UNIDAD\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_ID_UNIDAD\nON [Transversal].[FACT_PQRS] (ID_UNIDAD);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos de fechas\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_FECHAS\nON [Transversal].[FACT_PQRS] (FECHA_CREACION, FECHA_RESOLUCION, FECHA_VENCIMIENTO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ESTADO\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_ESTADO\nON [Transversal].[FACT_PQRS] (ESTADO);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo TIPO_PQRS\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_TIPO_PQRS\nON [Transversal].[FACT_PQRS] (TIPO_PQRS);\nGO\n\n-- \u00cdndice no cl\u00faster para los campos de dimensiones relacionadas\nCREATE NONCLUSTERED INDEX IX_FACT_PQRS_RELACIONES\nON [Transversal].[FACT_PQRS] (ID_EMPRESA, ID_AFILIADO, ID_BENEFICIARIO, ID_APORTANTE);\nGO\n</code></pre>"},{"location":"01.scripts/09.Index_Transversal/#fact_presupuesto","title":"[FACT_PRESUPUESTO]","text":"<p>Justificaci\u00f3n</p> <ol> <li> <p>\u00cdndice no cl\u00faster para <code>ID_FECHA</code></p> <ul> <li>Mejora la eficiencia en consultas que analizan presupuestos basados en periodos de tiempo.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CUENTA</code></p> <ul> <li>Optimiza la b\u00fasqueda y an\u00e1lisis de presupuestos asociados a cuentas contables espec\u00edficas.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para <code>ID_CEBE</code></p> <ul> <li>Aumenta el rendimiento en consultas relacionadas con unidades organizativas.</li> </ul> </li> <li> <p>\u00cdndice compuesto no cl\u00faster para <code>ID_TIPO_PRESUPUESTO</code> y <code>SEGMENT</code></p> <ul> <li>Facilita el an\u00e1lisis de presupuestos seg\u00fan el tipo y segmento.</li> </ul> </li> <li> <p>\u00cdndice no cl\u00faster para campos relacionados con valores (<code>INGRESOS</code>, <code>GASTOS</code>, <code>COSTOS</code>)</p> <ul> <li>Mejora el rendimiento de c\u00e1lculos financieros basados en estos campos.</li> </ul> </li> </ol> <p>C\u00f3digo</p> <pre><code>-- \u00cdndice no cl\u00faster para el campo ID_FECHA\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_ID_FECHA\nON [Transversal].[FACT_PRESUPUESTO] (ID_FECHA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CUENTA\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_ID_CUENTA\nON [Transversal].[FACT_PRESUPUESTO] (ID_CUENTA);\nGO\n\n-- \u00cdndice no cl\u00faster para el campo ID_CEBE\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_ID_CEBE\nON [Transversal].[FACT_PRESUPUESTO] (ID_CEBE);\nGO\n\n-- \u00cdndice compuesto no cl\u00faster para los campos ID_TIPO_PRESUPUESTO y SEGMENT\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_TIPO_SEGMENT\nON [Transversal].[FACT_PRESUPUESTO] (ID_TIPO_PRESUPUESTO, SEGMENT);\nGO\n\n-- \u00cdndices no cl\u00faster para campos relacionados con valores\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_INGRESOS\nON [Transversal].[FACT_PRESUPUESTO] (INGRESOS, INGRESOS_OPERACIONALES);\nGO\n\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_GASTOS\nON [Transversal].[FACT_PRESUPUESTO] (GASTOS, GASTOS_OPERACIONALES, GASTOS_OPERACIONALES_ADMIN);\nGO\n\nCREATE NONCLUSTERED INDEX IX_FACT_PRESUPUESTO_COSTOS\nON [Transversal].[FACT_PRESUPUESTO] (COSTOS);\nGO\n</code></pre>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/","title":"00. WEB SCRAPING","text":"<p>El contenido proporcionado documenta una amplia variedad de componentes y tareas en una soluci\u00f3n SSIS. Aqu\u00ed se integran scripts de Python como tareas externas para realizar operaciones espec\u00edficas. A continuaci\u00f3n, se detalla la actualizaci\u00f3n del modelo con base en este contenido.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#introduccion","title":"Introducci\u00f3n","text":"<p>El modelo de integraci\u00f3n documentado combina tareas de procesamiento de datos en SSIS con la ejecuci\u00f3n de scripts de Python externos. Estos scripts permiten realizar validaciones avanzadas, procesamiento din\u00e1mico y conexiones con sistemas externos como SharePoint. La soluci\u00f3n garantiza una ejecuci\u00f3n eficiente, flexible y configurable gracias al uso de expresiones del proyecto para adaptar rutas de trabajo y ejecutables a diferentes entornos.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#resumen-general","title":"Resumen General","text":"<p>Objetivos:</p> <ol> <li>Automatizaci\u00f3n: Integrar tareas repetitivas mediante scripts de Python.</li> <li>Estandarizaci\u00f3n: Establecer configuraciones din\u00e1micas para adaptabilidad en entornos variados.</li> <li>Escalabilidad: Dise\u00f1ar un modelo modular para incorporar nuevos flujos.</li> </ol> <p>Componentes Clave:</p> <ul> <li>Scripts Python:<ul> <li>Conexi\u00f3n y extracci\u00f3n desde SharePoint.</li> <li>Procesamiento de datos educativos, administrativos y financieros.</li> </ul> </li> <li>Tareas SSIS:<ul> <li>Ejecuci\u00f3n de scripts externos con configuraciones din\u00e1micas.</li> <li>Validaci\u00f3n y carga en el Data Warehouse.</li> </ul> </li> </ul> <p>Fuentes y Destinos:</p> <ul> <li>Fuentes:<ul> <li>Archivos planos, Excel y bases de datos relacionales.</li> <li>Sistemas externos a trav\u00e9s de scripts Python.</li> </ul> </li> <li>Destinos:<ul> <li>Tablas de hechos y dimensiones en el Data Warehouse <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as Python Executable\n    participant Script as Python Script\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; Python: Ejecuta script con configuraciones din\u00e1micas\n    Python -&gt;&gt; Script: Procesa datos o conecta con sistemas externos\n    Script -&gt;&gt; Python: Devuelve resultado\n    Python -&gt;&gt; SSIS: C\u00f3digo de retorno\n    SSIS -&gt;&gt; DWH: Carga datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#buenas-practicas","title":"Buenas Pr\u00e1cticas","text":"<ol> <li> <p>Configuraci\u00f3n Din\u00e1mica:</p> <ul> <li>Definir ejecutables y directorios mediante variables de proyecto.</li> <li>Adaptar las rutas seg\u00fan los entornos de desarrollo, pruebas y producci\u00f3n.</li> </ul> </li> <li> <p>Registro de Logs:</p> <ul> <li>Capturar la salida de los scripts Python para auditor\u00eda y resoluci\u00f3n de errores.</li> <li>Configurar registros detallados en SSIS.</li> </ul> </li> <li> <p>Compatibilidad:</p> <ul> <li>Validar la versi\u00f3n de Python y las dependencias necesarias para cada script.</li> <li>Probar la ejecuci\u00f3n en entornos similares al de producci\u00f3n.</li> </ul> </li> <li> <p>Ejecuci\u00f3n Segura:</p> <ul> <li>Establecer manejadores para c\u00f3digos de retorno inesperados.</li> <li>Asegurar la idempotencia de los scripts para evitar duplicidades.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-tecnicos","title":"Detalles T\u00e9cnicos","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componentes-principales","title":"Componentes Principales:","text":"<p>1. Ejecuci\u00f3n de Scripts Python:</p> <ul> <li>Propiedades Clave:<ul> <li>Ejecutable: Ruta del ejecutable de Python.</li> <li>Argumentos: Nombre del script y par\u00e1metros adicionales.</li> <li>Directorio de Trabajo: Ruta base configurada din\u00e1micamente.</li> </ul> </li> <li>C\u00f3digo de Retorno:<ul> <li>Configurado para no marcar fallos autom\u00e1ticamente.</li> </ul> </li> </ul> <p>2. Conexiones con Sistemas Externos:</p> <ul> <li>Scripts dedicados para conectar y extraer datos desde SharePoint.</li> <li>Generaci\u00f3n de registros detallados durante el proceso.</li> </ul> <p>3. Tareas de Procesamiento:</p> <ul> <li>Scripts que procesan datos educativos (docentes, matr\u00edculas, egresados).</li> <li>Scripts para consolidar datos operativos (ausencias, ingresos).</li> </ul>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#secuencia-de-operaciones","title":"Secuencia de Operaciones","text":"<ol> <li>Lee el valor de las expresiones del proyecto para determinar el ejecutable y el directorio de trabajo.</li> <li>Construye la instrucci\u00f3n de ejecuci\u00f3n del script.</li> <li>Ejecuta el script en el contexto del directorio especificado.</li> <li>Verifica el c\u00f3digo de retorno para determinar el estado de la tarea, pero no marca como fallo si no es un valor de \u00e9xito.</li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Executable\n    participant Script as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecutar `python.exe archivo_python.py`\n    Python -&gt;&gt; Script: Inicia ejecuci\u00f3n\n    Script -&gt;&gt; Python: Devuelve resultado\n    Python -&gt;&gt; SSIS: C\u00f3digo de retorno (no se fuerza fallo)</code></pre>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#consideraciones","title":"Consideraciones","text":"<ol> <li>Versiones de Python: El ejecutable especificado debe ser compatible con el script, asegurando que las bibliotecas y dependencias est\u00e9n instaladas.</li> <li>Errores en el Script: La tarea no fallar\u00e1 autom\u00e1ticamente si el c\u00f3digo de retorno no es exitoso. Si se requiere manejar este comportamiento, se debe incluir l\u00f3gica adicional en el flujo de trabajo.</li> <li>Configuraci\u00f3n Din\u00e1mica: Las expresiones del proyecto permiten adaptar el ejecutable y el directorio de trabajo seg\u00fan las configuraciones del entorno, facilitando portabilidad y mantenimiento.</li> <li>Control de Log: Configurar un registro adecuado para capturar la salida del script, especialmente si se omiten errores de retorno.</li> </ol> <p>Este componente es ideal para integrar scripts externos de Python en el flujo de ETL de SSIS, proporcionando flexibilidad para realizar tareas avanzadas o espec\u00edficas fuera del entorno nativo de SSIS.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#desarrollo-empresarial","title":"Desarrollo Empresarial","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01-docentes_desarrollo_empresarial","title":"Componente <code>Ejecutar Proceso: 01 Docentes_desarrollo_empresarial</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.Docentes_desarrollo_empresarial.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_docentes","title":"Componente <code>Ejecutar Proceso: emp_Docentes</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_1","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_01_Docentes.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-02preinscritospy","title":"Componente <code>Ejecutar Proceso: 02.Preinscritos.py</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_2","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>02.Preinscritos.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_03_preinscritos","title":"Componente <code>Ejecutar Proceso: emp_03_preinscritos</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_3","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_03_preinscritos.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-03listado_matriculas_emp","title":"Componente <code>Ejecutar Proceso: 03.Listado_matriculas_emp</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_4","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>03.Listado_matriculas_emp.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_02_listado_matriculas","title":"Componente <code>Ejecutar Proceso: emp_02_listado_matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_5","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_02_listado_matriculas.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04consolidado_inasistencias","title":"Componente <code>Ejecutar Proceso: 04.Consolidado_inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_6","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Consolidado_inasistencias.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_06_consolidado_inasistencias","title":"Componente <code>Ejecutar Proceso: emp_06_consolidado_Inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_7","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_06_consolidado_Inasistencias.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-06egresados_graduados_empresarial","title":"Componente <code>Ejecutar Proceso: 06.Egresados_graduados_empresarial</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_8","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>06.Egresados_graduados_empresarial.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_04_egresados_graduados","title":"Componente <code>Ejecutar Proceso: emp_04_egresados_Graduados</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_9","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_04_egresados_Graduados.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-05estudiantes_inasistencias","title":"Componente <code>Ejecutar Proceso: 05.Estudiantes_inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_10","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>05.Estudiantes_inasistencias.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-emp_05_estudiantes_inasistencias","title":"Componente <code>Ejecutar Proceso: emp_05_Estudiantes_inasistencias</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_11","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>emp_05_Estudiantes_inasistencias.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#cedesarrollo","title":"Cedesarrollo","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01docentes_cedesarrollo","title":"Componente <code>Ejecutar Proceso: 01.Docentes_Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_12","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.Docentes_Cedesarrollo.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_01_procesar_docentes","title":"Componente <code>Ejecutar Proceso: cede_01_procesar_docentes</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_13","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_01_procesar_docentes.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-02disenio_curricular","title":"Componente <code>Ejecutar Proceso:  02.Disenio_curricular</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_14","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>02.Disenio_curricular.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_02_procesar_diseno_curricular","title":"Componente <code>Ejecutar Proceso: cede_02_procesar_Dise\u00f1o_Curricular</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_15","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_02_procesar_Dise\u00f1o_Curricular.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-03listado_matriculas","title":"Componente <code>Ejecutar Proceso: 03.Listado_matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_16","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>03.Listado_matriculas.py --semestre True</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_03_procesar_listado_matriculas","title":"Componente <code>Ejecutar Proceso: cede_03_procesar_listado_matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_17","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_03_procesar_listado_matriculas.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04ingresos","title":"Componente <code>Ejecutar Proceso: 04.Ingresos</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_18","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.Ingresos.py --semestre True</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_04_procesar_cede_ingresos","title":"Componente <code>Ejecutar Proceso: cede_04_procesar_cede_Ingresos</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_19","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_04_procesar_cede_Ingresos.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-05historico_notas_cedesarrollo","title":"Componente <code>Ejecutar Proceso: 05.Historico_notas_Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_20","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>05.Historico_notas_Cedesarrollo.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_05_cede_historico_notas","title":"Componente <code>Ejecutar Proceso:  cede_05_cede_Historico_Notas</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_21","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_05_cede_Historico_Notas.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-06egresados_graduados_cedesarrollo","title":"Componente <code>Ejecutar Proceso: 06.Egresados_graduados_Cedesarrollo</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_22","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>06.Egresados_graduados_Cedesarrollo.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_06_cede_egresados_graduados","title":"Componente <code>Ejecutar Proceso: cede_06_cede_Egresados_Graduados</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_23","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_06_cede_Egresados_Graduados.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-07desertorespy","title":"Componente <code>Ejecutar Proceso: 07.Desertores.py</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_24","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_24","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>07.Desertores.py --semestre True</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-cede_07_cancelados_desertores","title":"Componente <code>Ejecutar Proceso: cede_07_Cancelados_Desertores</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_25","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python relacionado con la gesti\u00f3n de componente. El script se ejecuta desde un directorio espec\u00edfico en un entorno configurado para SharePoint.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_25","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta el script de Python <code>cede_07_Cancelados_Desertores.py</code> desde un directorio configurado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos (<code>Arguments</code>): <pre><code>emp_01_Docentes.py\n</code></pre></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\Sharepoint\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python, permitiendo flexibilidad en entornos.</li> <li><code>@[$Project::Working_Directory]</code>: Variable que define la ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#c4c","title":"C4C","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01c4c_webscraping_v4_actualizablepy","title":"Componente <code>Ejecutar Proceso: 01.C4C_webscraping_v4_Actualizable.py</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_26","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_26","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.C4C_webscraping_v4_Actualizable.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#archivos-manuales","title":"Archivos Manuales","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01sharepoint_connection_am-tra-08","title":"Componente <code>Ejecutar Proceso: 01.SharePoint_Connection_AM-TRA-08</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_27","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_27","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.SharePoint_Connection_AM-TRA-08.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-02sharepoint_connection_ep-tra-12","title":"Componente <code>Ejecutar Proceso: 02.SharePoint_Connection_EP-TRA-12</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_28","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_28","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>02.SharePoint_Connection_EP-TRA-12.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-04sharepoint_connection_ep-tra-05","title":"Componente <code>Ejecutar Proceso: 04.SharePoint_Connection_EP-TRA-05</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_29","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_29","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>04.SharePoint_Connection_EP-TRA-05.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-sharepoint_connection_transversal","title":"Componente <code>Ejecutar Proceso: SharePoint_Connection_Transversal</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_30","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_30","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>SharePoint_Connection_Transversal.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-sharepoint_connection_proteccion","title":"Componente <code>Ejecutar Proceso: SharePoint_Connection_Proteccion</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_31","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_31","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>SharePoint_Connection_Proteccion.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#componente-ejecutar-proceso-01sharepoint_connection_am-edf-153","title":"Componente <code>Ejecutar Proceso: 01.SharePoint_Connection_AM-EDF-153</code>","text":""},{"location":"02.Paquetes_SSIS/00-SCRAPING/#descripcion-general_32","title":"Descripci\u00f3n General","text":"<p>Este componente utiliza una tarea de proceso (<code>Execute Process Task</code>) en SSIS para ejecutar un script de Python que realiza operaciones relacionadas con el componente. La ejecuci\u00f3n se lleva a cabo desde una ubicaci\u00f3n de trabajo espec\u00edfica y usa un ejecutable de Python definido en las propiedades del proyecto.</p>"},{"location":"02.Paquetes_SSIS/00-SCRAPING/#detalles-del-componente_32","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar Proceso (Execute Process Task):</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python desde un directorio especificado.</li> <li>Propiedades:<ul> <li>Ejecutable (<code>Executable</code>): <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos (<code>Arguments</code>): <code>01.SharePoint_Connection_AM-EDF-153.py</code></li> <li>Directorio de Trabajo (<code>WorkingDirectory</code>): <pre><code>COMFENALCO_EDUCACION\\01.Scripts\\01.Q10\\02.Educacion_Continua\n</code></pre></li> <li>C\u00f3digo de retorno esperado (<code>FailTaskIfReturnCodeIsNotSuccessValue</code>): <code>False</code> (no falla si el c\u00f3digo de retorno no indica \u00e9xito).</li> </ul> </li> </ul> </li> <li> <p>Expresiones del Proyecto:</p> <ul> <li><code>@[$Project::Python_Executable]</code>: Variable que define la ruta del ejecutable de Python.</li> <li><code>@[$Project::Working_Directory]</code>: Ruta base del directorio de trabajo para los scripts.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/","title":"Introduccion","text":"<p>La presente soluci\u00f3n SSIS constituye un conjunto integral de paquetes ETL cuidadosamente dise\u00f1ados para consolidar, transformar y cargar datos provenientes de fuentes heterog\u00e9neas hacia el Data Warehouse <code>DWH_COMFENALCO</code>. Cada paquete aborda dominios espec\u00edficos, como educaci\u00f3n, protecci\u00f3n social, finanzas y operaciones transversales, maximizando la calidad, consistencia y accesibilidad de los datos con el prop\u00f3sito de sustentar decisiones estrat\u00e9gicas.</p>"},{"location":"02.Paquetes_SSIS/00.params/#resumen-general","title":"Resumen General","text":"<p>Prop\u00f3sitos Estrat\u00e9gicos:</p> <ol> <li>Centralizar y estandarizar datos multisectoriales.</li> <li>Proveer informaci\u00f3n verificada y estructurada para an\u00e1lisis operativos y de inteligencia empresarial.</li> <li>Implementar transformaciones avanzadas que optimicen la confiabilidad y el valor de los datos.</li> </ol> <p>Componentes Fundamentales:</p> <ul> <li>Dimensiones:<ul> <li>Educativas: <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_LIBROS</code>, <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Administrativas: <code>DIM_CUENTA_CONTABLE</code>, <code>DIM_PERSONAL</code>, <code>DIM_INFRAESTRUCTURA_CCF</code>.</li> <li>Temporales: <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Hechos:<ul> <li>Operativos: <code>FACT_TRANSPORTE</code>, <code>FACT_PERMISO_ESTUDIANTE</code>, <code>FACT_DIAGNOSTICOS_EE_JEC</code>.</li> <li>Financieros: <code>FACT_DETALLE_CONTABLE</code>, <code>FACT_CONVENIOS</code>, <code>FACT_PRESUPUESTO</code>.</li> </ul> </li> <li>Automatizaci\u00f3n:<ul> <li>Scripts Python para descargas y validaciones din\u00e1micas.</li> </ul> </li> </ul> <p>Paquetes Principales y Tablas Asociadas:</p> <ol> <li> <p>01-TRANSVERSAL_DIMENSIONES:</p> <ul> <li>Tablas clave: <code>DIM_CUENTA_CONTABLE</code>, <code>DIM_PERSONAL</code>, <code>DIM_INFRAESTRUCTURA_CCF</code>.</li> <li>Fuentes: Archivos Excel y bases de datos SQL Server.</li> </ul> </li> <li> <p>02-TRANSVERSAL_FACT:</p> <ul> <li>Tablas clave: <code>FACT_DETALLE_CONTABLE</code>, <code>FACT_ENCUESTAS_PSR</code>, <code>FACT_INICIATIVAS</code>.</li> <li>Fuentes: Archivos CSV, bases de datos SAP.</li> </ul> </li> <li> <p>03-COLEGIO_DIMENSIONES y 03-COLEGIO_DIMENSIONES_AUXILIAR:</p> <ul> <li>Tablas clave: <code>DIM_CURSO</code>, <code>DIM_GRADO</code>, <code>DIM_PLAN_CURRICULAR</code>.</li> <li>Fuentes: Bases remotas y archivos Excel.</li> </ul> </li> <li> <p>04-COLEGIO_FACT:</p> <ul> <li>Tablas clave: <code>FACT_TRANSPORTE</code>, <code>FACT_CUPOS_NEGADOS</code>, <code>FACT_BIBLIOTECA</code>.</li> <li>Fuentes: Bases SAP y datos operativos.</li> </ul> </li> <li> <p>05-CEDESARROLLO_DIMENSIONES:</p> <ul> <li>Tablas clave: <code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_JORNADA</code>.</li> <li>Fuentes: Archivos Excel y bases SQL Server.</li> </ul> </li> <li> <p>06-CEDESARROLLO_FACT:</p> <ul> <li>Tablas clave: <code>FACT_NOTAS</code>, <code>FACT_TRANSPORTE</code>, <code>FACT_PERMISO_ESTUDIANTE</code>.</li> <li>Fuentes: Bases de datos acad\u00e9micas.</li> </ul> </li> <li> <p>07-PROTECCION_DIMENSIONES y 08-PROTECCION_FACT:</p> <ul> <li>Tablas clave: <code>DIM_PREGUNTAS_EE_JEC</code>, <code>FACT_ENTREGA_MATERIAL</code>, <code>FACT_DESERCION</code>.</li> <li>Fuentes: Archivos planos y bases SQL Server.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#detalles-tecnicos-generales","title":"Detalles T\u00e9cnicos Generales","text":""},{"location":"02.Paquetes_SSIS/00.params/#extraccion-de-datos","title":"Extracci\u00f3n de Datos","text":"<ul> <li>Fuentes Primarias:<ul> <li>Bases SAP y SQL Server.</li> <li>Archivos CSV y Excel.</li> <li>Conexiones SharePoint para datos remotos.</li> </ul> </li> <li>Instrumentos:<ul> <li>ADO.NET para bases estructuradas.</li> <li>Scripts Python para descargas program\u00e1ticas.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#transformaciones","title":"Transformaciones","text":"<ul> <li>Validaciones:<ul> <li>Uso extensivo de <code>Lookup</code> para garantizar integridad referencial.</li> </ul> </li> <li>Transformaciones Especializadas:<ul> <li>Columnas derivadas para claves auxiliares y valores predeterminados.</li> <li>Clasificaci\u00f3n con <code>Conditional Split</code>.</li> <li>Conversi\u00f3n de tipos para alineaci\u00f3n de esquemas.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#carga-de-datos","title":"Carga de Datos","text":"<ul> <li>Tablas de Dimensiones:<ul> <li><code>DIM_CUENTA_CONTABLE</code>, <code>DIM_PROGRAMA</code>, <code>DIM_ESTUDIANTES</code>.</li> </ul> </li> <li>Tablas de Hechos:<ul> <li><code>FACT_TRANSPORTE</code>, <code>FACT_CONVENIOS</code>, <code>FACT_DIAGNOSTICOS_EE_JEC</code>.</li> </ul> </li> <li>Optimizaci\u00f3n:<ul> <li>Inserciones masivas (<code>Bulk Insert</code>) configuradas para alto rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#automatizacion","title":"Automatizaci\u00f3n","text":"<ul> <li>Scripts Python:<ul> <li>Validaciones din\u00e1micas en tiempo de ejecuci\u00f3n.</li> <li>Descarga de archivos con integraci\u00f3n SharePoint.</li> </ul> </li> <li>Procedimientos Almacenados:<ul> <li>Restauraci\u00f3n automatizada de reglas de integridad referencial.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#herramientas-y-tecnologias-utilizadas","title":"Herramientas y Tecnolog\u00edas Utilizadas","text":"<ul> <li>SSIS (SQL Server Integration Services):<ul> <li>Para dise\u00f1ar y ejecutar flujos de datos y procesos de control.</li> </ul> </li> <li>Python:<ul> <li>Automatizaci\u00f3n y validaci\u00f3n de datos mediante scripts personalizados.</li> </ul> </li> <li>ADO.NET:<ul> <li>Conexiones robustas a bases de datos relacionales.</li> </ul> </li> <li>OLE DB:<ul> <li>Lectura y transformaci\u00f3n de datos desde archivos Excel y CSV.</li> </ul> </li> <li>SQL Server:<ul> <li>Plataforma de destino para almacenar datos procesados.</li> </ul> </li> <li>Visual Studio:<ul> <li>Desarrollo y configuraci\u00f3n de paquetes SSIS.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#buenas-practicas","title":"Buenas Pr\u00e1cticas","text":"<ol> <li> <p>Estandarizaci\u00f3n:</p> <ul> <li>Nombrado uniforme para conexiones y componentes.</li> <li>Plantillas comunes en transformaciones y cargas.</li> </ul> </li> <li> <p>Optimizaci\u00f3n:</p> <ul> <li>Configuraci\u00f3n de cach\u00e9 para <code>Lookup</code>.</li> <li>Paralelizaci\u00f3n en flujos intensivos de datos.</li> </ul> </li> <li> <p>Automatizaci\u00f3n:</p> <ul> <li>Scripts Python para minimizar intervenciones manuales.</li> <li>Uso de variables din\u00e1micas para parametrizaci\u00f3n.</li> </ul> </li> <li> <p>Mantenimiento:</p> <ul> <li>Validaciones exhaustivas previas a la carga.</li> <li>Auditor\u00edas peri\u00f3dicas de consistencia.</li> </ul> </li> <li> <p>Seguridad:</p> <ul> <li>Eliminaci\u00f3n temporal de restricciones durante cargas masivas.</li> <li>Restauraci\u00f3n autom\u00e1tica tras completarse las operaciones.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#conclusion","title":"Conclusi\u00f3n","text":"<p>La soluci\u00f3n SSIS documentada constituye un pilar estrat\u00e9gico para la gesti\u00f3n y explotaci\u00f3n de datos organizacionales. Su dise\u00f1o modular y altamente automatizado no solo garantiza eficiencia operativa, sino que tambi\u00e9n habilita a la organizaci\u00f3n para responder \u00e1gilmente a desaf\u00edos futuros. La implementaci\u00f3n de buenas pr\u00e1cticas y recomendaciones adicionales potenciar\u00e1 su valor y sostenibilidad en el tiempo.</p> <p>A continuaci\u00f3n, se presentan diagramas en formato Mermaid que representan flujos de datos y relaciones entre tablas de la soluci\u00f3n SSIS:</p>"},{"location":"02.Paquetes_SSIS/00.params/#diagramas-ssis","title":"Diagramas SSIS","text":""},{"location":"02.Paquetes_SSIS/00.params/#diagrama-de-flujo-de-datos-general","title":"Diagrama de Flujo de Datos (General)","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel/CSV\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extrae datos desde fuentes remotas y locales\n    SSIS -&gt;&gt; Excel: Procesa datos adicionales desde archivos planos\n    SSIS -&gt;&gt; Python: Automatiza tareas de validaci\u00f3n y descarga\n    SSIS -&gt;&gt; DWH: Carga datos procesados en tablas destino</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#diagrama-de-transformaciones-ejemplo-para-dimensiones","title":"Diagrama de Transformaciones (Ejemplo para Dimensiones)","text":"<pre><code>graph TD\n    A1[Datos Crudos de Dimensiones] --&gt; T1[Validaci\u00f3n con Lookup]\n    T1 --&gt; T2[Conversi\u00f3n de Tipos]\n    T2 --&gt; T3[Columnas Derivadas]\n    T3 --&gt; T4[Filtrado con Conditional Split]\n    T4 --&gt; C1[Carga en Tablas de Dimensiones]</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#diagrama-er-para-tablas-de-dimensiones","title":"Diagrama ER para Tablas de Dimensiones","text":"<pre><code>erDiagram\n    DIM_CUENTA_CONTABLE {\n        int ID_CUENTA\n        string CUENTA_NUMERO\n        string DESCRIPCION\n    }\n    DIM_PERSONAL {\n        int ID_PERSONAL\n        string NOMBRE\n        string DIRECCION\n    }\n    DIM_INFRAESTRUCTURA_CCF {\n        int ID_INFRAESTRUCTURA\n        string DESCRIPCION\n    }\n    DIM_SEDES {\n        int ID_SEDE\n        string NOMBRE_SEDE\n    }\n    DIM_TIEMPO {\n        int ID_FECHA\n        date FECHA\n        string DESC_FECHA\n    }\n    DIM_CUENTA_CONTABLE ||--|| DIM_PERSONAL : \"Asociaci\u00f3n por Clave For\u00e1nea\"\n    DIM_INFRAESTRUCTURA_CCF ||--|| DIM_SEDES : \"Relaci\u00f3n Infraestructura-Sede\"\n    DIM_SEDES ||--|| DIM_TIEMPO : \"Relaci\u00f3n Temporal\"</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#diagrama-er-para-tablas-de-hechos-y-dimensiones","title":"Diagrama ER para Tablas de Hechos y Dimensiones","text":"<pre><code>erDiagram\n    FACT_TRANSPORTE {\n        string PARTNER_ESTUDIANTE\n        date FECHA_SERVICIO\n        int ANIO_ACADEMICO\n        string CATEGORIA_SERVICIO\n    }\n    FACT_CUPOS_NEGADOS {\n        string PARTNER_ESTUDIANTE\n        int ANIO_ACADEMICO\n        date FECHA_ESTADO\n    }\n    FACT_BIBLIOTECA {\n        string ITEM_LIBRO\n        date FECHA_PRESTAMO\n        string BP_ESTUDIANTE\n    }\n    FACT_PERMISO_ESTUDIANTE {\n        string BP_ESTUDIANTE\n        date FECHA_PERMISO\n        string MOTIVO\n    }\n    FACT_TRANSPORTE ||--|| FACT_CUPOS_NEGADOS : \"Relaci\u00f3n de estudiantes\"\n    FACT_BIBLIOTECA ||--|| FACT_PERMISO_ESTUDIANTE : \"Conexi\u00f3n por estudiantes\"\n    DIM_ESTUDIANTES ||--|| FACT_TRANSPORTE : \"Detalles de Estudiantes\"\n    DIM_LIBROS ||--|| FACT_BIBLIOTECA : \"Informaci\u00f3n de Libros\"</code></pre>"},{"location":"02.Paquetes_SSIS/00.params/#parametros-clave-en-la-solucion-ssis","title":"Par\u00e1metros Clave en la Soluci\u00f3n SSIS","text":""},{"location":"02.Paquetes_SSIS/00.params/#documentacion-del-archivo-projectparams","title":"Documentaci\u00f3n del Archivo <code>project.params</code>","text":"<p>El archivo <code>project.params</code> es un componente esencial en las soluciones de SQL Server Integration Services (SSIS), dise\u00f1ado para centralizar y administrar los par\u00e1metros utilizados globalmente en los paquetes de la soluci\u00f3n. Su prop\u00f3sito principal es facilitar la configuraci\u00f3n y gesti\u00f3n de variables cr\u00edticas, proporcionando un punto \u00fanico de control para ajustar valores clave sin necesidad de modificar cada paquete individualmente.</p> <p>Los par\u00e1metros definidos en este archivo son utilizados para:</p> <ol> <li> <p>Cadenas de conexi\u00f3n:</p> <ul> <li>Administrar el acceso a bases de datos y servicios externos.</li> <li>Establecer conexiones consistentes y seguras mediante cadenas configuradas que pueden ser reutilizadas en m\u00faltiples paquetes.</li> </ul> </li> <li> <p>Rutas de trabajo:</p> <ul> <li>Definir directorios y ubicaciones clave para archivos de entrada, salida o temporales.</li> <li>Estandarizar las rutas utilizadas en scripts y procesos, reduciendo la posibilidad de errores debido a inconsistencias.</li> </ul> </li> <li> <p>Configuraciones de tiempo de espera:</p> <ul> <li>Establecer valores predeterminados para manejar operaciones que requieren l\u00edmites temporales, como conexiones a bases de datos o transferencias de datos.</li> </ul> </li> <li> <p>Par\u00e1metros sensibles:</p> <ul> <li>Incluir contrase\u00f1as, claves de acceso y otras credenciales protegidas mediante la propiedad <code>Sensitive</code> que oculta estos valores en registros y exportaciones.</li> </ul> </li> <li> <p>Compatibilidad multi-entorno:</p> <ul> <li>Facilitar la portabilidad y configuraci\u00f3n de los paquetes SSIS en diferentes entornos (desarrollo, prueba, producci\u00f3n) mediante valores f\u00e1cilmente ajustables en un \u00fanico archivo.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#ventajas-del-uso-de-projectparams","title":"Ventajas del Uso de <code>project.params</code>","text":"<ol> <li>Centralizaci\u00f3n: Permite un punto \u00fanico de configuraci\u00f3n para par\u00e1metros globales, simplificando la administraci\u00f3n.</li> <li>Flexibilidad: Cambiar valores en el archivo afecta autom\u00e1ticamente todos los paquetes que dependen de estos par\u00e1metros, eliminando la necesidad de ediciones manuales en m\u00faltiples archivos.</li> <li>Estandarizaci\u00f3n: Garantiza consistencia en la configuraci\u00f3n entre paquetes, reduciendo errores y aumentando la mantenibilidad.</li> <li>Seguridad: Los par\u00e1metros sensibles pueden ser protegidos para evitar la exposici\u00f3n de informaci\u00f3n confidencial.</li> </ol>"},{"location":"02.Paquetes_SSIS/00.params/#estructura-del-archivo","title":"Estructura del Archivo","text":"<p>Cada par\u00e1metro en el archivo incluye: - Nombre: Identificador \u00fanico del par\u00e1metro. - Descripci\u00f3n: Informaci\u00f3n opcional que detalla el prop\u00f3sito del par\u00e1metro. - Propiedades clave:   - Sensitive: Indica si el par\u00e1metro contiene informaci\u00f3n sensible que debe ser protegida.   - DataType: Especifica el tipo de dato (e.g., cadena, n\u00famero).   - Valor: El valor asignado al par\u00e1metro, que puede ser una cadena de conexi\u00f3n, ruta, n\u00famero, entre otros.</p> <p>El dise\u00f1o del archivo <code>project.params</code> permite a los equipos de desarrollo y operaciones trabajar de manera eficiente y segura, garantizando que los procesos de integraci\u00f3n de datos sean robustos y escalables.</p>"},{"location":"02.Paquetes_SSIS/00.params/#1-dwh_comfenalco_connectionstring","title":"1. DWH_COMFENALCO_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para la base de datos principal <code>DWH_COMFENALCO</code>, utilizada para operaciones de carga y extracci\u00f3n de datos.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Initial Catalog=DWH_COMFENALCO;Persist Security Info=True;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code> (No contiene informaci\u00f3n sensible).</li> <li>DataType: <code>18</code> (Texto).</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#2-dwh_comfenalco_destino_connectionstring","title":"2. DWH_COMFENALCO_Destino_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para la base de datos de destino <code>DWH_COMFENALCO</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=QCSCONS19;Initial Catalog=DWH_COMFENALCO;Integrated Security=True;Encrypt=False;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#3-dwh_comfenalco_destino_oledb_connectionstring","title":"3. DWH_COMFENALCO_Destino_OLEDB_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n OLEDB para operaciones espec\u00edficas en la base de datos <code>DWH_COMFENALCO</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=QCSCONS19;Initial Catalog=DWH_COMFENALCO;Provider=MSOLEDBSQL.1;Integrated Security=SSPI;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#4-dwh_comfenalco_oledb_connectionstring","title":"4. DWH_COMFENALCO_OLEDB_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n OLEDB para la base de datos principal <code>DWH_COMFENALCO</code>, dise\u00f1ada para compatibilidad con aplicaciones que utilizan este proveedor.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Provider=MSOLEDBSQL.1;Persist Security Info=True;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#5-dwh_comfenalco_oledb_username","title":"5. DWH_COMFENALCO_OLEDB_UserName","text":"<ul> <li>Prop\u00f3sito: Nombre de usuario utilizado para la autenticaci\u00f3n en la conexi\u00f3n OLEDB de <code>DWH_COMFENALCO</code>.</li> <li>Ejemplo de Valor: <code>prov_quality1</code>.</li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#6-python_executable","title":"6. Python_Executable","text":"<ul> <li>Prop\u00f3sito: Ruta al ejecutable de Python que se utiliza en los scripts del proyecto.</li> <li>Ejemplo de Valor:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#7-sap_erp_connectionstring","title":"7. SAP_ERP_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para acceder al sistema SAP ERP.</li> <li>Ejemplo de Valor:   <pre><code>Server=10.5.4.51:30013;User ID=CONSULTAHANA;Database=HEQ;\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#8-stage_area_connectionstring","title":"8. STAGE_AREA_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n para la base de datos <code>STAGE_AREA</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Initial Catalog=STAGE_AREA;Persist Security Info=True;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#9-stage_area_oledb_connectionstring","title":"9. STAGE_AREA_OLEDB_ConnectionString","text":"<ul> <li>Prop\u00f3sito: Cadena de conexi\u00f3n OLEDB para operaciones en <code>STAGE_AREA</code>.</li> <li>Ejemplo de Valor:   <pre><code>Data Source=10.5.21.29\\bi;User ID=prov_quality1;Initial Catalog=STAGE_AREA;Provider=SQLNCLI11.1;...\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#10-stage_area_oledb_username","title":"10. STAGE_AREA_OLEDB_UserName","text":"<ul> <li>Prop\u00f3sito: Nombre de usuario utilizado en la autenticaci\u00f3n para la conexi\u00f3n OLEDB de <code>STAGE_AREA</code>.</li> <li>Ejemplo de Valor: <code>prov_quality1</code>.</li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#11-tiempo_espera_segundos","title":"11. Tiempo_Espera_Segundos","text":"<ul> <li>Prop\u00f3sito: Configuraci\u00f3n del tiempo de espera (en segundos) para operaciones de conexi\u00f3n.</li> <li>Ejemplo de Valor: <code>600</code>.</li> <li>Propiedades Clave:</li> <li>DataType: <code>9</code> (Entero).</li> </ul>"},{"location":"02.Paquetes_SSIS/00.params/#12-working_directory","title":"12. Working_Directory","text":"<ul> <li>Prop\u00f3sito: Directorio de trabajo utilizado para guardar archivos temporales y otros datos procesados por los paquetes de SSIS.</li> <li>Ejemplo de Valor:   <pre><code>\\\n</code></pre></li> <li>Propiedades Clave:</li> <li>Sensitive: <code>0</code>.</li> <li>DataType: <code>18</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/","title":"01. TRANSVERSAL_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#transversal_dimensiones","title":"TRANSVERSAL_DIMENSIONES","text":"<p>El paquete SSIS \"01-TRANSVERSAL_DIMENSIONES\" est\u00e1 dise\u00f1ado para gestionar flujos ETL enfocados en la consolidaci\u00f3n y estructuraci\u00f3n de datos de dimensiones transversales, como cuentas contables, infraestructura, sedes, poblaci\u00f3n educativa, y personal. Este paquete asegura la integraci\u00f3n eficiente de informaci\u00f3n desde m\u00faltiples fuentes en el Data Warehouse <code>DWH_COMFENALCO</code>, permitiendo an\u00e1lisis detallados y toma de decisiones estrat\u00e9gicas.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es centralizar, transformar y cargar datos relacionados con dimensiones transversales que impactan diferentes \u00e1reas operativas, asegurando su consistencia y calidad para an\u00e1lisis en plataformas de inteligencia de negocios.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes utilizadas:<ul> <li>Bases de Datos:<ul> <li><code>DIM_CUENTA_CONTABLE</code></li> <li><code>DIM_UNIDADES_ORGANIZATIVAS</code></li> <li><code>DIM_SEDES</code></li> </ul> </li> <li>Archivos Excel:<ul> <li>Informaci\u00f3n sobre poblaci\u00f3n educativa, infraestructura, y personal.</li> </ul> </li> </ul> </li> <li>Herramientas:<ul> <li>ADO.NET y OLE DB para conexiones eficientes.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Crea claves auxiliares y campos calculados.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Garantiza consistencia mediante b\u00fasquedas en tablas maestras.</li> </ul> </li> <li>Clasificaci\u00f3n (<code>Conditional Split</code>):<ul> <li>Segmentaci\u00f3n de datos seg\u00fan condiciones espec\u00edficas.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad entre columnas de entrada y destino.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_CUENTA_CONTABLE</code></li> <li><code>DIM_PERSONAL</code></li> <li><code>DIM_INFRAESTRUCTURA_CCF</code></li> <li><code>DIM_SEDES</code></li> </ul> </li> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python para integrar flujos de trabajo automatizados y procesar datos de SharePoint.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_CUENTA_CONTABLE:</p> <ul> <li><code>ID_CUENTA</code>: Identificador \u00fanico.</li> <li><code>CUENTA_NUMERO</code>: N\u00famero de cuenta.</li> <li><code>DESCRIPCION</code>: Descripci\u00f3n de la cuenta.</li> </ul> </li> <li> <p>DIM_PERSONAL:</p> <ul> <li><code>ID_PERSONAL</code>: Identificador \u00fanico.</li> <li><code>NOMBRE</code>: Nombre del personal.</li> <li><code>DIRECCION</code>: Direcci\u00f3n.</li> </ul> </li> <li> <p>DIM_INFRAESTRUCTURA_CCF:</p> <ul> <li><code>ID_INFRAESTRUCTURA</code>: Identificador \u00fanico.</li> <li><code>DESCRIPCION</code>: Descripci\u00f3n de la infraestructura.</li> </ul> </li> <li> <p>DIM_SEDES:</p> <ul> <li><code>ID_SEDE</code>: Identificador \u00fanico.</li> <li><code>NOMBRE_SEDE</code>: Nombre de la sede.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extrae datos de cuentas, personal, y sedes\n    SSIS -&gt;&gt; Excel: Procesa datos de infraestructura y poblaci\u00f3n\n    SSIS -&gt;&gt; Python: Ejecuta scripts para descargas\n    SSIS -&gt;&gt; DWH: Carga datos en tablas destino</code></pre> <ol> <li>Diagrama de Transformaciones y Validaciones</li> </ol> <pre><code>graph TD\n    A1[Datos de cuentas y sedes] --&gt; T1[Conversi\u00f3n de Datos]\n    A2[Datos de infraestructura y poblaci\u00f3n] --&gt; T2[Derived Column: Claves Auxiliares]\n    T1 --&gt; L1[Lookup en Tablas Maestras]\n    T2 --&gt; C1[Clasificaci\u00f3n por Condicional Split]\n    L1 --&gt; C2[Cargar datos transformados]</code></pre> <ol> <li>Diagrama ER para Tablas de Dimensiones</li> </ol> <pre><code>erDiagram\n    DIM_CUENTA_CONTABLE {\n        int ID_CUENTA\n        string CUENTA_NUMERO\n        string DESCRIPCION\n    }\n    DIM_PERSONAL {\n        int ID_PERSONAL\n        string NOMBRE\n        string DIRECCION\n    }\n    DIM_INFRAESTRUCTURA_CCF {\n        int ID_INFRAESTRUCTURA\n        string DESCRIPCION\n    }\n    DIM_SEDES {\n        int ID_SEDE\n        string NOMBRE_SEDE\n    }\n    DIM_CUENTA_CONTABLE ||--|| DIM_PERSONAL : \"Asociaci\u00f3n por Clave For\u00e1nea\"\n    DIM_INFRAESTRUCTURA_CCF ||--|| DIM_SEDES : \"Relaci\u00f3n Infraestructura-Sede\"</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-guardar-las-llaves-foraneas","title":"Componente: <code>Guardar las Llaves For\u00e1neas</code>","text":"<p>Prop\u00f3sito Esta tarea dentro de la soluci\u00f3n SSIS tiene como objetivo:</p> <ol> <li> <p>Crear tablas persistentes para almacenar definiciones de llaves for\u00e1neas en varios esquemas: <code>Transversal</code>, <code>Cedesarrollo</code>, <code>Proteccion</code> y <code>Colegio</code>.</p> </li> <li> <p>Insertar las definiciones de llaves for\u00e1neas en las tablas persistentes a partir de la metadata del sistema (<code>sys.foreign_keys</code> y tablas relacionadas).</p> </li> <li> <p>Eliminar restricciones de llaves for\u00e1neas existentes en los esquemas mencionados, prepar\u00e1ndose para un entorno donde no se necesiten dichas restricciones durante procesos espec\u00edficos (e.g., migraci\u00f3n o transformaci\u00f3n de datos).</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-tecnicos","title":"Detalles T\u00e9cnicos","text":"<ol> <li> <p>Tipo de Tarea: </p> <ul> <li><code>Microsoft.ExecuteSQLTask</code> (Tarea Ejecutar SQL).</li> </ul> </li> <li> <p>Descripci\u00f3n:</p> <ul> <li>La tarea ejecuta comandos SQL que realizan varias operaciones en los esquemas <code>Transversal</code>, <code>Cedesarrollo</code>, <code>Proteccion</code> y <code>Colegio</code>.</li> </ul> </li> <li> <p>Identificador de la Tarea:</p> <ul> <li>DTSID: <code>{86fe2b15-f28c-4064-b542-2d2ad2594a04}</code>.</li> </ul> </li> <li> <p>Nombre de la Tarea:</p> <ul> <li><code>Guardar las llaves foraneas</code>.</li> </ul> </li> <li> <p>Conexi\u00f3n Utilizada:</p> <ul> <li>Referenciada por el ID: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-codigo-sql","title":"Descripci\u00f3n del C\u00f3digo SQL","text":"<ol> <li> <p>Creaci\u00f3n de Tablas Persistentes:</p> <ul> <li>Para cada esquema (<code>Transversal</code>, <code>Cedesarrollo</code>, <code>Proteccion</code>, <code>Colegio</code>), se verifica la existencia previa de la tabla y se elimina si ya existe:  <pre><code>IF OBJECT_ID('dbo.ForeignKeys_&lt;Esquema&gt;', 'U') IS NOT NULL\n    DROP TABLE dbo.ForeignKeys_&lt;Esquema&gt;;\n</code></pre></li> <li>Posteriormente, se crea una nueva tabla con la estructura necesaria para almacenar las definiciones de las llaves for\u00e1neas:  <pre><code>CREATE TABLE dbo.ForeignKeys_&lt;Esquema&gt; (\n    TableName NVARCHAR(256),\n    ConstraintName NVARCHAR(256),\n    ColumnName NVARCHAR(256),\n    ReferencedTableName NVARCHAR(256),\n    ReferencedColumnName NVARCHAR(256)\n);\n</code></pre></li> </ul> </li> <li> <p>Inserci\u00f3n de Definiciones de Llaves For\u00e1neas:     .foreign_key_columns<code>,</code>sys.tables<code>,</code>sys.columns<code>,</code>sys.schemas`) y se insertan en las tablas persistentes:     <pre><code>INSERT INTO dbo.ForeignKeys_&lt;Esquema&gt; (TableName, ConstraintName, ColumnName, ReferencedTableName, ReferencedColumnName)\nSELECT \n    t.name AS TableName,\n    f.name AS ConstraintName,\n    c.name AS ColumnName,\n    rt.name AS ReferencedTableName,\n    rc.name AS ReferencedColumnName\nFROM sys.foreign_keys f\nINNER JOIN sys.foreign_key_columns fc ON f.object_id = fc.constraint_object_id\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\n...\nWHERE s.name = '&lt;Esquema&gt;';\n</code></pre></p> </li> <li> <p>Eliminaci\u00f3n de Restricciones de Llaves For\u00e1neas:     Se generan din\u00e1micamente comandos SQL para eliminar todas las restricciones de llaves for\u00e1neas en las tablas de cada esquema:         <pre><code>DECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; '\nFROM sys.foreign_keys f\n...\nWHERE s.name = '&lt;Esquema&gt;';\nEXEC sp_executesql @sql;\n</code></pre></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#esquemas-procesados","title":"Esquemas Procesados","text":"<ol> <li>Transversal.</li> <li>Cedesarrollo.</li> <li>Proteccion.</li> <li>Colegio.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#ventajas-de-la-implementacion","title":"Ventajas de la Implementaci\u00f3n","text":"<ol> <li>Centralizaci\u00f3n de definiciones: Las tablas persistentes almacenan todas las llaves for\u00e1neas en un lugar accesible para auditor\u00edas o referencias futuras.</li> <li>Flexibilidad: Elimina restricciones en los esquemas, permitiendo procesos m\u00e1s \u00e1giles como migraciones de datos.</li> <li>Reutilizaci\u00f3n: La l\u00f3gica puede ser ajustada para nuevos esquemas simplemente actualizando el c\u00f3digo SQL y par\u00e1metros en el SSIS.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-de-datos","title":"Diagrama de flujo de proceso de datos","text":"<pre><code>sequenceDiagram\n    participant SQL_TASK\n    participant TRANSVERSAL_SCHEMA\n    participant CEDESARROLLO_SCHEMA\n    participant PROTECCION_SCHEMA\n    participant COLEGIO_SCHEMA\n\n    SQL_TASK-&gt;&gt;TRANSVERSAL_SCHEMA: Crear tablas y definir llaves for\u00e1neas\n    SQL_TASK-&gt;&gt;CEDESARROLLO_SCHEMA: Crear tablas y definir llaves for\u00e1neas\n    SQL_TASK-&gt;&gt;PROTECCION_SCHEMA: Crear tablas y definir llaves for\u00e1neas\n    SQL_TASK-&gt;&gt;COLEGIO_SCHEMA: Crear tablas y definir llaves for\u00e1neas</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_cuenta_contable","title":"Componente <code>Cargar_DIM_CUENTA_CONTABLE</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Cargar_DIM_CUENTA_CONTABLE</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de cargar datos en la dimensi\u00f3n <code>DIM_CUENTA_CONTABLE</code>. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-y-funcionalidades","title":"Componentes y Funcionalidades","text":"<ol> <li> <p>Variables y Opciones de Registro</p> <ul> <li>No se definen variables espec\u00edficas.</li> <li>Opciones de registro configuradas con <code>DTS:FilterKind=\"0\"</code>.</li> </ul> </li> <li> <p>Pipeline</p> <ul> <li>Versi\u00f3n: 1</li> </ul> </li> <li> <p>Componentes del Pipeline</p> <ul> <li> <p>Conditional Split</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos utilizando expresiones SSIS.</li> <li>Entradas: <ul> <li>Columnas de entrada incluyen <code>CUENTA_NUMERO</code>, <code>CUENTA</code>, <code>CUENTA_HOMOLOGA</code>, <code>DESCRIPCION</code>, <code>TIPO_CUENTA</code>, <code>TIPO_OPERACION</code>, <code>GRUPO_CUENTA</code>, <code>SUBGRUPO_CUENTA</code>, <code>GRUPO_OPERACION</code>, <code>FEC_PROCESO</code>, <code>UDATE</code>, <code>CUENTA_SSF</code>, <code>DESCRIPCION_SSF</code>, <code>NUMERO_PROCESO_SQL</code>, <code>CLASIFICACION</code>, <code>USUARIO_PROCESO</code>, <code>ESTADO_REGISTRO</code>, <code>ID_CUENTA</code>.</li> </ul> </li> <li>Salidas:<ul> <li><code>Agregar</code>: Filtra filas donde <code>ID_CUENTA</code> es nulo.</li> <li><code>Modificar</code>: Filtra filas donde hay diferencias entre las columnas de origen y las columnas de b\u00fasqueda.</li> <li><code>Sin Cambios</code>: Salida por defecto para filas sin cambios.</li> <li><code>Conditional Split Error Output</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Carga datos en una base de datos compatible con ADO.NET.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_CUENTA_CONTABLE\"</code></li> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> <li>Entradas: Columnas de entrada incluyen <code>ID_CUENTA</code>, <code>CUENTA_NUMERO</code>, <code>CUENTA</code>, <code>CUENTA_HOMOLOGA</code>, <code>DESCRIPCION</code>, <code>TIPO_CUENTA</code>, <code>TIPO_OPERACION</code>, <code>GRUPO_CUENTA</code>, <code>SUBGRUPO_CUENTA</code>, <code>GRUPO_OPERACION</code>, <code>FEC_PROCESO</code>, <code>UDATE</code>, <code>CUENTA_SSF</code>, <code>DESCRIPCION_SSF</code>, <code>NUMERO_PROCESO_SQL</code>, <code>CLASIFICACION</code>, <code>USUARIO_PROCESO</code>, <code>ESTADO_REGISTRO</code>.</li> <li>Salidas:<ul> <li><code>Salida de error de destino de ADO NET</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>DIM_CUENTA_CONTABLE_ORIG</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server utilizando una instrucci\u00f3n Transact-SQL.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>SELECT [ID_CUENTA], [CUENTA_NUMERO], [CUENTA], [CUENTA_HOMOLOGA], [DESCRIPCION], [TIPO_CUENTA], [TIPO_OPERACION], [GRUPO_CUENTA], [SUBGRUPO_CUENTA], [GRUPO_OPERACION], [FEC_PROCESO], [UDATE], [CUENTA_SSF], [DESCRIPCION_SSF], [NUMERO_PROCESO_SQL], [CLASIFICACION], [USUARIO_PROCESO], [ESTADO_REGISTRO] FROM [DWH_COMFENALCO].[Financiera].[DIM_CUENTA_CONTABLE]</code></li> <li><code>CommandTimeout</code>: 30</li> <li><code>AllowImplicitStringConversion</code>: true</li> <li><code>TableOrViewName</code>: <code>\"Financiera\".\"DIM_CUENTA_CONTABLE\"</code></li> <li><code>AccessMode</code>: 2</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code></li> <li>Salidas:<ul> <li><code>Salida de origen de ADO NET</code>: Salida principal.</li> <li><code>Salida de error de origen de ADO NET</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda de valores en una tabla para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>SELECT [ID_CUENTA], [CUENTA_NUMERO], [CUENTA], [CUENTA_HOMOLOGA], [DESCRIPCION], [TIPO_CUENTA], [TIPO_OPERACION], [GRUPO_CUENTA], [SUBGRUPO_CUENTA], [GRUPO_OPERACION], [FEC_PROCESO], [UDATE], [CUENTA_SSF], [DESCRIPCION_SSF], [NUMERO_PROCESO_SQL], [CLASIFICACION], [USUARIO_PROCESO], [ESTADO_REGISTRO] FROM [Transversal].[DIM_CUENTA_CONTABLE]</code></li> <li><code>SqlCommandParam</code>: <code>select * from (SELECT [ID_CUENTA], [CUENTA_NUMERO], [CUENTA], [CUENTA_HOMOLOGA], [DESCRIPCION], [TIPO_CUENTA], [TIPO_OPERACION], [GRUPO_CUENTA], [SUBGRUPO_CUENTA], [GRUPO_OPERACION], [FEC_PROCESO], [UDATE], [CUENTA_SSF], [DESCRIPCION_SSF], [NUMERO_PROCESO_SQL], [CLASIFICACION], [USUARIO_PROCESO], [ESTADO_REGISTRO] FROM [Transversal].[DIM_CUENTA_CONTABLE]) [refTable] where [refTable].[ID_CUENTA] = ?</code></li> <li><code>ConnectionType</code>: 0</li> <li><code>CacheType</code>: 0</li> <li><code>NoMatchBehavior</code>: 0</li> <li><code>NoMatchCachePercentage</code>: 0</li> <li><code>MaxMemoryUsage</code>: 25</li> <li><code>MaxMemoryUsage64</code>: 25</li> <li><code>ReferenceMetadataXml</code>: <code>&lt;referenceMetadata&gt;...&lt;/referenceMetadata&gt;</code></li> <li><code>ParameterMap</code>: <code>#{Package\\Cargar_DIM_CUENTA_CONTABLE\\DIM_CUENTA_CONTABLE_ORIG.Outputs[Salida de origen de ADO NET].Columns[ID_CUENTA]};</code></li> <li><code>DefaultCodePage</code>: 1252</li> <li><code>TreatDuplicateKeysAsError</code>: false</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code></li> <li>Entradas: <code>ID_CUENTA</code></li> <li>Salidas:<ul> <li><code>Lookup Match Output</code>: Salida para filas con coincidencias.</li> <li><code>Lookup No Match Output</code>: Salida para filas sin coincidencias.</li> <li><code>Lookup Error Output</code>: Salida de error.</li> </ul> </li> </ul> </li> <li> <p>OLE DB Command</p> <ul> <li>Descripci\u00f3n: Ejecuta una instrucci\u00f3n SQL para cada fila en un flujo de datos.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>SqlCommand</code>: <code>UPDATE [Transversal].[DIM_CUENTA_CONTABLE] SET [CUENTA_NUMERO] = ?, [CUENTA] = ?, [CUENTA_HOMOLOGA] = ?, [DESCRIPCION] = ?, [TIPO_CUENTA] = ?, [TIPO_OPERACION] = ?, [GRUPO_CUENTA] = ?, [SUBGRUPO_CUENTA] = ?, [GRUPO_OPERACION] = ?, [FEC_PROCESO] = ?, [UDATE] = ?, [CUENTA_SSF] = ?, [DESCRIPCION_SSF] = ?, [NUMERO_PROCESO_SQL] = ?, [CLASIFICACION] = ?, [USUARIO_PROCESO] = ?, [ESTADO_REGISTRO] = ? WHERE [ID_CUENTA] = ?</code></li> <li><code>DefaultCodePage</code>: 1252</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code></li> <li>Entradas: Columnas de entrada incluyen <code>CUENTA_NUMERO</code>, <code>CUENTA</code>, <code>CUENTA_HOMOLOGA</code>,      <code>DESCRIPCION</code>, <code>TIPO_CUENTA</code>, <code>TIPO_OPERACION</code>, <code>GRUPO_CUENTA</code>, <code>SUBGRUPO_CUENTA</code>, <code>GRUPO_OPERACION</code>, <code>FEC_PROCESO</code>, <code>UDATE</code>, <code>CUENTA_SSF</code>, <code>DESCRIPCION_SSF</code>, <code>NUMERO_PROCESO_SQL</code>, <code>CLASIFICACION</code>, <code>USUARIO_PROCESO</code>, <code>ESTADO_REGISTRO</code>, <code>ID_CUENTA</code>.</li> <li>Salidas:<ul> <li><code>OLE DB Command Output</code>: Salida principal.</li> <li><code>OLE DB Command Error Output</code>: Salida de error.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Rutas del Pipeline</p> <ul> <li><code>Agregar</code>: Desde <code>Conditional Split.Outputs[Agregar]</code> hasta <code>Destino de ADO NET.Inputs[Entrada de destino de ADO NET]</code>.</li> <li><code>Lookup Match Output</code>: Desde <code>Lookup.Outputs[Lookup Match Output]</code> hasta <code>Conditional Split.Inputs[Conditional Split Input]</code>.</li> <li><code>Modificar</code>: Desde <code>Conditional Split.Outputs[Modificar]</code> hasta <code>OLE DB Command.Inputs[OLE DB Command Input]</code>.</li> <li><code>Salida de origen de ADO NET</code>: Desde <code>DIM_CUENTA_CONTABLE_ORIG.Outputs[Salida de origen de ADO NET]</code> hasta <code>Lookup.Inputs[Lookup Input]</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-proceso-de-datos_1","title":"Diagrama de flujo de proceso de datos","text":"<pre><code>sequenceDiagram\n    participant DIM_CUENTA_CONTABLE_ORIG\n    participant Lookup\n    participant Conditional_Split\n    participant Destino_de_ADO_NET\n    participant OLE_DB_Command\n\n    DIM_CUENTA_CONTABLE_ORIG-&gt;&gt;Lookup: Salida de origen de ADO NET\n    Lookup-&gt;&gt;Conditional_Split: Lookup Match Output\n    Conditional_Split-&gt;&gt;Destino_de_ADO_NET: Agregar\n    Conditional_Split-&gt;&gt;OLE_DB_Command: Modificar</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_unidad-dim_infraestructura_ccf-y-dim_categorias","title":"Componente <code>Cargar_DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIAS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Cargar_DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIAS</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de cargar datos en las dimensiones <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code> y <code>DIM_CATEGORIAS</code>. Esta tarea realiza operaciones de eliminaci\u00f3n, truncado e inserci\u00f3n de datos en las tablas correspondientes del Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{117A40D1-E1F3-4DF6-9457-B49F2D971A3B}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Descripci\u00f3n: Tarea Ejecutar SQL</li> <li>Conexi\u00f3n: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code></li> <li>Declaraciones SQL:<ul> <li>Eliminar restricciones de clave for\u00e1nea en el esquema <code>Transversal</code>.</li> <li>Truncar las tablas <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code> y <code>DIM_CATEGORIAS</code>.</li> <li>Insertar registros en las tablas <code>DIM_UNIDAD</code>, <code>DIM_INFRAESTRUCTURA_CCF</code> y <code>DIM_CATEGORIAS</code>.</li> <li>Insertar un registro para el personal sin datos en la tabla <code>DIM_PERSONAL</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Cargar_DIM_UNIDAD, DIM_INFRAESTRUCTURA_CCF y DIM_CATEGORIAS\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant SQL as Script SQL\n  participant DWH as Data Warehouse\n\n  SSIS-&gt;&gt;SQL: Ejecutar eliminaci\u00f3n de restricciones de clave for\u00e1nea\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de eliminaci\u00f3n\n  SSIS-&gt;&gt;SQL: Ejecutar truncado de tablas\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registros en DIM_UNIDAD\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_UNIDAD\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registros en DIM_INFRAESTRUCTURA_CCF\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_INFRAESTRUCTURA_CCF\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registros en DIM_CATEGORIAS\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_CATEGORIAS\n  SSIS-&gt;&gt;SQL: Ejecutar inserci\u00f3n de registro en DIM_PERSONAL\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n en DIM_PERSONAL</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo","title":"C\u00f3digo","text":"<pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON; -- Configura el manejo est\u00e1ndar de valores nulos.\nGO\nSET QUOTED_IDENTIFIER ON; -- Permite usar comillas dobles para nombres de objetos.\nGO\n\n-- Eliminar restricciones de clave for\u00e1nea del esquema 'Transversal'.\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n\n-- Limpiar las tablas mediante truncado para eliminar datos existentes.\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDAD]; -- Tabla de unidades.\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_INFRAESTRUCTURA_CCF]; -- Infraestructura CCF.\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CATEGORIA]; -- Categor\u00edas.\n\n-- Insertar registros iniciales en la tabla DIM_UNIDAD.\nINSERT INTO [Transversal].[DIM_UNIDAD] (UNIDAD)\nVALUES ('EDUCACI\u00d3N FORMAL'), -- Representa Educaci\u00f3n Formal.\n       ('EDUCACI\u00d3N T\u00c9CNICA'), -- Representa Educaci\u00f3n T\u00e9cnica.\n       ('EDUCACI\u00d3N CONTINUA'), -- Representa Educaci\u00f3n Continua.\n       ('PROTECCI\u00d3N SOCIAL'), -- Representa Protecci\u00f3n Social.\n       ('SIN UNIDAD'); -- Valor predeterminado para datos sin unidad.\n\n-- Insertar registros en DIM_INFRAESTRUCTURA_CCF con valores asociados a unidades espec\u00edficas.\nINSERT INTO [Transversal].[DIM_INFRAESTRUCTURA_CCF] ([COD_INFRAESTRUCTURA_CCF], [DESCRIPCION], [ID_UNIDAD]) VALUES\n('CCF008-12-00001', 'Educaci\u00f3n formal', 1), -- Educaci\u00f3n formal asociada a ID 1.\n('CCF008-13-00001', 'Educaci\u00f3n para el trabajo', 2), -- Educaci\u00f3n t\u00e9cnica asociada a ID 2.\n('CCF008-15-00001', 'Desarrollo empresarial', 3), -- Desarrollo empresarial asociado a ID 3.\n('CCF008-26-00001', 'Protecci\u00f3n social', 4); -- Protecci\u00f3n social asociada a ID 4.\n\n-- Insertar registros en DIM_CATEGORIA con las categor\u00edas disponibles.\nINSERT INTO [Transversal].[DIM_CATEGORIA] ([COD_CATEGORIA], [DESCRIPCION]) VALUES\n('1', 'Categor\u00eda A'), -- Categor\u00eda A.\n('2', 'Categor\u00eda B'), -- Categor\u00eda B.\n('3', 'Categor\u00eda C'), -- Categor\u00eda C.\n('4', 'Categor\u00eda D'), -- Categor\u00eda D.\n('5', 'Empresas'), -- Categor\u00eda para empresas.\n('6', 'Fondos de Ley'), -- Fondos de ley.\n('10', 'Convenios y Facultativos'), -- Convenios.\n('12', 'Empresa no afiliada'); -- Empresas no afiliadas.\n\n-- Insertar un registro en la tabla DIM_PERSONAL para representar datos gen\u00e9ricos o no disponibles.\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] ON; -- Permite insertar valores en la columna IDENTITY.\nINSERT INTO [Transversal].[DIM_PERSONAL] (\n    [ID_PERSONAL], \n    [COD_PERSONA_UNIDAD], \n    [ID_UNIDAD], \n    [SERVICIO], \n    [NOMBRE], \n    [TELEFONO], \n    [CELULAR], \n    [CORREO], \n    [DIRECCION], \n    [CIUDAD], \n    [TIPO_DOCUMENTO], \n    [DOCUMENTO], \n    [FECHA_NACIMIENTO], \n    [GENERO], \n    [HORAS_CONTRATADAS_MENSUAL], \n    [HORAS_CONTRATADAS_TOTALES], \n    [VALOR_TOTAL], \n    [TIPO_CONTRATACION], \n    [FECHA_INICIO_CONTRATACION], \n    [FECHA_FIN_CONTRATACION], \n    [CAUSA_TERMINACION_CONTRATO], \n    [PREGRADO], \n    [POSGRADO_ESPECIALIDAD], \n    [POSGRADO_MAESTRIA], \n    [POSGRADO_DOCTORADO], \n    [NIVEL_INGLES], \n    [AREA]\n) \nVALUES (\n    -1, -- ID predeterminado para datos gen\u00e9ricos.\n    -1, -- C\u00f3digo gen\u00e9rico.\n    5, -- Unidad asociada a \"SIN UNIDAD\".\n    NULL, NULL, NULL, NULL, NULL, NULL, NULL, -- Datos personales no disponibles.\n    'CC', '-1', NULL, NULL, NULL, NULL, NULL, -- Documento y tipo predeterminado.\n    NULL, '1900-01-01', '1900-01-01', NULL, NULL, NULL, NULL, NULL, NULL, NULL\n);\nSET IDENTITY_INSERT [Transversal].[DIM_PERSONAL] OFF; -- Finaliza la inserci\u00f3n de IDENTITY.\nGO\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-limpiar_dim_unidades_organizativas","title":"Componente <code>Limpiar_DIM_UNIDADES_ORGANIZATIVAS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Limpiar_DIM_UNIDADES_ORGANIZATIVAS</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de limpiar la tabla <code>DIM_UNIDADES_ORGANIZATIVAS</code> en el Data Warehouse. Esta tarea realiza operaciones de eliminaci\u00f3n de restricciones de clave for\u00e1nea y truncado de la tabla correspondiente.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea_1","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{047c1578-c938-442e-8b96-1f6a3417d0a2}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Descripci\u00f3n: Tarea Ejecutar SQL</li> <li>Conexi\u00f3n: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code></li> <li>Declaraciones SQL:<ul> <li>Eliminar restricciones de clave for\u00e1nea en el esquema <code>Transversal</code>.</li> <li>Truncar la tabla <code>DIM_UNIDADES_ORGANIZATIVAS</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_1","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Limpiar_DIM_UNIDADES_ORGANIZATIVAS\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant SQL as Script SQL\n  participant DWH as Data Warehouse\n\n  SSIS-&gt;&gt;SQL: Ejecutar eliminaci\u00f3n de restricciones de clave for\u00e1nea\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de eliminaci\u00f3n\n  SSIS-&gt;&gt;SQL: Ejecutar truncado de tabla DIM_UNIDADES_ORGANIZATIVAS\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql","title":"C\u00f3digo SQL","text":"<pre><code>USE DWH_COMFENALCO;\nGO\nSET ANSI_NULLS ON;\nGO\nSET QUOTED_IDENTIFIER ON;\nGO\n\n-- Eliminar restricciones de clave for\u00e1nea\nDECLARE @sql NVARCHAR(MAX) = '';\nSELECT @sql += 'ALTER TABLE ' + QUOTENAME(s.name) + '.' + QUOTENAME(t.name) \n    + ' DROP CONSTRAINT ' + QUOTENAME(f.name) + '; ' \nFROM sys.foreign_keys f\nINNER JOIN sys.tables t ON f.parent_object_id = t.object_id\nINNER JOIN sys.schemas s ON t.schema_id = s.schema_id\nWHERE s.name = 'Transversal';\nEXEC sp_executesql @sql;\n\n-- Truncar tabla DIM_UNIDADES_ORGANIZATIVAS\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_UNIDADES_ORGANIZATIVAS];\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_unidades_organizativas","title":"Componente <code>Cargar_DIM_UNIDADES_ORGANIZATIVAS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Cargar_DIM_UNIDADES_ORGANIZATIVAS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de cargar datos en la tabla <code>DIM_UNIDADES_ORGANIZATIVAS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Cargar_DIM_UNIDADES_ORGANIZATIVAS</code></li> <li>DTSID: <code>{2b52324e-63da-4f09-aadd-80b248ece527}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen de Datos ADO.NET (<code>DIM_UNIDADES_ORGANIZATIVAS_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server, OLE DB, ODBC u Oracle mediante el correspondiente proveedor de datos de .NET Framework.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_CEBE], [CEBE], [DESCRIPCION_BREVE], [DESCRIPCION_COMPLETA], [DEPARTAMENTO], [AREA], [SUBAREA], [SEGMENTO], [DESCRIPCION_SEGMENTO], [CODIGO_SSF], [NOMBRE_SSF], [UDATE], [NUMERO_PROCESO_SQL], [FEC_PROCESO], [USUARIO_PROCESO], [GRUPO_CEBE], \nCASE \n    WHEN [DEPARTAMENTO] = 'EDUCACION FORMAL' THEN 1\n    WHEN [DEPARTAMENTO] = 'EDUCACION PARA EL TRABAJO' THEN 2\n    WHEN [DEPARTAMENTO] = 'DESARROLLO EMPRESARIAL' THEN 3\n    WHEN [DEPARTAMENTO] = 'PROGRAMAS Y CONVENIOS ESPECIALES' AND [AREA] IN ('Adulto Mayor', 'Discapacidad', 'Atencion integral a la Ninez', 'Jornada Escolar Complementaria') THEN 4\n    ELSE 5\nEND AS [ID_UNIDAD]\nFROM [DWH_COMFENALCO].[Financiera].[DIM_UNIDADES_ORGANIZATIVAS]\nWHERE DEPARTAMENTO IN ('EDUCACION FORMAL', 'EDUCACION PARA EL TRABAJO', 'DESARROLLO EMPRESARIAL')\nOR (DEPARTAMENTO IN ('PROGRAMAS Y CONVENIOS ESPECIALES') AND AREA IN ('Adulto Mayor', 'Discapacidad','Atencion integral a la Ninez','Jornada Escolar Complementaria'))\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>AllowImplicitStringConversion</code>: <code>true</code></li> <li><code>TableOrViewName</code>: <code>\"Financiera\".\"DIM_CUENTA_CONTABLE\"</code></li> <li><code>AccessMode</code>: <code>2</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_CEBE</code>, <code>CEBE</code>, <code>DESCRIPCION_BREVE</code>, <code>DESCRIPCION_COMPLETA</code>, <code>DEPARTAMENTO</code>, <code>AREA</code>, <code>SUBAREA</code>, <code>SEGMENTO</code>, <code>DESCRIPCION_SEGMENTO</code>, <code>CODIGO_SSF</code>, <code>NOMBRE_SSF</code>, <code>UDATE</code>, <code>NUMERO_PROCESO_SQL</code>, <code>FEC_PROCESO</code>, <code>USUARIO_PROCESO</code>, <code>GRUPO_CEBE</code></li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_UNIDADES_ORGANIZATIVAS_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en una base de datos compatible con ADO.NET que use una vista o tabla de base de datos.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_UNIDADES_ORGANIZATIVAS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_CEBE</code>, <code>CEBE</code>, <code>DESCRIPCION_BREVE</code>, <code>DESCRIPCION_COMPLETA</code>, <code>DEPARTAMENTO</code>, <code>AREA</code>, <code>SUBAREA</code>, <code>SEGMENTO</code>, <code>DESCRIPCION_SEGMENTO</code>, <code>CODIGO_SSF</code>, <code>NOMBRE_SSF</code>, <code>UDATE</code>, <code>NUMERO_PROCESO_SQL</code>, <code>FEC_PROCESO</code>, <code>USUARIO_PROCESO</code>, <code>GRUPO_CEBE</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-descargar_am-tra-08","title":"Componente <code>Descargar_AM-TRA-08</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_AM-TRA-08</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para la conexi\u00f3n a SharePoint y la descarga de archivos manuales.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_1","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_1","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Descargar_AM-TRA-08</code></li> <li>DTSID: <code>{16C2FBC1-E5C9-472A-BE1E-3575DAEF56C3}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar proceso</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteProcess</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Executable: <code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>01.SharePoint_Connection_AM-TRA-08.py</code></li> <li>WorkingDirectory: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_2","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Descargar_AM-TRA-08\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Script as Script Python\n    participant SharePoint as SharePoint\n\n    SSIS-&gt;&gt;Script: Ejecutar 01.SharePoint_Connection_AM-TRA-08.py\n    Script-&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de conexi\u00f3n\n    Script-&gt;&gt;SharePoint: Descargar archivos manuales\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de descarga\n    Script--&gt;&gt;SSIS: Proceso completado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_servicios","title":"Componente <code>Procesar_DIM_SERVICIOS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_SERVICIOS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_TARIFAS_SERVICIOS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_2","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_2","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_SERVICIOS</code></li> <li>DTSID: <code>{0EC61E46-C061-4440-8E8D-2704CC9AD0D4}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>AM-TRA-08_Manual_Tarifario</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: <code>0</code></li> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[Excel_Connection_Dim_Servicios]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ANIO_TARIFA</code>, <code>COD_INFRAESTRUCTURA_CCF</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>COD_CATEGORIA</code>, <code>VAL_TARIFA</code>, <code>COD_SERVICIO</code></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Verificar Tipos de Datos</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> <li>Columnas de Entrada:     <code>ANIO_TARIFA</code>, <code>COD_INFRAESTRUCTURA_CCF</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>COD_CATEGORIA</code>, <code>VAL_TARIFA</code>, <code>COD_SERVICIO</code></li> <li>Columnas de Salida:     <code>ANIO_TARIFA_v</code>, <code>COD_INFRAESTRUCTURA_CCF_v</code>, <code>CON_OBJETO_TARIFA_v</code>, <code>COS_UNITARIO_CONCEPTO_v</code>, <code>COD_CATEGORIA_v</code>, <code>VAL_TARIFA_v</code>, <code>COD_SERVICIO_v</code></li> </ul> </li> <li> <p>Columna Derivada (<code>Crear ID_SERVICIO_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_TARIFA_AUXILIAR</code> concatenando varias columnas de entrada.</li> <li>Columnas de Entrada:<ul> <li><code>ANIO_TARIFA_v</code></li> <li><code>COD_INFRAESTRUCTURA_CCF_v</code></li> <li><code>COD_SERVICIO_v</code></li> <li><code>COD_CATEGORIA_v</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_TARIFAS_SERVICIOS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>select * from [Transversal].[DIM_TARIFAS_SERVICIOS]</code></li> <li><code>SqlCommandParam</code>: <code>select * from (select * from [Transversal].[DIM_TARIFAS_SERVICIOS]) [refTable] where [refTable].[ID_TARIFA_AUXILIAR] = ?</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>COD_SERVICIO</code>, <code>CON_OBJETO_TARIFA</code>, <code>COS_UNITARIO_CONCEPTO</code>, <code>VAL_TARIFA</code>, <code>COD_CATEGORIA</code></li> <li><code>ANIO_TARIFA</code>,  <code>COD_INFRAESTRUCTURA_CCF</code>, <code>ID_TARIFA</code>, <code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_TARIFA_AUXILIAR</code></li> </ul> </li> <li>Salidas:<ul> <li><code>Agregar</code>: Filas donde <code>ID_TARIFA_AUXILIAR</code> es nulo.</li> <li><code>Sin Cambios</code>: Filas donde <code>ID_TARIFA_AUXILIAR</code> no es nulo.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_SERVICIOS_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_TARIFAS_SERVICIOS</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_TARIFAS_SERVICIOS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>COD_SERVICIO_v</code>, <code>CON_OBJETO_TARIFA_v</code>, <code>COS_UNITARIO_CONCEPTO_v</code>, <code>VAL_TARIFA_v</code>, <code>COD_CATEGORIA_v</code>, <code>ANIO_TARIFA_v</code>, <code>COD_INFRAESTRUCTURA_CCF_v</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-cargar_dim_sedes","title":"Componente <code>Cargar_DIM_SEDES</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente <code>Cargar_DIM_SEDES</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de truncar y cargar datos en la tabla <code>DIM_SEDES</code> en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_3","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_3","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Cargar_DIM_SEDES</code></li> <li>DTSID: <code>{fbd7f70d-08d3-4da5-a641-f28f431909b7}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar SQL</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteSQLTask</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_1","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Connection: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_1","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>SQL Statement:   <pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_SEDES];\nINSERT INTO [Transversal].[DIM_SEDES] (SEDE)\nVALUES ('CEC'), ('CEDESARROLLO');\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_3","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Cargar_DIM_SEDES\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant SQL as Base de Datos SQL\n\n    SSIS-&gt;&gt;SQL: TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_SEDES]\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n    SSIS-&gt;&gt;SQL: INSERT INTO [Transversal].[DIM_SEDES] (SEDE) VALUES ('CEC'), ('CEDESARROLLO')\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso","title":"Descripci\u00f3n del Proceso","text":"<ol> <li>Truncar Tabla: La tarea ejecuta una instrucci\u00f3n SQL para truncar la tabla <code>DIM_SEDES</code>, eliminando todos los registros existentes.</li> <li>Insertar Datos: La tarea ejecuta una instrucci\u00f3n SQL para insertar nuevos registros en la tabla <code>DIM_SEDES</code> con los valores <code>'CEC'</code> y <code>'CEDESARROLLO'</code>.</li> </ol> <p>Este proceso asegura que la tabla <code>DIM_SEDES</code> se actualice con los datos m\u00e1s recientes, eliminando cualquier dato anterior y cargando los nuevos valores especificados.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-descargar_ep-tra-12","title":"Componente <code>Descargar_EP-TRA-12</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_EP-TRA-12</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para la conexi\u00f3n a SharePoint y la descarga de archivos manuales.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_4","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_4","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Descargar_EP-TRA-12</code></li> <li>DTSID: <code>{56e49c08-d0c9-4678-8e9c-27288db94c3b}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar proceso</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteProcess</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_2","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Executable: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_2","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>02.SharePoint_Connection_EP-TRA-12.py</code></li> <li>WorkingDirectory: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_4","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Descargar_EP-TRA-12\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Script as Script Python\n    participant SharePoint as SharePoint\n\n    SSIS-&gt;&gt;Script: Ejecutar 02.SharePoint_Connection_EP-TRA-12.py\n    Script-&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de conexi\u00f3n\n    Script-&gt;&gt;SharePoint: Descargar archivos manuales\n    SharePoint--&gt;&gt;Script: Confirmaci\u00f3n de descarga\n    Script--&gt;&gt;SSIS: Proceso completado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-del-proceso_1","title":"Descripci\u00f3n del Proceso","text":"<ol> <li>Ejecutar Script Python: La tarea ejecuta el script <code>02.SharePoint_Connection_EP-TRA-12.py</code> utilizando el int\u00e9rprete de Python especificado.</li> <li>Conectar a SharePoint: El script se conecta a SharePoint para acceder a los archivos manuales.</li> <li>Descargar Archivos: El script descarga los archivos manuales desde SharePoint al directorio de trabajo especificado.</li> <li>Confirmaci\u00f3n de Descarga: El script confirma la descarga exitosa de los archivos y finaliza el proceso.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_capacidad_fisica","title":"Componente <code>Procesar_DIM_CAPACIDAD_FISICA</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_CAPACIDAD_FISICA</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_CAPACIDAD_FISICA</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_5","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_5","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_CAPACIDAD_FISICA</code></li> <li>DTSID: <code>{592bbecc-5b7f-44ef-b177-462c29ca7233}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>EP-TRA-12_Capacidad Fisica</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: <code>0</code></li> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[Excel_Connection_Dim_Capacidad]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>JORNADA</code>, <code>DESCRIPCION_ESPACIO</code>, <code>ID_UNIDAD</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> <li> <p>Columnas de Entrada:     <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>JORNADA</code>, <code>DESCRIPCION_ESPACIO</code>, <code>ID_UNIDAD</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code></p> </li> <li> <p>Columnas de Salida:     <code>Copy of ID_SALON</code>, <code>Copy of CAPACIDAD</code>, <code>Copy of JORNADA</code>, <code>Copy of DESCRIPCION_ESPACIO</code>, <code>Copy of ID_UNIDAD</code>, <code>Copy of BLOQUE</code>, <code>Copy of GRUPO</code>, <code>Copy of ID_SEDE</code>, <code>Copy of SEDE</code>, <code>Copy of ESTADO</code>, <code>Copy of FECHA_ESTADO</code></p> </li> </ul> </li> <li> <p>Columna Derivada (<code>Crear_ID_CAPACIDAD_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_CAPACIDAD_AUXILIAR</code> concatenando varias columnas de entrada.</li> <li>Columnas de Entrada:     <code>Copy of ID_SALON</code>,  <code>Copy of JORNADA</code>, <code>Copy of ID_UNIDAD</code></li> <li>Columnas de Salida:     <code>ID_CAPACIDAD_AUXILIAR</code></li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_CAPACIDAD_FISICA</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>: <code>select * from [Transversal].[DIM_CAPACIDAD_FISICA]</code></li> <li><code>SqlCommandParam</code>: <code>select * from (select * from [Transversal].[DIM_CAPACIDAD_FISICA]) [refTable] where [refTable].[ID_CAPACIDAD_AUXILIAR] = ?</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_CAPACIDAD_AUXILIAR</code></li> <li>Columnas de Salida:     <code>ID_CAPACIDAD</code>, <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>DESCRIPCION_ESPACIO</code>, <code>JORNADA</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_UNIDAD</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code>, <code>ID_CAPACIDAD_AUXILIAR</code></li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li> <p>Columnas de Entrada:     <code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>JORNADA</code>, <code>DESCRIPCION_ESPACIO</code>, <code>ID_UNIDAD</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code>, <code>ID_CAPACIDAD</code></p> </li> <li> <p>Salidas:</p> <ul> <li><code>Agregar</code>: Filas donde <code>ID_CAPACIDAD</code> es nulo.</li> <li><code>Modificar</code>: Filas donde hay diferencias entre las columnas de entrada y las columnas de b\u00fasqueda.</li> <li><code>Sin Cambios</code>: Filas donde no hay diferencias.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_CAPACIDAD_FISICA_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_CAPACIDAD_FISICA</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_CAPACIDAD_FISICA\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>Copy of ID_SALON</code>, <code>Copy of CAPACIDAD</code>, <code>Copy of DESCRIPCION_ESPACIO</code>, <code>Copy of JORNADA</code>, <code>Copy of BLOQUE</code>, <code>Copy of GRUPO</code>, <code>Copy of ID_UNIDAD</code>, <code>Copy of ID_SEDE</code>, <code>Copy of SEDE</code>, <code>Copy of ESTADO</code>, <code>Copy of FECHA_ESTADO</code></li> </ul> </li> <li> <p>Comando OLE DB (<code>OLE DB Command 1</code>)</p> <ul> <li>Descripci\u00f3n: Ejecuta una instrucci\u00f3n SQL para cada fila en el flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>UPDATE [Transversal].[DIM_CAPACIDAD_FISICA]\n   SET [ID_SALON] = ?\n      ,[CAPACIDAD] = ?\n      ,[DESCRIPCION_ESPACIO] = ?\n      ,[JORNADA] = ?\n      ,[BLOQUE] = ?\n      ,[GRUPO] = ?\n      ,[ID_UNIDAD] = ?\n      ,[ID_SEDE] = ?\n      ,[SEDE] = ?\n      ,[ESTADO] = ?\n      ,[FECHA_ESTADO] = ?\n WHERE [ID_CAPACIDAD] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_SALON</code>, <code>CAPACIDAD</code>, <code>DESCRIPCION_ESPACIO</code>, <code>JORNADA</code>, <code>BLOQUE</code>, <code>GRUPO</code>, <code>ID_UNIDAD</code>, <code>ID_SEDE</code>, <code>SEDE</code>, <code>ESTADO</code>, <code>FECHA_ESTADO</code>, <code>ID_CAPACIDAD</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as EP-TRA-12_Capacidad Fisica\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Crear_ID_CAPACIDAD_AUXILIAR\n    participant Lookup as Lookup\n    participant ConditionalSplit as Conditional Split\n    participant AdoNetDestination as DIM_CAPACIDAD_FISICA_DEST\n    participant OleDbCommand as OLE DB Command 1\n\n    ExcelSource -&gt;&gt; DataConversion: Excel Source Output\n    DataConversion -&gt;&gt; DerivedColumn: Data Conversion Output\n    DerivedColumn -&gt;&gt; Lookup: Derived Column Output\n    Lookup -&gt;&gt; ConditionalSplit: Lookup Match Output\n    ConditionalSplit -&gt;&gt; AdoNetDestination: Agregar\n    ConditionalSplit -&gt;&gt; OleDbCommand: Modificar</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componende-agregar-registros-con-id-1-para-tablas-de-poblacion","title":"Componende <code>Agregar registros con ID -1 para tablas de poblaci\u00f3n</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion","title":"Descripci\u00f3n","text":"<p>Este proceso en la soluci\u00f3n SSIS se encarga de agregar registros con el ID <code>-1</code> en las tablas de poblaci\u00f3n. Este ID se utiliza para representar datos gen\u00e9ricos o no disponibles en las tablas de destino.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-proceso","title":"Detalles del Proceso","text":"<ol> <li>Truncar Tabla: Se ejecuta una instrucci\u00f3n SQL para truncar las tablas de poblaci\u00f3n, eliminando todos los registros existentes.</li> <li>Insertar Datos: Se ejecuta una instrucci\u00f3n SQL para insertar nuevos registros en las tablas de poblaci\u00f3n con el ID <code>-1</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_5","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Agregar registros con ID -1 para tablas de poblaci\u00f3n\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant SQL as Script SQL\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;SQL: Ejecutar truncado de tablas de poblaci\u00f3n\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado\n    SSIS-&gt;&gt;SQL: Insertar registros con ID -1 en tablas de poblaci\u00f3n\n    SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de inserci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_1","title":"C\u00f3digo SQL","text":"<pre><code>-- Truncar tablas de poblaci\u00f3n\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_POBLACION];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_ESTABLECIMIENTO_EDUCATIVO];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_PROGRAMA];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_CAMPOS_CARACT];\n\n-- Insertar registros con ID -1\nINSERT INTO [Transversal].[DIM_POBLACION] (ID_POBLACION, TIPO_DOCUMENTO, DOCUMENTO)\nVALUES (-1, 'N/A', 'N/A');\n\nINSERT INTO [Transversal].[DIM_ESTABLECIMIENTO_EDUCATIVO] (ID_ESTABLECIMIENTO_EDUCATIVO, NOMBRE_ESTABLECIMIENTO)\nVALUES (-1, 'N/A');\n\nINSERT INTO [Transversal].[DIM_PROGRAMA] (ID_PROGRAMA, PROGRAMA)\nVALUES (-1, 'N/A');\n\nINSERT INTO [Transversal].[DIM_CAMPOS_CARACT] (ID_PREGUNTA, PREGUNTA)\nVALUES (-1, 'N/A');\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-vaciar-tabla-temporal-de-poblacion-educacion","title":"Componente <code>Vaciar tabla temporal de Poblacion Educacion</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Vaciar tabla temporal de Poblacion Educacion</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de vaciar la tabla temporal <code>TMP_POBLACION_EDUCACION</code> en el Data Warehouse. Esta tarea realiza una operaci\u00f3n de truncado en la tabla correspondiente.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea_2","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{C1C8514E-6B9D-448B-B2C4-085047066756}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Descripci\u00f3n: Tarea Ejecutar SQL</li> <li>Conexi\u00f3n: <code>{878C9AA8-681C-4799-9C30-34C49CD01857}</code></li> <li>Declaraci\u00f3n SQL:<ul> <li>Truncar la tabla <code>TMP_POBLACION_EDUCACION</code> en el esquema <code>Transversal</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_6","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Vaciar tabla temporal de Poblacion Educacion\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant SQL as Script SQL\n  participant DWH as Data Warehouse\n\n  SSIS-&gt;&gt;SQL: Ejecutar truncado de tabla TMP_POBLACION_EDUCACION\n  SQL--&gt;&gt;SSIS: Confirmaci\u00f3n de truncado</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#codigo-sql_2","title":"C\u00f3digo SQL","text":"<pre><code>TRUNCATE TABLE [Transversal].[TMP_POBLACION_EDUCACION];\n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-poblacion-prs","title":"Componente <code>Procesar Poblacion PRS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Procesar Poblacion PRS</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para procesar la poblaci\u00f3n PRS. Esta tarea utiliza el ejecutable de Python y un script espec\u00edfico para realizar el procesamiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea_3","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{7f11d36d-f826-44f0-8b89-e04825763509}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteProcess</code></li> <li>Descripci\u00f3n: Tarea Ejecutar proceso</li> <li>Conexi\u00f3n: No aplica (ejecuci\u00f3n de proceso)</li> <li>Propiedades del Componente:<ul> <li>Executable: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_3","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>03.PoblacionProteccion.py</code></li> <li>WorkingDirectory: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_7","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de Procesar Poblacion PRS\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant Python as Script Python\n  participant FileSystem as Sistema de Archivos\n\n  SSIS-&gt;&gt;Python: Ejecutar script 03.PoblacionProteccion.py\n  Python--&gt;&gt;FileSystem: Leer y procesar datos\n  FileSystem--&gt;&gt;Python: Datos procesados\n  Python--&gt;&gt;SSIS: Confirmaci\u00f3n de ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-dim_estudiantes-py","title":"Componente <code>dim_Estudiantes py</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>La tarea <code>dim_Estudiantes py</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para procesar los datos de estudiantes. Esta tarea utiliza el ejecutable de Python y un script espec\u00edfico para realizar el procesamiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-tarea_4","title":"Detalles de la Tarea","text":"<ul> <li>ID de la Tarea: <code>{1c51612a-04dc-4abf-a64a-07ed112b11f8}</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteProcess</code></li> <li>Descripci\u00f3n: Tarea Ejecutar proceso</li> <li>Conexi\u00f3n: No aplica (ejecuci\u00f3n de proceso)</li> <li>Propiedades del Componente:<ul> <li>Executable: <code>@[$Project::Python_Executable]</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-de-la-ejecucion_4","title":"Detalles de la Ejecuci\u00f3n","text":"<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>dim_Estudiantes.py</code></li> <li>WorkingDirectory: <code>\\\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_8","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n  title Diagrama de Secuencia del Proceso ETL de dim_Estudiantes py\n  autonumber\n  participant SSIS as Tarea SSIS\n  participant Python as Script Python\n  participant FileSystem as Sistema de Archivos\n\n  SSIS-&gt;&gt;Python: Ejecutar script dim_Estudiantes.py\n  Python--&gt;&gt;FileSystem: Leer y procesar datos\n  FileSystem--&gt;&gt;Python: Datos procesados\n  Python--&gt;&gt;SSIS: Confirmaci\u00f3n de ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-identificar-poblacion-educacion","title":"Componente <code>Identificar Poblacion Educaci\u00f3n</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>El componente <code>Identificar Poblacion Educaci\u00f3n</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos relacionados con la poblaci\u00f3n educativa. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_6","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_6","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Identificar Poblacion Educaci\u00f3n</code></li> <li>DTSID: <code>{766D28A8-4CDF-4AA7-AF8A-444788C5A74F}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Matriculas_Cedesarrollo</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: <code>0</code></li> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[Excel_Connection_Dim_Estudiantes]</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos Excel (<code>Poblacion PRS</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: <code>0</code></li> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Package.ConnectionManagers[Administrador de conexiones con Excel]</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos ADO.NET (<code>Estudiantes Colegio</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una base de datos SQL Server.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [TIPO_DOCUMENTO], [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion 1</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Copy of TIPO_DOCUMENTO</code></li> <li><code>Copy of DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Ordenaci\u00f3n (<code>Sort 1</code>)</p> <ul> <li>Descripci\u00f3n: Ordena los datos de entrada.</li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Ordenaci\u00f3n (<code>Sort 2</code>)</p> <ul> <li>Descripci\u00f3n: Ordena los datos de entrada.</li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Ordenaci\u00f3n (<code>Sort</code>)</p> <ul> <li>Descripci\u00f3n: Ordena los datos de entrada.</li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Combinaci\u00f3n (<code>Merge 1</code>)</p> <ul> <li>Descripci\u00f3n: Combina filas de m\u00faltiples flujos de datos ordenados en un solo flujo de datos ordenado.</li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Combinaci\u00f3n (<code>Merge</code>)</p> <ul> <li>Descripci\u00f3n: Combina filas de m\u00faltiples flujos de datos ordenados en un solo flujo de datos ordenado.</li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_TIPO_DOCUMENTO</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_TIPODOC_AFILIADO], CAST([COD_TIPO_DOCUMENTO] AS NVARCHAR(3)) AS [TIPO_DOCUMENTO_SIGLAS]\nFROM [DWH_COMFENALCO].[Dwh].[DIM_TIPO_DOCUMENTO]\nWHERE [ESTADO] = 'ACT'\n</code></pre></li> <li><code>SqlCommandParam</code>:    <pre><code>select * from (SELECT [ID_TIPODOC_AFILIADO], CAST([COD_TIPO_DOCUMENTO] AS NVARCHAR(3)) AS [TIPO_DOCUMENTO_SIGLAS]\nFROM [DWH_COMFENALCO].[Dwh].[DIM_TIPO_DOCUMENTO]\nWHERE [ESTADO] = 'ACT') [refTable]\nwhere [refTable].[TIPO_DOCUMENTO_SIGLAS] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of TIPO_DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_TIPODOC_AFILIADO</code></li> <li><code>TIPO_DOCUMENTO_SIGLAS</code></li> </ul> </li> </ul> </li> <li> <p>Columna Derivada (<code>Derived Column</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_TIPODOC_AFILIADO</code> reemplazando valores nulos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_TIPODOC_AFILIADO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_TIPODOC_AFILIADO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>Poblacion Educacion (Stage Area)</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>TMP_POBLACION_EDUCACION</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"TMP_POBLACION_EDUCACION\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[STAGE_AREA]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of TIPO_DOCUMENTO</code></li> <li><code>Copy of DOCUMENTO</code></li> <li><code>ID_TIPODOC_AFILIADO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Archivo Plano (<code>Flat File Destination</code>)</p> <ul> <li>Descripci\u00f3n: Escribe datos en un archivo plano.</li> <li>Propiedades:<ul> <li><code>Overwrite</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>FlatFileConnection</code>: <code>Package.ConnectionManagers[Csv_Error_Poblacion]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos_1","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant ExcelSource1 as Matriculas_Cedesarrollo\n    participant ExcelSource2 as Poblacion PRS\n    participant AdoNetSource as Estudiantes Colegio\n    participant DataConversion1 as Data Conversion 1\n    participant DataConversion as Data Conversion\n    participant Sort1 as Sort 1\n    participant Sort2 as Sort 2\n    participant Sort as Sort\n    participant Merge1 as Merge 1\n    participant Merge as Merge\n    participant Lookup as Lookup\n    participant DerivedColumn as Derived Column\n    participant AdoNetDestination as Poblacion Educacion (Stage Area)\n    participant FlatFileDestination as Flat File Destination\n\n    ExcelSource1 -&gt;&gt; DataConversion1: Excel Source Output\n    ExcelSource2 -&gt;&gt; Sort2: Excel Source Output\n    AdoNetSource -&gt;&gt; Sort: Salida de origen de ADO NET\n    DataConversion1 -&gt;&gt; Sort1: Data Conversion Output\n    Sort1 -&gt;&gt; Merge: Sort Output\n    Sort2 -&gt;&gt; Merge1: Sort Output\n    Sort -&gt;&gt; Merge: Sort Output\n    Merge -&gt;&gt; Merge1: Merge Output 1\n    Merge1 -&gt;&gt; DataConversion: Merge Output 1\n    DataConversion -&gt;&gt; Lookup: Data Conversion Output\n    Lookup -&gt;&gt; DerivedColumn: Lookup Match Output\n    DerivedColumn -&gt;&gt; AdoNetDestination: Derived Column Output\n    DataConversion1 -&gt;&gt; FlatFileDestination: Data Conversion Error Output</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_beneficiarios","title":"Componente <code>Procesar DIM_BENEFICIARIOS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar DIM_BENEFICIARIOS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos relacionados con los beneficiarios. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>TMP POBLACION EDUCACION</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server mediante el proveedor de datos de .NET Framework.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [TIPO_DOCUMENTO_SIGLAS], [DOCUMENTO], [ID_TIPO_DOCUMENTO]\nFROM [Transversal].[TMP_POBLACION_EDUCACION]\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[STAGE_AREA]</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>TIPO_DOCUMENTO_SIGLAS</code></li> <li><code>DOCUMENTO</code></li> <li><code>ID_TIPO_DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Realiza la conversi\u00f3n de datos de las columnas de entrada a tipos de datos espec\u00edficos.</li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO_SIGLAS</code></li> <li><code>DOCUMENTO</code></li> <li><code>ID_TIPO_DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Copy of TIPO_DOCUMENTO_SIGLAS</code></li> <li><code>Copy of DOCUMENTO</code></li> <li><code>Copy of ID_TIPO_DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_BENEFICIARIOS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_BENEFICIARIO], [ID_TIPO_DOCUMENTO], [NUMERO_DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS]\nWHERE ESTADOREGISTRO = 'CURRENT' AND TIPO_APORTANTE = 'X'\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of ID_TIPO_DOCUMENTO</code></li> <li><code>Copy of DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_BENEFICIARIO</code></li> <li><code>ID_TIPO_DOCUMENTO</code></li> <li><code>NUMERO_DOCUMENTO</code></li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_BENEFICIARIO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Agregar</code>: Filas donde <code>ID_BENEFICIARIO</code> es nulo.</li> <li><code>Ya Incluido</code>: Filas donde <code>ID_BENEFICIARIO</code> no es nulo.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 1</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_BENEFICIARIOS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>WITH BENEFICIARIOS AS (\n    SELECT *\n    FROM [DWH_COMFENALCO].[Aportes].[DIM_BENEFICIARIOS]\n    WHERE ESTADOREGISTRO = 'CURRENT' AND TIPO_APORTANTE = 'X'\n),\nAFILIADOS AS (\n    SELECT \n        [ID_AFILIADO],\n        [PARTNER] as [BP_AFILIADO]\n    FROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS]\n    WHERE [ESTADOREGISTRO] = 'CURRENT' AND [EMPRESA_PRINCIPAL] = 'X'\n)\nSELECT * \nFROM BENEFICIARIOS b\nINNER JOIN AFILIADOS a ON b.[ID_PARENT_SAP] = a.[BP_AFILIADO]\nORDER BY b.[PARTNER];\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>PARTNER</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_BENEFICIARIO</code>, <code>PARTNER</code>, <code>TITULAR</code>, <code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>NUMERO_DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>, <code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code>, <code>ID_PARENTESCO</code>, <code>PARENTESCO</code>, <code>FECHA_AFILIACION</code>, <code>FECHA_RETIRO</code>, <code>ID_GENERO</code>, <code>GENERO</code>, <code>ID_NIVEL_EDUCATIVO</code>, <code>NIVEL_EDUCATIVO</code>, <code>ID_ESTADO_CIVIL</code>, <code>ESTADO_CIVIL</code>, <code>DISCAPACIDAD</code>, <code>FECHA_NACIMIENTO</code>, <code>DIRECCION</code>, <code>TELEFONO</code>, <code>BARRIO</code>, <code>ESTRATO</code>, <code>ID_CIUDAD</code>, <code>ID_AREA_GEOGRAFICA</code>, <code>AREA_GEOGRAFICA</code>, <code>FEC_CREACION</code>, <code>USUARIO_PROCESO</code>, <code>FEC_ACTUALIZACION</code>, <code>ESTADOREGISTRO</code>, <code>ID_PARENT_SAP</code>, <code>PARENT_SAP</code>, <code>APORTANTE</code>, <code>TIPO_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>FEC_DESDE</code>, <code>FEC_HASTA</code>, <code>ESTADO_BEN</code>, <code>FECHA_INGRESO_EMPRESA</code>, <code>ID_AFILIADO</code></li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split 1</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_BENEFICIARIO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Agregar</code>: Filas donde <code>ID_BENEFICIARIO</code> no es nulo.</li> <li><code>No Agregar</code>: Filas donde <code>ID_BENEFICIARIO</code> es nulo.</li> </ul> </li> </ul> </li> <li> <p>Ordenaci\u00f3n (<code>Sort</code>)</p> <ul> <li>Descripci\u00f3n: Ordena los datos de entrada en orden ascendente o descendente. <code>ID_BENEFICIARIO</code>, <code>PARTNER</code>, <code>TITULAR</code>, <code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>NUMERO_DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>, <code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code>, <code>ID_PARENTESCO</code>, <code>PARENTESCO</code>, <code>FECHA_AFILIACION</code>, <code>FECHA_RETIRO</code>, <code>ID_GENERO</code>, <code>GENERO</code>, <code>ID_NIVEL_EDUCATIVO</code>, <code>NIVEL_EDUCATIVO</code>, <code>ID_ESTADO_CIVIL</code>, <code>ESTADO_CIVIL</code>, <code>DISCAPACIDAD</code>, <code>FECHA_NACIMIENTO</code>, <code>DIRECCION</code>, <code>TELEFONO</code>, <code>BARRIO</code>, <code>ESTRATO</code>, <code>ID_CIUDAD</code>, <code>ID_AREA_GEOGRAFICA</code>, <code>AREA_GEOGRAFICA</code>, <code>FEC_CREACION</code>, <code>USUARIO_PROCESO</code>, <code>FEC_ACTUALIZACION</code>, <code>ESTADOREGISTRO</code>, <code>ID_PARENT_SAP</code>, <code>PARENT_SAP</code>, <code>APORTANTE</code>, <code>TIPO_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>FEC_DESDE</code>, <code>FEC_HASTA</code>, <code>ESTADO_BEN</code>, <code>FECHA_INGRESO_EMPRESA</code>, <code>ID_AFILIADO</code></li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_BENEFICIARIOS</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_BENEFICIARIOS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_BENEFICIARIO</code>, <code>PARTNER</code>, <code>TITULAR</code>, <code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>NUMERO_DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>, <code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code>, <code>ID_PARENTESCO</code>, <code>PARENTESCO</code>, <code>FECHA_AFILIACION</code>, <code>FECHA_RETIRO</code>, <code>ID_GENERO</code>, <code>GENERO</code>, <code>ID_NIVEL_EDUCATIVO</code>, <code>NIVEL_EDUCATIVO</code>, <code>ID_ESTADO_CIVIL</code>, <code>ESTADO_CIVIL</code>, <code>DISCAPACIDAD</code>, <code>FECHA_NACIMIENTO</code>, <code>DIRECCION</code>, <code>TELEFONO</code>, <code>BARRIO</code>, <code>ESTRATO</code>, <code>ID_CIUDAD</code>, <code>ID_AREA_GEOGRAFICA</code>, <code>AREA_GEOGRAFICA</code>, <code>FEC_CREACION</code>, <code>USUARIO_PROCESO</code>, <code>FEC_ACTUALIZACION</code>, <code>ESTADOREGISTRO</code>, <code>ID_PARENT_SAP</code>, <code>PARENT_SAP</code>, <code>APORTANTE</code>, <code>TIPO_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>FEC_DESDE</code>, <code>FEC_HASTA</code>, <code>ESTADO_BEN</code>, <code>FECHA_INGRESO_EMPRESA</code>, <code>ID_AFILIADO</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as TMP POBLACION EDUCACION\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup\n    participant ConditionalSplit as Conditional Split\n    participant Lookup1 as Lookup 1\n    participant ConditionalSplit1 as Conditional Split 1\n    participant Sort as Sort\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; DataConversion: Salida de origen de ADO NET\n    DataConversion -&gt;&gt; Lookup: Data Conversion Output\n    Lookup -&gt;&gt; ConditionalSplit: Lookup Match Output\n    ConditionalSplit -&gt;&gt; Lookup1: Agregar\n    Lookup1 -&gt;&gt; ConditionalSplit1: Lookup Match Output\n    ConditionalSplit1 -&gt;&gt; Sort: Agregar\n    Sort -&gt;&gt; AdoNetDestination: Sort Output</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_beneficiarios-por-bp","title":"Componente <code>Procesar DIM_BENEFICIARIOS por BP</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar DIM_BENEFICIARIOS por BP</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos relacionados con los beneficiarios. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_7","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_7","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar DIM_BENEFICIARIOS por BP</code></li> <li>DTSID: <code>{9D64A149-0EA1-4EED-BA34-23FA4B8690F6}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>DIM POBLACION MATRICULA Colegio</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server mediante el proveedor de datos de .NET Framework.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [PARTNER]\nFROM [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>PARTNER</code></li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_BENEFICIARIOS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT * FROM [Transversal].[DIM_BENEFICIARIOS]\n</code></pre></li> <li><code>SqlCommandParam</code>:    <pre><code>SELECT * FROM (SELECT * FROM [Transversal].[DIM_BENEFICIARIOS]) [refTable]\nWHERE [refTable].[PARTNER] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>PARTNER</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_BENEFICIARIO</code>, <code>PARTNER</code>, <code>TITULAR</code>, <code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>NUMERO_DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>, <code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code>, <code>ID_PARENTESCO</code>, <code>PARENTESCO</code>, <code>FECHA_AFILIACION</code>, <code>FECHA_RETIRO</code>, <code>ID_GENERO</code>, <code>GENERO</code>, <code>ID_NIVEL_EDUCATIVO</code>, <code>NIVEL_EDUCATIVO</code>, <code>ID_ESTADO_CIVIL</code>, <code>ESTADO_CIVIL</code>, <code>DISCAPACIDAD</code>, <code>FECHA_NACIMIENTO</code>, <code>DIRECCION</code>, <code>TELEFONO</code>, <code>BARRIO</code>, <code>ESTRATO</code>, <code>ID_CIUDAD</code>, <code>ID_AREA_GEOGRAFICA</code>, <code>AREA_GEOGRAFICA</code>, <code>FEC_CREACION</code>, <code>USUARIO_PROCESO</code>, <code>FEC_ACTUALIZACION</code>, <code>ESTADOREGISTRO</code>, <code>ID_PARENT_SAP</code>, <code>PARENT_SAP</code>, <code>APORTANTE</code>, <code>TIPO_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>FEC_DESDE</code>, <code>FEC_HASTA</code>, <code>ESTADO_BEN</code>, <code>FECHA_INGRESO_EMPRESA</code>, <code>ID_AFILIADO</code></li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 1</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_BENEFICIARIOS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>WITH BENEFICIARIOS AS (\n    SELECT *\n    FROM [DWH_COMFENALCO].[Aportes].[DIM_BENEFICIARIOS]\n    WHERE ESTADOREGISTRO = 'CURRENT' AND TIPO_APORTANTE = 'X'\n),\nAFILIADOS AS (\n    SELECT \n        [ID_AFILIADO],\n        [PARTNER] as [BP_AFILIADO]\n    FROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS]\n    WHERE [ESTADOREGISTRO] = 'CURRENT' AND [EMPRESA_PRINCIPAL] = 'X'\n)\nSELECT * \nFROM BENEFICIARIOS b\nINNER JOIN AFILIADOS a ON b.[ID_PARENT_SAP] = a.[BP_AFILIADO]\nORDER BY b.[PARTNER];\n</code></pre></li> <li><code>SqlCommandParam</code>:    <pre><code>SELECT * FROM (WITH BENEFICIARIOS AS (\n    SELECT *\n    FROM [DWH_COMFENALCO].[Aportes].[DIM_BENEFICIARIOS]\n    WHERE ESTADOREGISTRO = 'CURRENT' AND TIPO_APORTANTE = 'X'\n),\nAFILIADOS AS (\n    SELECT \n        [ID_AFILIADO],\n        [PARTNER] as [BP_AFILIADO]\n    FROM [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS]\n    WHERE [ESTADOREGISTRO] = 'CURRENT' AND [EMPRESA_PRINCIPAL] = 'X'\n)\nSELECT * \nFROM BENEFICIARIOS b\nINNER JOIN AFILIADOS a ON b.[ID_PARENT_SAP] = a.[BP_AFILIADO]\nORDER BY b.[PARTNER];) [refTable]\nWHERE [refTable].[PARTNER] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>PARTNER</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_BENEFICIARIO</code>, <code>PARTNER</code>, <code>TITULAR</code>, <code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>NUMERO_DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>, <code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code>, <code>ID_PARENTESCO</code>, <code>PARENTESCO</code>, <code>FECHA_AFILIACION</code>, <code>FECHA_RETIRO</code>, <code>ID_GENERO</code>, <code>GENERO</code>, <code>ID_NIVEL_EDUCATIVO</code>, <code>NIVEL_EDUCATIVO</code>, <code>ID_ESTADO_CIVIL</code>, <code>ESTADO_CIVIL</code>, <code>DISCAPACIDAD</code>, <code>FECHA_NACIMIENTO</code>, <code>DIRECCION</code>, <code>TELEFONO</code>, <code>BARRIO</code>, <code>ESTRATO</code>, <code>ID_CIUDAD</code>, <code>ID_AREA_GEOGRAFICA</code>, <code>AREA_GEOGRAFICA</code>, <code>FEC_CREACION</code>, <code>USUARIO_PROCESO</code>, <code>FEC_ACTUALIZACION</code>, <code>ESTADOREGISTRO</code>, <code>ID_PARENT_SAP</code>, <code>PARENT_SAP</code>, <code>APORTANTE</code>, <code>TIPO_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>FEC_DESDE</code>, <code>FEC_HASTA</code>, <code>ESTADO_BEN</code>, <code>FECHA_INGRESO_EMPRESA</code>, <code>ID_AFILIADO</code></li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_BENEFICIARIO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Agregar</code>: Filas donde <code>ID_BENEFICIARIO</code> es nulo.</li> <li><code>No Agregar</code>: Filas donde <code>ID_BENEFICIARIO</code> no es nulo.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_BENEFICIARIOS Transversal</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_BENEFICIARIOS</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_BENEFICIARIOS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_BENEFICIARIO</code>, <code>PARTNER</code>, <code>TITULAR</code>, <code>ID_TIPO_DOCUMENTO</code>, <code>COD_TIPO_DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>NUMERO_DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>, <code>PRIMER_APELLIDO</code>, <code>SEGUNDO_APELLIDO</code>, <code>PRIMER_NOMBRE</code>, <code>SEGUNDO_NOMBRE</code>, <code>ID_PARENTESCO</code>, <code>PARENTESCO</code>, <code>FECHA_AFILIACION</code>, <code>FECHA_RETIRO</code>, <code>ID_GENERO</code>, <code>GENERO</code>, <code>ID_NIVEL_EDUCATIVO</code>, <code>NIVEL_EDUCATIVO</code>, <code>ID_ESTADO_CIVIL</code>, <code>ESTADO_CIVIL</code>, <code>DISCAPACIDAD</code>, <code>FECHA_NACIMIENTO</code>, <code>DIRECCION</code>, <code>TELEFONO</code>, <code>BARRIO</code>, <code>ESTRATO</code>, <code>ID_CIUDAD</code>, <code>ID_AREA_GEOGRAFICA</code>, <code>AREA_GEOGRAFICA</code>, <code>FEC_CREACION</code>, <code>USUARIO_PROCESO</code>, <code>FEC_ACTUALIZACION</code>, <code>ESTADOREGISTRO</code>, <code>ID_PARENT_SAP</code>, <code>PARENT_SAP</code>, <code>APORTANTE</code>, <code>TIPO_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>FEC_DESDE</code>, <code>FEC_HASTA</code>, <code>ESTADO_BEN</code>, <code>FECHA_INGRESO_EMPRESA</code>, <code>ID_AFILIADO</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-flujo-de-datos_2","title":"Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as DIM POBLACION MATRICULA Colegio\n    participant Lookup as Lookup\n    participant Lookup1 as Lookup 1\n    participant ConditionalSplit as Conditional Split\n    participant AdoNetDestination as DIM_BENEFICIARIOS Transversal\n\n    AdoNetSource -&gt;&gt; Lookup: Salida de origen de ADO NET\n    Lookup -&gt;&gt; Lookup1: Lookup Match Output\n    Lookup1 -&gt;&gt; ConditionalSplit: Lookup Match Output\n    ConditionalSplit -&gt;&gt; AdoNetDestination: Agregar</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_afiliados","title":"Componente <code>Procesar_DIM_AFILIADOS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_AFILIADOS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_AFILIADOS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_8","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_8","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_AFILIADOS</code></li> <li>DTSID: <code>{UNIQUE-DTSID}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_3","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Afiliados</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_AFILIADOS\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#columnas-de-entrada","title":"Columnas de Entrada","text":"<ul> <li><code>ID_AFILIADO</code></li> <li><code>NOMBRE</code></li> <li><code>APELLIDO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>NUMERO_DOCUMENTO</code></li> <li><code>FECHA_NACIMIENTO</code></li> <li><code>GENERO</code></li> <li><code>ESTADO_CIVIL</code></li> <li><code>DIRECCION</code></li> <li><code>CIUDAD</code></li> <li><code>TELEFONO</code></li> <li><code>EMAIL</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_9","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_AFILIADOS\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Convertir datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_AFILIADO_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_AFILIADOS`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Modificar`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_AFILIADOS`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Sheet1$</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>CommandTimeout</code>: <code>0</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Verifica y convierte los tipos de datos de las columnas de entrada.</li> </ul> </li> <li> <p>Columna Derivada (<code>Crear ID_AFILIADO_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_AFILIADO_AUXILIAR</code> concatenando varias columnas de entrada.</li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_AFILIADOS</code> para unir columnas adicionales al flujo de datos.</li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> </ul> </li> <li> <p>Destino ADO.NET (<code>DIM_AFILIADOS_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_AFILIADOS</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_AFILIADOS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_empresas","title":"Componente <code>Procesar DIM_EMPRESAS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_EMPRESAS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_EMPRESAS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_9","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_9","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_EMPRESAS</code></li> <li>DTSID: <code>{DTSID_DEL_COMPONENTE}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_4","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Empresas</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino_1","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_EMPRESAS\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_10","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_EMPRESAS\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Verificar tipos de datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_EMPRESA_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_EMPRESAS`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Modificar`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_EMPRESAS`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar-dim_empresas-desde-afiliados","title":"Componente <code>Procesar DIM_EMPRESAS desde AFILIADOS</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_EMPRESAS</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_EMPRESAS</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_10","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_10","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_EMPRESAS</code></li> <li>DTSID: <code>{DTSID_DEL_COMPONENTE}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_5","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>OLE_DB_Connection_Afiliados</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino_2","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_EMPRESAS\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#columnas-de-entrada_1","title":"Columnas de Entrada","text":"<ul> <li>ID_EMPRESA</li> <li>NOMBRE_EMPRESA</li> <li>NIT</li> <li>DIRECCION</li> <li>TELEFONO</li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_11","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_EMPRESAS\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant SQL as Base de Datos SQL\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;SQL: Ejecutar extracci\u00f3n de datos de AFILIADOS\n    SQL--&gt;&gt;SSIS: Retornar datos extra\u00eddos\n    SSIS-&gt;&gt;SSIS: Transformar datos (limpieza, estandarizaci\u00f3n)\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla DIM_EMPRESAS\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (OLE DB Source)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde la tabla <code>AFILIADOS</code>.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>AFILIADOS</code></li> <li><code>CommandTimeout</code>: <code>0</code></li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos (Data Conversion)</p> <ul> <li>Descripci\u00f3n: Verifica y convierte los tipos de datos de las columnas de entrada.</li> </ul> </li> <li> <p>Columna Derivada (Derived Column)</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas necesarias para la tabla de destino.</li> </ul> </li> <li> <p>B\u00fasqueda (Lookup)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_EMPRESAS</code> para unir columnas adicionales al flujo de datos.</li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (Conditional Split)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> </ul> </li> <li> <p>Destino ADO.NET (ADO.NET Destination)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_EMPRESAS</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_EMPRESAS\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_aportante_no_afiliado","title":"Componente <code>Procesar_DIM_APORTANTE_NO_AFILIADO</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_APORTANTE_NO_AFILIADO</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_APORTANTE_NO_AFILIADO</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_11","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_11","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_APORTANTE_NO_AFILIADO</code></li> <li>DTSID: <code>{DTSID_DEL_COMPONENTE}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_6","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Aportante</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino_3","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_APORTANTE_NO_AFILIADO\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#columnas-de-entrada_2","title":"Columnas de Entrada","text":"<ul> <li><code>ID_APORTANTE</code></li> <li><code>NOMBRE_APORTANTE</code></li> <li><code>TIPO_APORTANTE</code></li> <li><code>FECHA_REGISTRO</code></li> <li><code>ESTADO</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_12","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_APORTANTE_NO_AFILIADO\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Convertir datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_APORTANTE_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_APORTANTE_NO_AFILIADO`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Modificar`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_APORTANTE_NO_AFILIADO`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Sheet1$</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>CommandTimeout</code>: <code>0</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> </ul> </li> <li> <p>Columna Derivada (<code>Crear_ID_APORTANTE_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_APORTANTE_AUXILIAR</code> concatenando varias columnas de entrada.</li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_APORTANTE_NO_AFILIADO</code> para unir columnas adicionales al flujo de datos.</li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> </ul> </li> <li> <p>Destino ADO.NET (<code>DIM_APORTANTE_NO_AFILIADO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_APORTANTE_NO_AFILIADO</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_APORTANTE_NO_AFILIADO\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-descargar_ep-tra-05","title":"Componente <code>Descargar_EP-TRA-05</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_EP-TRA-05</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script de Python para descargar archivos desde SharePoint. Este componente utiliza la tarea <code>Execute Process</code> para ejecutar el script.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_12","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_12","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Descargar_EP-TRA-05</code></li> <li>DTSID: <code>{769c3094-28c7-44e9-9e36-9e9bc371b279}</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar proceso</code></li> <li>Tipo de Componente: <code>Microsoft.ExecuteProcess</code></li> <li>TaskContact: <code>Execute Process Task;Microsoft Corporation; SQL Server 2022; \u00a9 2022 Microsoft Corporation; All Rights Reserved;http://www.microsoft.com/sql/support/default.asp;1</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-proceso","title":"Propiedades del Proceso","text":"<ul> <li>Executable: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> <li>Arguments: <code>04.SharePoint_Connection_EP-TRA-05.py</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso","title":"Diagrama de Secuencia del Proceso","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso - Descargar_EP-TRA-05\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Python as Script de Python\n    participant SharePoint as Servidor SharePoint\n\n    SSIS-&gt;&gt;Python: Ejecutar script `04.SharePoint_Connection_EP-TRA-05.py`\n    Python--&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Python: Confirmar conexi\u00f3n\n    Python-&gt;&gt;SharePoint: Descargar archivos\n    SharePoint--&gt;&gt;Python: Retornar archivos descargados\n    Python--&gt;&gt;SSIS: Confirmar finalizaci\u00f3n del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-proceso","title":"Componentes del Proceso","text":"<ol> <li> <p>Tarea Ejecutar Proceso (<code>Descargar_EP-TRA-05</code>)</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python para descargar archivos desde SharePoint.</li> <li>Propiedades:<ul> <li><code>Executable</code>: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li><code>WorkingDirectory</code>: <code>@[$Project::Working_Directory]+\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> <li><code>Arguments</code>: <code>04.SharePoint_Connection_EP-TRA-05.py</code></li> </ul> </li> </ul> </li> <li> <p>Script de Python (<code>04.SharePoint_Connection_EP-TRA-05.py</code>)</p> <ul> <li>Descripci\u00f3n: Script que se conecta a SharePoint y descarga los archivos necesarios.</li> </ul> </li> <li> <p>Servidor SharePoint</p> <ul> <li>Descripci\u00f3n: Servidor desde el cual se descargan los archivos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componente-procesar_dim_personal","title":"Componente <code>Procesar_DIM_PERSONAL</code>","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar_DIM_PERSONAL</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_PERSONAL</code> en el Data Warehouse. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#detalles-del-componente_13","title":"Detalles del Componente","text":""},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-del-componente_13","title":"Propiedades del Componente","text":"<ul> <li>Nombre del Componente: <code>Procesar_DIM_PERSONAL</code></li> <li>DTSID: <code>{A45BDAF4-5BCD-4E15-B7B0-6924847DB00B}</code></li> <li>Descripci\u00f3n: <code>Data Flow Task</code></li> <li>Tipo de Componente: <code>Microsoft.Pipeline</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-conexion_7","title":"Propiedades de la Conexi\u00f3n","text":"<ul> <li>Administrador de Conexiones: <code>Excel_Connection_Dim_Personal</code></li> <li>Tipo de Conexi\u00f3n: <code>OLE DB</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#propiedades-de-la-tabla-de-destino_4","title":"Propiedades de la Tabla de Destino","text":"<ul> <li>Nombre de la Tabla: <code>\"Transversal\".\"DIM_PERSONAL\"</code></li> <li>Batch Size: <code>0</code></li> <li>Command Timeout: <code>30</code></li> <li>Use Bulk Insert When Possible: <code>true</code></li> </ul>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#columnas-de-entrada_3","title":"Columnas de Entrada","text":"<p><code>COD_PERSONA_UNIDAD</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>NOMBRE</code>, <code>TELEFONO</code>, <code>CELULAR</code>, <code>CORREO</code>, <code>DIRECCION</code>, <code>CIUDAD</code>, <code>FECHA_NACIMIENTO</code>, <code>GENERO</code>, <code>ID_UNIDAD</code>, <code>SERVICIO</code>, <code>AREA</code>, <code>TIPO_CONTRATACION</code>, <code>FECHA_INICIO_CONTRATACION</code>, <code>FECHA_FIN_CONTRATACION</code>, <code>CAUSA_TERMINACION_CONTRATO</code>, <code>HORAS_CONTRATADAS_MENSUAL</code>, <code>HORAS_CONTRATADAS_TOTALES</code>, <code>VALOR_TOTAL</code>, <code>PREGRADO</code>, <code>POSGRADO_ESPECIALIDAD</code>, <code>POSGRADO_MAESTRIA</code>, <code>POSGRADO_DOCTORADO</code></p>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#diagrama-de-secuencia-del-proceso-etl_13","title":"Diagrama de Secuencia del Proceso ETL","text":"<pre><code>sequenceDiagram\n    title Diagrama de Secuencia del Proceso ETL - Procesar_DIM_PERSONAL\n    autonumber\n    participant SSIS as Tarea SSIS\n    participant Excel as Fuente de Datos Excel\n    participant DWH as Data Warehouse\n\n    SSIS-&gt;&gt;Excel: Leer datos de `Sheet1$`\n    Excel--&gt;&gt;SSIS: Retornar datos le\u00eddos\n    SSIS-&gt;&gt;SSIS: Convertir datos\n    SSIS-&gt;&gt;SSIS: Crear columna derivada `ID_PERSONAL_AUXILIAR`\n    SSIS-&gt;&gt;DWH: Realizar b\u00fasqueda en `DIM_PERSONAL`\n    DWH--&gt;&gt;SSIS: Retornar resultados de b\u00fasqueda\n    SSIS-&gt;&gt;SSIS: Dividir datos en `Agregar` y `Sin Cambios`\n    SSIS-&gt;&gt;DWH: Cargar datos en tabla `DIM_PERSONAL`\n    DWH--&gt;&gt;SSIS: Confirmaci\u00f3n de carga exitosa</code></pre>"},{"location":"02.Paquetes_SSIS/01.TRANSVERSAL_DIMENSIONES/#componentes-del-flujo-de-datos_9","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Sheet1$</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>CommandTimeout</code>: <code>0</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada.</li> </ul> </li> <li> <p>Columna Derivada (<code>Crear_ID_PERSONAL_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_PERSONAL_AUXILIAR</code> concatenando varias columnas de entrada.</li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_PERSONAL</code> para unir columnas adicionales al flujo de datos.</li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> </ul> </li> <li> <p>Destino ADO.NET (<code>DIM_PERSONAL_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>DIM_PERSONAL</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"DIM_PERSONAL\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/","title":"02. TRANSVERSAL_FACT","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#transversal_fact","title":"TRANSVERSAL_FACT","text":"<p>El paquete SSIS \"02-TRANSVERSAL_FACT\" est\u00e1 dise\u00f1ado para procesar y consolidar datos financieros, educativos y operativos relacionados con diversas \u00e1reas estrat\u00e9gicas. Este paquete facilita la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos, asegurando que se integren de manera efectiva en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es gestionar datos transversales cr\u00edticos, desde detalles contables y presupuestarios hasta encuestas y convenios. Este paquete asegura que los datos cargados en el Data Warehouse est\u00e9n preparados para an\u00e1lisis estrat\u00e9gicos, garantizando calidad, consistencia y precisi\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>FACT_DETALLE_CONTABLE</code></li> <li><code>FACT_PRESUPUESTO</code></li> <li><code>FACT_ENCUESTAS_PSR</code></li> <li><code>FACT_CONVENIOS</code></li> <li><code>FACT_INICIATIVAS</code></li> <li>Archivos Excel y CSV:</li> <li>Encuestas, PQRS, y otros registros de entrada.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB para acceso eficiente.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaciones (<code>Lookup</code>):<ul> <li>Garantiza la consistencia comparando con tablas maestras (<code>DIM_TIEMPO</code>, <code>DIM_AFILIADOS</code>, <code>DIM_EMPRESAS</code>).</li> </ul> </li> <li>Divisi\u00f3n Condicional (<code>Conditional Split</code>):<ul> <li>Clasifica registros en v\u00e1lidos y no v\u00e1lidos seg\u00fan criterios espec\u00edficos.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con el destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Genera claves auxiliares y valores predeterminados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas destino:<ul> <li><code>FACT_DETALLE_CONTABLE</code></li> <li><code>FACT_PRESUPUESTO</code></li> <li><code>FACT_ENCUESTAS_PSR</code></li> <li><code>FACT_CONVENIOS</code></li> <li><code>FACT_INICIATIVAS</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python para automatizar tareas relacionadas con conexiones a SharePoint y procesamiento din\u00e1mico de datos.</li> </ul> </li> <li> <p>Mantenimiento de Restricciones:</p> <ul> <li>Restauraci\u00f3n din\u00e1mica de llaves for\u00e1neas utilizando SQL din\u00e1mico para mantener integridad referencial.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>FACT_DETALLE_CONTABLE:</p> <ul> <li><code>ID_CEBE</code>, <code>ID_CUENTA</code>, <code>ID_FECHA</code>, <code>IMPORTE</code>, <code>GASTOS</code>, <code>ACTIVO</code>, <code>PASIVO</code>, entre otros.</li> </ul> </li> <li> <p>FACT_PRESUPUESTO:</p> <ul> <li><code>ID_CEBE</code>, <code>ID_FECHA</code>, <code>ID_TIPO_PRESUPUESTO</code>, <code>SEGMENT</code>, <code>VALOR</code>, <code>GASTOS</code>, <code>COSTOS</code>.</li> </ul> </li> <li> <p>FACT_ENCUESTAS_PSR:</p> <ul> <li><code>ID_FECHA</code>, <code>ID_EMPRESA</code>, <code>ID_BENEFICIARIO</code>, <code>DOCUMENTO</code>, <code>CALIFICACION</code>.</li> </ul> </li> <li> <p>FACT_CONVENIOS:</p> <ul> <li><code>ID_FECHA</code>, <code>NOMBRE_CONVENIO</code>, <code>VALOR_CONVENIO</code>, <code>ID_PROGRAMA</code>, <code>ID_UNIDAD</code>.</li> </ul> </li> <li> <p>FACT_INICIATIVAS:</p> <ul> <li><code>ID_INICIATIVA</code>, <code>ID_FECHA</code>, <code>NOMBRE_INICIATIVA</code>, <code>DESCRIPCION_INICIATIVA</code>, <code>OBSERVACIONES</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel y CSV\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de tablas maestras y transaccionales\n    SSIS -&gt;&gt; Excel: Leer datos de encuestas y PQRS\n    SSIS -&gt;&gt; Python: Ejecutar scripts de automatizaci\u00f3n\n    SSIS -&gt;&gt; DWH: Cargar datos procesados en tablas destino</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#2-diagrama-de-transformaciones-y-validaciones","title":"2. Diagrama de Transformaciones y Validaciones","text":"<pre><code>graph TD\n    A1[Fuente de Datos] --&gt; T1[Conversi\u00f3n de Datos]\n    A2[Tablas Maestras] --&gt; T2[Validaci\u00f3n mediante Lookup]\n    T1 --&gt; C1[Divisi\u00f3n por Condicional Split]\n    T2 --&gt; L1[Agregar Columnas Derivadas]\n    C1 --&gt; C2[Cargar datos transformados]</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#3-diagrama-er-para-tablas-de-hechos","title":"3. Diagrama ER para Tablas de Hechos","text":"<pre><code>erDiagram\n    FACT_DETALLE_CONTABLE {\n        int ID_CEBE\n        int ID_CUENTA\n        int ID_FECHA\n        float IMPORTE\n    }\n    FACT_PRESUPUESTO {\n        int ID_CEBE\n        int ID_FECHA\n        int ID_TIPO_PRESUPUESTO\n        float VALOR\n    }\n    FACT_ENCUESTAS_PSR {\n        int ID_FECHA\n        int ID_EMPRESA\n        int ID_BENEFICIARIO\n        string DOCUMENTO\n    }\n    FACT_CONVENIOS {\n        int ID_FECHA\n        string NOMBRE_CONVENIO\n        float VALOR_CONVENIO\n    }\n    FACT_INICIATIVAS {\n        int ID_INICIATIVA\n        int ID_FECHA\n        string NOMBRE_INICIATIVA\n    }\n    FACT_DETALLE_CONTABLE ||--|| FACT_PRESUPUESTO : \"Relaci\u00f3n Financiera\"\n    FACT_PRESUPUESTO ||--|| FACT_CONVENIOS : \"Conexi\u00f3n por Programas\"\n    FACT_ENCUESTAS_PSR ||--|| FACT_INICIATIVAS : \"An\u00e1lisis de Impacto\"</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-ejecucion-etls","title":"Componente <code>Ejecuci\u00f3n ETLs</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Ejecuci\u00f3n ETLs</code> es una tarea de ejecuci\u00f3n de procesos en un paquete SSIS que se encarga de ejecutar un script de Python para la conexi\u00f3n a SharePoint y la ejecuci\u00f3n de procesos ETL. Este componente utiliza la tarea <code>Execute Process Task</code> de SSIS.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li>Tarea Ejecutar Proceso (<code>Ejecuci\u00f3n ETLs</code>)<ul> <li>Descripci\u00f3n: Ejecuta un script de Python para la conexi\u00f3n a SharePoint y la ejecuci\u00f3n de procesos ETL.</li> <li>Propiedades:<ul> <li><code>DTSID</code>: <code>{15d614e5-f07f-4e85-bef0-e83e984f2dc2}</code></li> <li><code>ExecutableType</code>: <code>Microsoft.ExecuteProcess</code></li> <li><code>LocaleID</code>: <code>-1</code></li> <li><code>ObjectName</code>: <code>Ejecuci\u00f3n ETLs</code></li> <li><code>TaskContact</code>: <code>Execute Process Task;Microsoft Corporation; SQL Server 2022; \u00a9 2022 Microsoft Corporation; All Rights Reserved;http://www.microsoft.com/sql/support/default.asp;1</code></li> <li><code>ThreadHint</code>: <code>0</code></li> </ul> </li> <li>Expresiones de Propiedad:<ul> <li><code>Executable</code>: <code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"</code></li> <li><code>WorkingDirectory</code>: <code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\01.Transversal\"</code></li> </ul> </li> <li>Datos del Objeto:<ul> <li><code>Executable</code>: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li><code>Arguments</code>: <code>SharePoint_Connection_Transversal.py</code></li> <li><code>WorkingDirectory</code>: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\01.Transversal</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant ExecuteProcess as Ejecuci\u00f3n ETLs\n    participant PythonScript as SharePoint_Connection_Transversal.py\n\n    SSIS -&gt;&gt; ExecuteProcess: Iniciar tarea de ejecuci\u00f3n de proceso\n    ExecuteProcess -&gt;&gt; PythonScript: Ejecutar script de Python\n    PythonScript -&gt;&gt; ExecuteProcess: Finalizar ejecuci\u00f3n del script\n    ExecuteProcess -&gt;&gt; SSIS: Finalizar tarea de ejecuci\u00f3n de proceso</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_aportes_shr_det","title":"Componente <code>FACT_APORTES_SHR_DET</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_APORTES_SHR_DET</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos relacionados con los aportes. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>FACT_APORTES_SHR_DET</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server mediante el proveedor de datos de .NET Framework.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_EMPRESA], [ID_AFILIADO], [PERIODO], [OPBEL], [BELNR], [MOVIMIENTO], [FECHA_CONTABLE], [NUM_CUENTA], [APORTE], [INTERES], [ESTADOREGISTRO], [FECHA_ACTUALIZACION], [DESDE], [HASTA], [PROCESO], [BP_EMPRESA], [BP_AFILIADO], [TIPO_APORTANTE], [SW_AJUSTE], [APORTE_NUEVO]\nFROM [DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET]\nWHERE [FECHA_CONTABLE] &gt;= 20220101\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code></li> </ul> </li> <li>Columnas de Salida:     <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code>, <code>APORTE</code>, <code>INTERES</code>, <code>ESTADOREGISTRO</code>, <code>FECHA_ACTUALIZACION</code>, <code>DESDE</code>, <code>HASTA</code>, <code>PROCESO</code>, <code>BP_EMPRESA</code>, <code>BP_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>SW_AJUSTE</code>, <code>APORTE_NUEVO</code></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Realiza la conversi\u00f3n de datos de las columnas de entrada a tipos de datos espec\u00edficos.</li> <li>Columnas de Entrada:     <code>FECHA_CONTABLE</code></li> <li>Columnas de Salida:     <code>Copy of FECHA_CONTABLE</code></li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 1</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_AFILIADOS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT * FROM [Transversal].[DIM_AFILIADOS]\n</code></pre></li> <li><code>SqlCommandParam</code>:    <pre><code>SELECT * FROM (SELECT * FROM [Transversal].[DIM_AFILIADOS]) [refTable]\nWHERE [refTable].[ID_AFILIADO] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_AFILIADO</code></li> <li>Columnas de Salida:     <code>ID_AFILIADO_v</code></li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:     <code>ID_AFILIADO_v</code></li> <li>Columnas de Salida:<ul> <li><code>Case 1</code>: Filas donde <code>ID_AFILIADO_v</code> no es nulo.</li> <li><code>Conditional Split Default Output</code>: Filas donde <code>ID_AFILIADO_v</code> es nulo.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 2</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_EMPRESAS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT * FROM [Transversal].[DIM_EMPRESAS]\n</code></pre></li> <li><code>SqlCommandParam</code>:    <pre><code>SELECT * FROM (SELECT * FROM [Transversal].[DIM_EMPRESAS]) [refTable]\nWHERE [refTable].[ID_EMPRESA] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_EMPRESA</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_EMPRESA_v</code></li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split 1</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_EMPRESA_v</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Case 1</code>: Filas donde <code>ID_EMPRESA_v</code> no es nulo.</li> <li><code>Conditional Split Default Output</code>: Filas donde <code>ID_EMPRESA_v</code> es nulo.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>FACT_APORTES_SHR_DET</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_EMPRESA], [ID_AFILIADO], CAST([PERIODO] AS NVARCHAR(50)) AS PERIODO, CAST([OPBEL] AS NVARCHAR(50)) AS OPBEL, CAST([BELNR] AS NVARCHAR(50)) AS BELNR, CAST([MOVIMIENTO] AS NVARCHAR(50)) AS MOVIMIENTO, [FECHA_CONTABLE], CAST([NUM_CUENTA] AS NVARCHAR(50)) AS NUM_CUENTA, [APORTE], [INTERES], [ESTADOREGISTRO], [FECHA_ACTUALIZACION], [DESDE], [HASTA], [PROCESO], [BP_EMPRESA], [BP_AFILIADO], [TIPO_APORTANTE], [SW_AJUSTE], [APORTE_NUEVO]\nFROM [DWH_COMFENALCO].[Transversal].[FACT_APORTES_SHR_DET]\n</code></pre></li> <li><code>SqlCommandParam</code>:    <pre><code>SELECT * FROM (SELECT [ID_EMPRESA], [ID_AFILIADO], CAST([PERIODO] AS NVARCHAR(50)) AS PERIODO, CAST([OPBEL] AS NVARCHAR(50)) AS OPBEL, CAST([BELNR] AS NVARCHAR(50)) AS BELNR, CAST([MOVIMIENTO] AS NVARCHAR(50)) AS MOVIMIENTO, [FECHA_CONTABLE], CAST([NUM_CUENTA] AS NVARCHAR(50)) AS NUM_CUENTA, [APORTE], [INTERES], [ESTADOREGISTRO], [FECHA_ACTUALIZACION], [DESDE], [HASTA], [PROCESO], [BP_EMPRESA], [BP_AFILIADO], [TIPO_APORTANTE], [SW_AJUSTE], [APORTE_NUEVO]\nFROM [DWH_COMFENALCO].[Transversal].[FACT_APORTES_SHR_DET]) [refTable]\nWHERE [refTable].[ID_EMPRESA] = ? AND [refTable].[ID_AFILIADO] = ? AND [refTable].[PERIODO] = ? AND [refTable].[OPBEL] = ? AND [refTable].[BELNR] = ? AND [refTable].[MOVIMIENTO] = ? AND [refTable].[FECHA_CONTABLE] = ? AND [refTable].[NUM_CUENTA] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li> <p>Columnas de Entrada:     <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code></p> </li> <li> <p>Columnas de Salida:     <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code>, <code>APORTE</code>, <code>INTERES</code>, <code>ESTADOREGISTRO</code>, <code>FECHA_ACTUALIZACION</code>, <code>DESDE</code>, <code>HASTA</code>, <code>PROCESO</code>, <code>BP_EMPRESA</code>, <code>BP_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>SW_AJUSTE</code>, <code>APORTE_NUEVO</code></p> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>FACT_APORTES_SHR_DET</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"FACT_APORTES_SHR_DET\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code>, <code>APORTE</code>, <code>INTERES</code>, <code>ESTADOREGISTRO</code>, <code>FECHA_ACTUALIZACION</code>, <code>DESDE</code>, <code>HASTA</code>, <code>PROCESO</code>, <code>BP_EMPRESA</code>, <code>BP_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>SW_AJUSTE</code>, <code>APORTE_NUEVO</code>, <code>Copy of FECHA_CONTABLE</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as FACT_APORTES_SHR_DET\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup 1\n    participant ConditionalSplit as Conditional Split\n    participant Lookup2 as Lookup 2\n    participant ConditionalSplit1 as Conditional Split 1\n    participant Lookup as Lookup\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; DataConversion: Salida de origen de ADO NET\n    DataConversion -&gt;&gt; Lookup1: Data Conversion Output\n    Lookup1 -&gt;&gt; ConditionalSplit: Lookup Match Output\n    ConditionalSplit -&gt;&gt; Lookup2: Case 1\n    Lookup2 -&gt;&gt; ConditionalSplit1: Lookup Match Output\n    ConditionalSplit1 -&gt;&gt; Lookup: Case 1\n    Lookup -&gt;&gt; AdoNetDestination: Lookup No Match Output</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_aportes_shr_det_1","title":"Componente <code>FACT_APORTES_SHR_DET</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_APORTES_SHR_DET</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos relacionados con los aportes. Este componente realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de alto rendimiento.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>FACT_APORTES_SHR_DET</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de SQL Server mediante el proveedor de datos de .NET Framework.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_EMPRESA], [ID_AFILIADO], [PERIODO], [OPBEL], [BELNR], [MOVIMIENTO], [FECHA_CONTABLE], [NUM_CUENTA], [APORTE], [INTERES], [ESTADOREGISTRO], [FECHA_ACTUALIZACION], [DESDE], [HASTA], [PROCESO], [BP_EMPRESA], [BP_AFILIADO], [TIPO_APORTANTE], [SW_AJUSTE], [APORTE_NUEVO]\nFROM [DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET]\nWHERE [FECHA_CONTABLE] &gt;= 20220101\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code></li> </ul> </li> <li>Columnas de Salida: <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code>, <code>APORTE</code>, <code>INTERES</code>, <code>ESTADOREGISTRO</code>, <code>FECHA_ACTUALIZACION</code>, <code>DESDE</code>, <code>HASTA</code>, <code>PROCESO</code>, <code>BP_EMPRESA</code>, <code>BP_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>SW_AJUSTE</code>, <code>APORTE_NUEVO</code></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Realiza la conversi\u00f3n de datos de las columnas de entrada a tipos de datos espec\u00edficos.</li> <li>Columnas de Entrada:<ul> <li><code>FECHA_CONTABLE</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Copy of FECHA_CONTABLE</code></li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 1</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_AFILIADOS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT * FROM [Transversal].[DIM_AFILIADOS]\n</code></pre></li> <li><code>SqlCommandParam</code>:    <pre><code>SELECT * FROM (SELECT * FROM [Transversal].[DIM_AFILIADOS]) [refTable]\nWHERE [refTable].[ID_AFILIADO] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_AFILIADO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_AFILIADO_v</code></li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_AFILIADO_v</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Case 1</code>: Filas donde <code>ID_AFILIADO_v</code> no es nulo.</li> <li><code>Conditional Split Default Output</code>: Filas donde <code>ID_AFILIADO_v</code> es nulo.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 2</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_EMPRESAS</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT * FROM [Transversal].[DIM_EMPRESAS]\n</code></pre></li> <li><code>SqlCommandParam</code>:    <pre><code>SELECT * FROM (SELECT * FROM [Transversal].[DIM_EMPRESAS]) [refTable]\nWHERE [refTable].[ID_EMPRESA] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_EMPRESA</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_EMPRESA_v</code></li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split 1</code>)</p> <ul> <li>Descripci\u00f3n: Divide las filas de datos en diferentes salidas seg\u00fan el contenido de los datos.</li> <li>Columnas de Entrada:<ul> <li><code>ID_EMPRESA_v</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Case 1</code>: Filas donde <code>ID_EMPRESA_v</code> no es nulo.</li> <li><code>Conditional Split Default Output</code>: Filas donde <code>ID_EMPRESA_v</code> es nulo.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>FACT_APORTES_SHR_DET</code> para unir columnas adicionales al flujo de datos.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_EMPRESA], [ID_AFILIADO], CAST([PERIODO] AS NVARCHAR(50)) AS PERIODO, CAST([OPBEL] AS NVARCHAR(50)) AS OPBEL, CAST([BELNR] AS NVARCHAR(50)) AS BELNR, CAST([MOVIMIENTO] AS NVARCHAR(50)) AS MOVIMIENTO, [FECHA_CONTABLE], CAST([NUM_CUENTA] AS NVARCHAR(50)) AS NUM_CUENTA, [APORTE], [INTERES], [ESTADOREGISTRO], [FECHA_ACTUALIZACION], [DESDE], [HASTA], [PROCESO], [BP_EMPRESA], [BP_AFILIADO], [TIPO_APORTANTE], [SW_AJUSTE], [APORTE_NUEVO]\nFROM [DWH_COMFENALCO].[Transversal].[FACT_APORTES_SHR_DET]\n</code></pre></li> <li><code>SqlCommandParam</code>:    <pre><code>SELECT * FROM (SELECT [ID_EMPRESA], [ID_AFILIADO], CAST([PERIODO] AS NVARCHAR(50)) AS PERIODO, CAST([OPBEL] AS NVARCHAR(50)) AS OPBEL, CAST([BELNR] AS NVARCHAR(50)) AS BELNR, CAST([MOVIMIENTO] AS NVARCHAR(50)) AS MOVIMIENTO, [FECHA_CONTABLE], CAST([NUM_CUENTA] AS NVARCHAR(50)) AS NUM_CUENTA, [APORTE], [INTERES], [ESTADOREGISTRO], [FECHA_ACTUALIZACION], [DESDE], [HASTA], [PROCESO], [BP_EMPRESA], [BP_AFILIADO], [TIPO_APORTANTE], [SW_AJUSTE], [APORTE_NUEVO]\nFROM [DWH_COMFENALCO].[Transversal].[FACT_APORTES_SHR_DET]) [refTable]\nWHERE [refTable].[ID_EMPRESA] = ? AND [refTable].[ID_AFILIADO] = ? AND [refTable].[PERIODO] = ? AND [refTable].[OPBEL] = ? AND [refTable].[BELNR] = ? AND [refTable].[MOVIMIENTO] = ? AND [refTable].[FECHA_CONTABLE] = ? AND [refTable].[NUM_CUENTA] = ?\n</code></pre></li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code></li> </ul> </li> <li> <p>Columnas de Entrada: <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code></p> </li> <li> <p>Columnas de Salida: <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code>, <code>APORTE</code>, <code>INTERES</code>, <code>ESTADOREGISTRO</code>, <code>FECHA_ACTUALIZACION</code>, <code>DESDE</code>, <code>HASTA</code>, <code>PROCESO</code>, <code>BP_EMPRESA</code>, <code>BP_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>SW_AJUSTE</code>, <code>APORTE_NUEVO</code></p> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos en la tabla <code>FACT_APORTES_SHR_DET</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Transversal\".\"FACT_APORTES_SHR_DET\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code></li> </ul> </li> <li>Columnas de Entrada:     <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>PERIODO</code>, <code>OPBEL</code>, <code>BELNR</code>, <code>MOVIMIENTO</code>, <code>FECHA_CONTABLE</code>, <code>NUM_CUENTA</code>, <code>APORTE</code>, <code>INTERES</code>, <code>ESTADOREGISTRO</code>, <code>FECHA_ACTUALIZACION</code>, <code>DESDE</code>, <code>HASTA</code>, <code>PROCESO</code>, <code>BP_EMPRESA</code>, <code>BP_AFILIADO</code>, <code>TIPO_APORTANTE</code>, <code>SW_AJUSTE</code>, <code>APORTE_NUEVO</code>, <code>Copy of FECHA_CONTABLE</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as FACT_APORTES_SHR_DET\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup 1\n    participant ConditionalSplit as Conditional Split\n    participant Lookup2 as Lookup 2\n    participant ConditionalSplit1 as Conditional Split 1\n    participant Lookup as Lookup\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; DataConversion: Salida de origen de ADO NET\n    DataConversion -&gt;&gt; Lookup1: Data Conversion Output\n    Lookup1 -&gt;&gt; ConditionalSplit: Lookup Match Output\n    ConditionalSplit -&gt;&gt; Lookup2: Case 1\n    Lookup2 -&gt;&gt; ConditionalSplit1: Lookup Match Output\n    ConditionalSplit1 -&gt;&gt; Lookup: Case 1\n    Lookup -&gt;&gt; AdoNetDestination: Lookup No Match Output</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_detalle_contable","title":"Componente <code>FACT_DETALLE_CONTABLE</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_DETALLE_CONTABLE</code> es una tarea de flujo de datos en un paquete SSIS que realiza procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos financieros desde una base de datos fuente hacia un destino. Este flujo de datos incluye componentes para convertir datos, realizar b\u00fasquedas (lookup) y finalmente cargar los resultados en un destino de datos ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<p>Fuente de Datos ADO.NET (<code>FACT_DETALLE_CONTABLE</code>)</p> <ul> <li>Descripci\u00f3n: Componente que extrae los datos de la tabla <code>FACT_DETALLE_CONTABLE</code> en la base de datos <code>DWH_COMFENALCO</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT [ID_CEBE], [ID_CUENTA], [ID_FECHA], [SEGMENT], [IMPORTE], \n    [INGRESOS], [INGRESOS_OPERACIONALES], [GASTOS], [GASTOS_OPERACIONALES], \n    [GASTOS_OPERACIONALES_ADMIN], [RESULTADO_EJERCICIO], [COSTOS], \n    [ACTIVO], [PASIVO], [PATRIMONIO], [GASTOS_CON_DISTRIBUCION], \n    [GASTOS_SIN_DISTRIBUCION], CAST([FECHA_REGISTRO_SAP] AS smalldatetime) AS FECHA_REGISTRO_SAP, \n    CAST([FECHA_PROCESO] AS smalldatetime) AS FECHA_PROCESO, [USUARIO_PROCESO]\nFROM [DWH_COMFENALCO].[Financiera].[FACT_DETALLE_CONTABLE]\n</code></pre></li> <li>Tiempo de espera: <code>30 segundos</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> <li>Columnas de Salida:<ul> <li><code>ID_CEBE</code>, <code>ID_CUENTA</code>, <code>ID_FECHA</code>, <code>SEGMENT</code>, <code>IMPORTE</code>, <code>INGRESOS</code>, <code>ACTIVO</code>, <code>PASIVO</code>, <code>USUARIO_PROCESO</code>, entre otras.</li> </ul> </li> </ul> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte el tipo de datos de ciertas columnas para garantizar compatibilidad con los componentes posteriores.</li> <li>Columnas Convertidas:<ul> <li><code>FECHA_REGISTRO_SAP</code> \u2192 <code>Copy of FECHA_REGISTRO_SAP</code></li> <li><code>FECHA_PROCESO</code> \u2192 <code>Copy of FECHA_PROCESO</code></li> </ul> </li> </ul> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza un cruce con los datos en la tabla <code>FACT_DETALLE_CONTABLE</code> en el esquema <code>Transversal</code> para enriquecer la informaci\u00f3n del flujo.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Transversal].[FACT_DETALLE_CONTABLE]\nWHERE [ID_CEBE] = ? AND [ID_CUENTA] = ? AND [ID_FECHA] = ? AND [SEGMENT] = ? AND [IMPORTE] = ?\n</code></pre></li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> </ul> <p>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla de destino <code>FACT_DETALLE_CONTABLE</code> dentro del esquema <code>Transversal</code>.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_DETALLE_CONTABLE\"</code></li> <li>Tama\u00f1o del Lote: <code>0</code> (tama\u00f1o predeterminado de SSIS).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activado (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Columnas de Entrada:     <code>ID_CEBE</code>, <code>ID_CUENTA</code>, <code>ID_FECHA</code>, <code>SEGMENT</code>, <code>IMPORTE</code>, <code>GASTOS_OPERACIONALES_ADMIN</code>, <code>Copy of FECHA_REGISTRO_SAP</code>, <code>Copy of FECHA_PROCESO</code>, entre otras.</li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as FACT_DETALLE_CONTABLE\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; DataConversion: Salida de origen de ADO NET\n    DataConversion -&gt;&gt; Lookup: Data Conversion Output\n    Lookup -&gt;&gt; AdoNetDestination: Lookup No Match Output</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_convenios","title":"Componente <code>FACT_CONVENIOS</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_CONVENIOS</code> es una tarea de flujo de datos en un paquete SSIS que procesa datos de convenios desde una fuente de datos Excel hacia un destino en la base de datos <code>DWH_COMFENALCO</code>. Este flujo de datos incluye conversiones de datos, b\u00fasquedas (<code>Lookup</code>), y la carga final en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<p>1. Fuente de Datos Excel (<code>Excel Source</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel denominada <code>Sheet1$</code>.</li> <li>Propiedades:<ul> <li>Modo de acceso: <code>0</code> (por nombre de hoja).</li> <li>Tiempo de espera: <code>0</code> (infinito).</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[Administrador de conexiones con Excel 11]</code>.</li> <li>Columnas de Salida:<ul> <li><code>NOMBRE_CONVENIO</code>, <code>IDENTIFICACION_ACTO_CONVENIO</code>, <code>ENTIDAD_CONVENIO</code>, <code>COD_MUNICIPIO</code>, <code>VALOR_CONVENIO</code>, <code>APORTE_COMFENALCO</code>, <code>ESTADO_CONVENIO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>, <code>PROGRAMA</code>, <code>ID_PROGRAMA</code>, <code>ID_UNIDAD</code>.</li> </ul> </li> </ul> <p>2. Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte columnas seleccionadas a tipos de datos compatibles con los componentes posteriores.</li> <li>Columnas Convertidas:<ul> <li><code>FECHA_INICIO</code> \u2192 <code>Copy of FECHA_INICIO</code> (timestamp).</li> <li><code>FECHA_FIN</code> \u2192 <code>Copy of FECHA_FIN</code> (timestamp).</li> <li><code>ID_PROGRAMA</code> \u2192 <code>Copy of ID_PROGRAMA</code> (num\u00e9rico).</li> <li><code>PROGRAMA</code> \u2192 <code>Copy of PROGRAMA</code> (cadena de 40 caracteres).</li> <li><code>NOMBRE_CONVENIO</code> \u2192 <code>Copy of NOMBRE_CONVENIO</code> (cadena de 255 caracteres).</li> <li><code>ENTIDAD_CONVENIO</code> \u2192 <code>Copy of ENTIDAD_CONVENIO</code> (cadena de 255 caracteres).</li> <li><code>IDENTIFICACION_ACTO_CONVENIO</code> \u2192 <code>Copy of IDENTIFICACION_ACTO_CONVENIO</code> (cadena de 255 caracteres).</li> </ul> </li> </ul> <p>3. B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>Dwh.DIM_TIEMPO</code> para obtener informaci\u00f3n adicional basada en <code>Copy of FECHA_INICIO</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Dwh].[DIM_TIEMPO] \nWHERE [FECHA] = ?\n</code></pre></li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>Copy of FECHA_INICIO</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_FECHA</code>.</li> </ul> </li> </ul> <p>4. Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla de destino <code>FACT_CONVENIOS</code> dentro del esquema <code>Transversal</code>.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_CONVENIOS\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (tama\u00f1o predeterminado de SSIS).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activado (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Columnas de Entrada:     <code>Copy of FECHA_INICIO</code>, <code>Copy of FECHA_FIN</code>, <code>Copy of ID_PROGRAMA</code>, <code>Copy of PROGRAMA</code>, <code>Copy of NOMBRE_CONVENIO</code>, <code>Copy of ENTIDAD_CONVENIO</code>, <code>Copy of IDENTIFICACION_ACTO_CONVENIO</code>, <code>COD_MUNICIPIO</code>, <code>VALOR_CONVENIO</code>, <code>APORTE_COMFENALCO</code>, <code>ESTADO_CONVENIO</code>, <code>ID_FECHA</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup\n    participant AdoNetDestination as Destino de ADO NET\n\n    ExcelSource -&gt;&gt; DataConversion: Salida de origen de Excel\n    DataConversion -&gt;&gt; Lookup: Data Conversion Output\n    Lookup -&gt;&gt; AdoNetDestination: Lookup Match Output</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_presupuesto","title":"Componente <code>FACT_PRESUPUESTO</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_PRESUPUESTO</code> es una tarea de flujo de datos en un paquete SSIS dise\u00f1ada para realizar procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL) relacionados con datos financieros del presupuesto. Este flujo de datos incluye componentes para realizar divisiones condicionales, b\u00fasquedas (lookup) y cargas de datos en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>FACT_PRESUPUESTO</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos de la tabla <code>FACT_PRESUPUESTO</code> ubicada en el esquema <code>Financiera</code> de la base de datos <code>DWH_COMFENALCO</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT [ID_CEBE], [ID_CUENTA], [ID_FECHA], [ID_TIPO_PRESUPUESTO], [SEGMENT], [VALOR], [INGRESOS],\n       [INGRESOS_OPERACIONALES], [GASTOS], [GASTOS_OPERACIONALES], [GASTOS_OPERACIONALES_ADMIN],\n       [COSTOS], [GASTOS_CON_DISTRIBUCION], [GASTOS_SIN_DISTRIBUCION],\n       CAST([FECHA_PROCESO] AS smalldatetime) AS FECHA_PROCESO, [USUARIO_PROCESO]\nFROM [DWH_COMFENALCO].[Financiera].[FACT_PRESUPUESTO]\n</code></pre></li> <li>Tiempo de Espera: 30 segundos.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> <li>Columnas de Salida:     <code>ID_CEBE</code>, <code>ID_CUENTA</code>, <code>ID_FECHA</code>, <code>ID_TIPO_PRESUPUESTO</code>, <code>SEGMENT</code>, <code>VALOR</code>, <code>INGRESOS</code>, entre otras.</li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 1</code>)</p> <ul> <li>Descripci\u00f3n: Realiza un cruce con la tabla <code>DIM_UNIDADES_ORGANIZATIVAS</code> para enriquecer la informaci\u00f3n del flujo de datos.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * FROM [Transversal].[DIM_UNIDADES_ORGANIZATIVAS]\nWHERE [ID_CEBE] = ?\n</code></pre></li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Divide los datos en diferentes flujos seg\u00fan condiciones espec\u00edficas. Por ejemplo, separa los datos que cumplen con una condici\u00f3n de aquellos que no.</li> <li>Condiciones:<ul> <li>Case 1: <code>![ISNULL](ID_CEBE_v)</code></li> <li>Default Output: Filas que no cumplen las condiciones especificadas.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza un cruce con la tabla <code>FACT_PRESUPUESTO</code> en el esquema <code>Transversal</code> para validar y enriquecer los datos.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * FROM [Transversal].[FACT_PRESUPUESTO]\nWHERE [ID_CEBE] = ? AND [ID_CUENTA] = ? AND [ID_FECHA] = ? AND [ID_TIPO_PRESUPUESTO] = ?\n</code></pre></li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino <code>FACT_PRESUPUESTO</code> dentro del esquema <code>Transversal</code>.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_PRESUPUESTO\"</code>.</li> <li>Tama\u00f1o del Lote: 0 (predeterminado de SSIS).</li> <li>Tiempo de Espera: 30 segundos.</li> <li>Inserci\u00f3n Masiva: Activado (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Columnas de Entrada:     <code>ID_CEBE</code>, <code>ID_CUENTA</code>, <code>ID_FECHA</code>, <code>ID_TIPO_PRESUPUESTO</code>, <code>SEGMENT</code>, <code>VALOR</code>, entre otras.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as FACT_PRESUPUESTO\n    participant Lookup1 as Lookup 1\n    participant ConditionalSplit as Conditional Split\n    participant Lookup as Lookup\n    participant AdoNetDestination as Destino de ADO NET\n\n    AdoNetSource -&gt;&gt; Lookup1: Salida de origen de ADO NET\n    Lookup1 -&gt;&gt; ConditionalSplit: Lookup Match Output\n    ConditionalSplit -&gt;&gt; Lookup: Case 1\n    Lookup -&gt;&gt; AdoNetDestination: Lookup No Match Output</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_iniciativas","title":"Componente <code>FACT_INICIATIVAS</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_INICIATIVAS</code> es una tarea de flujo de datos en un paquete SSIS dise\u00f1ada para procesar y cargar datos relacionados con iniciativas. Realiza operaciones ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) utilizando transformaciones como conversi\u00f3n de datos, b\u00fasquedas (lookup), y carga de datos en una tabla ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Excel Source</code>)</p> <ul> <li>Descripci\u00f3n: Lee los datos desde un archivo Excel configurado con la hoja de entrada <code>Sheet1$</code>.</li> <li>Propiedades:<ul> <li>Modo de Acceso: <code>0</code> (Acceso por objeto de base de datos).</li> <li>Timeout del Comando: <code>0</code> (infinito).</li> <li>Conexi\u00f3n: <code>Administrador de conexiones con Excel</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_INICIATIVA</code>, <code>ID_UNIDAD</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>, <code>NOMBRE_INICIATIVA</code>, <code>DESCRIPCION_INICIATIVA</code>, <code>OBSERVACIONES</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Realiza la conversi\u00f3n de tipos de datos para asegurar compatibilidad.</li> <li>Columnas Convertidas:<ul> <li><code>FECHA_INICIO</code> \u2192 <code>Copy of FECHA_INICIO</code>.</li> <li><code>FECHA_FIN</code> \u2192 <code>Copy of FECHA_FIN</code>.</li> <li><code>NOMBRE_INICIATIVA</code> \u2192 <code>Copy of NOMBRE_INICIATIVA</code>.</li> <li><code>DESCRIPCION_INICIATIVA</code> \u2192 <code>Copy of DESCRIPCION_INICIATIVA</code>.</li> <li><code>OBSERVACIONES</code> \u2192 <code>Copy of OBSERVACIONES</code>.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza un cruce con la tabla <code>DIM_TIEMPO</code> para obtener el <code>ID_FECHA</code> correspondiente a <code>Copy of FECHA_INICIO</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * FROM [Dwh].[DIM_TIEMPO]\n</code></pre></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code>.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda 1 (<code>Lookup 1</code>)</p> <ul> <li>Descripci\u00f3n: Realiza un cruce con la tabla <code>FACT_INICIATIVAS</code> para validar registros existentes.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT TOP (1000) [ID_INICIATIVA], [ID_FECHA], CAST([ID_UNIDAD] AS NVARCHAR(50)) AS ID_UNIDAD, [FECHA_INICIO], [FECHA_FIN], [NOMBRE_INICIATIVA], [DESCRIPCION_INICIATIVA], [OBSERVACIONES]\nFROM [DWH_COMFENALCO].[Transversal].[FACT_INICIATIVAS]\n</code></pre></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_INICIATIVAS</code> dentro del esquema <code>Transversal</code>.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_INICIATIVAS\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code>.</li> <li>Timeout del Comando: <code>30</code>.</li> <li>Inserci\u00f3n Masiva: Activado.</li> </ul> </li> <li>Columnas de Entrada:     <code>ID_INICIATIVA</code>, <code>ID_UNIDAD</code>, <code>ID_FECHA</code>, <code>Copy of FECHA_INICIO</code>, <code>Copy of FECHA_FIN</code>, <code>Copy of NOMBRE_INICIATIVA</code>, <code>Copy of DESCRIPCION_INICIATIVA</code>, <code>Copy of OBSERVACIONES</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup\n    participant Lookup1 as Lookup 1\n    participant AdoNetDestination as Destino de ADO NET\n\n    ExcelSource -&gt;&gt; DataConversion: Salida de origen Excel\n    DataConversion -&gt;&gt; Lookup: Conversi\u00f3n de datos\n    Lookup -&gt;&gt; Lookup1: Lookup Match Output\n    Lookup1 -&gt;&gt; AdoNetDestination: Lookup No Match Output</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_encuestas","title":"Componente <code>FACT_ENCUESTAS</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_ENCUESTAS</code> es una tarea de flujo de datos dentro de un paquete SSIS que realiza procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL) para la consolidaci\u00f3n de datos relacionados con encuestas. Este flujo incluye transformaci\u00f3n de datos, b\u00fasquedas (lookup) en diferentes tablas y la carga de resultados en un destino de base de datos.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Plano (<code>Flat File Source</code>)</p> <ul> <li>Descripci\u00f3n: Lee datos desde un archivo plano utilizando un administrador de conexiones.</li> <li>Propiedades:<ul> <li>Conexi\u00f3n: <code>Csv_Connection_Fact_Encuestas</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>FECHA_ENCUESTA</code>, <code>DOCUMENTO</code>, <code>TIPO_DOCUMENTO</code>, <code>CALIFICACION</code>, <code>SERVICIO</code>, <code>PREGUNTA</code>, <code>NPS</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte columnas de entrada a tipos de datos espec\u00edficos para facilitar el procesamiento posterior.</li> <li>Columnas Convertidas:<ul> <li><code>Copy of FECHA_ENCUESTA</code> (dbTimeStamp).</li> <li><code>Copy of DOCUMENTO</code>, <code>Copy of TIPO_DOCUMENTO</code>, <code>Copy of SERVICIO</code>, <code>Copy of CALIFICACION</code>, <code>Copy of PREGUNTA</code>, <code>Copy of NPS</code> (wstr).</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza un cruce con la tabla <code>DIM_TIEMPO</code> para obtener informaci\u00f3n temporal.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT * FROM [Dwh].[DIM_TIEMPO]\nWHERE [FECHA] = ?\n</code></pre></li> <li>Columna de Entrada:<ul> <li><code>Copy of FECHA_ENCUESTA</code>.</li> </ul> </li> <li>Columna de Salida:<ul> <li><code>ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 1</code>)</p> <ul> <li>Descripci\u00f3n: Realiza un cruce con la tabla <code>DIM_EMPRESAS</code> para obtener informaci\u00f3n empresarial.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT * FROM [Transversal].[DIM_EMPRESAS]\nWHERE [DOCUMENTO] = ?\n</code></pre></li> <li>Columna de Entrada:     <code>Copy of DOCUMENTO</code>.</li> <li>Columna de Salida:     <code>ID_EMPRESA</code>.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 2</code>)</p> <ul> <li>Descripci\u00f3n: Realiza un cruce con la tabla <code>DIM_AFILIADOS</code> para enriquecer la informaci\u00f3n con datos de afiliados.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT * FROM [Transversal].[DIM_AFILIADOS]\nWHERE [NUMERO_DOCUMENTO] = ?\n</code></pre></li> <li>Columna de Entrada:     <code>Copy of DOCUMENTO</code>.</li> <li>Columna de Salida:     <code>ID_AFILIADO</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla destino <code>FACT_ENCUESTAS</code> dentro del esquema <code>Transversal</code>.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_ENCUESTAS\"</code>.</li> <li>Inserci\u00f3n Masiva: Activado (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Columnas de Entrada:     <code>ID_FECHA</code>, <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>Copy of CALIFICACION</code>, <code>Copy of SERVICIO</code>, <code>Copy of PREGUNTA</code>, <code>Copy of DOCUMENTO</code>, <code>Copy of TIPO_DOCUMENTO</code>, <code>Copy of FECHA_ENCUESTA</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant FlatFileSource as Flat File Source\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup (DIM_TIEMPO)\n    participant Lookup1 as Lookup 1 (DIM_EMPRESAS)\n    participant Lookup2 as Lookup 2 (DIM_AFILIADOS)\n    participant AdoNetDestination as Destino de ADO NET\n\n    FlatFileSource -&gt;&gt; DataConversion: Salida de Fuente de Datos Plano\n    DataConversion -&gt;&gt; Lookup: Salida de Conversi\u00f3n de Datos\n    Lookup -&gt;&gt; Lookup1: Salida de B\u00fasqueda (DIM_TIEMPO)\n    Lookup1 -&gt;&gt; Lookup2: Salida de B\u00fasqueda (DIM_EMPRESAS)\n    Lookup2 -&gt;&gt; AdoNetDestination: Salida de B\u00fasqueda (DIM_AFILIADOS)</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_encuestas_psr","title":"Componente <code>FACT_ENCUESTAS_PSR</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_ENCUESTAS_PSR</code> es una tarea de flujo de datos en un paquete SSIS dise\u00f1ado para procesar datos relacionados con encuestas y almacenarlos en una tabla de destino dentro del esquema <code>Transversal</code>. Este flujo de datos incluye transformaci\u00f3n, validaci\u00f3n y carga final.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos de Archivo Plano (<code>Flat File Source</code>)</p> <ul> <li>Descripci\u00f3n: Lee los datos desde un archivo plano que contiene registros de encuestas.</li> <li>Propiedades:<ul> <li>Retiene nulos: <code>False</code></li> <li>Nombre de la conexi\u00f3n: <code>Csv_Connection_Fact_Encuestas_PSR</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>FECHA_ENCUESTA</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> <li><code>PROGRAMA</code></li> <li><code>ACTIVIDAD_PREGUNTA</code></li> <li><code>CALIFICACION</code></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte las columnas de datos a tipos compatibles con los componentes posteriores.</li> <li>Columnas Convertidas:<ul> <li><code>FECHA_ENCUESTA</code> \u2192 <code>Copy of FECHA_ENCUESTA</code> (timestamp)</li> <li><code>TIPO_DOCUMENTO</code> \u2192 <code>Copy of TIPO_DOCUMENTO</code> (string)</li> <li><code>DOCUMENTO</code> \u2192 <code>Copy of DOCUMENTO</code> (string)</li> <li><code>PROGRAMA</code> \u2192 <code>Copy of PROGRAMA</code> (string)</li> <li><code>ACTIVIDAD_PREGUNTA</code> \u2192 <code>Copy of ACTIVIDAD_PREGUNTA</code> (string)</li> <li><code>CALIFICACION</code> \u2192 <code>Copy of CALIFICACION</code> (string)</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_TIEMPO</code> para asociar <code>ID_FECHA</code> con <code>FECHA_ENCUESTA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT * FROM [Dwh].[DIM_TIEMPO]\nWHERE [FECHA] = ?\n</code></pre></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of FECHA_ENCUESTA</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_FECHA</code></li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 1</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_EMPRESAS</code> para obtener <code>ID_EMPRESA</code> basado en <code>DOCUMENTO</code> y <code>TIPO_DOCUMENTO</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT * FROM [Transversal].[DIM_EMPRESAS]\nWHERE [DOCUMENTO] = ? AND [COD_TIPO_DOCUMENTO] = ?\n</code></pre></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of DOCUMENTO</code></li> <li><code>Copy of TIPO_DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_EMPRESA</code></li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 2</code>)</p> <ul> <li>Descripci\u00f3n: Busca <code>ID_BENEFICIARIO</code> en la tabla <code>DIM_BENEFICIARIOS</code> basado en <code>DOCUMENTO</code> y <code>TIPO_DOCUMENTO</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT * FROM [Transversal].[DIM_BENEFICIARIOS]\nWHERE [NUMERO_DOCUMENTO] = ? AND [COD_TIPO_DOCUMENTO] = ?\n</code></pre></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of DOCUMENTO</code></li> <li><code>Copy of TIPO_DOCUMENTO</code></li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_BENEFICIARIO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla de destino <code>FACT_ENCUESTAS_PSR</code>.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>\"Transversal\".\"FACT_ENCUESTAS_PSR\"</code></li> <li>Tama\u00f1o del Lote: <code>0</code></li> <li>Tiempo de Espera: <code>30 segundos</code></li> <li>Inserci\u00f3n Masiva: Activada</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_FECHA</code></li> <li><code>ID_EMPRESA</code></li> <li><code>ID_BENEFICIARIO</code></li> <li><code>Copy of DOCUMENTO</code></li> <li><code>Copy of TIPO_DOCUMENTO</code></li> <li><code>Copy of PROGRAMA</code></li> <li><code>Copy of ACTIVIDAD_PREGUNTA</code></li> <li><code>Copy of CALIFICACION</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant FlatFileSource as Flat File Source\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup (DIM_TIEMPO)\n    participant Lookup1 as Lookup 1 (DIM_EMPRESAS)\n    participant Lookup2 as Lookup 2 (DIM_BENEFICIARIOS)\n    participant AdoNetDestination as Destino de ADO NET\n\n    FlatFileSource -&gt;&gt; DataConversion: Lee datos\n    DataConversion -&gt;&gt; Lookup: Convierte columnas\n    Lookup -&gt;&gt; Lookup1: Agrega ID_FECHA\n    Lookup1 -&gt;&gt; Lookup2: Agrega ID_EMPRESA\n    Lookup2 -&gt;&gt; AdoNetDestination: Agrega ID_BENEFICIARIO\n    AdoNetDestination -&gt;&gt; AdoNetDestination: Inserta datos</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componente-fact_pqrs","title":"Componente <code>FACT_PQRS</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_PQRS</code> es una tarea de flujo de datos en un paquete SSIS que realiza procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL). Este flujo de datos incluye varias transformaciones, b\u00fasquedas y un destino de datos ADO.NET para manejar informaci\u00f3n de peticiones, quejas, reclamos y sugerencias (PQRS).</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_9","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>Excel Source</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel que contiene registros PQRS.</li> <li>Propiedades:<ul> <li>Nombre del objeto: <code>Sheet1$</code>.</li> <li>Tiempo de espera: <code>0</code> (infinito).</li> </ul> </li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_PQRS</code>.</li> <li>Columnas de Salida:<ul> <li><code>ID_PQR</code>, <code>ASUNTO</code>, <code>CREADO_POR</code>, <code>ESTADO</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>NOMBRE</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos para garantizar compatibilidad con los componentes posteriores.</li> <li>Columnas Convertidas:<ul> <li><code>FECHA_CREACION</code> \u2192 <code>Copy of FECHA_CREACION</code>.</li> <li><code>FECHA_RESOLUCION</code> \u2192 <code>Copy of FECHA_RESOLUCION</code>.</li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Segmenta los datos en flujos separados basados en condiciones espec\u00edficas.</li> <li>Salidas:<ul> <li><code>Agregar</code>: Registros nuevos.</li> <li><code>Modificar</code>: Registros existentes que requieren actualizaciones.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup 1</code>)</p> <ul> <li>Descripci\u00f3n: Enriquece los datos buscando informaci\u00f3n relacionada en <code>DIM_AFILIADOS</code>.</li> <li>Consulta SQL:     <pre><code>SELECT * FROM [Transversal].[DIM_AFILIADOS]\nWHERE [COD_TIPO_DOCUMENTO] = ? AND [NUMERO_DOCUMENTO] = ?\n</code></pre></li> <li>Columnas de Salida:<ul> <li><code>ID_AFILIADO</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos procesados en la tabla de destino <code>FACT_PQRS</code>.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>Transversal.FACT_PQRS</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup 1\n    participant ConditionalSplit as Conditional Split\n    participant AdoNetDestination as Destino de ADO NET\n\n    ExcelSource -&gt;&gt; DataConversion: Salida de origen de Excel\n    DataConversion -&gt;&gt; Lookup1: Data Conversion Output\n    Lookup1 -&gt;&gt; ConditionalSplit: Lookup Match Output\n    ConditionalSplit -&gt;&gt; AdoNetDestination: Filtrado por condici\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#restaurar-llaves-foraneas","title":"<code>Restaurar llaves for\u00e1neas</code>","text":""},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente <code>Restaurar llaves for\u00e1neas</code> es una tarea de ejecuci\u00f3n de SQL en un paquete SSIS que se encarga de restaurar las restricciones de clave for\u00e1nea en el esquema <code>Transversal</code>. Esta tarea utiliza un script din\u00e1mico para agregar nuevamente las restricciones desde una tabla persistente, seguida de la limpieza de dicha tabla.</p>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#componentes-del-flujo-de-datos_10","title":"Componentes del Flujo de Datos","text":"<ol> <li>Ejecuci\u00f3n de SQL (<code>Restaurar llaves for\u00e1neas</code>)</li> <li>Descripci\u00f3n: Restaura las restricciones de clave for\u00e1nea a partir de una tabla persistente (<code>ForeignKeys_Transversal</code>) en el esquema <code>Transversal</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:      <pre><code>-- Restaurar restricciones de clave for\u00e1nea\nDECLARE @restoreSql NVARCHAR(MAX) = '';\n\nSELECT @restoreSql += 'ALTER TABLE ' + QUOTENAME('Transversal') + '.' + QUOTENAME(fk.TableName) \n    + ' ADD CONSTRAINT ' + QUOTENAME(fk.ConstraintName) \n    + ' FOREIGN KEY (' + QUOTENAME(fk.ColumnName) + ') REFERENCES ' \n    + QUOTENAME(CASE WHEN fk.ReferencedTableName = 'DIM_TIEMPO' THEN 'Dwh' ELSE 'Transversal' END) + '.' + QUOTENAME(fk.ReferencedTableName) \n    + '(' + QUOTENAME(fk.ReferencedColumnName) + '); '\nFROM dbo.ForeignKeys_Transversal fk;\n\n-- Ejecutamos el SQL para restaurar las llaves for\u00e1neas\nEXEC sp_executesql @restoreSql;\n\n-- Limpiar la tabla persistente\nDROP TABLE dbo.ForeignKeys_Transversal;\n</code></pre></li> <li>Tiempo de espera: <code>30 segundos</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> <li>Descripci\u00f3n Adicional: Esta tarea realiza una restauraci\u00f3n din\u00e1mica basada en las definiciones de restricciones almacenadas previamente en <code>ForeignKeys_Transversal</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/02-TRANSVERSAL_FACT/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SQLTask as Restaurar llaves for\u00e1neas\n    participant TransversalSchema as Schema Transversal\n    participant DWH as Data Warehouse\n\n    SQLTask-&gt;&gt;TransversalSchema: Leer definiciones de llaves for\u00e1neas\n    SQLTask-&gt;&gt;TransversalSchema: Crear restricciones de clave for\u00e1nea\n    SQLTask-&gt;&gt;DWH: Verificar referencias cruzadas\n    SQLTask-&gt;&gt;TransversalSchema: Eliminar tabla `ForeignKeys_Transversal`</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/","title":"03. COLEGIO_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#colegio_dimensiones","title":"COLEGIO_DIMENSIONES","text":"<p>El paquete SSIS \"03-COLEGIO_DIMENSIONES\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar informaci\u00f3n relacionada con dimensiones clave del \u00e1mbito educativo, tales como a\u00f1os acad\u00e9micos, planes curriculares, poblaci\u00f3n matriculada y libros. Este paquete asegura un flujo de trabajo robusto y automatizado que consolida datos provenientes de m\u00faltiples fuentes, garantizando su calidad e integridad en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El prop\u00f3sito principal del paquete es estructurar y centralizar datos educativos cr\u00edticos, asegurando su disponibilidad y consistencia para an\u00e1lisis estrat\u00e9gicos y toma de decisiones operativas.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>FACT_ESTADO_MATRICULAS</code>, <code>DIM_PLAN_CURRICULAR</code>, <code>DIM_LIBROS</code>, <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Archivos Excel:</li> <li>Informaci\u00f3n sobre libros (<code>AM-EDF-153</code>).</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB para extracci\u00f3n y carga.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>B\u00fasquedas (<code>Lookup</code>):<ul> <li>Garantiza la consistencia mediante validaciones en tablas maestras como <code>DIM_PLAN_CURRICULAR</code> y <code>DIM_LIBROS</code>.</li> </ul> </li> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Genera claves auxiliares y valores predeterminados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_ANIO_ACADEMICO</code></li> <li><code>DIM_PLAN_CURRICULAR</code></li> <li><code>DIM_LIBROS</code></li> <li><code>DIM_POBLACION_MATRICULA</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Uso de scripts Python para automatizar tareas de descarga y validaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_ANIO_ACADEMICO:</p> <ul> <li><code>ANIO_ACADEMICO</code>: A\u00f1os acad\u00e9micos \u00fanicos extra\u00eddos de <code>FACT_ESTADO_MATRICULAS</code>.</li> </ul> </li> <li> <p>DIM_PLAN_CURRICULAR:</p> <ul> <li><code>COD_ASIGNATURA_SAP</code>, <code>ANIO_ACADEMICO</code>, <code>ASIGNATURA</code>, <code>PLAN_ESTUDIOS</code>.</li> </ul> </li> <li> <p>DIM_LIBROS:</p> <ul> <li><code>CODIGO_BARRAS</code>, <code>ITEM</code>, <code>TITULO</code>, <code>AUTOR</code>.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA:</p> <ul> <li><code>ID_POBLACION_MATRICULA</code>, <code>PARTNER</code>, <code>DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant FACT as FACT_ESTADO_MATRICULAS\n    participant PLAN as DIM_PLAN_CURRICULAR\n    participant LIBROS as DIM_LIBROS\n    participant POBLACION as DIM_POBLACION_MATRICULA\n\n    FACT -&gt;&gt; PLAN: Validaci\u00f3n de a\u00f1os acad\u00e9micos\n    PLAN -&gt;&gt; DIM_PLAN_CURRICULAR: Transformaci\u00f3n y carga\n    LIBROS -&gt;&gt; DIM_LIBROS: Datos transformados\n    POBLACION -&gt;&gt; DIM_POBLACION_MATRICULA: Inserci\u00f3n de datos</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#2-diagrama-er-para-tablas-de-dimensiones","title":"2. Diagrama ER para Tablas de Dimensiones","text":"<pre><code>erDiagram\n    DIM_ANIO_ACADEMICO {\n        int ANIO_ACADEMICO\n    }\n    DIM_PLAN_CURRICULAR {\n        string COD_ASIGNATURA_SAP\n        int ANIO_ACADEMICO\n        string ASIGNATURA\n        string PLAN_ESTUDIOS\n    }\n    DIM_LIBROS {\n        string CODIGO_BARRAS\n        string ITEM\n        string TITULO\n        string AUTOR\n    }\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION_MATRICULA\n        string PARTNER\n        string DOCUMENTO\n        string NOMBRE_COMPLETO\n    }\n    DIM_ANIO_ACADEMICO ||--|| DIM_PLAN_CURRICULAR : \"Relaciona a\u00f1os acad\u00e9micos\"\n    DIM_PLAN_CURRICULAR ||--|| DIM_LIBROS : \"Relaci\u00f3n con libros\"\n    DIM_LIBROS ||--|| DIM_POBLACION_MATRICULA : \"Asociaci\u00f3n de datos\"</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-poblar-dim_anio_academico","title":"Componente <code>Poblar DIM_ANIO_ACADEMICO</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Poblar DIM_ANIO_ACADEMICO</code> es una tarea de flujo de datos en un paquete SSIS que se encarga de procesar y cargar datos en la tabla <code>DIM_ANIO_ACADEMICO</code>. Este flujo incluye procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL) para garantizar datos limpios y estructurados en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>FACT_ESTADO_MATRICULAS</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde la tabla <code>FACT_ESTADO_MATRICULAS</code> en el esquema <code>Colegio</code> para generar un conjunto de a\u00f1os acad\u00e9micos \u00fanicos.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT DISTINCT [CA20_ANO_ACADEMICO] AS ANIO_ACADEMICO \nFROM [DWH_COMFENALCO].[Colegio].[FACT_ESTADO_MATRICULAS]\nORDER BY [CA20_ANO_ACADEMICO] ASC\n</code></pre></li> <li>Tiempo de espera: <code>30 segundos</code>.</li> <li>Permitir conversi\u00f3n impl\u00edcita de cadenas: <code>true</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code> (Tipo: Numeric, Precisi\u00f3n: 4).</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_ANIO_ACADEMICO</code> para determinar si un registro ya existe.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Colegio].[DIM_ANIO_ACADEMICO]\n</code></pre></li> <li>Comportamiento para filas sin coincidencias: Enviar filas a la salida sin coincidencias.</li> <li>Porcentaje de cach\u00e9 para filas sin coincidencias: <code>0%</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>ANIO_ACADEMICO</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code> (Coincidencias y sin coincidencias).</li> </ul> </li> </ul> </li> <li> <p>Divisi\u00f3n Condicional (<code>Conditional Split</code>)</p> <ul> <li>Descripci\u00f3n: Separa los registros en diferentes flujos de datos seg\u00fan la existencia de coincidencias en el paso de b\u00fasqueda.</li> <li>Condiciones:<ul> <li><code>Agregar</code>: Filas donde <code>ANIO_ACADEMICO</code> es nulo (filas nuevas).</li> <li><code>Ya incluido</code>: Filas donde <code>ANIO_ACADEMICO</code> ya existe.</li> <li><code>Conditional Split Error Output</code>: Filas con errores o problemas.</li> </ul> </li> <li>Expresi\u00f3n de condici\u00f3n:     <pre><code>ISNULL(Lookup.ANIO_ACADEMICO)\n</code></pre></li> </ul> </li> <li>Destino de Datos ADO.NET (<code>DIM_ANIO_ACADEMICO</code>)<ul> <li>Descripci\u00f3n: Carga los registros nuevos en la tabla <code>DIM_ANIO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Colegio\".\"DIM_ANIO_ACADEMICO\"</code>.</li> <li>Tama\u00f1o del lote: <code>0</code> (por defecto).</li> <li>Tiempo de espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n masiva: Activada.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>ANIO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-procesar-dim_plan_curricular","title":"Componente <code>Procesar DIM_PLAN_CURRICULAR</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente <code>DIM_PLAN_CURRICULAR</code> es una tarea de flujo de datos en un paquete SSIS que procesa informaci\u00f3n relacionada con el plan curricular de asignaturas. Este flujo realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) para consolidar los datos desde un sistema fuente hacia una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>PLAN_CURRICULAR SAP</code>)</p> <ul> <li>Descripci\u00f3n: Este componente extrae datos desde el sistema SAP ERP, relacionado con asignaturas y planes de estudio.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>WITH Curriculum AS (\nSELECT\n    objid AS ID_PLAN_ESTUDIOS,\n    CASE\n        WHEN objid = '02000000' THEN 'PREESCOLAR'\n        WHEN objid = '02000001' THEN 'PRIMARIA'\n        WHEN objid = '02000003' THEN 'BASICA/MEDIA SECUNDARIA'\n        ELSE 'OTROS'\n    END AS PLAN_ESTUDIOS\nFROM SAPABAP1.HRP1000\nWHERE plvar = '01' -- Plan activos\n    AND Otype = 'SC' -- Plan de estudios\n    AND langu = 'S' -- Espa\u00f1ol\n),\nSubjects as(\nSELECT\n  a.objid AS OBJETO_SAP_ASIGNATURA,\n  a.sobid AS ID_PLAN_ESTUDIOS,\n  b.peryr AS ANIO_ACADEMICO\n FROM SAPABAP1.HRP1001 as a\n INNER join\n  SAPABAP1.HRP1739 as b On a.otype = b.otype AND  A.objid = b.objid\n WHERE a.plvar = '01' and --\u201cPlan activo\n  A.otype = 'SM' and --\u201cEstudios\n  a.sclas = 'SC' and\n  --a.sobid = PE and --(Par\u00e1metros)\n  b.peryr &gt;= 2021 and --(Par\u00e1metro\n  b.perid = '001'-- \u201cPer. Comfenalco\n),\nCurriculumDetails AS (\nSelect\n  aclevelvar AS PROGRAMA_PLAN_ESTUDIOS\n From SAPABAP1.HRP1730\n Where plvar = '01'\n),\nSubjectDetails AS (\n SELECT\n  objid AS OBJETO_SAP_ASIGNATURA,\n  short,\n  stext,\n  --*,\n  CASE\n    WHEN SUBSTRING(SHORT, 1, 2) IN ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11','JD','PJ','TR') THEN\n        CASE SUBSTRING(SHORT, 1, 2)\n            WHEN '01' THEN 1\n            WHEN '02' THEN 2\n            WHEN '03' THEN 3\n            WHEN '04' THEN 4\n            WHEN '05' THEN 5\n            WHEN '06' THEN 6\n            WHEN '07' THEN 10\n            WHEN '08' THEN 11\n            WHEN '09' THEN 12\n            WHEN '10' THEN 13\n            WHEN '11' THEN 14\n            WHEN 'JD' THEN 7\n            WHEN 'PJ' THEN 8\n            WHEN 'TR' THEN 9\n        END\n    ELSE '-1'\nEND AS ID_CURSO,\nCASE\n    WHEN SUBSTRING(SHORT, 1, 2) IN ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11','JD','PJ','TR') THEN\n        CASE SUBSTRING(SHORT, 1, 2)\n            WHEN '01' THEN 'PRIMERO'\n            WHEN '02' THEN 'SEGUNDO'\n            WHEN '03' THEN 'TERCERO'\n            WHEN '04' THEN 'CUARTO'\n            WHEN '05' THEN 'QUINTO'\n            WHEN '06' THEN 'SEXTO'\n            WHEN '07' THEN 'SEPTIMO'\n            WHEN '08' THEN 'OCTAVO'\n            WHEN '09' THEN 'NOVENO'\n            WHEN '10' THEN 'DECIMO'\n            WHEN '11' THEN 'ONCE'\n            WHEN 'JD' THEN 'PREJARD\u00cdN'\n            WHEN 'PJ' THEN 'JARD\u00cdN'\n            WHEN 'TR' THEN 'TRANSICI\u00d3N'\n        END\n    ELSE 'TRANSVERSAL'\nEND AS CURSO\n FROM SAPABAP1.hrp1000\n WHERE otype = 'SM'\n AND plvar = '01'\n)\nSELECT\nsd.short AS COD_ASIGNATURA_SAP,\ns.ANIO_ACADEMICO,\ns.OBJETO_SAP_ASIGNATURA,\nsd.stext AS ASIGNATURA,\nsd.ID_CURSO,\n--sd.CURSO,\ns.ID_PLAN_ESTUDIOS,\nc.PLAN_ESTUDIOS,\nsd.short || '_' || s.ANIO_ACADEMICO AS ID_ASIGNATURA_AUXILIAR\nFROM Subjects AS s\nINNER JOIN Curriculum AS c ON s.ID_PLAN_ESTUDIOS = c.ID_PLAN_ESTUDIOS\nINNER JOIN SubjectDetails AS sd ON s.OBJETO_SAP_ASIGNATURA = sd.OBJETO_SAP_ASIGNATURA\nORDER BY s.ANIO_ACADEMICO,sd.short\n</code></pre></li> <li>Tiempo de espera: <code>30 segundos</code>.</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[SAP_ERP]</code>.</li> <li>Columnas de Salida:<ul> <li><code>COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>OBJETO_SAP_ASIGNATURA</code></li> <li><code>ASIGNATURA</code></li> <li><code>ID_CURSO</code></li> <li><code>ID_PLAN_ESTUDIOS</code></li> <li><code>PLAN_ESTUDIOS</code></li> <li><code>ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas de entrada para garantizar la compatibilidad con las transformaciones posteriores.</li> <li>Columnas Convertidas:<ul> <li><code>COD_ASIGNATURA_SAP</code> \u2192 <code>Copy of COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code> \u2192 <code>Copy of ANIO_ACADEMICO</code></li> <li><code>OBJETO_SAP_ASIGNATURA</code> \u2192 <code>Copy of OBJETO_SAP_ASIGNATURA</code></li> <li><code>ASIGNATURA</code> \u2192 <code>Copy of ASIGNATURA</code></li> <li><code>ID_CURSO</code> \u2192 <code>Copy of ID_CURSO</code></li> <li><code>ID_PLAN_ESTUDIOS</code> \u2192 <code>Copy of ID_PLAN_ESTUDIOS</code></li> <li><code>PLAN_ESTUDIOS</code> \u2192 <code>Copy of PLAN_ESTUDIOS</code></li> <li><code>ID_ASIGNATURA_AUXILIAR</code> \u2192 <code>Copy of ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una comparaci\u00f3n de los datos con la tabla <code>DIM_PLAN_CURRICULAR</code> para enriquecer los datos en el flujo de trabajo.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT\n    [ID_ASIGNATURA],\n    [COD_ASIGNATURA_SAP],\n    [ANIO_ACADEMICO],\n    [COD_ASIGNATURA_SAP] + '_' + CAST([ANIO_ACADEMICO] AS NVARCHAR) AS ID_ASIGNATURA_AUXILIAR\nFROM [DWH_COMFENALCO].[Colegio].[DIM_PLAN_CURRICULAR]\n</code></pre></li> <li>Comportamiento para filas sin coincidencias: Enviar a la salida \"No Match Output\".</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino_OLEDB]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>Copy of ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_ASIGNATURA</code></li> <li><code>COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>ID_ASIGNATURA_AUXILIAR</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_PLAN_CURRICULAR</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>DIM_PLAN_CURRICULAR</code> dentro del esquema <code>Colegio</code> en el Data Warehouse.</li> <li>Propiedades:<ul> <li>Tabla de Destino: <code>\"Colegio\".\"DIM_PLAN_CURRICULAR\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code>.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activado (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexi\u00f3n: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> <li>Columnas de Entrada:<ul> <li><code>COD_ASIGNATURA_SAP</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>OBJETO_SAP_ASIGNATURA</code></li> <li><code>ASIGNATURA</code></li> <li><code>ID_CURSO</code></li> <li><code>ID_PLAN_ESTUDIOS</code></li> <li><code>PLAN_ESTUDIOS</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant AdoNetSource as PLAN_CURRICULAR SAP\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup\n    participant AdoNetDestination as DIM_PLAN_CURRICULAR\n\n    AdoNetSource -&gt;&gt; DataConversion: Salida de origen de ADO NET\n    DataConversion -&gt;&gt; Lookup: Data Conversion Output\n    Lookup -&gt;&gt; AdoNetDestination: Lookup No Match Output</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-descargar_am-edf-153","title":"Componente <code>Descargar_AM-EDF-153</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente <code>Descargar_AM-EDF-153</code> es una tarea de ejecuci\u00f3n de proceso en un paquete SSIS que se encarga de ejecutar un script Python para conectar a SharePoint y descargar archivos manuales relacionados con el proyecto. Esta tarea utiliza la funcionalidad <code>Execute Process</code> de SSIS para garantizar una integraci\u00f3n fluida con sistemas externos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#detalles-del-componente","title":"Detalles del Componente","text":"<ol> <li> <p>Identificador del Componente:</p> <ul> <li>DTSID: <code>{dc092a95-1b4b-442c-9f34-b34054bbb72d}</code></li> </ul> </li> <li> <p>Tipo de Componente:</p> <ul> <li><code>Microsoft.ExecuteProcess</code></li> </ul> </li> <li> <p>Descripci\u00f3n:</p> <ul> <li>Tarea dise\u00f1ada para ejecutar un proceso externo, en este caso, un script Python que se conecta a SharePoint y descarga los archivos requeridos.</li> </ul> </li> <li> <p>Propiedades:</p> <ul> <li>Executable:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>WorkingDirectory:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\03.Archivos_Manuales\\04.Colegio\n</code></pre></li> <li>Arguments:      <pre><code>01.SharePoint_Connection_AM-EDF-153.py\n</code></pre></li> </ul> </li> </ol> <p>Propiedades Avanzadas</p> <ol> <li> <p>Configuraciones de Expresi\u00f3n:</p> <ul> <li>Executable:      <pre><code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"\n</code></pre></li> <li>WorkingDirectory:      <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\04.Colegio\"\n</code></pre></li> </ul> </li> <li> <p>Detalles del Proceso:</p> <ul> <li>Ejecutable:<ul> <li>Ubicaci\u00f3n del script de Python a ejecutar.</li> </ul> </li> <li>Argumentos:<ul> <li>Nombre del archivo de script: <code>01.SharePoint_Connection_AM-EDF-153.py</code>.</li> </ul> </li> <li>Directorio de Trabajo:<ul> <li>Ruta donde se encuentra el script y los archivos necesarios para su ejecuci\u00f3n.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as Script de Python\n    participant SharePoint as Servidor SharePoint\n\n    SSIS-&gt;&gt;Python: Ejecutar `01.SharePoint_Connection_AM-EDF-153.py`\n    Python-&gt;&gt;SharePoint: Conectar a SharePoint\n    SharePoint--&gt;&gt;Python: Confirmar conexi\u00f3n\n    Python-&gt;&gt;SharePoint: Descargar archivos\n    SharePoint--&gt;&gt;Python: Retornar archivos descargados\n    Python--&gt;&gt;SSIS: Confirmar finalizaci\u00f3n del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-procesar-dim_libros","title":"Componente <code>Procesar DIM_LIBROS</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar DIM_LIBROS</code> es una tarea de flujo de datos en un paquete SSIS que realiza operaciones ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) sobre informaci\u00f3n de libros. Los datos son extra\u00eddos desde un archivo de Excel, transformados mediante conversiones y columnas derivadas, y finalmente cargados en una base de datos destino. Adicionalmente, el flujo incluye una operaci\u00f3n de b\u00fasqueda (<code>Lookup</code>) para enriquecer los datos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos Excel (<code>AM-EDF-153</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde una hoja de c\u00e1lculo Excel.</li> <li>Propiedades:<ul> <li><code>OpenRowset</code>: <code>Sheet1$</code></li> <li><code>AccessMode</code>: <code>0</code> (Modo de acceso directo)</li> <li><code>CommandTimeout</code>: <code>0</code> (Sin l\u00edmite de tiempo)</li> </ul> </li> <li>Conexiones:<ul> <li><code>OleDbConnection</code>: Conexi\u00f3n a Excel referenciada por el administrador de conexiones <code>Excel_Connection_Dim_Libros</code>.</li> </ul> </li> <li>Columnas de Salida:     <code>CODIGO_BARRAS</code>, <code>ITEM</code>, <code>AUTOR</code>, <code>TITULO</code>.</li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (<code>Data Conversion</code>)</p> <ul> <li>Descripci\u00f3n: Convierte las columnas de datos para garantizar compatibilidad con los componentes posteriores.</li> <li>Columnas de Entrada:     <code>CODIGO_BARRAS</code>, <code>ITEM</code>, <code>AUTOR</code>, <code>TITULO</code>.</li> <li>Columnas de Salida:     <code>Copy of CODIGO_BARRAS</code>, <code>Copy of ITEM</code>, <code>Copy of AUTOR</code>, <code>Copy of TITULO</code>.</li> </ul> </li> <li> <p>Columna Derivada (<code>ID_LIBRO_AUXILIAR</code>)</p> <ul> <li>Descripci\u00f3n: Crea una nueva columna <code>ID_LIBRO_AUXILIAR</code> combinando <code>CODIGO_BARRAS</code> e <code>ITEM</code>.</li> <li>Expresi\u00f3n Derivada:      <pre><code>CODIGO_BARRAS + \"_\" + ITEM\n</code></pre></li> </ul> </li> <li> <p>B\u00fasqueda (<code>Lookup</code>)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_LIBROS</code> para enriquecer los datos con informaci\u00f3n adicional.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>SELECT [ID_LIBRO], [CODIGO_BARRAS]+'_'+[ITEM] AS ID_LIBRO_AUXILIAR\nFROM [DWH_COMFENALCO].[Colegio].[DIM_LIBROS]\n</code></pre></li> </ul> </li> <li>Columnas de Salida:     <code>ID_LIBRO</code>, <code>ID_LIBRO_AUXILIAR</code>.</li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_LIBROS</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>DIM_LIBROS</code> en la base de datos destino.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"DIM_LIBROS\"</code></li> <li><code>BatchSize</code>: <code>0</code> (Predeterminado)</li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Columnas de Entrada:     <code>Copy of CODIGO_BARRAS</code>, <code>Copy of ITEM</code>, <code>Copy of AUTOR</code>, <code>Copy of TITULO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as AM-EDF-153 (Fuente Excel)\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as ID_LIBRO_AUXILIAR\n    participant Lookup as Lookup\n    participant AdoNetDestination as DIM_LIBROS (Destino)\n\n    ExcelSource-&gt;&gt;DataConversion: Salida de datos Excel\n    DataConversion-&gt;&gt;DerivedColumn: Salida de datos convertidos\n    DerivedColumn-&gt;&gt;Lookup: Salida de columna derivada\n    Lookup-&gt;&gt;AdoNetDestination: Salida de b\u00fasqueda no coincidente</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componente-agregar-1-a-dim_poblacion","title":"Componente <code>Agregar -1 a DIM_POBLACION</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente <code>Agregar -1 a DIM_POBLACION</code> es una tarea de ejecuci\u00f3n SQL en un paquete SSIS. Su prop\u00f3sito es verificar si existe un registro con <code>ID_POBLACION_MATRICULA = -1</code> en la tabla <code>[DIM_POBLACION_MATRICULA]</code> del esquema <code>[Colegio]</code> y, si no existe, insertarlo con valores predeterminados.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li>Tarea Ejecutar SQL (<code>Agregar -1 a DIM_POBLACION</code>)<ul> <li>Descripci\u00f3n: Ejecuta un script SQL que realiza las siguientes operaciones:<ol> <li>Verifica si ya existe un registro con <code>ID_POBLACION_MATRICULA = -1</code>.</li> <li>Si no existe:<ul> <li>Activa <code>IDENTITY_INSERT</code> en la tabla para permitir la inserci\u00f3n de un valor espec\u00edfico en la columna de clave primaria.</li> <li>Inserta un registro con valores predeterminados.</li> <li>Desactiva <code>IDENTITY_INSERT</code>.</li> </ul> </li> </ol> </li> <li>Propiedades:<ul> <li>Conexi\u00f3n: <code>{C2A27DDB-56C2-4889-8A4B-7AA7124DFFD7}</code>.</li> <li>Consulta SQL:   <pre><code>-- Verificar si el registro ya existe\nIF NOT EXISTS (\n    SELECT 1\n    FROM [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA]\n    WHERE [ID_POBLACION_MATRICULA] = -1\n)\nBEGIN\n    -- Activar IDENTITY_INSERT para la tabla\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] ON;\n\n    -- Insertar el registro con ID_POBLACION_MATRICULA = -1\n    INSERT INTO [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA]\n    (\n        [ID_POBLACION_MATRICULA],\n        [PARTNER],\n        [TIPO_DOCUMENTO],\n        [DOCUMENTO],\n        [NOMBRE_COMPLETO],\n        [GENERO],\n        [DIRECCION],\n        [TELEFONO],\n        [CORREO],\n        [FECHA_NACIMIENTO]\n    )\n    VALUES\n    (\n        -1,\n        'N/A', -- PARTNER\n        'N/A', -- TIPO_DOCUMENTO\n        'N/A', -- DOCUMENTO\n        'Estudiantes sin cruce', -- NOMBRE_COMPLETO\n        'N/A', -- GENERO\n        'N/A', -- DIRECCION\n        'N/A', -- TELEFONO\n        'N/A', -- CORREO\n        NULL -- FECHA_NACIMIENTO\n    );\n\n    -- Desactivar IDENTITY_INSERT para la tabla\n    SET IDENTITY_INSERT [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] OFF;\nEND\n</code></pre></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/","title":"03 COLEGIO DIMENSIONES AUXILIAR","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#colegio_dimensiones_auxiliar","title":"COLEGIO_DIMENSIONES_AUXILIAR","text":"<p>El paquete SSIS \"03-COLEGIO_DIMENSIONES_AUXILIAR\" est\u00e1 dise\u00f1ado para gestionar la transferencia, transformaci\u00f3n y carga (ETL) de datos educativos relacionados con cursos, grados, poblaciones matriculadas y dimensiones de tiempo. Este paquete asegura que los datos provenientes de ambientes remotos se integren eficientemente en el Data Warehouse <code>DWH_COMFENALCO</code>, garantizando su calidad y disponibilidad para an\u00e1lisis.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es sincronizar y centralizar datos de dimensiones educativas clave, asegurando la consistencia y calidad de la informaci\u00f3n en el Data Warehouse. Esto facilita la toma de decisiones basada en datos para an\u00e1lisis operativos y estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos Remotas:</li> <li><code>DIM_CURSO</code>, <code>DIM_GRADO</code>, <code>DIM_POBLACION_MATRICULA</code>, <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET para lectura de datos remotos.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaci\u00f3n de Registros:<ul> <li>Se asegura que los datos est\u00e9n completos antes de cargarlos.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con las tablas destino.</li> </ul> </li> <li>Inserciones Masivas (<code>Bulk Insert</code>):<ul> <li>Habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_CURSO</code></li> <li><code>DIM_GRADO</code></li> <li><code>DIM_POBLACION_MATRICULA</code></li> <li><code>DIM_TIEMPO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_CURSO:</p> <ul> <li><code>ID_CURSO</code>, <code>DESC_CURSO</code>, <code>FECHA_CREACION</code>, <code>ESTADO_REGISTRO</code>.</li> </ul> </li> <li> <p>DIM_GRADO:</p> <ul> <li><code>ID_GRADO</code>, <code>DESC_GRADO</code>, <code>FECHA_CREACION</code>, <code>ESTADO_REGISTRO</code>.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA:</p> <ul> <li><code>ID_POBLACION_MATRICULA</code>, <code>PARTNER</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>NOMBRE_COMPLETO</code>, <code>GENERO</code>, <code>DIRECCION</code>, <code>TELEFONO</code>, <code>CORREO</code>, <code>FECHA_NACIMIENTO</code>.</li> </ul> </li> <li> <p>DIM_TIEMPO:</p> <ul> <li><code>ID_FECHA</code>, <code>FECHA</code>, <code>DESC_FECHA</code>, <code>ID_SEMANA</code>, <code>DESC_SEMANA</code>, <code>ID_MES</code>, <code>DESC_MES</code>, <code>ID_ANIO</code>, <code>FESTIVO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant CURSO_ORIG as DIM_CURSO_ORIG\n    participant CURSO_DEST as DIM_CURSO_DEST\n    participant GRADO_ORIG as DIM_GRADO_ORIG\n    participant GRADO_DEST as DIM_GRADO_DEST\n    participant POB_ORIG as DIM_POBLACION_MATRICULA_ORIG\n    participant POB_DEST as DIM_POBLACION_MATRICULA_DEST\n    participant TIEMPO_ORIG as DIM_TIEMPO_ORIG\n    participant TIEMPO_DEST as DIM_TIEMPO_DEST\n\n    CURSO_ORIG -&gt;&gt; CURSO_DEST: Transferir datos de DIM_CURSO\n    GRADO_ORIG -&gt;&gt; GRADO_DEST: Transferir datos de DIM_GRADO\n    POB_ORIG -&gt;&gt; POB_DEST: Transferir datos de DIM_POBLACION_MATRICULA\n    TIEMPO_ORIG -&gt;&gt; TIEMPO_DEST: Transferir datos de DIM_TIEMPO</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#2-diagrama-er-para-tablas-de-dimensiones","title":"2. Diagrama ER para Tablas de Dimensiones","text":"<pre><code>erDiagram\n    DIM_CURSO {\n        int ID_CURSO\n        string DESC_CURSO\n        date FECHA_CREACION\n        string ESTADO_REGISTRO\n    }\n    DIM_GRADO {\n        int ID_GRADO\n        string DESC_GRADO\n        date FECHA_CREACION\n        string ESTADO_REGISTRO\n    }\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION_MATRICULA\n        string PARTNER\n        string TIPO_DOCUMENTO\n        string DOCUMENTO\n        string NOMBRE_COMPLETO\n        string GENERO\n        string DIRECCION\n        string TELEFONO\n        string CORREO\n        date FECHA_NACIMIENTO\n    }\n    DIM_TIEMPO {\n        int ID_FECHA\n        date FECHA\n        string DESC_FECHA\n        int ID_SEMANA\n        string DESC_SEMANA\n        int ID_MES\n        string DESC_MES\n        int ID_ANIO\n        boolean FESTIVO\n    }</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componente-traer-a-local-tablas-disponibles-en-ambiente-comfenalco","title":"Componente <code>Traer a local tablas disponibles en ambiente Comfenalco</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente <code>Traer a local tablas disponibles en ambiente Comfenalco</code> es una tarea de flujo de datos en un paquete SSIS que transfiere datos desde un origen en un ambiente remoto hacia tablas de destino en un ambiente local. Est\u00e1 dise\u00f1ado para extraer, transformar y cargar (ETL) datos de m\u00faltiples tablas relacionadas con cursos, grados y poblaciones matriculadas.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>DIM_CURSO_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de la tabla <code>[Colegio].[DIM_CURSO]</code> en un origen remoto utilizando ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Colegio].[DIM_CURSO]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_CURSO</code></li> <li><code>DESC_CURSO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_CURSO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos transformados en la tabla <code>[Colegio].[DIM_CURSO]</code> del ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Colegio\".\"DIM_CURSO\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_CURSO</code></li> <li><code>DESC_CURSO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos ADO.NET (<code>DIM_GRADO_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de la tabla <code>[Colegio].[DIM_GRADO]</code> en un origen remoto utilizando ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Colegio].[DIM_GRADO]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_GRADO</code></li> <li><code>DESC_GRADO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_GRADO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos transformados en la tabla <code>[Colegio].[DIM_GRADO]</code> del ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Colegio\".\"DIM_GRADO\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_GRADO</code></li> <li><code>DESC_GRADO</code></li> <li><code>FECHA_CREACION</code></li> <li><code>ESTADO_REGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Fuente de Datos ADO.NET (<code>DIM_POBLACION_MATRICULA_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Consume datos de la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code> en un origen remoto utilizando ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_POBLACION_MATRICULA</code></li> <li><code>PARTNER</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>GENERO</code></li> <li><code>DIRECCION</code></li> <li><code>TELEFONO</code></li> <li><code>CORREO</code></li> <li><code>FECHA_NACIMIENTO</code></li> </ul> </li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_POBLACION_MATRICULA_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga datos transformados en la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code> del ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Colegio\".\"DIM_POBLACION_MATRICULA\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_POBLACION_MATRICULA</code></li> <li><code>PARTNER</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> <li><code>NOMBRE_COMPLETO</code></li> <li><code>GENERO</code></li> <li><code>DIRECCION</code></li> <li><code>TELEFONO</code></li> <li><code>CORREO</code></li> <li><code>FECHA_NACIMIENTO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#conexiones-entre-componentes","title":"Conexiones entre Componentes","text":"<ol> <li>DIM_CURSO_ORIG \u2192 DIM_CURSO_DEST </li> <li>DIM_GRADO_ORIG \u2192 DIM_GRADO_DEST </li> <li>DIM_POBLACION_MATRICULA_ORIG \u2192 DIM_POBLACION_MATRICULA_DEST</li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant CURSO_ORIG as DIM_CURSO_ORIG\n    participant CURSO_DEST as DIM_CURSO_DEST\n    participant GRADO_ORIG as DIM_GRADO_ORIG\n    participant GRADO_DEST as DIM_GRADO_DEST\n    participant POB_ORIG as DIM_POBLACION_MATRICULA_ORIG\n    participant POB_DEST as DIM_POBLACION_MATRICULA_DEST\n\n    CURSO_ORIG -&gt;&gt; CURSO_DEST: Transferencia de datos DIM_CURSO\n    GRADO_ORIG -&gt;&gt; GRADO_DEST: Transferencia de datos DIM_GRADO\n    POB_ORIG -&gt;&gt; POB_DEST: Transferencia de datos DIM_POBLACION_MATRICULA</code></pre>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componente-traer-dim-tiempo-a-local","title":"Componente <code>Traer Dim Tiempo a Local</code>","text":""},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente <code>Traer Dim Tiempo a Local</code> es un flujo de datos en SSIS dise\u00f1ado para transferir y cargar datos de la dimensi\u00f3n <code>DIM_TIEMPO</code> desde un ambiente remoto hacia un ambiente local. Este flujo est\u00e1 deshabilitado por defecto (<code>Disabled=\"True\"</code>), y su objetivo principal es mantener sincronizados los datos de tiempo.</p>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos ADO.NET (<code>DIM_TIEMPO_ORIG</code>)</p> <ul> <li>Descripci\u00f3n: Extrae datos de la tabla <code>[Dwh].[DIM_TIEMPO]</code> en un origen remoto utilizando una conexi\u00f3n ADO.NET.</li> <li>Propiedades:<ul> <li>Consulta SQL: No especificada directamente.</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Modo de Acceso: Lectura de la tabla <code>[Dwh].[DIM_TIEMPO]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO]</code>.</li> </ul> </li> <li>Columnas de Salida:  <code>ID_FECHA</code>, <code>FECHA</code>, <code>DESC_FECHA</code>, <code>ID_SEMANA</code>, <code>DESC_SEMANA</code>, <code>ID_NO_MES</code>, <code>DESC_NO_MES</code>, <code>ID_MES</code>, <code>DESC_MES</code>, <code>DESC_MES_CORTA</code>, <code>ID_BIMESTRE</code>, <code>DESC_BIMESTRE</code>, <code>ID_TRIMESTRE</code>, <code>DESC_TRIMESTRE</code>, <code>ID_CUATRIMESTRE</code>, <code>DESC_CUATRIMESTRE</code>, <code>ID_SEMESTRE</code>, <code>DESC_SEMESTRE</code>, <code>ID_ANIO</code>, <code>ID_ANIO_ANT</code>, <code>NUM_DIA_SEMANA</code>, <code>FESTIVO</code>, <code>FECHA_CORTA</code></li> </ul> </li> <li> <p>Destino de Datos ADO.NET (<code>DIM_TIEMPO_DEST</code>)</p> <ul> <li>Descripci\u00f3n: Carga los datos extra\u00eddos y transformados en la tabla <code>[Dwh].[DIM_TIEMPO]</code> en el ambiente local.</li> <li>Propiedades:<ul> <li>Nombre de la Tabla de Destino: <code>\"Dwh\".\"DIM_TIEMPO\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (predeterminado).</li> <li>Tiempo de Espera: <code>30 segundos</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible</code>).</li> </ul> </li> <li>Conexiones:<ul> <li>Connection Manager: <code>Project.ConnectionManagers[DWH_COMFENALCO_Destino]</code>.</li> </ul> </li> <li>Columnas de Entrada: <code>ID_FECHA</code>, <code>FECHA</code>, <code>DESC_FECHA</code>, <code>ID_SEMANA</code>, <code>DESC_SEMANA</code>, <code>ID_NO_MES</code>, <code>DESC_NO_MES</code>, <code>ID_MES</code>, <code>DESC_MES</code>, <code>DESC_MES_CORTA</code>, <code>ID_BIMESTRE</code>, <code>DESC_BIMESTRE</code>, <code>ID_TRIMESTRE</code>, <code>DESC_TRIMESTRE</code>, <code>ID_CUATRIMESTRE</code>, <code>DESC_CUATRIMESTRE</code>, <code>ID_SEMESTRE</code>, <code>DESC_SEMESTRE</code>, <code>ID_ANIO</code>, <code>ID_ANIO_ANT</code>, <code>NUM_DIA_SEMANA</code>, <code>FESTIVO</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#conexiones-entre-componentes_1","title":"Conexiones entre Componentes","text":"<ol> <li>DIM_TIEMPO_ORIG \u2192 DIM_TIEMPO_DEST</li> </ol>"},{"location":"02.Paquetes_SSIS/03-COLEGIO_DIMENSIONES_AUXILIAR/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant TIEMPO_ORIG as DIM_TIEMPO_ORIG\n    participant TIEMPO_DEST as DIM_TIEMPO_DEST\n\n    TIEMPO_ORIG -&gt;&gt; TIEMPO_DEST: Transferencia de datos DIM_TIEMPO</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/","title":"04. COLEGIO_FACT","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#colegio_fact","title":"COLEGIO_FACT","text":"<p>El paquete SSIS \"04-COLEGIO_FACT\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar datos cr\u00edticos relacionados con operaciones educativas en diversas \u00e1reas como matr\u00edculas, transporte, biblioteca y evaluaciones. Este paquete asegura la integraci\u00f3n efectiva de datos en el Data Warehouse <code>DWH_COMFENALCO</code>, garantizando su calidad y disponibilidad para an\u00e1lisis y reportes estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es consolidar informaci\u00f3n operativa y educativa para apoyar la toma de decisiones basada en datos. Esto incluye la transformaci\u00f3n de datos de diversas fuentes, su validaci\u00f3n y enriquecimiento antes de su carga en el Data Warehouse.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos SAP y SQL Server:</li> <li><code>FACT_TRANSPORTE</code>, <code>FACT_CUPOS_NEGADOS</code>, <code>FACT_AUSENTISMO_DOCENTE</code>, <code>FACT_BIBLIOTECA</code>.</li> <li>Archivos Excel:</li> <li>Informaci\u00f3n de permisos, ausentismo, y evaluaciones.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB para extracci\u00f3n y carga.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaci\u00f3n de Datos (<code>Lookup</code>):<ul> <li>Comprobaci\u00f3n en tablas maestras como <code>DIM_POBLACION_MATRICULA</code>, <code>DIM_CURSO</code>, y <code>DIM_LIBROS</code>.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad con tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>C\u00e1lculo de identificadores \u00fanicos y asignaciones condicionales.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>FACT_TRANSPORTE</code></li> <li><code>FACT_CUPOS_NEGADOS</code></li> <li><code>FACT_BIBLIOTECA</code></li> <li><code>FACT_PERMISO_ESTUDIANTE</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Uso de scripts Python para automatizaci\u00f3n de descargas y validaci\u00f3n de datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>FACT_TRANSPORTE:</p> <ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ID_FECHA</code>, <code>ANIO_ACADEMICO</code>, <code>CATEGORIA_SERVICIO</code>.</li> </ul> </li> <li> <p>FACT_CUPOS_NEGADOS:</p> <ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_ESTADO</code>.</li> </ul> </li> <li> <p>FACT_BIBLIOTECA:</p> <ul> <li><code>ITEM_LIBRO</code>, <code>FECHA_PRESTAMO</code>, <code>FECHA_DEVOLUCION</code>, <code>BP_ESTUDIANTE</code>.</li> </ul> </li> <li> <p>FACT_PERMISO_ESTUDIANTE:</p> <ul> <li><code>BP_ESTUDIANTE</code>, <code>FECHA_PERMISO</code>, <code>MOTIVO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de SAP y SQL Server\n    SSIS -&gt;&gt; Excel: Leer informaci\u00f3n operativa y educativa\n    SSIS -&gt;&gt; Python: Automatizar descargas\n    SSIS -&gt;&gt; DWH: Cargar datos procesados</code></pre> <ol> <li>Diagrama ER para Tablas de Hechos</li> </ol> <pre><code>erDiagram\n    FACT_TRANSPORTE {\n        string PARTNER_ESTUDIANTE\n        date FECHA_INICIO_SERVICIO\n        int ANIO_ACADEMICO\n        string CATEGORIA_SERVICIO\n    }\n    FACT_CUPOS_NEGADOS {\n        string PARTNER_ESTUDIANTE\n        int ANIO_ACADEMICO\n        date FECHA_ESTADO\n    }\n    FACT_BIBLIOTECA {\n        string ITEM_LIBRO\n        date FECHA_PRESTAMO\n        string BP_ESTUDIANTE\n    }\n    FACT_PERMISO_ESTUDIANTE {\n        string BP_ESTUDIANTE\n        date FECHA_PERMISO\n        string MOTIVO\n    }\n    FACT_TRANSPORTE ||--|| FACT_CUPOS_NEGADOS : \"Relaci\u00f3n de estudiantes\"\n    FACT_BIBLIOTECA ||--|| FACT_PERMISO_ESTUDIANTE : \"Conexi\u00f3n por estudiantes\"</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-01-fact_enfermeria","title":"Componente <code>EP-EDF-01 FACT_ENFERMERIA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-01 FACT_ENFERMERIA</code> es un proceso de ejecuci\u00f3n en un paquete SSIS dise\u00f1ado para correr un script de Python que realiza tareas relacionadas con la descarga de informaci\u00f3n para la facturaci\u00f3n de enfermer\u00eda. El componente utiliza una ruta espec\u00edfica y argumentos para ejecutar el script.</p> <p>Detalles del Componente</p> <ul> <li>Nombre del Componente: EP-EDF-01 FACT_ENFERMERIA</li> <li>Tipo: Execute Process Task</li> <li>Descripci\u00f3n: Ejecuta un script de Python encargado de descargar datos espec\u00edficos relacionados con el proceso <code>EP-EDF-01</code>.</li> <li>ID del Componente: <code>{4412de09-7ca0-4c06-ab1a-20e07c589832}</code></li> </ul> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-01</code> Tiempo de Espera No especificado (valor predeterminado) ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-01</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-01`\n    Python -&gt;&gt; Python: Descarga datos de `EP-EDF-01`\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-02-fact_ausentismo_docente","title":"Componente <code>EP-EDF-02 FACT_AUSENTISMO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-02 FACT_AUSENTISMO_DOCENTE</code> es un proceso dise\u00f1ado para ejecutar un script de Python que gestiona la descarga de informaci\u00f3n relacionada con el ausentismo docente. El componente utiliza configuraciones din\u00e1micas para el ejecutable y el directorio de trabajo, maximizando la flexibilidad y portabilidad dentro del entorno del proyecto.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-02 FACT_AUSENTISMO_DOCENTE Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python que descarga datos relacionados con el ausentismo docente. ID del Componente <code>{34225bf4-f1be-4808-9dfa-a648f4e220fc}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-02</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_1","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-02</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-02`\n    Python -&gt;&gt; Python: Descarga datos relacionados con ausentismo docente\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-03-fact_reemplazo_docente","title":"Componente <code>EP-EDF-03 FACT_REEMPLAZO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-03 FACT_REEMPLAZO_DOCENTE</code> es un componente dise\u00f1ado para ejecutar un script de Python. Su prop\u00f3sito es gestionar la descarga de informaci\u00f3n relacionada con el reemplazo docente. Utiliza configuraciones din\u00e1micas a trav\u00e9s de variables de proyecto, lo que garantiza flexibilidad y adaptabilidad dentro del entorno de desarrollo.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-03 FACT_REEMPLAZO_DOCENTE Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python que descarga datos relacionados con el reemplazo docente. ID del Componente <code>{df155a7f-6a3b-4e31-af0d-7b07113807e9}</code> <p>Propiedades Principales Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-03</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_2","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-03</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-03`\n    Python -&gt;&gt; Python: Descarga datos relacionados con reemplazo docente\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-04-fact_permiso_estudiante","title":"Componente <code>EP-EDF-04 FACT_PERMISO_ESTUDIANTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-04 FACT_PERMISO_ESTUDIANTE</code> es un componente que ejecuta un script de Python para descargar datos relacionados con permisos estudiantiles. Este componente utiliza variables din\u00e1micas de proyecto para definir tanto el ejecutable como el directorio de trabajo, asegurando flexibilidad y adaptabilidad al entorno.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-04 FACT_PERMISO_ESTUDIANTE Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python que descarga datos relacionados con permisos estudiantiles. ID del Componente <code>{2c32b9c0-798a-4bd5-a1e9-8b0351f2e222}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-04</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_3","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-04</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-04`\n    Python -&gt;&gt; Python: Descarga datos relacionados con permisos estudiantiles\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-05-fact_biblioteca","title":"Componente <code>EP-EDF-05 FACT_BIBLIOTECA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>La tarea <code>EP-EDF-05 FACT_BIBLIOTECA</code> es un componente que ejecuta un script de Python dise\u00f1ado para gestionar datos relacionados con la biblioteca del sistema. Este componente utiliza variables din\u00e1micas de proyecto para configurar el ejecutable y el directorio de trabajo, proporcionando flexibilidad en diferentes entornos.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-05 FACT_BIBLIOTECA Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python para gestionar datos de la biblioteca. ID del Componente <code>{93de8c31-f735-482b-9d44-ae33924b8a70}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-05</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_4","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-05</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-05`\n    Python -&gt;&gt; Python: Descarga datos de la biblioteca\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-06-fact_biblioteca_virtual","title":"Componente <code>EP-EDF-06 FACT_BIBLIOTECA_VIRTUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente <code>EP-EDF-06 FACT_BIBLIOTECA_VIRTUAL</code> est\u00e1 dise\u00f1ado para ejecutar un script de Python que gestiona la descarga de datos relacionados con la biblioteca virtual en el sistema. Este componente utiliza propiedades din\u00e1micas configuradas a nivel de proyecto, lo que permite flexibilidad en su uso en diferentes entornos.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-06 FACT_BIBLIOTECA_VIRTUAL Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python para gestionar datos de la biblioteca virtual. ID del Componente <code>{d22a6787-565a-4722-8ab0-acea586c4bfd}</code> <p>Propiedades Principales</p> <p>Detalles del Componente</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-06</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_5","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-06</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-06`\n    Python -&gt;&gt; Python: Descarga datos de la biblioteca virtual\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-ep-edf-07-fact_saber11_individual","title":"Componente <code>EP-EDF-07 FACT_SABER11_INDIVIDUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente <code>EP-EDF-07 FACT_SABER11_INDIVIDUAL</code> ejecuta un script de Python que gestiona la descarga y procesamiento de informaci\u00f3n relacionada con las evaluaciones Saber 11 individuales. Este componente utiliza variables de proyecto para configurar el ejecutable y el directorio de trabajo, lo que garantiza flexibilidad en diferentes entornos.</p> <p>Detalles del Componente</p> Propiedad Valor Nombre del Componente EP-EDF-07 FACT_SABER11_INDIVIDUAL Tipo Execute Process Task Descripci\u00f3n Ejecuta un script de Python para gestionar datos de evaluaciones Saber 11 individuales. ID del Componente <code>{47f926b0-8b2b-497d-bed6-90dc0e6f9d7c}</code> <p>Propiedades Principales</p> Propiedad Valor Ruta Ejecutable <code>@[$Project::Python_Executable]</code> Directorio <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code> Argumentos <code>download.py --key EP-EDF-07</code> Tiempo de Espera No especificado (valor predeterminado). ThreadHint <code>0</code>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#detalles-de-ejecucion_6","title":"Detalles de Ejecuci\u00f3n","text":"<ol> <li> <p>Ruta del Ejecutable: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Directorio de Trabajo: <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Argumentos del Script: <code>download.py --key EP-EDF-07</code></p> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EP-EDF-07`\n    Python -&gt;&gt; Python: Descarga y procesa datos de evaluaciones Saber 11\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_transporte","title":"Componente <code>Procesar FACT_TRANSPORTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_TRANSPORTE</code> es una tarea de flujo de datos en un paquete SSIS que realiza procesos ETL para gestionar informaci\u00f3n de transporte. Este flujo extrae datos de SAP, realiza transformaciones mediante conversiones, divisiones condicionales y b\u00fasquedas, y finalmente carga los datos procesados en una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li>Fuente de Datos ADO.NET (<code>FACT_TRANSPORTE SAP</code>)<ul> <li>Descripci\u00f3n: Extrae datos de SAP mediante una consulta SQL.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:    <pre><code>WITH TransportDetails AS (\n    SELECT OBJID AS OBJETO_SAP_ESTUDIANTE, BEGDA AS FECHA_INICIO_SERVICIO, \n           ENDDA AS FECHA_FIN_SERVICIO, BENCAT AS CATEGORIA_SERVICIO\n    FROM SAPABAP1.hrp1706 hh\n    WHERE PLVAR = '01' AND otype = 'ST' AND PDISCT2 = 'TRAN'\n), \nStudentKeys AS (\n    SELECT a.objid AS OBJETO_SAP_ESTUDIANTE, a.short AS NUMERO_MATRICULA,\n           b.PARTNER AS PARTNER_ESTUDIANTE\n    FROM SAPABAP1.HRP1000 AS a\n    INNER JOIN SAPABAP1.CMACBPST AS b ON a.objid = b.stobjid\n    WHERE a.plvar = 01 AND a.otype = 'ST' AND a.endda &gt;= CURDATE()\n)\nSELECT s.PARTNER_ESTUDIANTE, t.FECHA_INICIO_SERVICIO AS ID_FECHA,\n       YEAR(TO_DATE(t.FECHA_INICIO_SERVICIO, 'YYYYMMDD')) AS ANIO_ACADEMICO,\n       TO_DATE(t.FECHA_INICIO_SERVICIO, 'YYYYMMDD') AS FECHA_INICIO_SERVICIO,\n       TO_DATE(t.FECHA_FIN_SERVICIO, 'YYYYMMDD') AS FECHA_FIN_SERVICIO,\n       t.CATEGORIA_SERVICIO, 'SI' AS SERVICIO_TRANSPORTE,\n       s.PARTNER_ESTUDIANTE || '_' || TO_CHAR(t.FECHA_INICIO_SERVICIO, 'YYYYMMDD') AS ID_REGISTRO_AUXILIAR\nFROM TransportDetails AS t\nINNER JOIN StudentKeys AS S ON t.OBJETO_SAP_ESTUDIANTE = s.OBJETO_SAP_ESTUDIANTE\nWHERE t.FECHA_INICIO_SERVICIO &gt;= '20230101'\n</code></pre></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Conexiones:<ul> <li><code>IDbConnection</code>: Conexi\u00f3n a SAP referenciada por <code>SAP_ERP</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ID_FECHA</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_INICIO_SERVICIO</code>, <code>FECHA_FIN_SERVICIO</code>, <code>CATEGORIA_SERVICIO</code>, <code>SERVICIO_TRANSPORTE</code>, <code>ID_REGISTRO_AUXILIAR</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>)<ul> <li>Descripci\u00f3n: Convierte columnas de entrada para garantizar compatibilidad con componentes posteriores.</li> <li>Columnas de Entrada:<ul> <li><code>PARTNER_ESTUDIANTE</code>, <code>ID_FECHA</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_INICIO_SERVICIO</code>, <code>FECHA_FIN_SERVICIO</code>, <code>SERVICIO_TRANSPORTE</code>, <code>ID_REGISTRO_AUXILIAR</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_INICIO_SERVICIO</code>, <code>Copy of FECHA_FIN_SERVICIO</code>, <code>Copy of SERVICIO_TRANSPORTE</code>, <code>Copy of ID_REGISTRO_AUXILIAR</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>B\u00fasquedas (<code>Lookup</code>)<ul> <li>Lookup <code>1</code>:<ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_TARIFAS_SERVICIOS</code>.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:   <pre><code>SELECT [ID_TARIFA], [CON_OBJETO_TARIFA], CAST([ANIO_TARIFA] AS INT) AS [ANIO_TARIFA]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_TARIFAS_SERVICIOS]\nWHERE [COD_INFRAESTRUCTURA_CCF] = 'CCF008-12-00001' AND UPPER([CON_OBJETO_TARIFA]) LIKE '%TRANSPORTE%'\n</code></pre></li> </ul> </li> </ul> </li> <li>Lookup <code>2</code>:<ul> <li>Descripci\u00f3n: Busca en <code>FACT_TRANSPORTE</code> utilizando la columna <code>ID_REGISTRO_AUXILIAR</code>.</li> <li>Propiedades:<ul> <li><code>SqlCommand</code>:   <pre><code>SELECT [ID_REGISTRO], [BP_ESTUDIANTE], [ID_FECHA], [BP_ESTUDIANTE] + '_' + CONVERT(VARCHAR, [ID_FECHA], 112) AS [ID_REGISTRO_AUXILIAR]\nFROM [DWH_COMFENALCO].[Colegio].[FACT_TRANSPORTE]\n</code></pre></li> </ul> </li> </ul> </li> </ul> </li> </ol> <ol> <li>Divisi\u00f3n Condicional (<code>Conditional Split</code>)<ul> <li>Descripci\u00f3n: Separa filas en salidas distintas seg\u00fan condiciones espec\u00edficas.</li> <li>Condiciones:<ul> <li>Agregar: <code>!ISNULL(ID_TARIFA)</code></li> <li>No Agregar: Filas que no cumplen con la condici\u00f3n anterior.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Destino de Datos ADO.NET (<code>FACT_TRANSPORTE_DEST</code>)<ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_TRANSPORTE</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"FACT_TRANSPORTE\"</code></li> <li><code>BatchSize</code>: <code>0</code></li> <li><code>CommandTimeout</code>: <code>30</code></li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_INICIO_SERVICIO</code>, <code>Copy of FECHA_FIN_SERVICIO</code>, <code>Copy of SERVICIO_TRANSPORTE</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Source as FACT_TRANSPORTE SAP (Fuente)\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup 1\n    participant ConditionalSplit as Conditional Split\n    participant Lookup2 as Lookup 2\n    participant Destination as FACT_TRANSPORTE_DEST (Destino)\n\n    Source -&gt;&gt; DataConversion: Datos extra\u00eddos\n    DataConversion -&gt;&gt; Lookup1: Datos convertidos\n    Lookup1 -&gt;&gt; ConditionalSplit: Datos enriquecidos\n    ConditionalSplit -&gt;&gt; Lookup2: Filas seleccionadas\n    Lookup2 -&gt;&gt; Destination: Datos finales</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_cupos_negados","title":"Componente <code>Procesar FACT_CUPOS_NEGADOS</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_CUPOS_NEGADOS</code> es un flujo de datos en un paquete SSIS que gestiona el procesamiento de informaci\u00f3n relacionada con cupos negados para estudiantes. Este flujo incluye extracci\u00f3n de datos desde SAP, transformaciones mediante conversiones, b\u00fasquedas y derivaci\u00f3n de columnas, finalizando con la carga de datos en una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li>Fuente de Datos ADO.NET (<code>FACT_CUPOS NEGADOS SAP</code>)<ul> <li>Descripci\u00f3n: Extrae datos desde SAP utilizando una consulta SQL.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>WITH StudentKeys AS (\n    SELECT a.objid AS OBJETO_SAP_ESTUDIANTE, \n           a.short AS NUMERO_MATRICULA,\n           b.PARTNER AS PARTNER_ESTUDIANTE,\n           a.STEXT AS NOMBRE_ESTUDIANTE\n    FROM SAPABAP1.HRP1000 AS a\n    INNER JOIN SAPABAP1.CMACBPST AS b ON a.objid = b.stobjid\n    WHERE a.plvar = 01 AND a.otype = 'ST' AND a.endda &gt;= CURDATE()\n),\nDeniedStudents AS (\n    SELECT OBJID AS OBJETO_SAP_ESTUDIANTE, \n           HS_PERYR AS ANIO_ACADEMICO, \n           AEDTM AS FECHA_ESTADO\n    FROM SAPABAP1.HRP1728 AS h\n    WHERE plvar = '01' AND otype = 'ST' AND SUBTY = '9060' AND HS_STATE = 'A'\n)\nSELECT sk.NUMERO_MATRICULA, sk.PARTNER_ESTUDIANTE, sk.OBJETO_SAP_ESTUDIANTE, \n       sk.NOMBRE_ESTUDIANTE, d.ANIO_ACADEMICO, \n       TO_DATE(d.FECHA_ESTADO, 'YYYYMMDD') AS FECHA_ESTADO, d.FECHA_ESTADO AS ID_FECHA\nFROM DeniedStudents AS d\nINNER JOIN StudentKeys AS sk ON d.OBJETO_SAP_ESTUDIANTE = sk.OBJETO_SAP_ESTUDIANTE\n</code></pre></li> <li>Conexi\u00f3n: Referencia a <code>SAP_ERP</code>.</li> <li>Tiempo de espera: <code>30</code> segundos.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>NUMERO_MATRICULA</code>, <code>PARTNER_ESTUDIANTE</code>, <code>OBJETO_SAP_ESTUDIANTE</code>, <code>NOMBRE_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_ESTADO</code>, <code>ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>)<ul> <li>Descripci\u00f3n: Convierte columnas de entrada a tipos y longitudes compatibles con otros componentes.</li> <li>Columnas de Entrada:<ul> <li><code>NUMERO_MATRICULA</code>, <code>PARTNER_ESTUDIANTE</code>, <code>OBJETO_SAP_ESTUDIANTE</code>, <code>NOMBRE_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_ESTADO</code>, <code>ID_FECHA</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>Copy of NUMERO_MATRICULA</code>, <code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of OBJETO_SAP_ESTUDIANTE</code>, <code>Copy of NOMBRE_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_ESTADO</code>, <code>Copy of ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>B\u00fasqueda (<code>Lookup</code>)<ul> <li>Descripci\u00f3n: Busca datos adicionales en la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li>Columna de Uni\u00f3n: <code>PARTNER</code>.</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ID_POBLACION_MATRICULA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Columna Derivada (<code>Derived Column</code>)<ul> <li>Descripci\u00f3n: Calcula o asigna valores a columnas existentes o nuevas bas\u00e1ndose en condiciones.</li> <li>Expresi\u00f3n:   <pre><code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA\n</code></pre></li> <li>Columna Derivada:<ul> <li><code>ID_POBLACION_MATRICULA</code>.</li> </ul> </li> </ul> </li> </ol> <ol> <li>Destino de Datos ADO.NET (<code>Destino de ADO NET</code>)<ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_CUPOS_NEGADOS</code>.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Colegio\".\"FACT_CUPOS_NEGADOS\"</code>.</li> <li>BatchSize: <code>0</code> (tama\u00f1o predeterminado del b\u00fafer interno).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>Copy of NUMERO_MATRICULA</code>, <code>Copy of PARTNER_ESTUDIANTE</code>, <code>Copy of OBJETO_SAP_ESTUDIANTE</code>, <code>Copy of NOMBRE_ESTUDIANTE</code>, <code>Copy of ANIO_ACADEMICO</code>, <code>Copy of FECHA_ESTADO</code>, <code>Copy of ID_FECHA</code>, <code>ID_POBLACION_MATRICULA</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia-del-flujo","title":"Diagrama de Secuencia del Flujo","text":"<pre><code>sequenceDiagram\n    participant Source as FACT_CUPOS NEGADOS SAP (Fuente)\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup (DIM_POBLACION_MATRICULA)\n    participant DerivedColumn as Derived Column\n    participant Destination as FACT_CUPOS_NEGADOS (Destino)\n\n    Source -&gt;&gt; DataConversion: Extrae datos y los convierte\n    DataConversion -&gt;&gt; Lookup: Enriquecimiento con b\u00fasqueda\n    Lookup -&gt;&gt; DerivedColumn: Asigna valores derivados\n    DerivedColumn -&gt;&gt; Destination: Carga datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-crear-procedimiento","title":"Componente <code>Crear Procedimiento</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>El componente <code>Crear Procedimiento</code> es una tarea de ejecuci\u00f3n de SQL (<code>Execute SQL Task</code>) que permite la creaci\u00f3n din\u00e1mica de un procedimiento almacenado en una base de datos. Antes de proceder con la creaci\u00f3n, verifica si un procedimiento con el mismo nombre ya existe, y lo elimina si es necesario.</p> <p>Configuraci\u00f3n de la Tarea</p> <ol> <li>Nombre del Componente: <code>Crear Procedimiento</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Conexi\u00f3n: Referencia a una conexi\u00f3n de base de datos ADO.NET (<code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>).</li> <li>Consulta SQL:     <pre><code>-- Verificar si el procedimiento 'GetRetirosByYear' existe y eliminarlo si es as\u00ed\nDO\nBEGIN\n    DECLARE proc_count INT;\n\n    SELECT COUNT(*) INTO proc_count\n    FROM PROCEDURES\n    WHERE PROCEDURE_NAME = 'GETRETIROSBYYEAR' AND SCHEMA_NAME = CURRENT_SCHEMA;\n\n    IF proc_count &gt; 0 THEN\n        EXEC 'DROP PROCEDURE GETRETIROSBYYEAR';\n    END IF;\nEND;\n</code></pre></li> </ol> <p>Descripci\u00f3n del C\u00f3digo SQL</p> <ol> <li>Prop\u00f3sito:</li> <li>Elimina el procedimiento almacenado <code>GetRetirosByYear</code> si ya existe.</li> <li>Garantiza que la base de datos est\u00e9 limpia para crear un nuevo procedimiento.</li> <li>Operaciones Realizadas:</li> <li>Verificaci\u00f3n:<ul> <li>Consulta en la tabla de metadatos <code>PROCEDURES</code> si existe un procedimiento llamado <code>GETRETIROSBYYEAR</code>.</li> </ul> </li> <li>Eliminaci\u00f3n:<ul> <li>Si el procedimiento existe, se ejecuta <code>DROP PROCEDURE</code> para eliminarlo.</li> </ul> </li> </ol> <p>Conexi\u00f3n de Base de Datos</p> <ul> <li>Tipo de Conexi\u00f3n: ADO.NET.</li> <li>Identificador de Conexi\u00f3n: <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#flujo-de-la-tarea","title":"Flujo de la Tarea","text":"<pre><code>sequenceDiagram\n    participant ExecuteSQL as Crear Procedimiento\n    ExecuteSQL-&gt;&gt;DB: Verifica existencia de `GetRetirosByYear`\n    alt Procedimiento Existe\n        ExecuteSQL-&gt;&gt;DB: Ejecuta `DROP PROCEDURE`\n    end\n    ExecuteSQL-&gt;&gt;DB: Finaliza ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-validar-si-existe-tabla-para-guardar","title":"Componente <code>Validar si existe tabla para guardar</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Validar si existe tabla para guardar</code> es una ejecuci\u00f3n de SQL que verifica la existencia de una tabla espec\u00edfica (<code>RESULTS</code>) en la base de datos. Si esta tabla existe, la tarea procede a eliminarla, asegurando que el espacio para almacenar datos est\u00e9 limpio antes de realizar nuevas inserciones o procesos.</p> <p>Configuraci\u00f3n de la Tarea</p> <ol> <li>Nombre del Componente: <code>Validar si existe tabla para guardar</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Conexi\u00f3n: Referencia a una conexi\u00f3n de base de datos ADO.NET (<code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>).</li> <li>Consulta SQL:     <pre><code>-- Verificar si la tabla 'RESULTS' existe y eliminarla si es as\u00ed\nDO\nBEGIN\n    DECLARE table_count INT;\n\n    SELECT COUNT(*) INTO table_count\n    FROM TABLES\n    WHERE TABLE_NAME = 'RESULTS' AND SCHEMA_NAME = CURRENT_SCHEMA;\n\n    IF table_count &gt; 0 THEN\n        EXEC 'DROP TABLE RESULTS';\n    END IF;\nEND;\n</code></pre></li> </ol> <p>Descripci\u00f3n del C\u00f3digo SQL</p> <ol> <li>Prop\u00f3sito:</li> <li>Garantiza que no existan conflictos al trabajar con la tabla <code>RESULTS</code>.</li> <li> <p>Elimina la tabla si ya existe para permitir la creaci\u00f3n de una nueva o reutilizaci\u00f3n sin conflictos.</p> </li> <li> <p>Operaciones Realizadas:</p> </li> <li>Verificaci\u00f3n:<ul> <li>Consulta en la tabla de metadatos <code>TABLES</code> si existe una tabla llamada <code>RESULTS</code>.</li> </ul> </li> <li>Eliminaci\u00f3n:<ul> <li>Si la tabla existe, ejecuta <code>DROP TABLE RESULTS</code> para eliminarla.</li> </ul> </li> </ol> <p>Conexi\u00f3n de Base de Datos</p> <ul> <li>Tipo de Conexi\u00f3n: ADO.NET.</li> <li>Identificador de Conexi\u00f3n: <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#flujo-de-la-tarea_1","title":"Flujo de la Tarea","text":"<pre><code>sequenceDiagram\n    participant ExecuteSQL as Validar si existe tabla\n    ExecuteSQL-&gt;&gt;DB: Verifica existencia de `RESULTS`\n    alt Tabla Existe\n        ExecuteSQL-&gt;&gt;DB: Ejecuta `DROP TABLE RESULTS`\n    end\n    ExecuteSQL-&gt;&gt;DB: Finaliza ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-crear-tabla","title":"Componente <code>Crear Tabla</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Crear Tabla</code> es una ejecuci\u00f3n de SQL destinada a crear la tabla <code>RESULTS</code> en la base de datos. Esta tabla servir\u00e1 para almacenar de forma persistente los resultados procesados. Este paso asegura que exista una estructura adecuada para recibir datos y facilita la validaci\u00f3n y manipulaci\u00f3n posterior de los mismos.</p> <p>Configuraci\u00f3n de la Tarea</p> <ol> <li>Nombre del Componente: <code>Crear Tabla</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Conexi\u00f3n: Referencia a una conexi\u00f3n de base de datos ADO.NET (<code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>).</li> <li>Consulta SQL:     <pre><code>-- Crear la tabla persistente para almacenar los resultados\nCREATE TABLE RESULTS (\n    OBJETO_SAP_ESTUDIANTE VARCHAR(20),\n    NUMERO_MATRICULA VARCHAR(20),\n    PARTNER_ESTUDIANTE VARCHAR(20),\n    ANIO_ACADEMICO VARCHAR(20),\n    APELLIDOS VARCHAR(50),\n    NOMBRES VARCHAR(50),\n    CURSO VARCHAR(20),\n    GRADO VARCHAR(20),\n    FECHA_RETIRO_SAP DATE,\n    FECHA_VALIDO_DESDE DATE,\n    FECHA_VALIDO_HASTA DATE\n);\n</code></pre></li> </ol> <p>Descripci\u00f3n del C\u00f3digo SQL</p> <ol> <li> <p>Prop\u00f3sito:</p> <ul> <li>Define la estructura de la tabla <code>RESULTS</code> para almacenar datos relacionados con los retiros de estudiantes.</li> </ul> </li> <li> <p>Estructura de la Tabla:</p> <ul> <li>Columnas:<ul> <li><code>OBJETO_SAP_ESTUDIANTE</code>: Identificador \u00fanico del estudiante en SAP.</li> <li><code>NUMERO_MATRICULA</code>: Matr\u00edcula del estudiante.</li> <li><code>PARTNER_ESTUDIANTE</code>: Partner asociado al estudiante.</li> <li><code>ANIO_ACADEMICO</code>: A\u00f1o acad\u00e9mico del registro.</li> <li><code>APELLIDOS</code>: Apellidos del estudiante.</li> <li><code>NOMBRES</code>: Nombres del estudiante.</li> <li><code>CURSO</code>: Curso del estudiante.</li> <li><code>GRADO</code>: Grado acad\u00e9mico del estudiante.</li> <li><code>FECHA_RETIRO_SAP</code>: Fecha del retiro registrada en SAP.</li> <li><code>FECHA_VALIDO_DESDE</code>: Fecha de inicio de validez.</li> <li><code>FECHA_VALIDO_HASTA</code>: Fecha de fin de validez.</li> </ul> </li> </ul> </li> </ol> <p>Conexi\u00f3n de Base de Datos</p> <ul> <li>Tipo de Conexi\u00f3n: ADO.NET.</li> <li>Identificador de Conexi\u00f3n: <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>.</li> </ul> <p>Notas y Recomendaciones</p> <ol> <li> <p>Validaci\u00f3n Previa:</p> <ul> <li>Antes de ejecutar esta consulta, aseg\u00farese de que no exista ya una tabla con el nombre <code>RESULTS</code>. Si existe, deber\u00eda eliminarse con una tarea previa para evitar conflictos.</li> </ul> </li> <li> <p>Tipos de Datos:</p> <ul> <li>Verifique que los tipos de datos definidos sean los adecuados seg\u00fan las especificaciones del sistema y los datos que se procesar\u00e1n.</li> </ul> </li> <li> <p>Seguridad:</p> <ul> <li>Garantice que el usuario o conexi\u00f3n utilizada tenga permisos suficientes para crear tablas en el esquema de la base de datos.</li> </ul> </li> <li> <p>\u00cdndices:</p> <ul> <li>Si la tabla requiere \u00edndices para mejorar el rendimiento de consultas futuras, estos pueden a\u00f1adirse despu\u00e9s de la creaci\u00f3n de la tabla.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#flujo-de-la-tarea_2","title":"Flujo de la Tarea","text":"<pre><code>sequenceDiagram\n    participant ExecuteSQL as Crear Tabla\n    ExecuteSQL-&gt;&gt;DB: Ejecuta el comando SQL `CREATE TABLE RESULTS`\n    DB--&gt;&gt;ExecuteSQL: Confirma la creaci\u00f3n de la tabla</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-crear-procedimiento-anual","title":"Componente <code>Crear procedimiento anual</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Crear procedimiento anual</code> utiliza SQL para crear un procedimiento almacenado llamado <code>GetRetirosByYear</code>. Este procedimiento est\u00e1 dise\u00f1ado para insertar registros relacionados con los retiros de estudiantes en la tabla <code>RESULTS</code>, basado en un a\u00f1o espec\u00edfico proporcionado como par\u00e1metro de entrada.</p> <p>Configuraci\u00f3n de la Tarea</p> <ol> <li>Nombre del Componente: <code>Crear procedimiento anual</code></li> <li>Tipo de Tarea: <code>Microsoft.ExecuteSQLTask</code></li> <li>Conexi\u00f3n: Referencia a una conexi\u00f3n de base de datos ADO.NET (<code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>).</li> <li>Consulta SQL:     <pre><code>-- Crear el procedimiento para obtener los retiros por a\u00f1o\nCREATE PROCEDURE GetRetirosByYear (IN P_YEAR INT)\nLANGUAGE SQLSCRIPT\nAS\nBEGIN\n    DECLARE valid_from_date NVARCHAR(8); \n    valid_from_date := CONCAT(P_YEAR, '0101');\n\n    INSERT INTO RESULTS\n    SELECT \n        DISTINCT \n        h.objid AS OBJETO_SAP_ESTUDIANTE,\n        p.short AS NUMERO_MATRICULA,\n        b.PARTNER AS PARTNER_ESTUDIANTE,\n        o.ayear AS ANIO_ACADEMICO,\n        h.nachn AS APELLIDOS,\n        h.vorna AS NOMBRES,\n        i.prcl AS CURSO,\n        j.matrikel AS GRADO,\n        m.END_KEY_DATE AS FECHA_RETIRO_SAP,\n        i.mc_valid_from AS FECHA_VALIDO_DESDE,\n        i.mc_valid_to AS FECHA_VALIDO_HASTA\n    FROM SAPABAP1.hrp1702 AS h\n    INNER JOIN SAPABAP1.hrp1000 AS p ON h.plvar = p.plvar AND h.otype = p.otype AND h.objid = p.objid AND h.endda = p.endda\n    INNER JOIN SAPABAP1.hrp1705 AS j ON h.plvar = j.plvar AND h.otype = j.otype AND h.objid = j.objid AND h.endda = j.endda\n    INNER JOIN SAPABAP1.hrp1737 AS k ON j.plvar = k.plvar AND j.otype = k.otype AND j.objid = k.objid AND j.endda = k.endda\n    INNER JOIN SAPABAP1.hrt1737 AS i ON k.tabnr = i.tabnr\n    INNER JOIN SAPABAP1.hrp1001 AS l ON l.plvar = h.plvar AND l.otype = h.otype AND l.objid = h.objid AND l.endda = h.endda\n    INNER JOIN SAPABAP1.hrp1001 AS n ON n.plvar = l.plvar AND n.otype = l.sclas AND n.objid = l.sobid AND n.endda = l.endda\n    INNER JOIN SAPABAP1.hrp1769 AS m ON m.plvar = n.plvar AND m.otype = n.otype AND m.objid = n.objid\n    INNER JOIN SAPABAP1.hrp1771 AS o ON o.plvar = n.plvar AND o.otype = n.otype AND o.objid = n.objid\n    INNER JOIN SAPABAP1.CMACBPST as b On p.objid = b.stobjid\n    WHERE\n        l.sclas = 'CS' AND -- CS = Estudios\n        n.sclas = 'SC' AND -- SC = Plan de estudios\n        p.otype = 'ST' AND -- ST = Estudiante\n        p.plvar = '01' AND -- 01 \u2013 Plan activo\n        i.mc_valid_to &gt;= CURDATE() AND\n        i.prog_type = '4' AND\n        i.valid_from = valid_from_date AND\n        m.begda &lt;= CURDATE() AND -- Fec. Hoy\n        m.endda &lt;= CURDATE() AND -- &lt;= Fec. Hoy\n        o.prs_state = 'A' AND\n        o.ayear = P_YEAR AND\n        m.END_PROCESS = 'RW01' AND\n        m.END_KEY_DATE &gt;= i.valid_from;\nEND;\n</code></pre></li> </ol> <p>Descripci\u00f3n del C\u00f3digo SQL</p> <ol> <li> <p>Prop\u00f3sito:</p> <ul> <li>Crear un procedimiento almacenado que extrae registros de estudiantes retirados basados en el a\u00f1o proporcionado y los inserta en la tabla <code>RESULTS</code>.</li> </ul> </li> <li> <p>Par\u00e1metros:</p> <ul> <li><code>P_YEAR</code>: A\u00f1o de inter\u00e9s para filtrar los registros.</li> </ul> </li> <li> <p>Operaciones Clave:</p> <ul> <li>C\u00e1lculo de la fecha de inicio v\u00e1lida (<code>valid_from_date</code>).</li> <li>Inserci\u00f3n de datos en <code>RESULTS</code> desde m\u00faltiples tablas SAP relacionadas, con filtros espec\u00edficos para el a\u00f1o acad\u00e9mico, el estado del proceso y otras validaciones.</li> </ul> </li> <li> <p>Validaciones:</p> <ul> <li>Solo se incluyen registros donde el estudiante est\u00e9 activo, el a\u00f1o acad\u00e9mico coincida y las fechas de retiro sean v\u00e1lidas.</li> </ul> </li> </ol> <p>Conexi\u00f3n de Base de Datos</p> <ul> <li>Tipo de Conexi\u00f3n: ADO.NET.</li> <li>Identificador de Conexi\u00f3n: <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code>.</li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#flujo-de-la-tarea_3","title":"Flujo de la Tarea","text":"<pre><code>sequenceDiagram\n    participant ExecuteSQL as Crear procedimiento anual\n    ExecuteSQL-&gt;&gt;DB: Ejecuta el comando SQL `CREATE PROCEDURE GetRetirosByYear`\n    DB--&gt;&gt;ExecuteSQL: Confirma la creaci\u00f3n del procedimiento</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-truncar-tabla","title":"Componente: <code>Truncar tabla</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>El componente \"Truncar tabla\" es una tarea de ejecuci\u00f3n de SQL que elimina todos los datos de la tabla <code>RESULTS</code> antes de ejecutar cualquier procedimiento o carga posterior, asegurando que la tabla est\u00e9 vac\u00eda y preparada para nuevos datos. Utiliza el comando <code>TRUNCATE TABLE</code> para eliminar de forma eficiente los registros, sin generar registros de transacci\u00f3n para cada fila eliminada.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-detallados","title":"Componentes Detallados","text":"<p>Descripci\u00f3n - Nombre del componente: Truncar tabla - Tipo: Tarea Ejecutar SQL - Descripci\u00f3n: Limpia la tabla <code>RESULTS</code> para evitar conflictos o duplicados en cargas posteriores.</p> <p>Propiedades</p> Propiedad Valor Connection <code>{3A7D3F89-902D-4694-893E-02F1E08B0F72}</code> SqlStatementSource <code>TRUNCATE TABLE RESULTS;</code> LocaleID <code>-1</code> CreationName <code>Microsoft.ExecuteSQLTask</code> TaskContact <code>Execute SQL Task; Microsoft Corporation; SQL Server 2022; \u00a9 2022 Microsoft Corporation</code> <p>Script SQL <pre><code>-- Limpiar la tabla antes de ejecutar el procedimiento\nTRUNCATE TABLE RESULTS;\n</code></pre></p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-calcular-retiros","title":"Componente <code>Calcular retiros</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>El componente \"Calcular retiros\" es una tarea de flujo de datos en SSIS dise\u00f1ada para procesar, transformar y almacenar informaci\u00f3n relacionada con retiros de estudiantes. Este flujo extrae datos de una fuente SAP, realiza conversiones de datos, derivaciones de columnas, y finalmente almacena los resultados en la tabla de destino <code>FACT_RETIROS</code>.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>FACT_RETIROS SAP (Origen de datos)</p> <ul> <li>Descripci\u00f3n: Extrae informaci\u00f3n de estudiantes y retiros desde SAP usando un bloque SQL que recorre a\u00f1os desde 2023 hasta el a\u00f1o actual.</li> <li>Propiedades principales:<ul> <li>Consulta SQL: <pre><code>DO\nBEGIN\n    DECLARE year INT := 2023;\n    DECLARE current_year INT := YEAR(CURRENT_DATE);\n    WHILE year &lt;= current_year DO\n        CALL GetRetirosByYear(year);\n        year := year + 1;\n    END WHILE;\n    SELECT * FROM RESULTS;\nEND\n</code></pre></li> <li>Conexi\u00f3n: <code>SAP_ERP</code></li> <li>Timeout: 30 segundos.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos extra\u00eddos a los tipos requeridos para las siguientes transformaciones y el destino.</li> <li>Entrada:<ul> <li>Columnas: <code>OBJETO_SAP_ESTUDIANTE</code>, <code>NUMERO_MATRICULA</code>, <code>PARTNER_ESTUDIANTE</code>, <code>ANIO_ACADEMICO</code>, <code>APELLIDOS</code>, <code>NOMBRES</code>, <code>CURSO</code>, <code>GRADO</code>, <code>FECHA_RETIRO_SAP</code>, <code>FECHA_VALIDO_DESDE</code>, <code>FECHA_VALIDO_HASTA</code>.</li> </ul> </li> <li>Salida:<ul> <li>Columnas convertidas como <code>Copy of &lt;nombre original&gt;</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Enlaza informaci\u00f3n adicional de la tabla <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Propiedades principales:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li>Comportamiento de no coincidencia: Ignorar filas sin coincidencias.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code>.</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas a partir de las existentes. Por ejemplo, se genera la columna <code>ID_FECHA</code> utilizando <code>FECHA_RETIRO_SAP</code>.</li> <li>Expresi\u00f3n derivada: <pre><code>(DT_I4)(YEAR([Copy of FECHA_RETIRO_SAP]) * 10000 + MONTH([Copy of FECHA_RETIRO_SAP]) * 100 + DAY([Copy of FECHA_RETIRO_SAP]))\n</code></pre></li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Almacena los resultados procesados en la tabla <code>FACT_RETIROS</code> en la base de datos de destino.</li> <li>Propiedades principales:<ul> <li>Tabla de destino: <code>Colegio.FACT_RETIROS</code></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#flujo-del-proceso","title":"Flujo del Proceso","text":"<ol> <li>Extraer datos desde SAP mediante <code>FACT_RETIROS SAP</code>.</li> <li>Convertir datos en el componente <code>Data Conversion</code>.</li> <li>Realizar un lookup para enriquecer datos desde <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Derivar nuevas columnas usando <code>Derived Column</code>.</li> <li>Almacenar los datos procesados en la tabla <code>FACT_RETIROS</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia-del-flujo_1","title":"Diagrama de Secuencia del Flujo","text":"<pre><code>sequenceDiagram\n    participant SAP as FACT_RETIROS SAP\n    participant DC as Data Conversion\n    participant LKP as Lookup\n    participant DCOL as Derived Column\n    participant DEST as Destino de ADO NET\n\n    SAP-&gt;&gt;DC: Extraer datos desde SAP\n    DC-&gt;&gt;LKP: Convertir datos y realizar Lookup\n    LKP-&gt;&gt;DCOL: Enviar datos enriquecidos\n    DCOL-&gt;&gt;DEST: Derivar columnas y guardar en destino\n    DEST--&gt;&gt;SAP: Fin del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_ausentismo_docente","title":"Componente <code>Procesar FACT_AUSENTISMO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>El componente \"Procesar FACT_AUSENTISMO_DOCENTE\" es una tarea de flujo de datos en SSIS destinada a procesar, transformar y almacenar informaci\u00f3n relacionada con el ausentismo docente. El flujo de datos incluye una fuente de datos Excel, transformaciones como conversi\u00f3n de datos y derivaci\u00f3n de columnas, enriquecimiento con datos adicionales mediante <code>Lookup</code>, y finalmente el almacenamiento en la tabla <code>FACT_AUSENTISMO_DOCENTE</code>.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Leer EP-EDF-02 (Excel Source)</p> <ul> <li>Descripci\u00f3n: Lee los datos desde un archivo Excel ubicado en la conexi\u00f3n <code>Excel_Connection_Fact_Ausentismo_Docente</code>.</li> <li>Propiedades principales:<ul> <li>Nombre de la hoja: <code>Hoja1$</code>.</li> <li>Columnas: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ANIO_ACADEMICO</code>, <code>FECHA_REGISTRO</code>, <code>NOMBRE_DOCENTE</code>, <code>CARGO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>, <code>AUSENCIA_HORAS</code>, <code>AUSENCIA_DIAS</code>, <code>TIPO_AUSENCIA</code>, <code>PERMISO</code>, <code>MOTIVO_AUSENCIA</code>.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos extra\u00eddos a los tipos requeridos para las siguientes transformaciones y el destino.</li> <li>Entrada:<ul> <li>Columnas del archivo Excel.</li> </ul> </li> <li>Salida:<ul> <li>Columnas convertidas, con prefijo <code>Copy of</code>.</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas basadas en c\u00e1lculos sobre las columnas existentes. Por ejemplo, se genera <code>ID_FECHA</code> utilizando <code>FECHA_REGISTRO</code>.</li> <li>Expresi\u00f3n derivada: <pre><code>(DT_I4)(YEAR([Copy of FECHA_REGISTRO]) * 10000 + MONTH([Copy of FECHA_REGISTRO]) * 100 + DAY([Copy of FECHA_REGISTRO]))\n</code></pre></li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Enlaza informaci\u00f3n adicional desde la tabla <code>DIM_PERSONAL</code> en la base de datos <code>DWH_COMFENALCO</code>.</li> <li>Propiedades principales:<ul> <li>Consulta SQL: <pre><code>SELECT [ID_PERSONAL], CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO, [ID_UNIDAD], [TIPO_DOCUMENTO], [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1\n</code></pre></li> <li>Claves de uni\u00f3n: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ANIO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Almacena los datos procesados en la tabla <code>FACT_AUSENTISMO_DOCENTE</code>.</li> <li>Propiedades principales:<ul> <li>Tabla de destino: <code>Colegio.FACT_AUSENTISMO_DOCENTE</code>.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Leer EP-EDF-02 (Excel Source)\n    participant DC as Data Conversion\n    participant LKP as Lookup\n    participant DCOL as Derived Column\n    participant DEST as Destino de ADO NET\n\n    Excel-&gt;&gt;DC: Leer datos desde Excel\n    DC-&gt;&gt;DCOL: Convertir datos y derivar columnas\n    DCOL-&gt;&gt;LKP: Enviar datos para enriquecimiento\n    LKP-&gt;&gt;DEST: Guardar en base de datos\n    DEST--&gt;&gt;Excel: Fin del proceso</code></pre> <p>Flujo del Proceso</p> <ol> <li>Leer datos desde el archivo Excel (<code>Leer EP-EDF-02</code>).</li> <li>Convertir tipos de datos con el componente <code>Data Conversion</code>.</li> <li>Derivar nuevas columnas usando <code>Derived Column</code>.</li> <li>Enriquecer datos con informaci\u00f3n adicional mediante <code>Lookup</code>.</li> <li>Almacenar los datos procesados en la tabla <code>FACT_AUSENTISMO_DOCENTE</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_biblioteca","title":"Componente <code>Procesar FACT_BIBLIOTECA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos procesa la informaci\u00f3n de pr\u00e9stamos de biblioteca desde un archivo Excel hasta un destino en la base de datos relacional mediante transformaciones como conversiones de datos, columnas derivadas y b\u00fasquedas para enriquecer los datos con informaci\u00f3n adicional.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<p>1. Fuente: Leer EP-EDF-05</p> <ul> <li>Descripci\u00f3n: Extrae datos de un archivo Excel que contiene registros de pr\u00e9stamos de biblioteca.</li> <li>Propiedades:<ul> <li>Nombre de la hoja: <code>Hoja1$</code>.</li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Biblioteca</code>.</li> <li>Tiempo de espera del comando: <code>0</code> (sin l\u00edmite).</li> </ul> </li> <li>Columnas extra\u00eddas:<ul> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>BP_ESTUDIANTE</code>, <code>TIPO_USUARIO</code>, <code>FECHA_PRESTAMO</code>, <code>FECHA_VENCIMIENTO</code>, <code>FECHA_ENTREGA</code>, <code>BIBLIOTECA</code>, <code>ITEM_LIBRO</code>, <code>NO_PRESTAMOS</code>.</li> </ul> </li> </ul> <p>2. Transformaci\u00f3n: Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte las columnas extra\u00eddas en tipos compatibles con los destinos y procesos posteriores.</li> <li>Propiedades:<ul> <li>Conversi\u00f3n de tipos: <code>wstr</code> a tipos espec\u00edficos como <code>date</code> e <code>i4</code>.</li> <li>Columnas convertidas: <ul> <li>Ejemplo: <code>FECHA_PRESTAMO</code> a tipo <code>date</code>, <code>ITEM_LIBRO</code> a tipo <code>wstr</code> con longitud espec\u00edfica.</li> </ul> </li> <li>Disposici\u00f3n en caso de error: <code>FailComponent</code>.</li> </ul> </li> </ul> <p>3. Transformaci\u00f3n: Derived Column</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas de las existentes, como <code>ID_FECHA</code> y <code>ANIO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Expresiones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)(YEAR([FECHA_PRESTAMO])*10000 + MONTH([FECHA_PRESTAMO])*100 + DAY([FECHA_PRESTAMO]))</code>.</li> <li><code>ANIO_ACADEMICO</code>: <code>(DT_I4)(YEAR([FECHA_PRESTAMO]))</code>.</li> </ul> </li> <li>Manejo de errores: <code>FailComponent</code>.</li> </ul> </li> </ul> <p>4. Transformaci\u00f3n: Lookup</p> <ul> <li> <p>Lookup 1: Datos de matr\u00edcula (<code>DIM_POBLACION_MATRICULA</code>)</p> <ul> <li>Descripci\u00f3n: Asocia datos de estudiantes a partir de la columna <code>BP_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA];\n</code></pre></li> <li>Mapeo de par\u00e1metros: <code>BP_ESTUDIANTE \u2192 PARTNER</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup 2: Datos de libros (<code>DIM_LIBROS</code>)</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_LIBRO</code> usando el c\u00f3digo de barras o \u00edtem del libro.</li> <li>Propiedades:<ul> <li>Consulta SQL (con CTE para manejar duplicados): <pre><code>WITH CTE AS (\n    SELECT [ID_LIBRO], [ITEM],\n            ROW_NUMBER() OVER (PARTITION BY [ITEM] ORDER BY [ID_LIBRO]) AS rn\n    FROM [DWH_COMFENALCO].[Colegio].[DIM_LIBROS]\n)\nSELECT [ID_LIBRO], [ITEM] FROM CTE WHERE rn = 1;\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Lookup 3: Verificaci\u00f3n de registros existentes (<code>FACT_BIBLIOTECA</code>)</p> <ul> <li>Descripci\u00f3n: Verifica si ya existe un registro similar en la tabla destino.</li> <li>Propiedades:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[FACT_BIBLIOTECA];\n</code></pre></li> </ul> </li> </ul> </li> </ul> <p>5. Destino: Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados en la tabla <code>FACT_BIBLIOTECA</code> del esquema <code>Colegio</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Colegio\".\"FACT_BIBLIOTECA\"</code>.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code>.</li> <li>Tama\u00f1o de lotes: <code>0</code> (uso del tama\u00f1o de buffer interno).</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-05\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupMatricula as Lookup: DIM_POBLACION_MATRICULA\n    participant LookupLibros as Lookup: DIM_LIBROS\n    participant LookupFact as Lookup: FACT_BIBLIOTECA\n    participant Destino as ADO.NET Destination\n\n    ExcelSource -&gt;&gt; DataConversion: Extraer columnas y convertir tipos\n    DataConversion -&gt;&gt; DerivedColumn: Generar columnas derivadas\n    DerivedColumn -&gt;&gt; LookupMatricula: Buscar ID de matr\u00edcula\n    LookupMatricula -&gt;&gt; LookupLibros: Buscar ID de libro\n    LookupLibros -&gt;&gt; LookupFact: Verificar duplicados\n    LookupFact -&gt;&gt; Destino: Insertar registros finales</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_biblioteca_virtual","title":"Componente <code>Procesar FACT_BIBLIOTECA_VIRTUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) para los registros de la biblioteca virtual. Incluye conversiones de datos, derivaci\u00f3n de columnas, b\u00fasquedas y carga en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<p>1. Componente <code>Leer EP-EDF-06</code></p> <ul> <li>Descripci\u00f3n: Fuente de datos Excel que extrae informaci\u00f3n de la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0 (infinito).</li> <li><code>AccessMode</code>: 0 (tabla directa).</li> <li><code>OpenRowset</code>: <code>Hoja1$</code>.</li> </ul> </li> </ul> <p>2. Componente <code>Data Conversion</code></p> <ul> <li>Descripci\u00f3n: Convierte las columnas de entrada para ajustarlas a los tipos requeridos.</li> <li>Columnas Convertidas:<ul> <li><code>TIPO_DOCUMENTO</code>: <code>wstr</code> (40).</li> <li><code>DOCUMENTO</code>: <code>wstr</code> (20).</li> <li><code>FECHA_INICIO</code>: <code>date</code>.</li> </ul> </li> <li>Propiedades Adicionales:<ul> <li><code>FastParse</code>: <code>false</code> en todas las columnas.</li> </ul> </li> </ul> <p>3. Componente <code>Derived Column</code></p> <ul> <li>Descripci\u00f3n: Deriva columnas calculadas como <code>ID_FECHA</code> y <code>ANIO_ACADEMICO</code>.</li> <li>Columnas Derivadas:<ul> <li><code>ID_FECHA</code>: Combina a\u00f1o, mes y d\u00eda de <code>FECHA_INICIO</code>.</li> <li><code>ANIO_ACADEMICO</code>: Extrae solo el a\u00f1o.</li> </ul> </li> </ul> <p>4. Componente <code>Lookup</code></p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_POBLACION_MATRICULA</code> para obtener <code>ID_POBLACION_MATRICULA</code>.</li> <li>SQL de B\u00fasqueda: <pre><code>SELECT * FROM Colegio.DIM_POBLACION_MATRICULA WHERE TIPO_DOCUMENTO = ? AND DOCUMENTO = ?\n</code></pre></li> <li>Propiedades:<ul> <li><code>CacheType</code>: Completo.</li> <li><code>NoMatchBehavior</code>: Ignorar filas sin coincidencia.</li> </ul> </li> </ul> <p>5. Componente <code>Destino de ADO NET</code></p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>Colegio.FACT_BIBLIOTECA</code>.</li> <li>Propiedades:<ul> <li><code>BatchSize</code>: 0 (usa tama\u00f1o de b\u00fafer).</li> <li><code>UseBulkInsertWhenPossible</code>: <code>true</code>.</li> <li><code>CommandTimeout</code>: 30 segundos.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    Leer EP-EDF-06 -&gt;&gt; Data Conversion: Exporta datos Excel\n    Data Conversion -&gt;&gt; Derived Column: Convierte columnas\n    Derived Column -&gt;&gt; Lookup: Realiza b\u00fasquedas\n    Lookup -&gt;&gt; Derived Column 1: Agrega nuevas columnas derivadas\n    Derived Column 1 -&gt;&gt; Destino de ADO NET: Carga datos en la tabla FACT_BIBLIOTECA</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_desempenho_docente","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_DESEMPENHO_DOCENTE</code> es un flujo de datos dise\u00f1ado para extraer informaci\u00f3n desde un archivo Excel, realizar transformaciones y cargar los datos procesados en una base de datos. Este flujo incluye transformaciones clave como conversi\u00f3n de datos, derivaci\u00f3n de columnas, y consultas de b\u00fasqueda para enriquecer la informaci\u00f3n antes de almacenarla en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos:","text":"<ol> <li> <p>Leer EP-EDF-09 (Excel Source):</p> <ul> <li>Descripci\u00f3n: Fuente de datos que extrae informaci\u00f3n desde un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja: <code>Hoja1$</code></li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Desempenho_Colegio</code></li> <li>Columnas: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>ANIO_ACADEMICO</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion:</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipos de datos de las columnas extra\u00eddas.</li> <li>Columnas Convertidas:<ul> <li><code>TIPO_DOCUMENTO</code> a <code>wstr(40)</code></li> <li><code>FECHA</code> a <code>date</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column:</p> <ul> <li>Descripci\u00f3n: Genera la columna <code>ID_FECHA</code> basada en la fecha en formato <code>YYYYMMDD</code>.</li> <li>Expresi\u00f3n: <code>(DT_I4)(YEAR([Copy of FECHA]) * 10000 + MONTH([Copy of FECHA]) * 100 + DAY([Copy of FECHA]))</code></li> </ul> </li> <li> <p>Lookup:</p> <ul> <li>Descripci\u00f3n: Enlaza los datos con la tabla <code>DIM_PERSONAL</code> para obtener el <code>ID_PERSONAL</code>.</li> <li>Consulta SQL: <pre><code>SELECT [ID_PERSONAL], CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1\n</code></pre></li> </ul> </li> <li> <p>Derived Column 1:</p> <ul> <li>Descripci\u00f3n: Asigna <code>-1</code> al <code>ID_PERSONAL</code> si no se encuentra un valor correspondiente.</li> <li>Expresi\u00f3n: <code>ISNULL(ID_PERSONAL) ? -1 : ID_PERSONAL</code></li> </ul> </li> <li> <p>Lookup 1:</p> <ul> <li>Descripci\u00f3n: Verifica duplicados en la tabla <code>FACT_DESEMPENHO_DOCENTE</code> para evitar registros repetidos.</li> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[FACT_DESEMPENHO_DOCENTE]\nWHERE [ID_FECHA] = ? AND [ID_PERSONAL] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de ADO NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_DESEMPENHO_DOCENTE</code>.</li> <li>Tabla Destino: <code>\"Colegio\".\"FACT_DESEMPENHO_DOCENTE\"</code></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_11","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel_Source as Leer EP-EDF-09 (Excel Source)\n    participant Data_Conversion as Data Conversion\n    participant Derived_Column as Derived Column\n    participant Lookup as Lookup\n    participant Lookup_1 as Lookup 1\n    participant Derived_Column_1 as Derived Column 1\n    participant ADO_NET as Destino de ADO NET\n\n    Excel_Source -&gt;&gt; Data_Conversion: Env\u00edo de datos\n    Data_Conversion -&gt;&gt; Derived_Column: Conversi\u00f3n de tipos\n    Derived_Column -&gt;&gt; Lookup: Relaciona datos con DIM_PERSONAL\n    Lookup -&gt;&gt; Derived_Column_1: Combina resultados\n    Derived_Column_1 -&gt;&gt; Lookup_1: Valida duplicados en FACT_DESEMPENHO_DOCENTE\n    Lookup_1 -&gt;&gt; ADO_NET: Inserta datos \u00fanicos\n    Note right of ADO_NET: Datos procesados y almacenados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_enfermeria","title":"Componente <code>Procesar FACT_ENFERMERIA</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>El componente <code>Procesar FACT_ENFERMERIA</code> gestiona el flujo de datos para transformar, enriquecer y almacenar informaci\u00f3n relacionada con casos de atenci\u00f3n en enfermer\u00eda. Este flujo extrae datos de un archivo Excel, realiza conversiones y c\u00e1lculos, enriquece los datos con informaci\u00f3n adicional, y los carga en una tabla de base de datos mediante un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos:","text":"<ol> <li> <p>Leer EP-EDF-01 (Excel Source):</p> <ul> <li>Descripci\u00f3n: Fuente de datos que extrae informaci\u00f3n desde un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja: <code>Hoja1$</code></li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Enfermeria</code></li> <li>Columnas: <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>IDCASO</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion:</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipos de datos de las columnas extra\u00eddas.</li> <li>Columnas Convertidas:<ul> <li><code>TIPO_DOCUMENTO</code> a <code>wstr(40)</code></li> <li><code>FECHA_ATENCION</code> a <code>date</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column:</p> <ul> <li>Descripci\u00f3n: Genera la columna <code>ID_FECHA</code> basada en la fecha de atenci\u00f3n en formato <code>YYYYMMDD</code>.</li> <li>Expresi\u00f3n: <code>(DT_I4)(YEAR([Copy of FECHA_ATENCION]) * 10000 + MONTH([Copy of FECHA_ATENCION]) * 100 + DAY([Copy of FECHA_ATENCION]))</code></li> </ul> </li> <li> <p>Lookup:</p> <ul> <li>Descripci\u00f3n: Enlaza los datos con la tabla <code>DIM_POBLACION_MATRICULA</code> para obtener el <code>ID_POBLACION_MATRICULA</code>.</li> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]\nWHERE [TIPO_DOCUMENTO] = ? AND [DOCUMENTO] = ?\n</code></pre></li> </ul> </li> <li> <p>Derived Column 1:</p> <ul> <li>Descripci\u00f3n: Asigna <code>-1</code> al <code>ID_POBLACION_MATRICULA</code> si no se encuentra un valor correspondiente.</li> <li>Expresi\u00f3n: <code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA</code></li> </ul> </li> <li> <p>Lookup 1:</p> <ul> <li>Descripci\u00f3n: Verifica duplicados en la tabla <code>FACT_ENFERMERIA</code> para evitar registros repetidos.</li> <li>Consulta SQL: <pre><code>SELECT * FROM [Colegio].[FACT_ENFERMERIA]\nWHERE [ID_CASO] = ? AND [ID_FECHA] = ? AND [ID_POBLACION_MATRICULA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de ADO NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_ENFERMERIA</code>.</li> <li>Tabla Destino: <code>\"Colegio\".\"FACT_ENFERMERIA\"</code></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_12","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel_Source as Leer EP-EDF-01 (Excel Source)\n    participant Data_Conversion as Data Conversion\n    participant Derived_Column as Derived Column\n    participant Lookup as Lookup\n    participant Lookup_1 as Lookup 1\n    participant Derived_Column_1 as Derived Column 1\n    participant ADO_NET as Destino de ADO NET\n\n    Excel_Source -&gt;&gt; Data_Conversion: Env\u00edo de datos\n    Data_Conversion -&gt;&gt; Derived_Column: Conversi\u00f3n de tipos\n    Derived_Column -&gt;&gt; Lookup: Relaciona datos con DIM_POBLACION_MATRICULA\n    Lookup -&gt;&gt; Derived_Column_1: Combina resultados\n    Derived_Column_1 -&gt;&gt; Lookup_1: Verifica duplicados en FACT_ENFERMERIA\n    Lookup_1 -&gt;&gt; ADO_NET: Inserta datos \u00fanicos\n    Note right of ADO_NET: Almacena datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_legalizacion","title":"Componente <code>Procesar FACT_LEGALIZACION</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos del paquete SSIS tiene como objetivo procesar y cargar datos relacionados con FACT_LEGALIZACION desde una fuente de datos Excel hacia una base de datos compatible con ADO.NET. Los datos se someten a diversas transformaciones antes de ser insertados en la tabla destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<p>1. Leer EP-EDF-10</p> <ul> <li>Descripci\u00f3n: Lee datos desde una hoja de Excel llamada <code>Sheet1$</code> usando un origen de datos Excel.</li> <li>Propiedades:<ul> <li>Tiempo de espera: <code>0</code> (sin l\u00edmite).</li> <li>Modo de acceso: <code>0</code> (por defecto).</li> </ul> </li> <li>Columnas de salida:<ul> <li><code>RAZON_SOCIAL</code>: Ancho de 255 caracteres.</li> <li><code>FECHA</code>: Tipo de dato <code>date</code>.</li> <li><code>CODIGO_DANE</code>, <code>CODIGO_ICFES</code>: Tipo de dato <code>r8</code>.</li> <li>Otras columnas incluyen detalles como <code>CALENDARIO</code>, <code>NATURALEZA</code>, <code>CARACTER</code>, <code>TOTAL_ESTUDIANTES</code>, entre otros.</li> </ul> </li> </ul> <p>2. Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos y realiza ajustes necesarios en las columnas del flujo de datos para asegurar la compatibilidad con el destino.</li> <li>Propiedades:<ul> <li>Utiliza la opci\u00f3n <code>FailComponent</code> para manejar errores.</li> <li>Genera copias de las columnas le\u00eddas con ajustes de longitud y tipo de datos.</li> </ul> </li> <li>Columnas procesadas:<ul> <li>Ejemplo: <code>Copy of RAZON_SOCIAL</code> (tipo <code>wstr</code>, longitud: 40), <code>Copy of FECHA</code> (tipo <code>date</code>).</li> </ul> </li> </ul> <p>3. Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas a partir de transformaciones sobre las columnas existentes.</li> <li>Propiedades:<ul> <li>Calcula el campo <code>ID_FECHA</code> combinando valores de <code>A\u00f1o</code>, <code>Mes</code> y <code>D\u00eda</code> provenientes de <code>Copy of FECHA</code>.</li> <li>Ejemplo de expresi\u00f3n: <code>(DT_I4)(YEAR([Copy of FECHA]) * 10000 + MONTH([Copy of FECHA]) * 100 + DAY([Copy of FECHA]))</code>.</li> </ul> </li> </ul> <p>4. Lookup</p> <ul> <li>Descripci\u00f3n: Realiza b\u00fasquedas en la tabla de destino para verificar si los registros ya existen.</li> <li>Propiedades:<ul> <li>Usa la consulta SQL: <code>SELECT * FROM [Colegio].[FACT_LEGALIZACION]</code>.</li> <li>Maneja filas sin coincidencias envi\u00e1ndolas al flujo de datos.</li> <li>Coincidencias basadas en <code>RAZON_SOCIAL</code>, <code>CODIGO_DANE</code> y <code>ID_FECHA</code>.</li> </ul> </li> </ul> <p>5. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados en la tabla destino <code>FACT_LEGALIZACION</code> dentro de la base de datos del Colegio.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Colegio\".\"FACT_LEGALIZACION\"</code>.</li> <li>Tama\u00f1o del lote: <code>0</code> (uso de tama\u00f1o predeterminado).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Usa <code>SqlBulkCopy</code> para mejorar el rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_13","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-10\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant Lookup as Lookup\n    participant ADODestination as Destino de ADO.NET\n\n    ExcelSource-&gt;&gt;DataConversion: Flujo de datos\n    DataConversion-&gt;&gt;DerivedColumn: Datos convertidos\n    DerivedColumn-&gt;&gt;Lookup: Datos transformados\n    Lookup-&gt;&gt;ADODestination: Datos validados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_permiso_estudiante","title":"Componente <code>Procesar FACT_PERMISO_ESTUDIANTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>El flujo de datos del paquete SSIS procesa y carga informaci\u00f3n relacionada con permisos de estudiantes desde un archivo Excel hacia la base de datos del Colegio en la tabla <code>FACT_PERMISO_ESTUDIANTE</code>. El proceso incluye la validaci\u00f3n, transformaci\u00f3n y enriquecimiento de los datos.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_9","title":"Componentes del Flujo de Datos","text":"<p>1. Leer EP-EDF-04</p> <ul> <li>Descripci\u00f3n: Origen de datos Excel que lee los registros desde la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li>Tiempo de espera: <code>0</code> (sin l\u00edmite).</li> <li>Modo de acceso: <code>0</code> (predeterminado).</li> </ul> </li> <li>Columnas de salida: Incluye datos como <code>FECHA</code>, <code>BP_ESTUDIANTE</code>, <code>NOMBRE_ESTUDIANTE</code>, <code>GRADO</code>, <code>CURSO</code>, entre otros.</li> </ul> <p>2. Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos y ajusta las columnas para la compatibilidad con los pasos posteriores.</li> <li>Propiedades:<ul> <li>Asigna un prefijo <code>Copy of</code> a las columnas convertidas.</li> <li>Convierte columnas como <code>BP_ESTUDIANTE</code> (tipo <code>wstr</code>) y <code>FECHA</code> (tipo <code>date</code>).</li> </ul> </li> <li>Manejo de errores: Disposici\u00f3n <code>FailComponent</code>.</li> </ul> <p>3. Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas utilizando expresiones matem\u00e1ticas y l\u00f3gicas.</li> <li>Columnas generadas:<ul> <li><code>ID_FECHA</code>: Calculada como una combinaci\u00f3n de <code>A\u00f1o</code>, <code>Mes</code> y <code>D\u00eda</code>.</li> <li><code>ANIO_ACADEMICO</code>: Extra\u00eddo del a\u00f1o de la columna <code>Copy of FECHA</code>.</li> </ul> </li> </ul> <p>4. Lookup</p> <ul> <li>Descripci\u00f3n: Busca informaci\u00f3n adicional en la tabla de dimensiones <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> <li>Filtra filas bas\u00e1ndose en la columna <code>BP_ESTUDIANTE</code>.</li> </ul> </li> </ul> <p>5. Lookup 1 y Lookup 2</p> <ul> <li>Descripci\u00f3n: <ul> <li><code>Lookup 1</code>: Busca en <code>DIM_CURSO</code> para obtener el <code>ID_CURSO</code>.</li> <li><code>Lookup 2</code>: Busca en <code>DIM_GRADO</code> para obtener el <code>ID_GRADO</code>.</li> </ul> </li> <li>Propiedades:<ul> <li>Ambas operaciones utilizan columnas como <code>CURSO</code> y <code>GRADO</code> para realizar las coincidencias.</li> </ul> </li> </ul> <p>6. Lookup 3</p> <ul> <li>Descripci\u00f3n: Verifica si ya existen registros en la tabla destino <code>FACT_PERMISO_ESTUDIANTE</code> bas\u00e1ndose en las columnas <code>HORA</code>, <code>ID_FECHA</code> e <code>ID_POBLACION_MATRICULA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Colegio].[FACT_PERMISO_ESTUDIANTE]</code>.</li> </ul> </li> </ul> <p>7. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>FACT_PERMISO_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Colegio\".\"FACT_PERMISO_ESTUDIANTE\"</code>.</li> <li>Inserci\u00f3n masiva habilitada con <code>SqlBulkCopy</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_14","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-04\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant Lookup1 as Lookup DIM_POBLACION_MATRICULA\n    participant Lookup2 as Lookup DIM_CURSO\n    participant Lookup3 as Lookup DIM_GRADO\n    participant LookupFinal as Lookup FACT_PERMISO_ESTUDIANTE\n    participant Destination as Destino ADO.NET\n\n    ExcelSource-&gt;&gt;DataConversion: Datos le\u00eddos\n    DataConversion-&gt;&gt;DerivedColumn: Datos convertidos\n    DerivedColumn-&gt;&gt;Lookup1: Validaci\u00f3n de BP_ESTUDIANTE\n    Lookup1-&gt;&gt;Lookup2: Validaci\u00f3n de CURSO\n    Lookup2-&gt;&gt;Lookup3: Validaci\u00f3n de GRADO\n    Lookup3-&gt;&gt;Destination: Inserci\u00f3n en tabla destino</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_psiorientacion","title":"Componente <code>Procesar FACT_PSIORIENTACION</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>El flujo de datos del paquete SSIS procesa y carga informaci\u00f3n de orientaci\u00f3n psicol\u00f3gica de estudiantes desde un archivo Excel hacia la tabla de destino <code>FACT_PSICORIENTACION</code> en la base de datos. Incluye transformaciones de datos, validaciones y enriquecimientos utilizando varias transformaciones de SSIS.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_10","title":"Componentes del Flujo de Datos","text":"<p>1. Leer EP-EDF-11</p> <ul> <li>Descripci\u00f3n: Origen de datos Excel que lee la hoja <code>Hoja1$</code> para obtener la informaci\u00f3n.</li> <li>Propiedades:<ul> <li>Tiempo de espera: 0 (sin l\u00edmite).</li> <li>Modo de acceso: Predeterminado.</li> </ul> </li> <li>Columnas de salida:<ul> <li><code>BP_ESTUDIANTE</code>, <code>IDCASO</code>, <code>ANIO_ACADEMICO</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>FECHA_ATENCION</code>, <code>FECHA_SOLUCION</code>, <code>ESTADO</code>, <code>QUIEN_REMITE</code>, <code>NOTIFICACION_A_PADRES</code>, <code>MOTIVO_ATENCION</code>.</li> </ul> </li> </ul> <p>2. Data Conversion</p> <ul> <li>Descripci\u00f3n: Conversi\u00f3n de tipos de datos y ajuste de columnas.</li> <li>Propiedades:<ul> <li>Agrega un prefijo <code>Copy of</code> a las columnas convertidas.</li> <li>Convierte tipos de datos a <code>wstr</code>, <code>i4</code>, o <code>date</code> seg\u00fan corresponda.</li> </ul> </li> <li>Manejo de errores: <ul> <li>Disposici\u00f3n de error: <code>FailComponent</code>.</li> </ul> </li> </ul> <p>3. Derived Column</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas a partir de las columnas de entrada.</li> <li>Columnas creadas:<ul> <li><code>ID_FECHA</code>: Construido a partir del a\u00f1o, mes y d\u00eda de <code>Copy of FECHA_ATENCION</code>.</li> <li><code>ANIO_ACADEMICO</code>: Extra\u00eddo del a\u00f1o de <code>Copy of FECHA_ATENCION</code>.</li> </ul> </li> </ul> <p>4. Lookup</p> <ul> <li>Descripci\u00f3n: Busca en la tabla <code>DIM_POBLACION_MATRICULA</code> para enriquecer los datos con el identificador <code>ID_POBLACION_MATRICULA</code>.</li> <li>Consulta SQL: <code>SELECT * FROM [Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> <li>Condiciones de b\u00fasqueda: <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code>.</li> </ul> <p>5. Derived Column 1</p> <ul> <li>Descripci\u00f3n: Valida y ajusta el valor de <code>ID_POBLACION_MATRICULA</code> derivado.</li> <li>Expresi\u00f3n derivada:<ul> <li>Si el valor de <code>ID_POBLACION_MATRICULA</code> es nulo, asigna <code>-1</code>.</li> </ul> </li> </ul> <p>6. Lookup 1</p> <ul> <li>Descripci\u00f3n: Valida si el registro ya existe en la tabla <code>FACT_PSICORIENTACION</code> en funci\u00f3n de <code>ID_CASO</code>, <code>ID_FECHA</code>, y <code>ID_POBLACION_MATRICULA</code>.</li> <li>Consulta SQL: <pre><code>SELECT * \nFROM [Colegio].[FACT_PSICORIENTACION]\nWHERE ID_CASO = ? AND ID_FECHA = ? AND ID_POBLACION_MATRICULA = ?\n</code></pre></li> </ul> <p>7. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>FACT_PSICORIENTACION</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Colegio\".\"FACT_PSICORIENTACION\"</code>.</li> <li>Tama\u00f1o de lote: 0 (predeterminado, utiliza el tama\u00f1o del buffer interno).</li> <li>Tiempo de espera del comando: 30 segundos.</li> <li>Uso de <code>SqlBulkCopy</code>: Activado para mejorar el rendimiento.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_15","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-11\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant Lookup1 as Lookup DIM_POBLACION_MATRICULA\n    participant DerivedColumn2 as Derived Column Ajustado\n    participant Lookup2 as Lookup FACT_PSICORIENTACION\n    participant Destination as Destino ADO.NET\n\n    ExcelSource-&gt;&gt;DataConversion: Leer datos desde Excel\n    DataConversion-&gt;&gt;DerivedColumn: Convertir datos y crear ID_FECHA\n    DerivedColumn-&gt;&gt;Lookup1: Validar informaci\u00f3n con DIM_POBLACION_MATRICULA\n    Lookup1-&gt;&gt;DerivedColumn2: Validar ID_POBLACION_MATRICULA\n    DerivedColumn2-&gt;&gt;Lookup2: Verificar existencia en FACT_PSICORIENTACION\n    Lookup2-&gt;&gt;Destination: Insertar en la tabla destino</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_reemplazo_docente","title":"Componente <code>Procesar FACT_REEMPLAZO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>Este paquete SSIS realiza la extracci\u00f3n, transformaci\u00f3n y carga de datos relacionados con la facturaci\u00f3n del reemplazo de docentes. Incluye tareas de conversi\u00f3n de datos, columnas derivadas, b\u00fasquedas en tablas de dimensiones y la carga en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_11","title":"Componentes del Flujo de Datos","text":"<ul> <li>Leer EP-EDF-03 Descripci\u00f3n: Fuente de datos que lee informaci\u00f3n desde un archivo Excel en la hoja \"Hoja1$\". Propiedades:         - <code>CommandTimeout</code>: 0         - <code>OpenRowset</code>: \"Hoja1$\" Columnas de Salida:  ID_REEMPLAZO, TIPO_DOCUMENTO_DOCENTE_AUSENTE, DOCUMENTO_DOCENTE_AUSENTE, GRADO, FECHA, BLOQUE_HORARIO, NUMERO_HORAS, CURSO, DOCENTE_AUSENTE, DOCENTE_REEMPLAZA, TIPO_DOCUMENTO_DOCENTE_REEMPLAZA, DOCUMENTO_DOCENTE_REEMPLAZA</li> <li> <p>Data Conversion Descripci\u00f3n: Realiza conversiones de tipos de datos para columnas espec\u00edficas. Columnas Transformadas:  </p> <ul> <li><code>ANIO_ACADEMICO \u2192 DT_I4</code></li> <li><code>TIPO_DOCUMENTO_DOCENTE_AUSENTE \u2192 wstr (longitud 20)</code></li> <li><code>DOCUMENTO_DOCENTE_AUSENTE \u2192 wstr (longitud 40)</code></li> <li><code>FECHA \u2192 date</code></li> <li><code>BLOQUE_HORARIO \u2192 wstr (longitud 40)</code></li> </ul> </li> <li> <p>Derived Column Descripci\u00f3n: Genera nuevas columnas basadas en expresiones. Columnas Derivadas:         ID_FECHA: Calculado como <code>(DT_I4)(YEAR([Copy of FECHA]) * 10000 + MONTH([Copy of FECHA]) * 100 + DAY([Copy of FECHA]))</code>.</p> </li> <li> <p>Lookup (DIM_PERSONAL) Descripci\u00f3n: Busca informaci\u00f3n de personal docente ausente en la tabla <code>[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]</code>. SQL Utilizado: <pre><code>SELECT [ID_PERSONAL],\n    CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO,\n    [ID_UNIDAD],\n    [TIPO_DOCUMENTO],\n    [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1;\n</code></pre> Columnas Vinculadas:         - Copy of TIPO_DOCUMENTO_DOCENTE_AUSENTE \u2192 TIPO_DOCUMENTO         - Copy of DOCUMENTO_DOCENTE_AUSENTE \u2192 DOCUMENTO         - Copy of ANIO_ACADEMICO \u2192 ANIO_ACADEMICO  </p> </li> <li> <p>Lookup (DIM_GRADO) Descripci\u00f3n: Busca informaci\u00f3n del grado en la tabla <code>[Colegio].[DIM_GRADO]</code>. SQL Utilizado: <pre><code>SELECT * FROM [Colegio].[DIM_GRADO];\n</code></pre> Columnas Vinculadas:         - Copy of GRADO \u2192 DESC_GRADO  </p> </li> <li> <p>Destino ADO.NET Descripci\u00f3n: Carga los datos transformados en la tabla <code>\"Colegio\".\"FACT_REEMPLAZO_DOCENTE\"</code>. Propiedades:         - <code>BatchSize</code>: 0         - <code>CommandTimeout</code>: 30         - <code>UseBulkInsertWhenPossible</code>: true Columnas de Entrada:  ID_FECHA  , ID_PERSONAL_AUSENTE  , ID_PERSONAL_REEMPLAZA  , ID_CURSO  , ID_GRADO  , ANIO_ACADEMICO  , FECHA  </p> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_16","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-03\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupDimPersonal as Lookup DIM_PERSONAL\n    participant LookupDimGrado as Lookup DIM_GRADO\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Transformaci\u00f3n de datos\n    DataConversion -&gt;&gt; DerivedColumn: Generaci\u00f3n de columnas derivadas\n    DerivedColumn -&gt;&gt; LookupDimPersonal: B\u00fasqueda de personal\n    LookupDimPersonal -&gt;&gt; LookupDimGrado: B\u00fasqueda de grado\n    LookupDimGrado -&gt;&gt; ADONETDestination: Carga de datos</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_reserva_espacios","title":"Componente <code>Procesar FACT_RESERVA_ESPACIOS</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_24","title":"Descripci\u00f3n General","text":"<p>Este paquete SSIS procesa los datos relacionados con la reserva de espacios educativos. Realiza la extracci\u00f3n desde un archivo Excel, transforma los datos mediante conversiones y c\u00e1lculos, realiza b\u00fasquedas de informaci\u00f3n adicional en tablas de dimensiones y carga los datos transformados en una tabla de destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_12","title":"Componentes del Flujo de Datos","text":"<ul> <li> <p>Leer EP-EDF-12</p> <ul> <li>Descripci\u00f3n: Este componente extrae los datos desde un archivo Excel. Utiliza la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida:<code>ANIO_ACADEMICO</code>, <code>ID_RESERVA</code>, <code>FECHA_SOLICITUD</code>, <code>FECHA_RESERVA</code>, <code>TIPO_DOCUMENTO_DOCENTO</code>, <code>DOCUMENTO_DOCENTE</code>, <code>CORREO_DOCENTE</code>, <code>HORA_INICIO</code>, <code>HORA_FIN</code>, <code>ACTIVIDAD_PLANEADA</code>, <code>PLACA_PORTATIL</code>, <code>VIDEOBEAM</code></li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipos de datos para asegurar la compatibilidad con los componentes posteriores.</li> <li>Transformaciones:<ul> <li>ANIO_ACADEMICO \u2192 <code>DT_I4</code></li> <li>ID_RESERVA \u2192 <code>DT_I4</code></li> <li>FECHA_SOLICITUD \u2192 <code>DT_DATE</code></li> <li>FECHA_RESERVA \u2192 <code>DT_DATE</code></li> <li>TIPO_DOCUMENTO_DOCENTE \u2192 <code>wstr</code> (40)</li> <li>DOCUMENTO_DOCENTE \u2192 <code>wstr</code> (20)</li> <li>CORREO_DOCENTE \u2192 <code>wstr</code> (200)</li> <li>HORA_INICIO \u2192 <code>wstr</code> (40)</li> <li>HORA_FIN \u2192 <code>wstr</code> (40)</li> <li>ACTIVIDAD_PLANEADA \u2192 <code>wstr</code> (40)</li> <li>PLACA_PORTATIL \u2192 <code>wstr</code> (40)</li> <li>VIDEOBEAM \u2192 <code>wstr</code> (40)</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas a partir de c\u00e1lculos con las columnas existentes.</li> <li>Transformaciones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)(YEAR([Copy of FECHA_RESERVA]) * 10000 + MONTH([Copy of FECHA_RESERVA]) * 100 + DAY([Copy of FECHA_RESERVA]))</code></li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_PERSONAL)</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>[DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]</code> para obtener informaci\u00f3n adicional del personal docente.</li> <li>SQL Utilizado:     <pre><code>SELECT [ID_PERSONAL],\n       CAST(LEFT([COD_PERSONA_UNIDAD], 4) AS INT) AS ANIO_ACADEMICO,\n       [ID_UNIDAD],\n       [TIPO_DOCUMENTO],\n       [DOCUMENTO]\nFROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\nWHERE [ID_UNIDAD] = 1;\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li>Copy of ANIO_ACADEMICO \u2192 ANIO_ACADEMICO</li> <li>Copy of TIPO_DOCUMENTO_DOCENTE \u2192 TIPO_DOCUMENTO</li> <li>Copy of DOCUMENTO_DOCENTE \u2192 DOCUMENTO</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>\"Colegio\".\"FACT_RESERVA_ESPACIOS\"</code>.</li> <li>Propiedades:<ul> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Columnas de Entrada:     <code>ID_FECHA</code>, <code>ID_PERSONAL</code>, <code>Copy of ID_RESERVA</code>, <code>Copy of DOCUMENTO_DOCENTE</code>, <code>Copy of FECHA_SOLICITUD</code>, <code>Copy of FECHA_RESERVA</code>, <code>Copy of CORREO_DOCENTE</code>, <code>Copy of HORA_INICIO</code>, <code>Copy of HORA_FIN</code>, <code>Copy of ACTIVIDAD_PLANEADA</code>, <code>Copy of PLACA_PORTATIL</code>, <code>Copy of VIDEOBEAM</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_17","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-12\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupDimPersonal as Lookup DIM_PERSONAL\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Transformaci\u00f3n de datos\n    DataConversion -&gt;&gt; DerivedColumn: Generaci\u00f3n de columnas derivadas\n    DerivedColumn -&gt;&gt; LookupDimPersonal: B\u00fasqueda de datos adicionales\n    LookupDimPersonal -&gt;&gt; ADONETDestination: Carga de datos transformados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_saber11_colegios","title":"Componente <code>Procesar FACT_SABER11_COLEGIOS</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_25","title":"Descripci\u00f3n General","text":"<p>Este paquete de SSIS procesa datos relacionados con las evaluaciones del SABER 11 para colegios, extrayendo informaci\u00f3n de un archivo Excel, transformando y enriqueciendo los datos con c\u00e1lculos derivados y b\u00fasquedas, y carg\u00e1ndolos en una tabla de destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_13","title":"Componentes del Flujo de Datos","text":"<ul> <li> <p>Leer EP-EDF-08</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel ubicado en <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code> (a\u00f1o acad\u00e9mico del registro)</li> <li><code>ID_REGISTRO</code> (identificador del registro)</li> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> (c\u00f3digo DANE del establecimiento educativo)</li> <li><code>NOMBRE_ESTABLECIMIENTO_EDUCATIVO</code> (nombre del establecimiento)</li> <li><code>RESULTADO</code> (resultado del examen SABER 11)</li> <li><code>CATEGORIA_SABER11</code> (categor\u00eda del colegio seg\u00fan el SABER 11)</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de tipo de datos para asegurar la compatibilidad con los siguientes pasos del flujo de datos.</li> <li>Transformaciones:<ul> <li><code>ANIO_ACADEMICO</code> \u2192 <code>DT_I4</code></li> <li><code>ID_REGISTRO</code> \u2192 <code>wstr</code> (255)</li> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> \u2192 <code>wstr</code> (40)</li> <li><code>NOMBRE_ESTABLECIMIENTO_EDUCATIVO</code> \u2192 <code>wstr</code> (200)</li> <li><code>RESULTADO</code> \u2192 <code>wstr</code> (40)</li> <li><code>CATEGORIA_SABER11</code> \u2192 <code>wstr</code> (40)</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>[DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS]</code> para enriquecer los datos con informaci\u00f3n adicional.</li> <li>SQL Utilizado:     <pre><code>SELECT [ID_REGISTRO],\n       [ID_FECHA],\n       CAST([ANIO_ACADEMICO] AS INT) AS ANIO_ACADEMICO,\n       [COD_ESTABLECIMIENTO_EDUCATIVO],\n       [NOMBRE_EE],\n       [RESULTADO],\n       [CATEGORIA_SABER11]\nFROM [DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS];\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> \u2192 <code>COD_ESTABLECIMIENTO_EDUCATIVO</code></li> <li><code>ANIO_ACADEMICO</code> \u2192 <code>ANIO_ACADEMICO</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Calcula una columna derivada para el identificador de fecha.</li> <li>Transformaciones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)((DT_STR,4,1252)ANIO_ACADEMICO + \"1201\")</code></li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino <code>\"Colegio\".\"FACT_SABER11_COLEGIOS\"</code>.</li> <li>Propiedades:<ul> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_FECHA</code> (identificador \u00fanico para la fecha derivada)</li> <li><code>ANIO_ACADEMICO</code> (a\u00f1o acad\u00e9mico)</li> <li><code>CODIDGO_DANE_ESTABLECIMIENTO_EDUCATIVO</code> (c\u00f3digo DANE del establecimiento)</li> <li><code>NOMBRE_ESTABLECIMIENTO_EDUCATIVO</code> (nombre del establecimiento)</li> <li><code>RESULTADO</code> (resultado del examen)</li> <li><code>CATEGORIA_SABER11</code> (categor\u00eda seg\u00fan el examen SABER 11)</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_18","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-08\n    participant DataConversion as Data Conversion\n    participant Lookup as Lookup SABER11\n    participant DerivedColumn as Derived Column\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Transformaci\u00f3n de datos\n    DataConversion -&gt;&gt; Lookup: Enriquecimiento de datos\n    Lookup -&gt;&gt; DerivedColumn: Generaci\u00f3n de columnas derivadas\n    DerivedColumn -&gt;&gt; ADONETDestination: Carga de datos transformados</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_saber11_individual","title":"Componente <code>Procesar FACT_SABER11_INDIVIDUAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_26","title":"Descripci\u00f3n General","text":"<p>Este paquete de SSIS procesa datos individuales del SABER 11, extrayendo informaci\u00f3n desde un archivo Excel, transformando y enriqueciendo los datos mediante conversiones, columnas derivadas y b\u00fasquedas, para finalmente almacenarlos en una tabla de destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_14","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Leer EP-EDF-07</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel ubicado en <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida: <code>ANIO_ACADEMICO</code>, <code>ID_REGISTRO</code>, <code>RESULTADO</code>, <code>BP_ESTUDIANTE</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>FECHA</code>, <code>TEMATICA</code></li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los tipos de datos de las columnas para asegurar la compatibilidad con el resto del flujo.</li> <li>Transformaciones:<ul> <li><code>ANIO_ACADEMICO</code> \u2192 <code>DT_I4</code></li> <li><code>RESULTADO</code> \u2192 <code>wstr</code> (40)</li> <li><code>BP_ESTUDIANTE</code> \u2192 <code>wstr</code> (40)</li> <li><code>TIPO_DOCUMENTO</code> \u2192 <code>wstr</code> (40)</li> <li><code>DOCUMENTO</code> \u2192 <code>wstr</code> (20)</li> <li><code>FECHA</code> \u2192 <code>date</code></li> <li><code>TEMATICA</code> \u2192 <code>wstr</code> (40)</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Genera un identificador \u00fanico para las fechas en formato <code>YYYYMMDD</code>.</li> <li>Transformaciones:<ul> <li><code>ID_FECHA</code>: <code>(DT_I4)(YEAR([FECHA]) * 10000 + MONTH([FECHA]) * 100 + DAY([FECHA]))</code></li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_POBLACION_MATRICULA)</p> <ul> <li>Descripci\u00f3n: Enriquecer los datos con informaci\u00f3n de la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code>.</li> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Colegio].[DIM_POBLACION_MATRICULA]\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li><code>BP_ESTUDIANTE</code> \u2192 <code>PARTNER</code></li> </ul> </li> <li>Salida:<ul> <li><code>ID_POBLACION_MATRICULA</code></li> </ul> </li> </ul> </li> <li> <p>Lookup (FACT_SABER11_INDIVIDUAL)</p> <ul> <li>Descripci\u00f3n: Verifica si los datos ya existen en la tabla de destino <code>[Colegio].[FACT_SABER11_INDIVIDUAL]</code>.</li> <li>Consulta SQL:     <pre><code>SELECT \n    [ID_REGISTRO],\n    [ID_FECHA],\n    CAST([ANIO_ACADEMICO] AS INT) AS ANIO_ACADEMICO,\n    [ID_POBLACION_MATRICULA],\n    [TEMATICA],\n    [RESULTADO]\nFROM [Colegio].[FACT_SABER11_INDIVIDUAL]\n</code></pre></li> <li>Columnas Vinculadas:<ul> <li><code>ANIO_ACADEMICO</code></li> <li><code>TEMATICA</code></li> <li><code>ID_POBLACION_MATRICULA</code></li> </ul> </li> </ul> </li> <li> <p>Derived Column (Validaci\u00f3n de ID_POBLACION_MATRICULA)</p> <ul> <li>Descripci\u00f3n: Agrega una validaci\u00f3n para la columna <code>ID_POBLACION_MATRICULA</code>.</li> <li>Transformaciones:<ul> <li><code>ID_POBLACION_MATRICULA</code>: <code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA</code></li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>\"Colegio\".\"FACT_SABER11_INDIVIDUAL\"</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"FACT_SABER11_INDIVIDUAL\"</code></li> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> <li>Columnas de Entrada:<ul> <li><code>ID_FECHA</code></li> <li><code>ID_POBLACION_MATRICULA</code></li> <li><code>ANIO_ACADEMICO</code></li> <li><code>TEMATICA</code></li> <li><code>RESULTADO</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_19","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-07\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column (Fecha)\n    participant LookupDIM as Lookup DIM_POBLACION_MATRICULA\n    participant LookupFACT as Lookup FACT_SABER11_INDIVIDUAL\n    participant DerivedColumn2 as Derived Column (Validaci\u00f3n)\n    participant ADONETDestination as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Convertir tipos de datos\n    DataConversion -&gt;&gt; DerivedColumn: Crear ID_FECHA\n    DerivedColumn -&gt;&gt; LookupDIM: Enriquecer datos con ID_POBLACION_MATRICULA\n    LookupDIM -&gt;&gt; LookupFACT: Verificar existencia en FACT_SABER11_INDIVIDUAL\n    LookupFACT -&gt;&gt; DerivedColumn2: Validar ID_POBLACION_MATRICULA\n    DerivedColumn2 -&gt;&gt; ADONETDestination: Insertar datos en tabla de destino</code></pre>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componente-procesar-fact_servicio_social","title":"Componente <code>Procesar FACT_SERVICIO_SOCIAL</code>","text":""},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#descripcion-general_27","title":"Descripci\u00f3n General","text":"<p>Este paquete de SSIS procesa datos relacionados con el servicio social de estudiantes, transformando y enriqueciendo la informaci\u00f3n desde un archivo Excel para almacenarla en una base de datos relacional. Incluye conversiones de datos, b\u00fasqueda de informaci\u00f3n relacionada y validaciones, y finalmente inserta los datos en una tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#componentes-del-flujo-de-datos_15","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Leer EP-EDF-13</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel, ubicado en la hoja <code>Hoja1$</code>.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0</li> <li><code>OpenRowset</code>: Hoja1$</li> </ul> </li> <li>Columnas de Salida:<ul> <li><code>ANIO_ACADEMICO</code>, <code>BP_ESTUDIANTE</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>GRADO</code>, <code>CURSO</code>, <code>HORARIO</code>, <code>PROYECTO</code>, <code>PAZ_Y_SALVO</code>, <code>HORAS_EJECUTADAS</code>, <code>AUTORIZACION_ACUDIENTE</code></li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte las columnas para asegurar compatibilidad en el flujo.</li> <li>Transformaciones:<ul> <li><code>ANIO_ACADEMICO</code> \u2192 <code>DT_I4</code></li> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>GRADO</code>, <code>CURSO</code>, <code>HORARIO</code>, <code>PROYECTO</code>, <code>PAZ_Y_SALVO</code>, <code>HORAS_EJECUTADAS</code>, <code>AUTORIZACION_ACUDIENTE</code> \u2192 <code>wstr</code></li> </ul> </li> <li>Columnas Convertidas: Todas las columnas del componente de entrada.</li> </ul> </li> <li> <p>Lookup: DIM_POBLACION_MATRICULA</p> <ul> <li>Descripci\u00f3n: Busca el identificador de poblaci\u00f3n en la tabla <code>[Colegio].[DIM_POBLACION_MATRICULA]</code> usando <code>BP_ESTUDIANTE</code>.</li> <li>Consulta SQL:     <pre><code>SELECT *\nFROM [Colegio].[DIM_POBLACION_MATRICULA]\nWHERE [PARTNER] = ?\n</code></pre></li> <li>Columnas de Salida: <code>ID_POBLACION_MATRICULA</code></li> </ul> </li> <li> <p>Lookup: DIM_CURSO</p> <ul> <li>Descripci\u00f3n: Busca el identificador del curso en la tabla <code>[Colegio].[DIM_CURSO]</code> usando <code>DESC_CURSO</code>.</li> <li>Consulta SQL:     <pre><code>SELECT *\nFROM [Colegio].[DIM_CURSO]\nWHERE [DESC_CURSO] = ?\n</code></pre></li> <li>Columnas de Salida: <code>ID_CURSO</code></li> </ul> </li> <li> <p>Lookup: DIM_GRADO</p> <ul> <li>Descripci\u00f3n: Busca el identificador del grado en la tabla <code>[Colegio].[DIM_GRADO]</code> usando <code>DESC_GRADO</code>.</li> <li>Consulta SQL:     <pre><code>SELECT *\nFROM [Colegio].[DIM_GRADO]\nWHERE [DESC_GRADO] = ?\n</code></pre></li> <li>Columnas de Salida: <code>ID_GRADO</code></li> </ul> </li> <li> <p>Lookup: FACT_SERVICIO_SOCIAL</p> <ul> <li>Descripci\u00f3n: Verifica la existencia de registros en la tabla <code>[Colegio].[FACT_SERVICIO_SOCIAL]</code>.</li> <li>Consulta SQL:     <pre><code>SELECT [ID_REGISTRO], [ANIO_ACADEMICO], [ID_POBLACION_MATRICULA], [ID_CURSO], [ID_GRADO]\nFROM [Colegio].[FACT_SERVICIO_SOCIAL]\nWHERE [ANIO_ACADEMICO] = ? AND [ID_POBLACION_MATRICULA] = ? AND [ID_CURSO] = ? AND [ID_GRADO] = ?\n</code></pre></li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Agrega validaciones para columnas enriquecidas.</li> <li>Transformaciones:<ul> <li><code>ID_POBLACION_MATRICULA</code>: <code>ISNULL(ID_POBLACION_MATRICULA) ? -1 : ID_POBLACION_MATRICULA</code></li> <li><code>ID_CURSO</code>: <code>ISNULL(ID_CURSO) ? -1 : ID_CURSO</code></li> <li><code>ID_GRADO</code>: <code>ISNULL(ID_GRADO) ? -1 : ID_GRADO</code></li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>\"Colegio\".\"FACT_SERVICIO_SOCIAL\"</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Colegio\".\"FACT_SERVICIO_SOCIAL\"</code></li> <li><code>BatchSize</code>: 0</li> <li><code>CommandTimeout</code>: 30</li> <li><code>UseBulkInsertWhenPossible</code>: true</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/04-COLEGIO_FACT/#diagrama-de-secuencia_20","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Leer EP-EDF-13\n    participant DataConversion as Data Conversion\n    participant Lookup1 as Lookup DIM_POBLACION_MATRICULA\n    participant Lookup2 as Lookup DIM_CURSO\n    participant Lookup3 as Lookup DIM_GRADO\n    participant Lookup4 as Lookup FACT_SERVICIO_SOCIAL\n    participant DerivedColumn as Derived Column\n    participant ADO as Destino ADO.NET\n\n    ExcelSource -&gt;&gt; DataConversion: Convertir datos\n    DataConversion -&gt;&gt; Lookup1: Buscar ID_POBLACION_MATRICULA\n    Lookup1 -&gt;&gt; Lookup2: Buscar ID_CURSO\n    Lookup2 -&gt;&gt; Lookup3: Buscar ID_GRADO\n    Lookup3 -&gt;&gt; Lookup4: Verificar existencia\n    Lookup4 -&gt;&gt; DerivedColumn: Validar IDs\n    DerivedColumn -&gt;&gt; ADO: Insertar datos en FACT_SERVICIO_SOCIAL</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/","title":"05. CEDESARROLLO_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#cedesarrollo_dimensiones","title":"CEDESARROLLO_DIMENSIONES","text":"<p>El paquete SSIS \"05-CEDESARROLLO_DIMENSIONES\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar datos esenciales relacionados con dimensiones clave como per\u00edodos acad\u00e9micos, programas educativos, jornadas, y poblaci\u00f3n matriculada. Este paquete asegura la calidad e integridad de los datos consolidados en el Data Warehouse <code>DWH_COMFENALCO</code>, proporcionando una base s\u00f3lida para an\u00e1lisis estrat\u00e9gicos y toma de decisiones.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El prop\u00f3sito principal es gestionar, transformar y cargar datos relacionados con dimensiones transversales del \u00e1mbito educativo y administrativo, garantizando su consistencia y disponibilidad para an\u00e1lisis detallados en plataformas de inteligencia de negocios.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>DIM_PERIODO_ACADEMICO</code>, <code>DIM_PROGRAMA</code>, <code>DIM_JORNADA</code>, <code>DIM_POBLACION_MATRICULA</code>.</li> <li>Archivos Excel:</li> <li>Informaci\u00f3n de jornadas y programas.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET y OLE DB.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaciones (<code>Lookup</code>):<ul> <li>Asegura consistencia mediante b\u00fasquedas en tablas maestras como <code>DIM_ESTUDIANTES</code> y <code>DIM_TIEMPO</code>.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Garantiza compatibilidad con las tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Genera identificadores y valores predeterminados.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>DIM_PERIODO_ACADEMICO</code></li> <li><code>DIM_PROGRAMA</code></li> <li><code>DIM_JORNADA</code></li> <li><code>DIM_POBLACION_MATRICULA</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python para automatizar tareas de descarga y validaci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_PERIODO_ACADEMICO:</p> <ul> <li><code>ID_PERIODO</code>, <code>ID_UNIDAD</code>, <code>PERIODO_ACADEMICO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>.</li> </ul> </li> <li> <p>DIM_PROGRAMA:</p> <ul> <li><code>ID_PROGRAMA</code>, <code>NOMBRE_PROGRAMA</code>, <code>DESCRIPCION</code>.</li> </ul> </li> <li> <p>DIM_JORNADA:</p> <ul> <li><code>ID_JORNADA</code>, <code>NOMBRE_JORNADA</code>, <code>HORARIO</code>.</li> </ul> </li> <li> <p>DIM_POBLACION_MATRICULA:</p> <ul> <li><code>ID_POBLACION</code>, <code>NOMBRE</code>, <code>DOCUMENTO</code>, <code>GENERO</code>, <code>FECHA_NACIMIENTO</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagramas","title":"Diagramas","text":"<p>1. Diagrama de Flujo de Datos</p> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Excel\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de dimensiones\n    SSIS -&gt;&gt; Excel: Leer informaci\u00f3n adicional\n    SSIS -&gt;&gt; Python: Ejecutar scripts de validaci\u00f3n\n    SSIS -&gt;&gt; DWH: Cargar datos procesados</code></pre> <p>2. Diagrama ER para Tablas de Dimensiones</p> <pre><code>erDiagram\n    DIM_PERIODO_ACADEMICO {\n        int ID_PERIODO\n        int ID_UNIDAD\n        string PERIODO_ACADEMICO\n        date FECHA_INICIO\n        date FECHA_FIN\n    }\n    DIM_PROGRAMA {\n        int ID_PROGRAMA\n        string NOMBRE_PROGRAMA\n        string DESCRIPCION\n    }\n    DIM_JORNADA {\n        int ID_JORNADA\n        string NOMBRE_JORNADA\n        string HORARIO\n    }\n    DIM_POBLACION_MATRICULA {\n        int ID_POBLACION\n        string NOMBRE\n        string DOCUMENTO\n        string GENERO\n        date FECHA_NACIMIENTO\n    }\n    DIM_PERIODO_ACADEMICO ||--|| DIM_JORNADA : \"Relaci\u00f3n de Per\u00edodo con Jornadas\"\n    DIM_JORNADA ||--|| DIM_PROGRAMA : \"Asociaci\u00f3n a Programas\"\n    DIM_POBLACION_MATRICULA ||--|| DIM_PROGRAMA : \"Estudiantes en Programas\"</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-clave-del-paquete","title":"Componentes Clave del Paquete","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#sql-agregar-1-a-periodo_academico","title":"SQL: <code>Agregar -1 a Periodo_Academico</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Esta tarea de tipo \"Ejecutar SQL\" realiza la limpieza y la inserci\u00f3n de un registro especial en la tabla <code>[DIM_PERIODO_ACADEMICO]</code> en la base de datos <code>[Cedesarrollo]</code>. Este registro representa un valor por defecto (<code>-1</code>) para per\u00edodos acad\u00e9micos sin datos.</p> <p>Detalles de la Configuraci\u00f3n</p> <ul> <li>Nombre del Componente: <code>Agregar -1 a Periodo_Academico</code></li> <li>Descripci\u00f3n: <code>Tarea Ejecutar SQL</code></li> <li>Conexi\u00f3n: <code>{C2A27DDB-56C2-4889-8A4B-7AA7124DFFD7}</code></li> <li>Sentencia SQL:</li> </ul> <pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO];\n\n-- Insertar un registro para el periodo sin datos\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] ON;\n\nINSERT INTO [Cedesarrollo].[DIM_PERIODO_ACADEMICO] (\n    [ID_PERIODO], \n    [ID_UNIDAD], \n    [PERIODO_ACADEMICO], \n    [FECHA_INICIO], \n    [FECHA_FIN]\n) \nVALUES (\n    -1, \n    5, \n    'Sin datos', \n    NULL, \n    NULL\n);\n\nSET IDENTITY_INSERT [Cedesarrollo].[DIM_PERIODO_ACADEMICO] OFF;\nGO\n</code></pre> <p>Prop\u00f3sito</p> <ol> <li>Limpieza: Se utiliza la instrucci\u00f3n <code>TRUNCATE TABLE</code> para vaciar la tabla <code>[DIM_PERIODO_ACADEMICO]</code> y garantizar que est\u00e9 lista para nuevos datos.</li> <li>Inserci\u00f3n de Registro Especial:<ul> <li>ID_PERIODO: <code>-1</code>, para representar per\u00edodos sin datos.</li> <li>ID_UNIDAD: <code>5</code>, asociado a la unidad correspondiente.</li> <li>PERIODO_ACADEMICO: <code>'Sin datos'</code>, indicando ausencia de datos.</li> <li>FECHA_INICIO y FECHA_FIN: <code>NULL</code>, ya que no son aplicables para este registro.</li> </ul> </li> </ol> <p>Notas T\u00e9cnicas</p> <ol> <li><code>IDENTITY_INSERT</code>: La opci\u00f3n se activa para permitir la inserci\u00f3n manual de un valor en la columna <code>ID_PERIODO</code>, que es de tipo <code>IDENTITY</code>.</li> <li>Compatibilidad: Se asegura que la tabla est\u00e9 vac\u00eda antes de insertar el nuevo registro.</li> <li>Ejecuci\u00f3n Segura:</li> <li>No se utiliza <code>DELETE</code> sino <code>TRUNCATE</code>, optimizando el rendimiento y liberando espacio utilizado.</li> </ol> <p>Impacto Este registro asegura que cualquier operaci\u00f3n dependiente de <code>[DIM_PERIODO_ACADEMICO]</code> pueda manejar escenarios donde no existan datos reales, evitando errores o inconsistencias en el modelo de datos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama","title":"Diagrama","text":"<pre><code>sequenceDiagram\n    participant SQLTask as Agregar -1 a Periodo_Academico\n    participant DB as Base de Datos [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\n\n    SQLTask-&gt;&gt;DB: TRUNCATE TABLE [DIM_PERIODO_ACADEMICO]\n    SQLTask-&gt;&gt;DB: SET IDENTITY_INSERT [DIM_PERIODO_ACADEMICO] ON\n    SQLTask-&gt;&gt;DB: INSERT INTO [DIM_PERIODO_ACADEMICO] VALUES (-1, 5, 'Sin datos', NULL, NULL)\n    SQLTask-&gt;&gt;DB: SET IDENTITY_INSERT [DIM_PERIODO_ACADEMICO] OFF\n    DB--&gt;&gt;SQLTask: Confirmaci\u00f3n de ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-tarea-cede_listado_matriculas","title":"Componente <code>Tarea cede_Listado_Matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea cede_Listado_Matriculas ejecuta un script de Python utilizando un entorno espec\u00edfico. Este script realiza la descarga de informaci\u00f3n relacionada con la matriculaci\u00f3n bajo una clave identificadora proporcionada.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Descripci\u00f3n:</p> <ul> <li>Nombre del Script: <code>download.py</code></li> <li>Par\u00e1metros: <ul> <li><code>--key</code>: Define la clave del proceso, en este caso, <code>cede_Listado_Matriculas</code>.</li> </ul> </li> <li>Prop\u00f3sito: Descargar datos relevantes desde una fuente configurada previamente.</li> <li>Archivo Ejecutable: El script es ejecutado mediante el entorno virtual de Python especificado.</li> </ul> </li> <li> <p>Propiedades:</p> <ul> <li>Executable: <ul> <li><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> </ul> </li> <li>Working Directory:<ul> <li><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> <li>Argumentos del Script:<ul> <li><code>download.py --key cede_Listado_Matriculas</code></li> </ul> </li> </ul> </li> <li> <p>Conexi\u00f3n a Variables del Proyecto:</p> <ul> <li>Executable: Configurado din\u00e1micamente usando <code>@[$Project::Python_Executable]</code>.</li> <li>Directorio de Trabajo: Configurado como <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code>.</li> </ul> </li> <li> <p>Comportamiento de Registro:</p> <ul> <li>Configurado mediante el filtro predeterminado del contenedor SSIS.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea cede_Listado_Matriculas\n    participant OS as Sistema Operativo\n    participant PythonScript as Script download.py\n\n    SSIS-&gt;&gt;OS: Ejecuta python.exe\n    OS-&gt;&gt;PythonScript: Llama al script `download.py --key cede_Listado_Matriculas`\n    PythonScript--&gt;&gt;OS: Descarga completada o error\n    OS--&gt;&gt;SSIS: Resultado del proceso (\u00e9xito o error)</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_jornada","title":"Componente <code>DIM_JORNADA</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente DIM_JORNADA gestiona el flujo de datos necesario para procesar, limpiar y almacenar informaci\u00f3n relacionada con jornadas en la tabla <code>DIM_JORNADA</code> dentro de una base de datos. Este proceso incluye la lectura de datos desde un archivo Excel, la transformaci\u00f3n de los campos, la validaci\u00f3n de duplicados y la carga final en la base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Descripci\u00f3n: Lectura de datos desde una hoja de Excel llamada <code>Sheet1$</code>.</li> <li>Propiedades:<ul> <li>Modo de acceso: 0 (Abrir como tabla).</li> <li>Timeout: 0 (sin l\u00edmite de espera).</li> <li>Conexi\u00f3n: Administrador de conexiones <code>OleDbConnection</code>.</li> </ul> </li> </ul> </li> <li> <p>Sort JORNADA</p> <ul> <li>Descripci\u00f3n: Ordena los datos en el flujo seg\u00fan la columna <code>JORNADA</code>, eliminando duplicados.</li> <li>Propiedades:<ul> <li>Eliminar duplicados: <code>true</code>.</li> <li>N\u00famero m\u00e1ximo de hilos: <code>-1</code> (utiliza el m\u00e1ximo disponible).</li> </ul> </li> </ul> </li> <li> <p>ELIMINAR VACIOS</p> <ul> <li>Descripci\u00f3n: Filtra registros donde el campo <code>JORNADA</code> est\u00e1 vac\u00edo o nulo, enrutando solo los registros v\u00e1lidos.</li> <li>Condici\u00f3n: <pre><code>!ISNULL(JORNADA) &amp;&amp; LEN(JORNADA) &gt; 0\n</code></pre></li> </ul> </li> <li> <p>AJUSTAR CAMPO JORNADA</p> <ul> <li>Descripci\u00f3n: Transforma la columna <code>JORNADA</code> ajustando el formato de los datos a un tipo de dato compatible.</li> <li>Propiedades:<ul> <li>Tipo de salida: Cadena (<code>wstr</code>) de longitud m\u00e1xima <code>40</code>.</li> </ul> </li> </ul> </li> <li> <p>CREAR ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Asigna valores \u00fanicos al campo <code>ID_UNIDAD</code> en el flujo.</li> <li>C\u00f3digo principal: (Simplificado en Visual Basic)     <pre><code>Public Overrides Sub Entrada0_ProcessInputRow(ByVal Row As Entrada0Buffer)\n        Row.IDUNIDAD = 2\nEnd Sub\n</code></pre></li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Busca registros existentes en la tabla <code>DIM_JORNADA</code> basados en las columnas <code>JORNADA</code> y <code>ID_UNIDAD</code>.</li> <li>Comportamiento sin coincidencias: Enviar los registros sin coincidencia para ser almacenados en la tabla destino.</li> <li>Cache: Completo (<code>CacheType = 0</code>).</li> </ul> </li> <li> <p>Guardar en DIM_JORNADA</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados y transformados en la tabla <code>DIM_JORNADA</code>.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code>.</li> <li>Tama\u00f1o de lote: 0 (por defecto, igual al tama\u00f1o del buffer).</li> <li>Tiempo de espera: 30 segundos.</li> <li>Inserci\u00f3n masiva: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n        participant ExcelSource as Excel Source\n        participant SortJornada as Sort JORNADA\n        participant EliminarVacios as ELIMINAR VACIOS\n        participant AjustarCampo as AJUSTAR CAMPO JORNADA\n        participant CrearIDUnidad as CREAR ID_UNIDAD\n        participant Lookup as Lookup\n        participant Guardar as Guardar en DIM_JORNADA\n\n        ExcelSource -&gt;&gt; SortJornada: Flujo inicial de datos\n        SortJornada -&gt;&gt; EliminarVacios: Datos ordenados y sin duplicados\n        EliminarVacios -&gt;&gt; AjustarCampo: Filtrar registros v\u00e1lidos\n        AjustarCampo -&gt;&gt; CrearIDUnidad: Transformar campo JORNADA\n        CrearIDUnidad -&gt;&gt; Lookup: Agregar ID_UNIDAD\n        Lookup -&gt;&gt; Guardar: Registros sin coincidencias</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-tarea-emp_listado_matriculas","title":"Componente: <code>Tarea emp_Listado_Matriculas</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente Tarea emp_Listado_Matriculas es una tarea de proceso ejecutado en un paquete SSIS. Se utiliza para llamar un script de Python que ejecuta un proceso relacionado con la descarga o manipulaci\u00f3n de datos en un entorno espec\u00edfico definido por los argumentos del script.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#propiedades-del-componente","title":"Propiedades del Componente","text":"<p>Configuraci\u00f3n de Ejecuci\u00f3n     - Tipo de tarea: Proceso externo.     - Descripci\u00f3n: Ejecuta un script de Python llamado <code>download.py</code> con el argumento <code>--key emp_Listado_Matriculas</code>.     - Propiedades principales:     - Ejecutable: Ruta completa del int\u00e9rprete de Python utilizado para la ejecuci\u00f3n.         <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre>     - Argumentos: <pre><code>download.py --key emp_Listado_Matriculas\n</code></pre>     - Directorio de trabajo: Ruta al directorio donde se encuentra el script.         <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></p> <p>Propiedades Adicionales     - Expresiones din\u00e1micas:     - Ejecutable: <pre><code>@[$Project::Python_Executable]\n</code></pre>     - Directorio de trabajo: <pre><code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre>     - Tiempo de espera: No especificado, depende de la configuraci\u00f3n predeterminada del sistema.     - Registro: Configurado para capturar eventos seg\u00fan los filtros definidos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant PythonTask as Tarea emp_Listado_Matriculas\n    participant Script as download.py\n\n    SSIS -&gt;&gt; PythonTask: Llama al ejecutable\n    PythonTask -&gt;&gt; Script: Ejecuta download.py con argumentos (--key emp_Listado_Matriculas)\n    Script -&gt;&gt; PythonTask: Retorna resultado del proceso\n    PythonTask -&gt;&gt; SSIS: Finaliza ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_jornada-emp","title":"Componente <code>DIM_JORNADA emp</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El paquete DIM_JORNADA emp realiza la extracci\u00f3n, transformaci\u00f3n y carga de datos relacionados con las jornadas, utilizando diversas tareas y componentes. Este flujo procesa datos desde una fuente de Excel y realiza validaciones, conversiones y operaciones de b\u00fasqueda antes de cargar los datos en una tabla de destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae datos de una hoja de Excel (<code>Sheet1$</code>).</li> <li>Propiedades:<ul> <li>CommandTimeout: 0 (sin l\u00edmite de tiempo).</li> <li>OpenRowset: <code>Sheet1$</code>.</li> </ul> </li> <li>Columnas de salida:<ul> <li>JORNADA (wstr, longitud 255)</li> <li>Sede - jornada - Programa (wstr, longitud 255)</li> </ul> </li> </ul> </li> <li> <p>Sort</p> <ul> <li>Descripci\u00f3n: Ordena los datos por la columna <code>JORNADA</code>.</li> <li>Propiedades:<ul> <li>EliminateDuplicates: true.</li> <li>MaximumThreads: -1.</li> </ul> </li> <li>Salida Ordenada: Datos ordenados por <code>JORNADA</code>.</li> </ul> </li> <li> <p>Conditional Split</p> <ul> <li>Descripci\u00f3n: Divide los datos en m\u00faltiples salidas seg\u00fan la condici\u00f3n especificada.</li> <li>Condici\u00f3n Principal: Filtra filas donde <code>JORNADA</code> no es nulo y su longitud es mayor a 0.</li> <li>Salida: Filas que cumplen con las condiciones.</li> </ul> </li> <li> <p>Data Conversion (Verificar Tipos de Datos)</p> <ul> <li>Descripci\u00f3n: Convierte el tipo de datos de <code>JORNADA</code> a longitud 40.</li> <li>Columnas de salida: <ul> <li>JORNADA_Convertida (wstr, longitud 40).</li> </ul> </li> </ul> </li> <li> <p>Script Component</p> <ul> <li>Descripci\u00f3n: Personaliza el procesamiento de datos, asignando valores incrementales y campos espec\u00edficos.</li> <li>Operaciones principales:<ul> <li>Asigna valores al campo <code>ID_UNIDAD</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla de <code>DIM_JORNADA</code> para obtener valores relacionados.</li> <li>Propiedades:<ul> <li>SQLCommand:  <pre><code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]\n</code></pre></li> <li>NoMatchBehavior: Env\u00eda filas no coincidentes a la salida predeterminada.</li> </ul> </li> <li>Columnas de b\u00fasqueda:<ul> <li><code>JORNADA</code>, <code>ID_UNIDAD</code>.</li> </ul> </li> </ul> </li> <li> <p>ADO.NET Destination</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0.</li> <li>CommandTimeout: 30.</li> <li>UseBulkInsertWhenPossible: true.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source\n    participant Sort as Sort\n    participant ConditionalSplit as Conditional Split\n    participant DataConversion as Data Conversion\n    participant ScriptComponent as Script Component\n    participant Lookup as Lookup\n    participant ADONETDestination as ADO.NET Destination\n\n    ExcelSource-&gt;&gt;Sort: Extrae datos de la hoja `Sheet1$`\n    Sort-&gt;&gt;ConditionalSplit: Ordena datos por `JORNADA`\n    ConditionalSplit-&gt;&gt;DataConversion: Filtra y verifica filas v\u00e1lidas\n    DataConversion-&gt;&gt;ScriptComponent: Realiza conversiones\n    ScriptComponent-&gt;&gt;Lookup: Busca valores en `DIM_JORNADA`\n    Lookup-&gt;&gt;ADONETDestination: Carga filas no coincidentes en la tabla `Cedesarrollo.DIM_JORNADA`</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_periodo_academico-py","title":"Componente <code>dim_periodo_academico py</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>La tarea dim_periodo_academico py ejecuta un script de Python para procesar la dimensi\u00f3n <code>PERIODO_ACADEMICO</code>. Este script realiza operaciones espec\u00edficas relacionadas con la extracci\u00f3n, transformaci\u00f3n y carga (ETL) para actualizar la tabla de dimensiones en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#detalles-de-la-configuracion","title":"Detalles de la Configuraci\u00f3n","text":"<ol> <li> <p>Ejecutable</p> <ul> <li>Ruta del ejecutable:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Script ejecutado:      <pre><code>dim_periodo_academico.py\n</code></pre></li> </ul> </li> <li> <p>Directorio de trabajo</p> <ul> <li>Ruta:      <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul> </li> <li> <p>Argumentos</p> <ul> <li>Script llamado con el siguiente comando:     <pre><code>dim_periodo_academico.py\n</code></pre></li> </ul> </li> <li> <p>Propiedades Avanzadas</p> <ul> <li>Variables utilizadas:<ul> <li><code>Python_Executable</code>: Variable del proyecto que define la ruta del ejecutable de Python.</li> <li><code>Working_Directory</code>: Variable que especifica el directorio base para los scripts.</li> </ul> </li> <li>Propiedad de <code>Executable</code>:      <pre><code>@[$Project::Python_Executable]\n</code></pre></li> <li>Propiedad de <code>WorkingDirectory</code>:      <pre><code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"\n</code></pre></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSISPackage as Paquete SSIS\n    participant PythonScript as dim_periodo_academico.py\n\n    SSISPackage-&gt;&gt;PythonScript: Llama al ejecutable de Python\n    PythonScript-&gt;&gt;Database: Procesa datos de `PERIODO_ACADEMICO`\n    PythonScript-&gt;&gt;SSISPackage: Retorna el estado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_periodo_academico","title":"Componente <code>DIM_PERIODO_ACADEMICO</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos en SSIS realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) para la dimensi\u00f3n <code>DIM_PERIODO_ACADEMICO</code>. Utiliza datos de una fuente de Excel, realiza conversiones de tipo y valida los registros con una tabla de referencia antes de cargarlos en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae los datos desde una hoja de Excel llamada <code>Sheet1$</code>.</li> <li>Conexi\u00f3n: <code>Administrador de conexiones con Excel 8</code>.</li> <li>Columnas Extra\u00eddas:<ul> <li><code>PERIODO</code> (Texto, longitud 255)</li> <li><code>ID_UNIDAD</code> (Real)</li> <li><code>FECHA_INICIO</code> (Fecha)</li> <li><code>FECHA_FIN</code> (Fecha)</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos de entrada en tipos y formatos espec\u00edficos.</li> <li>Columnas Convertidas:</li> <li><code>_PERIODO</code> (Texto, longitud 40)</li> <li><code>_ID_UNIDAD</code> (Entero)</li> <li><code>_FECHA_INICIO</code> (Fecha)</li> <li><code>_FECHA_FIN</code> (Fecha)</li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Compara los registros con la tabla <code>DIM_PERIODO_ACADEMICO</code> en la base de datos para identificar coincidencias.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_Destino_OLEDB</code>.</li> <li>Consulta de Validaci\u00f3n: <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\nWHERE [PERIODO_ACADEMICO] = ? \n    AND [ID_UNIDAD] = ?\n</code></pre></li> <li>Columnas Validadas: <code>PERIODO_ACADEMICO</code>, <code>ID_UNIDAD</code></li> <li>Salidas:<ul> <li><code>Match Output</code>: Registros coincidentes.</li> <li><code>No Match Output</code>: Registros sin coincidencias, enviados para carga.</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Inserta los registros no coincidentes en la tabla de destino.</li> <li>Tabla de Destino: <code>\"Cedesarrollo\".\"DIM_PERIODO_ACADEMICO\"</code>.</li> <li>Propiedades:</li> <li>Inserci\u00f3n Masiva: Activada.</li> <li>Batch Size: 0 (Utiliza el tama\u00f1o predeterminado del b\u00fafer de SSIS).</li> <li>Timeout de Comando: 30 segundos.</li> <li>Columnas Insertadas: <code>PERIODO_ACADEMICO</code>, <code>ID_UNIDAD</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code></li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Fuente de Excel\n    participant DataConversion as Conversi\u00f3n de Datos\n    participant Lookup as Validaci\u00f3n de Datos\n    participant Destino as Base de Datos\n\n    Excel-&gt;&gt;DataConversion: Extraer datos\n    DataConversion-&gt;&gt;Lookup: Validar con tabla de referencia\n    Lookup-&gt;&gt;Destino: Insertar registros no coincidentes</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_estudiantespy","title":"Componente <code>dim_Estudiantes.py</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>La tarea <code>dim_Estudiantes.py</code> se ejecuta como parte del paquete SSIS para procesar y cargar datos relacionados con los estudiantes en el sistema. Utiliza un script de Python para realizar operaciones espec\u00edficas de extracci\u00f3n, transformaci\u00f3n y carga (ETL) sobre la dimensi\u00f3n <code>DIM_ESTUDIANTES</code>.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#detalles-del-proceso","title":"Detalles del Proceso","text":"<ul> <li>Script Ejecutado: <code>dim_Estudiantes.py</code></li> <li>Ubicaci\u00f3n del Script: <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> <li>Ejecutable de Python: <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos: <code>dim_Estudiantes.py</code></li> <li>Directorio de Trabajo: <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul> <p>Propiedades Configuradas</p> <ul> <li> <p><code>Executable</code>:   Configurado din\u00e1micamente como una expresi\u00f3n: <code>@[$Project::Python_Executable]</code>.</p> </li> <li> <p><code>WorkingDirectory</code>:   Configurado din\u00e1micamente como una expresi\u00f3n: <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code></p> </li> </ul> <p>Consideraciones Adicionales</p> <ol> <li> <p>Configuraci\u00f3n de Variables del Proyecto:</p> <ul> <li><code>Python_Executable</code>: Aseg\u00farese de que esta variable apunte al ejecutable de Python correcto en el entorno configurado.</li> <li><code>Working_Directory</code>: Verifique que el directorio definido sea accesible y tenga los permisos necesarios.</li> </ul> </li> <li> <p>Errores Comunes:</p> <ul> <li>Ruta Incorrecta: Confirme que el script <code>dim_Estudiantes.py</code> existe en la ruta especificada.</li> <li>Dependencias de Python: Revise que el entorno virtual contenga todas las dependencias necesarias para ejecutar el script.</li> </ul> </li> <li> <p>Registros de Ejecuci\u00f3n:</p> <ul> <li>Habilite el registro detallado para rastrear errores o problemas durante la ejecuci\u00f3n.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as dim_Estudiantes.py\n    participant BaseDatos as Base de Datos\n\n    SSIS-&gt;&gt;Python: Ejecutar script `dim_Estudiantes.py`\n    Python-&gt;&gt;BaseDatos: Conectar y procesar datos\n    Python-&gt;&gt;SSIS: Confirmar finalizaci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-dim_estudiantes","title":"Componente <code>DIM_ESTUDIANTES</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>El componente <code>DIM_ESTUDIANTES</code> es una tarea de flujo de datos en SSIS dise\u00f1ada para procesar, transformar y cargar informaci\u00f3n sobre estudiantes en una tabla de destino denominada <code>DIM_ESTUDIANTES</code>. Incluye fuentes de datos Excel, conversiones de datos, transformaciones derivadas y m\u00faltiples b\u00fasquedas para enriquecer la informaci\u00f3n de los estudiantes con datos relacionados.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<p>1. Fuente de Datos: Excel Source </p> <ul> <li>Descripci\u00f3n: Obtiene datos desde una hoja de Excel, <code>Sheet1$</code>, utilizando un administrador de conexi\u00f3n OLE DB.</li> <li>Propiedades:</li> <li>Timeout: 0 segundos (sin l\u00edmite de espera).</li> <li>Modo de Acceso: Directo a una tabla o vista.</li> </ul> <p>2. Transformaci\u00f3n: Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte columnas clave (<code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO_ESTUDIANTE</code>) en tipos de datos y longitudes compatibles con el destino.</li> <li>Propiedades de Salida:</li> <li><code>_TIPO_DOCUMENTO</code> \u2192 Tipo <code>wstr</code>, longitud 40.</li> <li><code>_DOCUMENTO</code> \u2192 Tipo <code>wstr</code>, longitud 20.</li> </ul> <p>3. Transformaci\u00f3n: Derived Column</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas basadas en expresiones derivadas, como valores predeterminados si las columnas originales son nulas o est\u00e1n vac\u00edas.</li> <li>Propiedades:</li> <li><code>_DOCUMENTO</code> \u2192 <code>ISNULL(_DOCUMENTO) || TRIM(_DOCUMENTO) == \"\" ? \"-1\" : _DOCUMENTO</code>.</li> </ul> <p>4. Transformaci\u00f3n: Lookup</p> <ul> <li>Descripci\u00f3n: Realiza b\u00fasquedas en tablas relacionadas para enriquecer datos:<ul> <li><code>Lookup Documento</code>: Valida documentos en <code>DIM_ESTUDIANTES</code>.</li> <li><code>Lookup 1 1</code>: Consulta <code>DIM_EMPRESAS</code> para obtener <code>ID_EMPRESA</code>.</li> <li><code>Lookup 1 1 1</code>: Consulta <code>DIM_AFILIADOS</code> para obtener <code>ID_AFILIADO</code>.</li> <li><code>Lookup 1 1 1 1</code>: Consulta <code>DIM_BENEFICIARIOS</code> para obtener <code>ID_BENEFICIARIO</code>.</li> <li><code>Lookup 1 1 1 1 1</code>: Consulta <code>DIM_APORTANTE_NOAFILIADO</code> para obtener <code>ID_APORTANTE</code>.</li> </ul> </li> </ul> <p>5. Transformaci\u00f3n: Aggregate</p> <ul> <li>Descripci\u00f3n: Agrupa y realiza operaciones como conteo o consolidaci\u00f3n de documentos y tipos de documentos.</li> </ul> <p>6. Destino: Flat File Destination</p> <ul> <li>Descripci\u00f3n: Registra errores de procesamiento en un archivo plano.</li> <li>Propiedades:<ul> <li>Sobrescribir archivo: Activado.</li> <li>Conexi\u00f3n: <code>Flat File Connection Manager</code>.</li> </ul> </li> </ul> <p>7. Destino: ADO.NET Destination</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>DIM_ESTUDIANTES</code>.</li> <li>Propiedades:<ul> <li>Tabla o Vista Destino: <code>\"Cedesarrollo\".\"DIM_ESTUDIANTES\"</code>.</li> <li>Inserci\u00f3n Masiva: Activado.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant ExcelSource as Excel Source\n    participant DataConversion as Data Conversion\n    participant DerivedColumn as Derived Column\n    participant LookupDoc as Lookup Documento\n    participant LookupEmpresa as Lookup 1 1 (DIM_EMPRESAS)\n    participant LookupAfiliado as Lookup 1 1 1 (DIM_AFILIADOS)\n    participant LookupBeneficiario as Lookup 1 1 1 1 (DIM_BENEFICIARIOS)\n    participant LookupAportante as Lookup 1 1 1 1 1 (DIM_APORTANTE_NOAFILIADO)\n    participant Aggregate as Aggregate\n    participant AdoNetDest as ADO.NET Destination\n    participant FlatFileDest as Flat File Destination\n\n    ExcelSource -&gt;&gt; DataConversion: Datos de Excel\n    DataConversion -&gt;&gt; DerivedColumn: Transformaci\u00f3n derivada\n    DerivedColumn -&gt;&gt; LookupDoc: Validaci\u00f3n en DIM_ESTUDIANTES\n    LookupDoc -&gt;&gt; Aggregate: Enriquecimiento y agregaci\u00f3n\n    Aggregate -&gt;&gt; LookupEmpresa: Validaci\u00f3n en DIM_EMPRESAS\n    LookupEmpresa -&gt;&gt; LookupAfiliado: Validaci\u00f3n en DIM_AFILIADOS\n    LookupAfiliado -&gt;&gt; LookupBeneficiario: Validaci\u00f3n en DIM_BENEFICIARIOS\n    LookupBeneficiario -&gt;&gt; LookupAportante: Validaci\u00f3n en DIM_APORTANTE_NOAFILIADO\n    LookupAportante -&gt;&gt; AdoNetDest: Carga a tabla final\n    AdoNetDest -&gt;&gt; FlatFileDest: Registro de errores</code></pre> <p>Notas</p> <ul> <li>Errores: Todos los errores de las transformaciones son redirigidos al componente <code>Flat File Destination</code>.</li> <li>Rendimiento: Se utilizan conexiones OLE DB y ADO.NET para garantizar integridad y rapidez en la carga de datos.</li> <li>Personalizaci\u00f3n: Puede expandirse con transformaciones adicionales seg\u00fan sea necesario.</li> </ul>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-tarea-cede_diseno_curricular","title":"Componente <code>Tarea cede_Dise\u00f1o_Curricular</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Tarea cede_Dise\u00f1o_Curricular</code> es un componente de ejecuci\u00f3n de procesos en SSIS que utiliza un script Python para procesar o descargar datos relacionados con el dise\u00f1o curricular de una instituci\u00f3n educativa. Este script es ejecutado en un entorno Python configurado previamente.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#detalles-del-componente","title":"Detalles del Componente","text":"<ul> <li>Tipo de Tarea: <code>Execute Process Task</code>.</li> <li>Descripci\u00f3n: Ejecuta un script Python (<code>download.py</code>) con un argumento espec\u00edfico (<code>--key cede_Dise\u00f1o_Curricular</code>) para realizar tareas como descargar o transformar datos asociados al dise\u00f1o curricular.</li> <li>Propiedades Clave:<ul> <li>Ejecutable: Ruta al ejecutable de Python configurado en la variable <code>Python_Executable</code> del proyecto.</li> <li>Directorio de Trabajo: Ruta configurada en la variable <code>Working_Directory</code> del proyecto.</li> <li>Argumentos: <code>download.py --key cede_Dise\u00f1o_Curricular</code>.</li> </ul> </li> </ul> <p>Propiedades T\u00e9cnicas</p> Propiedad Valor Executable <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code> Working Directory <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code> Arguments <code>download.py --key cede_Dise\u00f1o_Curricular</code> Tiempo de Ejecuci\u00f3n No especificado (timeout predeterminado del sistema). <p>Flujo de Trabajo</p> <ol> <li> <p>Inicio del Proceso: </p> <ul> <li>La tarea se inicia autom\u00e1ticamente al ejecutarse el paquete SSIS.</li> </ul> </li> <li> <p>Definici\u00f3n del Contexto:</p> <ul> <li>El entorno de ejecuci\u00f3n y los argumentos se configuran din\u00e1micamente utilizando expresiones vinculadas a las variables del proyecto:</li> <li><code>@[$Project::Python_Executable]</code> para el ejecutable.</li> <li><code>@[$Project::Working_Directory]</code> para el directorio de trabajo.</li> </ul> </li> <li> <p>Ejecuci\u00f3n del Script:</p> <ul> <li>El script Python (<code>download.py</code>) se ejecuta con el argumento <code>--key cede_Dise\u00f1o_Curricular</code>.</li> <li>El script puede realizar operaciones como descarga de datos, validaci\u00f3n, transformaci\u00f3n, etc.</li> </ul> </li> <li> <p>Finalizaci\u00f3n:</p> <ul> <li>El proceso concluye una vez que el script finaliza su ejecuci\u00f3n. Los resultados del script pueden ser monitoreados mediante los logs configurados en el paquete.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea SSIS\n    participant Python as Script Python\n    participant Sistema as Sistema Operativo\n\n    SSIS -&gt;&gt; Python: Ejecutar `download.py --key cede_Dise\u00f1o_Curricular`\n    Python -&gt;&gt; Sistema: Leer datos del directorio configurado\n    Sistema -&gt;&gt; Python: Proveer acceso a los archivos\n    Python -&gt;&gt; Python: Procesar o transformar datos\n    Python -&gt;&gt; SSIS: Retornar estado de finalizaci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_programa","title":"Componente <code>Data DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente <code>Data DIM_PROGRAMA</code> implementa un flujo de datos para extraer informaci\u00f3n de un archivo Excel, procesarla mediante operaciones de clasificaci\u00f3n, agregaci\u00f3n y b\u00fasquedas, y finalmente cargar los datos en la tabla <code>DIM_PROGRAMA</code> de la base de datos. Este proceso se utiliza para estructurar y consolidar datos relacionados con programas acad\u00e9micos.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos: <code>Excel Source</code></p> <ul> <li>Prop\u00f3sito: Leer datos desde un archivo Excel ubicado en la ruta configurada en el administrador de conexiones <code>OleDbConnection</code>.</li> <li>Columnas Procesadas:<ul> <li><code>PROGRAMA</code></li> <li><code>COD_MODULO</code></li> <li><code>MODULO</code></li> <li><code>SEMESTRE</code>, entre otras.</li> </ul> </li> <li>Propiedades Principales:<ul> <li>Tabla de Origen: <code>Sheet1$</code></li> <li>Acceso: Modo directo (<code>AccessMode = 0</code>).</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Sort PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Ordenar los datos por la columna <code>PROGRAMA</code> y eliminar duplicados.</li> <li>Propiedades Principales:<ul> <li>Columna de Ordenaci\u00f3n: <code>PROGRAMA</code>.</li> <li>Eliminaci\u00f3n de Duplicados: Activada.</li> </ul> </li> <li>Salida:<ul> <li>Datos ordenados para el componente de b\u00fasqueda.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Lookup PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Realizar una b\u00fasqueda en la tabla <code>DIM_PROGRAMA</code> para identificar programas existentes.</li> <li>Propiedades Principales:<ul> <li>SQL: <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA] WHERE [PROGRAMA] = ?\n</code></pre></li> <li>Comportamiento de No Coincidencia: Las filas sin coincidencias se env\u00edan al componente de agregaci\u00f3n.</li> </ul> </li> <li>Salida:<ul> <li>Coincidencias: Filas que ya existen en la tabla <code>DIM_PROGRAMA</code>.</li> <li>No Coincidencias: Filas nuevas que requieren agregaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Aggregate 1</code></p> <ul> <li>Prop\u00f3sito: Consolidar datos agrupados por la columna <code>PROGRAMA</code>.</li> <li>Propiedades Principales:<ul> <li>Columna de Agrupaci\u00f3n: <code>PROGRAMA</code>.</li> <li>Escala de Claves: Baja (500,000 valores aproximados).</li> </ul> </li> <li>Salida:<ul> <li>Datos agrupados enviados al destino.</li> </ul> </li> </ul> </li> <li> <p>Destino: <code>Guardar DIM_PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Cargar los datos procesados en la tabla <code>DIM_PROGRAMA</code> de la base de datos.</li> <li>Propiedades Principales:<ul> <li>Tabla de Destino: <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code>.</li> <li>Inserci\u00f3n Masiva: Activada.</li> </ul> </li> <li>Columnas Procesadas:<ul> <li><code>PROGRAMA</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Excel Source\n    participant Sort as Sort PROGRAMA\n    participant Lookup as Lookup PROGRAMA\n    participant Aggregate as Aggregate 1\n    participant Destino as Guardar DIM_PROGRAMA\n\n    Excel -&gt;&gt; Sort: Leer datos\n    Sort -&gt;&gt; Lookup: Ordenar datos\n    Lookup -&gt;&gt; Aggregate: Enviar no coincidencias\n    Aggregate -&gt;&gt; Destino: Enviar datos agregados\n    Destino -&gt;&gt; Destino: Cargar en `DIM_PROGRAMA`</code></pre>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componente-data-dim_plan_curricular","title":"Componente <code>Data DIM_PLAN_CURRICULAR</code>","text":""},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>El componente <code>Data DIM_PLAN_CURRICULAR</code> es un flujo de datos que extrae informaci\u00f3n desde una fuente Excel, realiza transformaciones derivadas y operaciones de b\u00fasqueda, y finalmente inserta los datos procesados en la tabla <code>DIM_PLAN_CURRICULAR</code> de la base de datos. Este flujo asegura la consolidaci\u00f3n y estructuraci\u00f3n de la informaci\u00f3n del plan curricular.</p>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos: <code>PLAN_CURRICULAR</code></p> <ul> <li>Prop\u00f3sito: Leer datos desde un archivo Excel utilizando el administrador de conexiones <code>OleDbConnection</code>.</li> <li>Columnas Procesadas:<ul> <li><code>PROGRAMA</code>, <code>COD_MODULO</code>, <code>MODULO</code>, <code>SEMESTRE</code>, <code>INTENSIDAD_HORARIA</code>, entre otras.</li> </ul> </li> <li>Propiedades Principales:<ul> <li>Tabla de Origen: <code>Sheet1$</code></li> <li>Modo de Acceso: Directo (<code>AccessMode = 0</code>).</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Tranformar Columnas</code></p> <ul> <li>Prop\u00f3sito: Crear nuevas columnas derivadas a partir de columnas existentes.</li> <li>Columnas Derivadas:<ul> <li><code>_SEMESTRE</code>: Convertido de <code>SEMESTRE</code> a formato <code>DT_WSTR, 40</code>.</li> <li><code>_MODULO</code>: Convertido de <code>MODULO</code> a formato <code>DT_WSTR, 200</code>.</li> <li><code>_INTENSIDAD_HORARIA</code>, <code>_INTENSIDAD_HORARIA_SEMANAL</code>, <code>_NO_CREDITOS</code>: Convertidas a formato <code>DT_WSTR, 40</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Lookup ID_PROGRAMA</code></p> <ul> <li>Prop\u00f3sito: Verificar y asociar la clave primaria <code>ID_PROGRAMA</code> de la tabla <code>DIM_PROGRAMA</code> con las filas procesadas.</li> <li>Propiedades Principales:<ul> <li>SQL: <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA] WHERE [PROGRAMA] = ?\n</code></pre></li> <li>Comportamiento de No Coincidencia: Ignorar fallas (<code>IgnoreFailure</code>).</li> </ul> </li> <li>Salida:<ul> <li>Coincidencias: Filas existentes en <code>DIM_PROGRAMA</code>.</li> <li>No Coincidencias: Se procesan en el siguiente paso.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: <code>Lookup DIM_PLAN_CURRICULAR</code></p> <ul> <li>Prop\u00f3sito: Identificar filas ya existentes en la tabla <code>DIM_PLAN_CURRICULAR</code>.</li> <li>Propiedades Principales:<ul> <li>SQL: <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PLAN_CURRICULAR] WHERE [MODULO] = ?\n</code></pre></li> <li>Comportamiento de No Coincidencia: Filas nuevas se env\u00edan al destino.</li> </ul> </li> </ul> </li> <li> <p>Destino: <code>Guardar DIM_PLAN_CURRICULAR</code></p> <ul> <li>Prop\u00f3sito: Insertar los datos procesados en la tabla <code>DIM_PLAN_CURRICULAR</code> de la base de datos.</li> <li>Propiedades Principales:<ul> <li>Tabla de Destino: <code>\"Cedesarrollo\".\"DIM_PLAN_CURRICULAR\"</code>.</li> <li>Inserci\u00f3n Masiva: Activada (<code>UseBulkInsertWhenPossible = true</code>).</li> </ul> </li> <li>Columnas Procesadas: <code>_MODULO</code>, <code>_INTENSIDAD_HORARIA</code>, <code>_INTENSIDAD_HORARIA_SEMANAL</code>, <code>_NO_CREDITOS</code>, <code>_SEMESTRE</code>, <code>ID_PROGRAMA</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/05-CEDESARROLLO_DIMENSIONES/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as PLAN_CURRICULAR\n    participant Transform as Tranformar Columnas\n    participant LookupID as Lookup ID_PROGRAMA\n    participant LookupPlan as Lookup DIM_PLAN_CURRICULAR\n    participant Destino as Guardar DIM_PLAN_CURRICULAR\n\n    Excel -&gt;&gt; Transform: Leer datos\n    Transform -&gt;&gt; LookupID: Generar columnas derivadas\n    LookupID -&gt;&gt; LookupPlan: Enviar registros coincidentes\n    LookupPlan -&gt;&gt; Destino: Enviar filas nuevas\n    Destino -&gt;&gt; Destino: Insertar en DIM_PLAN_CURRICULAR</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/","title":"06. CEDESARROLLO_FACT","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#cedesarrollo_fact","title":"CEDESARROLLO_FACT","text":"<p>El paquete SSIS \"06-CEDESARROLLO_FACT\" es un sistema robusto dise\u00f1ado para realizar procesos ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) relacionados con datos operativos educativos y administrativos. Este paquete se enfoca en integrar informaci\u00f3n sobre matr\u00edculas, jornadas, programas, per\u00edodos acad\u00e9micos y evaluaciones, consolidando datos desde m\u00faltiples fuentes en el Data Warehouse <code>DWH_COMFENALCO</code>. El objetivo principal es asegurar la disponibilidad de datos precisos y consistentes para an\u00e1lisis estrat\u00e9gico y generaci\u00f3n de reportes.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El paquete tiene como prop\u00f3sito principal gestionar y transformar datos cr\u00edticos de varias fuentes. A trav\u00e9s de un flujo de trabajo modular y escalable, asegura la integraci\u00f3n de los datos, prepar\u00e1ndolos para an\u00e1lisis detallados y toma de decisiones estrat\u00e9gicas.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Bases de Datos:</li> <li><code>DIM_ESTUDIANTES</code>: Informaci\u00f3n b\u00e1sica de estudiantes.</li> <li><code>DIM_JORNADA</code>: Detalles de las jornadas acad\u00e9micas.</li> <li><code>DIM_PROGRAMA</code>: Datos de programas educativos.</li> <li><code>FACT_NOTAS</code>: Registros de notas finales de los estudiantes.</li> <li>Archivos Excel y CSV:</li> <li>Planes curriculares.</li> <li>Programas educativos y datos de matr\u00edculas.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexi\u00f3n ADO.NET para acceso eficiente a bases de datos.</li> <li>Conexi\u00f3n OLE DB para lectura de archivos Excel y CSV.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>C\u00e1lculo de campos adicionales como <code>ID_PROGRAMA</code> y <code>NOTA_PROMEDIO</code>.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Comparaci\u00f3n de datos con tablas maestras como <code>DIM_PERIODO_ACADEMICO</code> y <code>DIM_JORNADA</code> para garantizar consistencia.</li> </ul> </li> <li>Clasificaci\u00f3n (<code>Conditional Split</code>):<ul> <li>Filtrado de datos bas\u00e1ndose en condiciones como registros v\u00e1lidos e inv\u00e1lidos.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad entre columnas de entrada y destino.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas utilizadas:<ul> <li><code>DIM_PERIODO_ACADEMICO</code>: Detalles de los per\u00edodos acad\u00e9micos.</li> <li><code>DIM_JORNADA</code>: Informaci\u00f3n sobre jornadas.</li> <li><code>DIM_PROGRAMA</code>: Datos de programas educativos.</li> <li><code>FACT_NOTAS</code>: Registros consolidados de evaluaciones.</li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones Masivas (<code>Bulk Insert</code>): Activada para maximizar el rendimiento en la carga de datos.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Scripts Python:<ul> <li>Automatizan tareas como descargas desde rutas predefinidas y validaci\u00f3n de datos en tiempo real.</li> </ul> </li> <li>Integraci\u00f3n:<ul> <li>Uso de variables din\u00e1micas para ajustar rutas de trabajo y par\u00e1metros espec\u00edficos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_ESTUDIANTES:</p> <ul> <li><code>ID_ESTUDIANTE</code>: Identificador \u00fanico.</li> <li><code>NOMBRE</code>: Nombre del estudiante.</li> <li><code>DOCUMENTO</code>: Documento de identidad.</li> </ul> </li> <li> <p>DIM_JORNADA:</p> <ul> <li><code>ID_JORNADA</code>: Identificador de la jornada.</li> <li><code>JORNADA</code>: Descripci\u00f3n de la jornada.</li> </ul> </li> <li> <p>DIM_PROGRAMA:</p> <ul> <li><code>ID_PROGRAMA</code>: Identificador \u00fanico.</li> <li><code>NOMBRE_PROGRAMA</code>: Nombre del programa acad\u00e9mico.</li> </ul> </li> <li> <p>FACT_NOTAS:</p> <ul> <li><code>ID_NOTA</code>: Identificador \u00fanico de la nota.</li> <li><code>ID_ESTUDIANTE</code>: Relaci\u00f3n con el estudiante.</li> <li><code>ID_JORNADA</code>: Relaci\u00f3n con la jornada.</li> <li><code>NOTA_FINAL</code>: Evaluaci\u00f3n final.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos (Data Flow Diagram - DFD)</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extrae datos de DIM_ESTUDIANTES, DIM_JORNADA y FACT_NOTAS\n    SSIS -&gt;&gt; Python: Ejecuta scripts para validaci\u00f3n y descargas\n    SSIS -&gt;&gt; DWH: Carga datos procesados en tablas destino</code></pre> <ol> <li>Diagrama de Transformaciones y Validaciones</li> </ol> <pre><code>graph TD\n    %% Entradas\n    A1[DIM_ESTUDIANTES] --&gt; T1[Derived Column: Transformaci\u00f3n de campos]\n    A2[DIM_JORNADA] --&gt; T2[Lookup: Validaci\u00f3n de jornadas]\n    A3[FACT_NOTAS] --&gt; T3[Conditional Split: Filtrado de registros]\n\n    %% Transformaciones\n    T1 --&gt; L1[Lookup ID_ESTUDIANTE]\n    T2 --&gt; L2[Lookup ID_JORNADA]\n    T3 --&gt; C1[Guardar datos transformados]</code></pre> <ol> <li>Diagrama ER para Tablas de Dimensiones</li> </ol> <pre><code>erDiagram\n    DIM_ESTUDIANTES {\n        int ID_ESTUDIANTE\n        string NOMBRE\n        string DOCUMENTO\n    }\n    DIM_JORNADA {\n        int ID_JORNADA\n        string JORNADA\n    }\n    DIM_PROGRAMA {\n        int ID_PROGRAMA\n        string NOMBRE_PROGRAMA\n    }\n    FACT_NOTAS {\n        int ID_NOTA\n        int ID_ESTUDIANTE\n        int ID_JORNADA\n        float NOTA_FINAL\n    }\n    DIM_ESTUDIANTES ||--|| DIM_JORNADA : \"Relaci\u00f3n Estudiante-Jornada\"\n    DIM_JORNADA ||--|| FACT_NOTAS : \"Jornada-Notas\"\n    DIM_PROGRAMA ||--|| FACT_NOTAS : \"Programa-Notas\"</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_inscripcion_matriculas","title":"FACT_INSCRIPCION_MATRICULAS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-emp_preinscritos","title":"Componente <code>Tarea emp_Preinscritos</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tarea emp_Preinscritos ejecuta un proceso externo para obtener y consolidar datos de preinscripci\u00f3n de matr\u00edculas desde un sistema o archivo fuente. Este componente es parte del paquete SSIS FACT_INSCRIPCION_MATRICULAS y utiliza un script de Python con par\u00e1metros espec\u00edficos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-la-tarea","title":"Propiedades de la Tarea","text":"<ul> <li> <p>Nombre del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></p> </li> <li> <p>Argumentos: <code>download.py --key emp_Preinscritos</code></p> </li> <li> <p>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></p> </li> <li> <p>Descripci\u00f3n:   Ejecuta un proceso externo para consolidar datos de preinscritos en el sistema de matr\u00edculas.</p> </li> <li> <p>Configuraciones espec\u00edficas:</p> <ul> <li>Filtro de registro: <code>FilterKind=0</code></li> <li>Expresi\u00f3n de propiedades:<ul> <li>Executable: <code>@[$Project::Python_Executable]</code></li> <li>WorkingDirectory: <code>@[$Project::Working_Directory] + \"\\\\COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\"</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key emp_Preinscritos`\n    Python -&gt;&gt; Python: Descarga datos de preinscritos consolidados\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_estudiante-1-1","title":"Componente <code>Data DIM_ESTUDIANTE 1 1</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_ESTUDIANTE 1 1 realiza operaciones de extracci\u00f3n, transformaci\u00f3n y carga (ETL) relacionadas con los datos de estudiantes. Este flujo procesa informaci\u00f3n desde una fuente de Excel, realiza transformaciones de columnas, verifica registros duplicados y vac\u00edos, y finalmente carga los datos en una tabla de destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Descripci\u00f3n: Este componente extrae datos desde una hoja de Excel.</li> <li>Propiedades:</li> <li>Hoja: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <ul> <li>TIPO_DOCUMENTO</li> <li>REFERENCIA</li> <li>INSCRITO</li> <li>FECHA</li> <li>DOCUMENTO_ESTUDIANTE</li> <li>PROGRAMA</li> <li>NOMBRE</li> <li>SEDE</li> <li>JORNADA</li> </ul> </li> </ul> </li> <li> <p>Sort DOCUMENTO</p> <ul> <li>Descripci\u00f3n: Ordena los datos en funci\u00f3n de las columnas DOCUMENTO_ESTUDIANTE y TIPO_DOCUMENTO.</li> <li>Propiedades:</li> <li>Elimina duplicados: <code>true</code></li> <li>Columnas utilizadas para ordenar:<ul> <li>DOCUMENTO_ESTUDIANTE: Ascendente.</li> <li>TIPO_DOCUMENTO: Ning\u00fan orden.</li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas</p> <ul> <li>Descripci\u00f3n: Transforma las columnas existentes y genera nuevas:</li> <li>_DOCUMENTO: Transformaci\u00f3n de DOCUMENTO_ESTUDIANTE.</li> <li>_TIPO_DOCUMENTO: Transformaci\u00f3n de TIPO_DOCUMENTO.</li> </ul> </li> <li> <p>Filtrar registros vac\u00edos</p> <ul> <li>Descripci\u00f3n: Filtra los registros donde _DOCUMENTO no sea nulo ni vac\u00edo.</li> <li>Expresi\u00f3n de filtro: <code>!ISNULL(_DOCUMENTO) &amp;&amp; LEN(TRIM(_DOCUMENTO)) &gt; 0</code></li> </ul> </li> <li> <p>Lookup Documento</p> <ul> <li>Descripci\u00f3n: Realiza un cruce de informaci\u00f3n con la tabla DIM_ESTUDIANTES para enriquecer los datos.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code></li> <li>Comportamiento ante no coincidencias: Genera un flujo para registros sin coincidencia.</li> </ul> </li> </ul> </li> <li> <p>Aggregate</p> <ul> <li>Descripci\u00f3n: Realiza operaciones de agregaci\u00f3n sobre las columnas:<ul> <li>_DOCUMENTO</li> <li>_TIPO_DOCUMENTO</li> </ul> </li> <li>Propiedades:<ul> <li>Factor de extensi\u00f3n de memoria: <code>25%</code></li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_ESTUDIANTES</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino DIM_ESTUDIANTES.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_ESTUDIANTES\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Table\n\n    SSIS -&gt;&gt; Excel: Extraer datos\n    Excel -&gt;&gt; SSIS: Datos procesados\n    SSIS -&gt;&gt; SQL: Lookup con DIM_ESTUDIANTES\n    SQL -&gt;&gt; SSIS: Resultados del cruce\n    SSIS -&gt;&gt; SQL: Carga de datos en DIM_ESTUDIANTES</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_programa-1","title":"Componente <code>Data DIM_PROGRAMA 1</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data DIM_PROGRAMA 1 se encarga de procesar informaci\u00f3n de programas acad\u00e9micos, realizando operaciones de extracci\u00f3n desde una fuente de Excel, transformaci\u00f3n de datos y carga en una tabla de destino. Incluye tareas de ordenamiento, b\u00fasqueda y agregaci\u00f3n de registros.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde una hoja de Excel.</li> <li>Propiedades:<ul> <li>Hoja: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>TIPO_DOCUMENTO, REFERENCIA, INSCRITO, FECHA, DOCUMENTO_ESTUDIANTE, PROGRAMA, NOMBRE, SEDE, JORNADA</code></li> </ul> </li> </ul> </li> <li> <p>Sort PROGRAMA</p> <ul> <li>Descripci\u00f3n: Ordena los datos en funci\u00f3n de la columna PROGRAMA.</li> <li>Propiedades:<ul> <li>Elimina duplicados: <code>true</code></li> <li>Orden por columna: PROGRAMA en orden ascendente.</li> </ul> </li> </ul> </li> <li> <p>Lookup PROGRAMA</p> <ul> <li>Descripci\u00f3n: Realiza un cruce de informaci\u00f3n con la tabla DIM_PROGRAMA para enriquecer los datos.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA]</code></li> <li>Comportamiento ante no coincidencias: Envia registros sin coincidencia a un flujo separado.</li> </ul> </li> </ul> </li> <li> <p>Aggregate 1</p> <ul> <li>Descripci\u00f3n: Realiza operaciones de agregaci\u00f3n sobre la columna PROGRAMA.</li> <li>Propiedades:<ul> <li>Factor de extensi\u00f3n de memoria: <code>25%</code></li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_PROGRAMA</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino DIM_PROGRAMA.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_PROGRAMA\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Table\n\n    SSIS -&gt;&gt; Excel: Extraer datos\n    Excel -&gt;&gt; SSIS: Datos procesados\n    SSIS -&gt;&gt; SQL: Lookup con DIM_PROGRAMA\n    SQL -&gt;&gt; SSIS: Resultados del cruce\n    SSIS -&gt;&gt; SQL: Carga de datos en DIM_PROGRAMA</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-fact_inscripcion_matriculas","title":"Componente <code>Data FACT_INSCRIPCION_MATRICULAS</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Data FACT_INSCRIPCION_MATRICULAS maneja la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con la inscripci\u00f3n de matr\u00edculas. Incluye tareas de b\u00fasqueda, transformaci\u00f3n y derivaci\u00f3n de columnas, con la carga final en una tabla de hechos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>TIPO_DOCUMENTO,REFERENCIA,INSCRITO,FECHA,DOCUMENTO_ESTUDIANTE,PROGRAMA,NOMBRE,SEDE,JORNADA</code></li> </ul> </li> </ul> </li> <li> <p>Lookup ID_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Busca y asocia el identificador del estudiante desde la tabla DIM_ESTUDIANTES.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code></li> <li>Columna de uni\u00f3n: DOCUMENTO</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PROGRAMA</p> <ul> <li>Descripci\u00f3n: Busca y asocia el identificador del programa desde la tabla DIM_PROGRAMA.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PROGRAMA]</code></li> <li>Columna de uni\u00f3n: PROGRAMA</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_JORNADA</p> <ul> <li>Descripci\u00f3n: Busca y asocia el identificador de la jornada desde la tabla DIM_JORNADA.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]</code></li> <li>Columna de uni\u00f3n: JORNADA</li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas</p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas con transformaciones personalizadas.</li> <li>Columnas derivadas:<ul> <li><code>_INSCRITO</code>: <code>(DT_WSTR,40)INSCRITO</code></li> <li><code>_FECHA</code>: <code>(DT_DATE)FECHA</code></li> <li><code>_ID_PERIODO</code>: <code>-1</code></li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_INSCRIPCION_MATRICULAS</p> <ul> <li>Descripci\u00f3n: Busca coincidencias en la tabla FACT_INSCRIPCION_MATRICULAS.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]</code></li> <li>Columnas de uni\u00f3n: ID_ESTUDIANTE, ID_PROGRAMA, ID_JORNADA</li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_INSCRIPCION_MATRICULAS</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla de destino.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_INSCRIPCION_MATRICULAS\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Table\n\n    SSIS -&gt;&gt; Excel: Extraer datos\n    Excel -&gt;&gt; SSIS: Datos procesados\n    SSIS -&gt;&gt; SQL: Lookup con DIM_ESTUDIANTES\n    SQL -&gt;&gt; SSIS: Resultado Lookup ID_ESTUDIANTE\n    SSIS -&gt;&gt; SQL: Lookup con DIM_PROGRAMA\n    SQL -&gt;&gt; SSIS: Resultado Lookup ID_PROGRAMA\n    SSIS -&gt;&gt; SQL: Lookup con DIM_JORNADA\n    SQL -&gt;&gt; SSIS: Resultado Lookup ID_JORNADA\n    SSIS -&gt;&gt; SQL: Carga datos en FACT_INSCRIPCION_MATRICULAS</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_notas","title":"FACT_NOTAS","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-cede_historico_notas","title":"Componente <code>Tarea cede_Historico_Notas</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>La tarea cede_Historico_Notas ejecuta un proceso externo para descargar datos hist\u00f3ricos de notas utilizando un script de Python.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-proceso","title":"Componentes del Proceso","text":"<ol> <li>Tarea cede_Historico_Notas<ul> <li>Descripci\u00f3n: Ejecuta un script de Python para descargar datos hist\u00f3ricos de notas.</li> <li>Propiedades:<ul> <li>Ruta del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos: <code>download.py --key cede_Historico_Notas</code></li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key cede_Historico_Notas`\n    Python -&gt;&gt; Python: Descarga datos de notas hist\u00f3ricas\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-dim_estudiantes-py","title":"Componente <code>dim_Estudiantes py</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>La tarea dim_Estudiantes py ejecuta un proceso externo para procesar la dimensi\u00f3n de estudiantes utilizando un script de Python.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-proceso_1","title":"Componentes del Proceso","text":"<ol> <li>dim_Estudiantes py<ul> <li>Descripci\u00f3n: Ejecuta un script de Python para procesar la tabla de dimensi\u00f3n de estudiantes.</li> <li>Propiedades:<ul> <li><code>Ruta del ejecutable</code>: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li><code>Argumentos</code>: <code>dim_Estudiantes.py</code></li> <li><code>Directorio de trabajo</code>: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `dim_Estudiantes.py`\n    Python -&gt;&gt; Python: Procesa la dimensi\u00f3n de estudiantes\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_jornada","title":"Componente <code>Data DIM_JORNADA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_JORNADA realiza el flujo de datos necesario para procesar y cargar la tabla de dimensi\u00f3n DIM_JORNADA. Incluye la extracci\u00f3n desde un archivo de Excel, transformaciones de datos y la carga en una base de datos de destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>JORNADA, SEDE, PERIODO_ACADEMICO, CURSO, NOMBRE_ESTUDIANTE, PRIMER_CORTE, SEGUNDO_CORTE, TERCER_CORTE, NOTA_FINAL, INASISTENCIAS_ACUMULADAS, MODULO, FECHA_INICIO, PROGRAMA_ACADEMICO, NOMBRE_DOCENTE, FECHA_FIN</code></li> </ul> </li> </ul> </li> <li> <p>Transformar ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Deriva una nueva columna con un identificador de unidad fijo.</li> <li>Columnas derivadas:<ul> <li>ID_UNIDAD: <code>2</code></li> </ul> </li> </ul> </li> <li> <p>Sort ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Ordena los datos por JORNADA y ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Eliminaci\u00f3n de duplicados: <code>true</code></li> </ul> </li> </ul> </li> <li> <p>Ajustar Ancho Columnas</p> <ul> <li>Descripci\u00f3n: Ajusta el ancho de las columnas procesadas.</li> <li>Columnas derivadas:<ul> <li>_JORNADA: <code>(DT_WSTR,40)JORNADA</code></li> <li>_ID_UNIDAD: <code>(DT_I4)ID_UNIDAD</code></li> </ul> </li> </ul> </li> <li> <p>Filtrar Registros Nulos</p> <ul> <li>Descripci\u00f3n: Filtra registros con valores nulos o vac\u00edos en la columna _JORNADA.</li> <li>Condici\u00f3n: <code>!ISNULL(_JORNADA) &amp;&amp; LEN(TRIM(_JORNADA)) &gt; 0</code></li> </ul> </li> <li> <p>Lookup DIM_JORNADA</p> <ul> <li>Descripci\u00f3n: Busca y asocia los registros en la tabla DIM_JORNADA con base en las columnas _JORNADA y _ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]</code></li> <li>Columnas de uni\u00f3n: JORNADA, ID_UNIDAD</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_JORNADA</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla DIM_JORNADA.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_JORNADA\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant DB as Database\n\n    SSIS -&gt;&gt; Excel: Extrae datos de `Sheet1$`\n    Excel -&gt;&gt; SSIS: Devuelve datos extra\u00eddos\n    SSIS -&gt;&gt; SSIS: Realiza transformaciones y ajustes\n    SSIS -&gt;&gt; DB: Guarda datos en `DIM_JORNADA`</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-dim_periodo_academico","title":"Componente <code>Data DIM_PERIODO_ACADEMICO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_PERIODO_ACADEMICO realiza un flujo de datos para procesar y cargar la tabla de dimensi\u00f3n DIM_PERIODO_ACADEMICO. Este flujo incluye la extracci\u00f3n desde un archivo de Excel, transformaciones de datos y la carga en una base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo de Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code></li> <li>Columnas extra\u00eddas: <code>PERIODO_ACADEMICO, SEDE, JORNADA, CURSO, NOMBRE_ESTUDIANTE, PRIMER_CORTE, SEGUNDO_CORTE, TERCER_CORTE, NOTA_FINAL, INASISTENCIAS_ACUMULADAS, MODULO, FECHA_INICIO, PROGRAMA_ACADEMICO, NOMBRE_DOCENTE, FECHA_FIN</code></li> </ul> </li> </ul> </li> <li> <p>Crear ID_UNIDAD</p> <ul> <li>Descripci\u00f3n: Deriva una nueva columna con un identificador de unidad fijo.</li> <li>Columnas derivadas:<ul> <li>ID_UNIDAD: <code>3</code></li> </ul> </li> </ul> </li> <li> <p>Sort PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Ordena los datos por PERIODO_ACADEMICO y ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Eliminaci\u00f3n de duplicados: <code>true</code></li> </ul> </li> </ul> </li> <li> <p>Ajustar Ancho Columnas</p> <ul> <li>Descripci\u00f3n: Ajusta el ancho de las columnas procesadas.</li> <li>Columnas derivadas:<ul> <li>_PERIODO_ACADEMICO: <code>(DT_WSTR,40)PERIODO_ACADEMICO</code></li> <li>_ID_UNIDAD: <code>(DT_I4)ID_UNIDAD</code></li> </ul> </li> </ul> </li> <li> <p>Filtrar Registros Vac\u00edos</p> <ul> <li>Descripci\u00f3n: Filtra registros con valores vac\u00edos o nulos en la columna _PERIODO_ACADEMICO.</li> <li>Condici\u00f3n: <code>!ISNULL(_PERIODO_ACADEMICO) &amp;&amp; LEN(TRIM(_PERIODO_ACADEMICO)) &gt; 0</code></li> </ul> </li> <li> <p>Lookup DIM_PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Busca y asocia registros en la tabla DIM_PERIODO_ACADEMICO con base en las columnas _PERIODO_ACADEMICO y _ID_UNIDAD.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code></li> <li>Columnas de uni\u00f3n: PERIODO_ACADEMICO, ID_UNIDAD</li> </ul> </li> </ul> </li> <li> <p>Guardar DIM_PERIODO_ACADEMICO</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla DIM_PERIODO_ACADEMICO.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_PERIODO_ACADEMICO\"</code></li> <li>Inserci\u00f3n masiva habilitada: <code>true</code></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencias","title":"Diagrama de Secuencias","text":"<pre><code>graph TD\n    A(Excel Source) --&gt; B(Crear ID_UNIDAD: Deriva ID_UNIDAD=3)\n    B --&gt; C(Sort PERIODO_ACADEMICO: Ordena por PERIODO_ACADEMICO, ID_UNIDAD)\n    C --&gt; D(Ajustar Ancho Columnas: Deriva _PERIODO_ACADEMICO y _ID_UNIDAD)\n    D --&gt; E(Filtrar Registros Vac\u00edos: Elimina registros vac\u00edos)\n    E --&gt; F(Lookup DIM_PERIODO_ACADEMICO: Busca en DIM_PERIODO_ACADEMICO)\n    F --&gt; G(Guardar DIM_PERIODO_ACADEMICO: Carga a la tabla destino)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-flow-task","title":"Componente <code>Data Flow Task</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>El componente Data Flow Task tiene como prop\u00f3sito principal realizar la integraci\u00f3n, transformaci\u00f3n y carga de datos desde diversas fuentes hacia un destino final, aplicando transformaciones y validaciones requeridas para asegurar la calidad de los datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-de-los-componentes-del-flujo-de-datos","title":"Detalle de los Componentes del Flujo de Datos","text":"<ol> <li> <p>Combinar las tablas</p> <ul> <li>Descripci\u00f3n: Realiza una operaci\u00f3n de combinaci\u00f3n tipo JOIN entre dos conjuntos de datos. Se utiliza para consolidar datos en base a un campo clave.</li> <li>Propiedades:<ul> <li>Tipo de combinaci\u00f3n: <code>INNER JOIN</code>.</li> <li>N\u00famero de columnas clave: <code>1</code>.</li> <li>Manejo de nulos: Se trata como valores iguales.</li> <li>Buffers m\u00e1ximos por entrada: <code>5</code>.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada izquierda: Datos ordenados por <code>_NOMBRE_ESRTUDIANTE</code>.</li> <li>Entrada derecha: Datos ordenados por <code>NOMBRE_ESTUDIANTE</code>.</li> <li>Salida: Datos combinados con columnas provenientes de ambas entradas.</li> </ul> </li> </ul> </li> <li> <p>DIM_ESTUDIANTES PROCESADO</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla DIM_ESTUDIANTES para agregar informaci\u00f3n adicional a los registros actuales.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code>.</li> <li>Manejo de filas sin coincidencia: Se redirigen a una salida de error.</li> </ul> </li> <li>Conexiones:<ul> <li>Fuente de datos: OLE DB Connection Manager a DWH_COMFENALCO_Destino_OLEDB.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: <code>_DOCUMENTO</code>.</li> <li>Salida: <code>ID_ESTUDIANTE</code> mapeado desde la tabla de referencia.</li> </ul> </li> </ul> </li> <li> <p>Excel Source 1</p> <ul> <li>Descripci\u00f3n: Extrae datos desde una hoja de Excel para procesarlos en el flujo de datos.</li> <li>Propiedades:<ul> <li>Tabla/hoja: <code>Sheet1$</code>.</li> <li>Modo de acceso: Directo.</li> </ul> </li> <li>Conexiones:<ul> <li>Administrador de conexiones: OLE DB Connection Manager configurado para Excel.</li> </ul> </li> <li>Salidas:<ul> <li>Salida principal: Datos le\u00eddos con columnas como <code>PERIODO_ACADEMICO</code>, <code>JORNADA</code>, y <code>NOMBRE_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_NOTAS</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla FACT_NOTAS del destino de base de datos.</li> <li>Propiedades:<ul> <li>Nombre de la tabla: <code>\"Cedesarrollo\".\"FACT_NOTAS\"</code>.</li> <li>Tama\u00f1o del lote: <code>0</code> (autom\u00e1tico).</li> <li>Uso de inserci\u00f3n masiva: Habilitado.</li> </ul> </li> <li>Conexiones:<ul> <li>Fuente: OLE DB Connection Manager configurado a DWH_COMFENALCO_Destino.</li> </ul> </li> <li>Entradas:<ul> <li>Datos combinados y enriquecidos con columnas como <code>PRIMER_CORTE</code>, <code>SEGUNDO_CORTE</code>, y <code>NOTA_FINAL</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_NOTAS</p> <ul> <li>Descripci\u00f3n: Valida si las notas ya existen en la tabla destino mediante un proceso de b\u00fasqueda.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_NOTAS] WHERE CURSO = ?</code>.</li> <li>Manejo de filas sin coincidencia: Redirige a una salida espec\u00edfica.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: Claves combinadas como <code>CURSO</code>, <code>ID_JORNADA</code>, y <code>ID_ESTUDIANTE</code>.</li> <li>Salida: Coincidencias y no coincidencias gestionadas separadamente.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_JORNADA</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_JORNADA</code> basado en el campo <code>JORNADA</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_JORNADA]</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Fuente: OLE DB Connection Manager.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: <code>JORNADA</code>.</li> <li>Salida: <code>ID_JORNADA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Recupera el <code>ID_PERIODO</code> usando el campo <code>PERIODO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code>.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: <code>PERIODO_ACADEMICO</code>.</li> <li>Salida: <code>ID_PERIODO</code>.</li> </ul> </li> </ul> </li> <li> <p>Sort NOMBRE_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Ordena los datos por el campo <code>_NOMBRE_ESRTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Elimina duplicados: No.</li> <li>Orden: Ascendente por <code>_NOMBRE_ESRTUDIANTE</code>.</li> </ul> </li> <li>Entradas y Salidas:<ul> <li>Entrada: Datos procesados.</li> <li>Salida: Datos ordenados.</li> </ul> </li> </ul> </li> <li> <p>Sort _NOMBRE_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Similar al componente anterior, ordena los datos por el campo <code>_NOMBRE_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Elimina duplicados: No.</li> <li>Orden: Ascendente por <code>_NOMBRE_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n Columnas</p> <ul> <li>Descripci\u00f3n: Aplica transformaciones para generar columnas derivadas.</li> <li>Propiedades:<ul> <li>Agrega columnas como <code>_CURSO</code> y <code>_NOMBRE_DOCENTE</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    Excel[Excel Source 1] --&gt; Transformacion[Transformaci\u00f3n Columnas]\n    Transformacion --&gt; DIM_ESTUDIANTES[Lookup DIM_ESTUDIANTES]\n    DIM_ESTUDIANTES --&gt; CombinarTablas[Combinar las tablas]\n    CombinarTablas --&gt; Sort1[Sort NOMBRE_ESTUDIANTE]\n    Sort1 --&gt; LookupPERIODO[Lookup ID_PERIODO]\n    Sort1 --&gt; LookupJORNADA[Lookup ID_JORNADA]\n    LookupPERIODO --&gt; Guardar[Guardar FACT_NOTAS]\n    LookupJORNADA --&gt; Guardar\n    Sort1 --&gt; Guardar\n    _NOMBRE_ESTUDIANTE[Sort _NOMBRE_ESTUDIANTE] --&gt; Guardar</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_facturacion","title":"FACT_FACTURACION","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-cede_ingresos","title":"Componente <code>Tarea cede_Ingresos</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>El componente Tarea cede_Ingresos es un proceso ejecutado externamente que utiliza un script Python para descargar y procesar datos de ingresos relacionados con el proyecto COMFENALCO_EDUCACION. Este componente permite la integraci\u00f3n de datos externos al flujo de trabajo de SSIS, automatizando la adquisici\u00f3n de informaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-componente","title":"Detalle del Componente","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python externo para procesar datos de ingresos. Este script interact\u00faa con un servicio o base de datos externa, descargando y preparando la informaci\u00f3n para el an\u00e1lisis posterior.</li> <li>Propiedades:<ul> <li>Script ejecutado: <code>download.py</code>.</li> <li>Par\u00e1metro pasado: <code>--key cede_Ingresos</code>.</li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Utiliza las variables del proyecto:<ul> <li>Python_Executable: Ruta del ejecutable de Python.</li> <li>Working_Directory: Ruta del directorio base del proyecto.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea cede_Ingresos\n    participant Python as Script Python\n\n    SSIS -&gt;&gt; Python: Ejecutar `download.py --key cede_Ingresos`\n    Python -&gt;&gt; Python: Descargar y procesar datos de ingresos\n    Python -&gt;&gt; SSIS: Retornar datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-06-archivos-manuales","title":"Componente <code>Tarea EP-EPT-06 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EPT-06 (archivos manuales) es una tarea de ejecuci\u00f3n de proceso dise\u00f1ada para procesar datos de manera manual a trav\u00e9s de un script Python. Este componente forma parte del flujo de trabajo de FACT_FACTURACION, permitiendo la obtenci\u00f3n de informaci\u00f3n espec\u00edfica asociada con el identificador EPEPT06.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-componente_1","title":"Detalle del Componente","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python para procesar archivos manuales relacionados con el proyecto. Esta tarea es esencial para integrar datos que requieren intervenci\u00f3n manual antes de su inclusi\u00f3n en el flujo automatizado.</li> <li>Propiedades:<ul> <li>Script ejecutado: <code>download.py</code>.</li> <li>Par\u00e1metro pasado: <code>--key EPEPT06</code>.</li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Utiliza las variables del proyecto:<ul> <li>Python_Executable: Ruta del ejecutable de Python.</li> <li>Working_Directory: Ruta del directorio base del proyecto.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea EP-EPT-06\n    participant Python as Script Python\n\n    SSIS -&gt;&gt; Python: Ejecutar `download.py --key EPEPT06`\n    Python -&gt;&gt; Python: Procesar archivos manuales asociados\n    Python -&gt;&gt; SSIS: Retornar resultados procesados</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-fact_facturacion","title":"Componente <code>Tarea fact_facturacion</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>El componente Tarea fact_facturacion es una tarea de ejecuci\u00f3n de proceso utilizada para automatizar el procesamiento de datos de facturaci\u00f3n mediante un script Python. Este componente forma parte del flujo de trabajo de FACT_FACTURACION, desempe\u00f1ando un rol crucial en la generaci\u00f3n de reportes y el manejo de datos relacionados con la facturaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalle-del-componente_2","title":"Detalle del Componente","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python encargado del procesamiento de la informaci\u00f3n de facturaci\u00f3n.</li> <li>Propiedades:<ul> <li>Script ejecutado: <code>fact_facturacion.py</code>.</li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> </ul> </li> <li>Conexiones:<ul> <li>Utiliza las variables del proyecto:<ul> <li>Python_Executable: Ruta del ejecutable de Python.</li> <li>Working_Directory: Ruta del directorio base del proyecto.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Tarea fact_facturacion\n    participant Python as Script Python\n\n    SSIS -&gt;&gt; Python: Ejecutar `fact_facturacion.py`\n    Python -&gt;&gt; Python: Procesar datos de facturaci\u00f3n\n    Python -&gt;&gt; SSIS: Retornar resultados procesados</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-data-fact_facturacion","title":"Componente <code>Data FACT_FACTURACION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>El componente Data FACT_FACTURACION realiza el flujo de datos para la extracci\u00f3n, transformaci\u00f3n y carga de informaci\u00f3n relacionada con la facturaci\u00f3n. Incluye la lectura de datos desde un archivo Excel, transformaciones en columnas, b\u00fasquedas de datos en una tabla de facturaci\u00f3n y la carga final en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>EP-EPT-06 (Excel Source)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code>.</li> <li>Columnas extra\u00eddas:     <code>NO_RECIBO</code>, <code>FECHA_CONTABLE</code>, <code>PAGADO_POR</code>, <code>TIPO_DOCUMENTO_PAGO</code>, <code>DOCUMENTO_PAGO</code>, <code>CAJERO</code>, <code>ID_CONCEPTO</code>, <code>CONCEPTO</code>, <code>VALOR_FACTURADO</code>, <code>NOMBRE</code>, <code>VALOR_1</code>, <code>VALOR_PAGADO</code>.</li> </ul> </li> </ul> </li> <li> <p>Derived Column</p> <ul> <li>Descripci\u00f3n: Crea columnas derivadas mediante expresiones para transformar datos existentes.</li> <li>Columnas derivadas:<ul> <li>_DOCUMENTO_PAGO: <code>(DT_WSTR,20)DOCUMENTO_PAGO</code>.</li> <li>ID_FECHA: <code>(DT_I4)(YEAR(FECHA_CONTABLE) * 10000 + MONTH(FECHA_CONTABLE) * 100 + DAY(FECHA_CONTABLE))</code>.</li> <li>_CONCEPTO: <code>(DT_WSTR,255)CONCEPTO</code>.</li> <li>_ID_CONCEPTO: <code>(DT_I4)ID_CONCEPTO</code>.</li> <li>_TIPO_DOCUMENTO: <code>(DT_WSTR,40)TIPO_DOCUMENTO_PAGO</code>.</li> <li>_NO_RECIBO: <code>(DT_WSTR,40)NO_RECIBO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup</p> <ul> <li>Descripci\u00f3n: Busca y asocia datos desde la tabla FACT_FACTURACION.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_FACTURACION]</code>.</li> <li>Condiciones de uni\u00f3n:<ul> <li><code>NO_RECIBO</code> con <code>NO_RECIBO</code>.</li> <li><code>_DOCUMENTO_PAGO</code> con <code>DOCUMENTO_PAGO</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla de destino en la base de datos.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_FACTURACION\"</code>.</li> <li>Inserci\u00f3n masiva habilitada: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_11","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(EP-EPT-06: Fuente Excel) --&gt; B(Derived Column: Transformaciones)\n    B --&gt; C(Lookup: Buscar en FACT_FACTURACION)\n    C --&gt; D(Destino de ADO NET: Cargar datos en FACT_FACTURACION)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_horario","title":"FACT_HORARIO","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_horario","title":"Componente <code>Procesar FACT_HORARIO</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>Este paquete SSIS tiene como objetivo procesar los datos relacionados con horarios acad\u00e9micos. Incluye m\u00faltiples transformaciones para extraer, transformar y cargar datos (ETL) desde archivos de Excel hacia una base de datos compatible con ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source </p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel.  </li> <li>Propiedades:  <ul> <li>Nombre de hoja: <code>'EP-EPT-04$'</code> </li> <li>Timeout del comando: <code>0</code> (sin l\u00edmite).  </li> <li>AccessMode: <code>0</code> (modo directo).  </li> </ul> </li> <li>Conexiones: OleDbConnection.  </li> <li>Columnas de salida:  <ul> <li><code>MODULO</code>, <code>PERIODO ACADEMICO</code>, <code>PROGRAMA</code>, <code>JORNADA</code>, <code>SEMESTRE</code>, etc.  </li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PROGRAMA </p> <ul> <li>Descripci\u00f3n: Asocia datos del m\u00f3dulo con su respectivo programa.  </li> <li>Propiedades:  <ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PLAN_CURRICULAR] WHERE MODULO = ?</code> </li> <li>Tipo de cach\u00e9: <code>Completa</code>.  </li> </ul> </li> <li>Conexi\u00f3n: OleDbConnection.  </li> <li>Columnas de entrada: <code>MODULO</code>.  </li> <li>Columnas de salida: <code>ID_PROGRAMA</code>, <code>ID_MODULO</code>.  </li> </ul> </li> <li> <p>Join Tablas </p> <ul> <li>Descripci\u00f3n: Une dos flujos de datos ordenados.  </li> <li>Propiedades:  <ul> <li>Tipo de uni\u00f3n: <code>INNER</code>.  </li> <li>Columnas clave: <code>SEMESTRE</code>, <code>GRUPO</code>.  </li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas </p> <ul> <li>Descripci\u00f3n: Aplica transformaciones derivadas a las columnas.  </li> <li>Columnas de salida:  <ul> <li><code>NOMBRE_DOCENTE</code>: <code>(DT_WSTR,200)_DOCENTE</code>.  </li> <li><code>HORA_FIN</code>: <code>(DT_WSTR,40)FIN</code>.  </li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_HORARIO </p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_HORARIO</code>.  </li> <li>Propiedades:  <ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_HORARIO\"</code>.  </li> <li>Tama\u00f1o de lotes: <code>0</code>.  </li> </ul> </li> <li>Columnas de entrada: <code>GRUPO</code>, <code>ID_MODULO</code>, <code>ID_PERIODO</code>, <code>NOMBRE_DOCENTE</code>, etc.  </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_12","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Excel Source\n    participant Lookup as Lookup ID_PROGRAMA\n    participant Join as Join Tablas\n    participant Transform as Transformar Columnas\n    participant Save as Guardar FACT_HORARIO\n\n    Excel -&gt;&gt; Lookup: Env\u00eda datos (MODULO)\n    Lookup -&gt;&gt; Join: Devuelve ID_PROGRAMA\n    Join -&gt;&gt; Transform: Realiza uni\u00f3n\n    Transform -&gt;&gt; Save: Transformaciones derivadas\n    Save -&gt;&gt; DB: Inserta datos en FACT_HORARIO</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_ausentismo_docente","title":"FACT_AUSENTISMO_DOCENTE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-edf-02-achivos-manuales","title":"Componente Tarea EP-EDF-02 (achivos manuales)","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EDF-02 (achivos manuales) ejecuta un proceso externo mediante un script de Python. Este script est\u00e1 dise\u00f1ado para descargar y preparar datos manuales asociados al archivo identificado como EP-EDF-02.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-componente","title":"Detalles del Componente","text":"<p>Propiedades</p> <ul> <li>Tipo de Tarea: Ejecutar proceso externo.</li> <li>Ruta del Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> <li>Argumentos:<ul> <li><code>download.py --key EPEDF02</code>.</li> </ul> </li> <li>Directorio de Trabajo:<ul> <li><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> </ul> </li> </ul> <p>Variables Utilizadas</p> <ul> <li>@[$Project::Python_Executable]: Ruta al ejecutable de Python.</li> <li>@[$Project::Working_Directory]: Ruta base del directorio de trabajo.</li> </ul> <p>Descripci\u00f3n del Script</p> <ul> <li>Script: <code>download.py</code>.</li> <li>Argumento Principal: <code>--key EPEDF02</code>, utilizado para identificar el archivo espec\u00edfico a procesar.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_13","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEDF02`\n    Python -&gt;&gt; Python: Descarga datos correspondientes a EPEDF02\n    Python -&gt;&gt; SSIS: Finaliza ejecuci\u00f3n del proceso</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_ausentismo_docente","title":"Componente <code>Procesar FACT_AUSENTISMO_DOCENTE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_AUSENTISMO_DOCENTE gestiona el flujo de datos para la extracci\u00f3n, transformaci\u00f3n y carga de informaci\u00f3n sobre ausentismo docente. Inicia con la lectura de un archivo Excel, realiza transformaciones en columnas, utiliza b\u00fasquedas en tablas relacionadas y finalmente carga los datos transformados en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel EP-EDF-02 (Excel Source)</p> <ul> <li>Descripci\u00f3n: Extrae datos de un archivo Excel.</li> <li>Propiedades:<ul> <li>Hoja de origen: <code>Sheet1$</code>.</li> <li>Columnas extra\u00eddas:     <code>PERIODO_ACADEMICO</code>, <code>FECHA</code>, <code>NOMBRE_DOCENTE</code>, <code>CARGO</code>, <code>FECHA_INICIO</code>, <code>FECHA_FIN</code>, <code>AUSENCIA_HORAS</code>, <code>AUSENCIA_DIAS</code>, <code>TIPO_AUSENCIA</code>, <code>PERMISO</code>, <code>MOTIVO_AUSENCIA</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformacion de Columnas</p> <ul> <li>Descripci\u00f3n: Realiza transformaciones para crear nuevas columnas derivadas.</li> <li>Columnas derivadas:<ul> <li>_PERIODO: <code>(DT_WSTR,40)PERIODO_ACADEMICO</code>.</li> <li>ID_FECHA: <code>[REPLACE]([REPLACE]([REPLACE](FECHA,\"-\",\"\"),\"/\",\"\"),\".\",\"\")</code>.</li> <li>_MOTIVO_AUSENCIA: <code>(DT_WSTR,40)MOTIVO_AUSENCIA</code>.</li> <li>_FECHA: <code>(DT_DATE)FECHA</code>.</li> <li>_DOCENTE: <code>(DT_WSTR,200)NOMBRE_DOCENTE</code>.</li> <li>_CARGO: <code>(DT_WSTR,40)CARGO</code>.</li> <li>_INICIO: <code>(DT_DATE)FECHA_INICIO</code>.</li> <li>_FIN: <code>(DT_DATE)FECHA_FIN</code>.</li> <li>_HORAS: <code>(DT_WSTR,40)AUSENCIA_HORAS</code>.</li> <li>_DIAS: <code>(DT_WSTR,40)AUSENCIA_DIAS</code>.</li> <li>_TIPO: <code>(DT_WSTR,40)TIPO_AUSENCIA</code>.</li> <li>_PERMISO: <code>(DT_WSTR,40)PERMISO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Busca el ID del periodo acad\u00e9mico en la tabla DIM_PERIODO_ACADEMICO.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code>.</li> <li>Condiciones de uni\u00f3n:<ul> <li><code>_PERIODO</code> con <code>PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Columna _ID_FECHA</p> <ul> <li>Descripci\u00f3n: Convierte el valor de ID_FECHA a tipo entero.</li> <li>Propiedades:<ul> <li>Expresi\u00f3n: <code>(DT_I4)ID_FECHA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_AUSENTISMO_DOCENTE</p> <ul> <li>Descripci\u00f3n: Busca datos en la tabla de destino para determinar registros existentes.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]</code>.</li> <li>Condiciones de uni\u00f3n:<ul> <li><code>_DOCENTE</code> con <code>NOMBRE_DOCENTE</code>.</li> <li><code>ID_PERIODO</code> con <code>ID_PERIODO</code>.</li> <li><code>_ID_FECHA</code> con <code>ID_FECHA</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Guardar FACT_AUSENTISMO_DOCENTE</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla destino.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_AUSENTISMO_DOCENTE\"</code>.</li> <li>Inserci\u00f3n masiva habilitada: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_14","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(EP-EDF-02: Fuente Excel) --&gt; B(Transformacion de Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Columna _ID_FECHA)\n    D --&gt; E(Lookup FACT_AUSENTISMO_DOCENTE)\n    E --&gt; F(Guardar FACT_AUSENTISMO_DOCENTE)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_permiso_estudiante","title":"FACT_PERMISO_ESTUDIANTE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-edf-04-achivos-manuales","title":"Componente <code>Tarea EP-EDF-04 (achivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EDF-04 (achivos manuales) ejecuta un proceso externo mediante un script de Python. Este script est\u00e1 dise\u00f1ado para descargar y procesar datos manuales relacionados con el archivo identificado como EP-EDF-04.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-componente_1","title":"Detalles del Componente","text":"<p>Propiedades</p> <ul> <li>Tipo de Tarea: Ejecutar proceso externo.</li> <li>Ruta del Ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code>.</li> <li>Argumentos:<ul> <li><code>download.py --key EPEDF04</code>.</li> </ul> </li> <li>Directorio de Trabajo:<ul> <li><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> </ul> </li> </ul> <p>Variables Utilizadas</p> <ul> <li>@[$Project::Python_Executable]: Ruta al ejecutable de Python.</li> <li>@[$Project::Working_Directory]: Ruta base del directorio de trabajo.</li> </ul> <p>Descripci\u00f3n del Script</p> <ul> <li>Script: <code>download.py</code>.</li> <li>Argumento Principal: <code>--key EPEDF04</code>, utilizado para identificar el archivo espec\u00edfico a procesar.</li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_15","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEDF04`\n    Python -&gt;&gt; Python: Descarga datos correspondientes a EPEDF04\n    Python -&gt;&gt; SSIS: Reporta resultado de la ejecuci\u00f3n</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_permiso_estudiante","title":"Componente <code>Procesar FACT_PERMISO_ESTUDIANTE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_PERMISO_ESTUDIANTE extrae datos de un archivo Excel (<code>EP-EDF-04</code>), transforma y enriquece los datos utilizando varias transformaciones, y finalmente los carga en una tabla destino en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<p>1. Excel Source (EP-EDF-04)</p> <ul> <li>Descripci\u00f3n: Carga datos desde el archivo Excel asociado a la hoja <code>Sheet1$</code>.</li> <li>Propiedades:<ul> <li>Timeout de Comando: <code>0</code> (sin l\u00edmite).</li> <li>Modo de Acceso: <code>OpenRowset</code>.</li> </ul> </li> <li>Columnas Procesadas:   <code>PERIODO ACADEMICO</code>, <code>DOC_ESTUDIANTE</code>, <code>MODULO</code>, <code>FECHA</code>, <code>HORA</code>, <code>MOTIVO_AUSENCIA</code>, <code>SOPORTE_AUSENCIA</code>.</li> </ul> <p>2. Transformar Columnas</p> <ul> <li>Descripci\u00f3n: Aplica transformaciones para crear nuevas columnas y enriquecer los datos.</li> <li>Columnas Derivadas:<ul> <li><code>_PERIODO</code>: Transformaci\u00f3n de <code>PERIODO ACADEMICO</code>.</li> <li><code>DOCUMENTO</code>: Transformaci\u00f3n de <code>DOC_ESTUDIANTE</code>.</li> <li><code>_MODULO</code>: Transformaci\u00f3n de <code>MODULO</code>.</li> <li><code>ID_FECHA</code>: Deriva un identificador de fecha.</li> <li><code>_FECHA</code>: Conversi\u00f3n a formato de fecha.</li> <li><code>_HORA</code>, <code>_MOTIVO_AUSENCIA</code>, <code>_SOPORTE_AUSENCIA</code>.</li> </ul> </li> </ul> <p>3. Lookup ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Enlaza informaci\u00f3n de la tabla <code>DIM_PERIODO_ACADEMICO</code> para identificar el ID del periodo acad\u00e9mico.</li> <li>Consulta SQL:   <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\nWHERE [PERIODO_ACADEMICO] = ?\n</code></pre></li> <li>Salida:     <code>ID_PERIODO</code>.</li> </ul> <p>4. Lookup ID_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Consulta la tabla <code>DIM_ESTUDIANTES</code> para obtener el ID del estudiante basado en su documento.</li> <li>Consulta SQL:   <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_ESTUDIANTES]\nWHERE [DOCUMENTO] = ?\n</code></pre></li> <li>Salida:   <code>ID_ESTUDIANTE</code>.</li> </ul> <p>5. Lookup FACT_PERMISO_ESTUDIANTE</p> <ul> <li>Descripci\u00f3n: Verifica si existe un permiso para el estudiante en la tabla <code>FACT_PERMISO_ESTUDIANTE</code> utilizando m\u00faltiples claves.</li> <li>Consulta SQL:   <pre><code>SELECT * \nFROM [Cedesarrollo].[FACT_PERMISO_ESTUDIANTE]\nWHERE [ID_FECHA] = ? \n  AND [ID_PERIODO] = ? \n  AND [ID_ESTUDIANTE] = ?\n</code></pre></li> </ul> <p>6. Destino ADO.NET (Guardar FACT_PERMISO_ESTUDIANTE)</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla <code>FACT_PERMISO_ESTUDIANTE</code>.</li> <li>Propiedades:<ul> <li>Tabla Destino: <code>\"Cedesarrollo\".\"FACT_PERMISO_ESTUDIANTE\"</code>.</li> <li>Tama\u00f1o del Lote: <code>0</code> (ajustado al tama\u00f1o del buffer).</li> <li>Timeout de Comando: <code>30</code>.</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_16","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant DB as SQL Server Database\n\n    SSIS -&gt;&gt; Excel: Carga datos de EP-EDF-04\n    Excel -&gt;&gt; SSIS: Env\u00eda datos al flujo\n    SSIS -&gt;&gt; DB: Consulta ID_PERIODO desde DIM_PERIODO_ACADEMICO\n    SSIS -&gt;&gt; DB: Consulta ID_ESTUDIANTE desde DIM_ESTUDIANTES\n    SSIS -&gt;&gt; DB: Verifica datos en FACT_PERMISO_ESTUDIANTE\n    SSIS -&gt;&gt; DB: Inserta datos en FACT_PERMISO_ESTUDIANTE</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#dim_preguntas_cotizacion","title":"DIM_PREGUNTAS_COTIZACION","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-12-archivos-manuales","title":"Componente <code>Tarea EP-EPT-12 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>La tarea Tarea EP-EPT-12 (archivos manuales) utiliza el componente Execute Process Task para ejecutar un script Python que descarga datos asociados con la clave <code>EPEPT12</code>.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-configuracion","title":"Propiedades de Configuraci\u00f3n","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python ubicado en el entorno de trabajo para descargar datos.</li> <li>Archivo Ejecutable: <code>python.exe</code> del entorno virtual en:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos:   <pre><code>download.py --key EPEPT12\n</code></pre></li> <li>Directorio de Trabajo:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_17","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT12`\n    Python -&gt;&gt; Python: Descarga datos asociados a la clave\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_evaluacion_formacion","title":"Componente <code>Procesar FACT_EVALUACION_FORMACION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_EVALUACION_FORMACION tiene como prop\u00f3sito extraer, transformar y cargar datos relacionados con las preguntas de cotizaci\u00f3n en la tabla destino DIM_PREGUNTAS_COTIZACION. Utiliza un archivo Excel como fuente y realiza transformaciones y validaciones antes de insertar los datos en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_9","title":"Componentes del Flujo de Datos","text":"<p>1. Componente EP-EPT-12 (Fuente Excel)</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel en la hoja <code>Sheet1$</code>.</li> <li>Propiedades:<ul> <li>Conexi\u00f3n: Administrador de conexiones con Excel.</li> <li>Columnas de salida:<ul> <li><code>PREGUNTA</code>: Texto relacionado con las preguntas de cotizaci\u00f3n.</li> <li><code>OBSERVACIONES</code>: Comentarios u observaciones adicionales.</li> </ul> </li> </ul> </li> </ul> <p>2. Transformaci\u00f3n de Columnas</p> <ul> <li>Descripci\u00f3n: Crea nuevas columnas derivadas de las existentes o las formatea seg\u00fan sea necesario.</li> <li>Columnas de salida:<ul> <li><code>_PREGUNTA</code>: Conversi\u00f3n de <code>PREGUNTA</code> al formato <code>DT_WSTR</code> con una longitud de 200.</li> <li><code>_OBSERVACIONES</code>: Conversi\u00f3n de <code>OBSERVACIONES</code> al formato <code>DT_WSTR</code> con una longitud de 200.</li> </ul> </li> </ul> <p>3. Lookup</p> <ul> <li>Descripci\u00f3n: Verifica si las preguntas ya existen en la tabla destino para evitar duplicados.</li> <li>Fuente de referencia: Tabla DIM_PREGUNTAS_COTIZACION.</li> <li>Propiedades:<ul> <li>SQL de b\u00fasqueda:      <pre><code>SELECT * FROM [Cedesarrollo].[DIM_PREGUNTAS_COTIZACION]\n</code></pre></li> <li>Comportamiento en caso de no coincidencias: Enviar filas al siguiente paso.</li> </ul> </li> </ul> <p>4. Destino de ADO.NET</p> <ul> <li>Descripci\u00f3n: Inserta datos nuevos en la tabla DIM_PREGUNTAS_COTIZACION.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"DIM_PREGUNTAS_COTIZACION\"</code>.</li> <li>Conexi\u00f3n: Administrador de conexiones con ADO.NET.</li> <li>Columnas cargadas:<ul> <li><code>PREGUNTA</code>.</li> <li><code>OBSERVACIONES</code>.</li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_18","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Fuente Excel\n    participant SSIS as Flujo de Datos\n    participant DB as Base de Datos\n\n    Excel -&gt;&gt; SSIS: Extrae datos (PREGUNTA, OBSERVACIONES)\n    SSIS -&gt;&gt; SSIS: Aplica transformaciones (_PREGUNTA, _OBSERVACIONES)\n    SSIS -&gt;&gt; DB: Verifica duplicados (Lookup)\n    SSIS -&gt;&gt; DB: Inserta datos nuevos</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_plan_cobertura","title":"FACT_PLAN_COBERTURA","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-07-archivos-manuales","title":"Componente <code>Tarea EP-EPT-07 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EPT-07 (archivos manuales) ejecuta un proceso externo mediante un script de Python. Su prop\u00f3sito es descargar los datos relacionados con el plan de cobertura, proces\u00e1ndolos desde un archivo externo y prepar\u00e1ndolos para su integraci\u00f3n en el flujo de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo","title":"Componentes del Flujo","text":"<p>1. Ejecutar Proceso (EP-EPT-07)</p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python ubicado en el directorio de trabajo para descargar los datos correspondientes.</li> <li>Propiedades:</li> <li>Archivo ejecutable:     <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe\n</code></pre></li> <li>Argumentos del script:     <pre><code>download.py --key EPEPT07\n</code></pre></li> <li>Directorio de trabajo:     <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> <li>Propiedades din\u00e1micas:<ul> <li><code>Executable</code>: @[$Project::Python_Executable]</li> <li><code>WorkingDirectory</code>: @[$Project::Working_Directory] + \"\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\"</li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_19","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT07`\n    Python -&gt;&gt; Python: Descarga datos de Plan de Cobertura\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_plan_cobertura","title":"Componente <code>Procesar FACT_PLAN_COBERTURA</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_PLAN_COBERTURA permite extraer, transformar y cargar (ETL) datos relacionados con el plan de cobertura. Utiliza varias transformaciones y b\u00fasquedas para preparar los datos antes de almacenarlos en el destino.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_10","title":"Componentes del Flujo de Datos","text":"<p>1. Fuente de Excel (EP-EPT-07)</p> <ul> <li>Descripci\u00f3n: Extrae datos de una hoja de c\u00e1lculo de Excel.</li> <li>Propiedades:<ul> <li>Nombre del objeto de base de datos: <code>Sheet1$</code></li> <li>Conexi\u00f3n: Administrador de conexiones con Excel 17</li> <li>Columnas de salida: <code>,UNIDAD,MODALIDAD,CATEGOR\u00cdA,USOS_PROYECTADOS,USUARIOS_PROYECTADOS,PERIODO_ACADEMICO,PROGRAMA</code></li> </ul> </li> </ul> <p>2. Columna Derivada</p> <ul> <li>Descripci\u00f3n: Genera una nueva columna <code>_PERIODO</code> basada en la columna <code>PERIODO ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Expresi\u00f3n derivada: <code>(DT_WSTR,40)[PERIODO ACADEMICO]</code></li> <li>Columna de salida: <code>_PERIODO</code></li> </ul> </li> </ul> <p>3. B\u00fasqueda de ID_PERIODO</p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>DIM_PERIODO_ACADEMICO</code> para obtener el ID del per\u00edodo acad\u00e9mico asociado.</li> <li>Propiedades:<ul> <li>Consulta SQL:     <pre><code>SELECT * \nFROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]\nWHERE [PERIODO_ACADEMICO] = ?\n</code></pre></li> <li>Columnas relacionadas:<ul> <li>Entrada: <code>_PERIODO</code></li> <li>Salida: <code>ID_PERIODO</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_20","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Fuente de Excel\n    participant SQL as SQL Lookup\n\n    SSIS -&gt;&gt; Excel: Extrae datos desde \"Sheet1$\"\n    Excel -&gt;&gt; SSIS: Env\u00eda datos transformados\n    SSIS -&gt;&gt; SQL: Realiza b\u00fasqueda en \"DIM_PERIODO_ACADEMICO\"\n    SQL -&gt;&gt; SSIS: Retorna ID_PERIODO</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_desempenho_docente_de","title":"FACT_DESEMPENHO_DOCENTE_DE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-08-archivos-manuales","title":"Componente <code>Tarea EP-EPT-08 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-08 es un componente de tipo <code>Execute Process Task</code> que ejecuta un script de Python para descargar datos necesarios en el flujo de trabajo del paquete SSIS. El script se ejecuta utilizando un entorno virtual Python previamente configurado.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente","title":"Propiedades del Componente","text":"<ul> <li>Ruta del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Argumentos: <code>download.py --key EPEPT08</code></li> <li>Directorio de trabajo:   <pre><code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\n</code></pre></li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_21","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT08`\n    Python -&gt;&gt; Python: Descarga datos\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_desempenho_docente_de","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE_DE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_23","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_DESEMPENHO_DOCENTE_DE es responsable de la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de los datos de evaluaci\u00f3n de desempe\u00f1o docente en la base de datos destino <code>Cedesarrollo.FACT_DESEMPENHO_DOCENTE_DE</code>. Incluye transformaciones para derivar columnas, realizar b\u00fasquedas en tablas relacionadas y cargar los datos procesados en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_11","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source (EP-EPT-08) </p> <ul> <li>Descripci\u00f3n: Extrae datos de una hoja de c\u00e1lculo Excel denominada <code>Sheet1$</code>.</li> <li>Propiedades:  <ul> <li>Nombre de la tabla u objeto: <code>Sheet1$</code>.  </li> <li>Conexi\u00f3n: Administrador de conexiones Excel 18.  </li> </ul> </li> </ul> </li> <li> <p>Transformar Columnas </p> <ul> <li>Descripci\u00f3n: Deriva nuevas columnas como <code>_PERIODO_ACADEMICO</code>, <code>_ID_FECHA</code>, y <code>_ID_UNIDAD</code> a partir de las columnas de entrada.  </li> <li>Propiedades de las columnas derivadas:  <ul> <li><code>_PERIODO_ACADEMICO</code>: Convierte <code>PERIODO_ACADEMICO</code> a <code>DT_WSTR</code> (40).  </li> <li><code>_ID_FECHA</code>: Calcula un identificador num\u00e9rico basado en <code>FECHA</code>.  </li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO </p> <ul> <li>Descripci\u00f3n: Busca el identificador de per\u00edodo acad\u00e9mico en la tabla <code>DIM_PERIODO_ACADEMICO</code>.  </li> <li>Propiedades:  <ul> <li>Consulta SQL: <code>SELECT * FROM DIM_PERIODO_ACADEMICO</code>.  </li> </ul> </li> </ul> </li> <li> <p>Lookup 1 </p> <ul> <li>Descripci\u00f3n: Compara los datos actuales con los registros en <code>FACT_DESEMPENHO_DOCENTE_DE</code> para verificar duplicados.  </li> <li>Propiedades:  <ul> <li>Condici\u00f3n de b\u00fasqueda: Coincide con <code>NOMBRE_DOCENTE</code>, <code>PROGRAMA</code>, <code>ID_FECHA</code>, entre otros campos.  </li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET </p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en <code>FACT_DESEMPENHO_DOCENTE_DE</code>.  </li> <li>Propiedades:  <ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_DESEMPENHO_DOCENTE_DE\"</code>.  </li> <li>Inserci\u00f3n masiva habilitada.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_22","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Excel as Excel Source\n    participant Transform as Transformar Columnas\n    participant LookupPeriodo as Lookup ID_PERIODO\n    participant LookupFact as Lookup FACT_DESEMPENHO_DOCENTE_DE\n    participant ADO as Destino de ADO NET\n\n    Excel -&gt;&gt; Transform: Enviar datos\n    Transform -&gt;&gt; LookupPeriodo: Buscar ID_PERIODO\n    LookupPeriodo -&gt;&gt; LookupFact: Validar duplicados\n    LookupFact -&gt;&gt; ADO: Insertar nuevos registros</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_desempenho_docente_ce","title":"FACT_DESEMPENHO_DOCENTE_CE","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_desempenho_docente_ce","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE_CE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_24","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EDF-09 (archivos manuales) ejecuta un proceso externo para descargar datos de evaluaci\u00f3n del desempe\u00f1o docente utilizando un script en Python. Este componente forma parte de la soluci\u00f3n ETL dise\u00f1ada para integrar datos en el sistema.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-del-componente_1","title":"Propiedades del Componente","text":"<ol> <li>Descripci\u00f3n: Ejecuta un script de Python que descarga datos necesarios para el proceso ETL.</li> <li>Script Python: <code>download.py</code></li> <li>Argumentos: <code>--key EPEDF09</code></li> <li>Ejecutable:    Ruta del ejecutable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Directorio de Trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_23","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEDF09`\n    Python -&gt;&gt; Python: Descarga datos para FACT_DESEMPENHO_DOCENTE_CE\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_desempenho_docente_ce_1","title":"Componente <code>Procesar FACT_DESEMPENHO_DOCENTE_CE</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_25","title":"Descripci\u00f3n General","text":"<p>Este componente Procesar FACT_DESEMPENHO_DOCENTE_CE realiza la integraci\u00f3n y transformaci\u00f3n de datos para evaluar el desempe\u00f1o docente centralizado. Se utiliza una combinaci\u00f3n de fuentes de datos Excel, transformaciones derivadas, b\u00fasquedas (lookups) y carga de datos a un destino compatible con ADO.NET en una base de datos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_12","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente Excel (EP-EDF-09):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel que contiene la informaci\u00f3n inicial de desempe\u00f1o docente.</li> <li>Propiedades:<ul> <li>Tabla o rango: <code>Sheet1$</code></li> <li>Columnas principales: <code>ID_UNIDAD</code>, <code>PERIODO_ACADEMICO</code>, <code>NOMBRE_DOCENTE</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Columnas:</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas o ajusta valores en las existentes.</li> <li>Propiedades:<ul> <li>Ejemplo: Convierte <code>PERIODO_ACADEMICO</code> a una columna derivada <code>_PERIODO_ACADEMICO</code>.</li> <li>Ajusta <code>ID_UNIDAD</code> de <code>wstr</code> a <code>i4</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO:</p> <ul> <li>Descripci\u00f3n: Busca informaci\u00f3n del periodo acad\u00e9mico desde la tabla <code>DIM_PERIODO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Modo de b\u00fasqueda: Exact Match.</li> <li>Columna unida: <code>PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup Principal:</p> <ul> <li>Descripci\u00f3n: Relaciona datos adicionales desde <code>FACT_DESEMPENHO_DOCENTE_CE</code>.</li> <li>Propiedades:<ul> <li>Criterios: <code>ID_UNIDAD</code>, <code>NOMBRE_DOCENTE</code>, <code>ID_PERIODO</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_DESEMPENHO_DOCENTE_CE</code>.</li> <li>Propiedades:<ul> <li>Nombre de tabla: <code>\"Cedesarrollo\".\"FACT_DESEMPENHO_DOCENTE_CE\"</code></li> <li>Tama\u00f1o de lote: <code>0</code> (predeterminado).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_24","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Fuente Excel) --&gt; B(Transformar Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Lookup Principal)\n    D --&gt; E(Destino ADO.NET)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_asistencia_act_bienestar","title":"FACT_ASISTENCIA_ACT_BIENESTAR","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-11-archivos-manuales","title":"Componente <code>Tarea EP-EPT-11 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_26","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-11 (archivos manuales) ejecuta un script en Python que descarga los datos necesarios para alimentar el flujo de datos del paquete. Este proceso es fundamental para asegurar que los archivos requeridos est\u00e9n disponibles en el entorno de trabajo antes de procesar la informaci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-la-tarea_1","title":"Propiedades de la Tarea","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python para descargar archivos manuales asociados al flujo de datos.</li> <li>Propiedades Configuradas:<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>download.py --key EPEPT11</code></li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#funcionamiento","title":"Funcionamiento","text":"<ol> <li>El script se ejecuta usando el int\u00e9rprete de Python configurado en el entorno virtual localizado en el directorio <code>env</code>.</li> <li>Descarga el archivo identificado por la clave <code>EPEPT11</code> mediante el comando <code>download.py</code>.</li> <li>Al completarse, los datos quedan disponibles en el directorio de trabajo especificado.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_25","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT11`\n    Python -&gt;&gt; Python: Descarga datos para archivos manuales\n    Python -&gt;&gt; SSIS: Reporta \u00e9xito o error</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_asistencia_act_bienestar","title":"Componente <code>Procesar FACT_ASISTENCIA_ACT_BIENESTAR</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_27","title":"Descripci\u00f3n General","text":"<p>El flujo de datos Procesar FACT_ASISTENCIA_ACT_BIENESTAR integra, transforma y carga informaci\u00f3n relacionada con la asistencia a actividades de bienestar. Este proceso incluye extracciones desde Excel, transformaciones de columnas, b\u00fasquedas en tablas auxiliares y la carga final de los datos en la tabla destino de SQL Server.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_13","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente Excel (EP-EPT-11):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel con informaci\u00f3n inicial de asistencia.</li> <li>Propiedades:<ul> <li>Tabla o rango: <code>Sheet1$</code></li> <li>Columnas principales: <code>PERIODO_ACADEMICO</code>, <code>DOCUMENTO</code>, <code>FECHA</code>, <code>ACTIVIDAD</code>, <code>ASISTIO</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Columnas:</p> <ul> <li>Descripci\u00f3n: Genera nuevas columnas derivadas y realiza conversiones de formato.</li> <li>Propiedades:<ul> <li>Convierte <code>FECHA</code> a formato <code>date</code> y deriva <code>ID_FECHA</code>.</li> <li>Ajusta los tipos de datos para <code>DOCUMENTO</code> y <code>TIPO_DOCUMENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO:</p> <ul> <li>Descripci\u00f3n: Busca el ID del periodo acad\u00e9mico en la tabla <code>DIM_PERIODO_ACADEMICO</code>.</li> <li>Propiedades:<ul> <li>Columna de uni\u00f3n: <code>PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_ESTUDIANTE:</p> <ul> <li>Descripci\u00f3n: Encuentra el ID del estudiante utilizando el documento de identificaci\u00f3n desde la tabla <code>DIM_ESTUDIANTES</code>.</li> <li>Propiedades:<ul> <li>Columna de uni\u00f3n: <code>DOCUMENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_ASISTENCIA_ACT_BIENESTAR:</p> <ul> <li>Descripci\u00f3n: Verifica duplicados en la tabla destino antes de la carga.</li> <li>Propiedades:<ul> <li>Criterios: <code>ID_FECHA</code>, <code>ID_PERIODO</code>, <code>ID_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO.NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>FACT_ASISTENCIA_ACT_BIENESTAR</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Cedesarrollo\".\"FACT_ASISTENCIA_ACT_BIENESTAR\"</code>.</li> <li>Tama\u00f1o de lote: <code>0</code> (predeterminado).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_26","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Fuente Excel) --&gt; B(Transformar Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Lookup ID_ESTUDIANTE)\n    D --&gt; E(Lookup FACT_ASISTENCIA_ACT_BIENESTAR)\n    E --&gt; F(Destino ADO.NET)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_evaluacion_plan_curricular","title":"FACT_EVALUACION_PLAN_CURRICULAR","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-09-archivos-manuales","title":"Componente <code>Tarea EP-EPT-09 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_28","title":"Descripci\u00f3n General","text":"<p>La tarea EP-EPT-09 (archivos manuales) es una tarea de proceso que ejecuta un script en Python para descargar los archivos necesarios relacionados con la evaluaci\u00f3n del plan curricular. Este paso es crucial para garantizar que los datos requeridos est\u00e9n disponibles antes de procesar la informaci\u00f3n en el flujo de datos del paquete.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#propiedades-de-la-tarea_2","title":"Propiedades de la Tarea","text":"<ul> <li>Descripci\u00f3n: Ejecuta un script Python para descargar archivos relacionados con el plan curricular.</li> <li>Propiedades Configuradas:<ul> <li>Executable: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils\\env\\Scripts\\python.exe</code></li> <li>Arguments: <code>download.py --key EPEPT09</code></li> <li>Directorio de trabajo: <code>\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code></li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#funcionamiento_1","title":"Funcionamiento","text":"<ol> <li>El script <code>download.py</code> se ejecuta a trav\u00e9s del int\u00e9rprete de Python especificado en el entorno virtual.</li> <li>Usa el argumento <code>--key EPEPT09</code> para identificar los datos a descargar.</li> <li>Los archivos descargados se almacenan en el directorio de trabajo configurado, asegurando la disponibilidad para las siguientes etapas del flujo.</li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_27","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key EPEPT09`\n    Python -&gt;&gt; Python: Descarga datos relacionados con EPEPT09\n    Python -&gt;&gt; SSIS: Reporta \u00e9xito o error</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_evaluacion_plan_curricular","title":"Componente <code>Procesar FACT_EVALUACION_PLAN_CURRICULAR</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_29","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_EVALUACION_PLAN_CURRICULAR es una tarea de flujo de datos en un paquete SSIS que se encarga de extraer datos desde un archivo Excel, transformar las columnas necesarias y cargar la informaci\u00f3n procesada en una tabla en la base de datos. Este proceso incluye pasos de b\u00fasqueda y transformaci\u00f3n para asegurar la consistencia de los datos y su adecuaci\u00f3n para an\u00e1lisis posteriores.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_14","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source (EP-EPT-09) </p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (hoja <code>Sheet1$</code>) relacionado con la evaluaci\u00f3n del plan curricular.</li> <li>Propiedades:<ul> <li>Archivo de Origen: Conexi\u00f3n OLE DB configurada para Excel.</li> <li>Columnas Extra\u00eddas:</li> <li><code>ID_UNIDAD</code></li> <li><code>UNIDAD</code></li> <li><code>PERIODO_ACADEMICO</code></li> <li><code>CALIFICACION</code></li> <li><code>OBSERVACIONES</code></li> </ul> </li> <li>Conexi\u00f3n: Administrador de conexiones de Excel 21.</li> </ul> </li> <li> <p>Derived Column (Transformar Columnas) </p> <ul> <li>Descripci\u00f3n: Aplica transformaciones a las columnas de entrada, generando nuevas columnas derivadas.</li> <li>Columnas Derivadas:<ul> <li><code>_PERIODO_ACADEMICO</code>: Transformaci\u00f3n de <code>PERIODO_ACADEMICO</code> para formato interno.</li> <li><code>_ID_UNIDAD</code>: Conversi\u00f3n de <code>ID_UNIDAD</code> a entero.</li> <li><code>_UNIDAD</code>, <code>_CALIFICACION</code>, <code>_OBSERVACIONES</code>: Procesadas para asegurar consistencia.</li> </ul> </li> </ul> </li> <li> <p>Lookup ID_PERIODO </p> <ul> <li>Descripci\u00f3n: Busca informaci\u00f3n adicional en la tabla <code>[Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code> relacionada con el per\u00edodo acad\u00e9mico.</li> <li>Propiedades:<ul> <li>SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_PERIODO_ACADEMICO]</code>.</li> <li>Columna de uni\u00f3n: <code>_PERIODO_ACADEMICO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup FACT_EVALUACION_PLAN_CURRICULAR </p> <ul> <li>Descripci\u00f3n: Valida si los datos ya existen en la tabla <code>[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]</code> para evitar duplicados.</li> <li>Propiedades:<ul> <li>SQL: <code>SELECT * FROM [Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR] WHERE [ID_UNIDAD] = ? AND [ID_PERIODO] = ?</code>.</li> </ul> </li> </ul> </li> <li> <p>ADO.NET Destination (Guardar FACT_EVALUACION_PLAN_CURRICULAR) </p> <ul> <li>Descripci\u00f3n: Inserta los datos transformados y validados en la tabla <code>[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR]</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Cedesarrollo\".\"FACT_EVALUACION_PLAN_CURRICULAR\"</code>.</li> <li>Batch Size: 0 (usa tama\u00f1o predeterminado).</li> <li>Modo de inserci\u00f3n: Bulk Insert para mejor rendimiento.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_28","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(EP-EPT-09: Extraer Excel) --&gt; B(Transformar Columnas)\n    B --&gt; C(Lookup ID_PERIODO)\n    C --&gt; D(Lookup FACT_EVALUACION_PLAN_CURRICULAR)\n    D --&gt; E(Guardar FACT_EVALUACION_PLAN_CURRICULAR)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_evaluacion_formacion","title":"FACT_EVALUACION_FORMACION","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-tarea-ep-ept-10-archivos-manuales","title":"Componente <code>Tarea EP-EPT-10 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_30","title":"Descripci\u00f3n General","text":"<p>El componente Tarea EP-EPT-10 (archivos manuales) ejecuta un proceso externo utilizando un script de Python para descargar datos relacionados con la evaluaci\u00f3n de formaci\u00f3n. La tarea es parte de un paquete SSIS y est\u00e1 configurada para garantizar que los datos se procesen correctamente antes de ser utilizados en el flujo de datos del paquete.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_15","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Execute Process Task (EP-EPT-10) </p> <ul> <li>Descripci\u00f3n: Ejecuta un script de Python ubicado en el directorio <code>COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> <li>Propiedades:<ul> <li>Executable: Ruta del ejecutable de Python configurado mediante una variable de proyecto (<code>@[$Project::Python_Executable]</code>).</li> <li>Argumentos: <code>download.py --key EPEPT10</code>.</li> <li>Directorio de Trabajo: <code>\\\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.</li> </ul> </li> <li>Prop\u00f3sito:<ul> <li>Descargar datos necesarios para el proceso de evaluaci\u00f3n de formaci\u00f3n.</li> <li>Asegurar que los archivos est\u00e1n actualizados antes de continuar con las siguientes tareas en el flujo de datos.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_29","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Inicia Tarea EP-EPT-10) --&gt; B(Ejecuta Python Script)\n    B --&gt; C(Descarga datos)\n    C --&gt; D(Contin\u00faa flujo SSIS)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_evaluacion_formacion_1","title":"Componente <code>Procesar FACT_EVALUACION_FORMACION</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_31","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_EVALUACION_FORMACION es una tarea de flujo de datos en un paquete SSIS. Su objetivo principal es extraer datos desde un archivo Excel, transformarlos y realizar un Lookup en la base de datos antes de cargar los datos en la tabla destino <code>Cedesarrollo.FACT_EVALUACION_FORMACION</code>. </p> <p>Este proceso incluye tareas de transformaci\u00f3n de columnas, validaci\u00f3n de datos y manejo de errores para garantizar la calidad y coherencia de la informaci\u00f3n cargada.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo-de-datos_16","title":"Componentes del Flujo de Datos","text":"<p>1. Excel Source (EP-EPT-10)     - Descripci\u00f3n: Extrae datos de un archivo Excel ubicado en un directorio espec\u00edfico.     - Propiedades:         - Hoja de trabajo: <code>Sheet1$</code>.         - Conexi\u00f3n: Administrador de conexiones configurado para Excel (<code>Administrador de conexiones con Excel 22</code>).  </p> <p>2. Derived Column Transformation     - Descripci\u00f3n: Realiza transformaciones en los datos extra\u00eddos, generando nuevas columnas derivadas o modificando las existentes.     - Propiedades principales:         - Transformaci\u00f3n de datos como <code>TIPO_DOCUMENTO_ENCUESTADO</code>, <code>DOCUMENTO_ENCUESTADO</code>, y columnas de evaluaci\u00f3n (<code>ASPECTO_1</code> a <code>ASPECTO_9</code>).  </p> <p>3. Lookup Transformation     - Descripci\u00f3n: Realiza una b\u00fasqueda de datos en la tabla <code>FACT_EVALUACION_FORMACION</code> para validar y complementar la informaci\u00f3n procesada.     - Propiedades principales:         - SQL de referencia: <pre><code>SELECT * \nFROM Cedesarrollo.FACT_EVALUACION_FORMACION\nWHERE DOCUMENTO_ENCUESTADO = ? \n    AND ID_TARIFA = ?\n</code></pre>         - Manejo de filas sin coincidencia: Env\u00eda las filas al destino final para carga.  </p> <p>4. Destino ADO.NET     - Descripci\u00f3n: Carga los datos procesados en la tabla <code>Cedesarrollo.FACT_EVALUACION_FORMACION</code>.     - Propiedades principales:         - Nombre de la tabla: <code>\"Cedesarrollo\".\"FACT_EVALUACION_FORMACION\"</code>.         - Inserci\u00f3n masiva: Activada para optimizar el rendimiento.  </p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_30","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant Derived as Derived Columns\n    participant Lookup as Lookup Table\n    participant ADO as ADO.NET Destination\n\n    SSIS -&gt;&gt; Excel: Extrae datos de archivo\n    Excel -&gt;&gt; Derived: Transforma columnas\n    Derived -&gt;&gt; Lookup: Busca datos existentes\n    Lookup -&gt;&gt; ADO: Env\u00eda filas sin coincidencia\n    ADO -&gt;&gt; SSIS: Finaliza carga de datos</code></pre> <pre><code>graph TD\n    A(Inicio) --&gt; B(Excel Source: EP-EPT-10)\n    B --&gt; C(Transformar Columnas)\n    C --&gt; D(Lookup Transformation)\n    D --&gt; E(Destino ADO.NET)\n    E --&gt; F(Finalizaci\u00f3n)</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#fact_cotizaciones","title":"FACT_COTIZACIONES","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-tarea-am-dre-05-archivos-manuales","title":"Componente <code>Procesar Tarea AM-DRE-05 (archivos manuales)</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_32","title":"Descripci\u00f3n General","text":"<p>Esta tarea ejecuta un script Python para descargar datos necesarios para el proceso de integraci\u00f3n de <code>FACT_COTIZACIONES</code>. El script se ejecuta desde un entorno virtual configurado en el proyecto y utiliza una clave espec\u00edfica <code>AMDRE05</code> para identificar los datos que se deben procesar.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componentes-del-flujo_1","title":"Componentes del Flujo","text":"<p>1. Tarea de Ejecuci\u00f3n de Proceso: AM-DRE-05     - Descripci\u00f3n: Ejecuta el script Python <code>download.py</code> para obtener los datos relevantes.     - Propiedades:         - Ejecutable: <code>python.exe</code> ubicado en el entorno virtual configurado.         - Directorio de Trabajo: <code>\\\\COMFENALCO_EDUCACION\\01.Scripts\\Utils</code>.         - Argumentos del Script: <code>download.py --key AMDRE05</code>.  </p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-ejecucion","title":"Diagrama de Ejecuci\u00f3n","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Python as Python Script\n\n    SSIS -&gt;&gt; Python: Ejecuta `download.py --key AMDRE05`\n    Python -&gt;&gt; Python: Descarga datos de cotizaciones\n    Python -&gt;&gt; SSIS: Reporta resultado</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#componente-procesar-fact_cotizaciones","title":"Componente <code>Procesar FACT_COTIZACIONES</code>","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_33","title":"Descripci\u00f3n General","text":"<p>El componente Procesar FACT_COTIZACIONES representa una tarea de flujo de datos en SSIS dise\u00f1ada para extraer, transformar y cargar informaci\u00f3n de cotizaciones desde un archivo Excel hacia una base de datos. Este proceso incluye transformaciones derivadas, operaciones de b\u00fasqueda, combinaciones de datos y ordenamientos.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-de-los-componentes-del-flujo-de-datos","title":"Detalles de los Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos: Excel Source</p> <ul> <li>Descripci\u00f3n: Extrae los datos de un archivo Excel.</li> <li>Propiedades:<ul> <li><code>CommandTimeout</code>: 0 (tiempo de espera infinito).</li> <li><code>OpenRowset</code>: Sheet1$.</li> <li><code>AccessMode</code>: 0 (modo de acceso por defecto).</li> </ul> </li> <li>Conexi\u00f3n:<ul> <li><code>ConnectionManager</code>: Administrador de conexiones con Excel 23.</li> </ul> </li> <li>Salidas:<ul> <li>Columnas: FECHA_REGISTRO, NOMBRE, DOCUMENTO, TIPO_DOCUMENTO, ESTADO_COTIZACION, PREGUNTA, RESPUESTA.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Derived Column (Transformar Columnas)</p> <ul> <li>Descripci\u00f3n: Crea columnas derivadas mediante expresiones.</li> <li>Propiedades:<ul> <li>Ejemplo: Generaci\u00f3n de <code>_ID_FECHA</code> reemplazando caracteres en <code>FECHA_REGISTRO</code>.</li> </ul> </li> <li>Columnas Derivadas:<ul> <li><code>_ID_FECHA</code>, <code>_DOCUMENTO</code>, <code>_TIPO_DOCUMENTO</code>, <code>_NOMBRE</code>, <code>_EST_COTIZACION</code>, <code>_PREGUNTA</code>, <code>_RESPUESTA</code>, <code>_FECHA_REGISTRO</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Lookup (ID_ESTUDIANTE)</p> <ul> <li>Descripci\u00f3n: Busca datos en la tabla <code>DIM_ESTUDIANTES</code>.</li> <li>Propiedades:<ul> <li>SQL: <code>SELECT * FROM [Cedesarrollo].[DIM_ESTUDIANTES]</code>.</li> <li>Comportamiento: Ignorar fallos de coincidencia.</li> </ul> </li> <li>Entradas:<ul> <li><code>_DOCUMENTO</code>.</li> </ul> </li> <li>Salidas:<ul> <li>Coincidencias: <code>ID_ESTUDIANTE</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Sort</p> <ul> <li>Descripci\u00f3n: Ordena los datos de entrada en orden ascendente por columnas espec\u00edficas.</li> <li>Propiedades:<ul> <li><code>MaximumThreads</code>: -1 (uso autom\u00e1tico de hilos).</li> </ul> </li> <li>Columnas Ordenadas:<ul> <li><code>PREGUNTA</code>, <code>_PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n: Merge Join</p> <ul> <li>Descripci\u00f3n: Combina dos flujos de datos ordenados mediante un Join INNER.</li> <li>Propiedades:<ul> <li><code>JoinType</code>: INNER JOIN.</li> </ul> </li> <li>Entradas:<ul> <li>Izquierda: Datos ordenados por <code>PREGUNTA</code>.</li> <li>Derecha: Datos ordenados por <code>_PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de Datos: ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos combinados en la tabla <code>FACT_COTIZACIONES</code>.</li> <li>Propiedades:<ul> <li><code>TableOrViewName</code>: <code>\"Cedesarrollo\".\"FACT_COTIZACIONES\"</code>.</li> <li><code>BatchSize</code>: 0.</li> </ul> </li> <li>Entradas:<ul> <li>Columnas transformadas y combinadas.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_31","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Excel Source\n    participant SQL as SQL Database\n\n    SSIS -&gt;&gt; Excel: Extrae datos de Sheet1$\n    SSIS -&gt;&gt; SSIS: Realiza transformaci\u00f3n derivada\n    SSIS -&gt;&gt; SQL: Realiza Lookup ID_ESTUDIANTE\n    SSIS -&gt;&gt; SSIS: Ordena datos\n    SSIS -&gt;&gt; SSIS: Combina flujos (Merge Join)\n    SSIS -&gt;&gt; SQL: Carga datos en FACT_COTIZACIONES</code></pre>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#restaurar-llaves-foraneas-esquema-cedesarrollo","title":"Restaurar llaves foraneas esquema Cedesarrollo","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#documentacion-xml-del-componente-restaurar-llaves-foraneas-esquema-cedesarrollo","title":"Documentaci\u00f3n XML del Componente \"Restaurar llaves for\u00e1neas esquema Cedesarrollo\"","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-general_34","title":"Descripci\u00f3n General","text":"<p>El componente Restaurar llaves for\u00e1neas esquema Cedesarrollo es una tarea de ejecuci\u00f3n de SQL en SSIS que se utiliza para restaurar las restricciones de clave for\u00e1nea dentro del esquema <code>Cedesarrollo</code>. Adem\u00e1s, este proceso limpia la tabla temporal <code>ForeignKeys_Cedesarrollo</code> al final de la ejecuci\u00f3n.</p>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#detalles-del-componente_2","title":"Detalles del Componente","text":"<ol> <li> <p>Tarea Ejecutar SQL</p> <ul> <li>Descripci\u00f3n: Ejecuta un script SQL que reconstruye las claves for\u00e1neas en el esquema <code>Cedesarrollo</code>.</li> <li>Conexi\u00f3n:</li> <li><code>ConnectionManagerID</code>: <code>{57F24C4D-9B0A-4EBB-AE46-43F9B341582B}</code> (Conexi\u00f3n al servidor SQL donde se encuentra el esquema <code>Cedesarrollo</code>).</li> <li>Propiedades:</li> <li><code>SqlStatementSource</code>: Contiene el siguiente script SQL:</li> </ul> <pre><code>-- Restaurar restricciones de clave for\u00e1nea para el esquema Cedesarrollo\nDECLARE @restoreSql_Cedesarrollo NVARCHAR(MAX) = '';\n\nSELECT @restoreSql_Cedesarrollo += 'ALTER TABLE ' + QUOTENAME('Cedesarrollo') + '.' + QUOTENAME(fk.TableName) \n    + ' ADD CONSTRAINT ' + QUOTENAME(fk.ConstraintName) \n    + ' FOREIGN KEY (' + QUOTENAME(fk.ColumnName) + ') REFERENCES ' \n    + QUOTENAME(\n        CASE \n            WHEN fk.ReferencedTableName IN ('DIM_AFILIADOS', 'DIM_APORTANTE_NOAFILIADO', 'DIM_BENEFICIARIOS', 'DIM_CAPACIDAD_FISICA', 'DIM_CATEGORIA', 'DIM_CUENTA_CONTABLE', 'DIM_EMPRESAS', 'DIM_INFRAESTRUCTURA_CCF', 'DIM_PERSONAL', 'DIM_SEDES', 'DIM_TARIFAS_SERVICIOS', 'DIM_UNIDAD', 'DIM_UNIDADES_ORGANIZATIVAS')\n            THEN 'Transversal'\n            WHEN fk.ReferencedTableName = 'DIM_TIEMPO' \n            THEN 'Dwh' \n            ELSE 'Cedesarrollo'\n        END\n    ) + '.' + QUOTENAME(fk.ReferencedTableName) \n    + '(' + QUOTENAME(fk.ReferencedColumnName) + '); '\nFROM dbo.ForeignKeys_Cedesarrollo;\n\n-- Ejecutamos el SQL para restaurar las llaves for\u00e1neas del esquema Cedesarrollo\nEXEC sp_executesql @restoreSql_Cedesarrollo;\n\n-- Limpiar la tabla persistente\nDROP TABLE dbo.ForeignKeys_Cedesarrollo;\n</code></pre> </li> </ol>"},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#diagrama-de-secuencia_32","title":"Diagrama de Secuencia","text":""},{"location":"02.Paquetes_SSIS/06-CEDESARROLLO_FACT/#descripcion-del-proceso","title":"Descripci\u00f3n del Proceso","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS -&gt;&gt; SQL: Declara variable @restoreSql_Cedesarrollo\n    SQL -&gt;&gt; SQL: Construye sentencias ALTER TABLE din\u00e1micamente\n    SQL -&gt;&gt; SQL: Ejecuta las sentencias con sp_executesql\n    SQL -&gt;&gt; SQL: Elimina la tabla temporal ForeignKeys_Cedesarrollo</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/","title":"07. PROTECCION_DIMENSIONES","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#proteccion_dimensiones","title":"PROTECCION_DIMENSIONES","text":"<p>El paquete SSIS \"07-PROTECCION_DIMENSIONES\" est\u00e1 dise\u00f1ado para gestionar flujos ETL que procesan datos cr\u00edticos relacionados con dimensiones de protecci\u00f3n, como preguntas y respuestas educativas, caracter\u00edsticas de campos y establecimientos educativos. Este paquete asegura un flujo de trabajo eficiente, consolidando datos desde m\u00faltiples fuentes y garantizando su integridad en el Data Warehouse <code>DWH_COMFENALCO</code>.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal del paquete es transformar y cargar datos clave para dimensiones educativas y de protecci\u00f3n social. Esto incluye validar informaci\u00f3n de campos, programas y encuestas, asegurando que los datos consolidados sean precisos, consistentes y preparados para an\u00e1lisis estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes utilizadas:<ul> <li>Archivos Excel: Informaci\u00f3n sobre preguntas, respuestas, programas y caracter\u00edsticas de campos.</li> <li>Bases de Datos: Validaci\u00f3n de registros en tablas maestras como <code>DIM_PROGRAMA</code>, <code>DIM_PREGUNTAS_EE_JEC</code> y <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>.</li> </ul> </li> <li>Conexiones configuradas:<ul> <li>Administradores OLE DB y ADO.NET.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Conversi\u00f3n de Datos (<code>Data Conversion</code>):<ul> <li>Asegura compatibilidad de tipos entre columnas de entrada y destino.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Garantiza consistencia mediante b\u00fasquedas en tablas maestras.</li> </ul> </li> <li>Clasificaci\u00f3n (<code>Conditional Split</code>):<ul> <li>Filtra registros v\u00e1lidos y redirige no v\u00e1lidos.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas destino:<ul> <li><code>DIM_CAMPOS_CARACT</code></li> <li><code>DIM_PROGRAMA</code></li> <li><code>DIM_PREGUNTAS_EE_JEC</code></li> <li><code>DIM_RESPUESTAS_EE_JEC</code></li> <li><code>DIM_ESTABLECIMIENTO_EDUCATIVO</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para optimizar la carga.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Integraci\u00f3n de scripts Python para automatizar descargas desde SharePoint y procesar datos.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>DIM_CAMPOS_CARACT:</p> <ul> <li><code>ID_CARACTERISTICA</code>: Identificador \u00fanico.</li> <li><code>PREGUNTA</code>: Texto de la pregunta.</li> <li><code>OBSERVACIONES</code>: Informaci\u00f3n adicional.</li> </ul> </li> <li> <p>DIM_PROGRAMA:</p> <ul> <li><code>ID_PROGRAMA</code>: Identificador del programa.</li> <li><code>NOMBRE_PROGRAMA</code>: Descripci\u00f3n del programa.</li> </ul> </li> <li> <p>DIM_PREGUNTAS_EE_JEC:</p> <ul> <li><code>ID_PREGUNTA</code>: Identificador \u00fanico.</li> <li><code>PREGUNTA</code>: Texto de la pregunta.</li> <li><code>ID_PROGRAMA</code>: Relaci\u00f3n con el programa.</li> </ul> </li> <li> <p>DIM_RESPUESTAS_EE_JEC:</p> <ul> <li><code>ID_RESPUESTA</code>: Identificador \u00fanico.</li> <li><code>RESPUESTA</code>: Texto de la respuesta.</li> <li><code>ID_PREGUNTA</code>: Relaci\u00f3n con la pregunta.</li> </ul> </li> <li> <p>DIM_ESTABLECIMIENTO_EDUCATIVO:</p> <ul> <li><code>ID_ESTABLECIMIENTO</code>: Identificador \u00fanico.</li> <li><code>NOMBRE_ESTABLECIMIENTO</code>: Nombre del establecimiento.</li> <li><code>REPRESENTANTE_LEGAL</code>: Persona responsable.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagramas","title":"Diagramas","text":"<ol> <li>Diagrama de Flujo de Datos (Data Flow Diagram - DFD)</li> </ol> <pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant Excel as Fuente de Excel\n    participant DB as Base de Datos\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; Excel: Extraer datos de campos, programas y preguntas\n    SSIS -&gt;&gt; DB: Validar registros en tablas maestras\n    SSIS -&gt;&gt; Python: Ejecutar scripts para extracci\u00f3n desde SharePoint\n    SSIS -&gt;&gt; DWH: Cargar datos procesados en tablas destino</code></pre> <ol> <li>Diagrama de Transformaciones y Validaciones</li> </ol> <pre><code>graph TD\n    A1[Datos de Campos y Programas] --&gt; T1[Conversi\u00f3n de Datos]\n    A2[Preguntas y Respuestas] --&gt; T2[Lookup: Validar Preguntas]\n    T1 --&gt; T3[Clasificaci\u00f3n por Condicional Split]\n    T2 --&gt; L1[Lookup: Validar Respuestas]\n    T3 --&gt; C1[Cargar datos validados]</code></pre> <ol> <li>Diagrama ER para Tablas de Dimensiones</li> </ol> <pre><code>erDiagram\n    DIM_CAMPOS_CARACT {\n        int ID_CARACTERISTICA\n        string PREGUNTA\n        string OBSERVACIONES\n    }\n    DIM_PROGRAMA {\n        int ID_PROGRAMA\n        string NOMBRE_PROGRAMA\n    }\n    DIM_PREGUNTAS_EE_JEC {\n        int ID_PREGUNTA\n        string PREGUNTA\n        int ID_PROGRAMA\n    }\n    DIM_RESPUESTAS_EE_JEC {\n        int ID_RESPUESTA\n        string RESPUESTA\n        int ID_PREGUNTA\n    }\n    DIM_ESTABLECIMIENTO_EDUCATIVO {\n        int ID_ESTABLECIMIENTO\n        string NOMBRE_ESTABLECIMIENTO\n        string REPRESENTANTE_LEGAL\n    }\n    DIM_PROGRAMA ||--|| DIM_PREGUNTAS_EE_JEC : \"Asociado a programas\"\n    DIM_PREGUNTAS_EE_JEC ||--|| DIM_RESPUESTAS_EE_JEC : \"Relaci\u00f3n Pregunta-Respuesta\"\n    DIM_ESTABLECIMIENTO_EDUCATIVO ||--|| DIM_PROGRAMA : \"Conexi\u00f3n con programas\"</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-ejecucion-etls","title":"Componente <code>Ejecuci\u00f3n ETLs</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>Este componente ejecuta un proceso Python encargado de la conexi\u00f3n y extracci\u00f3n de datos desde SharePoint para la carpeta espec\u00edfica <code>Protecci\u00f3n</code>, ubicada dentro de la estructura de archivos del proyecto. Es parte del flujo de automatizaci\u00f3n de ETL en un paquete de SSIS.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ul> <li> <p>Descripci\u00f3n: Este componente utiliza una tarea de tipo <code>Execute Process Task</code> en SSIS para invocar un script Python que se encuentra dentro del entorno virtual configurado para el proyecto.</p> </li> <li> <p>Propiedades:</p> <ul> <li> <p>Executable:      <pre><code>@[$Project::Working_Directory]+ \"COMFENALCO_EDUCACION\\\\01.Scripts\\\\Utils\\\\env\\\\Scripts\\\\python.exe\"\n</code></pre>     Especifica la ruta al ejecutable de Python dentro del entorno virtual del proyecto.</p> </li> <li> <p>WorkingDirectory:     <pre><code>@[$Project::Working_Directory] +\"COMFENALCO_EDUCACION\\\\01.Scripts\\\\03.Archivos_Manuales\\\\03.Proteccion\"\n</code></pre>     Define el directorio de trabajo donde se encuentra el script Python.</p> </li> <li> <p>Arguments:      <pre><code>SharePoint_Connection_Proteccion.py\n</code></pre>     Indica el script que ser\u00e1 ejecutado para conectar y procesar los datos de SharePoint.</p> </li> <li> <p>TimeOut:     <pre><code>@[$Project::Tiempo_Espera_Segundos]\n</code></pre>     Configura el tiempo m\u00e1ximo de espera en segundos para que el proceso se complete, definido en 600 segundos (10 minutos).</p> </li> </ul> </li> </ul>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo-del-proceso","title":"Diagrama de Flujo del Proceso","text":"<p>El siguiente diagrama ilustra el flujo de ejecuci\u00f3n para el componente Ejecuci\u00f3n ETLs:</p> <pre><code>graph TD\n    A[Inicio del proceso] --&gt; B[Obtener ruta del ejecutable Python]\n    B --&gt; C[Definir directorio de trabajo]\n    C --&gt; D[Ejecutar script SharePoint_Connection_Proteccion.py]\n    D --&gt; E[Esperar a la finalizaci\u00f3n del proceso Timeout: 600 seg]\n    E --&gt; F[\u00bfProceso completado exitosamente?]\n    F --&gt; G[Registrar \u00e9xito en logs]:::success\n    F --&gt; H[Registrar error y abortar]:::error\n    G --&gt; I[Fin del proceso]\n    H --&gt; I</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_campos_caract","title":"Componente <code>Data DIM_CAMPOS_CARACT</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_CAMPOS_CARACT forma parte de un flujo ETL desarrollado en SSIS para cargar y transformar datos relacionados con las caracter\u00edsticas de campos en la tabla <code>DIM_CAMPOS_CARACT</code> dentro del esquema <code>Protecci\u00f3n</code>. Este proceso incluye la lectura de datos desde un archivo Excel, conversi\u00f3n de datos, validaci\u00f3n mediante un componente de tipo Lookup, y finalmente, la carga en la base de datos de destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Conecta y extrae datos desde una hoja llamada <code>Sheet1$</code> en un archivo Excel, con columnas <code>PREGUNTA</code> y <code>OBSERVACIONES</code>.</li> <li>Propiedades:<ul> <li>AccessMode: 0 (por tabla u objeto).</li> <li>Hoja seleccionada: <code>Sheet1$</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Convierte los datos extra\u00eddos a un formato compatible con los siguientes componentes del flujo.</li> <li>Columnas Convertidas:<ul> <li><code>PREGUNTA</code> \u2192 <code>Copy of PREGUNTA</code>.</li> <li><code>OBSERVACIONES</code> \u2192 <code>Copy of OBSERVACIONES</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida y enriquece los datos mediante la b\u00fasqueda de correspondencias en la tabla destino <code>DIM_CAMPOS_CARACT</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_CAMPOS_CARACT]\nWHERE [PREGUNTA] = ?\n</code></pre></li> <li>Columnas Salida:<ul> <li><code>PREGUNTA_</code>.</li> <li><code>OBSERVACIONES_</code>.</li> <li><code>ID_PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados y validados en la tabla <code>DIM_CAMPOS_CARACT</code> dentro del esquema <code>Protecci\u00f3n</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (tama\u00f1o predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva si es posible).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el flujo completo de datos del componente Data DIM_CAMPOS_CARACT:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Conversi\u00f3n de datos]\n    C --&gt; D[Validaci\u00f3n mediante Lookup]\n    D --&gt; E{\u00bfCoincidencia encontrada?}\n    E -- S\u00ed --&gt; F[Cargar datos en ADO NET Destination]\n    E -- No --&gt; G[Registrar datos no coincidentes]\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_programa","title":"Componente <code>Data DIM_PROGRAMA</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>El componente Data DIM_PROGRAMA forma parte de un flujo ETL que carga y transforma datos relacionados con programas en la tabla <code>DIM_PROGRAMA</code> del esquema <code>Protecci\u00f3n</code>. El flujo procesa datos desde un archivo Excel, realiza validaciones, y los carga en una base de datos de destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae los datos de un archivo Excel, espec\u00edficamente de una hoja llamada <code>Sheet1$</code>.</li> <li>Columnas de entrada:<ul> <li><code>ID_PROGRAMA</code></li> <li><code>PROGRAMA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura desde tabla u objeto definido).</li> <li>Hoja seleccionada: <code>Sheet1$</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Convierte las columnas extra\u00eddas a formatos compatibles para la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>PROGRAMA</code> \u2192 <code>Copy of PROGRAMA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n (Lookup):</p> <ul> <li>Descripci\u00f3n: Verifica si las filas coinciden con registros existentes en la tabla destino <code>DIM_PROGRAMA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PROGRAMA]\nWHERE [PROGRAMA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia: Los datos se procesan.</li> <li>Sin coincidencia: Los datos se redirigen para manejo adicional.</li> </ul> </li> </ul> </li> <li> <p>Destino (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>DIM_PROGRAMA</code> del esquema <code>Protecci\u00f3n</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (por defecto).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva si es posible).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_1","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el flujo completo de datos del componente Data DIM_PROGRAMA:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Conversi\u00f3n de Datos]\n    C --&gt; D[Validaci\u00f3n mediante Lookup]\n    D --&gt; E{\u00bfCoincidencia encontrada?}\n    E -- S\u00ed --&gt; F[Cargar datos en ADO NET Destination]\n    E -- No --&gt; G[Manejo de filas no coincidentes]\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_preguntas_ee_jec","title":"Componente <code>Data DIM_PREGUNTAS_EE_JEC</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>Este componente gestiona un flujo de datos ETL que extrae preguntas relacionadas con ejecuci\u00f3n de eventos educativos desde un archivo Excel y las procesa para ser almacenadas en la tabla <code>DIM_PREGUNTAS_EE_JEC</code> del esquema <code>Protecci\u00f3n</code>. Incluye validaciones, transformaciones, y manejo de datos no coincidentes.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae los datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PROGRAMA</code></li> <li><code>PREGUNTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde una hoja).</li> <li>Conexi\u00f3n: Administrador de conexiones <code>Excel_Connection_Dim_Preguntas_JEC</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Programas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida los programas en los datos de entrada con los registros existentes en <code>DIM_PROGRAMA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PROGRAMA]\nWHERE [PROGRAMA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia encontrada: Asocia el <code>ID_PROGRAMA</code>.</li> <li>Sin coincidencia: Redirige a la etapa de conversi\u00f3n de datos.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas extra\u00eddas (<code>PREGUNTA</code>) a un formato compatible con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>PREGUNTA</code> \u2192 <code>Copy of PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup):</p> <ul> <li>Descripci\u00f3n: Verifica si las preguntas existen en la tabla destino <code>DIM_PREGUNTAS_EE_JEC</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_JEC]\nWHERE [PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>DIM_PREGUNTAS_EE_JEC</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_2","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el flujo completo del componente Data DIM_PREGUNTAS_EE_JEC:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n de Programas Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Preguntas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_respuesta_ee_jec","title":"Componente <code>Data DIM_RESPUESTA_EE_JEC</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos procesa respuestas asociadas a preguntas de encuestas educativas (<code>DIM_RESPUESTA_EE_JEC</code>). Las respuestas se extraen de un archivo Excel, se validan con las tablas existentes y se cargan en la base de datos destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PREGUNTA</code></li> <li><code>RESPUESTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde la hoja).</li> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_Respuestas_JEC</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida que las preguntas existan en <code>DIM_PREGUNTAS_EE_JEC</code> y asigna el <code>ID_PREGUNTA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_JEC]\nWHERE [PREGUNTA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia encontrada: Asocia el <code>ID_PREGUNTA</code>.</li> <li>Sin coincidencia: Redirige al flujo de transformaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas de texto para compatibilidad con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>RESPUESTA</code> \u2192 <code>Copy of RESPUESTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Respuestas (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida que las respuestas no est\u00e9n duplicadas en <code>DIM_RESPUESTAS_EE_JEC</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_RESPUESTAS_EE_JEC]\nWHERE [RESPUESTA] = ? AND [ID_PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga las respuestas validadas y procesadas en <code>DIM_RESPUESTAS_EE_JEC</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_3","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama muestra el proceso completo del flujo de datos:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n de Preguntas Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Respuestas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_preguntas_aipi","title":"Componente <code>Data DIM_PREGUNTAS_AIPI</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos carga preguntas relacionadas con el programa AIPI en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code>. El proceso incluye validaci\u00f3n, transformaci\u00f3n de datos y carga en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PROGRAMA</code></li> <li><code>PREGUNTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde la hoja).</li> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_Preguntas_AIPI</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n del Programa (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida que el programa asociado a la pregunta exista en la tabla <code>DIM_PROGRAMA</code> y asigna el <code>ID_PROGRAMA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PROGRAMA]\nWHERE [PROGRAMA] = ?\n</code></pre></li> <li>Salida:<ul> <li>Coincidencia encontrada: Asocia el <code>ID_PROGRAMA</code>.</li> <li>Sin coincidencia: Redirige al flujo de transformaci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas para compatibilidad con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>PREGUNTA</code> \u2192 <code>Copy of PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida que las preguntas no est\u00e9n duplicadas en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_AIPI]\nWHERE [PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga las preguntas validadas y procesadas en <code>DIM_PREGUNTAS_EE_AIPI</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_4","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el proceso:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n del Programa Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Preguntas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_respuesta_aipi","title":"Componente <code>Data DIM_RESPUESTA_AIPI</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos realiza la carga de respuestas relacionadas con el programa AIPI en la tabla <code>DIM_RESPUESTAS_EE_AIPI</code>. El proceso incluye validaci\u00f3n, conversi\u00f3n de datos y carga en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>PREGUNTA</code></li> <li><code>RESPUESTA</code></li> </ul> </li> <li>Propiedades:<ul> <li>AccessMode: 0 (lectura directa desde la hoja).</li> <li>Conexi\u00f3n: <code>Excel_Connection_Respuesta_AIPI</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Preguntas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Valida que la pregunta asociada a la respuesta exista en la tabla <code>DIM_PREGUNTAS_EE_AIPI</code> y asigna el <code>ID_PREGUNTA</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_PREGUNTAS_EE_AIPI]\nWHERE [PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Transforma las columnas para compatibilidad con la base de datos destino.</li> <li>Columnas Convertidas:<ul> <li><code>RESPUESTA</code> \u2192 <code>Copy of RESPUESTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Respuestas (Lookup):</p> <ul> <li>Descripci\u00f3n: Valida que las respuestas no est\u00e9n duplicadas en la tabla <code>DIM_RESPUESTAS_EE_AIPI</code>.</li> <li>SQL de Consulta:     <pre><code>SELECT * \nFROM [Proteccion].[DIM_RESPUESTAS_EE_AIPI]\nWHERE [RESPUESTA] = ? AND [ID_PREGUNTA] = ?\n</code></pre></li> </ul> </li> <li> <p>Destino de Datos (ADO NET Destination):</p> <ul> <li>Descripci\u00f3n: Carga las respuestas validadas y procesadas en <code>DIM_RESPUESTAS_EE_AIPI</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (valor predeterminado).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code> (usa inserci\u00f3n masiva).</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_5","title":"Diagrama de Flujo","text":"<p>El siguiente diagrama ilustra el proceso:</p> <pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n de Preguntas Lookup 1]\n    C -- Coincidencia encontrada --&gt; D[Validaci\u00f3n de Respuestas Lookup]\n    C -- Sin coincidencia --&gt; E[Conversi\u00f3n de Datos]\n    D -- Coincidencia encontrada --&gt; F[Cargar datos en ADO NET Destination]\n    D -- Sin coincidencia --&gt; G[Manejo de filas no coincidentes]\n    E --&gt; F\n    F --&gt; H[Fin]\n    G --&gt; H</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-dim_poblacion","title":"Componente <code>Data DIM_POBLACION</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>Este componente procesa y carga informaci\u00f3n sobre la poblaci\u00f3n en la tabla <code>DIM_POBLACION</code>. El flujo incluye pasos de transformaci\u00f3n de datos, validaci\u00f3n de referencias con otras tablas, y la carga de datos procesados en un destino ADO.NET.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Lee los datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> </ul> </li> <li>Propiedades:<ul> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_Poblacion</code>.</li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos (Data Conversion):</p> <ul> <li>Descripci\u00f3n: Realiza la transformaci\u00f3n de las columnas para ajustarse a los requisitos del destino.</li> <li>Columnas Convertidas:<ul> <li><code>DOCUMENTO</code> \u2192 <code>Copy of DOCUMENTO</code></li> <li><code>TIPO_DOCUMENTO</code> \u2192 <code>Copy of TIPO_DOCUMENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Empresas (Lookup 1):</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_EMPRESA</code> en la tabla <code>DIM_EMPRESAS</code> a partir de los datos <code>DOCUMENTO</code> y <code>TIPO_DOCUMENTO</code>.</li> </ul> </li> <li> <p>Validaci\u00f3n de Afiliados (Lookup 2):</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_AFILIADO</code> en la tabla <code>DIM_AFILIADOS</code> a partir de los datos <code>DOCUMENTO</code> y <code>TIPO_DOCUMENTO</code>.</li> </ul> </li> <li> <p>Validaci\u00f3n de Beneficiarios (Lookup 3):</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_BENEFICIARIO</code> en la tabla <code>DIM_BENEFICIARIOS</code>.</li> </ul> </li> <li> <p>Validaci\u00f3n de Aportantes (Lookup 4):</p> <ul> <li>Descripci\u00f3n: Busca el <code>ID_APORTANTE</code> en la tabla <code>DIM_APORTANTE_NOAFILIADO</code>.</li> </ul> </li> <li> <p>Carga de Datos (ADO.NET Destination):</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados y validados en la tabla <code>DIM_POBLACION</code>.</li> <li>Propiedades:<ul> <li>BatchSize: 0 (por defecto).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_6","title":"Diagrama de Flujo","text":"<pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Conversi\u00f3n de Datos]\n    C --&gt; D[Validaci\u00f3n de Empresas Lookup 1]\n    D --&gt; E[Validaci\u00f3n de Afiliados Lookup 2]\n    E --&gt; F[Validaci\u00f3n de Beneficiarios Lookup 3]\n    F --&gt; G[Validaci\u00f3n de Aportantes Lookup 4]\n    G --&gt; H[Carga de Datos en ADO.NET Destination]\n    H --&gt; I[Fin]</code></pre>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componente-data-establecimiento_educativo","title":"Componente <code>Data ESTABLECIMIENTO_EDUCATIVO</code>","text":""},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Este componente procesa informaci\u00f3n relacionada con establecimientos educativos y la carga en la tabla <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>. El flujo asegura que los datos sean validados y transformados antes de insertarse en el destino.</p>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Fuente de Datos (Excel Source):</p> <ul> <li>Descripci\u00f3n: Extrae los datos desde un archivo Excel (<code>Sheet1$</code>).</li> <li>Columnas de Entrada:<ul> <li><code>NOMBRE_ESTABLECIMIENTO</code></li> <li><code>REPRESENTANTE_LEGAL</code></li> <li><code>DIRECCION</code></li> <li><code>MUNICIPIO</code></li> </ul> </li> <li>Propiedades:<ul> <li>Conexi\u00f3n: <code>Excel_Connection_Dim_EE</code>.</li> </ul> </li> </ul> </li> <li> <p>Validaci\u00f3n de Datos (Lookup):</p> <ul> <li>Descripci\u00f3n: Busca si los registros ya existen en la tabla <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code> para evitar duplicados.</li> <li>Condiciones de B\u00fasqueda:<ul> <li><code>NOMBRE_ESTABLECIMIENTO</code></li> <li><code>REPRESENTANTE_LEGAL</code></li> <li><code>DIRECCION</code></li> <li><code>MUNICIPIO</code>.</li> </ul> </li> <li>Salida:<ul> <li>Filas coincidentes se eliminan del flujo.</li> <li>Filas no coincidentes contin\u00faan hacia el destino.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos (ADO.NET Destination):</p> <ul> <li>Descripci\u00f3n: Inserta los datos validados y \u00fanicos en la tabla <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>.</li> <li>Columnas de Entrada:<ul> <li><code>NOMBRE_ESTABLECIMIENTO</code></li> <li><code>REPRESENTANTE_LEGAL</code></li> <li><code>DIRECCION</code></li> <li><code>MUNICIPIO</code>.</li> </ul> </li> <li>Propiedades:<ul> <li>BatchSize: 0 (por defecto).</li> <li>CommandTimeout: 30 segundos.</li> <li>UseBulkInsertWhenPossible: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/07-PROTECCION_DIMENSIONES/#diagrama-de-flujo_7","title":"Diagrama de Flujo","text":"<pre><code>graph TD\n    A[Inicio] --&gt; B[Lectura desde Excel Source]\n    B --&gt; C[Validaci\u00f3n con Lookup]\n    C --&gt;|No Coincide| D[Carga en ADO.NET Destination]\n    C --&gt;|Coincide| E[Descartar Registros]\n    D --&gt; F[Fin]\n    E --&gt; F</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/","title":"08. PROTECCION_FACT","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#proteccion_fact","title":"PROTECCION_FACT","text":"<p>El paquete SSIS \"08-PROTECCION_FACT\" est\u00e1 dise\u00f1ado para procesar, transformar y cargar informaci\u00f3n cr\u00edtica relacionada con operaciones de protecci\u00f3n social, como caracterizaci\u00f3n de beneficiarios, diagn\u00f3sticos, entregas de materiales, y visitas de seguimiento. Este paquete consolida datos de m\u00faltiples fuentes en el Data Warehouse <code>DWH_COMFENALCO</code>, asegurando su calidad, consistencia y disponibilidad para an\u00e1lisis y reportes estrat\u00e9gicos.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#proposito-del-paquete","title":"Prop\u00f3sito del Paquete","text":"<p>El objetivo principal es integrar datos operativos de protecci\u00f3n, asegurando su integridad y estructuraci\u00f3n para apoyar an\u00e1lisis avanzados y toma de decisiones en el \u00e1mbito social y educativo.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<ol> <li> <p>Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Archivos Planos:</li> <li><code>FACT_CARACTERIZACION</code>, <code>FACT_DIAGNOSTICOS_EE_JEC</code>, <code>FACT_ENTREGA_MATERIAL</code>.</li> <li>Bases de Datos Relacionales:</li> <li><code>DIM_TIEMPO</code>, <code>DIM_POBLACION</code>, <code>DIM_PROGRAMA</code>, entre otros.</li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones OLE DB y ADO.NET para integraci\u00f3n.</li> </ul> </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:</p> <ul> <li>Validaciones (<code>Lookup</code>):<ul> <li>Comparaci\u00f3n de datos con tablas maestras para enriquecer informaci\u00f3n, como <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code> y <code>DIM_PREGUNTAS_EE_JEC</code>.</li> </ul> </li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Garantiza compatibilidad de datos con tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Generaci\u00f3n de claves \u00fanicas y valores predefinidos.</li> </ul> </li> </ul> </li> <li> <p>Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>FACT_CARACTERIZACION</code></li> <li><code>FACT_DIAGNOSTICOS_EE_JEC</code></li> <li><code>FACT_ENTREGA_MATERIAL</code></li> <li><code>FACT_VISITAS</code></li> <li><code>FACT_DESERCION</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para mejorar el rendimiento.</li> </ul> </li> </ul> </li> <li> <p>Automatizaci\u00f3n y Scripts:</p> <ul> <li>Uso de scripts SQL din\u00e1micos para restaurar claves for\u00e1neas y garantizar integridad referencial.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<ol> <li> <p>FACT_CARACTERIZACION:</p> <ul> <li><code>ID_POBLACION</code>, <code>ID_PROGRAMA</code>, <code>ID_FECHA</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>.</li> </ul> </li> <li> <p>FACT_DIAGNOSTICOS_EE_JEC:</p> <ul> <li><code>ID_FECHA</code>, <code>ID_PREGUNTA</code>, <code>ID_RESPUESTA</code>, <code>ID_REGISTRO</code>.</li> </ul> </li> <li> <p>FACT_ENTREGA_MATERIAL:</p> <ul> <li><code>ID_FECHA_ENTREGA</code>, <code>ID_MATERIAL</code>, <code>ID_PERSONAL</code>, <code>CANTIDAD_MATERIAL</code>.</li> </ul> </li> <li> <p>FACT_VISITAS:</p> <ul> <li><code>ID_FECHA</code>, <code>ID_PROGRAMA</code>, <code>MUNICIPIO</code>, <code>FECHA_PLANEADA</code>, <code>FECHA_EJECUTADA</code>.</li> </ul> </li> <li> <p>FACT_DESERCION:</p> <ul> <li><code>ID_ESTABLECIMIENTO_EDUCATIVO</code>, <code>ID_POBLACION</code>, <code>ID_FECHA_REGISTRO</code>, <code>PROGRAMA</code>, <code>CAUSA</code>.</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagramas","title":"Diagramas","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant DB as Base de Datos\n    participant Excel as Archivos Planos\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; DB: Extraer datos de dimensiones clave\n    SSIS -&gt;&gt; Excel: Leer datos desde archivos planos\n    SSIS -&gt;&gt; Python: Restaurar claves for\u00e1neas\n    SSIS -&gt;&gt; DWH: Cargar datos procesados</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#2-diagrama-er-para-tablas-de-hechos","title":"2. Diagrama ER para Tablas de Hechos","text":"<pre><code>erDiagram\n    FACT_CARACTERIZACION {\n        int ID_POBLACION\n        int ID_PROGRAMA\n        int ID_FECHA\n        string TIPO_DOCUMENTO\n        string DOCUMENTO\n    }\n    FACT_DIAGNOSTICOS_EE_JEC {\n        int ID_FECHA\n        int ID_PREGUNTA\n        int ID_RESPUESTA\n        int ID_REGISTRO\n    }\n    FACT_ENTREGA_MATERIAL {\n        int ID_FECHA_ENTREGA\n        int ID_MATERIAL\n        int ID_PERSONAL\n        float CANTIDAD_MATERIAL\n    }\n    FACT_VISITAS {\n        int ID_FECHA\n        int ID_PROGRAMA\n        string MUNICIPIO\n        date FECHA_PLANEADA\n        date FECHA_EJECUTADA\n    }\n    FACT_DESERCION {\n        int ID_ESTABLECIMIENTO_EDUCATIVO\n        int ID_POBLACION\n        int ID_FECHA_REGISTRO\n        string PROGRAMA\n        string CAUSA\n    }\n    FACT_CARACTERIZACION ||--|| FACT_DIAGNOSTICOS_EE_JEC : \"Relaci\u00f3n por poblaci\u00f3n\"\n    FACT_ENTREGA_MATERIAL ||--|| FACT_VISITAS : \"Asociaci\u00f3n por programa\"\n    FACT_DESERCION ||--|| FACT_VISITAS : \"Conexi\u00f3n por registro\"</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes","title":"Componentes","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-procesar-fact_caracterizacion","title":"Componente <code>Procesar FACT_CARACTERIZACION</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El componente FACT_CARACTERIZACION realiza un flujo de procesamiento ETL que carga datos desde un archivo plano, realiza conversiones, aplica transformaciones <code>Lookup</code> para enriquecer los datos con informaci\u00f3n adicional desde tablas externas y finalmente almacena los resultados en una base de datos relacional. Este proceso asegura la integraci\u00f3n de m\u00faltiples fuentes y formatos de datos en una estructura unificada.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source Descripci\u00f3n:     Carga datos desde un archivo plano con columnas como <code>FECHA</code>, <code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, entre otros.</p> <p>Propiedades: - RetainNulls: <code>false</code> - FileNameColumnName: No especificado.</p> </li> <li> <p>Data Conversion Descripci\u00f3n:     Convierte los datos de entrada a tipos requeridos para el procesamiento posterior.</p> <p>Propiedades: - Conversi\u00f3n de columnas como <code>FECHA</code> (a <code>dbTimeStamp</code>) y otras cadenas (<code>wstr</code>) con especificaci\u00f3n de longitud.</p> </li> <li> <p>Lookup (DIM_TIEMPO) Descripci\u00f3n:     Realiza un cruce con la dimensi\u00f3n de tiempo para obtener <code>ID_FECHA</code>.</p> <p>Propiedades: - SQL Command: <code>select * from [Dwh].[DIM_TIEMPO]</code>.</p> </li> <li> <p>Lookup (DIM_POBLACION) Descripci\u00f3n:     Asocia <code>TIPO_DOCUMENTO</code> y <code>DOCUMENTO</code> con el <code>ID_POBLACION</code>.</p> <p>Propiedades: - SQL Command: <code>select * from [Proteccion].[DIM_POBLACION]</code>.</p> </li> <li> <p>Lookup (DIM_PROGRAMA) Descripci\u00f3n:     Relaciona los datos de <code>PROGRAMA</code> con <code>ID_PROGRAMA</code>.</p> <p>Propiedades: - SQL Command: <code>select * from [Proteccion].[DIM_PROGRAMA]</code>.</p> </li> <li> <p>Destino ADO.NET Descripci\u00f3n:     Inserta los datos finales en la tabla <code>FACT_CARACTERIZACION</code> de la base de datos de destino.</p> <p>Propiedades: - Tabla: <code>\"Proteccion\".\"FACT_CARACTERIZACION\"</code>.</p> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant FlatFileSource as Flat File Source\n    participant DataConversion as Data Conversion\n    participant LookupTime as Lookup (DIM_TIEMPO)\n    participant LookupPopulation as Lookup (DIM_POBLACION)\n    participant AdoNetDestination as Destino ADO.NET\n\n    FlatFileSource -&gt;&gt; DataConversion: Procesar datos del archivo\n    DataConversion -&gt;&gt; LookupTime: Cruzar con DIM_TIEMPO\n    LookupTime -&gt;&gt; LookupPopulation: Cruzar con DIM_POBLACION\n    LookupPopulation -&gt;&gt; AdoNetDestination: Cargar datos transformados</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-procesar-fact_diagnosticos_ee_jec","title":"Componente <code>Procesar FACT_DIAGNOSTICOS_EE_JEC</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente FACT_DIAGNOSTICOS_EE_JEC es una tarea de flujo de datos en SSIS dise\u00f1ada para cargar datos desde un archivo plano en la tabla de hechos <code>FACT_DIAGNOSTICOS_EE_JEC</code>. Incluye conversiones de datos, transformaciones de b\u00fasqueda y validaciones previas al almacenamiento en el destino final.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source</p> <ul> <li>Descripci\u00f3n: Lee datos de un archivo plano configurado con el administrador de conexiones <code>Csv_Connection_Fact_Diagnosticos_EE_JEC</code>.</li> <li>Propiedades:<ul> <li>RetainNulls: <code>false</code></li> <li>FileNameColumnName: No especificado.</li> </ul> </li> <li>Columnas de salida:<ul> <li><code>FECHA</code>, <code>PROGRAMA</code>, <code>PREGUNTA</code>, <code>RESPUESTA</code>, <code>ID_REGISTRO</code>, entre otros.</li> </ul> </li> <li>Errores:<ul> <li>Columnas de error incluyen <code>ErrorCode</code> y <code>ErrorColumn</code>.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos de entrada a los formatos requeridos para el procesamiento y almacenamiento.</li> <li>Columnas convertidas:<ul> <li><code>Copy of ID_REGISTRO</code>, <code>Copy of FECHA_HORA_INICIO</code>, <code>Copy of FECHA_HORA_FIN</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_TIEMPO)</p> <ul> <li>Descripci\u00f3n: Realiza b\u00fasquedas en la dimensi\u00f3n <code>DIM_TIEMPO</code> para recuperar el <code>ID_FECHA</code> basado en la columna <code>FECHA</code>.</li> <li>SQL de referencia: <code>SELECT * FROM [Dwh].[DIM_TIEMPO]</code></li> <li>Propiedades:<ul> <li>CacheType: Completo.</li> <li>NoMatchBehavior: Fallar en ausencia de coincidencias.</li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_PREGUNTAS_EE_JEC)</p> <ul> <li>Descripci\u00f3n: Asocia cada pregunta con su identificador \u00fanico en la tabla <code>DIM_PREGUNTAS_EE_JEC</code>.</li> <li>SQL de referencia: <code>SELECT * FROM [Proteccion].[DIM_PREGUNTAS_EE_JEC]</code></li> <li>Columnas clave:<ul> <li><code>Copy of PREGUNTA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup (DIM_RESPUESTAS_EE_JEC)</p> <ul> <li>Descripci\u00f3n: Identifica las respuestas mediante las columnas <code>RESPUESTA</code> y <code>ID_PREGUNTA</code>.</li> <li>SQL de referencia: <code>SELECT * FROM [Proteccion].[DIM_RESPUESTAS_EE_JEC]</code></li> </ul> </li> <li> <p>Destino de ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos transformados y validados en la tabla <code>FACT_DIAGNOSTICOS_EE_JEC</code> en el servidor de base de datos.</li> <li>Propiedades:<ul> <li>TableOrViewName: <code>\"Proteccion\".\"FACT_DIAGNOSTICOS_EE_JEC\"</code></li> <li>UseBulkInsertWhenPossible: <code>true</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A[Flat File Source] --&gt; B[Data Conversion]\n    B --&gt; C[Lookup DIM_TIEMPO]\n    C --&gt; D[Lookup DIM_PREGUNTAS_EE_JEC]\n    D --&gt; E[Lookup DIM_RESPUESTAS_EE_JEC]\n    E --&gt; F[ADO NET Destination]</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-procesar-fact_diagnosticos_ee_aipi","title":"Componente <code>Procesar FACT_DIAGNOSTICOS_EE_AIPI</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos extrae informaci\u00f3n desde un archivo plano, realiza transformaciones para cumplir con los requerimientos de integridad y formato, realiza b\u00fasquedas en tablas de referencia para enriquecer los datos y finalmente los carga en una tabla destino en SQL Server.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source</p> <ul> <li>Descripci\u00f3n: Este componente carga datos desde un archivo plano (texto) y los env\u00eda al flujo de datos para transformarlos y procesarlos.</li> <li>Propiedades:<ul> <li>RetainNulls: <code>False</code> (No retiene valores nulos de origen).</li> <li>Columns: Define las columnas a extraer, incluyendo:<ul> <li>\"ESTABLECIMIENTO EDUCATIVO\" (wstr, 255)</li> <li>\"NOMBRE_SEDE\" (wstr, 255)</li> <li>\"MUNICIPIO\" (wstr, 255)</li> <li>\"ENTIDAD_ADMINISTRADORA\" (wstr, 255)</li> <li>\"DIRECCION\" (wstr, 300)</li> <li>\"FECHA\" (dbTimestamp).</li> </ul> </li> <li>Formato de archivo: Delimitado por comas o tabulaciones (dependiendo de la configuraci\u00f3n espec\u00edfica del archivo).</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Realiza conversiones de datos para asegurar que las columnas tengan el tipo y formato adecuado.</li> <li>Propiedades:<ul> <li>Convierte las siguientes columnas:<ul> <li>\"ESTABLECIMIENTO EDUCATIVO\" a \"Copy of ESTABLECIMIENTO EDUCATIVO\" (wstr, 255).</li> <li>\"NOMBRE_SEDE\" a \"Copy of NOMBRE_SEDE\" (wstr, 255).</li> <li>\"MUNICIPIO\" a \"Copy of MUNICIPIO\" (wstr, 255).</li> <li>\"ENTIDAD_ADMINISTRADORA\" a \"Copy of ENTIDAD_ADMINISTRADORA\" (wstr, 255).</li> <li>\"DIRECCION\" a \"Copy of DIRECCION\" (wstr, 300).</li> <li>\"FECHA\" a \"Copy of FECHA\" (dbTimestamp).</li> </ul> </li> <li>Error Row Disposition: <code>Fail Component</code> (El proceso falla si hay un error en la conversi\u00f3n).</li> </ul> </li> </ul> </li> <li> <p>Lookup Transformations</p> <ul> <li>Descripci\u00f3n: Realiza b\u00fasquedas en tablas de referencia para enriquecer los datos o identificar duplicados.</li> <li>Componentes:<ul> <li>Lookup DIM_ESTABLECIMIENTO_EDUCATIVO:<ul> <li>Tabla de referencia: <code>DIM_ESTABLECIMIENTO_EDUCATIVO</code>.</li> <li>Columnas para unir:<ul> <li>\"Copy of ESTABLECIMIENTO EDUCATIVO\" con \"NOMBRE_ESTABLECIMIENTO\".</li> <li>\"Copy of MUNICIPIO\" con \"MUNICIPIO\".</li> </ul> </li> <li>Columnas devueltas: \"ID_ESTABLECIMIENTO_EDUCATIVO\".</li> <li>No Match Behavior: <code>Redirect rows to No Match Output</code>.</li> </ul> </li> <li>Lookup DIM_PREGUNTAS_EE_AIPI:<ul> <li>Tabla de referencia: <code>DIM_PREGUNTAS_EE_AIPI</code>.</li> <li>Columnas para unir:<ul> <li>\"Copy of PREGUNTA\" con \"PREGUNTA\".</li> </ul> </li> <li>Columnas devueltas: \"ID_PREGUNTA\".</li> <li>No Match Behavior: <code>Redirect rows to No Match Output</code>.</li> </ul> </li> <li>Lookup DIM_RESPUESTAS_EE_AIPI:<ul> <li>Tabla de referencia: <code>DIM_RESPUESTAS_EE_AIPI</code>.</li> <li>Columnas para unir:<ul> <li>\"Copy of RESPUESTA\" con \"RESPUESTA\".</li> </ul> </li> <li>Columnas devueltas: \"ID_RESPUESTA\".</li> <li>No Match Behavior: <code>Redirect rows to No Match Output</code>.</li> </ul> </li> <li>Lookup FACT_DIAGNOSTICOS_EE_AIPI:<ul> <li>Tabla de referencia: <code>FACT_DIAGNOSTICOS_EE_AIPI</code>.</li> <li>Columnas para unir: Todas las columnas clave para verificar duplicados.</li> <li>No Match Behavior: <code>Redirect rows to No Match Output</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>ADO.NET Destination</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla destino <code>FACT_DIAGNOSTICOS_EE_AIPI</code>.</li> <li>Propiedades:         - Tabla o vista: <code>\"Proteccion\".\"FACT_DIAGNOSTICOS_EE_AIPI\"</code>.         - Batch Size: <code>0</code> (usa el tama\u00f1o predeterminado del b\u00fafer).         - Command Timeout: <code>30</code> segundos.         - UseBulkInsertWhenPossible: <code>True</code> (habilita el uso de inserciones masivas para mejorar el rendimiento).</li> <li>Columnas cargadas:         - \"ID_ESTABLECIMIENTO_EDUCATIVO\".         - \"ID_PREGUNTA\".         - \"ID_RESPUESTA\".         - \"Copy of FECHA\".</li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Flat File Source) --&gt; B(Data Conversion)\n    B --&gt; C(Lookup DIM_ESTABLECIMIENTO_EDUCATIVO)\n    C --&gt; D(Lookup DIM_PREGUNTAS_EE_AIPI)\n    D --&gt; E(Lookup DIM_RESPUESTAS_EE_AIPI)\n    E --&gt; F(ADO.NET Destination)</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-procesar-fact_venta","title":"Componente <code>Procesar FACT_VENTA</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos se encarga de procesar informaci\u00f3n sobre ventas a trav\u00e9s de varias transformaciones, b\u00fasquedas en tablas de referencia y la inserci\u00f3n final en una tabla destino <code>FACT_VENTA</code>. El objetivo principal es enriquecer los datos, realizar validaciones y optimizar el almacenamiento en la base de datos.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source</p> <ul> <li>Descripci\u00f3n: Lee datos desde un archivo plano delimitado. </li> <li>Propiedades:<ul> <li>Formato: Delimitado (ejemplo: por comas).</li> <li>Columnas cargadas:</li> <li><code>FECHA</code></li> <li><code>DOCUMENTO</code></li> <li><code>NOMBRE_USUARIO</code></li> <li><code>CATEGORIA_VENTA</code></li> <li><code>SERVICIO</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li>Otros campos como <code>VALOR_PAGADO_SIN_IMP</code>, <code>COSTO</code>, <code>SUBSIDIO</code>.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos de entrada para cumplir con los requerimientos del flujo.</li> <li>Propiedades:<ul> <li>Convierte las columnas:</li> <li><code>FECHA</code> a tipo <code>dbTimeStamp</code>.</li> <li><code>DOCUMENTO</code>, <code>NOMBRE_USUARIO</code>, <code>CATEGORIA_VENTA</code>, <code>SERVICIO</code>, y <code>TIPO_DOCUMENTO</code> a tipo <code>wstr</code> con longitudes espec\u00edficas.</li> <li>Error Row Disposition: <code>FailComponent</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup Transformations</p> <ul> <li>Descripci\u00f3n: Realiza b\u00fasquedas en tablas de referencia para enriquecer los datos con identificadores clave.</li> <li>Componentes:<ul> <li>Lookup DIM_TIEMPO:</li> <li>Tabla: <code>DIM_TIEMPO</code>.</li> <li>Uniones:<ul> <li><code>Copy of FECHA</code> -&gt; <code>FECHA</code>.</li> </ul> </li> <li>Resultado: <code>ID_FECHA</code>.</li> <li>No Match Behavior: Redirigir filas sin coincidencias.</li> <li>Lookup DIM_POBLACION:</li> <li>Tabla: <code>DIM_POBLACION</code>.</li> <li>Uniones:<ul> <li><code>Copy of TIPO_DOCUMENTO</code> -&gt; <code>TIPO_DOCUMENTO</code>.</li> <li><code>Copy of DOCUMENTO</code> -&gt; <code>DOCUMENTO</code>.</li> </ul> </li> <li>Resultado: <code>ID_POBLACION</code>.</li> <li>No Match Behavior: Redirigir filas sin coincidencias.</li> <li>Lookup DIM_TARIFAS_SERVICIOS:</li> <li>Tabla: <code>DIM_TARIFAS_SERVICIOS</code>.</li> <li>Uni\u00f3n:<ul> <li><code>Copy of SERVICIO</code> -&gt; <code>CON_OBJETO_TARIFA</code>.</li> </ul> </li> <li>Resultado: Informaci\u00f3n relacionada con tarifas.</li> <li>Lookup FACT_VENTA:</li> <li>Tabla: <code>FACT_VENTA</code>.</li> <li>Uniones:<ul> <li>Clave compuesta: <code>FECHA</code>, <code>DOCUMENTO</code>, <code>CATEGORIA_VENTA</code>, <code>SERVICIO</code>, entre otros.</li> </ul> </li> <li>No Match Behavior: Redirigir filas sin coincidencias.</li> </ul> </li> </ul> </li> <li> <p>ADO.NET Destination</p> <ul> <li>Descripci\u00f3n: Inserta datos en la tabla destino <code>FACT_VENTA</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Proteccion\".\"FACT_VENTA\"</code>.</li> <li>Batch Size: <code>0</code> (tama\u00f1o predeterminado).</li> <li>Timeout: <code>30</code> segundos.</li> </ul> </li> <li>Columnas cargadas:<ul> <li><code>ID_FECHA</code>, <code>ID_POBLACION</code>, <code>VALOR_PAGADO_SIN_IMP</code>, <code>COSTO</code>, <code>SUBSIDIO</code>, entre otros.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Flat File Source) --&gt; B(Data Conversion)\n    B --&gt; C(Lookup DIM_TIEMPO)\n    C --&gt; D(Lookup DIM_POBLACION)\n    D --&gt; E(Lookup DIM_TARIFAS_SERVICIOS)\n    E --&gt; F(Lookup FACT_VENTA)\n    F --&gt; G(ADO.NET Destination)</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-procesar-fact_entrega_material","title":"Componente <code>Procesar FACT_ENTREGA_MATERIAL</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>Este flujo de datos procesa la informaci\u00f3n de entregas de material, realiza transformaciones y enriquecimientos de datos, y carga los datos finales en la tabla <code>FACT_ENTREGA_MATERIAL</code>. Utiliza varias transformaciones para realizar b\u00fasquedas en tablas de referencia y asegurar la integridad de los datos antes de su almacenamiento.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo plano delimitado.</li> <li>Propiedades:<ul> <li>Formato: Delimitado.</li> <li>Columnas cargadas:</li> <li><code>FECHA_ENTREGA</code></li> <li><code>TIPO_DOCUMENTO</code></li> <li><code>DOCUMENTO</code></li> <li><code>NOMBRE_MATERIAL</code></li> <li><code>TIPO_MATERIAL</code></li> <li><code>CANTIDAD_MATERIAL</code></li> <li><code>VALOR_MATERIAL</code></li> <li><code>PROGRAMA</code>.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos para asegurar que cumplan con los requisitos de las transformaciones posteriores.</li> <li>Propiedades:<ul> <li>Convierte:</li> <li><code>FECHA_ENTREGA</code> a <code>dbTimeStamp</code>.</li> <li><code>TIPO_DOCUMENTO</code>, <code>DOCUMENTO</code>, <code>NOMBRE_MATERIAL</code>, <code>TIPO_MATERIAL</code>, y <code>PROGRAMA</code> a <code>wstr</code>.</li> <li><code>ID_PERSONAL</code> y <code>ID_MATERIAL</code> a <code>numeric</code>.</li> <li>Error Row Disposition: <code>FailComponent</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup Transformations</p> <ul> <li>Descripci\u00f3n: Realiza b\u00fasquedas en tablas de referencia para enriquecer los datos con identificadores clave.</li> <li>Componentes:<ul> <li>Lookup DIM_TIEMPO:</li> <li>Tabla: <code>DIM_TIEMPO</code>.</li> <li>Uni\u00f3n:<ul> <li><code>Copy of FECHA_ENTREGA</code> -&gt; <code>FECHA</code>.</li> </ul> </li> <li>Resultado: <code>ID_FECHA</code>.</li> <li>No Match Behavior: Ignorar filas sin coincidencias.</li> <li>Lookup DIM_PROGRAMA:</li> <li>Tabla: <code>DIM_PROGRAMA</code>.</li> <li>Uni\u00f3n:<ul> <li><code>Copy of PROGRAMA</code> -&gt; <code>PROGRAMA</code>.</li> </ul> </li> <li>Resultado: <code>ID_PROGRAMA</code>.</li> <li>No Match Behavior: Ignorar filas sin coincidencias.</li> <li>Lookup DIM_POBLACION:</li> <li>Tabla: <code>DIM_POBLACION</code>.</li> <li>Uni\u00f3n:<ul> <li><code>Copy of TIPO_DOCUMENTO</code> -&gt; <code>TIPO_DOCUMENTO</code>.</li> <li><code>Copy of DOCUMENTO</code> -&gt; <code>DOCUMENTO</code>.</li> </ul> </li> <li>Resultado: <code>ID_POBLACION</code>.</li> <li>No Match Behavior: Ignorar filas sin coincidencias.</li> <li>Lookup FACT_ENTREGA_MATERIAL:</li> <li>Tabla: <code>FACT_ENTREGA_MATERIAL</code>.</li> <li>Uniones:<ul> <li>Clave compuesta: <code>FECHA_ENTREGA</code>, <code>NOMBRE_MATERIAL</code>, <code>TIPO_MATERIAL</code>, <code>ID_FECHA</code>, <code>ID_PROGRAMA</code>, <code>ID_POBLACION</code>.</li> </ul> </li> <li>No Match Behavior: Redirigir filas sin coincidencias.</li> </ul> </li> </ul> </li> <li> <p>ADO.NET Destination</p> <ul> <li>Descripci\u00f3n: Carga los datos en la tabla destino <code>FACT_ENTREGA_MATERIAL</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Proteccion\".\"FACT_ENTREGA_MATERIAL\"</code>.</li> <li>Batch Size: <code>0</code> (tama\u00f1o predeterminado).</li> <li>Timeout: <code>30</code> segundos.</li> </ul> </li> <li>Columnas cargadas:<ul> <li><code>ID_FECHA</code>, <code>ID_PROGRAMA</code>, <code>ID_POBLACION</code>, <code>CANTIDAD_MATERIAL</code>, <code>VALOR_MATERIAL</code>, entre otros.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Flat File Source) --&gt; B(Data Conversion)\n    B --&gt; C(Lookup DIM_TIEMPO)\n    C --&gt; D(Lookup DIM_PROGRAMA)\n    D --&gt; E(Lookup DIM_POBLACION)\n    E --&gt; F(Lookup FACT_ENTREGA_MATERIAL)\n    F --&gt; G(ADO.NET Destination)</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-procesar-fact_visitas","title":"Componente <code>Procesar FACT_VISITAS</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El flujo de datos procesa informaci\u00f3n de visitas, incluyendo planificaci\u00f3n, ejecuci\u00f3n, y metadatos relacionados. Se enfoca en transformar los datos y realizar b\u00fasquedas en tablas de referencia antes de cargarlos en la tabla <code>FACT_VISITAS</code>.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source</p> <ul> <li>Descripci\u00f3n: Extrae datos desde un archivo plano delimitado.</li> <li>Propiedades:<ul> <li>Formato: Delimitado.</li> <li>Columnas cargadas:</li> <li><code>MUNICIPIO</code></li> <li><code>FECHA_PLANEADA</code></li> <li><code>ID_PERSONAL</code></li> <li><code>PERSONAL</code></li> <li><code>ACTIVIDAD</code></li> <li><code>LUGAR</code></li> <li><code>FECHA_EJECUTADA</code></li> <li><code>PROGRAMA</code>.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion</p> <ul> <li>Descripci\u00f3n: Convierte los datos al formato requerido para las transformaciones posteriores.</li> <li>Propiedades:<ul> <li>Convierte:</li> <li><code>FECHA_PLANEADA</code>, <code>FECHA_EJECUTADA</code> a <code>dbTimeStamp</code>.</li> <li><code>MUNICIPIO</code>, <code>ACTIVIDAD</code>, <code>LUGAR</code>, <code>PROGRAMA</code> a <code>wstr</code>.</li> <li><code>PERSONAL</code> a <code>str</code>.</li> <li>Error Row Disposition: <code>FailComponent</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup Transformations</p> <ul> <li>Descripci\u00f3n: Realiza b\u00fasquedas en tablas de referencia para enriquecer los datos con identificadores clave.</li> <li>Componentes:<ul> <li>Lookup DIM_TIEMPO:</li> <li>Tabla: <code>DIM_TIEMPO</code>.</li> <li>Uni\u00f3n:<ul> <li><code>Copy of FECHA_PLANEADA</code> -&gt; <code>FECHA</code>.</li> </ul> </li> <li>Resultado: <code>ID_FECHA</code>.</li> <li>No Match Behavior: Ignorar filas sin coincidencias.</li> <li>Lookup DIM_PROGRAMA:</li> <li>Tabla: <code>DIM_PROGRAMA</code>.</li> <li>Uni\u00f3n:<ul> <li><code>Copy of PROGRAMA</code> -&gt; <code>PROGRAMA</code>.</li> </ul> </li> <li>Resultado: <code>ID_PROGRAMA</code>.</li> <li>No Match Behavior: Ignorar filas sin coincidencias.</li> <li>Lookup FACT_VISITAS:</li> <li>Tabla: <code>FACT_VISITAS</code>.</li> <li>Uniones:<ul> <li>Clave compuesta: <code>MUNICIPIO</code>, <code>FECHA_PLANEADA</code>, <code>ACTIVIDAD</code>, <code>LUGAR</code>, <code>FECHA_EJECUTADA</code>, <code>ID_FECHA</code>, <code>ID_PROGRAMA</code>.</li> </ul> </li> <li>No Match Behavior: Redirigir filas sin coincidencias.</li> </ul> </li> </ul> </li> <li> <p>ADO.NET Destination</p> <ul> <li>Descripci\u00f3n: Carga los datos en la tabla destino <code>FACT_VISITAS</code>.</li> <li>Propiedades:<ul> <li>Tabla destino: <code>\"Proteccion\".\"FACT_VISITAS\"</code>.</li> <li>Batch Size: <code>0</code> (tama\u00f1o predeterminado).</li> <li>Timeout: <code>30</code> segundos.</li> </ul> </li> <li>Columnas cargadas:<ul> <li><code>ID_FECHA</code>, <code>ID_PROGRAMA</code>, <code>MUNICIPIO</code>, <code>FECHA_PLANEADA</code>, <code>PERSONAL</code>, <code>ACTIVIDAD</code>, <code>LUGAR</code>, <code>FECHA_EJECUTADA</code>, entre otros.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Flat File Source) --&gt; B(Data Conversion)\n    B --&gt; C(Lookup DIM_TIEMPO)\n    C --&gt; D(Lookup DIM_PROGRAMA)\n    D --&gt; E(Lookup FACT_VISITAS)\n    E --&gt; F(ADO.NET Destination)</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-procesar-fact_desercion","title":"Componente <code>Procesar FACT_DESERCION</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>Este componente procesa datos de deserci\u00f3n acad\u00e9mica para cargar informaci\u00f3n transformada y enriquecida en una base de datos de destino. El flujo incluye pasos de conversi\u00f3n, enriquecimiento mediante consultas <code>Lookup</code>, y carga final en la tabla <code>FACT_DESERCION</code>.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Flat File Source:</p> <ul> <li>Descripci\u00f3n: Origen de datos que extrae informaci\u00f3n de un archivo CSV.</li> <li>Propiedades:<ul> <li>Archivo Conexi\u00f3n: <code>Csv_Connection_Fact_Desercion</code>.</li> <li>Columnas: ID_REGISTRO, COD_ESTABLECIMIENTO_EDUCATIVO, NOMBRE_EE, TIPO_DOCUMENTO, DOCUMENTO, ANIO_ACADEMICO, FECHA_REGISTRO, PROGRAMA, CAUSA.</li> <li>Configuraci\u00f3n de errores: Disposici\u00f3n ante error: <code>FailComponent</code>.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion:</p> <ul> <li>Descripci\u00f3n: Conversi\u00f3n de datos para estandarizar tipos y formatos.</li> <li>Propiedades:<ul> <li>Convierte columnas como <code>FECHA_REGISTRO</code> a <code>dbTimeStamp</code> y texto a formato ancho (wstr).</li> <li>Columnas Convertidas: <ul> <li>FECHA_REGISTRO \u2192 dbTimeStamp.</li> <li>CAUSA \u2192 wstr (longitud 40).</li> <li>ANIO_ACADEMICO \u2192 wstr (longitud 40).</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Lookup - DIM_TIEMPO:</p> <ul> <li>Descripci\u00f3n: Enriquecimiento de datos con claves temporales.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Dwh].[DIM_TIEMPO] WHERE FECHA = ?</code>.</li> <li>Une <code>FECHA_REGISTRO</code> con <code>DIM_TIEMPO.FECHA</code> para obtener <code>ID_FECHA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup - DIM_PROGRAMA:</p> <ul> <li>Descripci\u00f3n: Obtenci\u00f3n de ID del programa.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Proteccion].[DIM_PROGRAMA] WHERE PROGRAMA = ?</code>.</li> <li>Une <code>PROGRAMA</code> con <code>DIM_PROGRAMA.PROGRAMA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup - DIM_ESTABLECIMIENTO_EDUCATIVO:</p> <ul> <li>Descripci\u00f3n: Identificaci\u00f3n del establecimiento educativo.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] WHERE NOMBRE_ESTABLECIMIENTO = ?</code>.</li> <li>Une <code>NOMBRE_EE</code> con <code>DIM_ESTABLECIMIENTO_EDUCATIVO.NOMBRE_ESTABLECIMIENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup - DIM_POBLACION:</p> <ul> <li>Descripci\u00f3n: Enriquecimiento de datos de poblaci\u00f3n.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Proteccion].[DIM_POBLACION] WHERE DOCUMENTO = ? AND TIPO_DOCUMENTO = ?</code>.</li> <li>Une <code>DOCUMENTO</code> y <code>TIPO_DOCUMENTO</code> con <code>DIM_POBLACION</code>.</li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET:</p> <ul> <li>Descripci\u00f3n: Carga de datos procesados a la tabla <code>FACT_DESERCION</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Proteccion\".\"FACT_DESERCION\"</code>.</li> <li>Tiempo de espera: 30 segundos.</li> <li>Inserci\u00f3n masiva: Activada.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Flat File Source: Csv_Connection_Fact_Desercion) --&gt; B(Data Conversion: Convertir tipos y longitudes)\n    B --&gt; C(Lookup: Enriquecer con DIM_TIEMPO)\n    C --&gt; D(Lookup: Enriquecer con DIM_PROGRAMA)\n    D --&gt; E(Lookup: Enriquecer con DIM_ESTABLECIMIENTO_EDUCATIVO)\n    E --&gt; F(Lookup: Enriquecer con DIM_POBLACION)\n    F --&gt; G(ADO NET: Cargar en FACT_DESERCION)</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componente-procesar-fact_plan_cobertura","title":"Componente <code>Procesar FACT_PLAN_COBERTURA</code>","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>Este componente gestiona la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con el plan de cobertura. Incluye pasos de conversi\u00f3n de datos, enriquecimiento mediante <code>Lookup</code>, y almacenamiento en la tabla <code>FACT_PLAN_COBERTURA</code>.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Excel Source:</p> <ul> <li>Descripci\u00f3n: Obtiene datos desde un archivo Excel que contiene informaci\u00f3n del plan de cobertura.</li> <li>Propiedades:<ul> <li>Hoja: <code>Sheet1$</code>.</li> <li>Conexi\u00f3n: <code>Excel_Connection_Fact_Plan_Cobertura</code>.</li> <li>Columnas: ZODES, MUNICIPIO, COBERTURA PROYECTADA, LINEA DE INTERVENCION, ANIO, INSTTITUCIONES EDUCATIVAS, PROGRAMA.</li> </ul> </li> </ul> </li> <li> <p>Data Conversion:</p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos para estandarizarlos seg\u00fan los requisitos del destino.</li> <li>Propiedades:<ul> <li>Convierte columnas como <code>COBERTURA PROYECTADA</code>, <code>LINEA DE INTERVENCION</code> y <code>ANIO</code> a formato de texto ancho (wstr).</li> <li>Columnas Convertidas:<ul> <li><code>COBERTURA PROYECTADA</code>, <code>LINEA DE INTERVENCION</code>, <code>ANIO</code>, y <code>MUNICIPIO</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Lookup - DIM_ESTABLECIMIENTO_EDUCATIVO:</p> <ul> <li>Descripci\u00f3n: Relaciona los datos de la instituci\u00f3n educativa con su ID en la tabla de dimensiones.</li> <li>Propiedades:<ul> <li>Consulta SQL: <code>SELECT * FROM [Proteccion].[DIM_ESTABLECIMIENTO_EDUCATIVO] WHERE NOMBRE_ESTABLECIMIENTO = ?</code>.</li> <li>Une <code>INSTTITUCIONES EDUCATIVAS</code> con <code>DIM_ESTABLECIMIENTO_EDUCATIVO.NOMBRE_ESTABLECIMIENTO</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup - DIM_PROGRAMA:</p> <ul> <li>Descripci\u00f3n: Obtiene el ID del programa asociado.</li> <li>Propiedades:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Proteccion].[DIM_PROGRAMA] WHERE PROGRAMA = ?\n</code></pre></li> <li>Une <code>PROGRAMA</code> con <code>DIM_PROGRAMA.PROGRAMA</code>.</li> </ul> </li> </ul> </li> <li> <p>Lookup - FACT_PLAN_COBERTURA:</p> <ul> <li>Descripci\u00f3n: Verifica la existencia previa de los datos para evitar duplicados.</li> <li>Propiedades:<ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Proteccion].[FACT_PLAN_COBERTURA] \nWHERE MUNICIPIO = ? AND LINEA_INTERVENCION = ? \nAND COBERTURA_PROYECTADA = ? AND ANIO = ? \nAND ID_ESTABLECIMIENTO_EDUCATIVO = ? AND ID_PROGRAMA = ?\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET:</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>FACT_PLAN_COBERTURA</code>.</li> <li>Propiedades:<ul> <li>Tabla de destino: <code>\"Proteccion\".\"FACT_PLAN_COBERTURA\"</code>.</li> <li>Inserci\u00f3n masiva: Activada.</li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>graph TD\n    A(Excel Source: Excel_Connection_Fact_Plan_Cobertura) --&gt; B(Data Conversion: Convertir tipos y longitudes)\n    B --&gt; C(Lookup: DIM_ESTABLECIMIENTO_EDUCATIVO)\n    C --&gt; D(Lookup: DIM_PROGRAMA)\n    D --&gt; E(Lookup: FACT_PLAN_COBERTURA)\n    E --&gt; F(ADO NET: Cargar en FACT_PLAN_COBERTURA)</code></pre>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#restaurar-llaves-foraneas-esquema-proteccion","title":"Restaurar llaves for\u00e1neas esquema Proteccion","text":""},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Este componente ejecuta un script SQL para restaurar las claves for\u00e1neas en el esquema <code>Proteccion</code>. Se asegura de que todas las restricciones de clave for\u00e1nea est\u00e9n definidas y actualizadas en las tablas correspondientes. Tambi\u00e9n limpia la tabla persistente <code>ForeignKeys_Proteccion</code> al finalizar.</p>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#detalles-del-componente","title":"Detalles del Componente","text":"<ol> <li>Tarea Ejecutar SQL (Execute SQL Task):<ul> <li>Descripci\u00f3n: Restaura las claves for\u00e1neas y limpia la tabla temporal utilizada para su almacenamiento.</li> <li>Propiedades:<ul> <li>Conexi\u00f3n: Conexi\u00f3n <code>DWH_COMFENALCO_Destino_OLEDB</code>.</li> <li>Consulta SQL: <pre><code>-- Restaurar restricciones de clave for\u00e1nea para el esquema Proteccion\nDECLARE @restoreSql_Proteccion NVARCHAR(MAX) = '';\n\nSELECT @restoreSql_Proteccion += 'ALTER TABLE ' + QUOTENAME('Proteccion') + '.' + QUOTENAME(fk.TableName) \n    + ' ADD CONSTRAINT ' + QUOTENAME(fk.ConstraintName) \n    + ' FOREIGN KEY (' + QUOTENAME(fk.ColumnName) + ') REFERENCES ' \n    + QUOTENAME(\n        CASE \n            WHEN fk.ReferencedTableName IN ('DIM_AFILIADOS', 'DIM_APORTANTE_NOAFILIADO', 'DIM_BENEFICIARIOS', 'DIM_CAPACIDAD_FISICA', 'DIM_CATEGORIA', 'DIM_CUENTA_CONTABLE', 'DIM_EMPRESAS', 'DIM_INFRAESTRUCTURA_CCF', 'DIM_PERSONAL', 'DIM_SEDES', 'DIM_TARIFAS_SERVICIOS', 'DIM_UNIDAD', 'DIM_UNIDADES_ORGANIZATIVAS')\n            THEN 'Transversal'\n            WHEN fk.ReferencedTableName = 'DIM_TIEMPO' \n            THEN 'Dwh' \n            ELSE 'Proteccion'\n        END\n    ) + '.' + QUOTENAME(fk.ReferencedTableName) \n    + '(' + QUOTENAME(fk.ReferencedColumnName) + '); ' \nFROM dbo.ForeignKeys_Proteccion fk;\n\n-- Ejecutamos el SQL para restaurar las llaves for\u00e1neas del esquema Proteccion\nEXEC sp_executesql @restoreSql_Proteccion;\n\n-- Limpiar la tabla persistente\nDROP TABLE dbo.ForeignKeys_Proteccion;\n</code></pre></li> </ul> </li> </ul> </li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#secuencia-de-operaciones","title":"Secuencia de Operaciones","text":"<ol> <li>Construye din\u00e1micamente los comandos <code>ALTER TABLE</code> para cada clave for\u00e1nea registrada en la tabla <code>ForeignKeys_Proteccion</code>.</li> <li>Define las claves for\u00e1neas asegur\u00e1ndose de que las tablas referenciadas pertenezcan al esquema correcto (<code>Proteccion</code>, <code>Transversal</code> o <code>Dwh</code>).</li> <li>Ejecuta el script generado con <code>sp_executesql</code>.</li> <li>Elimina la tabla temporal <code>ForeignKeys_Proteccion</code>.</li> </ol>"},{"location":"02.Paquetes_SSIS/08-PROTECCION_FACT/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Task\n    participant SQL as SQL Server\n\n    SSIS -&gt;&gt; SQL: Construir consulta @restoreSql_Proteccion\n    SQL -&gt;&gt; SQL: Generar comandos ALTER TABLE\n    SQL -&gt;&gt; SQL: Ejecutar sp_executesql\n    SQL -&gt;&gt; SQL: DROP TABLE dbo.ForeignKeys_Proteccion</code></pre>"},{"location":"02.Paquetes_SSIS/09-ETLS_CUBO/","title":"09. ETLS_CUBO","text":""},{"location":"02.Paquetes_SSIS/09-ETLS_CUBO/#etls-cubo","title":"ETLS CUBO","text":"<p>El paquete SSIS \"ETLS CUBO\" est\u00e1 dise\u00f1ado para gestionar procesos ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) enfocados en datos transversales y financieros. Este paquete asegura la correcta preparaci\u00f3n de tablas, la consolidaci\u00f3n de datos y la integraci\u00f3n eficiente en el Data Warehouse <code>DWH_COMFENALCO</code>, proporcionando una base s\u00f3lida para an\u00e1lisis y generaci\u00f3n de reportes.</p> <p>ETL PAQUETE 09</p>"},{"location":"03.Cubo/00.Introduccion/","title":"Introducci\u00f3n","text":""},{"location":"03.Cubo/00.Introduccion/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El cubo desarrollado en SSIS (SQL Server Integration Services) es una soluci\u00f3n anal\u00edtica dise\u00f1ada para procesar, consolidar y estructurar datos de m\u00faltiples fuentes dentro de un modelo sem\u00e1ntico. Este modelo permite realizar an\u00e1lisis multidimensionales, facilitando la toma de decisiones estrat\u00e9gicas y operativas mediante m\u00e9tricas clave, segmentaciones, y relaciones entre diversas dimensiones y hechos.</p> <p>El cubo integra datos desde un Data Warehouse centralizado, asegurando consistencia y eficiencia en la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de informaci\u00f3n. Este enfoque proporciona una vista consolidada y anal\u00edtica de los datos organizacionales.</p>"},{"location":"03.Cubo/00.Introduccion/#objetivos-del-cubo","title":"Objetivos del Cubo","text":"<p>1. Consolidaci\u00f3n de Datos:</p> <ul> <li>Unificar informaci\u00f3n procedente de diferentes tablas y dimensiones.</li> <li>Proveer datos consistentes para el an\u00e1lisis organizacional.</li> </ul> <p>2. An\u00e1lisis Multidimensional:</p> <ul> <li>Facilitar la creaci\u00f3n de reportes din\u00e1micos y visualizaciones anal\u00edticas.</li> <li>Permitir el desglose de informaci\u00f3n por jerarqu\u00edas, periodos y categor\u00edas.</li> </ul> <p>3. Optimizaci\u00f3n de Decisiones:</p> <ul> <li>Proveer m\u00e9tricas clave como ingresos, aportes, cobertura, y desempe\u00f1o.</li> <li>Ayudar en la identificaci\u00f3n de tendencias y oportunidades de mejora.</li> </ul>"},{"location":"03.Cubo/00.Introduccion/#principales-componentes-del-cubo","title":"Principales Componentes del Cubo","text":"<p>1. Dimensiones:</p> <ul> <li>Representan las jerarqu\u00edas y atributos que permiten segmentar y analizar los datos.</li> <li>Ejemplo: DIM_UNIDAD, DIM_TIEMPO_MENSUAL, y DIM_CATEGORIA.</li> </ul> <p>2. Hechos:</p> <ul> <li>Contienen los datos medibles y m\u00e9tricas clave para el an\u00e1lisis.</li> <li>Ejemplo: FACT_ACTIVIDADES, FACT_PERSONAL, y FACT_FINANCIERA.</li> </ul> <p>3. Relaciones:</p> <ul> <li>Definen c\u00f3mo las dimensiones y los hechos interact\u00faan entre s\u00ed.</li> <li>Aseguran consistencia y precisi\u00f3n en el modelo.</li> </ul> <p>4. Medidas:</p> <ul> <li>Proveen c\u00e1lculos predefinidos como sumas, promedios y conteos.</li> <li>Ejemplo: # Empresas Afiliadas Caja, Valor Aportes Totales.</li> </ul>"},{"location":"03.Cubo/00.Introduccion/#beneficios-del-cubo","title":"Beneficios del Cubo","text":"<p>1. Agilidad Anal\u00edtica:</p> <ul> <li>Generaci\u00f3n r\u00e1pida de informes para diversas \u00e1reas de la organizaci\u00f3n.</li> <li>Reducci\u00f3n de tiempos en la obtenci\u00f3n y an\u00e1lisis de datos.</li> </ul> <p>2. Consistencia y Calidad de Datos:</p> <ul> <li>Integraci\u00f3n de datos con controles de calidad y validaciones.</li> <li>Centralizaci\u00f3n de la informaci\u00f3n para evitar duplicidades o inconsistencias.</li> </ul> <p>3. Escalabilidad:</p> <ul> <li>Capacidad de adaptarse a nuevas necesidades de negocio a\u00f1adiendo dimensiones, hechos o medidas.</li> </ul> <p>4. Decisiones Basadas en Datos:</p> <ul> <li>Facilitaci\u00f3n de insights clave para la toma de decisiones fundamentadas.</li> </ul>"},{"location":"03.Cubo/00.Introduccion/#vista-del-modelo","title":"Vista del modelo","text":""},{"location":"03.Cubo/00.Introduccion/#diagrama-de-relaciones-y-tablas","title":"Diagrama de Relaciones y Tablas","text":"<pre><code>graph TD\n    FACT_ACTIVIDADES[Transversal FACT_ACTIVIDADES]\n    FACT_PERSONAL[Transversal FACT_PERSONAL]\n    FACT_FINANCIERA[Transversal FACT_FINANCIERA]\n    FACT_EVALUACION_DOCENTE[Transversal FACT_EVALUACION_DOCENTE]\n    DIM_UNIDAD[Transversal DIM_UNIDAD]\n    DIM_CATEGORIA[Transversal DIM_CATEGORIA]\n    DIM_TIEMPO[Transversal DIM_TIEMPO_MENSUAL]\n\n    FACT_ACTIVIDADES --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_ACTIVIDADES --&gt; DIM_CATEGORIA[ID_CATEGORIA]\n    FACT_ACTIVIDADES --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_FINANCIERA --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_TIEMPO[ID_FECHA]</code></pre>"},{"location":"03.Cubo/01.Origen/","title":"01. ORIGEN Y MEDIDAS","text":""},{"location":"03.Cubo/01.Origen/#origen-de-datos-del-cubo","title":"Origen de Datos del Cubo","text":""},{"location":"03.Cubo/01.Origen/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>El origen de datos es un componente estructurado que conecta el cubo de SSIS con el Data Warehouse principal. Esta conexi\u00f3n permite la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos necesarios para las operaciones anal\u00edticas.</p>"},{"location":"03.Cubo/01.Origen/#detalles-de-configuracion","title":"Detalles de Configuraci\u00f3n","text":"<p>1. Tipo de Origen: </p> <ul> <li>Estructurado (<code>structured</code>).</li> </ul> <p>2. Nombre del Origen:</p> <ul> <li><code>SQL/10 5 21 29\\\\bi;DWH_COMFENALCO</code>.</li> </ul> <p>3. Detalles de Conexi\u00f3n:</p> <ul> <li>Protocolo: <code>tds</code> (Tabular Data Stream, utilizado para bases de datos SQL Server).</li> <li>Direcci\u00f3n:<ul> <li>Servidor: <code>10.5.21.29\\bi</code>.</li> <li>Base de Datos: <code>DWH_COMFENALCO</code>.</li> </ul> </li> </ul> <p>4. Autenticaci\u00f3n:</p> <ul> <li>Tipo: <code>UsernamePassword</code>.</li> <li>Usuario: <code>prov_quality2</code>.</li> <li>Conexi\u00f3n encriptada: <code>false</code>.</li> </ul> <p>5. Credenciales:</p> <ul> <li>Ruta: <code>10.5.21.29\\\\bi;DWH_COMFENALCO</code>.</li> <li>Cifrado: No aplica (<code>EncryptConnection: false</code>).</li> </ul>"},{"location":"03.Cubo/01.Origen/#proposito","title":"Prop\u00f3sito","text":"<p>El origen de datos garantiza la conectividad y el acceso a las tablas y medidas necesarias para el funcionamiento del cubo. Este origen permite a los paquetes de SSIS consumir datos directamente desde el DWH para su an\u00e1lisis y explotaci\u00f3n.</p>"},{"location":"03.Cubo/01.Origen/#medidas","title":"Medidas","text":""},{"location":"03.Cubo/01.Origen/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tabla Medidas contiene columnas calculadas y una serie de medidas configuradas para realizar an\u00e1lisis y c\u00e1lculos dentro del cubo. Estas medidas se utilizan para analizar datos clave y generar m\u00e9tricas significativas para la toma de decisiones.</p>"},{"location":"03.Cubo/01.Origen/#estructura","title":"Estructura","text":"<p>1. Nombre de la Tabla: <code>Medidas</code>.</p> <p>2. Columnas:</p> <ul> <li>Column1:<ul> <li>Tipo de Columna: Columna Calculada (<code>calculatedTableColumn</code>).</li> <li>Nombre: <code>Column1</code>.</li> <li>Tipo de Datos: <code>int64</code>.</li> <li>Nombre Inferido: <code>true</code>.</li> <li>Tipo de Datos Inferido: <code>true</code>.</li> <li>Columna Fuente: <code>[Column1]</code>.</li> </ul> </li> </ul>"},{"location":"03.Cubo/01.Origen/#particiones","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>CalculatedTable 1</code>.</p> <p>2. Fuente:</p> <ul> <li>Tipo: <code>calculated</code>.</li> <li>Expresi\u00f3n:    <pre><code>DATATABLE(\"Column1\", INTEGER, {{1}})\n</code></pre></li> </ul>"},{"location":"03.Cubo/01.Origen/#1-unidades","title":"1. Unidades:","text":"<ul> <li>Expresi\u00f3n:      <pre><code>DISTINCTCOUNT('Transversal DIM_UNIDAD'[ID_UNIDAD])\n</code></pre></li> <li>Descripci\u00f3n: Cuenta el n\u00famero distinto de unidades en la dimensi\u00f3n <code>DIM_UNIDAD</code>.</li> </ul>"},{"location":"03.Cubo/01.Origen/#2-empresas-afiliadas-caja","title":"2. Empresas Afiliadas Caja:","text":"<ul> <li>Expresi\u00f3n:      <pre><code>VAR EmpresasCalculo = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[TIPO_POBLACION] = \"EMPRESA\", \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n    )\nRETURN SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 4}, 0,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) = 3, \n    REMOVEFILTERS('Transversal DIM_UNIDAD'),\n    EmpresasCalculo\n)\n</code></pre></li> <li>Descripci\u00f3n: Calcula el n\u00famero de empresas afiliadas, con reglas espec\u00edficas basadas en las actividades filtradas en <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/01.Origen/#3-afiliados-caja","title":"3. Afiliados Caja:","text":"<ul> <li>Expresi\u00f3n:      <pre><code>VAR AfiliadosCalculo = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[TIPO_POBLACION] = \"AFILIADO\", \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n    )\nRETURN SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 3, 4}, \n    AfiliadosCalculo,\n    REMOVEFILTERS('Transversal DIM_UNIDAD')\n)\n</code></pre></li> <li>Descripci\u00f3n: Calcula el n\u00famero de afiliados registrados en actividades de afiliaci\u00f3n, con base en filtros de la dimensi\u00f3n <code>DIM_UNIDAD</code>.</li> </ul>"},{"location":"03.Cubo/01.Origen/#4-beneficiarios-caja","title":"4. Beneficiarios Caja:","text":"<ul> <li>Expresi\u00f3n:      <pre><code>VAR BeneficiariosCalculo = \n    CALCULATE(\n        DISTINCTCOUNT('Transversal FACT_ACTIVIDADES'[PARTNER]), \n        'Transversal FACT_ACTIVIDADES'[TIPO_POBLACION] = \"BENEFICIARIO\", \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"AFILIACION\"\n    )\nRETURN SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 3, 4}, \n    REMOVEFILTERS('Transversal DIM_UNIDAD'),\n    BeneficiariosCalculo\n)\n</code></pre></li> <li>Descripci\u00f3n: Calcula el total de beneficiarios registrados en actividades de afiliaci\u00f3n, aplicando filtros espec\u00edficos en <code>DIM_UNIDAD</code>.</li> </ul>"},{"location":"03.Cubo/01.Origen/#5-aportes-totales","title":"5. Aportes Totales:","text":"<ul> <li>Expresi\u00f3n:      <pre><code>VAR AportesCalculo = \n    CALCULATE(\n        SUM('Transversal FACT_ACTIVIDADES'[NUMERO_APORTES]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"APORTES\"\n    )\nRETURN SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 3, 4}, \n    REMOVEFILTERS('Transversal DIM_UNIDAD'),\n    AportesCalculo\n)\n</code></pre></li> <li>Descripci\u00f3n: Suma el n\u00famero total de aportes asociados a actividades espec\u00edficas de la dimensi\u00f3n <code>FACT_ACTIVIDADES</code>.</li> </ul>"},{"location":"03.Cubo/01.Origen/#6-valor-aportes-totales","title":"6. Valor Aportes Totales:","text":"<ul> <li> <p>Expresi\u00f3n:</p> <p><pre><code>VAR AportesCalculo = \n    CALCULATE(\n        SUM('Transversal FACT_ACTIVIDADES'[TOTAL_APORTES]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"APORTES\"\n    )\n\nVAR AportesCalculoSinFiltros = \n    CALCULATE(\n        SUM('Transversal FACT_ACTIVIDADES'[TOTAL_APORTES]), \n        'Transversal FACT_ACTIVIDADES'[ACTIVIDAD] = \"APORTES\",\n        REMOVEFILTERS('Transversal DIM_UNIDAD')\n    )\n\nRETURN SWITCH (\n    TRUE(),\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) IN {1, 2, 3, 4}, \n    AportesCalculoSinFiltros,\n    SELECTEDVALUE('Transversal DIM_UNIDAD'[ID_UNIDAD]) = 5, \n    AportesCalculo,\n    AportesCalculo -- Valor por defecto si no cumple ninguna condici\u00f3n anterior\n)\n</code></pre>    - Descripci\u00f3n: Calcula el valor total de aportes asociados a las actividades de la dimensi\u00f3n <code>FACT_ACTIVIDADES</code>, eliminando restricciones de filtros seg\u00fan la configuraci\u00f3n de la dimensi\u00f3n <code>DIM_UNIDAD</code>.</p> </li> <li> <p>Formato:</p> <ul> <li>formatString: <code>\\$ #,0;-\\\\$ #,0;\\\\$ #,0</code></li> <li>Descripci\u00f3n: Define el formato como moneda en pesos colombianos, mostrando valores positivos, negativos y ceros con el s\u00edmbolo <code>$</code>.</li> </ul> </li> <li> <p>Anotaciones:      <pre><code>&lt;Format Format=\"Currency\"&gt;\n    &lt;Currency \n        LCID=\"9226\" \n        DisplayName=\"$ Espa\u00f1ol (Colombia)\" \n        Symbol=\"$\" \n        PositivePattern=\"2\" \n        NegativePattern=\"9\" /&gt;\n&lt;/Format&gt;\n</code></pre></p> <ul> <li>LCID: <code>9226</code> - Localizaci\u00f3n para espa\u00f1ol (Colombia).</li> <li>DisplayName: <code>$ Espa\u00f1ol (Colombia)</code>.</li> <li>Symbol: <code>$</code>.</li> <li>PositivePattern: <code>2</code> - El formato para valores positivos (e.g., <code>$ 1,000</code>).</li> <li>NegativePattern: <code>9</code> - El formato para valores negativos (e.g., <code>$ -1,000</code>).</li> </ul> </li> </ul>"},{"location":"03.Cubo/01.Origen/#7-valores-estaticos","title":"7. Valores Est\u00e1ticos","text":"Medida Expresi\u00f3n #Empresas_Atendidas 8000 #Afiliados_Atendidos 90000 #Beneficiarios_Atendidos 100000 Cumplimiento_Cobertura 0.95 Cantidad_Usos 138.968 Numero_PQRS 10.987 Numero_Usos_PQRS 90.998 Cantidad_Aportes_Totales 386.792 Valor_Aportes_Totales 900000000 Cantidad de aportes empresas atendidas Educaci\u00f3n 386.792 Valor de aportes empresas atendidas Educaci\u00f3n 900000000 Valor de aportes empresas atendidas Educaci\u00f3n 900000000 Cantidad de subsidio a la demanda 86.976 Valor de subsidio a la demanda 138968000 % Poblaci\u00f3n Atendida por Educaci\u00f3n 0 Cobertura ejecutada 100.000 Cantidad de Graduados 3983 Porcentaje de promoci\u00f3n 0.85 Porcentaje de deserci\u00f3n 0.08 Variaci\u00f3n deserci\u00f3n respecto vigencia anterior 0.5 Porcentaje de empresas que repiten la compra de los servicios de fomento empresarial 0.5 Porcentaje de usuarios que repiten la compra de servicios de protecci\u00f3n social 0.5 # Espacios f\u00edsicos (Salones) 10 # Servicios ofertados 20 # Servicios vendidos 15 # Estudiantes activos 0 # Estudiantes por sal\u00f3n 0 # Docentes y profesionales 0 # PQRS 90.998 N\u00famero de usos por PQRS 90.998 Porcentaje Promotores 0.98 Porcentaje de detractores 0.02 Calificaciones de docentes 0 % de estudiantes con resultado superior al 50% de valor total de la Prueba 0.5 Resultado de la Categor\u00eda de las pruebas Saber 11 para la CEC 0 Porcentaje de efectividad en las cotizaciones Fomento empresarial-I7404 0.5 Ingresos ejecutados / Ingresos presupuestados 0 # Empresas que compran servicios de fomento empresarial 0 \u00cdndice de resultados para el plantel educativo 0 # Afiliados atendidos por Protecci\u00f3n Social 0 Cobertura para Empleados de la Caja de Compensaci\u00f3n en programas de educaci\u00f3n 0 Porcentaje de afiliados atendidos respecto al total atendido (Protecci\u00f3n Social) 0.5 Porcentaje de poblaci\u00f3n FOSFEC respecto al total atendido (Desarrollo Empresarial) 0.5 Cobertura proyectada 0 Movilidad acad\u00e9mica 0 Nivel de satisfacci\u00f3n a partir de la NSU promedio 0 Promotores promedio del proceso a partir de la NSU 0 Cantidad de matr\u00edculas 0 Detractores promedio del proceso a partir de la NSU 0.5 Valor del subsidio a la demanda a partir de las transacciones realizadas por los afiliados 0 N\u00famero de transacciones de afiliados con categor\u00eda A y B 0 Resultado del ejercicio / Resultado presupuestado 0 Valor de los ingresos percibidos por la prestaci\u00f3n de servicios (Ingresos ejecutados) 0 Porcentaje de estudiantes de la JEC que desertan de la Instituci\u00f3n Educativa 0.5 Porcentaje de estudiantes de AIPI que desertan de la Instituci\u00f3n Educativa 0 Deserci\u00f3n temprana de FOSFEC 0 # horas contratadas 8000 Reductores de capacidad contratada 90 % real de tiempo administrativo 40.45 # Horas empleadas en cubrir ausencias 10200 % Utilizaci\u00f3n de las bibliotecas virtuales 0.8 Inversiones en la infraestructura f\u00edsica 1000000 Inversi\u00f3n en infraestructura tecnol\u00f3gica 0 % Rotaci\u00f3n de la planta Total 0.15 % de Estudiantes matriculados con documentos completos del total de matriculados 1 % de afiliados beneficiados desde PS respecto a la poblaci\u00f3n impactada de PS 0.9 % Empresas Atendidas 0.5 % afiliados por educaci\u00f3n 0.5 % Beneficiarios Atendidos 0.66 N\u00famero de iniciativas 0 % evaluaciones por debajo del promedio 0.5 Incremento del % de rentabilidad del servicio sin fomento al empleo 0.8 Nivel de ejecuci\u00f3n del fondo JEC 0 Nivel de ejecuci\u00f3n del fondo PAIPI 0 Atenci\u00f3n usuarios de los programas de protecci\u00f3n social 0 Evaluaci\u00f3n de la Pertinencia del Dise\u00f1o Curricular por el Sector Productivo 0 % efectividad en las cotizaciones Fomento empresarial 0.5 Productividad del portafolio de desarrollo empresarial 0 Cantidad de poblaci\u00f3n FOSFEC atendida por Desarrollo Empresarial 0 N\u00famero de aportes de empresas atendidas por Educaci\u00f3n 0 Atenci\u00f3n poblaci\u00f3n vulnerable 977 % accidentalidad de la poblaci\u00f3n estudiantil 0.5 % Estudiantes matriculados con documentos completos del total de matriculados 0.77"},{"location":"03.Cubo/01.Origen/#proposito_1","title":"Prop\u00f3sito","text":"<p>1. Proveer c\u00e1lculos espec\u00edficos como conteos, sumas y agregaciones sobre datos transversales.</p> <p>2. Facilitar m\u00e9tricas clave como n\u00famero de unidades, afiliados, beneficiarios y aportes.</p> <p>3. Apoyar an\u00e1lisis avanzados eliminando restricciones de filtros seg\u00fan sea necesario.</p> <p>4. Generar informaci\u00f3n valiosa para la toma de decisiones estrat\u00e9gicas y operativas.</p>"},{"location":"03.Cubo/02.Tablas/","title":"02. TABLAS","text":""},{"location":"03.Cubo/02.Tablas/#tablas","title":"Tablas","text":""},{"location":"03.Cubo/02.Tablas/#tabla-transversal-dim_unidad","title":"Tabla: Transversal DIM_UNIDAD","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_UNIDAD es una dimensi\u00f3n que define las unidades organizacionales o funcionales del sistema. Esta tabla es fundamental para categorizar y segmentar datos relacionados con las actividades y procesos empresariales.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla","title":"Estructura de la Tabla","text":"<p>1. Nombre de la Tabla: <code>Transversal DIM_UNIDAD</code>.</p> <p>2. Columnas:</p> <ul> <li>ID_UNIDAD:<ul> <li>Tipo de Datos: <code>int64</code>.</li> <li>Descripci\u00f3n: Identificador \u00fanico de cada unidad.</li> <li>Columna Fuente: <code>ID_UNIDAD</code>.</li> </ul> </li> <li>UNIDAD:<ul> <li>Tipo de Datos: <code>string</code>.</li> <li>Descripci\u00f3n: Nombre descriptivo de la unidad.</li> <li>Columna Fuente: <code>UNIDAD</code>.</li> </ul> </li> </ul>"},{"location":"03.Cubo/02.Tablas/#particiones","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos de la tabla).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_UNIDAD = Source{[Schema=\"Transversal\", Item=\"DIM_UNIDAD\"]}[Data]\nin\n    Transversal_DIM_UNIDAD\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_UNIDAD se utiliza para:</p> <ul> <li>Proveer una referencia jer\u00e1rquica o categ\u00f3rica para an\u00e1lisis y segmentaciones.</li> <li>Establecer relaciones con otras tablas, como hechos o medidas, en el modelo sem\u00e1ntico del cubo.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#relacion-con-el-cubo","title":"Relaci\u00f3n con el Cubo","text":"<p>Esta tabla se integra con otras dimensiones y hechos para calcular medidas como: - N\u00famero de actividades por unidad. - Rendimiento de procesos espec\u00edficos.</p> <p>Entendido, aqu\u00ed est\u00e1 la documentaci\u00f3n ajustada con la numeraci\u00f3n en negritas dentro del formato Markdown:</p>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-dim_tiempo_mensual","title":"Tabla: Transversal DIM_TIEMPO_MENSUAL","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_TIEMPO_MENSUAL es una dimensi\u00f3n de tiempo que permite segmentar los datos en diferentes niveles temporales, como d\u00edas, semanas, meses, bimestres, trimestres, cuatrimestres, semestres y a\u00f1os. Proporciona una estructura detallada para an\u00e1lisis cronol\u00f3gicos.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_1","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA FECHA dateTime FECHA DESC_FECHA string DESC_FECHA ID_SEMANA int64 ID_SEMANA DESC_SEMANA string DESC_SEMANA ID_NO_MES int64 ID_NO_MES DESC_NO_MES string DESC_NO_MES ID_MES int64 ID_MES DESC_MES string DESC_MES DESC_MES_CORTA string DESC_MES_CORTA ID_BIMESTRE int64 ID_BIMESTRE DESC_BIMESTRE string DESC_BIMESTRE ID_TRIMESTRE int64 ID_TRIMESTRE DESC_TRIMESTRE string DESC_TRIMESTRE ID_CUATRIMESTRE int64 ID_CUATRIMESTRE DESC_CUATRIMESTRE string DESC_CUATRIMESTRE ID_SEMESTRE int64 ID_SEMESTRE DESC_SEMESTRE string DESC_SEMESTRE ID_ANIO int64 ID_ANIO ID_ANIO_ANT int64 ID_ANIO_ANT NUM_DIA_SEMANA int64 NUM_DIA_SEMANA FESTIVO int64 FESTIVO FECHA_CORTA dateTime FECHA_CORTA"},{"location":"03.Cubo/02.Tablas/#particiones_1","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:       <pre><code>let\n      Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n      Transversal_DIM_TIEMPO_MENSUAL = Source{[Schema=\"Transversal\",Item=\"DIM_TIEMPO_MENSUAL\"]}[Data]\nin\n      Transversal_DIM_TIEMPO_MENSUAL\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_1","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_TIEMPO_MENSUAL se utiliza para:</p> <ul> <li>Segmentar datos en intervalos de tiempo espec\u00edficos.</li> <li>Proporcionar jerarqu\u00edas temporales para an\u00e1lisis (d\u00eda, semana, mes, bimestre, trimestre, cuatrimestre, semestre y a\u00f1o).</li> <li>Relacionar datos temporales con otras dimensiones y hechos para an\u00e1lisis detallados.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-dim_categoria","title":"Tabla: Transversal DIM_CATEGORIA","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal DIM_CATEGORIA define las categor\u00edas utilizadas en el modelo para clasificar datos. Esta dimensi\u00f3n permite agrupar y segmentar informaci\u00f3n relacionada con diferentes \u00e1reas del sistema.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_2","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente COD_CATEGORIA string COD_CATEGORIA DESCRIPCION string DESCRIPCION"},{"location":"03.Cubo/02.Tablas/#particiones_2","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_DIM_CATEGORIA = Source{[Schema=\"Transversal\",Item=\"DIM_CATEGORIA\"]}[Data]\nin\n    Transversal_DIM_CATEGORIA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_2","title":"Prop\u00f3sito","text":"<p>La dimensi\u00f3n DIM_CATEGORIA se utiliza para:</p> <ul> <li>Clasificar informaci\u00f3n en grupos o categor\u00edas predefinidas.</li> <li>Relacionar datos categorizados con otras dimensiones y hechos para an\u00e1lisis m\u00e1s detallados.</li> <li>Facilitar la segmentaci\u00f3n de datos en reportes y consultas.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_actividades","title":"Tabla: Transversal FACT_ACTIVIDADES","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_ACTIVIDADES registra informaci\u00f3n detallada sobre las actividades realizadas por afiliados y empresas, incluyendo datos demogr\u00e1ficos, econ\u00f3micos, y sobre aportes. Esta tabla es clave para el an\u00e1lisis de hechos y m\u00e9tricas relacionadas con las actividades.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_3","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente PARTNER string PARTNER ID_EMPRESA int64 ID_EMPRESA ID_AFILIADO int64 ID_AFILIADO ID_TIPO_AFILIADO int64 ID_TIPO_AFILIADO TIPO_AFILIADO string TIPO_AFILIADO ID_CATEGORIA int64 ID_CATEGORIA FECHA_AFILIACION dateTime FECHA_AFILIACION FECHA_RETIRO dateTime FECHA_RETIRO ID_GENERO int64 ID_GENERO ID_ESTADO_CIVIL int64 ID_ESTADO_CIVIL ID_PERTENENCIA_ETNICA int64 ID_PERTENENCIA_ETNICA ID_FACTOR_VULNERABILIDAD int64 ID_FACTOR_VULNERABILIDAD ESTRATO int64 ESTRATO ID_CIUDAD int64 ID_CIUDAD SALARIO_BASICO double SALARIO_BASICO FECHA_MENSUAL dateTime FECHA_MENSUAL ID_FECHA int64 ID_FECHA ID_UNIDAD int64 ID_UNIDAD ESTADOREGISTRO string ESTADOREGISTRO PARTNER_AFILIADO string PARTNER_AFILIADO PARTNER_EMPRESA string PARTNER_EMPRESA TIPO_POBLACION string TIPO_POBLACION ACTIVIDAD string ACTIVIDAD TOTAL_APORTES double TOTAL_APORTES NUMERO_APORTES int64 NUMERO_APORTES"},{"location":"03.Cubo/02.Tablas/#particiones_3","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_ACTIVIDADES = Source{[Schema=\"Transversal\",Item=\"FACT_ACTIVIDADES\"]}[Data]\nin\n    Transversal_FACT_ACTIVIDADES\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_3","title":"Prop\u00f3sito","text":"<p>La tabla FACT_ACTIVIDADES se utiliza para:</p> <ul> <li>Analizar informaci\u00f3n demogr\u00e1fica, econ\u00f3mica y de aportes de afiliados y empresas.</li> <li>Calcular m\u00e9tricas relacionadas con actividades y aportes.</li> <li>Proveer datos detallados para informes y an\u00e1lisis multidimensionales.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_personal","title":"Tabla: Transversal FACT_PERSONAL","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_PERSONAL almacena informaci\u00f3n relacionada con el personal, sus asignaciones y las horas contratadas. Es \u00fatil para el an\u00e1lisis de recursos humanos y la planificaci\u00f3n operativa.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_4","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA ID_PERSONAL int64 ID_PERSONAL NOMBRE string NOMBRE CONCEPTO string CONCEPTO DESCRIPCION string DESCRIPCION FECHA_FIN dateTime FECHA_FIN HORAS_CONTRATADAS_MENSUAL int64 HORAS_CONTRATADAS_MENSUAL ID_UNIDAD int64 ID_UNIDAD"},{"location":"03.Cubo/02.Tablas/#particiones_4","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_PERSONAL = Source{[Schema=\"Transversal\",Item=\"FACT_PERSONAL\"]}[Data]\nin\n    Transversal_FACT_PERSONAL\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_4","title":"Prop\u00f3sito","text":"<p>La tabla FACT_PERSONAL se utiliza para:</p> <ul> <li>Analizar las asignaciones y contratos del personal.</li> <li>Monitorear las horas contratadas mensualmente.</li> <li>Relacionar los datos del personal con otras dimensiones para informes y planificaci\u00f3n estrat\u00e9gica.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_financiera","title":"Tabla: Transversal FACT_FINANCIERA","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_FINANCIERA contiene informaci\u00f3n detallada sobre los datos financieros de la organizaci\u00f3n, incluyendo cuentas, ingresos, gastos, y resultados. Es una fuente fundamental para el an\u00e1lisis financiero y la generaci\u00f3n de informes.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_5","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente ID_FECHA int64 ID_FECHA ID_ANIO int64 ID_ANIO ID_MES int64 ID_MES ID_CEBE string ID_CEBE CEBE string CEBE DESCRIPCION_CEBE string DESCRIPCION_CEBE DEPARTAMENTO string DEPARTAMENTO AREA string AREA SUBAREA string SUBAREA SEGMENTO string SEGMENTO DESCRIPCION_SEGMENTO string DESCRIPCION_SEGMENTO CODIGO_SSF int64 CODIGO_SSF NOMBRE_SSF string NOMBRE_SSF ID_CUENTA string ID_CUENTA CUENTA string CUENTA CUENTA_HOMOLOGA string CUENTA_HOMOLOGA DESCRIPCION string DESCRIPCION TIPO_CUENTA string TIPO_CUENTA TIPO_OPERACION string TIPO_OPERACION GRUPO_CUENTA string GRUPO_CUENTA SUBGRUPO_CUENTA string SUBGRUPO_CUENTA GRUPO_OPERACION string GRUPO_OPERACION CUENTA_SSF string CUENTA_SSF DESCRIPCION_SSF string DESCRIPCION_SSF CUENTA_DESCRIPCION string CUENTA_DESCRIPCION CUENTA_DESCRIPCION_SSF string CUENTA_DESCRIPCION_SSF SIGNO_INGRESOS int64 SIGNO_INGRESOS CLASIFICACION int64 CLASIFICACION SEGMENT string SEGMENT IMPORTE int64 IMPORTE INGRESOS int64 INGRESOS INGRESOS_OPERACIONALES int64 INGRESOS_OPERACIONALES GASTOS int64 GASTOS GASTOS_OPERACIONALES int64 GASTOS_OPERACIONALES GASTOS_OPERACIONALES_ADMIN int64 GASTOS_OPERACIONALES_ADMIN RESULTADO_EJERCICIO int64 RESULTADO_EJERCICIO COSTOS int64 COSTOS ACTIVO int64 ACTIVO PASIVO int64 PASIVO PATRIMONIO int64 PATRIMONIO GASTOS_CON_DISTRIBUCION int64 GASTOS_CON_DISTRIBUCION GASTOS_SIN_DISTRIBUCION int64 GASTOS_SIN_DISTRIBUCION"},{"location":"03.Cubo/02.Tablas/#particiones_5","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_FINANCIERA = Source{[Schema=\"Transversal\",Item=\"FACT_FINANCIERA\"]}[Data]\nin\n    Transversal_FACT_FINANCIERA\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_5","title":"Prop\u00f3sito","text":"<p>La tabla FACT_FINANCIERA se utiliza para:</p> <ul> <li>Analizar el comportamiento financiero de la organizaci\u00f3n.</li> <li>Evaluar ingresos, gastos, costos, y resultados financieros.</li> <li>Relacionar los datos financieros con otras dimensiones para an\u00e1lisis multidimensionales y generaci\u00f3n de informes detallados.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-transversal-fact_evaluacion_docente","title":"Tabla: Transversal FACT_EVALUACION_DOCENTE","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>La tabla Transversal FACT_EVALUACION_DOCENTE almacena informaci\u00f3n relacionada con las evaluaciones acad\u00e9micas de los docentes, incluyendo calificaciones definitivas, per\u00edodos acad\u00e9micos y datos personales. Es clave para el an\u00e1lisis del desempe\u00f1o docente.</p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_6","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente PERIODO_ACADEMICO string PERIODO_ACADEMICO ID_UNIDAD int64 ID_UNIDAD ID_PERSONAL int64 ID_PERSONAL NOMBRE_DOCENTE string NOMBRE_DOCENTE CALIFICACION_DEFINITIVA string CALIFICACION_DEFINITIVA ID_FECHA int64 ID_FECHA"},{"location":"03.Cubo/02.Tablas/#particiones_6","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>Partition</code>.</p> <p>2. Vista de Datos: <code>full</code> (carga completa de los datos).</p> <p>3. Fuente:</p> <ul> <li>Tipo: <code>m</code>.</li> <li>Expresi\u00f3n:      <pre><code>let\n    Source = #\"SQL/10 5 21 29\\bi;DWH_COMFENALCO\",\n    Transversal_FACT_EVALUACION_DOCENTE = Source{[Schema=\"Transversal\",Item=\"FACT_EVALUACION_DOCENTE\"]}[Data]\nin\n    Transversal_FACT_EVALUACION_DOCENTE\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_6","title":"Prop\u00f3sito","text":"<p>La tabla FACT_EVALUACION_DOCENTE se utiliza para:</p> <ul> <li>Analizar el desempe\u00f1o acad\u00e9mico de los docentes.</li> <li>Generar informes de calificaciones definitivas por per\u00edodo acad\u00e9mico.</li> <li>Relacionar datos de evaluaci\u00f3n docente con otras dimensiones como unidades y fechas.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#tabla-calculatedtableindicadores","title":"Tabla: CalculatedTableIndicadores","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>La tabla CalculatedTableIndicadores es una tabla calculada que contiene indicadores clave para el an\u00e1lisis y evaluaci\u00f3n del rendimiento en diversas \u00e1reas, como cobertura, movilidad acad\u00e9mica, promoci\u00f3n, deserci\u00f3n, matr\u00edculas, graduados, y satisfacci\u00f3n.</p> <p></p>"},{"location":"03.Cubo/02.Tablas/#estructura-de-la-tabla_7","title":"Estructura de la Tabla","text":"Columna Tipo de Datos Columna Fuente indicador string (calculada) [indicador]"},{"location":"03.Cubo/02.Tablas/#particiones_7","title":"Particiones","text":"<p>1. Nombre de la Partici\u00f3n: <code>CalculatedTable 1</code>.</p> <p>2. Fuente:</p> <ul> <li>Tipo: <code>calculated</code>.</li> <li>Expresi\u00f3n:      <pre><code>DATATABLE (\n    \"indicador\", STRING, \n    { \n        {\"Cumplimiento Cobertura\"},\n        {\"Cobertura Proyectada\"},\n        {\"Movilidad Academica\"},\n        {\"Porcentaje de Promoci\u00f3n\"},\n        {\"Porcentaje de Deserci\u00f3n\"},\n        {\"Cantidad de Matr\u00edculas\"},\n        {\"Cantidad de Graduados\"},\n        {\"Cantidad de PQRs\"},\n        {\"Nivel de satisfacci\u00f3n a partir de la NSU promedio\"},\n        {\"Promotores promedio del Proceso a partir de la NSU\"},\n        {\"Detractores promedio del Proceso a partir de la NSU\"}\n    }\n)\n</code></pre></li> </ul>"},{"location":"03.Cubo/02.Tablas/#proposito_7","title":"Prop\u00f3sito","text":"<p>La tabla CalculatedTableIndicadores se utiliza para:</p> <ul> <li>Listar y categorizar indicadores clave para el an\u00e1lisis.</li> <li>Servir como base para reportes y consultas espec\u00edficas relacionadas con la evaluaci\u00f3n del desempe\u00f1o.</li> <li>Proveer una visi\u00f3n consolidada de los indicadores m\u00e1s relevantes para la organizaci\u00f3n.</li> </ul>"},{"location":"03.Cubo/02.Tablas/#relaciones-del-modelo","title":"Relaciones del Modelo","text":""},{"location":"03.Cubo/02.Tablas/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>Las relaciones definen c\u00f3mo las tablas del modelo interact\u00faan entre s\u00ed, asegurando la coherencia y la integridad de los datos en los an\u00e1lisis. A continuaci\u00f3n se detallan las relaciones establecidas entre las tablas del modelo.</p> Nombre Tabla Origen Columna Origen Tabla Destino Columna Destino e8e7ee5e-2bb5-447c-8a42-40fa4ccf9143 Transversal FACT_ACTIVIDADES ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 1a8196d0-09e6-4d0c-9f29-4a8d0ff4ee13 Transversal FACT_ACTIVIDADES ID_CATEGORIA Transversal DIM_CATEGORIA COD_CATEGORIA e4a99626-9ef6-4da8-89db-664ec2a6d8c8 Transversal FACT_ACTIVIDADES ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 395ef55c-3800-4448-bc48-46690276bd39 Transversal FACT_PERSONAL ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA cdfe13d4-3917-431a-b0c9-b496df147a20 Transversal FACT_PERSONAL ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD a8efdf32-e907-42ab-a950-937906c7b167 Transversal FACT_EVALUACION_DOCENTE ID_UNIDAD Transversal DIM_UNIDAD ID_UNIDAD 632bc53c-67b6-4634-82f9-8adbfc71e691 Transversal FACT_EVALUACION_DOCENTE ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA 7246e8e1-e2c3-4a17-89eb-c077680b0f6b Transversal FACT_FINANCIERA ID_FECHA Transversal DIM_TIEMPO_MENSUAL ID_FECHA"},{"location":"03.Cubo/02.Tablas/#diagrama-de-relaciones-y-tablas","title":"Diagrama de Relaciones y Tablas","text":"<p>A continuaci\u00f3n, se presenta el diagrama de relaciones del modelo utilizando formato Mermaid para visualizar las conexiones entre tablas y sus relaciones:</p> <pre><code>graph TD\n    FACT_ACTIVIDADES[Transversal FACT_ACTIVIDADES]\n    FACT_PERSONAL[Transversal FACT_PERSONAL]\n    FACT_FINANCIERA[Transversal FACT_FINANCIERA]\n    FACT_EVALUACION_DOCENTE[Transversal FACT_EVALUACION_DOCENTE]\n    DIM_UNIDAD[Transversal DIM_UNIDAD]\n    DIM_CATEGORIA[Transversal DIM_CATEGORIA]\n    DIM_TIEMPO[Transversal DIM_TIEMPO_MENSUAL]\n\n    FACT_ACTIVIDADES --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_ACTIVIDADES --&gt; DIM_CATEGORIA[ID_CATEGORIA]\n    FACT_ACTIVIDADES --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_PERSONAL --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_FINANCIERA --&gt; DIM_TIEMPO[ID_FECHA]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_UNIDAD[ID_UNIDAD]\n    FACT_EVALUACION_DOCENTE --&gt; DIM_TIEMPO[ID_FECHA]</code></pre>"},{"location":"03.Cubo/02.Tablas/#explicacion-del-diagrama","title":"Explicaci\u00f3n del Diagrama","text":"<ol> <li> <p>Tablas de Hechos:</p> <ul> <li>FACT_ACTIVIDADES: Conecta con DIM_UNIDAD, DIM_CATEGORIA, y DIM_TIEMPO_MENSUAL.</li> <li>FACT_PERSONAL: Relacionada con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> <li>FACT_FINANCIERA: Conecta con DIM_TIEMPO_MENSUAL.</li> <li>FACT_EVALUACION_DOCENTE: Conecta con DIM_UNIDAD y DIM_TIEMPO_MENSUAL.</li> </ul> </li> <li> <p>Tablas de Dimensiones:</p> <ul> <li>DIM_UNIDAD: Relaciona hechos mediante el campo <code>ID_UNIDAD</code>.</li> <li>DIM_CATEGORIA: Relaciona hechos mediante el campo <code>ID_CATEGORIA</code>.</li> <li>DIM_TIEMPO_MENSUAL: Relaciona hechos mediante el campo <code>ID_FECHA</code>.</li> </ul> </li> </ol>"},{"location":"03.Cubo/02.Tablas/#proposito-de-las-relaciones","title":"Prop\u00f3sito de las Relaciones","text":"<ul> <li> <p>Conexi\u00f3n entre hechos y dimensiones: Permitir que las tablas de hechos como FACT_ACTIVIDADES, FACT_PERSONAL, FACT_FINANCIERA y FACT_EVALUACION_DOCENTE se relacionen directamente con sus dimensiones correspondientes.</p> </li> <li> <p>Integridad de Datos: Garantizar que los datos en el modelo est\u00e9n relacionados de manera l\u00f3gica y consistente.</p> </li> <li> <p>Facilitar el An\u00e1lisis Multidimensional: Habilitar an\u00e1lisis por jerarqu\u00edas y categor\u00edas, como tiempo, unidad, y categor\u00eda.</p> </li> </ul>"},{"location":"03.Cubo/03.ETL/","title":"03. ETL","text":"<p>El paquete SSIS \"FACT_MINERIA\" est\u00e1 dise\u00f1ado para gestionar procesos ETL (Extracci\u00f3n, Transformaci\u00f3n y Carga) enfocados en datos de actividades empresariales, afiliaciones, aportes, personal y evaluaciones. Este paquete asegura la correcta preparaci\u00f3n de tablas, la consolidaci\u00f3n de datos y la integraci\u00f3n eficiente en el Data Warehouse <code>DWH_COMFENALCO</code>, proporcionando una base s\u00f3lida para an\u00e1lisis y generaci\u00f3n de reportes.</p> <p>El paquete SSIS \"FACT_MINERIA\" centraliza datos clave de actividades empresariales, afiliaciones, aportes, personal y evaluaciones, asegurando su calidad y consistencia. Adem\u00e1s, prepara las tablas destino para la carga eficiente y garantiza la integridad referencial de los datos.</p> <p>Este paquete se encarga de:</p> <ol> <li>Extracci\u00f3n de Datos: Recopila informaci\u00f3n de diversas fuentes, incluyendo archivos Excel, CSV y bases de datos, para asegurar una cobertura completa de los datos necesarios.</li> <li>Transformaci\u00f3n de Datos: Realiza conversiones de tipos, validaciones y derivaciones de columnas para asegurar que los datos sean consistentes y est\u00e9n listos para su an\u00e1lisis.</li> <li>Carga de Datos: Inserta los datos transformados en el Data Warehouse <code>DWH_COMFENALCO</code>, utilizando t\u00e9cnicas de inserci\u00f3n masiva para optimizar el rendimiento.</li> <li>Preparaci\u00f3n de Tablas: Limpia y crea tablas clave, asegurando que est\u00e9n listas para recibir nuevos datos sin duplicaciones ni inconsistencias.</li> <li>Validaciones: Verifica la integridad referencial y la consistencia de los datos, asegurando que todas las relaciones entre tablas sean correctas y que no haya datos faltantes o incorrectos.</li> </ol>"},{"location":"03.Cubo/03.ETL/#descripcion-del-paquete","title":"Descripci\u00f3n del Paquete","text":"<p>1. Preparaci\u00f3n de Tablas:</p> <ul> <li>Limpieza y creaci\u00f3n de tablas clave como:<ul> <li><code>FACT_UNIDADES</code></li> <li><code>FACT_ACTIVIDADES</code></li> <li><code>FACT_EVALUACION_DOCENTE</code></li> <li><code>FACT_FINANCIERA</code></li> <li><code>FACT_PERSONAL</code></li> <li><code>FACT_MINERIA</code></li> <li><code>DIM_TIEMPO_MENSUAL</code></li> </ul> </li> <li>Acciones realizadas:<ul> <li>Si las tablas existen: <code>TRUNCATE TABLE</code>.</li> <li>Si no existen: <code>CREATE TABLE</code>.</li> </ul> </li> </ul> <p>2. Extracci\u00f3n de Datos:</p> <ul> <li>Fuentes principales:<ul> <li>Archivos Excel y CSV.</li> <li>Bases de Datos:</li> <li><code>DIM_EMPRESAS</code></li> <li><code>DIM_AFILIADOS</code></li> <li><code>FACT_APORTES_SHR_DET</code></li> <li><code>FACT_PERSONAL</code></li> <li><code>FACT_FINANCIERA</code></li> </ul> </li> <li>Herramientas utilizadas:<ul> <li>Conexiones ADO.NET para consultas optimizadas.</li> <li>Scripts Python para automatizaci\u00f3n de validaciones y restauraciones.</li> <li>Paquetes SSIS para la integraci\u00f3n y transformaci\u00f3n de datos.</li> </ul> </li> </ul> <p>3. Transformaci\u00f3n de Datos:</p> <ul> <li>Comprobaciones en tablas maestras como <code>DIM_TIEMPO_MENSUAL</code> y <code>DIM_POBLACION</code>.</li> <li>Conversi\u00f3n de Tipos (<code>Data Conversion</code>):<ul> <li>Asegura la compatibilidad de los tipos de datos con las tablas destino.</li> </ul> </li> <li>Columnas Derivadas (<code>Derived Column</code>):<ul> <li>Generaci\u00f3n de valores calculados como <code>ID_FECHA</code> y agregados mensuales.</li> </ul> </li> <li>Validaciones (<code>Lookup</code>):<ul> <li>Verificaci\u00f3n de integridad referencial y consistencia de datos.</li> </ul> </li> </ul> <p>4. Carga de Datos en el Data Warehouse:</p> <ul> <li>Tablas procesadas:<ul> <li><code>FACT_ACTIVIDADES</code></li> <li><code>FACT_PERSONAL</code></li> <li><code>FACT_EVALUACION_DOCENTE</code></li> <li><code>FACT_FINANCIERA</code></li> <li><code>FACT_MINERIA</code></li> <li><code>DIM_TIEMPO_MENSUAL</code></li> </ul> </li> <li>Configuraci\u00f3n:<ul> <li>Inserciones masivas habilitadas para maximizar el rendimiento.</li> <li>Uso de conexiones ADO.NET y scripts Python para optimizar la carga y validaci\u00f3n de datos.</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#tablas-y-columnas-clave","title":"Tablas y Columnas Clave","text":"<p>1. FACT_ACTIVIDADES:</p> <ul> <li><code>PARTNER</code>, <code>ID_EMPRESA</code>, <code>ID_AFILIADO</code>, <code>ID_TIPO_AFILIADO</code>, <code>TIPO_AFILIADO</code>, <code>ID_CATEGORIA</code>, <code>FECHA_AFILIACION</code>, <code>FECHA_RETIRO</code>, <code>ID_GENERO</code>, <code>ID_ESTADO_CIVIL</code>, <code>ID_PERTENENCIA_ETNICA</code>, <code>ID_FACTOR_VULNERABILIDAD</code>, <code>ESTRATO</code>, <code>ID_CIUDAD</code>, <code>SALARIO_BASICO</code>, <code>FECHA_MENSUAL</code>, <code>ID_FECHA</code>, <code>ID_UNIDAD</code>, <code>ESTADOREGISTRO</code>, <code>PARTNER_AFILIADO</code>, <code>PARTNER_EMPRESA</code>, <code>TIPO_POBLACION</code>, <code>ACTIVIDAD</code>.</li> </ul> <p>2. FACT_PERSONAL:</p> <ul> <li><code>ID_PERSONAL</code>, <code>NOMBRE</code>, <code>CONCEPTO</code>, <code>DESCRIPCION</code>, <code>FECHA_FIN</code>.</li> </ul> <p>3. FACT_EVALUACION_DOCENTE:</p> <ul> <li><code>PERIODO_ACADEMICO</code>, <code>ID_UNIDAD</code>, <code>ID_PERSONAL</code>, <code>NOMBRE_DOCENTE</code>, <code>CALIFICACION_DEFINITIVA</code>.</li> </ul> <p>4. FACT_FINANCIERA:</p> <ul> <li><code>ID_FECHA</code>, <code>ID_CEBE</code>, <code>DESCRIPCION_CEBE</code>, <code>DEPARTAMENTO</code>, <code>TOTAL</code>, <code>COSTOS</code>.</li> </ul> <p>5. DIM_TIEMPO_MENSUAL:</p> <ul> <li><code>ID_FECHA</code>, <code>FECHA</code>, <code>ID_MES</code>, <code>ID_ANIO</code>, <code>DESC_MES</code>.</li> </ul>"},{"location":"03.Cubo/03.ETL/#diagramas","title":"Diagramas","text":""},{"location":"03.Cubo/03.ETL/#1-diagrama-de-flujo-de-datos","title":"1. Diagrama de Flujo de Datos","text":"<pre><code>sequenceDiagram\n    participant SSIS as Paquete SSIS\n    participant SQLServer as Servidor SQL\n    participant ExcelCSV as Archivos Excel y CSV\n    participant Python as Scripts Python\n    participant DWH as Data Warehouse\n\n    SSIS -&gt;&gt; SQLServer: Extraer datos de diversas fuentes\n    SSIS -&gt;&gt; ExcelCSV: Procesar datos de archivos externos\n    SSIS -&gt;&gt; Python: Automatizar validaciones y restauraciones\n    SSIS -&gt;&gt; DWH: Cargar datos transformados en tablas destino</code></pre>"},{"location":"03.Cubo/03.ETL/#2-diagrama-er-para-tablas-de-hechos","title":"2. Diagrama ER para Tablas de Hechos","text":"<pre><code>erDiagram\n    FACT_ACTIVIDADES {\n        string PARTNER\n        int ID_EMPRESA\n        int ID_AFILIADO\n        date FECHA_AFILIACION\n        string TIPO_AFILIADO\n        string ACTIVIDAD\n    }\n    FACT_PERSONAL {\n        int ID_PERSONAL\n        string NOMBRE\n        string CONCEPTO\n        string DESCRIPCION\n        date FECHA_FIN\n    }\n    FACT_EVALUACION_DOCENTE {\n        string PERIODO_ACADEMICO\n        int ID_UNIDAD\n        int ID_PERSONAL\n        string NOMBRE_DOCENTE\n        float CALIFICACION_DEFINITIVA\n    }\n    FACT_FINANCIERA {\n        int ID_FECHA\n        int ID_CEBE\n        string DESCRIPCION_CEBE\n        string DEPARTAMENTO\n        float TOTAL\n        float COSTOS\n    }\n    DIM_TIEMPO_MENSUAL {\n        int ID_FECHA\n        date FECHA\n        int ID_MES\n        int ID_ANIO\n        string DESC_MES\n    }\n    FACT_ACTIVIDADES ||--|| FACT_PERSONAL : \"Relaci\u00f3n por personal\"\n    FACT_EVALUACION_DOCENTE ||--|| DIM_TIEMPO_MENSUAL : \"Relaci\u00f3n por fechas\"\n    FACT_FINANCIERA ||--|| DIM_TIEMPO_MENSUAL : \"Asociaci\u00f3n financiera por tiempo\"</code></pre>"},{"location":"03.Cubo/03.ETL/#componentes","title":"Componentes","text":""},{"location":"03.Cubo/03.ETL/#componente-truncar-tablas-cubo","title":"Componente <code>Truncar Tablas Cubo</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Truncar Tablas Cubo</code> es un componente de ejecuci\u00f3n SQL en un paquete SSIS dise\u00f1ado para preparar el entorno del Data Warehouse (<code>DWH_COMFENALCO</code>) antes de la carga de datos. Esta tarea asegura que las tablas destino est\u00e9n vac\u00edas eliminando todo su contenido mediante comandos <code>TRUNCATE TABLE</code>.</p>"},{"location":"03.Cubo/03.ETL/#proposito","title":"Prop\u00f3sito","text":"<ol> <li>Preparar el Data Warehouse: <ul> <li>Garantizar que las tablas destino no contengan datos previos que puedan causar duplicaci\u00f3n o inconsistencias.</li> </ul> </li> <li>Optimizar el rendimiento: <ul> <li>Al usar <code>TRUNCATE TABLE</code>, se eliminan r\u00e1pidamente todos los registros de las tablas sin registrar las operaciones de borrado individualmente.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas","title":"Tablas Afectadas","text":"<p>El componente ejecuta los comandos de truncado en las siguientes tablas:</p> <ol> <li> <p>[DWH_COMFENALCO].[Transversal].[FACT_UNIDADES]</p> <ul> <li>Tabla de hechos que contiene informaci\u00f3n relacionada con unidades operativas.</li> </ul> </li> <li> <p>[DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]</p> <ul> <li>Almacena datos consolidados de actividades relacionadas con afiliados, empresas y aportes.</li> </ul> </li> <li> <p>[DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE]</p> <ul> <li>Contiene evaluaciones de desempe\u00f1o docente.</li> </ul> </li> <li> <p>[DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA]</p> <ul> <li>Tabla de hechos para datos financieros.</li> </ul> </li> <li> <p>[DWH_COMFENALCO].[Transversal].[FACT_PERSONAL]</p> <ul> <li>Registra datos relacionados con personal, como ausentismo y contrataciones.</li> </ul> </li> <li> <p>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]</p> <ul> <li>Incluye informaci\u00f3n relevante a procesos de miner\u00eda de datos en el an\u00e1lisis educativo.</li> </ul> </li> <li> <p>[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]</p> <ul> <li>Dimensi\u00f3n que almacena informaci\u00f3n temporal organizada por meses.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada:</p> <pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_UNIDADES];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_EVALUACION_DOCENTE];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_FINANCIERA];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_PERSONAL];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_MINERIA];\nTRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL];\n</code></pre> <p>Caracter\u00edsticas del Comando:</p> <ul> <li>R\u00e1pido: Elimina todas las filas de las tablas especificadas sin afectar la estructura.</li> <li>Seguro: Restringe la eliminaci\u00f3n si hay claves for\u00e1neas activas que referencian las tablas.</li> </ul>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Paquete SSIS\n    participant SQLServer as Servidor SQL\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_UNIDADES\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_ACTIVIDADES\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_EVALUACION_DOCENTE\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_FINANCIERA\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_PERSONAL\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_MINERIA\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE DIM_TIEMPO_MENSUAL</code></pre> <p>La tarea <code>Truncar Tablas Cubo</code> es cr\u00edtica para la preparaci\u00f3n del entorno del Data Warehouse, asegurando que las tablas est\u00e9n listas para la carga de nuevos datos. El uso de <code>TRUNCATE TABLE</code> garantiza un proceso eficiente y r\u00e1pido de limpieza de datos.</p>"},{"location":"03.Cubo/03.ETL/#componente-dim_tiempo_mensual","title":"Componente <code>DIM_TIEMPO_MENSUAL</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_1","title":"Descripci\u00f3n General","text":"<p>El componente <code>DIM_TIEMPO_MENSUAL</code> es una tarea de flujo de datos (Data Flow Task) en un paquete SSIS dise\u00f1ada para cargar y mantener la tabla de dimensi\u00f3n temporal mensual en el Data Warehouse. Extrae datos de la tabla <code>Dwh.DIM_TIEMPO</code>, filtra los registros correspondientes al primer d\u00eda de cada mes de los \u00faltimos tres a\u00f1os, y los carga en la tabla <code>Transversal.DIM_TIEMPO_MENSUAL</code>. Este proceso garantiza que la dimensi\u00f3n temporal est\u00e9 actualizada para soportar an\u00e1lisis mensuales.</p>"},{"location":"03.Cubo/03.ETL/#proposito_1","title":"Prop\u00f3sito","text":"<ol> <li>Construir la dimensi\u00f3n temporal mensual:  <ul> <li>Proporcionar una estructura de datos consolidada para an\u00e1lisis basados en meses, trimestres, semestres y a\u00f1os.  </li> </ul> </li> <li>Optimizar consultas anal\u00edticas:  <ul> <li>Facilitar agregaciones r\u00e1pidas y filtros temporales en cubos OLAP o informes.  </li> </ul> </li> <li>Garantizar integridad temporal:  <ul> <li>Asegurar que solo se incluyan fechas v\u00e1lidas y relevantes (hasta junio de 2024 para la construcci\u00f3n inicial).  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_1","title":"Tablas Afectadas","text":"<ol> <li>[DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]:  <ul> <li>Tabla de origen que contiene datos detallados de tiempo (d\u00edas, semanas, meses, etc.).  </li> </ul> </li> <li>[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]:  <ul> <li>Tabla destino que almacena datos temporales agregados por mes, con jerarqu\u00edas precalculadas (trimestres, semestres, a\u00f1os).  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_1","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada en el Origen (ADO NET): <pre><code>WITH FechasPrimerDiaMes AS (\n    SELECT \n        [ID_FECHA],\n        [FECHA],\n        [DESC_FECHA],\n        [ID_SEMANA],\n        [DESC_SEMANA],\n        [ID_NO_MES],\n        [DESC_NO_MES],\n        [ID_MES],\n        [DESC_MES],\n        [DESC_MES_CORTA],\n        [ID_BIMESTRE],\n        [DESC_BIMESTRE],\n        [ID_TRIMESTRE],\n        [DESC_TRIMESTRE],\n        [ID_CUATRIMESTRE],\n        [DESC_CUATRIMESTRE],\n        [ID_SEMESTRE],\n        [DESC_SEMESTRE],\n        [ID_ANIO],\n        [ID_ANIO_ANT],\n        [NUM_DIA_SEMANA],\n        [FESTIVO],\n        [FECHA_CORTA]\n    FROM \n        [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]\n    WHERE \n        DATEPART(DAY, FECHA) = 1\n        AND ID_ANIO BETWEEN DATEPART(YEAR, GETDATE()) - 3 AND DATEPART(YEAR, GETDATE())\n)\nSELECT \n    [ID_FECHA],\n    [FECHA],\n    [DESC_FECHA],\n    [ID_SEMANA],\n    [DESC_SEMANA],\n    [ID_NO_MES],\n    [DESC_NO_MES],\n    [ID_MES],\n    [DESC_MES],\n    [DESC_MES_CORTA],\n    [ID_BIMESTRE],\n    [DESC_BIMESTRE],\n    [ID_TRIMESTRE],\n    [DESC_TRIMESTRE],\n    [ID_CUATRIMESTRE],\n    [DESC_CUATRIMESTRE],\n    [ID_SEMESTRE],\n    [DESC_SEMESTRE],\n    [ID_ANIO],\n    [ID_ANIO_ANT],\n    [NUM_DIA_SEMANA],\n    [FESTIVO],\n    [FECHA_CORTA]\nFROM \n    FechasPrimerDiaMes\n-- Filtro de fecha para construccion inicial. Comentar para actualizar \nWHERE [FECHA] &lt; '2024-06-01'\nORDER BY \n    [FECHA];\n</code></pre></p> <p>Caracter\u00edsticas del C\u00f3digo: - CTE <code>FechasPrimerDiaMes</code>: Filtra los primeros d\u00edas de cada mes dentro de un rango de 3 a\u00f1os. - Filtro inicial: Excluye fechas posteriores a junio de 2024 durante la construcci\u00f3n inicial.  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET </p> <ul> <li>Descripci\u00f3n: Extrae datos de la tabla <code>Dwh.DIM_TIEMPO</code> usando la consulta SQL anterior.  </li> <li>Propiedades clave:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera del comando: 30 segundos.  </li> <li>Modo de acceso: Consulta SQL.  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>Transversal.DIM_TIEMPO_MENSUAL</code>.  </li> <li>Propiedades clave:  <ul> <li>Tabla destino: <code>\"Transversal\".\"DIM_TIEMPO_MENSUAL\"</code>.  </li> <li>Inserci\u00f3n masiva: Habilitada (<code>UseBulkInsertWhenPossible = true</code>).  </li> <li>Tama\u00f1o de lote: 0 (usa el tama\u00f1o predeterminado del b\u00fafer).  </li> <li>Tiempo de espera del comando: 30 segundos.  </li> </ul> </li> </ul> </li> </ol> <p>Columnas Mapeadas (Ejemplos Clave): </p> Origen Destino Tipo de Dato <code>ID_FECHA</code> <code>ID_FECHA</code> Entero (i4) <code>FECHA</code> <code>FECHA</code> DateTime <code>DESC_MES</code> <code>DESC_MES</code> String (wstr) <code>ID_TRIMESTRE</code> <code>ID_TRIMESTRE</code> Entero (i4) <code>FECHA_CORTA</code> <code>FECHA_CORTA</code> Date"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_1","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET\n    participant Destino as Destino ADO NET\n    Origen-&gt;&gt;Destino: Extrae datos de DIM_TIEMPO (primer d\u00eda de mes)\n    Destino-&gt;&gt;Destino: Carga en DIM_TIEMPO_MENSUAL (Bulk Insert)</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-afiliacion-mensual-empresas-paquete-fact_actividades","title":"Componente <code>Afiliaci\u00f3n Mensual Empresas</code> (Paquete <code>FACT_ACTIVIDADES</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_2","title":"Descripci\u00f3n General","text":"<p>Este componente corresponde a un Data Flow Task que realiza el proceso de extracci\u00f3n, transformaci\u00f3n y carga (ETL) para registrar informaci\u00f3n de afiliaci\u00f3n mensual de empresas en la tabla <code>Transversal.FACT_ACTIVIDADES</code>. El flujo est\u00e1 compuesto por dos componentes principales: Origen ADO NET y Destino ADO NET.</p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_1","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Empresas (Origen de ADO NET):</p> <ul> <li>Descripci\u00f3n: Este componente extrae datos desde la base de datos SQL Server utilizando una instrucci\u00f3n SQL optimizada con m\u00faltiples CTEs.</li> <li>Propiedades:<ul> <li>Consulta SQL:   <pre><code>WITH MinFecha AS (\n    SELECT MIN(FECHA) AS MinFecha\n    FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n),\nMaxFecha AS (\n    SELECT MAX(FECHA) AS MaxFecha\n    FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n),\nEmpresas AS (\n    SELECT\n        [ID_EMPRESA],\n        [PARTNER],\n        CAST([FECHA_AFILIACION] AS DATE) AS [FECHA_AFILIACION],\n        [FECHA_FUNDACION],\n        CAST([FECHA_RETIRO] AS DATE) AS [FECHA_RETIRO],\n        [ESTADO],\n        [ESTADOREGISTRO],\n        [COD_CIUDAD]\n    FROM \n        [DWH_COMFENALCO].[Aportes].[DIM_EMPRESAS]\n    WHERE [ESTADO] = 'VIGEN' AND [ESTADOREGISTRO] = 'CURRENT'\n),\nEmpresasOptimizado AS (\n    SELECT \n        [ID_EMPRESA],\n        [PARTNER],\n        [FECHA_FUNDACION],\n        CASE \n            WHEN [FECHA_AFILIACION] &lt;= (SELECT MinFecha FROM MinFecha) THEN COALESCE(CAST((SELECT MinFecha FROM MinFecha) AS DATE), CAST(GETDATE() AS DATE))\n            ELSE [FECHA_AFILIACION]\n        END AS [FECHA_AFILIACION],\n        CASE \n            WHEN [FECHA_RETIRO] &gt;= (SELECT MaxFecha FROM MaxFecha) THEN COALESCE(CAST((SELECT MaxFecha FROM MaxFecha) AS DATE), CAST(GETDATE() AS DATE))\n            ELSE [FECHA_RETIRO]\n        END AS [FECHA_RETIRO],\n        [ESTADOREGISTRO],\n        [ESTADO],\n        [COD_CIUDAD]\n    FROM Empresas\n),\nEmpresasPorMes AS (\n    SELECT \n        e.[ID_EMPRESA],\n        e.[PARTNER],\n        e.[FECHA_AFILIACION],\n        e.[FECHA_FUNDACION],\n        e.[FECHA_RETIRO],\n        e.[ESTADOREGISTRO],\n        e.[ESTADO],\n        e.[COD_CIUDAD],\n        ds.FECHA_CORTA AS FECHA_MENSUAL,\n        ds.ID_FECHA,\n        5 AS ID_UNIDAD\n    FROM \n        EmpresasOptimizado e\n    INNER JOIN \n        [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] ds ON ds.FECHA_CORTA BETWEEN e.[FECHA_AFILIACION] AND COALESCE(e.[FECHA_RETIRO], GETDATE())\n)\nSELECT \n    em.[PARTNER],\n    em.[ID_EMPRESA],\n    -1 AS ID_AFILIADO,\n    -1 AS ID_TIPO_AFILIADO,\n    NULL AS TIPO_AFILIADO,\n    5 AS ID_CATEGORIA, \n    em.[FECHA_AFILIACION],\n    em.[FECHA_RETIRO],\n    -1 AS ID_GENERO,\n    -1 AS ID_ESTADO_CIVIL,\n    -1 AS ID_PERTENENCIA_ETNICA,\n    -1 AS ID_FACTOR_VULNERABILIDAD,\n    NULL AS ESTRATO,\n    em.[COD_CIUDAD] AS ID_CIUDAD,\n    NULL AS SALARIO_BASICO,\n    em.[FECHA_MENSUAL],\n    em.[ID_FECHA],\n    em.[ID_UNIDAD],\n    em.[ESTADOREGISTRO],\n    -1 AS PARTNER_AFILIADO,\n    em.[PARTNER] AS PARTNER_EMPRESA,\n    'EMPRESA' AS TIPO_POBLACION,\n    'AFILIACION' AS ACTIVIDAD\nFROM \n    EmpresasPorMes em\nORDER BY \n    em.[ID_EMPRESA], em.[FECHA_MENSUAL];\n</code></pre></li> <li>Tiempo de espera del comando (CommandTimeout): 30 segundos.</li> <li>Conexi\u00f3n: <code>[DWH_COMFENALCO]</code>, manejado por un administrador de conexiones.</li> </ul> </li> </ul> </li> <li> <p>Destino de ADO NET:</p> <ul> <li>Descripci\u00f3n: Este componente carga los datos procesados en la tabla <code>Transversal.FACT_ACTIVIDADES</code> en la base de datos destino.</li> <li>Propiedades:<ul> <li>Nombre de la tabla o vista: <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code>.</li> <li>Tama\u00f1o del lote (BatchSize): 0 (utiliza el tama\u00f1o predeterminado del b\u00fafer).</li> <li>Uso de inserci\u00f3n masiva (UseBulkInsertWhenPossible): Habilitado para mejorar el rendimiento.</li> <li>Tiempo de espera del comando (CommandTimeout): 30 segundos.</li> <li>Conexi\u00f3n: <code>[DWH_COMFENALCO]</code>, manejado por un administrador de conexiones.</li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_2","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Paquete SSIS\n    participant SQL as Origen de ADO NET (Empresas)\n    participant ADO as Destino de ADO NET\n\n    SSIS -&gt;&gt; SQL: Ejecuta consulta SQL (con CTEs)\n    SQL --&gt;&gt; SSIS: Devuelve datos transformados\n    SSIS -&gt;&gt; ADO: Carga datos en FACT_ACTIVIDADES\n    ADO --&gt;&gt; SSIS: Confirma la inserci\u00f3n</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-afiliacion-mensual-afiliados-paquete-fact_actividades","title":"Componente <code>Afiliaci\u00f3n mensual Afiliados</code> (Paquete <code>FACT_ACTIVIDADES</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_3","title":"Descripci\u00f3n General","text":"<p>El componente <code>Afiliaci\u00f3n mensual Afiliados</code> extrae, transforma y carga datos relacionados con afiliados en el sistema DWH_COMFENALCO. Este proceso genera datos mensualizados para afiliados activos y los carga en la tabla <code>FACT_ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_2","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Componente: <code>Afiliados</code></p> <p>Descripci\u00f3n: Este componente realiza la extracci\u00f3n de datos de la tabla <code>[DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS]</code>, mensualiza la informaci\u00f3n y filtra afiliados activos.</p> <p>Propiedades:</p> <ul> <li> <p>SQLCommand: <pre><code>WITH MaxFecha AS (\n    SELECT MAX(FECHA) AS MaxFecha\n    FROM [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]\n),\nNumberSeries AS (\n    SELECT ROW_NUMBER() OVER (ORDER BY (SELECT NULL)) - 1 AS Number\n    FROM [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO]\n),\nDateSeries AS (\n    SELECT \n        DATEADD(MONTH, Number, DATEFROMPARTS(YEAR(MaxFecha) - 3, 1, 1)) AS MonthDate,\n        CONVERT(INT, FORMAT(DATEADD(MONTH, Number, DATEFROMPARTS(YEAR(MaxFecha) - 3, 1, 1)), 'yyyyMMdd')) AS ID_FECHA\n    FROM \n        NumberSeries\n    CROSS JOIN \n        MaxFecha\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dtm \n        ON dtm.ID_FECHA = CONVERT(INT, FORMAT(DATEADD(MONTH, Number, DATEFROMPARTS(YEAR(MaxFecha) - 3, 1, 1)), 'yyyyMMdd'))\n    WHERE \n        Number BETWEEN 0 AND DATEDIFF(MONTH, DATEFROMPARTS(YEAR(MaxFecha) - 3, 1, 1), MaxFecha)\n),\nAfiliadosPorMes AS (\n    SELECT \n        a.[ID_AFILIADO], a.[PARTNER], a.[ID_TIPO_AFILIADO], a.[TIPO_AFILIADO],\n        a.[ID_CATEGORIA], a.[FECHA_AFILIACION], a.[FECHA_RETIRO],\n        a.[ID_GENERO], a.[ID_ESTADO_CIVIL], a.[ID_PERTENENCIA_ETNICA],\n        a.[ID_FACTOR_VULNERABILIDAD], a.[ESTRATO], a.[ID_CIUDAD],\n        a.[SALARIO_BASICO], a.[APORTANTE], a.[ESTADOREGISTRO],\n        ds.MonthDate AS FECHA_MENSUAL, ds.ID_FECHA, 5 AS ID_UNIDAD\n    FROM \n        [DWH_COMFENALCO].[Aportes].[DIM_AFILIADOS] a\n    INNER JOIN \n        DateSeries ds \n        ON ds.MonthDate BETWEEN a.[FECHA_AFILIACION] AND COALESCE(a.[FECHA_RETIRO], GETDATE())\n)\nSELECT \n    am.[PARTNER], -1 AS ID_EMPRESA, am.[ID_AFILIADO], am.[ID_TIPO_AFILIADO],\n    am.[TIPO_AFILIADO], am.[ID_CATEGORIA], am.[FECHA_AFILIACION],\n    am.[FECHA_RETIRO], am.[ID_GENERO], am.[ID_ESTADO_CIVIL],\n    am.[ID_PERTENENCIA_ETNICA], am.[ID_FACTOR_VULNERABILIDAD],\n    am.[ESTRATO], am.[ID_CIUDAD], am.[SALARIO_BASICO],\n    am.[FECHA_MENSUAL], am.[ID_FECHA], am.[ID_UNIDAD], am.[ESTADOREGISTRO],\n    am.[PARTNER] AS PARTNER_AFILIADO, NULL AS PARTNER_EMPRESA,\n    'AFILIADO' AS TIPO_POBLACION, 'AFILIACION' AS ACTIVIDAD\nFROM \n    AfiliadosPorMes am;\n</code></pre></p> </li> <li> <p>CommandTimeout: <code>600 segundos</code></p> </li> <li>Columnas de salida principales: <ul> <li><code>PARTNER</code></li> <li><code>ID_AFILIADO</code></li> <li><code>FECHA_MENSUAL</code></li> <li><code>TIPO_AFILIADO</code></li> <li><code>ESTADOREGISTRO</code></li> </ul> </li> </ul> </li> <li> <p>Componente: <code>Destino de ADO NET 1</code></p> <p>Descripci\u00f3n: Carga los datos procesados por el componente <code>Afiliados</code> en la tabla <code>FACT_ACTIVIDADES</code>.</p> <p>Propiedades:</p> <ul> <li>Tabla destino: <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code></li> <li>BatchSize: <code>0</code></li> <li>UseBulkInsertWhenPossible: <code>true</code></li> <li>Tiempo de espera del comando: <code>30 segundos</code></li> </ul> <p>Columnas principales de entrada:</p> <ul> <li><code>PARTNER</code></li> <li><code>ID_AFILIADO</code></li> <li><code>TIPO_AFILIADO</code></li> <li><code>FECHA_MENSUAL</code></li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_3","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Afiliados as Extracci\u00f3n SQL\n    participant DataFlow as Data Flow Task\n    participant FACT_ACTIVIDADES as Tabla Destino\n\n    Afiliados -&gt;&gt; DataFlow: Proceso y transformaci\u00f3n\n    DataFlow -&gt;&gt; FACT_ACTIVIDADES: Inserta registros</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-afiliacion-mensual-beneficiarios-paquete-fact_actividades","title":"Componente <code>Afiliaci\u00f3n Mensual Beneficiarios</code> (Paquete <code>FACT_ACTIVIDADES</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_4","title":"Descripci\u00f3n General","text":"<p>El componente <code>Afiliaci\u00f3n Mensual Beneficiarios</code> es un flujo de datos que procesa y carga informaci\u00f3n relacionada con los beneficiarios de afiliaciones mensuales. Utiliza consultas SQL avanzadas para extraer, transformar y cargar datos desde la base de datos fuente hacia el destino en la tabla <code>Transversal.FACT_ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#sql-utilizado","title":"SQL Utilizado","text":"<p>El flujo de datos incluye la siguiente instrucci\u00f3n SQL para procesar la informaci\u00f3n:</p> <pre><code>WITH MinFecha AS (\n    SELECT MIN(FECHA) AS MinFecha\n    FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n),\nMaxFecha AS (\n    SELECT MAX(FECHA) AS MaxFecha\n    FROM [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n),\nBeneficiarios AS (\n    SELECT \n        [ID_BENEFICIARIO],\n        [PARTNER],\n        COALESCE(TRY_CAST([FECHA_AFILIACION] AS DATE), CAST(GETDATE() AS DATE)) as [FECHA_AFILIACION],\n        CASE \n            WHEN COALESCE([FECHA_RETIRO], CAST(GETDATE() AS DATE)) = '1900-01-01' THEN '9999-12-31'\n            ELSE COALESCE([FECHA_RETIRO], CAST(GETDATE() AS DATE))\n        END AS [FECHA_RETIRO],\n        [ID_GENERO],\n        [ID_ESTADO_CIVIL],\n        [ESTRATO],\n        [ID_CIUDAD],\n        [ID_PARENT_SAP],\n        [PARENT_SAP],\n        [APORTANTE],\n        [TIPO_AFILIADO],\n        [TIPO_APORTANTE],\n        [ESTADOREGISTRO],\n        FECHA_INGRESO_EMPRESA\n    FROM \n        [DWH_COMFENALCO].[Aportes].[DIM_BENEFICIARIOS]\n    WHERE \n        [ESTADOREGISTRO] = 'CURRENT' AND [TIPO_APORTANTE] = 'X' \n),\nBeneficiariosPosibles AS (\n    SELECT *,\n        ROW_NUMBER() OVER (PARTITION BY PARTNER ORDER BY CASE WHEN FECHA_INGRESO_EMPRESA = '' THEN 99991231 END) AS ROWNUM\n    FROM Beneficiarios\n    WHERE FECHA_RETIRO &gt;= (SELECT MinFecha FROM MinFecha)\n),\nFilteredBeneficiarios AS (\n    SELECT *\n    FROM BeneficiariosPosibles\n    WHERE ROWNUM = 1\n),\nBeneficiariosOptimizado AS (\n    SELECT \n        [ID_BENEFICIARIO],\n        [PARTNER],\n        CASE \n            WHEN [FECHA_AFILIACION] &lt;= (SELECT MinFecha FROM MinFecha) THEN COALESCE(CAST((SELECT MinFecha FROM MinFecha) AS DATE), CAST(GETDATE() AS DATE))\n            ELSE [FECHA_AFILIACION]\n        END AS [FECHA_AFILIACION],\n        CASE \n            WHEN [FECHA_RETIRO] &gt;= (SELECT MaxFecha FROM MaxFecha) THEN COALESCE(CAST((SELECT MaxFecha FROM MaxFecha) AS DATE), CAST(GETDATE() AS DATE))\n            ELSE [FECHA_RETIRO]\n        END AS [FECHA_RETIRO],\n        [ID_GENERO],\n        [ID_ESTADO_CIVIL],\n        [ESTRATO],\n        [ID_CIUDAD],\n        [ID_PARENT_SAP],\n        [PARENT_SAP],\n        [APORTANTE],\n        [TIPO_AFILIADO],\n        [TIPO_APORTANTE],\n        [ESTADOREGISTRO]\n    FROM FilteredBeneficiarios\n),\nBeneficiariosPorMes AS (\n    SELECT \n        b.[ID_BENEFICIARIO],\n        b.[PARTNER],\n        b.[FECHA_AFILIACION],\n        b.[FECHA_RETIRO],\n        b.[ID_GENERO],\n        b.[ID_ESTADO_CIVIL],\n        b.[ESTRATO],\n        b.[ID_CIUDAD],\n        b.[ID_PARENT_SAP],\n        b.[PARENT_SAP],\n        b.[APORTANTE],\n        b.[TIPO_AFILIADO],\n        b.[TIPO_APORTANTE],\n        b.[ESTADOREGISTRO],\n        ds.FECHA_CORTA AS FECHA_MENSUAL,\n        ds.ID_FECHA,\n        ROW_NUMBER() OVER (PARTITION BY b.[ID_BENEFICIARIO], ds.ID_FECHA ORDER BY ds.FECHA_CORTA DESC) AS RN\n    FROM \n        BeneficiariosOptimizado b\n    INNER JOIN \n        [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] ds ON ds.FECHA_CORTA BETWEEN b.[FECHA_AFILIACION] AND COALESCE(b.[FECHA_RETIRO], GETDATE())\n)\nSELECT \n    bm.[PARTNER],\n    -1 AS ID_EMPRESA,\n    -1 AS ID_AFILIADO,\n    bm.[ID_BENEFICIARIO],\n    -1 AS ID_TIPO_AFILIADO,\n    NULL AS TIPO_AFILIADO,\n    -1 AS ID_CATEGORIA,\n    bm.[FECHA_AFILIACION],\n    bm.[FECHA_RETIRO],\n    bm.[ID_GENERO],\n    bm.[ID_ESTADO_CIVIL],\n    -1 AS ID_PERTENENCIA_ETNICA,\n    -1 AS ID_FACTOR_VULNERABILIDAD,\n    bm.[ESTRATO],\n    bm.[ID_CIUDAD],\n    NULL AS SALARIO_BASICO,\n    bm.[FECHA_MENSUAL],\n    bm.[ID_FECHA],\n    5 AS ID_UNIDAD,\n    bm.[ESTADOREGISTRO],\n    bm.[ID_PARENT_SAP] AS PARTNER_AFILIADO,\n    bm.[PARENT_SAP] AS PARTNER_EMPRESA,\n    'BENEFICIARIO' AS TIPO_POBLACION,\n    'AFILIACION' AS ACTIVIDAD\nFROM \n    BeneficiariosPorMes bm\nWHERE bm.RN = 1;\n</code></pre>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_3","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: Beneficiarios </p> <ul> <li>Descripci\u00f3n: Extrae datos de la tabla <code>DIM_BENEFICIARIOS</code> usando la instrucci\u00f3n SQL anterior.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.</li> </ul> </li> <li> <p>Transformaci\u00f3n: L\u00f3gica SQL </p> <ul> <li>Descripci\u00f3n: Implementa filtros y c\u00e1lculos avanzados, como la optimizaci\u00f3n de fechas y la generaci\u00f3n de datos por mes.</li> </ul> </li> <li> <p>Destino ADO NET </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla destino <code>Transversal.FACT_ACTIVIDADES</code>.</li> <li>Propiedades clave:<ul> <li>Nombre de la tabla: <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code></li> <li>Tama\u00f1o de lote: <code>0</code> (uso predeterminado).</li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_4","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS-&gt;&gt;SQL: Ejecuta consulta SQL para extraer datos\n    SQL-&gt;&gt;SSIS: Retorna datos procesados\n    SSIS-&gt;&gt;SQL: Carga datos en `FACT_ACTIVIDADES`</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-fact_actividades_pqrs-paquete-fact_actividades","title":"Componente <code>FACT_ACTIVIDADES_PQRS</code> (Paquete <code>FACT_ACTIVIDADES</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_5","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_ACTIVIDADES_PQRS</code> extrae, transforma y carga datos relacionados con las actividades de PQR (Preguntas, Quejas y Reclamos) hacia la tabla <code>Transversal.FACT_ACTIVIDADES</code> en el almac\u00e9n de datos. Integra informaci\u00f3n desde m\u00faltiples dimensiones y tablas de hechos para consolidar los datos de actividades clasificadas por afiliados, beneficiarios, empresas y no aportantes.</p>"},{"location":"03.Cubo/03.ETL/#sql-utilizado_1","title":"SQL Utilizado","text":"<p>El componente utiliza la siguiente instrucci\u00f3n SQL para extraer y transformar los datos de origen:</p> <pre><code>-- Afiliado\nSELECT fp.[ID_PQR],\n    fp.[ID_UNIDAD],\n(\n        CAST(\n            SUBSTRING(CAST(fp.[ID_FECHA] AS VARCHAR), 1, 6) + '01' AS INT\n        )\n    ) AS ID_FECHA,\n    fp.[ESTADO] AS ESTADO_PQR,\n    fp.[ID_EMPRESA],\n    fp.[ID_AFILIADO],\n    fp.[ID_BENEFICIARIO],\n    'PQR' AS ACTIVIDAD,\n    fp.[CAUSA] AS CAUSA_PQR,\n    fp.[TIPO_PQRS],\n    a.[PARTNER],\n    a.[ID_TIPO_AFILIADO],\n    a.[TIPO_AFILIADO],\n    a.[ID_CATEGORIA],\n    a.[FECHA_AFILIACION],\n    a.[FECHA_RETIRO],\n    a.[ID_GENERO],\n    a.[ID_ESTADO_CIVIL],\n    a.[ID_PERTENENCIA_ETNICA],\n    a.[ID_FACTOR_VULNERABILIDAD],\n    a.[ESTRATO],\n    a.[ID_CIUDAD],\n    a.[SALARIO_BASICO],\n    a.[ESTADOREGISTRO],\n    a.[PARTNER] AS PARTNER_AFILIADO,\n    NULL AS PARTNER_EMPRESA,\n    -1 AS APORTANTE,\n    -1 AS TIPO_APORTANTE,\n    NULL AS FECHA_INGRESO_EMPRESA\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] fp\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON (\n        CAST(\n            SUBSTRING(CAST(fp.[ID_FECHA] AS VARCHAR), 1, 6) + '01' AS INT\n        )\n    ) = tm.[ID_FECHA]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a ON fp.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE fp.ID_AFILIADO != -1\nUNION ALL\n-- Beneficiario\nSELECT fp.[ID_PQR],\n    fp.[ID_UNIDAD],\n(\n        CAST(\n            SUBSTRING(CAST(fp.[ID_FECHA] AS VARCHAR), 1, 6) + '01' AS INT\n        )\n    ) AS ID_FECHA,\n    fp.[ESTADO] AS ESTADO_PQR,\n    fp.[ID_EMPRESA],\n    fp.[ID_AFILIADO],\n    fp.[ID_BENEFICIARIO],\n    'PQR' AS ACTIVIDAD,\n    fp.[CAUSA] AS CAUSA_PQR,\n    fp.[TIPO_PQRS],\n    b.[PARTNER],\n    -1 AS ID_TIPO_AFILIADO,\n    NULL AS TIPO_AFILIADO,\n    4 AS ID_CATEGORIA,\n    NULL AS FECHA_AFILIACION,\n    NULL AS FECHA_RETIRO,\n    b.[ID_GENERO],\n    b.[ID_ESTADO_CIVIL],\n    -1 AS ID_PERTENENCIA_ETNICA,\n    -1 AS ID_FACTOR_VULNERABILIDAD,\n    b.[ESTRATO],\n    b.[ID_CIUDAD],\n    NULL AS SALARIO_BASICO,\n    b.[ESTADOREGISTRO],\n    b.[ID_PARENT_SAP] AS PARTNER_AFILIADO,\n    b.[PARENT_SAP] AS PARTNER_EMPRESA,\n    b.[APORTANTE],\n    NULL AS TIPO_APORTANTE,\n    b.[FECHA_INGRESO_EMPRESA]\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] fp\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON (\n        CAST(\n            SUBSTRING(CAST(fp.[ID_FECHA] AS VARCHAR), 1, 6) + '01' AS INT\n        )\n    ) = tm.[ID_FECHA]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b ON fp.[ID_BENEFICIARIO] = b.[ID_BENEFICIARIO]\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a ON b.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE fp.ID_BENEFICIARIO != -1\nUNION ALL\n-- Empresa\nSELECT fp.[ID_PQR],\n    fp.[ID_UNIDAD],\n(\n        CAST(\n            SUBSTRING(CAST(fp.[ID_FECHA] AS VARCHAR), 1, 6) + '01' AS INT\n        )\n    ) AS ID_FECHA,\n    fp.[ESTADO] AS ESTADO_PQR,\n    fp.[ID_EMPRESA],\n    fp.[ID_AFILIADO],\n    fp.[ID_BENEFICIARIO],\n    'PQR' AS ACTIVIDAD,\n    fp.[CAUSA] AS CAUSA_PQR,\n    fp.[TIPO_PQRS],\n    em.[PARTNER],\n    NULL AS ID_TIPO_AFILIADO,\n    NULL AS TIPO_AFILIADO,\n    5 AS ID_CATEGORIA,\n    em.[FECHA_AFILIACION],\n    em.[FECHA_RETIRO],\n    -1 AS ID_GENERO,\n    -1 AS ID_ESTADO_CIVIL,\n    -1 AS ID_PERTENENCIA_ETNICA,\n    -1 AS ID_FACTOR_VULNERABILIDAD,\n    NULL AS ESTRATO,\n    em.[COD_CIUDAD] AS ID_CIUDAD,\n    NULL AS SALARIO_BASICO,\n    em.[ESTADOREGISTRO],\n    -1 AS PARTNER_AFILIADO,\n    NULL AS APORTANTE,\n    NULL AS TIPO_APORTANTE,\n    NULL AS FECHA_INGRESO_EMPRESA,\n    em.[PARTNER] AS PARTNER_EMPRESA\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] fp\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON (\n        CAST(\n            SUBSTRING(CAST(fp.[ID_FECHA] AS VARCHAR), 1, 6) + '01' AS INT\n        )\n    ) = tm.[ID_FECHA]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] em ON fp.[ID_EMPRESA] = em.[ID_EMPRESA]\nWHERE fp.ID_EMPRESA != -1\nUNION ALL\n-- No aportante\nSELECT fp.[ID_PQR],\n    fp.[ID_UNIDAD],\n(\n        CAST(\n            SUBSTRING(CAST(fp.[ID_FECHA] AS VARCHAR), 1, 6) + '01' AS INT\n        )\n    ) AS ID_FECHA,\n    fp.[ESTADO] AS ESTADO_PQR,\n    fp.[ID_EMPRESA],\n    fp.[ID_AFILIADO],\n    fp.[ID_BENEFICIARIO],\n    'PQR' AS ACTIVIDAD,\n    fp.[CAUSA] AS CAUSA_PQR,\n    fp.[TIPO_PQRS],\n    '0000000000' AS PARTNER,\n    NULL AS ID_TIPO_AFILIADO,\n    NULL AS TIPO_AFILIADO,\n    4 AS ID_CATEGORIA,\n    NULL AS FECHA_AFILIACION,\n    NULL AS FECHA_RETIRO,\n    -1 AS ID_GENERO,\n    -1 AS ID_ESTADO_CIVIL,\n    -1 AS ID_PERTENENCIA_ETNICA,\n    -1 AS ID_FACTOR_VULNERABILIDAD,\n    -1 AS ESTRATO,\n    NULL AS ID_CIUDAD,\n    NULL AS SALARIO_BASICO,\n    NULL AS ESTADOREGISTRO,\n    NULL AS PARTNER_AFILIADO,\n    NULL AS APORTANTE,\n    NULL AS TIPO_APORTANTE,\n    NULL AS FECHA_INGRESO_EMPRESA,\n    NULL AS PARTNER_EMPRESA\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] fp\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON (\n        CAST(\n            SUBSTRING(CAST(fp.[ID_FECHA] AS VARCHAR), 1, 6) + '01' AS INT\n        )\n    ) = tm.[ID_FECHA]\nWHERE fp.ID_AFILIADO + fp.ID_EMPRESA + fp.ID_BENEFICIARIO = -3\n</code></pre>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_4","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET </p> <ul> <li>Descripci\u00f3n: Extrae los datos de la tabla <code>FACT_PQRS</code> del almac\u00e9n de datos utilizando la instrucci\u00f3n SQL mencionada.</li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.</li> <li>Columnas extra\u00eddas:<ul> <li><code>ID_PQR</code></li> <li><code>ID_UNIDAD</code></li> <li><code>ID_FECHA</code></li> <li><code>ESTADO_PQR</code></li> <li><code>CAUSA_PQR</code>, entre otras.</li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET </p> <ul> <li>Descripci\u00f3n: Carga los datos transformados en la tabla <code>Transversal.FACT_ACTIVIDADES</code>.</li> <li>Propiedades clave:<ul> <li>Nombre de tabla: <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code>.</li> <li>Tama\u00f1o de lote: <code>0</code> (uso predeterminado).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> </ul> </li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.</li> </ul> </li> <li> <p>Conexi\u00f3n entre componentes </p> <ul> <li>El flujo conecta el Origen ADO NET con el Destino ADO NET mediante la salida principal.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_5","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS-&gt;&gt;SQL: Ejecuta consulta para extraer datos de PQR\n    SQL-&gt;&gt;SSIS: Retorna datos transformados\n    SSIS-&gt;&gt;SQL: Inserta datos en la tabla destino `FACT_ACTIVIDADES`</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-fact_actividades_nps-paquete-fact_actividades","title":"Componente <code>FACT_ACTIVIDADES_NPS</code> (Paquete <code>FACT_ACTIVIDADES</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_6","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_ACTIVIDADES_NPS</code> es un flujo de datos en un paquete SSIS que realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con el c\u00e1lculo del NPS (Net Promoter Score). Este proceso combina y transforma datos de diversas fuentes para insertarlos en la tabla de destino <code>Transversal.FACT_ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_5","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: FACT_ENCUESTAS</p> <ul> <li>Descripci\u00f3n: Este componente extrae datos desde la tabla <code>Transversal.FACT_ENCUESTAS</code> y otras tablas relacionadas mediante una consulta SQL optimizada. Incluye uniones y filtros para obtener \u00fanicamente registros relacionados con el NPS.</li> <li>Propiedades clave:<ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.</li> <li>Consulta SQL:   <pre><code>  SELECT NULL as CURSO,\n      NULL as ID_GRADO,\n      NULL as ANIO_ACADEMICO,\n      [PARTNER],\n      NULL as ESTADO,\n      NULL as ESTADO_PAGO,\n      ID_FECHA,\n      NULL as ID_ESTADO_GESTION,\n      NULL as ID_CURSO,\n      NULL as FECHA_ADMISION,\n      NULL as SERVICIO_TRANSPORTE,\n      [ID_EMPRESA],\n      [ID_AFILIADO],\n      [ID_TIPO_AFILIADO],\n      [TIPO_AFILIADO],\n      [ID_CATEGORIA],\n      [FECHA_AFILIACION],\n      [FECHA_RETIRO],\n      [ID_GENERO],\n      [ID_ESTADO_CIVIL],\n      [ID_PERTENENCIA_ETNICA],\n      [ID_FACTOR_VULNERABILIDAD],\n      [ESTRATO],\n      [ID_CIUDAD],\n      [SALARIO_BASICO],\n      [FECHA_MENSUAL],\n      NULL as ID_CONCEPTO,\n      NULL as VALOR_FACTURADO,\n      NULL as VALOR_PAGADO,\n      NULL as ADEUDA,\n      NULL as NO_PRESTAMOS,\n      NULL as DESCRIPCION,\n      [ACTIVIDAD],\n      [ESTADOREGISTRO],\n      [TIPO_POBLACION],\n      [TOTAL_APORTES],\n      [NUMERO_APORTES],\n      [CALIFICACION],\n      [ID_UNIDAD]\n  from (\n          SELECT CASE\n                  WHEN de.PARTNER &amp; lt;\n  &amp; gt;\n  '0000000000' THEN de.PARTNER\n  ELSE CASE\n      WHEN da.PARTNER &amp; lt;\n  &amp; gt;\n  '0000000000' THEN da.PARTNER\n  ELSE CASE\n      WHEN db.PARTNER &amp; lt;\n  &amp; gt;\n  '0000000000' THEN db.PARTNER\n  ELSE daa.PARTNER\n  END\n  END\n  END as [PARTNER],\n  fe.[ID_EMPRESA],\n  fe.[ID_AFILIADO],\n  NULL AS [ID_TIPO_AFILIADO],\n  NULL AS [TIPO_AFILIADO],\n  NULL AS [ID_CATEGORIA],\n  NULL AS [FECHA_AFILIACION],\n  NULL AS [FECHA_RETIRO],\n  NULL AS [ID_GENERO],\n  NULL AS [ID_ESTADO_CIVIL],\n  NULL AS [ID_PERTENENCIA_ETNICA],\n  NULL AS [ID_FACTOR_VULNERABILIDAD],\n  NULL AS [ESTRATO],\n  NULL AS [ID_CIUDAD],\n  NULL AS [SALARIO_BASICO],\n  NULL AS [FECHA_MENSUAL],\n  LEFT(fe.[ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n  fe.[ID_UNIDAD],\n  NULL AS [ESTADOREGISTRO],\n  NULL AS [PARTNER_AFILIADO],\n  NULL AS [PARTNER_EMPRESA],\n  NULL AS [TIPO_POBLACION],\n  'NSU' AS [ACTIVIDAD],\n  NULL AS [TOTAL_APORTES],\n  NULL AS [NUMERO_APORTES],\n  fe.[CALIFICACION]\n  FROM [DWH_COMFENALCO].[Transversal].[FACT_ENCUESTAS] fe\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] da ON fe.ID_AFILIADO = da.ID_AFILIADO\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] db ON fe.ID_BENEFICIARIO = db.ID_BENEFICIARIO\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] de ON fe.ID_EMPRESA = de.ID_EMPRESA\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] daa ON fe.ID_APORTANTE = daa.ID_APORTANTE\n  WHERE NPS = 'SI'\n  ) as uni --   WHERE [ID_FECHA] IS NOT NULL\n  INNER JOIN (\n      select ID_FECHA as ID_FECHA2\n      from [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n  ) dimM ON uni.ID_FECHA = dimM.ID_FECHA2\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET</p> <ul> <li>Descripci\u00f3n: Este componente carga los datos transformados en la tabla <code>Transversal.FACT_ACTIVIDADES</code>.</li> <li>Propiedades clave:<ul> <li>Tabla de destino: <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code>.</li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o del b\u00fafer interno de SSIS).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Uso de inserci\u00f3n masiva (Bulk Insert): Activado.</li> </ul> </li> </ul> </li> <li> <p>Conexi\u00f3n entre componentes</p> <ul> <li>Descripci\u00f3n: Los datos extra\u00eddos y transformados por el componente Origen ADO NET son enviados directamente al componente Destino ADO NET para su carga en la base de datos.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_6","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS-&gt;&gt;SQL: Ejecuta consulta SQL para extraer datos de FACT_ENCUESTAS\n    SQL-&gt;&gt;SSIS: Devuelve datos transformados\n    SSIS-&gt;&gt;SQL: Inserta datos en FACT_ACTIVIDADES</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-fact_actividades_proteccion-paquete-fact_actividades","title":"Componente <code>FACT_ACTIVIDADES_PROTECCION</code> (Paquete <code>FACT_ACTIVIDADES</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_7","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_ACTIVIDADES_PROTECCION</code> implementa un flujo de datos en un paquete SSIS para integrar informaci\u00f3n de diversas fuentes relacionadas con actividades de protecci\u00f3n. Este flujo procesa datos mediante conversiones, transformaciones y los carga en la tabla de destino <code>Transversal.FACT_ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_6","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: Proteccion</p> <ul> <li>Descripci\u00f3n: Extrae datos desde m\u00faltiples tablas de la base de datos Proteccion usando una instrucci\u00f3n SQL. Los datos son transformados y consolidados en un conjunto de resultados \u00fanico que incluye informaci\u00f3n sobre ventas, caracterizaci\u00f3n, deserci\u00f3n y entrega de materiales.</li> <li>Propiedades clave:<ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.</li> <li>Consulta SQL:   <pre><code>      SELECT CASE\n              WHEN de.PARTNER &amp; lt;\n      &amp; gt;\n      '0000000000' THEN de.PARTNER\n      ELSE CASE\n          WHEN da.PARTNER &amp; lt;\n      &amp; gt;\n      '0000000000' THEN da.PARTNER\n      ELSE CASE\n          WHEN db.PARTNER &amp; lt;\n      &amp; gt;\n      '0000000000' THEN db.PARTNER\n      ELSE daa.PARTNER\n      END\n      END\n      END as [PARTNER],\n      dp.[ID_EMPRESA],\n      dp.[ID_AFILIADO],\n      ID_FECHA,\n      [CATEGORIA_VENTA],\n      DESCRIPCION,\n      [COSTO],\n      [SUBSIDIO],\n      [VALOR_PAGADO_SIN_IMP],\n      ID_PREGUNTA,\n      RESPUESTA,\n      ANIO_ACADEMICO,\n      CAUSA,\n      ID_PROGRAMA,\n      ID_MATERIAL,\n      CANTIDAD_MATERIAL,\n      VALOR_MATERIAL,\n      ACTIVIDAD,\n      4 AS ID_UNIDAD\n      from(\n              --FACT_VENTA\n              SELECT LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                  [ID_POBLACION],\n                  [CATEGORIA_VENTA],\n                  [SERVICIO] as DESCRIPCION,\n                  [COSTO],\n                  [SUBSIDIO],\n                  [VALOR_PAGADO_SIN_IMP],\n                  NULL as ID_PREGUNTA,\n                  NULL as RESPUESTA,\n                  NULL as ANIO_ACADEMICO,\n                  NULL as CAUSA,\n                  NULL as ID_PROGRAMA,\n                  NULL as ID_MATERIAL,\n                  NULL as CANTIDAD_MATERIAL,\n                  NULL as VALOR_MATERIAL,\n                  'VENTA' as ACTIVIDAD\n              FROM [DWH_COMFENALCO].[Proteccion].[FACT_VENTA]\n              UNION ALL\n              --FACT_CARACTERIZACION\n              SELECT LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                  [ID_POBLACION],\n                  NULL as CATEGORIA_VENTA,\n                  NULL as DESCRIPCION,\n                  NULL as COSTO,\n                  NULL as SUBSIDIO,\n                  NULL as VALOR_PAGADO_SIN_IMP,\n                  [ID_PREGUNTA],\n                  [RESPUESTA],\n                  NULL as ANIO_ACADEMICO,\n                  NULL as CAUSA,\n                  NULL as ID_PROGRAMA,\n                  NULL as ID_MATERIAL,\n                  NULL as CANTIDAD_MATERIAL,\n                  NULL as VALOR_MATERIAL,\n                  'CARACTERIZACION' as ACTIVIDAD\n              FROM [DWH_COMFENALCO].[Proteccion].[FACT_CARACTERIZACION]\n              UNION ALL\n              --DESERCION\n              SELECT LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                  [ID_POBLACION],\n                  NULL as CATEGORIA_VENTA,\n                  NULL as DESCRIPCION,\n                  NULL as COSTO,\n                  NULL as SUBSIDIO,\n                  NULL as VALOR_PAGADO_SIN_IMP,\n                  NULL as ID_PREGUNTA,\n                  NULL as RESPUESTA,\n                  [ANIO_ACADEMICO] * 10000 + 101 as ANIO_ACADEMICO,\n                  [CAUSA],\n                  NULL as ID_PROGRAMA,\n                  NULL as ID_MATERIAL,\n                  NULL as CANTIDAD_MATERIAL,\n                  NULL as VALOR_MATERIAL,\n                  'DESERCION' as ACTIVIDAD\n              FROM [DWH_COMFENALCO].[Proteccion].[FACT_DESERCION]\n              UNION ALL\n              --ENTREGA_MATERIAL\n              SELECT LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                  [ID_POBLACION],\n                  NULL as CATEGORIA_VENTA,\n                  NULL as DESCRIPCION,\n                  NULL as COSTO,\n                  NULL as SUBSIDIO,\n                  NULL as VALOR_PAGADO_SIN_IMP,\n                  NULL as ID_PREGUNTA,\n                  NULL as RESPUESTA,\n                  NULL as ANIO_ACADEMICO,\n                  NULL as CAUSA,\n                  [ID_PROGRAMA],\n                  [ID_MATERIAL],\n                  [CANTIDAD_MATERIAL],\n                  [VALOR_MATERIAL],\n                  'ENTREGA_MATERIAL' as ACTIVIDAD\n              FROM [DWH_COMFENALCO].[Proteccion].[FACT_ENTREGA_MATERIAL]\n          ) un\n          JOIN [DWH_COMFENALCO].[Proteccion].[DIM_POBLACION] dp ON un.[ID_POBLACION] = dp.[ID_POBLACION]\n          LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] da ON dp.ID_AFILIADO = da.ID_AFILIADO\n          LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] db ON dp.ID_BENEFICIARIO = db.ID_BENEFICIARIO\n          LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] de ON dp.ID_EMPRESA = de.ID_EMPRESA\n          LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] daa ON dp.ID_APORTANTE = daa.ID_APORTANTE\n          INNER JOIN (\n              select ID_FECHA as ID_FECHA2\n              from [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n          ) dimM ON un.ID_FECHA = dimM.ID_FECHA2\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos</p> <ul> <li>Descripci\u00f3n: Este componente convierte los tipos de datos de columnas espec\u00edficas a formatos compatibles con la tabla de destino. Ejemplo:<ul> <li><code>VALOR_MATERIAL</code>: De numeric a decimal.</li> <li><code>SUBSIDIO</code>: De numeric a string.</li> </ul> </li> <li>Propiedades clave:<ul> <li>Columnas de entrada:<ul> <li>VALOR_MATERIAL (numeric).</li> <li>SUBSIDIO (numeric).</li> <li>VALOR_PAGADO_SIN_IMP (numeric).</li> </ul> </li> <li>Columnas de salida:<ul> <li>Copy of VALOR_MATERIAL (decimal, escala: 2).</li> <li>Copy of SUBSIDIO (wstr, longitud: 50).</li> <li>Copy of VALOR_PAGADO_SIN_IMP (decimal, escala: 2).</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>Transversal.FACT_ACTIVIDADES</code>.</li> <li>Propiedades clave:<ul> <li>Tabla de destino: <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code>.</li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Tama\u00f1o de lote: <code>0</code> (uso del tama\u00f1o del b\u00fafer interno).</li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_7","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS-&gt;&gt;SQL: Ejecuta consulta SQL para extraer datos desde Proteccion\n    SQL-&gt;&gt;SSIS: Devuelve datos transformados\n    SSIS-&gt;&gt;SSIS: Realiza conversi\u00f3n de datos\n    SSIS-&gt;&gt;SQL: Inserta datos en FACT_ACTIVIDADES</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-fact_actividades_cedesarrollo-paquete-fact_actividades","title":"Componente <code>FACT_ACTIVIDADES_CEDESARROLLO</code> (Paquete <code>FACT_ACTIVIDADES</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_8","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_ACTIVIDADES_CEDESARROLLO</code> gestiona la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos relacionados con actividades acad\u00e9micas y administrativas en Cedesarrollo. Las actividades incluyen graduados, inasistencias, inscripci\u00f3n de matr\u00edculas, asistencia a actividades de bienestar y cotizaciones. La informaci\u00f3n transformada se carga en la tabla <code>Transversal.FACT_ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_7","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: Cedesarrollo</p> <ul> <li>Descripci\u00f3n: Recupera datos de m\u00faltiples tablas en la base de datos Cedesarrollo. La consulta SQL unifica las actividades en un \u00fanico conjunto de datos.</li> <li>Propiedades clave:<ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.</li> <li>Consulta SQL:   <pre><code>  SELECT   \n      ID_PROGRAMA,\n      ID_FECHA,\n      TOTAL_INASISTENCIA,\n      uni.ESTADO,\n      DESCRIPCION,\n      ASISTIO,\n      ACTIVIDAD,\n      ISNULL(\n  CASE WHEN de.PARTNER &amp;lt;&amp;gt; '0000000000' THEN  de.PARTNER ELSE\n      CASE WHEN da.PARTNER &amp;lt;&amp;gt; '0000000000' THEN  da.PARTNER ELSE\n          CASE WHEN db.PARTNER &amp;lt;&amp;gt; '0000000000' THEN db.PARTNER ELSE\n          daa.PARTNER\n          END\n          END\n          END,'0000000000') as [PARTNER],\n      ID_UNIDAD\n  from (\n  --GRADUADOS\n  SELECT \n          [ID_ESTUDIANTE],\n          ISNULL(ID_PROGRAMA,-1) AS ID_PROGRAMA,\n          NULL as ID_PERIODO,\n          [GRUPO],\n          LEFT(FORMAT([FECHA_GRADUADO], 'yyyyMMdd'),6) * 100 + 1 as ID_FECHA,\n          NULL as TOTAL_INASISTENCIA,\n          NULL as ESTADO,\n          NULL as DESCRIPCION,\n          NULL as ASISTIO,\n          'GRADUADOS' as ACTIVIDAD,\n      j.[ID_UNIDAD]\n      FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_GRADUADOS] fg\n      INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on fg.[ID_JORNADA] = j.[ID_JORNADA]\n\n  UNION ALL\n\n  --INASISTENCIAS\n  SELECT \n          [ID_ESTUDIANTE],\n          -1 as ID_PROGRAMA,\n          NULL as ID_PERIODO,\n          NULL as GRUPO,\n          LEFT([ID_FECHA],6) * 100 + 1 as ID_FECHA,\n          [TOTAL_INASISTENCIA],\n          NULL as ESTADO,\n          NULL as DESCRIPCION,\n          NULL as ASISTIO,\n          'INASISTENCIAS' as ACTIVIDAD,\n      j.[ID_UNIDAD]\n      FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INASISTENCIAS] fi\n      INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on fi.[ID_JORNADA] = j.[ID_JORNADA]\n  UNION ALL\n\n  --INSCRIPCION_MATRICULAS\n  SELECT \n          [ID_ESTUDIANTE],\n          ISNULL(ID_PROGRAMA,-1) AS ID_PROGRAMA,\n          [ID_PERIODO],\n          NULL as GRUPO,\n          LEFT([ID_FECHA],6) * 100 + 1 as ID_FECHA,\n          NULL as TOTAL_INASISTENCIA,\n          [ESTADO],\n          NULL as DESCRIPCION,\n          NULL as ASISTIO,\n          'INSCRIPCION_MATRICULAS' as ACTIVIDAD,\n      j.[ID_UNIDAD]\n      FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] fm\n      INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on fm.[ID_JORNADA] = j.[ID_JORNADA]\n\n  UNION ALL\n\n  --ASISTENCIA_ACT_BIENESTAR\n  SELECT \n          ID_ESTUDIANTE,\n          -1 as ID_PROGRAMA,\n          [ID_PERIODO],\n          NULL as GRUPO,\n          LEFT(FORMAT([FECHA], 'yyyyMMdd'),6) * 100 + 1 as ID_FECHA,\n          NULL as TOTAL_INASISTENCIA,\n          NULL as ESTADO,\n          [ACTIVIDAD] as DESCRIPCION,\n          [ASISTIO],\n          'ASISTENCIA_ACT_BIENESTAR' as ACTIVIDAD,\n      2 AS ID_UNIDAD\n      FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_ASISTENCIA_ACT_BIENESTAR]\n\n  UNION ALL\n\n  --COTIZACIONES\n      SELECT [ID_ESTUDIANTE],\n      -1 as ID_PROGRAMA,\n      NULL as ID_PERIODO,\n      NULL as GRUPO,\n      LEFT(FORMAT([FECHA_REGISTRO], 'yyyyMMdd'),6) * 100 + 1 as ID_FECHA,\n      NULL as GRUPO,\n      NULL as TOTAL_INASISTENCIA,\n      [ESTADO_COTIZACION] as ESTADO, \n  NULL as DESCRIPCION,\n  'COTIZACIONES' as ACTIVIDAD,\n  3 AS ID_UNIDAD\n      FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_COTIZACIONES]\n\n\n      ) uni\n\n      LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] die\n      ON uni.[ID_ESTUDIANTE] = die.[ID_ESTUDIANTE]\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] da\n      ON die.ID_AFILIADO = da.ID_AFILIADO\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] db\n      ON die.ID_BENEFICIARIO = db.ID_BENEFICIARIO\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] de\n      ON die.ID_EMPRESA = de.ID_EMPRESA\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] daa\n      ON die.ID_APORTANTE = daa.ID_APORTANTE\n      INNER JOIN (select ID_FECHA as ID_FECHA2  from  [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] ) dimM\n  ON uni.ID_FECHA = dimM.ID_FECHA2 \n  UNION\n      --FACTURACION\n  SELECT \n      -1 as ID_PROGRAMA,\n      LEFT([ID_FECHA],6) * 100 + 1 as ID_FECHA,\n      NULL as TOTAL_INASISTENCIA,\n      [ESTADO_PAGO] as ESTADO,\n      [TIPO_DOCUMENTO_PAGO] as DESCRIPCION,\n      NULL as ASISTIO,\n      'FACTURACION' as ACTIVIDAD,\n      ISNULL(\n      CASE \n          WHEN de.PARTNER &amp;lt;&amp;gt; '0000000000' THEN de.PARTNER \n          ELSE CASE \n              WHEN da.PARTNER &amp;lt;&amp;gt; '0000000000' THEN da.PARTNER \n              ELSE CASE \n                  WHEN db.PARTNER &amp;lt;&amp;gt; '0000000000' THEN db.PARTNER \n                  ELSE daa.PARTNER \n                  END \n              END \n          END,'0000000000') as [PARTNER],\n      CASE\n              WHEN LEN(NO_RECIBO) &amp;lt; 6 THEN 2\n              ELSE 3\n          END AS ID_UNIDAD\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] da\n      ON ff.[TIPO_DOCUMENTO_PAGO] = da.[COD_TIPO_DOCUMENTO]\n      AND ff.[DOCUMENTO_PAGO] = da.[NUMERO_DOCUMENTO]\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] db\n      ON ff.[TIPO_DOCUMENTO_PAGO] = db.[COD_TIPO_DOCUMENTO]\n      AND ff.[DOCUMENTO_PAGO] = db.[NUMERO_DOCUMENTO]\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] de\n      ON ff.[TIPO_DOCUMENTO_PAGO] = de.[COD_TIPO_DOCUMENTO]\n      AND ff.[DOCUMENTO_PAGO] = de.[DOCUMENTO]\n      LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] daa\n      ON ff.[TIPO_DOCUMENTO_PAGO] = daa.[COD_TIPO_DOCUMENTO]\n      AND ff.[DOCUMENTO_PAGO] = daa.[DOCUMENTO]\n      INNER JOIN (select ID_FECHA as ID_FECHA2  from  [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] ) dimM\n  ON ff.ID_FECHA = dimM.ID_FECHA2\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET</p> <ul> <li>Descripci\u00f3n: Inserta los datos procesados en la tabla de destino <code>Transversal.FACT_ACTIVIDADES</code>.</li> <li>Propiedades clave:<ul> <li>Tabla de destino: <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code>.</li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Tama\u00f1o de lote: <code>0</code> (uso del tama\u00f1o del b\u00fafer interno).</li> <li>Columnas de entrada:<ul> <li>ID_PROGRAMA</li> <li>ID_FECHA</li> <li>ESTADO</li> <li>DESCRIPCION</li> <li>ACTIVIDAD</li> <li>PARTNER</li> <li>ID_UNIDAD</li> </ul> </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_8","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS-&gt;&gt;SQL: Ejecuta consulta SQL para extraer datos desde Cedesarrollo\n    SQL-&gt;&gt;SSIS: Devuelve datos transformados\n    SSIS-&gt;&gt;SQL: Inserta datos en FACT_ACTIVIDADES</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-fact_actividades_colegio-paquete-fact_actividades","title":"Componente <code>FACT_ACTIVIDADES_COLEGIO</code> (Paquete <code>FACT_ACTIVIDADES</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_9","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_ACTIVIDADES_COLEGIO</code> realiza la extracci\u00f3n, transformaci\u00f3n y carga (ETL) de datos acad\u00e9micos y administrativos relacionados con las actividades de colegios. Integra informaci\u00f3n de varias tablas para registrar actividades como matr\u00edculas, transporte, facturaci\u00f3n, biblioteca, entre otras, consolidando estos datos en la tabla destino <code>Transversal.FACT_ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_8","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: Colegio</p> <ul> <li>Descripci\u00f3n: Extrae datos consolidados desde m\u00faltiples tablas en la base de datos del colegio. La consulta SQL incluye uniones y transformaciones para unificar los registros de las actividades.</li> <li>Propiedades clave:<ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.</li> <li>Consulta SQL:      <pre><code>    SELECT CURSO,\n        ID_GRADO,\n        ANIO_ACADEMICO,\n        [PARTNER],\n        ESTADO,\n        ESTADO_PAGO,\n        ID_FECHA,\n        [ID_ESTADO_GESTION],\n        [ID_CURSO],\n        [FECHA_ADMISION],\n        SERVICIO_TRANSPORTE,\n        NULL as ID_EMPRESA,\n        NULL as ID_AFILIADO,\n        NULL as ID_TIPO_AFILIADO,\n        NULL as TIPO_AFILIADO,\n        NULL as ID_CATEGORIA,\n        NULL as FECHA_AFILIACION,\n        NULL as FECHA_RETIRO,\n        NULL as ID_GENERO,\n        NULL as ID_ESTADO_CIVIL,\n        NULL as ID_PERTENENCIA_ETNICA,\n        NULL as ID_FACTOR_VULNERABILIDAD,\n        NULL as ESTRATO,\n        NULL as ID_CIUDAD,\n        NULL as SALARIO_BASICO,\n        NULL as FECHA_MENSUAL,\n        ID_CONCEPTO,\n        VALOR_FACTURADO,\n        VALOR_PAGADO,\n        ADEUDA,\n        NO_PRESTAMOS,\n        DESCRIPCION,\n        ACTIVIDAD,\n        NULL as ESTADOREGISTRO,\n        NULL as PARTNER_AFILIADO,\n        NULL as PARTNER_EMPRESA,\n        NULL as TIPO_POBLACION,\n        NULL as TOTAL_APORTES,\n        NULL as NUMERO_APORTES,\n        NULL as CALIFICACION,\n        1 AS ID_UNIDAD\n    from (\n            --ESTADO_MATRICULAS\n            SELECT [CA20_CURSO] as CURSO,\n                [ID_GRADO],\n                [CA20_ANO_ACADEMICO] * 10000 + 101 as ANIO_ACADEMICO,\n                [CA20_BP_ESTUDIANTE] as [PARTNER],\n                [CA20_ESTADO_MATRICULA] as ESTADO,\n                [CA20_ESTADO_PAGO] as ESTADO_PAGO,\n                CASE\n                    WHEN [CA20_FECHA_PAGO] = 00000000 THEN [CA20_FECHA_PAGO]\n                    ELSE LEFT([CA20_FECHA_PAGO], 6) * 100 + 1\n                END AS ID_FECHA,\n                NULL as ID_ESTADO_GESTION,\n                NULL as ID_CURSO,\n                NULL as FECHA_ADMISION,\n                NULL as SERVICIO_TRANSPORTE,\n                NULL as VAL_TARIFA,\n                NULL as ID_CONCEPTO,\n                NULL as VALOR_FACTURADO,\n                NULL as VALOR_PAGADO,\n                NULL as ADEUDA,\n                NULL as NO_PRESTAMOS,\n                NULL as DESCRIPCION,\n                'ESTADO_MATRICULAS' as ACTIVIDAD\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_ESTADO_MATRICULAS]\n            UNION\n            --INSCRIPCION_MATRICULAS\n            SELECT NULL as CURSO,\n                NULL as ID_GRADO,\n                [ANIO_ACADEMICO] * 10000 + 101 as ANIO_ACADEMICO,\n                [BP] as [PARTNER],\n                CAST([ID_ESTADO_PROCESO] AS NVARCHAR) as ESTADO,\n                NULL as ESTADO_PAGO,\n                LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                [ID_ESTADO_GESTION],\n                [ID_CURSO],\n                [FECHA_ADMISION],\n                NULL as SERVICIO_TRANSPORTE,\n                NULL as VAL_TARIFA,\n                NULL as ID_CONCEPTO,\n                NULL as VALOR_FACTURADO,\n                NULL as VALOR_PAGADO,\n                NULL as ADEUDA,\n                NULL as NO_PRESTAMOS,\n                NULL as DESCRIPCION,\n                'INSCRIPCION_MATRICULAS' as ACTIVIDAD\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS]\n            UNION\n            --TRANSPORTE\n            SELECT NULL as CURSO,\n                NULL as ID_GRADO,\n                [ANIO_ACADEMICO] * 10000 + 101 as ANIO_ACADEMICO,\n                [BP_ESTUDIANTE] as [PARTNER],\n                NULL as ESTADO,\n                NULL as ESTADO_PAGO,\n                LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                NULL as ID_ESTADO_GESTION,\n                NULL as ID_CURSO,\n                NULL as FECHA_ADMISION,\n                [SERVICIO_TRANSPORTE],\n                [VAL_TARIFA],\n                NULL as ID_CONCEPTO,\n                NULL as VALOR_FACTURADO,\n                NULL as VALOR_PAGADO,\n                NULL as ADEUDA,\n                NULL as NO_PRESTAMOS,\n                NULL as DESCRIPCION,\n                'TRANSPORTE' as ACTIVIDAD\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_TRANSPORTE] ft\n                LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_TARIFAS_SERVICIOS] ts ON ft.[ID_TARIFA] = ts.[ID_TARIFA]\n            UNION\n            --FACTURACION_MATRICULAS\n            SELECT NULL as CURSO,\n                NULL as ID_GRADO,\n                NULL as ANIO_ACADEMICO,\n                [BP] as [PARTNER],\n                [ESTADO_PAGO] as ESTADO,\n                [ESTADO_PAGO],\n                LEFT([FECHA_CONTABLE], 6) * 100 + 1 as ID_FECHA,\n                NULL as ID_ESTADO_GESTION,\n                NULL as ID_CURSO,\n                NULL as FECHA_ADMISION,\n                NULL as SERVICIO_TRANSPORTE,\n                NULL as VAL_TARIFA,\n                [ID_CONCEPTO],\n                [VALOR_FACTURADO],\n                [VALOR_PAGADO],\n                [ADEUDA],\n                NULL as NO_PRESTAMOS,\n                NULL as DESCRIPCION,\n                'FACTURACION_MATRICULAS' as ACTIVIDAD\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_FACTURACION_MATRICULAS]\n            UNION\n            --BIBLIOTECA\n            SELECT NULL as CURSO,\n                NULL as ID_GRADO,\n                [ANIO_ACADEMICO] * 10000 + 101 as ANIO_ACADEMICO,\n                [PARTNER],\n                NULL as ESTADO,\n                NULL as ESTADO_PAGO,\n                LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                NULL as ID_ESTADO_GESTION,\n                NULL as ID_CURSO,\n                NULL as FECHA_ADMISION,\n                NULL as SERVICIO_TRANSPORTE,\n                NULL as VAL_TARIFA,\n                NULL as ID_CONCEPTO,\n                NULL as VALOR_FACTURADO,\n                NULL as VALOR_PAGADO,\n                NULL as ADEUDA,\n                [NO_PRESTAMOS],\n                NULL as DESCRIPCION,\n                'BIBLIOTECA' as ACTIVIDAD\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_BIBLIOTECA] fb\n                LEFT JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] dpm ON fb.[ID_POBLACION_MATRICULA] = dpm.[ID_POBLACION_MATRICULA]\n            UNION\n            --BIBLIOTECA_VIRTUAL\n            SELECT NULL as CURSO,\n                NULL as ID_GRADO,\n                [ANIO_ACADEMICO] * 10000 + 101 as ANIO_ACADEMICO,\n                [PARTNER],\n                NULL as ESTADO,\n                NULL as ESTADO_PAGO,\n                LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                NULL as ID_ESTADO_GESTION,\n                NULL as ID_CURSO,\n                NULL as FECHA_ADMISION,\n                NULL as SERVICIO_TRANSPORTE,\n                NULL as VAL_TARIFA,\n                NULL as ID_CONCEPTO,\n                NULL as VALOR_FACTURADO,\n                NULL as VALOR_PAGADO,\n                NULL as ADEUDA,\n                NULL as NO_PRESTAMOS,\n                [ACTIVIDAD] as DESCRIPCION,\n                'BIBLIOTECA_VIRTUAL' as ACTIVIDAD\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_BIBLIOTECA_VIRTUAL] fb\n                LEFT JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] dpm ON fb.[ID_POBLACION_MATRICULA] = dpm.[ID_POBLACION_MATRICULA]\n            UNION\n            --ENFERMERIA\n            SELECT NULL as CURSO,\n                NULL as ID_GRADO,\n                [ANIO_ACADEMICO] * 10000 + 101 as ANIO_ACADEMICO,\n                [PARTNER],\n                [ESTADO],\n                NULL as ESTADO_PAGO,\n                LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                NULL as ID_ESTADO_GESTION,\n                NULL as ID_CURSO,\n                NULL as FECHA_ADMISION,\n                NULL as SERVICIO_TRANSPORTE,\n                NULL as VAL_TARIFA,\n                NULL as ID_CONCEPTO,\n                NULL as VALOR_FACTURADO,\n                NULL as VALOR_PAGADO,\n                NULL as ADEUDA,\n                NULL as NO_PRESTAMOS,\n                [MOTIVO_REMISION] as DESCRIPCION,\n                'ENFERMERIA' as ACTIVIDAD\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_ENFERMERIA] fe\n                LEFT JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] dpm ON fe.[ID_POBLACION_MATRICULA] = dpm.[ID_POBLACION_MATRICULA]\n            UNION\n            --RETIROS\n            SELECT NULL as CURSO,\n                NULL as ID_GRADO,\n                [ANIO_ACADEMICO] * 10000 + 101 as ANIO_ACADEMICO,\n                [BP_ESTUDIANTE] as [PARTNER],\n                NULL as ESTADO,\n                NULL as ESTADO_PAGO,\n                LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                NULL as ID_ESTADO_GESTION,\n                NULL as ID_CURSO,\n                NULL as FECHA_ADMISION,\n                NULL as SERVICIO_TRANSPORTE,\n                NULL as VAL_TARIFA,\n                NULL as ID_CONCEPTO,\n                NULL as VALOR_FACTURADO,\n                NULL as VALOR_PAGADO,\n                NULL as ADEUDA,\n                NULL as NO_PRESTAMOS,\n                NULL as DESCRIPCION,\n                'RETIROS' as ACTIVIDAD\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_RETIROS]\n            UNION\n            --PSICORIENTACION\n            SELECT NULL as CURSO,\n                NULL as ID_GRADO,\n                [ANIO_ACADEMICO] * 10000 + 101 as ANIO_ACADEMICO,\n                [PARTNER],\n                [ESTADO],\n                NULL as ESTADO_PAGO,\n                LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                NULL as ID_ESTADO_GESTION,\n                NULL as ID_CURSO,\n                NULL as FECHA_ADMISION,\n                NULL as SERVICIO_TRANSPORTE,\n                NULL as VAL_TARIFA,\n                NULL as ID_CONCEPTO,\n                NULL as VALOR_FACTURADO,\n                NULL as VALOR_PAGADO,\n                NULL as ADEUDA,\n                NULL as NO_PRESTAMOS,\n                NULL as DESCRIPCION,\n                'PSICORIENTACION' as ACTIVIDAD\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_PSICORIENTACION] fp\n                LEFT JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] dpm ON fp.[ID_POBLACION_MATRICULA] = dpm.[ID_POBLACION_MATRICULA]\n        ) as uni --   WHERE [ID_FECHA] IS NOT NULL\n        INNER JOIN (\n            select ID_FECHA as ID_FECHA2\n            from [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n        ) dimM ON uni.ID_FECHA = dimM.ID_FECHA2\n</code></pre></li> <li>Configuraci\u00f3n de salida:<ul> <li>Columnas principales:<ul> <li>CURSO</li> <li>ID_GRADO</li> <li>ANIO_ACADEMICO</li> <li>PARTNER</li> <li>ESTADO</li> <li>ESTADO_PAGO</li> <li>ID_FECHA</li> <li>ACTIVIDAD</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de destino <code>Transversal.FACT_ACTIVIDADES</code>.</li> <li>Propiedades clave:<ul> <li>Tabla de destino: <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code>.</li> <li>Tama\u00f1o de lote: <code>0</code> (uso del tama\u00f1o del b\u00fafer interno de SSIS).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Columnas de entrada:<ul> <li>CURSO, ID_GRADO, ANIO_ACADEMICO, PARTNER, ESTADO, ESTADO_PAGO, ID_FECHA, ACTIVIDAD y otros campos relevantes definidos en el esquema de entrada.</li> </ul> </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_9","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS-&gt;&gt;SQL: Ejecuta consulta SQL para extraer datos consolidados\n    SQL-&gt;&gt;SSIS: Retorna los datos transformados\n    SSIS-&gt;&gt;SQL: Inserta datos en FACT_ACTIVIDADES</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-aportes-totales-paquete-fact_actividades","title":"Componente <code>Aportes Totales</code> (Paquete <code>FACT_ACTIVIDADES</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_10","title":"Descripci\u00f3n General","text":"<p>El componente <code>Aportes Totales</code> est\u00e1 dise\u00f1ado para procesar datos relacionados con aportes mensuales de empresas y afiliados. Este componente extrae, agrupa y consolida informaci\u00f3n financiera y poblacional, incluyendo datos de aportes y su relaci\u00f3n con actividades educativas, para finalmente cargarlos en la tabla destino <code>Transversal.FACT_ACTIVIDADES</code>.</p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_9","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: Aportes</p> <ul> <li>Descripci\u00f3n: Extrae datos desde la tabla de aportes utilizando una consulta SQL con m\u00faltiples CTEs (Common Table Expressions) para calcular aportes totales, n\u00famero de aportes, y la poblaci\u00f3n educativa asociada.</li> <li>Propiedades clave:<ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.</li> <li>Consulta SQL:     <pre><code>    WITH Aportes_Total AS (\n        SELECT ISNULL(a.[BP_EMPRESA], '0000000000') as 'PARTNER',\n            a.[ID_EMPRESA],\n            a.[ID_AFILIADO],\n            CONVERT(\n                DATE,\n                LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01'\n            ) AS FECHA_MENSUAL,\n            LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' AS ID_FECHA,\n            SUM(CONVERT(DECIMAL(18, 2), a.[APORTE])) AS TOTAL_APORTES,\n            COUNT(a.[APORTE]) AS NUMERO_APORTES,\n            ISNULL(a.[BP_EMPRESA], '0000000000') AS BP_EMPRESA,\n            a.[BP_AFILIADO],\n            'APORTES' AS ACTIVIDAD\n        FROM [DWH_COMFENALCO].[Aportes].[FACT_APORTES_SHR_DET] a\n            INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] t ON LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01' = CONVERT(VARCHAR(8), t.[ID_FECHA], 112)\n        GROUP BY a.[ID_EMPRESA],\n            a.[ID_AFILIADO],\n            LEFT(CONVERT(VARCHAR(8), a.[FECHA_CONTABLE], 112), 6) + '01',\n            a.[BP_EMPRESA],\n            a.[BP_AFILIADO]\n    ),\n    Poblacion_Educacion_Mes AS (\n        SELECT DISTINCT [ID_FECHA],\n            [PARTNER]\n        FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n        WHERE ACTIVIDAD != 'AFILIACION'\n    ),\n    AfiliadosMes AS (\n        SELECT DISTINCT [ID_FECHA],\n            [PARTNER],\n            [PARTNER_AFILIADO]\n        FROM [DWH_COMFENALCO].[Transversal].[FACT_ACTIVIDADES]\n        WHERE ACTIVIDAD = 'AFILIACION'\n            AND PARTNER_AFILIADO IS NOT NULL\n    ),\n    AfiliadosEducacionMes AS (\n        SELECT am.[ID_FECHA],\n            am.[PARTNER_AFILIADO]\n        FROM AfiliadosMes am\n            INNER JOIN Poblacion_Educacion_Mes pem ON am.[ID_FECHA] = pem.[ID_FECHA]\n            and am.PARTNER = pem.PARTNER\n    )\n    SELECT ap.* --,am.PARTNER_AFILIADO\n    ,\n    CASE\n            WHEN aem.PARTNER_AFILIADO IS NULL THEN 'NO'\n            ELSE 'SI'\n        END AS POBLACION_EDUCACION\n    FROM Aportes_Total ap\n        LEFT JOIN AfiliadosEducacionMes aem ON ap.ID_FECHA = aem.ID_FECHA\n        AND ap.BP_AFILIADO = aem.PARTNER_AFILIADO\n</code></pre><ul> <li><code>Aportes_Total</code>: Agrupa y calcula los aportes totales y el n\u00famero de aportes por empresa, afiliado y mes.</li> <li><code>Poblacion_Educacion_Mes</code>: Identifica registros relacionados con actividades educativas en el mes.</li> <li><code>AfiliadosMes</code>: Extrae afiliados registrados en el mes correspondiente.</li> <li><code>AfiliadosEducacionMes</code>: Combina afiliados y poblaci\u00f3n educativa para identificar asociaciones.</li> </ul> </li> <li>Tiempo de espera: <code>600</code> segundos.</li> <li>Columnas principales:<ul> <li>PARTNER</li> <li>ID_EMPRESA</li> <li>ID_AFILIADO</li> <li>FECHA_MENSUAL</li> <li>ID_FECHA</li> <li>TOTAL_APORTES</li> <li>NUMERO_APORTES</li> <li>ACTIVIDAD (valor constante: <code>'APORTES'</code>)</li> <li>POBLACION_EDUCACION (indica <code>'SI'</code> o <code>'NO'</code> seg\u00fan la asociaci\u00f3n con educaci\u00f3n).</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla destino <code>Transversal.FACT_ACTIVIDADES</code>.</li> <li>Propiedades clave:<ul> <li>Tabla de destino: <code>\"Transversal\".\"FACT_ACTIVIDADES\"</code>.</li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o del b\u00fafer interno de SSIS).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Columnas de entrada:<ul> <li>PARTNER, ID_EMPRESA, ID_AFILIADO, FECHA_MENSUAL, ID_FECHA, TOTAL_APORTES, NUMERO_APORTES, ACTIVIDAD, POBLACION_EDUCACION.</li> </ul> </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_10","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS-&gt;&gt;SQL: Ejecuta consulta SQL para calcular aportes totales\n    SQL-&gt;&gt;SSIS: Retorna los datos procesados\n    SSIS-&gt;&gt;SQL: Inserta datos en FACT_ACTIVIDADES</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-fact_personal_cubo","title":"Componente <code>FACT_PERSONAL_CUBO</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_11","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_PERSONAL_CUBO</code> tiene como objetivo consolidar datos relacionados con el personal docente, sus contrataciones, ausencias y reemplazos, para luego cargarlos en la tabla <code>Transversal.FACT_PERSONAL</code>. Este flujo combina datos de m\u00faltiples fuentes, proces\u00e1ndolos para crear un registro unificado con detalles espec\u00edficos sobre fechas, conceptos y horas asociadas.</p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_10","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: FACT_PERSONAL</p> <ul> <li>Descripci\u00f3n: Extrae datos desde m\u00faltiples tablas de origen relacionadas con el personal docente, sus contrataciones, ausencias y reemplazos.</li> <li>Propiedades clave:<ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.</li> <li>Consulta SQL:     <pre><code>    SELECT uni.ID_FECHA,\n        uni.ID_PERSONAL,\n        uni.NOMBRE,\n        uni.CONCEPTO,\n        uni.DESCRIPCION,\n        uni.FECHA_FIN,\n        uni.HORAS_CONTRATADAS_MENSUAL,\n        pers.ID_UNIDAD,\n        AUSENCIA_HORAS,\n        TIPO_AUSENCIA\n    FROM(\n            SELECT LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                [ID_PERSONAL],\n                [NOMBRE_DOCENTE] as NOMBRE,\n                'AUSENTISMO' as CONCEPTO,\n                [MOTIVO_AUSENCIA] as DESCRIPCION,\n                [FECHA_FIN],\n                NULL as HORAS_CONTRATADAS_MENSUAL,\n                AUSENCIA_HORAS,\n                TIPO_AUSENCIA\n            FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_AUSENTISMO_DOCENTE]\n            UNION\n            SELECT LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                [ID_PERSONAL_REEMPLAZA] as ID_PERSONAL,\n                [DOCENTE_REEMPLAZA] as NOMBRE,\n                'REEMPLAZO' as CONCEPTO,\n                NULL as DESCRIPCION,\n                NULL as FECHA_FIN,\n                NULL as HORAS_CONTRATADAS_MENSUAL,\n                NULL as AUSENCIA_HORAS,\n                NULL as TIPO_AUSENCIA\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_REEMPLAZO_DOCENTE]\n            UNION\n            SELECT LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA,\n                [ID_PERSONAL],\n                [NOMBRE_DOCENTE] as NOMBRE,\n                'AUSENTISMO' as CONCEPTO,\n                [MOTIVO_AUSENCIA] as DESCRIPCION,\n                [FECHA_FIN],\n                NULL as HORAS_CONTRATADAS_MENSUAL,\n                AUSENCIA_HORAS,\n                TIPO_AUSENCIA\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_AUSENTISMO_DOCENTE]\n            UNION\n            SELECT LEFT(\n                    CONVERT(\n                        INT,\n                        FORMAT([FECHA_INICIO_CONTRATACION], 'yyyyMMdd')\n                    ),\n                    6\n                ) * 100 + 1 AS ID_FECHA,\n                [ID_PERSONAL],\n                [NOMBRE],\n                'CONTRATACION' as CONCEPTO,\n                NULL as DESCRIPCION,\n                [FECHA_FIN_CONTRATACION] AS FECHA_FIN,\n                [HORAS_CONTRATADAS_MENSUAL],\n                NULL as AUSENCIA_HORAS,\n                NULL as TIPO_AUSENCIA\n            FROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\n            UNION\n            SELECT LEFT(\n                    CONVERT(\n                        INT,\n                        FORMAT([FECHA_FIN_CONTRATACION], 'yyyyMMdd')\n                    ),\n                    6\n                ) * 100 + 1 AS ID_FECHA,\n                [ID_PERSONAL],\n                [NOMBRE],\n                'FIN_CONTRATACION' as CONCEPTO,\n                [CAUSA_TERMINACION_CONTRATO] as DESCRIPCION,\n                NULL as FECHA_FIN,\n                NULL as HORAS_CONTRATADAS_MENSUAL,\n                NULL as AUSENCIA_HORAS,\n                NULL as TIPO_AUSENCIA\n            FROM [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL]\n        ) as uni --   WHERE [ID_FECHA] IS NOT NULL\n        INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] dimM ON uni.ID_FECHA = dimM.ID_FECHA\n        LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_PERSONAL] pers ON uni.ID_PERSONAL = pers.ID_PERSONAL            \n</code></pre><ul> <li><code>FACT_AUSENTISMO_DOCENTE</code> y <code>FACT_REEMPLAZO_DOCENTE</code>: Proveen informaci\u00f3n sobre ausencias y reemplazos.</li> <li><code>DIM_PERSONAL</code>: Agrega datos sobre contrataciones y terminaciones de contrato.</li> <li>Join con <code>DIM_TIEMPO_MENSUAL</code>: Relaciona las fechas con el tiempo mensual.</li> <li>Columnas seleccionadas:<ul> <li>ID_FECHA: Fecha procesada en formato mensual.</li> <li>ID_PERSONAL: Identificador \u00fanico del personal.</li> <li>NOMBRE: Nombre del personal.</li> <li>CONCEPTO: Identifica la categor\u00eda del registro (<code>AUSENTISMO</code>, <code>REEMPLAZO</code>, <code>CONTRATACION</code>, <code>FIN_CONTRATACION</code>).</li> <li>DESCRIPCION: Informaci\u00f3n adicional (motivo de ausencia, causa de terminaci\u00f3n, etc.).</li> <li>FECHA_FIN: Fecha de finalizaci\u00f3n de contrato o ausencia.</li> <li>HORAS_CONTRATADAS_MENSUAL: Horas mensuales contratadas.</li> <li>AUSENCIA_HORAS y TIPO_AUSENCIA: Informaci\u00f3n espec\u00edfica de ausencias.</li> </ul> </li> </ul> </li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Columnas de salida:<ul> <li>ID_FECHA, ID_PERSONAL, NOMBRE, CONCEPTO, DESCRIPCION, FECHA_FIN, HORAS_CONTRATADAS_MENSUAL, ID_UNIDAD, AUSENCIA_HORAS, TIPO_AUSENCIA.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET</p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla destino <code>Transversal.FACT_PERSONAL</code>.</li> <li>Propiedades clave:<ul> <li>Tabla de destino: <code>\"Transversal\".\"FACT_PERSONAL\"</code>.</li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o del b\u00fafer interno de SSIS).</li> <li>Tiempo de espera: <code>30</code> segundos.</li> <li>Columnas de entrada:<ul> <li>ID_FECHA, ID_PERSONAL, NOMBRE, CONCEPTO, DESCRIPCION, FECHA_FIN, HORAS_CONTRATADAS_MENSUAL, ID_UNIDAD.</li> </ul> </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_11","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as SSIS Package\n    participant SQL as SQL Server\n    SSIS-&gt;&gt;SQL: Ejecuta consulta SQL para extraer datos del personal\n    SQL-&gt;&gt;SSIS: Retorna los datos procesados\n    SSIS-&gt;&gt;SQL: Inserta datos en FACT_PERSONAL</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-fact_evaluacion_docente_cubo","title":"Componente <code>FACT_EVALUACION_DOCENTE_CUBO</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_12","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_EVALUACION_DOCENTE_CUBO</code> es una tarea de flujo de datos (Data Flow Task) dise\u00f1ada para consolidar y cargar datos de evaluaciones de desempe\u00f1o docente desde m\u00faltiples fuentes en el Data Warehouse. Combina informaci\u00f3n de tres tablas principales (<code>Colegio</code>, <code>Cedesarrollo</code>) y la integra en la tabla de hechos <code>Transversal.FACT_EVALUACION_DOCENTE</code>, asegurando una visi\u00f3n unificada para an\u00e1lisis acad\u00e9micos.</p>"},{"location":"03.Cubo/03.ETL/#proposito_2","title":"Prop\u00f3sito","text":"<ol> <li>Consolidar evaluaciones docentes:  <ul> <li>Unificar datos de desempe\u00f1o docente de diferentes sistemas (Colegio y Cedesarrollo).  </li> </ul> </li> <li>Facilitar an\u00e1lisis temporal:  <ul> <li>Vincular las evaluaciones con la dimensi\u00f3n temporal mensual (<code>DIM_TIEMPO_MENSUAL</code>) para an\u00e1lisis hist\u00f3ricos.  </li> </ul> </li> <li>Optimizar consultas anal\u00edticas:  <ul> <li>Proporcionar una estructura de datos estandarizada para reportes de calidad educativa.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_2","title":"Tablas Afectadas","text":"<ol> <li>Origen:  <ul> <li>[Colegio].[FACT_DESEMPENHO_DOCENTE]: Evaluaciones de docentes en colegios.  </li> <li>[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_CE]: Evaluaciones de docentes en programas de educaci\u00f3n continua.  </li> <li>[Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_DE]: Evaluaciones de docentes en educaci\u00f3n para el desarrollo.  </li> <li>[Cedesarrollo].[DIM_PERIODO_ACADEMICO]: Dimensiones de per\u00edodos acad\u00e9micos.  </li> </ul> </li> <li>Destino:  <ul> <li>[Transversal].[FACT_EVALUACION_DOCENTE]: Tabla de hechos consolidada para an\u00e1lisis de desempe\u00f1o docente.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_2","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada (Origen ADO NET): <pre><code>SELECT PERIODO_ACADEMICO, ID_UNIDAD, ID_PERSONAL, NOMBRE_DOCENTE, \n       CALIFICACION_DEFINITIVA, uni.ID_FECHA \nFROM (\n    -- Datos de Colegio\n    SELECT \n        [ANIO_ACADEMICO] as PERIODO_ACADEMICO,\n        NULL as ID_UNIDAD,\n        [ID_PERSONAL],\n        [NOMBRE_DOCENTE],\n        [TOTAL_GENERAL] as CALIFICACION_DEFINITIVA,\n        [ID_FECHA]\n    FROM [Colegio].[FACT_DESEMPENHO_DOCENTE]\n\n    UNION\n\n    -- Datos de Cedesarrollo (Educaci\u00f3n Continua)\n    SELECT \n        c2.[PERIODO_ACADEMICO],\n        c1.[ID_UNIDAD],\n        c1.[ID_PERSONAL],\n        c1.[NOMBRE_DOCENTE],\n        c1.[CALIFICACION_DEFINITIVA],\n        NULL as ID_FECHA  -- Campo pendiente de implementaci\u00f3n\n    FROM [Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_CE] c1\n    LEFT JOIN [Cedesarrollo].[DIM_PERIODO_ACADEMICO] c2 \n        ON c1.ID_PERIODO = c2.ID_PERIODO\n\n    UNION\n\n    -- Datos de Cedesarrollo (Educaci\u00f3n para el Desarrollo)\n    SELECT \n        c2.[PERIODO_ACADEMICO],\n        c1.[ID_UNIDAD],\n        c1.[ID_PERSONAL],\n        c1.[NOMBRE_DOCENTE],\n        c1.[CALIFICACION] as CALIFICACION_DEFINITIVA,\n        c1.[ID_FECHA]\n    FROM [Cedesarrollo].[FACT_DESEMPENHO_DOCENTE_DE] c1\n    LEFT JOIN [Cedesarrollo].[DIM_PERIODO_ACADEMICO] c2 \n        ON c1.ID_PERIODO = c2.ID_PERIODO\n) uni\nINNER JOIN [Transversal].[DIM_TIEMPO_MENSUAL] dimM \n    ON uni.ID_FECHA = dimM.ID_FECHA;\n</code></pre></p> <p>Caracter\u00edsticas del C\u00f3digo:    - Unificaci\u00f3n de datos: Combina tres fuentes con <code>UNION</code>, estandarizando campos.    - Joins estrat\u00e9gicos: Relaciona con <code>DIM_PERIODO_ACADEMICO</code> y <code>DIM_TIEMPO_MENSUAL</code> para integridad temporal.    - Filtro temporal impl\u00edcito: Solo incluye fechas existentes en <code>DIM_TIEMPO_MENSUAL</code>.  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_11","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET (<code>FACT_EVALUACION</code>) </p> <ul> <li>Descripci\u00f3n: Extrae y unifica datos de evaluaciones docentes usando la consulta SQL anterior.  </li> <li>Propiedades clave:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: 30 segundos.  </li> <li>Columnas clave:  </li> <li><code>PERIODO_ACADEMICO</code> (per\u00edodo acad\u00e9mico).  </li> <li><code>ID_UNIDAD</code> (unidad educativa).  </li> <li><code>CALIFICACION_DEFINITIVA</code> (calificaci\u00f3n num\u00e9rica o categ\u00f3rica).  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET </p> <ul> <li>Descripci\u00f3n: Carga los datos en la tabla de hechos <code>FACT_EVALUACION_DOCENTE</code>.  </li> <li>Propiedades clave:  <ul> <li>Tabla destino: <code>\"Transversal\".\"FACT_EVALUACION_DOCENTE\"</code>.  </li> <li>Inserci\u00f3n masiva: Habilitada (<code>UseBulkInsertWhenPossible = true</code>).  </li> <li>Mapeo de columnas:  </li> </ul> </li> </ul> Origen Destino <code>PERIODO_ACADEMICO</code> <code>PERIODO_ACADEMICO</code> <code>ID_UNIDAD</code> <code>ID_UNIDAD</code> <code>CALIFICACION_DEFINITIVA</code> <code>CALIFICACION_DEFINITIVA</code> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_12","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET\n    participant Destino as Destino ADO NET\n    Origen-&gt;&gt;Destino: Extrae y unifica datos (Colegio + Cedesarrollo)\n    Destino-&gt;&gt;Destino: Carga en FACT_EVALUACION_DOCENTE (Bulk Insert)</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-fact_financiera_cubo","title":"Componente <code>FACT_FINANCIERA_CUBO</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_13","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_FINANCIERA_CUBO</code> es un Data Flow Task dise\u00f1ado para consolidar datos financieros de ejecuci\u00f3n contable y presupuestos en el Data Warehouse DWH_COMFENALCO. Combina informaci\u00f3n de m\u00faltiples fuentes (detalles contables y presupuestarios) y realiza transformaciones cr\u00edticas para cargar los datos en la tabla <code>Transversal.FACT_FINANCIERA</code>. El flujo incluye conversiones de datos y manejo de errores para garantizar la integridad de la informaci\u00f3n.</p>"},{"location":"03.Cubo/03.ETL/#proposito_3","title":"Prop\u00f3sito","text":"<ol> <li> <p>Consolidaci\u00f3n Financiera:  </p> <ul> <li>Integra datos de ejecuci\u00f3n contable (<code>FACT_DETALLE_CONTABLE</code>) y presupuestos (<code>FACT_PRESUPUESTO</code>).</li> <li>Genera m\u00e9tricas clave como ingresos, gastos, costos, activos y pasivos.  </li> </ul> </li> <li> <p>Transformaci\u00f3n de Datos:  </p> <ul> <li>Normaliza tipos de datos para compatibilidad con el esquema destino (ej: conversi\u00f3n de num\u00e9ricos a cadenas).</li> <li>Aplica l\u00f3gica de agregaci\u00f3n (<code>SUM</code>) y filtros para excluir categor\u00edas redundantes.  </li> </ul> </li> <li> <p>Optimizaci\u00f3n para An\u00e1lisis:  </p> <ul> <li>Estructura los datos para facilitar an\u00e1lisis multidimensionales en cubos OLAP.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_3","title":"Tablas Afectadas","text":"<ol> <li> <p>[Transversal].[FACT_FINANCIERA]:  </p> <ul> <li>Tabla de hechos destino que almacena m\u00e9tricas financieras mensualizadas.</li> <li>Columnas clave: <code>ID_FECHA</code>, <code>ID_CEBE</code>, <code>IMPORTE</code>, <code>INGRESOS</code>, <code>GASTOS</code>, <code>ACTIVO</code>, <code>PASIVO</code>.</li> </ul> </li> <li> <p>[Financiera].[DIM_CUENTA_CONTABLE]:  </p> <ul> <li>Proporciona descripciones y clasificaciones de cuentas contables.</li> </ul> </li> <li> <p>[Dwh].[DIM_TIEMPO]:  </p> <ul> <li>Dimensiona fechas para asociar registros a per\u00edodos mensuales.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_3","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada: <pre><code>SELECT UNI.*,\n    ID_UNIDAD\nfrom (\n        SELECT Tp.[ID_MES] * 100 + 1 as ID_FECHA,\n            Tp.[ID_ANIO],\n            Tp.[ID_MES],\n            Ft.[ID_CEBE],\n            Uo.[CEBE],\n            Upper(Uo.[CEBE_DESCRIPCION]) As [DESCRIPCION_CEBE],\n            Upper(Uo.[DEPARTAMENTO]) As [DEPARTAMENTO],\n            Upper(Uo.[AREA]) As [AREA],\n            Upper(Uo.[SUBAREA]) As [SUBAREA],\n            Uo.[SEGMENTO],\n            Uo.[DESCRIPCION_SEGMENTO],\n            Uo.[CODIGO_SSF],\n            Uo.[NOMBRE_SSF],\n            Ft.[ID_CUENTA],\n            Ct.[CUENTA],\n            Ct.[CUENTA_HOMOLOGA],\n            Upper(Ct.[DESCRIPCION]) As [DESCRIPCION],\n            Upper(Ct.[TIPO_CUENTA]) As [TIPO_CUENTA],\n            Upper(Ct.[TIPO_OPERACION]) As [TIPO_OPERACION],\n            Upper(Ct.[GRUPO_CUENTA]) As [GRUPO_CUENTA],\n            Upper(Ct.[SUBGRUPO_CUENTA]) As [SUBGRUPO_CUENTA],\n            Upper(Ct.[GRUPO_OPERACION]) As [GRUPO_OPERACION],\n            Ct.[CUENTA_SSF],\n            Upper(Ct.[DESCRIPCION_SSF]) As [DESCRIPCION_SSF],\n            Upper(Ct.[CUENTA_DESCRIPCION]) As [CUENTA_DESCRIPCION],\n            Upper(Ct.[CUENTA_DESCRIPCION_SSF]) As [CUENTA_DESCRIPCION_SSF],\n            Ct.[SIGNO_INGRESOS],\n            Ct.[CLASIFICACION],\n            Ft.[SEGMENT],\n            Try_Convert(Numeric(18, 0), Sum(isnull(Ft.[IMPORTE], 0))) As [IMPORTE],\n            Try_Convert(Numeric(18, 0), Sum(isnull(Ft.[INGRESOS], 0))) As [INGRESOS],\n            --ing ejecutados\n            Try_Convert(\n                Numeric(18, 0),\n                Sum(isnull(Ft.[INGRESOS_OPERACIONALES], 0))\n            ) As [INGRESOS_OPERACIONALES],\n            Try_Convert(Numeric(18, 0), Sum(isnull(Ft.[GASTOS], 0))) As [GASTOS],\n            Try_Convert(\n                Numeric(18, 0),\n                Sum(isnull(Ft.[GASTOS_OPERACIONALES], 0))\n            ) As [GASTOS_OPERACIONALES],\n            Try_Convert(\n                Numeric(18, 0),\n                Sum(isnull(Ft.[GASTOS_OPERACIONALES_ADMIN], 0))\n            ) As [GASTOS_OPERACIONALES_ADMIN],\n            Try_Convert(\n                Numeric(18, 0),\n                Sum(isnull(Ft.[RESULTADO_EJERCICIO], 0))\n            ) As [RESULTADO_EJERCICIO],\n            Try_Convert(Numeric(18, 0), Sum(isnull(Ft.[COSTOS], 0))) As [COSTOS],\n            Try_Convert(Numeric(18, 0), Sum(isnull(Ft.[ACTIVO], 0))) As [ACTIVO],\n            Try_Convert(Numeric(18, 0), Sum(isnull(Ft.[PASIVO], 0))) As [PASIVO],\n            Try_Convert(Numeric(18, 0), Sum(isnull(Ft.[PATRIMONIO], 0))) As [PATRIMONIO],\n            Try_Convert(\n                Numeric(18, 0),\n                Sum(isnull(Ft.[GASTOS_CON_DISTRIBUCION], 0))\n            ) As [GASTOS_CON_DISTRIBUCION],\n            Try_Convert(\n                Numeric(18, 0),\n                Sum(isnull(Ft.[GASTOS_SIN_DISTRIBUCION], 0))\n            ) As [GASTOS_SIN_DISTRIBUCION],\n            'EJECUCION_CONTABLE' as ACTIVIDAD\n        FROM [DWH_COMFENALCO].[Transversal].[FACT_DETALLE_CONTABLE] as Ft\n            LEFT JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] Tp On Ft.ID_FECHA = tp.ID_FECHA\n            LEFT JOIN [DWH_COMFENALCO].[Financiera].[DIM_UNIDADES_ORGANIZATIVAS] Uo On Ft.ID_CEBE = Uo.ID_CEBE\n            INNER JOIN [DWH_COMFENALCO].[Financiera].[DIM_CUENTA_CONTABLE] Ct On Ft.ID_CUENTA = ct.ID_CUENTA\n        Where\n            /*  TP.ID_ANIO = @A\u00f1o_Actual AND Try_convert(date,tp.FECHA,103) &amp;lt;= @PeriodoMax\n             AND*/\n            Ct.TIPO_CUENTA Not in ('INGRESOS', 'COSTOS', 'GASTOS')\n            AND LEFT(Ct.CUENTA, 4) in (1516, 1528)\n        Group by Tp.[ID_ANIO],\n            Tp.[ID_MES],\n            Ft.[ID_CEBE],\n            Uo.[CEBE],\n            Uo.[CEBE_DESCRIPCION],\n            Uo.[DEPARTAMENTO],\n            Uo.[AREA],\n            Uo.[SUBAREA],\n            Uo.[SEGMENTO],\n            Uo.[DESCRIPCION_SEGMENTO],\n            Uo.[CODIGO_SSF],\n            Uo.[NOMBRE_SSF],\n            Ft.[ID_CUENTA],\n            Ct.[CUENTA],\n            Ct.[CUENTA_HOMOLOGA],\n            Ct.[DESCRIPCION],\n            Ct.[TIPO_CUENTA],\n            Ct.[TIPO_OPERACION],\n            Ct.[GRUPO_CUENTA],\n            Ct.[SUBGRUPO_CUENTA],\n            Ct.[GRUPO_OPERACION],\n            Ct.[CUENTA_SSF],\n            Ct.[DESCRIPCION_SSF],\n            Ct.[CUENTA_DESCRIPCION],\n            Ct.[CUENTA_DESCRIPCION_SSF],\n            Ct.[SIGNO_INGRESOS],\n            Ct.[CLASIFICACION],\n            Ft.[SEGMENT]\n    ) uni\n    INNER JOIN (\n        select ID_FECHA as ID_FECHA2\n        from [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n    ) dimM ON uni.ID_FECHA = dimM.ID_FECHA2\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_UNIDADES_ORGANIZATIVAS] do ON uni.ID_CEBE = do.ID_CEBE --Agregar campo ACTIVIDAD :EJECUCION CONTABLE, PRESUPUESTO CONTABLE\nUNION\nselect uni.*,\n    ID_UNIDAD\nfrom (\n        SELECT [ID_FECHA],\n            NULL as [ID_ANIO],\n            NULL as [ID_MES],\n            [ID_CEBE],\n            NULL as [CEBE],\n            NULL as [DESCRIPCION_CEBE],\n            NULL as [DEPARTAMENTO],\n            NULL as [AREA],\n            NULL as [SUBAREA],\n            NULL as [SEGMENTO],\n            NULL as [DESCRIPCION_SEGMENTO],\n            NULL as [CODIGO_SSF],\n            NULL as [NOMBRE_SSF],\n            [ID_CUENTA],\n            NULL as [CUENTA],\n            NULL as [CUENTA_HOMOLOGA],\n            NULL as [DESCRIPCION],\n            NULL as [TIPO_CUENTA],\n            NULL as [TIPO_OPERACION],\n            NULL as [GRUPO_CUENTA],\n            NULL as [SUBGRUPO_CUENTA],\n            NULL as [GRUPO_OPERACION],\n            NULL as [CUENTA_SSF],\n            NULL as [DESCRIPCION_SSF],\n            NULL as [CUENTA_DESCRIPCION],\n            NULL as [CUENTA_DESCRIPCION_SSF],\n            NULL as [SIGNO_INGRESOS],\n            NULL as [CLASIFICACION],\n            [SEGMENT],\n            [VALOR] as [IMPORTE],\n            [INGRESOS],\n            [INGRESOS_OPERACIONALES],\n            [GASTOS],\n            [GASTOS_OPERACIONALES],\n            [GASTOS_OPERACIONALES_ADMIN],\n            NULL as [RESULTADO_EJERCICIO],\n            [COSTOS],\n            NULL as [ACTIVO],\n            NULL as [PASIVO],\n            NULL as [PATRIMONIO],\n            NULL as [GASTOS_CON_DISTRIBUCION],\n            NULL as [GASTOS_SIN_DISTRIBUCION],\n            'PRESUPUESTO_CONTABLE' as ACTIVIDAD\n        FROM [DWH_COMFENALCO].[Transversal].[FACT_PRESUPUESTO]\n    ) uni\n    INNER JOIN (\n        select ID_FECHA as ID_FECHA2\n        from [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n    ) dimM ON uni.ID_FECHA = dimM.ID_FECHA2\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_UNIDADES_ORGANIZATIVAS] do ON uni.ID_CEBE = do.ID_CEBE\n</code></pre></p> <p>Caracter\u00edsticas del C\u00f3digo: - Uniones (UNION): Combina datos operativos y presupuestarios en un \u00fanico conjunto. - Agregaciones: Calcula totales con <code>SUM</code> para m\u00e9tricas financieras. - Filtros: Excluye tipos de cuenta redundantes (<code>TIPO_CUENTA NOT IN ...</code>).  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_12","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: FACT_FINANCIERA </p> <ul> <li>Descripci\u00f3n: Extrae datos de las tablas <code>FACT_DETALLE_CONTABLE</code> y <code>FACT_PRESUPUESTO</code> usando la consulta SQL anterior.  </li> <li>Propiedades:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: 30 segundos.  </li> <li>Columnas clave: <code>ID_FECHA</code>, <code>ID_CEBE</code>, <code>IMPORTE</code>, <code>INGRESOS</code>, <code>GASTOS</code>.  </li> </ul> </li> </ul> </li> <li> <p>Conversi\u00f3n de Datos </p> <ul> <li>Descripci\u00f3n: Convierte tipos de datos para evitar truncamientos y errores de inserci\u00f3n:  <ul> <li><code>SEGMENTO</code> (i8 \u2192 wstr, 40 caracteres).  </li> <li><code>CUENTA_DESCRIPCION_SSF</code> (wstr, 286 \u2192 wstr, 255).  </li> </ul> </li> <li>Columnas Afectadas:  <ul> <li><code>SEGMENTO</code>, <code>SEGMENT</code>, <code>CUENTA_DESCRIPCION_SSF</code>, <code>ID_CEBE</code>.  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en <code>Transversal.FACT_FINANCIERA</code>.  </li> <li>Propiedades:  <ul> <li>Inserci\u00f3n masiva: Habilitada (<code>UseBulkInsertWhenPossible=true</code>).  </li> <li>Tama\u00f1o de lote: 0 (configuraci\u00f3n predeterminada).  </li> <li>Columnas mapeadas: 34 columnas, incluyendo <code>ID_FECHA</code>, <code>ID_CEBE</code>, <code>IMPORTE</code>, <code>ACTIVIDAD</code>.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_13","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET (FACT_DETALLE_CONTABLE y FACT_PRESUPUESTO)\n    participant Conversion as Conversi\u00f3n de Datos\n    participant Destino as Destino ADO NET (FACT_FINANCIERA)\n\n    Origen -&gt;&gt; Conversion: Env\u00eda datos brutos\n    Conversion -&gt;&gt; Destino: Env\u00eda datos transformados\n    Destino -&gt;&gt; Destino: Inserta registros con inserci\u00f3n masiva</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-fact_unidades","title":"Componente <code>FACT_UNIDADES</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_14","title":"Descripci\u00f3n General","text":"<p>El componente <code>FACT_UNIDADES</code> es una tarea de flujo de datos (Data Flow Task) en un paquete SSIS dise\u00f1ado para consolidar y cargar datos relacionados con unidades operativas en la tabla <code>Transversal.FACT_UNIDADES</code>. Este flujo combina informaci\u00f3n de m\u00faltiples fuentes, incluyendo presupuestos, planes de cobertura, evaluaciones acad\u00e9micas y datos de matr\u00edculas, para generar un registro unificado de actividades educativas y operativas.</p>"},{"location":"03.Cubo/03.ETL/#proposito_4","title":"Prop\u00f3sito","text":"<ol> <li>Consolidaci\u00f3n de Datos:  <ul> <li>Integrar informaci\u00f3n de diversas tablas del Data Warehouse (<code>DWH_COMFENALCO</code>) para formar una vista unificada de las unidades operativas y educativas.</li> </ul> </li> <li>Carga Eficiente:  <ul> <li>Utilizar inserci\u00f3n masiva para optimizar el rendimiento al cargar datos en la tabla destino.</li> </ul> </li> <li>Registro de Actividades:  <ul> <li>Documentar actividades como cobertura proyectada, evaluaciones de dise\u00f1o curricular, deserci\u00f3n estudiantil y resultados de pruebas acad\u00e9micas.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_4","title":"Tablas Afectadas","text":"<ol> <li>[Transversal].[FACT_UNIDADES]:  <ul> <li>Tabla destino que almacena los datos consolidados de unidades operativas, incluyendo informaci\u00f3n de cursos, grados, programas y m\u00e9tricas de poblaci\u00f3n estudiantil.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_4","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada (Origen ADO NET: unidades): <pre><code>SELECT un.*\nFROM (\n        SELECT ID_CURSO,\n            GRADO,\n            ID_UNIDAD,\n            CATEGORIA,\n            ID_PLAN_COBERTURA,\n            CAST(ID_ESTABLECIMIENTO_EDUCATIVO AS nvarchar(40)) as ID_ESTABLECIMIENTO_EDUCATIVO,\n            ID_PROGRAMA,\n            ID_FECHA_MENSUAL,\n            POBLACION_PROYECTADA,\n            ORIGEN,\n            'COBERTURA PROYECTADA' as ACTIVIDAD,\n            NULL as RESULTADO,\n            NULL as CATEGORIA_SABER11,\n            NULL as CAUSA,\n            NULL as NUM_POBLACION,\n            NULL as CALIFICACION,\n            NULL as DOCUMENTOS_COMPLETOS,\n            NULL as NUM_ESTUDIANTES,\n            NULL as NUM_MAYOR_250,\n            NULL as TEMATICA\n        from(\n                --DIM_PRESUPUESTO\n                SELECT [ID_CURSO] AS ID_CURSO,\n                    [GRADO] AS GRADO,\n                    NULL AS ID_UNIDAD,\n                    NULL AS CATEGORIA,\n                    NULL AS ID_PLAN_COBERTURA,\n                    NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n                    NULL AS ID_PROGRAMA,\n                    ID_FECHA_MENSUAL,\n                    SUM(CAST(POBL_PROYECT AS INT)) AS POBLACION_PROYECTADA,\n                    ORIGEN\n                FROM (\n                        SELECT [ID_CURSO],\n                            [GRADO],\n                            [ID_ANIO_PRESUPUESTO] * 10000 + 101 AS ID_FECHA_MENSUAL,\n                            'DIM_PRESUPUESTO' AS ORIGEN,\n                            POBL_PROYECT\n                        FROM [DWH_COMFENALCO].[Colegio].[DIM_PRESUPUESTO]\n                    ) l\n                GROUP BY [ID_CURSO],\n                    [GRADO],\n                    ID_FECHA_MENSUAL,\n                    ORIGEN\n                UNION\n                -- [Cedesarrollo].[FACT_PLAN_COBERTURA]\n                SELECT NULL AS ID_CURSO,\n                    NULL AS GRADO,\n                    [ID_UNIDAD] AS ID_UNIDAD,\n                    [CATEGORIA] AS CATEGORIA,\n                    NULL AS ID_PLAN_COBERTURA,\n                    NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n                    [ID_PROGRAMA] AS ID_PROGRAMA,\n                    ID_FECHA_MENSUAL,\n                    SUM(CAST([USUARIOS_PROYECTADOS] AS INT)) AS POBLACION_PROYECTADA,\n                    ORIGEN\n                FROM (\n                        SELECT FORMAT([FECHA_INICIO], 'yyyyMMdd') AS ID_FECHA_MENSUAL,\n                            up.[ID_UNIDAD],\n                            [CATEGORIA],\n                            [ID_PROGRAMA],\n                            [USUARIOS_PROYECTADOS],\n                            'FACT_PLAN_COBERTURA' AS ORIGEN\n                        FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_PLAN_COBERTURA] up\n                            LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] pa ON up.ID_PERIODO = pa.ID_PERIODO\n                    ) ll\n                GROUP BY [ID_UNIDAD],\n                    [CATEGORIA],\n                    ID_FECHA_MENSUAL,\n                    [ID_PROGRAMA],\n                    ORIGEN\n                UNION\n                -- [Proteccion].[FACT_PLAN_COBERTURA]\n                SELECT NULL AS ID_CURSO,\n                    NULL AS GRADO,\n                    NULL AS ID_UNIDAD,\n                    NULL AS CATEGORIA,\n                    [ID_PLAN_COBERTURA] AS ID_PLAN_COBERTURA,\n                    [ID_ESTABLECIMIENTO_EDUCATIVO] AS ID_ESTABLECIMIENTO_EDUCATIVO,\n                    [ID_PROGRAMA] AS ID_PROGRAMA,\n                    ID_FECHA_MENSUAL,\n                    SUM(CAST([POBLACION_PROYECTADA] AS INT)) AS POBLACION_PROYECTADA,\n                    ORIGEN\n                FROM (\n                        SELECT [ID_PLAN_COBERTURA],\n                            [ANIO] * 10000 + 101 AS ID_FECHA_MENSUAL,\n                            [ID_ESTABLECIMIENTO_EDUCATIVO],\n                            [ID_PROGRAMA],\n                            [COBERTURA_PROYECTADA] AS POBLACION_PROYECTADA,\n                            'FACT_PLAN_COBERTURA' AS ORIGEN\n                        FROM [DWH_COMFENALCO].[Proteccion].[FACT_PLAN_COBERTURA]\n                    ) ll\n                GROUP BY [ID_PLAN_COBERTURA],\n                    [ID_ESTABLECIMIENTO_EDUCATIVO],\n                    [ID_PROGRAMA],\n                    ID_FECHA_MENSUAL,\n                    ORIGEN\n            ) kk\n        UNION\n        ---.[Colegio].[FACT_SABER11_INDIVIDUAL]\n        select ID_CURSO,\n            GRADO,\n            ID_UNIDAD,\n            CATEGORIA,\n            ID_PLAN_COBERTURA,\n            ID_ESTABLECIMIENTO_EDUCATIVO,\n            ID_PROGRAMA,\n            ID_FECHA_MENSUAL,\n            POBLACION_PROYECTADA,\n            ORIGEN,\n            ACTIVIDAD,\n            NULL as RESULTADO,\n            CATEGORIA_SABER11,\n            CAUSA,\n            NUM_POBLACION,\n            CALIFICACION,\n            DOCUMENTOS_COMPLETOS,\n            COUNT(DISTINCT([ID_REGISTRO])) as NUM_ESTUDIANTES,\n            COUNT(\n                DISTINCT CASE\n                    WHEN CAST([RESULTADO] AS int) &amp; gt;\n= 250 THEN [ID_REGISTRO]\nELSE NULL\nEND\n) AS NUM_MAYOR_250,\nTEMATICA\nfrom(\n        SELECT 1 as ID_CURSO,\n            'UNDECIMO' as GRADO,\n            NULL AS ID_UNIDAD,\n            NULL AS CATEGORIA,\n            NULL AS ID_PLAN_COBERTURA,\n            NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n            NULL AS ID_PROGRAMA,\n            LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA_MENSUAL,\n            NULL AS POBLACION_PROYECTADA,\n            'FACT_SABER11_INDIVIDUAL' AS ORIGEN,\n            'SABER 11' as ACTIVIDAD,\n            [ID_REGISTRO],\n            [RESULTADO],\n            NULL as CATEGORIA_SABER11,\n            NULL as CAUSA,\n            NULL as NUM_POBLACION,\n            NULL as CALIFICACION,\n            NULL as DOCUMENTOS_COMPLETOS,\n            TEMATICA\n        FROM [DWH_COMFENALCO].[Colegio].[FACT_SABER11_INDIVIDUAL]\n    ) kk\ngroup by ID_CURSO,\n    GRADO,\n    ID_UNIDAD,\n    CATEGORIA,\n    ID_PLAN_COBERTURA,\n    ID_ESTABLECIMIENTO_EDUCATIVO,\n    ID_PROGRAMA,\n    ID_FECHA_MENSUAL,\n    POBLACION_PROYECTADA,\n    ORIGEN,\n    ACTIVIDAD,\n    CATEGORIA_SABER11,\n    CAUSA,\n    NUM_POBLACION,\n    CALIFICACION,\n    DOCUMENTOS_COMPLETOS,\n    TEMATICA ---[Colegio].[FACT_SABER11_COLEGIOS]\nUNION\n---[Colegio].[FACT_SABER11_COLEGIOS]\nSELECT 1 as ID_CURSO,\n    'UNDECIMO' as GRADO,\n    NULL AS ID_UNIDAD,\n    NULL AS CATEGORIA,\n    NULL AS ID_PLAN_COBERTURA,\n    [COD_ESTABLECIMIENTO_EDUCATIVO] AS ID_ESTABLECIMIENTO_EDUCATIVO,\n    NULL AS ID_PROGRAMA,\n    LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA_MENSUAL,\n    NULL AS POBLACION_PROYECTADA,\n    'FACT_SABER11_COLEGIOS_CEC' AS ORIGEN,\n    'SABER 11' as ACTIVIDAD,\n    [RESULTADO],\n    [CATEGORIA_SABER11],\n    NULL as CAUSA,\n    NULL as NUM_POBLACION,\n    NULL as CALIFICACION,\n    NULL as DOCUMENTOS_COMPLETOS,\n    NULL as NUM_ESTUDIANTES,\n    NULL as NUM_MAYOR_250,\n    NULL as TEMATICA\nFROM [DWH_COMFENALCO].[Colegio].[FACT_SABER11_COLEGIOS]\nwhere [COD_ESTABLECIMIENTO_EDUCATIVO] = 313001003095\nUNION\nSELECT ID_CURSO,\n    GRADO,\n    ID_UNIDAD,\n    CATEGORIA,\n    ID_PLAN_COBERTURA,\n    ID_ESTABLECIMIENTO_EDUCATIVO,\n    ID_PROGRAMA,\n    ID_FECHA_MENSUAL,\n    POBLACION_PROYECTADA,\n    ORIGEN,\n    ACTIVIDAD,\n    RESULTADO,\n    CATEGORIA_SABER11,\n    [CAUSA],\n    COUNT(DISTINCT([ID_POBLACION])) as NUM_POBLACION,\n    NULL as CALIFICACION,\n    NULL as DOCUMENTOS_COMPLETOS,\n    NULL as NUM_ESTUDIANTES,\n    NULL as NUM_MAYOR_250,\n    NULL as TEMATICA\nFROM(\n        SELECT NULL as ID_CURSO,\n            NULL as GRADO,\n            NULL AS ID_UNIDAD,\n            NULL AS CATEGORIA,\n            NULL AS ID_PLAN_COBERTURA,\n            CAST(ID_ESTABLECIMIENTO_EDUCATIVO AS nvarchar(40)) as ID_ESTABLECIMIENTO_EDUCATIVO,\n            ID_PROGRAMA,\n            LEFT([ID_FECHA], 6) * 100 + 1 as ID_FECHA_MENSUAL,\n            NULL AS POBLACION_PROYECTADA,\n            'FACT_DESERCION' AS ORIGEN,\n            'DESERCION' as ACTIVIDAD,\n            NULL as ID_POBLACION_MATRICULA,\n            NULL as RESULTADO,\n            NULL as CATEGORIA_SABER11,\n            [CAUSA],\n            [ID_POBLACION]\n        FROM [DWH_COMFENALCO].[Proteccion].[FACT_DESERCION]\n    ) ll\ngroup by ID_CURSO,\n    GRADO,\n    ID_UNIDAD,\n    CATEGORIA,\n    ID_PLAN_COBERTURA,\n    ID_ESTABLECIMIENTO_EDUCATIVO,\n    ID_PROGRAMA,\n    ID_FECHA_MENSUAL,\n    POBLACION_PROYECTADA,\n    ORIGEN,\n    ACTIVIDAD,\n    ID_POBLACION_MATRICULA,\n    RESULTADO,\n    CATEGORIA_SABER11,\n    [CAUSA]\nUNION\nSELECT NULL as ID_CURSO,\n    NULL as GRADO,\n    fep.[ID_UNIDAD] as ID_UNIDAD,\n    NULL AS CATEGORIA,\n    NULL AS ID_PLAN_COBERTURA,\n    NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n    NULL AS ID_PROGRAMA,\n    FORMAT([FECHA_INICIO], 'yyyyMMdd') AS ID_FECHA_MENSUAL,\n    NULL AS POBLACION_PROYECTADA,\n    'FACT_EVALUACION_PLAN_CURRICULAR' AS ORIGEN,\n    'EVALUACION DISENO CURRICULAR' as ACTIVIDAD,\n    NULL as RESULTADO,\n    NULL as CATEGORIA_SABER11,\n    NULL as CAUSA,\n    NULL as NUM_POBLACION,\n    [CALIFICACION],\n    NULL as DOCUMENTOS_COMPLETOS,\n    NULL as NUM_ESTUDIANTES,\n    NULL as NUM_MAYOR_250,\n    NULL as TEMATICA\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_EVALUACION_PLAN_CURRICULAR] fep\n    LEFT JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_PERIODO_ACADEMICO] pa ON fep.ID_PERIODO = pa.ID_PERIODO\nUNION\nSELECT NULL as ID_CURSO,\n    NULL as GRADO,\n    NULL AS ID_UNIDAD,\n    NULL AS CATEGORIA,\n    NULL AS ID_PLAN_COBERTURA,\n    NULL AS ID_ESTABLECIMIENTO_EDUCATIVO,\n    NULL AS ID_PROGRAMA,\n    LEFT(ID_FECHA, 6) * 100 + 1 as ID_FECHA_MENSUAL,\n    NULL AS POBLACION_PROYECTADA,\n    'FACT_ESTADO_MATRICULAS' AS ORIGEN,\n    'MATRICULAS_ESTUDIANTES' as ACTIVIDAD,\n    NULL as RESULTADO,\n    NULL as CATEGORIA_SABER11,\n    NULL as CAUSA,\n    NULL as NUM_POBLACION,\n    NULL as CALIFICACION,\n    DOCUMENTOS_COMPLETOS,\n    COUNT(DISTINCT(ID_ESTUDIANTE)) as NUM_ESTUDIANTES,\n    NULL as NUM_MAYOR_250,\n    NULL as TEMATICA\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS]\nGROUP BY ID_FECHA,\n    DOCUMENTOS_COMPLETOS\n) un\nINNER JOIN (\n    select ID_FECHA as ID_FECHA2\n    from [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]\n) dimM ON un.ID_FECHA_MENSUAL = dimM.ID_FECHA2\n</code></pre></p> <p>Caracter\u00edsticas del C\u00f3digo:  </p> <ul> <li>Uniones Complejas: Combina datos de tablas como <code>DIM_PRESUPUESTO</code>, <code>FACT_PLAN_COBERTURA</code>, <code>FACT_SABER11_INDIVIDUAL</code> y <code>FACT_EVALUACION_PLAN_CURRICULAR</code>.</li> <li>Agregaciones: Calcula m\u00e9tricas como <code>NUM_ESTUDIANTES</code> y <code>NUM_MAYOR_250</code> (estudiantes con puntaje mayor a 250 en pruebas).</li> <li>Manejo de Fechas: Normaliza fechas al formato mensual (<code>ID_FECHA_MENSUAL</code>) para alinearse con la dimensi\u00f3n temporal.</li> </ul>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_13","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: unidades </p> <ul> <li>Descripci\u00f3n: Extrae datos mediante una consulta SQL que unifica m\u00faltiples fuentes.  </li> <li>Propiedades:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: <code>30 segundos</code>.  </li> <li>Modo de acceso: <code>Comando SQL</code>.  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>Transversal.FACT_UNIDADES</code>.  </li> <li>Propiedades:  <ul> <li>Tabla destino: <code>\"Transversal\".\"FACT_UNIDADES\"</code>.  </li> <li>Inserci\u00f3n masiva: Habilitada (<code>UseBulkInsertWhenPossible = true</code>).  </li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o predeterminado del b\u00fafer).  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_14","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET (unidades)\n    participant Destino as Destino ADO NET\n    Origen-&gt;&gt;Destino: Extrae y transforma datos\n    Destino-&gt;&gt;FACT_UNIDADES: Inserta registros con Bulk Insert</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-truncar-tabla-paquete-fact_mineriamineria_colegio","title":"Componente <code>Truncar Tabla</code> (Paquete <code>FACT_MINERIA\\MINERIA_COLEGIO</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_15","title":"Descripci\u00f3n General","text":"<p>La tarea <code>Truncar Tabla</code> es un componente de ejecuci\u00f3n SQL dentro de un paquete SSIS dise\u00f1ado para preparar la tabla <code>FACT_MINERIA</code> antes de una nueva carga de datos. Este componente elimina todos los registros de la tabla utilizando el comando <code>TRUNCATE TABLE</code>, asegurando un entorno limpio para procesos posteriores.</p>"},{"location":"03.Cubo/03.ETL/#proposito_5","title":"Prop\u00f3sito","text":"<ol> <li>Limpieza de Datos:  <ul> <li>Elimina todos los registros existentes en la tabla <code>FACT_MINERIA</code> para evitar duplicados o inconsistencias durante la carga incremental o total.  </li> </ul> </li> <li>Optimizaci\u00f3n de Rendimiento:  <ul> <li>Utiliza <code>TRUNCATE TABLE</code> para borrar datos de manera eficiente, minimizando el uso de logs y recursos del servidor.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_5","title":"Tablas Afectadas","text":"<ol> <li>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]:  <ul> <li>Tabla de hechos que almacena informaci\u00f3n relevante para procesos de miner\u00eda de datos en an\u00e1lisis educativos o operativos.  </li> <li>Estructura t\u00edpica: Incluye m\u00e9tricas, indicadores y datos hist\u00f3ricos para modelos anal\u00edticos.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_5","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada: <pre><code>TRUNCATE TABLE [DWH_COMFENALCO].[Transversal].[FACT_MINERIA];\n</code></pre></p> <p>Caracter\u00edsticas del Comando: - Eficiencia: Elimina todas las filas sin registrar operaciones individuales de borrado. - Seguridad: Requiere permisos elevados y no funciona si hay restricciones de integridad referencial activas.  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_14","title":"Componentes del Flujo de Datos","text":"<ol> <li>Tarea Ejecutar SQL (<code>Truncar Tabla</code>) <ul> <li>Tipo: <code>Microsoft.ExecuteSQLTask</code>.  </li> <li>Propiedades Clave:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: Valor predeterminado (no especificado en XML).  </li> <li>Instrucci\u00f3n SQL: Directa y sin par\u00e1metros.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_15","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant SSIS as Paquete SSIS\n    participant SQLServer as Servidor SQL\n    SSIS -&gt;&gt; SQLServer: Ejecutar TRUNCATE TABLE FACT_MINERIA\n    SQLServer --&gt;&gt; SSIS: Confirmaci\u00f3n de operaci\u00f3n</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-gestion-matriculas-paquete-fact_mineriamineria_colegio","title":"Componente <code>Gesti\u00f3n Matr\u00edculas</code> (Paquete <code>FACT_MINERIA\\MINERIA_COLEGIO</code>)","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_16","title":"Descripci\u00f3n General","text":"<p>El componente <code>Gesti\u00f3n Matr\u00edculas</code> es un flujo de datos ETL dentro de un paquete SSIS dise\u00f1ado para consolidar y transformar informaci\u00f3n relacionada con procesos de matr\u00edcula en instituciones educativas. Extrae datos de m\u00faltiples tablas de origen, aplica l\u00f3gica de negocio para calcular m\u00e9tricas de tiempo, estados de admisi\u00f3n y gesti\u00f3n acad\u00e9mica, y carga los resultados en la tabla <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#proposito_6","title":"Prop\u00f3sito","text":"<ol> <li>Consolidar Datos Educativos:  <ul> <li>Integra informaci\u00f3n de matr\u00edculas, estados de admisi\u00f3n, tiempos de gesti\u00f3n y categor\u00edas estudiantiles para an\u00e1lisis de miner\u00eda de datos.  </li> </ul> </li> <li>Seguimiento de Procesos Acad\u00e9micos:  <ul> <li>Mide tiempos de gesti\u00f3n en \u00e1reas como codeudores, secretar\u00eda acad\u00e9mica, psicolog\u00eda y coordinaci\u00f3n.  </li> </ul> </li> <li>Clasificaci\u00f3n de Estudiantes:  <ul> <li>Identifica estudiantes en proceso, admitidos, no admitidos o desistentes mediante indicadores binarios (<code>IND_ADMITIDO</code>, <code>IND_NO_ADMITIDO</code>, etc.).  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_6","title":"Tablas Afectadas","text":"<ol> <li>Origen:  <ul> <li>[Colegio].[FACT_INSCRIPCION_MATRICULAS]: Datos crudos de inscripciones y matr\u00edculas.  </li> <li>[Dwh].[DIM_TIEMPO], [DIM_CATEGORIAS], [Colegio].[DIM_ESTADO_PROCESO]: Dimensiones para tiempo, categor\u00edas familiares y estados de procesos.  </li> </ul> </li> <li>Destino:  <ul> <li>[Transversal].[FACT_MINERIA]: Tabla de hechos para an\u00e1lisis de miner\u00eda de datos.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_6","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada (Resumen): <pre><code>WITH Proceso_Matriculas AS (\n    -----------------------------------------------------------------------------------------------------------\n    -- FT FACT_INSCRIPCION_MATRICULAS   \n    -----------------------------------------------------------------------------------------------------------\n    SELECT FT.ID_FECHA,\n        FT.ID_ANIO_ACADEMICO,\n        FT.BP,\n        FT.ID_CATEGORIA,\n        FT.ID_CURSO,\n        FT.ID_TIPO_ESTUDIANTE,\n        CASE\n            WHEN FT2.[1] IS NULL THEN 0\n            ELSE 1\n        END AS IND_CODEUDOR,\n        CASE\n            WHEN FT2.[1] = FT4.T_TOTAL_GESTION\n            AND ISNULL(Ft3.IND_CUMPLIMIENTO, 1) = 0 THEN 0\n            ELSE 1\n        END AS P_CODEUDOR,\n        FT2.[1] AS T_CODEUDOR,\n        CASE\n            WHEN FT2.[3] IS NULL THEN 0\n            ELSE 1\n        END AS IND_SECRETARIA_ACADEMICA,\n        CASE\n            WHEN FT2.[3] = FT4.T_TOTAL_GESTION\n            AND ISNULL(Ft3.IND_CUMPLIMIENTO, 1) = 0 THEN 0\n            ELSE 1\n        END AS P_SECRETARIA_ACADEMICA,\n        FT2.[3] AS T_SECRETARIA_ACADEMICA,\n        CASE\n            WHEN FT2.[4] IS NULL THEN 0\n            ELSE 1\n        END AS IND_PSICOLOGIA,\n        CASE\n            WHEN FT2.[4] = FT4.T_TOTAL_GESTION\n            AND ISNULL(Ft3.IND_CUMPLIMIENTO, 1) = 0 THEN 0\n            ELSE 1\n        END AS P_PSICOLOGIA,\n        FT2.[4] AS T_PSICOLOGIA,\n        CASE\n            WHEN FT2.[5] IS NULL THEN 0\n            ELSE 1\n        END AS IND_COORDINACION_ACADEMICA,\n        CASE\n            WHEN FT2.[5] = FT4.T_TOTAL_GESTION\n            AND ISNULL(Ft3.IND_CUMPLIMIENTO, 1) = 0 THEN 0\n            ELSE 1\n        END AS P_COORDINACION_ACADEMICA,\n        FT2.[5] AS T_COORDINACION_ACADEMICA,\n        1 AS INDICADOR,\n        FT4.T_TOTAL_GESTION,\n        ISNULL(Ft3.IND_CUMPLIMIENTO, 1) AS IND_CUMPLIMIENTO,\n        ISNULL(FT5.IND_EN_PROCESO, 0) AS IND_EN_PROCESO,\n        ISNULL(FT5.IND_ADMITIDO, 0) AS IND_ADMITIDO,\n        ISNULL(FT5.IND_NO_ADMITIDO, 0) AS IND_NO_ADMITIDO,\n        ISNULL(FT5.IND_DESISTIDO, 0) AS IND_DESISTIDO\n    FROM (\n            SELECT T.ID_FECHA,\n                MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                MT.BP,\n                CA.ID_CATEGORIA,\n                CS.ID_CURSO,\n                ES.ID_TIPO_ESTUDIANTE\n            FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT\n                JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n                JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n                JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION] EG ON EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n                JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO] EP ON EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n                JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA ON EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n                JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS ON CS.ID_CURSO = MT.ID_CURSO\n                JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES ON ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED ON ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n                JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n            WHERE MT.ID_ESTADO_PROCESO != 11\n                AND MT.ID_TIPO_ESTUDIANTE != 2\n            GROUP BY T.ID_FECHA,\n                MT.ANIO_ACADEMICO,\n                MT.BP,\n                CA.ID_CATEGORIA,\n                CS.ID_CURSO,\n                ES.ID_TIPO_ESTUDIANTE\n        ) FT\n        OUTER APPLY (\n            SELECT [1],\n                [3],\n                [4],\n                [5],\n                [11],\n                [-1]\n            FROM (\n                    SELECT T.ID_FECHA,\n                        MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                        MT.BP,\n                        CA.ID_CATEGORIA,\n                        CS.ID_CURSO,\n                        ES.ID_TIPO_ESTUDIANTE,\n                        EP.ID_ESTADO_PROCESO,\n                        SUM(MT.TIEMPO_GESTION_SEGUNDO_DIA_HABIL) AS TIEMPO_GESTION_SEGUNDO_DIA_HABIL\n                    FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT\n                        JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n                        JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION] EG ON EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO] EP ON EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA ON EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS ON CS.ID_CURSO = MT.ID_CURSO\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES ON ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED ON ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n                    WHERE MT.ID_ESTADO_PROCESO != 11\n                        AND FT.ID_FECHA = MT.ID_FECHA\n                        AND FT.ID_ANIO_ACADEMICO = MT.ANIO_ACADEMICO\n                        AND FT.BP = MT.BP\n                        AND FT.ID_CURSO = MT.ID_CURSO\n                        AND FT.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                    GROUP BY T.ID_FECHA,\n                        MT.ANIO_ACADEMICO,\n                        MT.BP,\n                        CA.ID_CATEGORIA,\n                        CS.ID_CURSO,\n                        ES.ID_TIPO_ESTUDIANTE,\n                        EP.ID_ESTADO_PROCESO\n                ) FT1 PIVOT (\n                    SUM(TIEMPO_GESTION_SEGUNDO_DIA_HABIL) FOR ID_ESTADO_PROCESO IN ([1], [3], [4], [5], [11], [-1])\n                ) as PVT\n        ) FT2\n        OUTER APPLY (\n            SELECT IND_CUMPLIMIENTO\n            FROM (\n                    SELECT T.ID_FECHA,\n                        MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                        MT.BP,\n                        CA.ID_CATEGORIA,\n                        CS.ID_CURSO,\n                        ES.ID_TIPO_ESTUDIANTE,\n                        0 AS IND_CUMPLIMIENTO\n                    FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT\n                        JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n                        JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION] EG ON EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO] EP ON EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA ON EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS ON CS.ID_CURSO = MT.ID_CURSO\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES ON ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED ON ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n                    WHERE MT.ID_ESTADO_PROCESO != 11\n                        AND FT.ID_FECHA = MT.ID_FECHA\n                        AND FT.ID_ANIO_ACADEMICO = MT.ANIO_ACADEMICO\n                        AND FT.BP = MT.BP\n                        AND FT.ID_CURSO = MT.ID_CURSO\n                        AND FT.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                        AND cast(mt.FECHA_GESTION AS date) = '1900-01-01'\n                    GROUP BY T.ID_FECHA,\n                        MT.ANIO_ACADEMICO,\n                        MT.BP,\n                        CA.ID_CATEGORIA,\n                        CS.ID_CURSO,\n                        ES.ID_TIPO_ESTUDIANTE\n                ) FT1\n        ) FT3\n        OUTER APPLY (\n            SELECT T_TOTAL_GESTION\n            FROM (\n                    SELECT T.ID_FECHA,\n                        MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                        MT.BP,\n                        CA.ID_CATEGORIA,\n                        CS.ID_CURSO,\n                        ES.ID_TIPO_ESTUDIANTE,\n                        MAX(TIEMPO_GESTION_SEGUNDO_DIA_HABIL) AS T_TOTAL_GESTION\n                    FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT\n                        JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n                        JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION] EG ON EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO] EP ON EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA ON EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS ON CS.ID_CURSO = MT.ID_CURSO\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES ON ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED ON ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n                    WHERE MT.ID_ESTADO_PROCESO != 11\n                        AND FT.ID_FECHA = MT.ID_FECHA\n                        AND FT.ID_ANIO_ACADEMICO = MT.ANIO_ACADEMICO\n                        AND FT.BP = MT.BP\n                        AND FT.ID_CURSO = MT.ID_CURSO\n                        AND FT.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                    GROUP BY T.ID_FECHA,\n                        MT.ANIO_ACADEMICO,\n                        MT.BP,\n                        CA.ID_CATEGORIA,\n                        CS.ID_CURSO,\n                        ES.ID_TIPO_ESTUDIANTE\n                ) FT1\n        ) FT4\n        OUTER APPLY (\n            SELECT ISNULL ([EN PROCESO], 0) AS IND_EN_PROCESO,\n                ISNULL ([ADMITIDO], 0) AS IND_ADMITIDO,\n                ISNULL ([NO ADMITIDO], 0) AS IND_NO_ADMITIDO,\n                ISNULL ([PROCESO DESISTIDO], 0) AS IND_DESISTIDO\n            FROM (\n                    SELECT T.ID_FECHA,\n                        MT.ANIO_ACADEMICO AS ID_ANIO_ACADEMICO,\n                        MT.BP,\n                        CA.ID_CATEGORIA,\n                        CS.ID_CURSO,\n                        ES.ID_TIPO_ESTUDIANTE,\n                        EA.DESC_ESTADO_ADMISION,\n                        COUNT(MT.BP) AS IND_ADMISION\n                    FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS] MT\n                        JOIN [DWH_COMFENALCO].[Dwh].[DIM_TIEMPO] T ON T.ID_FECHA = MT.ID_FECHA\n                        JOIN [DWH_COMFENALCO].[Dwh].[DIM_CATEGORIAS] CA ON CA.ID_CATEGORIA = MT.ID_CATEGORIA_FAMILIAR\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_GESTION] EG ON EG.ID_ESTADO_GESTION = MT.ID_ESTADO_GESTION\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_PROCESO] EP ON EP.ID_ESTADO_PROCESO = MT.ID_ESTADO_PROCESO\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_ADMISION] EA ON EA.ID_ESTADO_ADMISION = MT.ID_ESTADO_ADMISION\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_CURSO] CS ON CS.ID_CURSO = MT.ID_CURSO\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_TIPO_ESTUDIANTE] ES ON ES.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_ESTADO_CODEUDOR] ED ON ED.ID_ESTADO_CODEUDOR = MT.ID_ESTADO_CODEUDOR\n                        JOIN [DWH_COMFENALCO].[Colegio].[DIM_POBLACION_MATRICULA] EM ON EM.PARTNER = MT.BP\n                    WHERE MT.ID_ESTADO_PROCESO != 11\n                        AND EA.DESC_ESTADO_ADMISION IN (\n                            'EN PROCESO',\n                            'ADMITIDO',\n                            'NO ADMITIDO',\n                            'PROCESO DESISTIDO'\n                        )\n                        AND FT.ID_FECHA = MT.ID_FECHA\n                        AND FT.ID_ANIO_ACADEMICO = MT.ANIO_ACADEMICO\n                        AND FT.BP = MT.BP\n                        AND FT.ID_CURSO = MT.ID_CURSO\n                        AND FT.ID_TIPO_ESTUDIANTE = MT.ID_TIPO_ESTUDIANTE\n                    GROUP BY T.ID_FECHA,\n                        MT.ANIO_ACADEMICO,\n                        MT.BP,\n                        CA.ID_CATEGORIA,\n                        CS.ID_CURSO,\n                        ES.ID_TIPO_ESTUDIANTE,\n                        EA.DESC_ESTADO_ADMISION\n                ) FT1 PIVOT (\n                    COUNT(FT1.BP) FOR FT1.DESC_ESTADO_ADMISION IN (\n                        [EN PROCESO],\n                        [ADMITIDO],\n                        [NO ADMITIDO],\n                        [PROCESO DESISTIDO]\n                    )\n                ) as PVT\n        ) FT5\n)\nSELECT BP,\n    ID_FECHA_MENSUAL,\n    ID_ANIO_ACADEMICO --,CONVERT(INT, LEFT(CAST(ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL\n,\n    1 AS ID_UNIDAD,\n    CAST(CONVERT(varchar, [ID_FECHA]) AS datetime) AS FECHA_INICIAL,\n    DATEADD(\n        SECOND,\n        TIEMPO_SEGUNDOS,\n        CAST(CONVERT(varchar, [ID_FECHA]) AS datetime)\n    ) AS FECHA_FINAL,\n    ACTIVIDAD,\n    TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    ID_CATEGORIA,\n    ID_CURSO,\n    ID_TIPO_ESTUDIANTE --P_CODEUDOR,\n    --P_PSICOLOGIA,\n    --P_SECRETARIA_ACADEMICA,\n    --P_COORDINACION_ACADEMICA,    \n    /*CASE \n     WHEN IND_EN_PROCESO + IND_ADMITIDO + IND_NO_ADMITIDO + IND_DESISTIDO = 0 THEN 1 \n     ELSE IND_EN_PROCESO \n     END AS IND_EN_PROCESO,*/\n    --IND_ADMITIDO,\n    --IND_NO_ADMITIDO,\n    --IND_DESISTIDO\nFROM (\n        SELECT BP,\n            pm.ID_FECHA,\n            ID_ANIO_ACADEMICO,\n            CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n            ID_CATEGORIA,\n            ID_CURSO,\n            ID_TIPO_ESTUDIANTE,\n            P_CODEUDOR,\n            P_PSICOLOGIA,\n            P_SECRETARIA_ACADEMICA,\n            P_COORDINACION_ACADEMICA,\n            'Gesti\u00f3n Codeudor' AS ACTIVIDAD,\n            ISNULL(T_CODEUDOR, 0) AS TIEMPO_SEGUNDOS,\n            IND_EN_PROCESO,\n            IND_ADMITIDO,\n            IND_NO_ADMITIDO,\n            IND_DESISTIDO\n        FROM Proceso_Matriculas pm\n            INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(\n                INT,\n                LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01'\n            )\n        WHERE P_CODEUDOR = 1\n        UNION ALL\n        SELECT BP,\n            pm.ID_FECHA,\n            ID_ANIO_ACADEMICO,\n            CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n            ID_CATEGORIA,\n            ID_CURSO,\n            ID_TIPO_ESTUDIANTE,\n            P_CODEUDOR,\n            P_PSICOLOGIA,\n            P_SECRETARIA_ACADEMICA,\n            P_COORDINACION_ACADEMICA,\n            'Gesti\u00f3n Secretaria Acad\u00e9mica' AS ACTIVIDAD,\n            ISNULL(T_SECRETARIA_ACADEMICA, 0) AS TIEMPO_SEGUNDOS,\n            IND_EN_PROCESO,\n            IND_ADMITIDO,\n            IND_NO_ADMITIDO,\n            IND_DESISTIDO\n        FROM Proceso_Matriculas pm\n            INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(\n                INT,\n                LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01'\n            )\n        WHERE P_SECRETARIA_ACADEMICA = 1\n        UNION ALL\n        SELECT BP,\n            pm.ID_FECHA,\n            ID_ANIO_ACADEMICO,\n            CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n            ID_CATEGORIA,\n            ID_CURSO,\n            ID_TIPO_ESTUDIANTE,\n            P_CODEUDOR,\n            P_PSICOLOGIA,\n            P_SECRETARIA_ACADEMICA,\n            P_COORDINACION_ACADEMICA,\n            'Gesti\u00f3n Psicolog\u00eda' AS ACTIVIDAD,\n            ISNULL(T_PSICOLOGIA, 0) AS TIEMPO_SEGUNDOS,\n            IND_EN_PROCESO,\n            IND_ADMITIDO,\n            IND_NO_ADMITIDO,\n            IND_DESISTIDO\n        FROM Proceso_Matriculas pm\n            INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(\n                INT,\n                LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01'\n            )\n        WHERE P_PSICOLOGIA = 1\n        UNION ALL\n        SELECT BP,\n            pm.ID_FECHA,\n            ID_ANIO_ACADEMICO,\n            CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n            ID_CATEGORIA,\n            ID_CURSO,\n            ID_TIPO_ESTUDIANTE,\n            P_CODEUDOR,\n            P_PSICOLOGIA,\n            P_SECRETARIA_ACADEMICA,\n            P_COORDINACION_ACADEMICA,\n            'Gesti\u00f3n Coordinaci\u00f3n Acad\u00e9mica' AS ACTIVIDAD,\n            ISNULL(T_COORDINACION_ACADEMICA, 0) AS TIEMPO_SEGUNDOS,\n            IND_EN_PROCESO,\n            IND_ADMITIDO,\n            IND_NO_ADMITIDO,\n            IND_DESISTIDO\n        FROM Proceso_Matriculas pm\n            INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(\n                INT,\n                LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01'\n            )\n        WHERE P_COORDINACION_ACADEMICA = 1\n        UNION ALL\n        SELECT BP,\n            pm.ID_FECHA,\n            ID_ANIO_ACADEMICO,\n            CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n            ID_CATEGORIA,\n            ID_CURSO,\n            ID_TIPO_ESTUDIANTE,\n            P_CODEUDOR,\n            P_PSICOLOGIA,\n            P_SECRETARIA_ACADEMICA,\n            P_COORDINACION_ACADEMICA,\n            'En Proceso' AS ACTIVIDAD,\n            T_TOTAL_GESTION AS TIEMPO_SEGUNDOS,\n            IND_EN_PROCESO,\n            IND_ADMITIDO,\n            IND_NO_ADMITIDO,\n            IND_DESISTIDO\n        FROM Proceso_Matriculas pm\n            INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(\n                INT,\n                LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01'\n            )\n        WHERE IND_EN_PROCESO = 1\n            OR IND_EN_PROCESO + IND_ADMITIDO + IND_NO_ADMITIDO + IND_DESISTIDO = 0\n        UNION ALL\n        SELECT BP,\n            pm.ID_FECHA,\n            ID_ANIO_ACADEMICO,\n            CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n            ID_CATEGORIA,\n            ID_CURSO,\n            ID_TIPO_ESTUDIANTE,\n            P_CODEUDOR,\n            P_PSICOLOGIA,\n            P_SECRETARIA_ACADEMICA,\n            P_COORDINACION_ACADEMICA,\n            'Estudiante Admitido' AS ACTIVIDAD,\n            T_TOTAL_GESTION AS TIEMPO_SEGUNDOS,\n            IND_EN_PROCESO,\n            IND_ADMITIDO,\n            IND_NO_ADMITIDO,\n            IND_DESISTIDO\n        FROM Proceso_Matriculas pm\n            INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(\n                INT,\n                LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01'\n            )\n        WHERE IND_ADMITIDO = 1\n        UNION ALL\n        SELECT BP,\n            pm.ID_FECHA,\n            ID_ANIO_ACADEMICO,\n            CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n            ID_CATEGORIA,\n            ID_CURSO,\n            ID_TIPO_ESTUDIANTE,\n            P_CODEUDOR,\n            P_PSICOLOGIA,\n            P_SECRETARIA_ACADEMICA,\n            P_COORDINACION_ACADEMICA,\n            'Estudiante No Admitido' AS ACTIVIDAD,\n            T_TOTAL_GESTION AS TIEMPO_SEGUNDOS,\n            IND_EN_PROCESO,\n            IND_ADMITIDO,\n            IND_NO_ADMITIDO,\n            IND_DESISTIDO\n        FROM Proceso_Matriculas pm\n            INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(\n                INT,\n                LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01'\n            )\n        WHERE IND_NO_ADMITIDO = 1\n        UNION ALL\n        SELECT BP,\n            pm.ID_FECHA,\n            ID_ANIO_ACADEMICO,\n            CONVERT(INT, CAST(ID_ANIO_ACADEMICO AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n            ID_CATEGORIA,\n            ID_CURSO,\n            ID_TIPO_ESTUDIANTE,\n            P_CODEUDOR,\n            P_PSICOLOGIA,\n            P_SECRETARIA_ACADEMICA,\n            P_COORDINACION_ACADEMICA,\n            'Estudiante Con Proceso Desistido' AS ACTIVIDAD,\n            T_TOTAL_GESTION AS TIEMPO_SEGUNDOS,\n            IND_EN_PROCESO,\n            IND_ADMITIDO,\n            IND_NO_ADMITIDO,\n            IND_DESISTIDO\n        FROM Proceso_Matriculas pm\n            INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm on tm.[ID_FECHA] = CONVERT(\n                INT,\n                LEFT(CAST(pm.ID_FECHA AS VARCHAR), 6) + '01'\n            )\n        WHERE IND_DESISTIDO = 1\n    ) AS MATRICULAS_COLEGIO\n</code></pre> Caracter\u00edsticas Clave:    - CTEs y Pivotes: Agrupa tiempos de gesti\u00f3n por \u00e1rea usando <code>PIVOT</code>.    - Uniones Estratificadas: Combina m\u00e9tricas de diferentes procesos acad\u00e9micos mediante <code>UNION ALL</code>.    - Conversi\u00f3n de Fechas: Transforma <code>ID_FECHA</code> en fechas mensuales para an\u00e1lisis temporal.  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_15","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: <code>Consulta Matriculas</code> </p> <ul> <li>Descripci\u00f3n: Extrae y transforma datos con una consulta SQL compleja que incluye CTEs y uniones.  </li> <li>Propiedades:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de Espera: 30 segundos.  </li> <li>Columnas Destacadas:  </li> <li><code>BP</code> (ID estudiante/empresa), <code>ACTIVIDAD</code> (tipo de gesti\u00f3n), <code>TIEMPO_SEGUNDOS</code> (duraci\u00f3n del proceso).  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET: <code>FACT_MINERIA</code> </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla de miner\u00eda de datos.  </li> <li>Propiedades:  <ul> <li>Tabla Destino: <code>\"Transversal\".\"FACT_MINERIA\"</code>.  </li> <li>Inserci\u00f3n Masiva: Habilitada (<code>UseBulkInsertWhenPossible = true</code>).  </li> <li>Tama\u00f1o de Lote: 0 (usa configuraci\u00f3n predeterminada).  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_16","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET (Consulta Matriculas)\n    participant Destino as Destino ADO NET (FACT_MINERIA)\n    Origen -&gt;&gt; Destino: Extrae y transforma datos\n    Destino --&gt;&gt; Origen: Confirmaci\u00f3n de carga</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-pagos-matriculas","title":"Componente <code>Pagos Matriculas</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_17","title":"Descripci\u00f3n General","text":"<p>El componente <code>Pagos Matriculas</code> es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS <code>FACT_MINERIA</code>. Su objetivo principal es procesar y cargar datos relacionados con los pagos de matr\u00edculas en el sistema <code>DWH_COMFENALCO</code>. Este flujo extrae informaci\u00f3n de las tablas de facturaci\u00f3n y matr\u00edculas, realiza transformaciones y la carga en la tabla <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#proposito_7","title":"Prop\u00f3sito","text":"<ol> <li>Objetivo Primario:  <ul> <li>Consolidar y transformar datos de pagos de matr\u00edculas y subsidios para su an\u00e1lisis en el Data Warehouse.  </li> </ul> </li> <li>Beneficios Clave:  <ul> <li>Proporciona una visi\u00f3n detallada de los pagos de matr\u00edculas, incluyendo estados (pagado, anulado, sin pago) y subsidios.  </li> <li>Facilita el seguimiento de las actividades relacionadas con los pagos de matr\u00edculas.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_7","title":"Tablas Afectadas","text":"<ol> <li>[DWH_COMFENALCO].[Colegio].[FACT_FACTURACION_MATRICULAS]:  <ul> <li>Tabla de origen que contiene los registros de facturaci\u00f3n de matr\u00edculas.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS]:  <ul> <li>Tabla de origen que almacena informaci\u00f3n sobre las inscripciones de matr\u00edculas.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]:  <ul> <li>Tabla destino donde se cargan los datos procesados.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_7","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada: <pre><code>WITH Facturacion AS(\n    SELECT --DISTINCT\n        --i.ID,\n        i.BP,\n        --i.FECHA_CONTABLE,\n        CONVERT(INT, CAST(CASE \n            WHEN MONTH(i.FECHA_CONTABLE) &amp;gt;= 10 THEN YEAR(i.FECHA_CONTABLE) + 1\n            ELSE YEAR(i.FECHA_CONTABLE)\n        END AS VARCHAR) + '0101') AS ID_FECHA_MENSUAL,\n        CASE \n            WHEN MONTH(i.FECHA_CONTABLE) &amp;gt;= 10 THEN YEAR(i.FECHA_CONTABLE) + 1\n            ELSE YEAR(i.FECHA_CONTABLE)\n        END AS ID_ANIO_ACADEMICO,\n        1 AS ID_UNIDAD,\n        CAST(CONVERT(varchar, i.FECHA_CONTABLE) AS datetime) AS FECHA_INICIAL,\n        CAST(CONVERT(varchar, i.FECHA_CONTABLE) AS datetime) AS FECHA_FINAL,\n        CASE\n            WHEN e.DESC_CONCEPTO = 'MATRICULA' AND i.ESTADO_PAGO = 'ANULADO' THEN 'Pago Matr\u00edcula Anulado'\n            WHEN e.DESC_CONCEPTO = 'MATRICULA' AND i.ESTADO_PAGO = 'PAGADO' THEN 'Pago Matr\u00edcula'\n            WHEN e.DESC_CONCEPTO = 'MATRICULA' AND i.ESTADO_PAGO = 'SIN PAGO' THEN 'Sin Pago Matr\u00edcula'\n            WHEN e.DESC_CONCEPTO = 'SUBSIDIO MATRICULA' AND i.ESTADO_PAGO = 'ANULADO' THEN 'Pago Matr\u00edcula Subsidio Anulado'\n            WHEN e.DESC_CONCEPTO = 'SUBSIDIO MATRICULA' AND i.ESTADO_PAGO = 'PAGADO' THEN 'Pago Matr\u00edcula Subsidio'\n            WHEN e.DESC_CONCEPTO = 'SUBSIDIO MATRICULA' AND i.ESTADO_PAGO = 'SIN PAGO' THEN 'Sin Pago Matr\u00edcula Subsidio'\n            ELSE 'Sin Identificar'\n        END AS ACTIVIDAD,\n        0 AS TIEMPO_SEGUNDOS,\n        i.VALOR_PAGADO\n        --i.ESTADO_PAGO,\n        --e.DESC_CONCEPTO\n    FROM\n        DWH_COMFENALCO.Colegio.FACT_FACTURACION_MATRICULAS i\n    INNER JOIN DWH_COMFENALCO.Colegio.FACT_INSCRIPCION_MATRICULAS f ON i.ID = f.ID\n    INNER JOIN DWH_COMFENALCO.Colegio.DIM_CONCEPTO_FACT e ON i.ID_CONCEPTO = e.ID_CONCEPTO\n    WHERE e.DESC_CONCEPTO NOT IN ('BIBLIOBANCO')\n),\nUniqueRows AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA_FAMILIAR] AS ID_CATEGORIA,\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE],\n        ROW_NUMBER() OVER (PARTITION BY [BP], [ANIO_ACADEMICO] ORDER BY [ID] DESC) AS RowNum\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS]\n),\nInscripcion_Matriculas AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA],\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE]\n    FROM UniqueRows\n    WHERE RowNum = 1\n)\n\nSELECT f.*\n       ,ISNULL(im.ID_CATEGORIA,4) AS ID_CATEGORIA,\n       ISNULL(im.ID_CURSO,-1) AS ID_CURSO,\n       ISNULL(im.ID_TIPO_ESTUDIANTE,-1) AS ID_TIPO_ESTUDIANTE\nFROM Facturacion f\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = f.[ID_FECHA_MENSUAL]\nLEFT JOIN Inscripcion_Matriculas im on im.[BP] = f.[BP] AND im.[ANIO_ACADEMICO] = f.[ID_ANIO_ACADEMICO]\n</code></pre></p> <p>Caracter\u00edsticas del C\u00f3digo:    - CTEs: Se utilizan Common Table Expressions (CTEs) para organizar y filtrar los datos de manera eficiente.    - Transformaciones: Se aplican l\u00f3gicas condicionales para clasificar los pagos de matr\u00edculas y subsidios.    - Uniones: Se combinan datos de facturaci\u00f3n con inscripciones para enriquecer la informaci\u00f3n.  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_16","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: <code>Consulta Pagos</code> </p> <ul> <li>Descripci\u00f3n: Extrae datos de las tablas de facturaci\u00f3n y matr\u00edculas utilizando la consulta SQL anterior.  </li> <li>Propiedades:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: <code>30</code> segundos.  </li> <li>Columnas principales:  </li> <li><code>BP</code>: Identificador del beneficiario.  </li> <li><code>ID_FECHA_MENSUAL</code>: Fecha mensual procesada.  </li> <li><code>ACTIVIDAD</code>: Tipo de actividad (pago, anulaci\u00f3n, etc.).  </li> <li><code>VALOR_PAGADO</code>: Monto pagado.  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET: <code>FACT_MINERIA</code> </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>Transversal.FACT_MINERIA</code>.  </li> <li>Propiedades:  <ul> <li>Tabla: <code>\"Transversal\".\"FACT_MINERIA\"</code>.  </li> <li>Inserci\u00f3n masiva: Habilitada.  </li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o predeterminado del b\u00fafer).  </li> <li>Columnas principales:  </li> <li><code>BP</code>, <code>ID_FECHA_MENSUAL</code>, <code>ACTIVIDAD</code>, <code>VALOR_PAGADO</code>.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_17","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET (Consulta Pagos)\n    participant Destino as Destino ADO NET (FACT_MINERIA)\n    Origen-&gt;&gt;Destino: Extrae y transforma datos\n    Destino-&gt;&gt;Destino: Carga datos en FACT_MINERIA</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-pqrs-colegio","title":"Componente <code>PQRs Colegio</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_18","title":"Descripci\u00f3n General","text":"<p>El componente <code>PQRs Colegio</code> es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS <code>FACT_MINERIA</code>. Su objetivo principal es procesar y cargar datos relacionados con las PQR (Peticiones, Quejas y Reclamos) asociadas a los acudientes de estudiantes en el sistema <code>DWH_COMFENALCO</code>. Este flujo extrae informaci\u00f3n de las tablas de PQR y matr\u00edculas, realiza transformaciones y la carga en la tabla <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#proposito_8","title":"Prop\u00f3sito","text":"<ol> <li>Objetivo Primario:  <ul> <li>Consolidar y transformar datos de PQR asociadas a acudientes de estudiantes para su an\u00e1lisis en el Data Warehouse.  </li> </ul> </li> <li>Beneficios Clave:  <ul> <li>Proporciona una visi\u00f3n detallada de las PQR, incluyendo fechas de creaci\u00f3n y resoluci\u00f3n, tiempo de resoluci\u00f3n y actividades relacionadas.  </li> <li>Facilita el seguimiento de las actividades relacionadas con las PQR en el contexto educativo.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_8","title":"Tablas Afectadas","text":"<ol> <li>[DWH_COMFENALCO].[Transversal].[FACT_PQRS]:  <ul> <li>Tabla de origen que contiene los registros de PQR.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Colegio].[DIM_ACUDIENTES]:  <ul> <li>Tabla de origen que almacena informaci\u00f3n sobre los acudientes de los estudiantes.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]:  <ul> <li>Tabla destino donde se cargan los datos procesados.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_8","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada: <pre><code>WITH PQRS_ACUDIENTES AS (\n    SELECT \n        ac.[BP_ESTUDIANTE] as BP,\n        CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n        CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n        [ID_UNIDAD],\n        [FECHA_CREACION] AS FECHA_INICIAL,\n        [FECHA_RESOLUCION] AS FECHA_FINAL,\n        CONCAT('PQR ', LOWER([CAUSA])) AS ACTIVIDAD,\n        DATEDIFF(SECOND, [FECHA_CREACION], [FECHA_RESOLUCION]) AS TIEMPO_SEGUNDOS,\n        0 AS VALOR_PAGADO\n    FROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] f\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n        ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01')\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n        ON f.[ID_AFILIADO] = a.[ID_AFILIADO]\n    INNER JOIN [DWH_COMFENALCO].[Colegio].[DIM_ACUDIENTES] ac \n        ON ac.[BP_ACUDIENTE] = a.[PARTNER]\n    WHERE f.ID_AFILIADO != -1 AND ID_UNIDAD = 1\n),\nUniqueRows AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA_FAMILIAR] AS ID_CATEGORIA,\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE],\n        ROW_NUMBER() OVER (PARTITION BY [BP], [ANIO_ACADEMICO] ORDER BY [ID] DESC) AS RowNum\n    FROM [DWH_COMFENALCO].[Colegio].[FACT_INSCRIPCION_MATRICULAS]\n),\nInscripcion_Matriculas AS (\n    SELECT \n        [BP],\n        [ANIO_ACADEMICO],\n        [ID_CATEGORIA],\n        [ID_CURSO],\n        [ID_TIPO_ESTUDIANTE]\n    FROM UniqueRows\n    WHERE RowNum = 1\n)\nSELECT pa.*,\n       ISNULL(im.ID_CATEGORIA, 4) AS ID_CATEGORIA,\n       ISNULL(im.ID_CURSO, -1) AS ID_CURSO,\n       ISNULL(im.ID_TIPO_ESTUDIANTE, -1) AS ID_TIPO_ESTUDIANTE\nFROM PQRS_ACUDIENTES pa\nLEFT JOIN Inscripcion_Matriculas im \n    ON im.[BP] = pa.[BP] AND im.[ANIO_ACADEMICO] = pa.[ID_ANIO_ACADEMICO]\n</code></pre> Caracter\u00edsticas del C\u00f3digo: - CTEs: Se utilizan Common Table Expressions (CTEs) para organizar y filtrar los datos de manera eficiente. - Transformaciones: Se aplican l\u00f3gicas condicionales para clasificar las PQR y calcular el tiempo de resoluci\u00f3n. - Uniones: Se combinan datos de PQR con inscripciones para enriquecer la informaci\u00f3n.  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_17","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: <code>Consulta PQRs</code> </p> <ul> <li>Descripci\u00f3n: Extrae datos de las tablas de PQR y acudientes utilizando la consulta SQL anterior.  </li> <li>Propiedades:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: <code>30</code> segundos.  </li> <li>Columnas principales:  </li> <li><code>BP</code>: Identificador del beneficiario.  </li> <li><code>ID_FECHA_MENSUAL</code>: Fecha mensual procesada.  </li> <li><code>ACTIVIDAD</code>: Tipo de actividad (PQR).  </li> <li><code>TIEMPO_SEGUNDOS</code>: Tiempo de resoluci\u00f3n en segundos.  </li> </ul> </li> </ul> </li> <li> <p>Lookup: <code>Lookup</code> </p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>Transversal.FACT_MINERIA</code> para evitar duplicados.  </li> <li>Propiedades:  <ul> <li>Consulta SQL: <code>SELECT * FROM [Transversal].[FACT_MINERIA]</code>.  </li> <li>Columnas de b\u00fasqueda: <code>BP</code>.  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET: <code>FACT_MINERIA</code> </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>Transversal.FACT_MINERIA</code>.  </li> <li>Propiedades:  <ul> <li>Tabla: <code>\"Transversal\".\"FACT_MINERIA\"</code>.  </li> <li>Inserci\u00f3n masiva: Habilitada.  </li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o predeterminado del b\u00fafer).  </li> <li>Columnas principales:  </li> <li><code>BP</code>, <code>ID_FECHA_MENSUAL</code>, <code>ACTIVIDAD</code>, <code>TIEMPO_SEGUNDOS</code>.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_18","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET (Consulta PQRs)\n    participant Lookup as Lookup (FACT_MINERIA)\n    participant Destino as Destino ADO NET (FACT_MINERIA)\n    Origen-&gt;&gt;Lookup: Extrae y transforma datos\n    Lookup-&gt;&gt;Destino: Carga datos en FACT_MINERIA</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-inscripcion","title":"Componente <code>Inscripcion</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_19","title":"Descripci\u00f3n General","text":"<p>El componente <code>Inscripcion</code> es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS <code>FACT_MINERIA</code>. Su objetivo principal es procesar y cargar datos relacionados con las inscripciones de estudiantes en programas de educaci\u00f3n t\u00e9cnica y continua. Este flujo extrae informaci\u00f3n de las tablas de inscripciones, realiza transformaciones y la carga en la tabla <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#proposito_9","title":"Prop\u00f3sito","text":"<ol> <li>Objetivo Primario:  <ul> <li>Consolidar y transformar datos de inscripciones de estudiantes para su an\u00e1lisis en el Data Warehouse.  </li> </ul> </li> <li>Beneficios Clave:  <ul> <li>Proporciona una visi\u00f3n detallada de las inscripciones, incluyendo estados (inscrito, no inscrito) y categor\u00edas de estudiantes.  </li> <li>Facilita el seguimiento de las actividades relacionadas con las inscripciones en programas educativos.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_9","title":"Tablas Afectadas","text":"<ol> <li>[DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS]:  <ul> <li>Tabla de origen que contiene los registros de inscripciones de estudiantes.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES]:  <ul> <li>Tabla de origen que almacena informaci\u00f3n sobre los estudiantes.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]:  <ul> <li>Tabla destino donde se cargan los datos procesados.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_9","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada: <pre><code>-- Afiliados\nSELECT \n      a.[PARTNER] as BP\n      ,CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(im.[FECHA]) AS ID_ANIO_ACADEMICO\n      --,im.[ID_ESTUDIANTE]\n      ,j.[ID_UNIDAD]\n      ,im.[FECHA] AS FECHA_INICIAL\n      ,im.[FECHA] AS FECHA_FINAL\n      ,CASE\n            WHEN im.[ESTADO] = 'INSCRITO' THEN 'Estudiante Inscrito'\n            WHEN im.[ESTADO] = 'NO INSCRITO' THEN 'Estudiante con Proceso Desistido'\n            ELSE 'Sin Identificar'\n        END AS ACTIVIDAD\n      ,0 AS TIEMPO_SEGUNDOS\n      ,0 AS VALOR_PAGADO\n      ,a.[ID_CATEGORIA]\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,im.[ID_PROGRAMA]\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] im\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on im.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a on e.[ID_AFILIADO] = a.[ID_AFILIADO]\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on im.[ID_JORNADA] = j.[ID_JORNADA]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)\n WHERE e.ID_AFILIADO != -1\n\n UNION ALL\n\n  -- Beneficiarios\nSELECT \n      b.[PARTNER] as BP\n      ,CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(im.[FECHA]) AS ID_ANIO_ACADEMICO\n      --,im.[ID_ESTUDIANTE]\n      ,j.[ID_UNIDAD]\n      ,im.[FECHA] AS FECHA_INICIAL\n      ,im.[FECHA] AS FECHA_FINAL\n      ,CASE\n            WHEN im.[ESTADO] = 'INSCRITO' THEN 'Estudiante Inscrito'\n            WHEN im.[ESTADO] = 'NO INSCRITO' THEN 'Estudiante con Proceso Desistido'\n            ELSE 'Sin Identificar'\n        END AS ACTIVIDAD\n      ,0 AS TIEMPO_SEGUNDOS\n      ,0 AS VALOR_PAGADO\n      ,ISNULL(a.[ID_CATEGORIA],4) AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,im.[ID_PROGRAMA]\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] im\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on im.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b on e.[ID_BENEFICIARIO] =  b.[ID_BENEFICIARIO]\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on im.[ID_JORNADA] = j.[ID_JORNADA]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)\n LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a on b.[ID_AFILIADO] = a.[ID_AFILIADO]\n WHERE e.ID_BENEFICIARIO != -1\n\n UNION ALL\n  -- Empresas\nSELECT \n      em.[PARTNER] as BP\n      ,CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(im.[FECHA]) AS ID_ANIO_ACADEMICO\n      --,im.[ID_ESTUDIANTE]\n      ,j.[ID_UNIDAD]\n      ,im.[FECHA] AS FECHA_INICIAL\n      ,im.[FECHA] AS FECHA_FINAL\n      ,CASE\n            WHEN im.[ESTADO] = 'INSCRITO' THEN 'Estudiante Inscrito'\n            WHEN im.[ESTADO] = 'NO INSCRITO' THEN 'Estudiante con Proceso Desistido'\n            ELSE 'Sin Identificar'\n        END AS ACTIVIDAD\n      ,0 AS TIEMPO_SEGUNDOS\n      ,0 AS VALOR_PAGADO\n      ,5 AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,im.[ID_PROGRAMA]\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] im\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on im.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] em on e.[ID_EMPRESA] =  em.[ID_EMPRESA]\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on im.[ID_JORNADA] = j.[ID_JORNADA]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)\n WHERE e.ID_EMPRESA != -1\n\n UNION ALL\n\n  -- No aportante\nSELECT \n      '0000000000' as BP\n      ,CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(im.[FECHA]) AS ID_ANIO_ACADEMICO\n      --,im.[ID_ESTUDIANTE]\n      ,j.[ID_UNIDAD]\n      ,im.[FECHA] AS FECHA_INICIAL\n      ,im.[FECHA] AS FECHA_FINAL\n      ,CASE\n            WHEN im.[ESTADO] = 'INSCRITO' THEN 'Estudiante Inscrito'\n            WHEN im.[ESTADO] = 'NO INSCRITO' THEN 'Estudiante con Proceso Desistido'\n            ELSE 'Sin Identificar'\n        END AS ACTIVIDAD\n      ,0 AS TIEMPO_SEGUNDOS\n      ,0 AS VALOR_PAGADO\n      ,CASE\n            WHEN e.[TIPO_DOCUMENTO] = 'NI' THEN 12\n            ELSE 4\n        END AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,im.[ID_PROGRAMA]\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_INSCRIPCION_MATRICULAS] im\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on im.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\n --INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_APORTANTE_NOAFILIADO] em on e.[ID_EMPRESA] =  em.[ID_EMPRESA]\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on im.[ID_JORNADA] = j.[ID_JORNADA]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(im.[FECHA], 'yyyyMM01') AS INT)\n WHERE ID_AFILIADO + ID_EMPRESA+ ID_BENEFICIARIO  = -3\n</code></pre></p> <p>Caracter\u00edsticas del C\u00f3digo:    - Uniones: Combina datos de afiliados, beneficiarios, empresas y no aportantes.    - Transformaciones: Clasifica los estados de inscripci\u00f3n y asigna categor\u00edas seg\u00fan el tipo de estudiante.    - Filtros: Excluye registros no v\u00e1lidos o sin informaci\u00f3n relevante.  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_18","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: <code>Consulta Inscripcion</code> </p> <ul> <li>Descripci\u00f3n: Extrae datos de las tablas de inscripciones utilizando la consulta SQL anterior.  </li> <li>Propiedades:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: <code>30</code> segundos.  </li> <li>Columnas principales:  </li> <li><code>BP</code>: Identificador del beneficiario.  </li> <li><code>ID_FECHA_MENSUAL</code>: Fecha mensual procesada.  </li> <li><code>ACTIVIDAD</code>: Tipo de actividad (inscrito, no inscrito).  </li> <li><code>ID_CATEGORIA</code>: Categor\u00eda del estudiante.  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET: <code>Destino de ADO NET</code> </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>Transversal.FACT_MINERIA</code>.  </li> <li>Propiedades:  <ul> <li>Tabla: <code>\"Transversal\".\"FACT_MINERIA\"</code>.  </li> <li>Inserci\u00f3n masiva: Habilitada.  </li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o predeterminado del b\u00fafer).  </li> <li>Columnas principales:  </li> <li><code>BP</code>, <code>ID_FECHA_MENSUAL</code>, <code>ACTIVIDAD</code>, <code>ID_CATEGORIA</code>.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_19","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET (Consulta Inscripcion)\n    participant Destino as Destino ADO NET (FACT_MINERIA)\n    Origen-&gt;&gt;Destino: Extrae y transforma datos\n    Destino-&gt;&gt;Destino: Carga datos en FACT_MINERIA</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-admision","title":"Componente <code>Admision</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_20","title":"Descripci\u00f3n General","text":"<p>El componente <code>Admision</code> es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS <code>FACT_MINERIA</code>. Su objetivo principal es procesar y cargar datos relacionados con las admisiones de estudiantes en el sistema <code>DWH_COMFENALCO</code>. Este flujo extrae informaci\u00f3n de las tablas de estado de matr\u00edculas, estudiantes y afiliados, realiza transformaciones y la carga en la tabla <code>Transversal.FACT_MINERIA</code>.</p>"},{"location":"03.Cubo/03.ETL/#proposito_10","title":"Prop\u00f3sito","text":"<ol> <li>Objetivo Primario:  <ul> <li>Consolidar y transformar datos de admisiones de estudiantes para su an\u00e1lisis en el Data Warehouse.  </li> </ul> </li> <li>Beneficios Clave:  <ul> <li>Proporciona una visi\u00f3n detallada de las admisiones de estudiantes, incluyendo categor\u00edas como \"Estudiante Admitido Nuevo\" y \"Estudiante Admitido Antiguo\".  </li> <li>Facilita el seguimiento de las actividades relacionadas con las admisiones.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_10","title":"Tablas Afectadas","text":"<ol> <li>[DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS]:  <ul> <li>Tabla de origen que contiene los registros de estado de matr\u00edculas.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES]:  <ul> <li>Tabla de origen que almacena informaci\u00f3n sobre los estudiantes.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS]:  <ul> <li>Tabla de origen que contiene datos de afiliados.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]:  <ul> <li>Tabla destino donde se cargan los datos procesados.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_10","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada: <pre><code>-- Afiliados\nSELECT \n      a.[PARTNER] as BP\n      ,CAST(FORMAT(fm.[FECHA_MATRICULA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(fm.[FECHA_MATRICULA]) AS ID_ANIO_ACADEMICO\n      ,j.[ID_UNIDAD]\n      ,fm.[FECHA_MATRICULA] AS FECHA_INICIAL\n      ,fm.[FECHA_MATRICULA] AS FECHA_FINAL\n      ,CASE\n            WHEN fm.[SEMESTRE] = '\u00danico' or fm.[SEMESTRE] = '1'  THEN 'Estudiante Admitido Nuevo'\n            ELSE 'Estudiante Admitido Antiguo'\n        END AS ACTIVIDAD\n      , 0 AS TIEMPO_SEGUNDOS\n      ,0 AS VALOR_PAGADO\n      ,ISNULL(a.[ID_CATEGORIA],4) AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,fm.[ID_PROGRAMA]\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS] fm\n  INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on fm.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a on e.[ID_AFILIADO] = a.[ID_AFILIADO]\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on fm.[ID_JORNADA] = j.[ID_JORNADA]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(fm.[FECHA_MATRICULA], 'yyyyMM01') AS INT)\n WHERE e.ID_AFILIADO != -1\n\n UNION ALL\n  -- Beneficiarios\nSELECT \n      b.[PARTNER] as BP\n      ,CAST(FORMAT(fm.[FECHA_MATRICULA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(fm.[FECHA_MATRICULA]) AS ID_ANIO_ACADEMICO\n      ,j.[ID_UNIDAD]\n      ,fm.[FECHA_MATRICULA] AS FECHA_INICIAL\n      ,fm.[FECHA_MATRICULA] AS FECHA_FINAL\n      ,CASE\n            WHEN fm.[SEMESTRE] = '\u00danico' or fm.[SEMESTRE] = '1'  THEN 'Estudiante Admitido Nuevo'\n            ELSE 'Estudiante Admitido Antiguo'\n        END AS ACTIVIDAD\n      , 0 AS TIEMPO_SEGUNDOS\n      ,0 AS VALOR_PAGADO\n      ,ISNULL(a.[ID_CATEGORIA],4) AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,fm.[ID_PROGRAMA]\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS] fm\n  INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on fm.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b on e.[ID_BENEFICIARIO] =  b.[ID_BENEFICIARIO]\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on fm.[ID_JORNADA] = j.[ID_JORNADA]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(fm.[FECHA_MATRICULA], 'yyyyMM01') AS INT)\n LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a on b.[ID_AFILIADO] = a.[ID_AFILIADO]\n WHERE e.ID_BENEFICIARIO != -1\n\n UNION ALL\n   -- Empresas\nSELECT \n      em.[PARTNER] as BP\n      ,CAST(FORMAT(fm.[FECHA_MATRICULA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(fm.[FECHA_MATRICULA]) AS ID_ANIO_ACADEMICO\n      ,j.[ID_UNIDAD]\n      ,fm.[FECHA_MATRICULA] AS FECHA_INICIAL\n      ,fm.[FECHA_MATRICULA] AS FECHA_FINAL\n      ,CASE\n            WHEN fm.[SEMESTRE] = '\u00danico' or fm.[SEMESTRE] = '1'  THEN 'Estudiante Admitido Nuevo'\n            ELSE 'Estudiante Admitido Antiguo'\n        END AS ACTIVIDAD\n      , 0 AS TIEMPO_SEGUNDOS\n      ,0 AS VALOR_PAGADO\n      ,5 AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,fm.[ID_PROGRAMA]\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS] fm\n  INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on fm.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] em on e.[ID_EMPRESA] =  em.[ID_EMPRESA]\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on fm.[ID_JORNADA] = j.[ID_JORNADA]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(fm.[FECHA_MATRICULA], 'yyyyMM01') AS INT)\n  WHERE e.ID_EMPRESA != -1\n\n  UNION ALL\n\n  -- No aportante\nSELECT \n      '0000000000' as BP\n      ,CAST(FORMAT(fm.[FECHA_MATRICULA], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL\n      ,YEAR(fm.[FECHA_MATRICULA]) AS ID_ANIO_ACADEMICO\n      ,j.[ID_UNIDAD]\n      ,fm.[FECHA_MATRICULA] AS FECHA_INICIAL\n      ,fm.[FECHA_MATRICULA] AS FECHA_FINAL\n      ,CASE\n            WHEN fm.[SEMESTRE] = '\u00danico' or fm.[SEMESTRE] = '1'  THEN 'Estudiante Admitido Nuevo'\n            ELSE 'Estudiante Admitido Antiguo'\n        END AS ACTIVIDAD\n      , 0 AS TIEMPO_SEGUNDOS\n      ,0 AS VALOR_PAGADO\n      ,CASE\n            WHEN e.[TIPO_DOCUMENTO] = 'NI' THEN 12\n            ELSE 4\n        END AS ID_CATEGORIA\n      --,im.[ID_PERIODO]\n      ,-1 AS ID_CURSO\n      ,-1 AS ID_TIPO_ESTUDIANTE\n      ,fm.[ID_PROGRAMA]\n  FROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_ESTADO_MATRICULAS] fm\n  INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on fm.[ID_ESTUDIANTE] = e.[ID_ESTUDIANTE]\n INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_JORNADA] j on fm.[ID_JORNADA] = j.[ID_JORNADA]\n INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(fm.[FECHA_MATRICULA], 'yyyyMM01') AS INT)\n WHERE ID_AFILIADO + ID_EMPRESA+ ID_BENEFICIARIO  = -3\n</code></pre> Caracter\u00edsticas del C\u00f3digo:    - Uniones: Combina datos de afiliados, beneficiarios, empresas y no aportantes.    - Transformaciones: Clasifica a los estudiantes en \"Estudiante Admitido Nuevo\" o \"Estudiante Admitido Antiguo\" seg\u00fan el semestre.    - Filtros: Excluye registros no v\u00e1lidos o duplicados.  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_19","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET: <code>Origen de ADO NET</code> </p> <ul> <li>Descripci\u00f3n: Extrae datos de las tablas de estado de matr\u00edculas, estudiantes y afiliados utilizando la consulta SQL anterior.  </li> <li>Propiedades:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: <code>30</code> segundos.  </li> <li>Columnas principales:  </li> <li><code>BP</code>: Identificador del beneficiario.  </li> <li><code>ID_FECHA_MENSUAL</code>: Fecha mensual procesada.  </li> <li><code>ACTIVIDAD</code>: Tipo de actividad (Estudiante Admitido Nuevo o Antiguo).  </li> <li><code>ID_PROGRAMA</code>: Identificador del programa acad\u00e9mico.  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET: <code>Destino de ADO NET</code> </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>Transversal.FACT_MINERIA</code>.  </li> <li>Propiedades:  <ul> <li>Tabla: <code>\"Transversal\".\"FACT_MINERIA\"</code>.  </li> <li>Inserci\u00f3n masiva: Habilitada.  </li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o predeterminado del b\u00fafer).  </li> <li>Columnas principales:  </li> <li><code>BP</code>, <code>ID_FECHA_MENSUAL</code>, <code>ACTIVIDAD</code>, <code>ID_PROGRAMA</code>.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_20","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET (Consulta SQL)\n    participant Destino as Destino ADO NET (FACT_MINERIA)\n    Origen-&gt;&gt;Destino: Extrae y transforma datos\n    Destino-&gt;&gt;Destino: Carga datos en FACT_MINERIA</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-pago","title":"Componente <code>Pago</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_21","title":"Descripci\u00f3n General","text":"<p>El componente <code>Pago</code> es un Data Flow Task dentro del paquete SSIS <code>FACT_MINERIA</code>. Su funci\u00f3n principal es extraer, transformar y cargar datos relacionados con pagos de matr\u00edculas de estudiantes en la tabla <code>Transversal.FACT_MINERIA</code>. Este flujo de datos procesa informaci\u00f3n de diferentes tipos de estudiantes (afiliados, beneficiarios, empresas y no aportantes) y consolida los datos en un formato estructurado para su an\u00e1lisis posterior.</p>"},{"location":"03.Cubo/03.ETL/#proposito_11","title":"Prop\u00f3sito","text":"<ol> <li>Objetivo Primario:  <ul> <li>Consolidar los registros de pagos de matr\u00edculas realizados por estudiantes en la tabla <code>FACT_MINERIA</code> para su an\u00e1lisis en el Data Warehouse.  </li> </ul> </li> <li>Beneficios Clave:  <ul> <li>Proporciona una visi\u00f3n unificada de los pagos realizados por diferentes tipos de estudiantes.  </li> <li>Facilita el seguimiento de transacciones financieras relacionadas con la educaci\u00f3n t\u00e9cnica y continua.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_11","title":"Tablas Afectadas","text":"<ol> <li>[DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION]:  <ul> <li>Tabla de origen que contiene los registros de facturaci\u00f3n y pagos realizados por estudiantes.  </li> </ul> </li> <li>[DWH_COMFENALCO].[Transversal].[FACT_MINERIA]:  <ul> <li>Tabla de destino donde se cargan los datos consolidados de pagos de matr\u00edculas.  </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_11","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada: <pre><code>-- Afiliados\nSELECT distinct a.[PARTNER] as BP --,ff.[TIPO_DOCUMENTO_PAGO]\n    --,ff.[DOCUMENTO_PAGO]\n,\n    CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL,\n    YEAR(ff.[FECHA_CONTABLE]) AS ID_ANIO_ACADEMICO,\nCASE\n        WHEN LEN(NO_RECIBO) &amp; lt;\n6 THEN 2\nELSE 3\nEND AS ID_UNIDAD,\nff.[FECHA_CONTABLE] AS FECHA_INICIAL,\nff.[FECHA_CONTABLE] AS FECHA_FINAL,\n'Pago Matr\u00edcula' AS ACTIVIDAD,\n0 AS TIEMPO_SEGUNDOS --,ff.[CONCEPTO]\n,\nff.[VALOR_PAGADO],\nISNULL(a.[ID_CATEGORIA], 4) AS ID_CATEGORIA --,im.[ID_PERIODO]\n,\n-1 AS ID_CURSO,\n-1 AS ID_TIPO_ESTUDIANTE,\n-1 AS ID_PROGRAMA\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n    INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on ff.[TIPO_DOCUMENTO_PAGO] = e.[TIPO_DOCUMENTO]\n    and ff.[DOCUMENTO_PAGO] = e.[DOCUMENTO]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a on e.[ID_AFILIADO] = a.[ID_AFILIADO]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT)\nWHERE [CONCEPTO] NOT LIKE '%CERTIFICADO%'\n    AND [CONCEPTO] NOT LIKE '%DERECHO GRADO%'\n    AND e.ID_AFILIADO != -1\nUNION ALL\n-- Beneficiarios\nSELECT distinct b.[PARTNER] as BP --,ff.[TIPO_DOCUMENTO_PAGO]\n    --,ff.[DOCUMENTO_PAGO]\n,\n    CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL,\n    YEAR(ff.[FECHA_CONTABLE]) AS ID_ANIO_ACADEMICO,\nCASE\n        WHEN LEN(NO_RECIBO) &amp; lt;\n6 THEN 2\nELSE 3\nEND AS ID_UNIDAD,\nff.[FECHA_CONTABLE] AS FECHA_INICIAL,\nff.[FECHA_CONTABLE] AS FECHA_FINAL,\n'Pago Matr\u00edcula' AS ACTIVIDAD,\n0 AS TIEMPO_SEGUNDOS --,ff.[CONCEPTO]\n,\nff.[VALOR_PAGADO],\nISNULL(a.[ID_CATEGORIA], 4) AS ID_CATEGORIA --,im.[ID_PERIODO]\n,\n-1 AS ID_CURSO,\n-1 AS ID_TIPO_ESTUDIANTE,\n-1 AS ID_PROGRAMA\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n    INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on ff.[TIPO_DOCUMENTO_PAGO] = e.[TIPO_DOCUMENTO]\n    and ff.[DOCUMENTO_PAGO] = e.[DOCUMENTO]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b on e.[ID_BENEFICIARIO] = b.[ID_BENEFICIARIO]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT)\n    LEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a on b.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE [CONCEPTO] NOT LIKE '%CERTIFICADO%'\n    AND [CONCEPTO] NOT LIKE '%DERECHO GRADO%'\n    AND e.ID_BENEFICIARIO != -1\nUNION ALL\n-- Empresas\nSELECT distinct em.[PARTNER] as BP --,ff.[TIPO_DOCUMENTO_PAGO]\n    --,ff.[DOCUMENTO_PAGO]\n,\n    CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL,\n    YEAR(ff.[FECHA_CONTABLE]) AS ID_ANIO_ACADEMICO,\nCASE\n        WHEN LEN(NO_RECIBO) &amp; lt;\n6 THEN 2\nELSE 3\nEND AS ID_UNIDAD,\nff.[FECHA_CONTABLE] AS FECHA_INICIAL,\nff.[FECHA_CONTABLE] AS FECHA_FINAL,\n'Pago Matr\u00edcula' AS ACTIVIDAD,\n0 AS TIEMPO_SEGUNDOS --,ff.[CONCEPTO]\n,\nff.[VALOR_PAGADO],\n5 AS ID_CATEGORIA --,im.[ID_PERIODO]\n,\n-1 AS ID_CURSO,\n-1 AS ID_TIPO_ESTUDIANTE,\n-1 AS ID_PROGRAMA\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n    INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on ff.[TIPO_DOCUMENTO_PAGO] = e.[TIPO_DOCUMENTO]\n    and ff.[DOCUMENTO_PAGO] = e.[DOCUMENTO]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] em on e.[ID_EMPRESA] = em.[ID_EMPRESA]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT)\nWHERE [CONCEPTO] NOT LIKE '%CERTIFICADO%'\n    AND [CONCEPTO] NOT LIKE '%DERECHO GRADO%'\n    AND e.ID_EMPRESA != -1\nUNION ALL\n-- No aportante\nSELECT distinct '0000000000' as BP --,ff.[TIPO_DOCUMENTO_PAGO]\n    --,ff.[DOCUMENTO_PAGO]\n,\n    CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT) AS ID_FECHA_MENSUAL,\n    YEAR(ff.[FECHA_CONTABLE]) AS ID_ANIO_ACADEMICO,\nCASE\n        WHEN LEN(NO_RECIBO) &amp; lt;\n6 THEN 2\nELSE 3\nEND AS ID_UNIDAD,\nff.[FECHA_CONTABLE] AS FECHA_INICIAL,\nff.[FECHA_CONTABLE] AS FECHA_FINAL,\n'Pago Matr\u00edcula' AS ACTIVIDAD,\n0 AS TIEMPO_SEGUNDOS --,ff.[CONCEPTO]\n,\nff.[VALOR_PAGADO],\nCASE\n    WHEN e.[TIPO_DOCUMENTO] = 'NI' THEN 12\n    ELSE 4\nEND AS ID_CATEGORIA --,im.[ID_PERIODO]\n,\n-1 AS ID_CURSO,\n-1 AS ID_TIPO_ESTUDIANTE,\n-1 AS ID_PROGRAMA\nFROM [DWH_COMFENALCO].[Cedesarrollo].[FACT_FACTURACION] ff\n    INNER JOIN [DWH_COMFENALCO].[Cedesarrollo].[DIM_ESTUDIANTES] e on ff.[TIPO_DOCUMENTO_PAGO] = e.[TIPO_DOCUMENTO]\n    and ff.[DOCUMENTO_PAGO] = e.[DOCUMENTO] --INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_EMPRESAS] em on e.[ID_EMPRESA] =  em.[ID_EMPRESA]\n    INNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm ON tm.[ID_FECHA] = CAST(FORMAT(ff.[FECHA_CONTABLE], 'yyyyMM01') AS INT)\nWHERE [CONCEPTO] NOT LIKE '%CERTIFICADO%'\n    AND [CONCEPTO] NOT LIKE '%DERECHO GRADO%'\n    AND ID_AFILIADO + ID_EMPRESA + ID_BENEFICIARIO = -3\n</code></pre></p> <p>Caracter\u00edsticas del C\u00f3digo: - Uniones: Combina datos de diferentes tipos de estudiantes (afiliados, beneficiarios, empresas y no aportantes). - Filtros: Excluye conceptos como \"CERTIFICADO\" y \"DERECHO GRADO\". - Transformaciones: Convierte fechas a formato mensual y asigna categor\u00edas seg\u00fan el tipo de estudiante.  </p>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_20","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET:  </p> <ul> <li>Descripci\u00f3n: Extrae datos de la tabla <code>FACT_FACTURACION</code> utilizando la consulta SQL anterior.  </li> <li>Propiedades:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: <code>30</code> segundos.  </li> <li>Columnas principales: <code>BP</code>, <code>ID_FECHA_MENSUAL</code>, <code>ID_ANIO_ACADEMICO</code>, <code>ID_UNIDAD</code>, <code>FECHA_INICIAL</code>, <code>FECHA_FINAL</code>, <code>ACTIVIDAD</code>, <code>VALOR_PAGADO</code>, <code>ID_CATEGORIA</code>, <code>ID_CURSO</code>, <code>ID_TIPO_ESTUDIANTE</code>, <code>ID_PROGRAMA</code>.  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET:  </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>Transversal.FACT_MINERIA</code>.  </li> <li>Propiedades:  <ul> <li>Tabla: <code>\"Transversal\".\"FACT_MINERIA\"</code>.  </li> <li>Inserci\u00f3n masiva: Habilitada.  </li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o predeterminado del b\u00fafer).  </li> <li>Tiempo de espera: <code>30</code> segundos.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_21","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET\n    participant Destino as Destino ADO NET\n    Origen-&gt;&gt;Destino: Extrae y transforma datos\n    Destino-&gt;&gt;FACT_MINERIA: Carga datos en la tabla</code></pre>"},{"location":"03.Cubo/03.ETL/#componente-pqrs","title":"Componente <code>PQRs</code>","text":""},{"location":"03.Cubo/03.ETL/#descripcion-general_22","title":"Descripci\u00f3n General","text":"<p>El componente <code>PQRs</code> es una tarea de flujo de datos (Data Flow Task) dentro del paquete SSIS <code>FACT_MINERIA</code>. Su objetivo principal es procesar datos relacionados con PQR (Preguntas, Quejas y Reclamos) y cargarlos en la tabla <code>Transversal.FACT_MINERIA</code>. Este flujo incluye la extracci\u00f3n de datos desde una fuente, la aplicaci\u00f3n de transformaciones y la carga en la tabla destino.</p>"},{"location":"03.Cubo/03.ETL/#proposito_12","title":"Prop\u00f3sito","text":"<ol> <li>Extracci\u00f3n de Datos:  <ul> <li>Recuperar datos de PQR desde la tabla <code>Transversal.FACT_PQRS</code> y otras tablas relacionadas.  </li> </ul> </li> <li>Transformaci\u00f3n de Datos:  <ul> <li>Aplicar l\u00f3gica de negocio para calcular campos como <code>TIEMPO_SEGUNDOS</code> (diferencia en segundos entre la creaci\u00f3n y resoluci\u00f3n de PQR) y <code>ACTIVIDAD</code> (concatenaci\u00f3n de \"PQR\" con la causa).  </li> </ul> </li> <li>Carga de Datos:  <ul> <li>Insertar los datos procesados en la tabla <code>Transversal.FACT_MINERIA</code> para su posterior an\u00e1lisis.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#tablas-afectadas_12","title":"Tablas Afectadas","text":"<ol> <li> <p>Origen:  </p> <ul> <li><code>[DWH_COMFENALCO].[Transversal].[FACT_PQRS]</code>: Tabla que almacena los registros de PQR.  </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL]</code>: Tabla de dimensiones para el tiempo mensual.  </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS]</code>: Tabla de dimensiones para afiliados.  </li> <li><code>[DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS]</code>: Tabla de dimensiones para beneficiarios.  </li> </ul> </li> <li> <p>Destino:  </p> <ul> <li><code>[Transversal].[FACT_MINERIA]</code>: Tabla de hechos que almacena los datos procesados de PQR.</li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#implementacion-del-sql_12","title":"Implementaci\u00f3n del SQL","text":"<p>Consulta SQL Utilizada en el Origen ADO NET: <pre><code>SELECT \n    a.[PARTNER] as BP,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n    [ID_UNIDAD],\n    [FECHA_CREACION] AS FECHA_INICIAL,\n    [FECHA_RESOLUCION] AS FECHA_FINAL,\n    CONCAT('PQR ', LOWER([CAUSA])) AS ACTIVIDAD,\n    DATEDIFF(SECOND, [FECHA_CREACION], [FECHA_RESOLUCION]) AS TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    [ID_CATEGORIA],\n    -1 AS ID_CURSO,\n    -1 AS ID_TIPO_ESTUDIANTE\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] f\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n    ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01')\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n    ON f.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE f.ID_AFILIADO != -1 AND ID_UNIDAD IN (2, 3)\n\nUNION ALL\n\nSELECT \n    b.[PARTNER] as BP,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01') AS ID_FECHA_MENSUAL,\n    CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 4)) AS ID_ANIO_ACADEMICO,\n    [ID_UNIDAD],\n    [FECHA_CREACION] AS FECHA_INICIAL,\n    [FECHA_RESOLUCION] AS FECHA_FINAL,\n    CONCAT('PQR ', LOWER([CAUSA])) AS ACTIVIDAD,\n    DATEDIFF(SECOND, [FECHA_CREACION], [FECHA_RESOLUCION]) AS TIEMPO_SEGUNDOS,\n    0 AS VALOR_PAGADO,\n    ISNULL(a.[ID_CATEGORIA], 4) AS ID_CATEGORIA,\n    -1 AS ID_CURSO,\n    -1 AS ID_TIPO_ESTUDIANTE\nFROM [DWH_COMFENALCO].[Transversal].[FACT_PQRS] f\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_TIEMPO_MENSUAL] tm \n    ON tm.[ID_FECHA] = CONVERT(INT, LEFT(CAST(f.ID_FECHA AS VARCHAR), 6) + '01')\nINNER JOIN [DWH_COMFENALCO].[Transversal].[DIM_BENEFICIARIOS] b \n    ON f.[ID_BENEFICIARIO] = b.[ID_BENEFICIARIO]\nLEFT JOIN [DWH_COMFENALCO].[Transversal].[DIM_AFILIADOS] a \n    ON b.[ID_AFILIADO] = a.[ID_AFILIADO]\nWHERE f.ID_BENEFICIARIO != -1 AND ID_UNIDAD IN (2, 3)\n</code></pre></p> <p>Caracter\u00edsticas del C\u00f3digo:  </p> <ul> <li>Uni\u00f3n de Datos: Combina datos de afiliados y beneficiarios en un solo conjunto de resultados.  </li> <li>Transformaciones:  <ul> <li><code>ID_FECHA_MENSUAL</code>: Convierte la fecha a formato mensual.  </li> <li><code>ACTIVIDAD</code>: Concatena \"PQR\" con la causa.  </li> <li><code>TIEMPO_SEGUNDOS</code>: Calcula la diferencia en segundos entre la creaci\u00f3n y resoluci\u00f3n de la PQR.  </li> </ul> </li> <li>Filtros:  <ul> <li>Excluye registros con <code>ID_AFILIADO</code> y <code>ID_BENEFICIARIO</code> igual a -1.  </li> <li>Filtra por <code>ID_UNIDAD</code> en (2, 3).</li> </ul> </li> </ul>"},{"location":"03.Cubo/03.ETL/#componentes-del-flujo-de-datos_21","title":"Componentes del Flujo de Datos","text":"<ol> <li> <p>Origen ADO NET:  </p> <ul> <li>Descripci\u00f3n: Extrae datos de la tabla <code>FACT_PQRS</code> y otras tablas relacionadas utilizando la consulta SQL mencionada.  </li> <li>Propiedades:  <ul> <li>Conexi\u00f3n: <code>DWH_COMFENALCO</code>.  </li> <li>Tiempo de espera: <code>30</code> segundos.  </li> <li>Columnas de salida:  </li> <li><code>BP</code>: Identificador del afiliado o beneficiario.  </li> <li><code>ID_FECHA_MENSUAL</code>: Fecha en formato mensual.  </li> <li><code>ID_ANIO_ACADEMICO</code>: A\u00f1o acad\u00e9mico.  </li> <li><code>ID_UNIDAD</code>: Identificador de la unidad.  </li> <li><code>FECHA_INICIAL</code>: Fecha de creaci\u00f3n de la PQR.  </li> <li><code>FECHA_FINAL</code>: Fecha de resoluci\u00f3n de la PQR.  </li> <li><code>ACTIVIDAD</code>: Descripci\u00f3n de la actividad (PQR + causa).  </li> <li><code>TIEMPO_SEGUNDOS</code>: Tiempo en segundos entre creaci\u00f3n y resoluci\u00f3n.  </li> <li><code>VALOR_PAGADO</code>: Valor pagado (si aplica).  </li> <li><code>ID_CATEGORIA</code>: Categor\u00eda del afiliado o beneficiario.  </li> <li><code>ID_CURSO</code>: Identificador del curso (no aplica en este caso).  </li> <li><code>ID_TIPO_ESTUDIANTE</code>: Tipo de estudiante (no aplica en este caso).  </li> </ul> </li> </ul> </li> <li> <p>Lookup:  </p> <ul> <li>Descripci\u00f3n: Realiza una b\u00fasqueda en la tabla <code>Transversal.FACT_MINERIA</code> para validar si los registros ya existen.  </li> <li>Propiedades:  <ul> <li>Consulta SQL: <pre><code>SELECT * FROM [Transversal].[FACT_MINERIA]\n</code></pre></li> <li>Conexi\u00f3n: <code>DWH_COMFENALCO_OLEDB</code>.  </li> <li>Manejo de errores: Env\u00eda filas no coincidentes a la salida de error.  </li> </ul> </li> </ul> </li> <li> <p>Destino ADO NET:  </p> <ul> <li>Descripci\u00f3n: Carga los datos procesados en la tabla <code>Transversal.FACT_MINERIA</code>.  </li> <li>Propiedades:  <ul> <li>Tabla destino: <code>\"Transversal\".\"FACT_MINERIA\"</code>.  </li> <li>Tama\u00f1o de lote: <code>0</code> (usa el tama\u00f1o predeterminado del b\u00fafer).  </li> <li>Inserci\u00f3n masiva: Habilitada.  </li> <li>Tiempo de espera: <code>30</code> segundos.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"03.Cubo/03.ETL/#diagrama-de-secuencia_22","title":"Diagrama de Secuencia","text":"<pre><code>sequenceDiagram\n    participant Origen as Origen ADO NET\n    participant Lookup as Lookup\n    participant Destino as Destino ADO NET\n\n    Origen -&gt;&gt; Lookup: Env\u00eda datos transformados\n    Lookup -&gt;&gt; Destino: Filtra y env\u00eda datos v\u00e1lidos\n    Lookup -&gt;&gt; Error: Env\u00eda filas no coincidentes</code></pre>"},{"location":"04.sharepoint/00.Introduccion/","title":"00.Introduccion","text":""},{"location":"04.sharepoint/00.Introduccion/#introduccion","title":"Introducci\u00f3n","text":""},{"location":"04.sharepoint/estructura_archivos_actualizacion/","title":"Estructura Archivos Actualizacion","text":""},{"location":"04.sharepoint/estructura_archivos_actualizacion/#sharepoint-detalle-actualizacion-archivos","title":"Sharepoint (Detalle actualizaci\u00f3n Archivos)","text":""},{"location":"04.sharepoint/estructura_archivos_actualizacion/#introduccion","title":"Introducci\u00f3n","text":"<p>La siguiente estructura detallada de los archivos organizados en SharePoint para la gesti\u00f3n de documentos relacionados con Comfenalco. Este esquema est\u00e1 dise\u00f1ado para facilitar el acceso, la actualizaci\u00f3n y el mantenimiento de los datos esenciales, asegurando que las responsabilidades y las frecuencias de actualizaci\u00f3n est\u00e9n claramente definidas.</p>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#proposito-del-documento","title":"Prop\u00f3sito del Documento","text":"<p>El prop\u00f3sito principal es servir como una gu\u00eda de referencia para:</p> <ol> <li>Ubicaci\u00f3n de Archivos: Identificar r\u00e1pidamente la ubicaci\u00f3n de cada archivo en SharePoint.</li> <li>Frecuencia de Actualizaci\u00f3n: Detallar la periodicidad con la que los archivos deben ser actualizados para mantener la informaci\u00f3n al d\u00eda.</li> <li>Responsables: Asignar claramente las responsabilidades para el mantenimiento de cada archivo.</li> <li>Observaciones Espec\u00edficas: Incluir notas relevantes, como la nomenclatura para los a\u00f1os o dependencias de terceros, para garantizar un correcto entendimiento de cada archivo.</li> </ol>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#estructura-del-documento","title":"Estructura del Documento","text":"<ol> <li>03.Archivos_Manuales:</li> <li> <p>Contiene subcarpetas que agrupan documentos seleccionados, estructuras propuestas y otros archivos categorizados en \u00e1reas como Transversal, Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica y Continua, y Protecci\u00f3n Social.</p> </li> <li> <p>Detalles por Archivo:</p> </li> <li>Cada archivo cuenta con la siguiente informaci\u00f3n:<ul> <li>Nombre del Archivo: Identificaci\u00f3n \u00fanica del documento.</li> <li>Ubicaci\u00f3n: Ruta exacta en SharePoint.</li> <li>Unidad: \u00c1rea responsable o relacionada con el contenido del archivo.</li> <li>Frecuencia de Actualizaci\u00f3n: Intervalo en el que debe ser revisado o actualizado.</li> <li>Responsable: Personas o equipos encargados del mantenimiento del documento.</li> <li>Observaciones: Detalles adicionales relevantes, como la estructura del nombre o el prop\u00f3sito del archivo.</li> </ul> </li> </ol>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#ejemplo-de-uso","title":"Ejemplo de Uso","text":"<ul> <li>Archivo: <code>AM-TRA-08.xlsx</code></li> <li>Ubicaci\u00f3n: <code>03.Archivos_Manuales/01.Archivos_Seleccionados/01.Transversal/01.Dim_Servicios</code></li> <li>Frecuencia de Actualizaci\u00f3n: Anual.</li> <li>Responsable: Planeaci\u00f3n y Presupuesto.</li> <li>Observaci\u00f3n: Archivos que incluyen un a\u00f1o en el nombre, por ejemplo, <code>AM-TRA-08_2024.xlsx</code>.</li> </ul>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#beneficios-del-documento","title":"Beneficios del Documento","text":"<ol> <li>Estandarizaci\u00f3n: Facilita el acceso y evita duplicaci\u00f3n o errores en la gesti\u00f3n documental.</li> <li>Claridad: Define roles y frecuencias, lo que asegura la actualizaci\u00f3n constante de los datos.</li> <li>Escalabilidad: Permite integrar nuevos archivos sin perder la organizaci\u00f3n.</li> </ol>"},{"location":"04.sharepoint/estructura_archivos_actualizacion/#actualizacion-de-archivos","title":"Actualizaci\u00f3n de archivos","text":"03.Archivos_Manuales 01.Archivos_Seleccionados 01.Transversal 01.Dim_Servicios <ul> <li>Archivo: AM-TRA-08.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/01.Archivos_Seleccionados/01.Transversal/01.Dim_Servicios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 02.Educacion_Formal 01.Dim_Libros <ul> <li>Archivo: AM-EDF-153.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/01.Archivos_Seleccionados/02.Educacion_Formal/01.Dim_Libros</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE BIBLIOTECA/AUXILIAR DE BIBLIOTECA Observaciones: Sin observaciones.</li> </ul> 02.Estructuras_Propuestas 01.Transversal 01.Dim_Servicios <ul> <li>Archivo: EP-TRA-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/01.Transversal/01.Dim_Servicios</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n; Planeaci\u00f3n y Presupuesto Observaciones: Sin observaciones.</li> </ul> 02.Dim_Capacidad_Fisica <ul> <li>Archivo: EP-TRA-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/01.Transversal/02.Dim_Capacidad_Fisica</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Sin observaciones.</li> </ul> 02.Educacion_Formal 01.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/01.DIM_PERSONAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 02.FACT_AUSENTISMO_DOCENTE <ul> <li>Archivo: EP-EDF-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/02.FACT_AUSENTISMO_DOCENTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORD. ACAD\u00c9MICAS Observaciones: Sin observaciones.</li> </ul> 03.FACT_BIBLIOTECA <ul> <li>Archivo: EP-EDF-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/03.FACT_BIBLIOTECA</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE BIBLIOTECA/AUXILIAR DE BIBLIOTECA Observaciones: Sin observaciones.</li> </ul> 04.FACT_BIBLIOTECA_VIRTUAL <ul> <li>Archivo: EP-EDF-06.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/04.FACT_BIBLIOTECA_VIRTUAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE BIBLIOTECA/AUXILIAR DE BIBLIOTECA Observaciones: Sin observaciones.</li> </ul> 05.FACT_DESEMPENHO_DOCENTE <ul> <li>Archivo: EP-EDF-09.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/05.FACT_DESEMPENHO_DOCENTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 06.FACT_ENFERMERIA <ul> <li>Archivo: EP-EDF-01.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/06.FACT_ENFERMERIA</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Enfermera Observaciones: Sin observaciones.</li> </ul> 07.FACT_LEGALIZACION <ul> <li>Archivo: EP-EDF-10.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/07.FACT_LEGALIZACION</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ANALISTA DE RECURSOS TECNOL\u00d3GICOS Observaciones: Sin observaciones.</li> </ul> 08.FACT_PERMISO_ESTUDIANTE <ul> <li>Archivo: EP-EDF-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/08.FACT_PERMISO_ESTUDIANTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 09.FACT_PSIORIENTACION <ul> <li>Archivo: EP-EDF-11.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/09.FACT_PSIORIENTACION</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADOR DE PSICOLOG\u00cdA Observaciones: Sin observaciones.</li> </ul> 10.FACT_REEMPLAZO_DOCENTE <ul> <li>Archivo: EP-EDF-03.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/10.FACT_REEMPLAZO_DOCENTE</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORD. ACAD\u00c9MICAS Observaciones: Sin observaciones.</li> </ul> 11.FACT_RESERVA_ESPACIOS <ul> <li>Archivo: EP-EDF-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/11.FACT_RESERVA_ESPACIOS</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: ANALISTA DE RECURSOS F\u00cdSICOS Y ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 12.FACT_SABER11_COLEGIOS <ul> <li>Archivo: EP-EDF-08.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/12.FACT_SABER11_COLEGIOS</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 13.FACT_SABER11_INDIVIDUAL <ul> <li>Archivo: EP-EDF-07.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/13.FACT_SABER11_INDIVIDUAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORD ACAD\u00c9MICOS Observaciones: Sin observaciones.</li> </ul> 14.FACT_SERVICIO_SOCIAL <ul> <li>Archivo: EP-EDF-13.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/02.Educacion_Formal/14.FACT_SERVICIO_SOCIAL</code> Unidad: Educaci\u00f3n Formal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ASISTENTE ACAD\u00c9MICO BSMA Observaciones: Sin observaciones.</li> </ul> 03.Educacion_Tecnica 01.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/03.Educacion_Tecnica/01.DIM_PERSONAL</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 04.Educacion_Continua 01.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/04.Educacion_Continua/01.DIM_PERSONAL</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 05.Proteccion_Social 01.Caracterizacion AM-PRS-03 <ul> <li>Archivo: AM-PRS-03.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-03</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI y JEC. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> AM-PRS-10 <ul> <li>Archivo: AM-PRS-10.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-10</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para Adulto Mayor. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-102 <ul> <li>Archivo: AM-PRS-102.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-102</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Trimestral Responsable del Documento: Analista de protecci\u00f3n social Observaciones: Sin observaciones.</li> </ul> AM-PRS-11 <ul> <li>Archivo: AM-PRS-11.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-11</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para Discapacidad. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-12 <ul> <li>Archivo: AM-PRS-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-12</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para JEC. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-120 <ul> <li>Archivo: AM-PRS-120.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-120</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Analista de protecci\u00f3n social Observaciones: Sin observaciones.</li> </ul> AM-PRS-13 <ul> <li>Archivo: AM-PRS-13.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-13</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI. Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-PRS-10-202403 es para marzo de 2024.</li> </ul> AM-PRS-145 <ul> <li>Archivo: AM-PRS-145.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-145</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI.</li> </ul> AM-PRS-145_CATEGORICAS <ul> <li>Archivo: AM-PRS-145_CATEGORICAS.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-145_CATEGORICAS</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: A demanda Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI.</li> </ul> AM-PRS-23 <ul> <li>Archivo: AM-PRS-23.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-23</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADORA DE PROGRAMA \u2013 AUXILIAR DE DEPARTAMENTO DE PROTECCI\u00d3N SOCIAL Observaciones: Sin observaciones.</li> </ul> AM-PRS-41 <ul> <li>Archivo: AM-PRS-41.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-41</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: AUXILIAR DE DEPARTAMENTO DE PROTECCI\u00d3N SOCIAL Observaciones: Sin observaciones.</li> </ul> AM-PRS-81 <ul> <li>Archivo: AM-PRS-81.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-81</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: COORDINADOR DE PROGRAMA Observaciones: Para AIPI.</li> </ul> AM-PRS-91 <ul> <li>Archivo: AM-PRS-91.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-91</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADOR DE PROGRAMA Observaciones: Para JEC.</li> </ul> AM-PRS-91_CATEGORICAS <ul> <li>Archivo: AM-PRS-91_CATEGORICAS.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/AM-PRS-91_CATEGORICAS</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: COORDINADOR DE PROGRAMA Observaciones: Para JEC.</li> </ul> DIM_PROGRAMA <ul> <li>Archivo: ID_PROGRAMA.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/DIM_PROGRAMA</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: A demanda Responsable del Documento: Analista de protecci\u00f3n social Observaciones: Sin observaciones.</li> </ul> EP-PRS-02 <ul> <li>Archivo: EP-PSR-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PRS-02</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Sin observaciones.</li> </ul> EP-PRS-03 <ul> <li>Archivo: EP-PSR-03.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PRS-03</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Sin observaciones.</li> </ul> EP-PSR-01 <ul> <li>Archivo: EP-PSR-01.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-PSR-01</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: Coordinadora Protecci\u00f3n Social Observaciones: Para AIPI.</li> </ul> EP-TRA-02 <ul> <li>Archivo: EP-TRA-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/EP-TRA-02</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n Observaciones: Sin observaciones.</li> </ul> NSU/CEC <ul> <li>Archivo: CEC (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: CEC.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocec.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/CEC</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Cedesarrollo convenios <ul> <li>Archivo: campanas comfenalcoconvenios (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconvenios.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Convenios (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Convenios.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cedesarrollo convenios</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Consultorias <ul> <li>Archivo: campanas comfenalcoconsultorias (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoconsultorias.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Consultorias (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Consultorias.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Consultorias</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Cursos y diplomados <ul> <li>Archivo: campanas comfenalcodiplomados (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcodiplomados.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Cursos y diplomados (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Cursos y diplomados.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Cursos y diplomados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Egresados <ul> <li>Archivo: comfenalcocedesarrolloegresados (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados (3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados (4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados (5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: comfenalcocedesarrolloegresados.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Egresado (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Egresado.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Egresados</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Estudiantes Activos <ul> <li>Archivo: base1.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base1Activos1.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base2.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base2Activos0.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base3.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base4.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: base5.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Estudiantes Activos (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Estudiantes Activos.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Estudiantes Activos</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> NSU/Proteccion social <ul> <li>Archivo: campanas comfenalcoproteccion(2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoproteccion(3).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoproteccion(4).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: campanas comfenalcoproteccion(5).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Proteccion social (2).txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> <li>Archivo: Proteccion social.txt Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/01.Caracterizacion/NSU/Proteccion social</code> Unidad: Transversal Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Planeaci\u00f3n y Presupuesto Observaciones: Archivos dependen de un tercero.</li> </ul> 02.DIM_PERSONAL <ul> <li>Archivo: EP-TRA-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/02.Estructuras_Propuestas/05.Proteccion_Social/02.DIM_PERSONAL</code> Unidad: Protecci\u00f3n Social Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinadora Educaci\u00f3n; Recursos Humanos Observaciones: Los archivos seguidos de _ y un n\u00famero indican el a\u00f1o del archivo. Por ejemplo, AM-TRA-08_2024.xlsx es para el a\u00f1o 2024.</li> </ul> 03.Otros_Archivos <ul> <li>Archivo: AM-DRE-05_08_12_2024.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Mensual Responsable del Documento: AUXILIAR ADMINISTRATIVO/ANALISTAS DE SERVICIO EMPRESARIAL/ANALISTA DE FOMENTO EMPRESARIAL Observaciones: Sin observaciones.</li> <li>Archivo: AM-DRE-16.xls Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: PERSONAL EXPERTO/ANALISTA DE FOMENTO EMPRESARIAL/ANALISTA DE SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: AM-EPT-47.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: COORDINADOR DE SERVICIOS TECNOL\u00d3GICOS Observaciones: Sin observaciones.</li> <li>Archivo: EP-EDF-02.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EDF-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EDF-09.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EDF-09_01_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-04.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: COORDINADOR DE SERVICIOS TECNOL\u00d3GICOS Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-05.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: PERSONAL EXPERTO/ANALISTA DE FOMENTO EMPRESARIAL/ANALISTA DE SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-06.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-06_10_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-06_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-07.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-07_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: Coordinador Desarrollo empresarial Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-08.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: ANALISTA SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-08_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: ANALISTA SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-09.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-10.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ANALISTA DE SERVICIOS EMPRESARIALES/ANALISTA DE FOMENTO EMPRESARIAL Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-10_13_01_2025.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Anual Responsable del Documento: ANALISTA DE SERVICIOS EMPRESARIALES/ANALISTA DE FOMENTO EMPRESARIAL Observaciones: Para Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-11.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: Semestral Responsable del Documento: Coordinadora Cedesarrollo Observaciones: Para Educaci\u00f3n T\u00e9cnica y Educaci\u00f3n Continua.</li> <li>Archivo: EP-EPT-12.xlsx Ubicaci\u00f3n: <code>03.Archivos_Manuales/03.Otros_Archivos</code> Unidad: Educaci\u00f3n T\u00e9cnica y Continua Frecuencia de Actualizaci\u00f3n: A demanda Responsable del Documento: PERSONAL EXPERTO/ANALISTA DE FOMENTO EMPRESARIAL/ANALISTA DE SERVICIOS EMPRESARIALES Observaciones: Para Educaci\u00f3n Continua.</li> </ul> <p>```</p>"},{"location":"04.sharepoint/estructura_sharepoint/","title":"Estructura carpeta Sharepoint","text":""},{"location":"04.sharepoint/estructura_sharepoint/#sharepoint-configuracion-y-estructura","title":"Sharepoint (Configuraci\u00f3n y Estructura)","text":""},{"location":"04.sharepoint/estructura_sharepoint/#introduccion","title":"Introducci\u00f3n","text":"<p>La integraci\u00f3n de SharePoint con los procesos ETL (Extract, Transform, Load) garantiza una gesti\u00f3n centralizada, accesible y segura de los datos capturados mediante t\u00e9cnicas avanzadas de webscraping. Este enfoque permite organizar, almacenar y compartir informaci\u00f3n acad\u00e9mica y administrativa de manera eficiente, asegurando que los equipos involucrados puedan acceder a datos actualizados y estructurados.</p> <p>En el \u00e1mbito de la Educaci\u00f3n T\u00e9cnica y Continua, SharePoint se convierte en una herramienta clave para el manejo de los datos procesados, facilitando la colaboraci\u00f3n entre m\u00faltiples actores y plataformas. La implementaci\u00f3n de una estructura bien definida de carpetas y permisos asegura que los flujos de trabajo sean consistentes y escalables.</p>"},{"location":"04.sharepoint/estructura_sharepoint/#principales-caracteristicas-de-la-configuracion","title":"Principales Caracter\u00edsticas de la Configuraci\u00f3n","text":"<ol> <li>Creaci\u00f3n del Sitio del Proyecto:    El sitio COMFENALCO_EDUCACION act\u00faa como el repositorio principal de los datos extra\u00eddos, procesados y consolidados.</li> <li> <p>Estructuraci\u00f3n de Carpetas:  </p> <ul> <li>Las carpetas est\u00e1n organizadas en niveles jer\u00e1rquicos, categorizando los datos seg\u00fan su origen y prop\u00f3sito.</li> <li>Subcarpetas espec\u00edficas almacenan datos procesados y sin procesar, lo que permite un control preciso de las versiones y una f\u00e1cil recuperaci\u00f3n de informaci\u00f3n.</li> </ul> </li> <li> <p>Autenticaci\u00f3n Segura mediante Azure:  </p> <ul> <li>Registro de una aplicaci\u00f3n en Azure para la autenticaci\u00f3n de SharePoint.</li> <li>Uso de un cliente secreto y certificados para garantizar un acceso seguro a los datos.</li> </ul> </li> <li> <p>Gesti\u00f3n de Permisos:  </p> <ul> <li>Configuraci\u00f3n de permisos espec\u00edficos para aplicaciones como <code>Sites.FullControl.All</code> y <code>TermStore.Read.All</code>.</li> <li>Garant\u00eda de que solo usuarios autorizados puedan acceder y modificar la informaci\u00f3n almacenada.</li> </ul> </li> <li> <p>Automatizaci\u00f3n con Python:  </p> <ul> <li>El c\u00f3digo <code>SharePoint_Connection.py</code> permite interactuar directamente con las carpetas y archivos de SharePoint, automatizando procesos como la carga y extracci\u00f3n de datos.</li> </ul> </li> </ol>"},{"location":"04.sharepoint/estructura_sharepoint/#metodologia-para-configuracion-sharepoint-online-para-web-scrapping-y-ssis","title":"Metodolog\u00eda para Configuraci\u00f3n Sharepoint Online para Web Scrapping y SSIS","text":"<ol> <li>Crear en SharePoint el sitio del proyecto (<code>COMFENALCO_EDUCACION</code>)</li> <li> <p>En la parte de documentos crear las carpetas necesarias</p> <p></p> </li> <li> <p>En <code>Azure</code> ir a <code>Registro de Aplicaciones</code></p> </li> <li>Crear una nueva aplicaci\u00f3n.</li> <li>Asignarle un cliente secreto y copiar y guardar el <code>secret_client</code> que se genera. Solo se puede ver en este momento.</li> <li> <p>Subir un certificado. En la carpeta donde se vaya a crear la ETL de Web Scraping correr el siguiente comando y subir el archivo generado.     </p> <p>Observaciones</p> <ul> <li>Puede ser necesario instalar <code>OpenSSL</code> en Windows. Gu\u00eda para instalar <code>https://www.youtube.com/watch?v=coaGBdUcKiw</code></li> <li>Se puede tomar como referencia el siguiente video <code>https://www.youtube.com/watch?v=KWKiwpK-L5o</code></li> </ul> </li> <li> <p>Luego ir a <code>Permisos de API</code> y agregar un nuevo permiso. Buscar la aplicaci\u00f3n <code>SharePoint</code> y escoger permisos de aplicaci\u00f3n <code>Sites.FullControl.All</code>, <code>Real.All</code>, <code>TermStore.Read.all</code> </p> </li> <li>Conceder el permiso del paso anterior. Para este paso se requieren permisos de administrador en la consola de Azure. </li> <li>Con esto el c\u00f3digo de <code>SharePoint_Connection.py</code> debe funcionar. Tener cuidado de la carpeta a la cual se est\u00e1 dirigiendo en la variable <code>folder_url</code></li> </ol>"},{"location":"04.sharepoint/estructura_sharepoint/#estructura-de-la-carpeta","title":"Estructura de la Carpeta","text":""},{"location":"04.sharepoint/estructura_sharepoint/#comfenalco-educacion","title":"COMFENALCO EDUCACION","text":"Estructura de Carpetas Contraer todo Contiene los archivos resultado del WebScraping de diferentes plataformas relacionadas con la educaci\u00f3n y convenios de Comfenalco. 01.Q10 <ul> Carpeta principal con los datos extra\u00eddos del sistema Q10, organizados en categor\u00edas espec\u00edficas. 01.Educacion_Tecnica <ul> Subcarpeta con informaci\u00f3n t\u00e9cnica sobre docentes, matr\u00edculas, ingresos y notas hist\u00f3ricas. 01.Docentes <ul> Contiene archivos relacionados con los registros de los docentes procesados y sin procesar. <li>Docentes_08_12_2024.xlsx </li> <li>Docentes_09_12_2024.xlsx </li> <li>Docentes_20_11_2024.xlsx </li> <li>Docentes_21_11_2024.xlsx </li> <li>Docentes_23_11_2024.xlsx </li> <li>Docentes_23_12_2024.xlsx </li> <li>Docentes_27_12_2024.xlsx </li> </ul> 02.Disenio_Curricular <ul> Archivos relacionados con el plan de estudios (Pensum) de cada programa. <li>Dise\u00f1o_Curricular_08_12_2024.xlsx </li> <li>Dise\u00f1o_Curricular_17_12_2024.xlsx </li> <li>Dise\u00f1o_Curricular_20_11_2024.xlsx </li> <li>Dise\u00f1o_Curricular_21_11_2024.xlsx </li> <li>Dise\u00f1o_Curricular_27_12_2024.xlsx </li> </ul> 03.Listado_Matriculas <ul> Listado de matr\u00edculas con el listado de los estudiantes que fueron matriculados en un programa espec\u00edfico en el rango de fechas o periodo seleccionado. <li>Listado_Matriculas_01_01_2016_31_12_2016_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2016_31_12_2016_Act_24_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2017_31_12_2017_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2017_31_12_2017_Act_24_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2017_31_12_2017_Act_24_11_20241.xlsx </li> <li>Listado_Matriculas_01_01_2018_31_12_2018_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2018_31_12_2018_Act_24_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2019_31_12_2019_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2020_31_12_2020_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2021_31_12_2021_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2022_31_12_2022_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2023_31_12_2023_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_28_11_2024_Act_28_11_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_30_06_2024_Act_27_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_31_12_2024_Act_23_12_2024.xlsx </li> <li>Listado_Matriculas_01_01_2024_31_12_2024_Act_27_12_2024.xlsx </li> </ul> 04.Ingresos <ul> Listado de archivos contiene el dinero recibido por concepto de pagos registrados en las diferentes modalidades de recaudo. <li>Ingresos_01_01_2017_31_12_2017_23_12_2024.xlsx </li> <li>Ingresos_01_01_2018_31_12_2018_23_12_2024.xlsx </li> <li>Ingresos_01_01_2019_31_12_2019_23_12_2024.xlsx </li> <li>Ingresos_01_01_2020_31_12_2020_23_12_2024.xlsx </li> <li>Ingresos_01_01_2020_31_12_2020_27_12_2024.xlsx </li> <li>Ingresos_01_01_2021_31_12_2021_23_12_2024.xlsx </li> <li>Ingresos_01_01_2022_31_12_2022_23_12_2024.xlsx </li> <li>Ingresos_01_01_2023_31_12_2023_23_12_2024.xlsx </li> <li>Ingresos_01_01_2024_31_12_2024_23_12_2024.xlsx </li> </ul> 05.Historico_Notas<ul> Historial detallado de los cursos que han sido archivados con sus respectivos estudiantes y notas. <li>- Historico_Notas_2023_2_0100c7e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_026fa7c8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_02cbe285_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0449a5e7_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_07dba647_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_092aac38_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0cddad19_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0dff50cb_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_0e7858c3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_10375576_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_109d6949_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_121fad89_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_12dc19a4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_1735f955_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_185ac97e_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_1958d0f8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_1a220917_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2210ee55_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2226d5a5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2380e5e7_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_24b41186_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_273540de_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_29769f40_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2be84da8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2d29660f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2e068ad5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_2ee8230e_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_306b3846_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_30cc8d74_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_32e309f0_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_33b9edfc_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_378b0fac_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_384c0f48_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4215b767_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_46b79fc3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4921f516_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4bad2c64_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4d3cc959_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_4dc601e8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_541f1898_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_55a3bd93_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_55e6763f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_58f870e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_5f5f368b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_62908c57_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6500f569_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6540bc55_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_66b59284_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_68bb266b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6b58a8a9_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6ef0249a_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_6f559dd2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_73887911_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7a4650f1_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7a962879_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7c26c9fe_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7e5281f2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7eaa6bf3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_7ecf3546_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_81280bf5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_812e8d89_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_85fd6ce5_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_885e0511_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_88851305_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_8a1dc0e8_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_8ead704b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_8fd27aa1_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_91cb763c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_956755ea_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_9776db00_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_9a88ca6d_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_a8543b8f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_a895cfc3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ab2d75de_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ac6e1db1_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ad933526_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_af9aa73c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_b1d06454_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_b88458df_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_baec81f2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_bb6bce34_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_bbb5dd53_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_bec15051_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c155c17a_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c3b000d2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c576f83c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c6407892_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_c9ac9d62_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_caa22d82_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_cae7be5c_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_cbf22cd4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ccb297f0_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d413cda3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d573164b_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d888e4af_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_d9bd30a3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_dadd2624_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_db34b6b2_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_dea03ce6_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_df10e46e_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_df7dbde9_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e1111635_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e6f87f14_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e7ec41ef_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_e964d7d0_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_ec138d23_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_eccbecbe_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_eea8e976_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f02f4642_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f0a906ec_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f104cb7f_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f18569e3_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f2835d58_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f75fcc99_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f8939331_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f9c45ab6_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_f9d3b157_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_fa3190bf_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_fabd1fb4_24_12_2024.xlsx </li> <li>- Historico_Notas_2023_2_fcd657ef_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_046ce457_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_0e466b26_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_0f91b4b0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1130b71a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_12570c3e_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1a458bff_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1e01dc0c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1e36519c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1e949cc6_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1f4264e3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_1f5150ed_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_248946e3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_28e1fc5a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_2c7b3b56_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_316ee9d7_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3255b38a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3283e4b3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_35394ea3_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3588253c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3a428752_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3b426767_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_3fa7f518_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_40fae1d1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_4ec16e1f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_50b5f8e0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_535a9c53_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_5d9b1d37_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_5ee76ea0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_62d748e5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_64183122_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_68eb8641_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_6e7f7ac5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_6f3268f9_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_6f48dd2f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_700898eb_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7044b236_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_741e9221_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_75f1b194_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_769e73ee_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_796685b9_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7b2d09b2_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7b8a67d1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7b8caefb_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7cf1c303_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7d9ff89c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7e2ece94_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7f88a9c1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_7fd4026f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_82c2d334_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_86841d92_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_86fe6856_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_8870b866_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_898499c8_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_8a325911_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_8c233e77_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_9051cfba_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_91ca2296_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_95a35066_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_964ae673_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_978c7d05_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_98f3faec_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_9a46e7e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_9e635b41_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a2182500_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a4e412ce_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a80338d1_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a8d30ce5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a9862f6d_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_a9eb40a4_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_aa322057_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_ab514259_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_af9f6622_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b06dc7df_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b5c640c2_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b5f21992_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b8884db6_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_b95c9d2a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_bb80a2a7_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_c5c6495d_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_c7133773_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_c7583eed_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_ca93eb94_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_cba65ff5_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_cc57a34b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d1ce1966_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d34f5bf8_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d68444b2_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d812cccc_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_d9aa91e4_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dc6f2109_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dccac103_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dcd84c6c_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_dcf2b57f_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e3430d8b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e4ad961e_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e546f874_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e6a6da65_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e9175c3b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_e91bf7dc_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_ef1d746b_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f541b731_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f70675c0_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f828cd1a_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_f9e953ce_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_fb4fd7a6_24_12_2024.xlsx </li> <li>- Historico_Notas_2024_2_fbb74184_24_12_2024.xlsx </li> <li>- Historico_Notas_AA-Com. Org-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Compras-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Cont. Inv. Apli-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Gest. Doc-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Htas. Apoy. Tec-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Htas. Apoy. Tec-JN-G2-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-PROD.DOC-JM-S1-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-PROD.DOC-JN-S1-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-PROD.DOC-JN-S1-G2-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_AA-Sem. Tra. Emp-JN-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_MV-Est. Can. Dist-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_MV-Estrat. Prec.-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_MV-Inv. Merc.-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-IMP.SG-SST-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-Sem. Tra. Emp-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-Sem. Tra. V.S-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_SO-STAR-2-JM-G1-(2023-2)_27_11_2024.xlsx </li> <li>- Historico_Notas_T\u00e9cnico Laboral en Auxiliar Administrativo_27_11_2024.xlsx </li> </ul> 06.Egresados_Graduados<ul> Nota: Contiene archivos de Excel con la informaci\u00f3n de los egresados y graduados.                          <li>- Graduados_2010 - 1_21_11_2024.xlsx </li> <li>- Graduados_2010 - 2_21_11_2024.xlsx </li> <li>- Graduados_2011 - 1_21_11_2024.xlsx </li> <li>- Graduados_2011 - 2_21_11_2024.xlsx </li> <li>- Graduados_2012 - 1_21_11_2024.xlsx </li> <li>- Graduados_2012 - 2_21_11_2024.xlsx </li> <li>- Graduados_2013 - 1_21_11_2024.xlsx </li> <li>- Graduados_2013 - 2_21_11_2024.xlsx </li> <li>- Graduados_2014 - 1_21_11_2024.xlsx </li> <li>- Graduados_2014 - 2_21_11_2024.xlsx </li> <li>- Graduados_2015 - 1_21_11_2024.xlsx </li> <li>- Graduados_2015 - 2_21_11_2024.xlsx </li> <li>- Graduados_2016 - 1_21_11_2024.xlsx </li> <li>- Graduados_2016 - 1_24_12_2024.xlsx </li> <li>- Graduados_2016 - 2_21_11_2024.xlsx </li> <li>- Graduados_2016 - 2_24_12_2024.xlsx </li> <li>- Graduados_2017 - 1_21_11_2024.xlsx </li> <li>- Graduados_2017 - 1_24_12_2024.xlsx </li> <li>- Graduados_2017 - 2_21_11_2024.xlsx </li> <li>- Graduados_2017 - 2_24_12_2024.xlsx </li> <li>- Graduados_2018-1_21_11_2024.xlsx </li> <li>- Graduados_2018-1_24_12_2024.xlsx </li> <li>- Graduados_2018-2_21_11_2024.xlsx </li> <li>- Graduados_2018-2_24_12_2024.xlsx </li> <li>- Graduados_2019-1 CONVENIO_21_11_2024.xlsx </li> <li>- Graduados_2019-1 CONVENIO_24_12_2024.xlsx </li> <li>- Graduados_2019-1_21_11_2024.xlsx </li> <li>- Graduados_2019-1_24_12_2024.xlsx </li> <li>- Graduados_2019-2_21_11_2024.xlsx </li> <li>- Graduados_2019-2_24_12_2024.xlsx </li> <li>- Graduados_2020-1_21_11_2024.xlsx </li> <li>- Graduados_2020-1_24_12_2024.xlsx </li> <li>- Graduados_2020-2_21_11_2024.xlsx </li> <li>- Graduados_2020-2_24_12_2024.xlsx </li> <li>- Graduados_2021-1_21_11_2024.xlsx </li> <li>- Graduados_2021-1_24_12_2024.xlsx </li> <li>- Graduados_2021-2_21_11_2024.xlsx </li> <li>- Graduados_2021-2_24_12_2024.xlsx </li> <li>- Graduados_2022-1_21_11_2024.xlsx </li> <li>- Graduados_2022-1_24_12_2024.xlsx </li> <li>- Graduados_2022-2_21_11_2024.xlsx </li> <li>- Graduados_2022-2_24_12_2024.xlsx </li> <li>- Graduados_2023-1_21_11_2024.xlsx </li> <li>- Graduados_2023-1_24_12_2024.xlsx </li> <li>- Graduados_2023-2_21_11_2024.xlsx </li> <li>- Graduados_2023-2_24_12_2024.xlsx </li> <li>- Graduados_2024-1_21_11_2024.xlsx </li> <li>- Graduados_2024-1_24_12_2024.xlsx </li> <li>- Graduados_2024-1_27_12_2024.xlsx </li> <li>- Graduados_2024-2_21_11_2024.xlsx </li> <li>- Graduados_2024-2_24_12_2024.xlsx </li> <li>- Graduados_2024-2_27_12_2024.xlsx </li> <li>- Graduados_23_12_2024.xlsx </li> <li>- Graduados_Agosto 2024_23_12_2024.xlsx </li> <li>- Graduados_Julio 2024_23_12_2024.xlsx </li> <li>- Graduados_Junio 2024_23_12_2024.xlsx </li> <li>- Graduados_Octubre 2024_23_12_2024.xlsx </li> <li>- Graduados_Septiembre 2024_23_12_2024.xlsx </li> </ul> 07.Cancelados_Desertores<ul> Nota: Contiene los registros de estudiantes que han cancelado su matr\u00edcula con su respectiva causa y descripci\u00f3n.                          <li>- Cancelados_desertores_01_02_2024_04_10_2024.xlsx </li> <li>- Cancelados_desertores_01_02_2024_22_03_2024.xlsx </li> <li>- Cancelados_desertores_03_02_2020_12_12_2020.xlsx </li> <li>- Cancelados_desertores_10_02_2022_21_10_2022.xlsx </li> <li>- Cancelados_desertores_11_02_2023_09_10_2023.xlsx </li> <li>- Cancelados_desertores_11_03_2019_03_12_2019.xlsx </li> <li>- Cancelados_desertores_28_02_2021_23_12_2021.xlsx </li> <li>- Cancelados_desertores_31_08_2018_04_10_2018.xlsx </li> </ul> Procesados<ul> Nota: Esta secci\u00f3n contiene los archivos procesados, organizados seg\u00fan la misma estructura jer\u00e1rquica de carpetas original. Los datos han sido preparados y optimizados para su integraci\u00f3n y consumo directo mediante SSIS, garantizando compatibilidad y eficiencia en los procesos ETL.                          01.Docentes<ul> <li>- procesado_cede_Docentes_08_12_2024_20_27.xlsx </li> <li>- procesado_cede_Docentes_23_12_2024_14_39.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_11_52.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_11_53.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_12_18.xlsx </li> <li>- procesado_cede_Docentes_27_12_2024_12_26.xlsx </li> 02.Disenio_Curricular<ul> <li>- procesado_cede_Dise\u00f1o_Curricular_08_12_2024_20_28.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_23_12_2024_14_41.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_27_12_2024_12_02.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_27_12_2024_12_03.xlsx </li> <li>- procesado_cede_Dise\u00f1o_Curricular_27_12_2024_14_05.xlsx </li> 03.Listado_Matriculas<ul> <li>- procesado_cede_Listado_Matriculas_08_12_2024_20_21.xlsx </li> <li>- procesado_cede_Listado_Matriculas_08_12_2024_20_26.xlsx </li> <li>- procesado_cede_Listado_Matriculas_17_12_2024_09_34.xlsx </li> <li>- procesado_cede_Listado_Matriculas_23_12_2024_14_45.xlsx </li> <li>- procesado_cede_Listado_Matriculas_27_12_2024_12_09.xlsx </li> 04.Ingresos<ul> <li>- procesado_cede_Ingresos_08_12_2024_20_32.xlsx </li> <li>- procesado_cede_Ingresos_23_12_2024_14_56.xlsx </li> <li>- procesado_cede_Ingresos_27_12_2024_14_11.xlsx </li> 05.Historico_Notas<ul> <li>- procesado_cede_Historico_Notas_08_12_2024_20_36.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_08_44.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_08_50.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_09_04.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_09_20.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_09_23.xlsx </li> <li>- procesado_cede_Historico_Notas_24_12_2024_18_15.xlsx </li> 06.Egresados_Graduados<ul> <li>- procesado_cede_Egresados_Graduados_08_12_2024_20_38.xlsx </li> <li>- procesado_cede_Egresados_Graduados_23_12_2024_21_28.xlsx </li> <li>- procesado_cede_Egresados_Graduados_24_12_2024_19_42.xlsx </li> 07.Cancelados_Desertores<ul> <li>- procesado_cede_Cancelados_Desertores_08_12_2024_20_41.xlsx </li> <li>- procesado_cede_Cancelados_Desertores_24_12_2024_20_14.xlsx </li> </ul> </ul> </ul> 02.Educacion_Continua Nota: Contiene registros de docentes relacionados con programas de educaci\u00f3n continua.                  <ul> 01.Docentes<ul> Nota: Listado de preinscritos en programas de educaci\u00f3n continua.                          <li>- Docentes_08_12_2024.xlsx </li> <li>- Docentes_20_11_2024.xlsx </li> <li>- Docentes_21_11_2024.xlsx </li> <li>- Docentes_25_12_2024.xlsx </li> <li>- Docentes_28_12_2024.xlsx </li> <li>- Docentes_30_11_2024.xlsx </li> </ul> 02.Preinscritos<ul> Nota: Archivos detallados de preinscritos en programas de educaci\u00f3n continua.                          <li>- Preinscritos_20_11_2024.xlsx </li> <li>- Preinscritos_21_11_2024.xlsx </li> <li>- Preinscritos_25_12_2024.xlsx </li> <li>- Preinscritos_27_12_2024.xlsx </li> <li>- Preinscritos_30_11_2024.xlsx </li> </ul> 03.Listado_Matriculas<ul> Nota: Listado de los estudiantes que fueron matriculados en un programa espec\u00edfico en el rango de fechas o periodo seleccionado.                          <li>- Listado_Matriculas_01_01_2018_31_12_2018_Act_30_11_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2019_30_06_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2019_31_03_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2020_31_03_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2021_31_03_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2022_31_03_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2023_31_03_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2024_31_03_2024_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_01_2024_31_03_2024_Act_27_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2019_30_06_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2020_30_06_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2021_30_06_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2022_30_06_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2023_30_06_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2024_30_06_2024_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_04_2024_30_06_2024_Act_27_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2018_31_12_2018_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2019_30_09_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2020_30_09_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2021_30_09_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2022_30_09_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_07_2023_30_09_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2018_31_12_2018_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2019_31_12_2019_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2020_31_12_2020_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2021_31_12_2021_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2022_31_12_2022_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2023_31_12_2023_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2024_31_12_2024_Act_25_12_2024.xlsx </li> <li>- Listado_Matriculas_01_10_2024_31_12_2024_Act_27_12_2024.xlsx </li> </ul> 04.Consolidado_inasistencias<ul> Nota: <li>- Consolidado_Inasistencias_1020.xlsx </li> <li>- Consolidado_Inasistencias_Consolidado_de_Inasistencias (1).xlsx </li> <li>- Consolidado_Inasistencias_Desarrollo Empresarial - Ma\u00f1ana_AUTOCONFIANZA_Noviembre 2024.xlsx </li> </ul> 05.Estudiantes_cancelados_por_inasistencias<ul> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Agosto 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Diciembre 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Diciembre 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Julio 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Noviembre 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2023.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Octubre 2024.xlsx </li> <li>- emp_Estudiantes_inasistencias_Per\u00edodo Septiembre 2023.xlsx </li> </ul> 06.Egresados_Graduados<ul> <li>- Graduados_Abril 2022_21_11_2024.xlsx </li> <li>- Graduados_Abril 2023_21_11_2024.xlsx </li> <li>- Graduados_Abril 2024_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2021_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2022_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2023_21_11_2024.xlsx </li> <li>- Graduados_Agosto 2024_21_11_2024.xlsx </li> <li>- Graduados_Diciembre 2021_21_11_2024.xlsx </li> <li>- Graduados_Diciembre 2022_21_11_2024.xlsx </li> <li>- Graduados_Diciembre 2023_21_11_2024.xlsx </li> <li>- Graduados_Enero 2022_21_11_2024.xlsx </li> <li>- Graduados_Enero 2023_21_11_2024.xlsx </li> <li>- Graduados_Enero 2024_21_11_2024.xlsx </li> <li>- Graduados_Febrero 2022_21_11_2024.xlsx </li> <li>- Graduados_Febrero 2023_21_11_2024.xlsx </li> <li>- Graduados_Febrero 2024_21_11_2024.xlsx </li> <li>- Graduados_Julio 2022_21_11_2024.xlsx </li> <li>- Graduados_Julio 2023_21_11_2024.xlsx </li> <li>- Graduados_Julio 2024_21_11_2024.xlsx </li> <li>- Graduados_Junio 2022_21_11_2024.xlsx </li> <li>- Graduados_Junio 2023_21_11_2024.xlsx </li> <li>- Graduados_Junio 2024_21_11_2024.xlsx </li> <li>- Graduados_Marzo 2022_21_11_2024.xlsx </li> <li>- Graduados_Marzo 2023_21_11_2024.xlsx </li> <li>- Graduados_Marzo 2024_21_11_2024.xlsx </li> <li>- Graduados_Mayo 2022_21_11_2024.xlsx </li> <li>- Graduados_Mayo 2023_21_11_2024.xlsx </li> <li>- Graduados_Mayo 2024_21_11_2024.xlsx </li> <li>- Graduados_Noviembre 2022_21_11_2024.xlsx </li> <li>- Graduados_Noviembre 2023_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2019_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2021_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2022_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2023_21_11_2024.xlsx </li> <li>- Graduados_Octubre 2024_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2021_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2022_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2023_21_11_2024.xlsx </li> <li>- Graduados_Septiembre 2024_21_11_2024.xlsx </li> </ul> Procesados Nota: Esta secci\u00f3n contiene los archivos procesados, organizados seg\u00fan la misma estructura jer\u00e1rquica de carpetas original. Los datos han sido preparados y optimizados para su integraci\u00f3n y consumo directo mediante SSIS, garantizando compatibilidad y eficiencia en los procesos ETL.                                                  0001.Docentes<ul> <li>- procesado_emp_Docentes_06_12_2024_19_05.xlsx </li> <li>- procesado_emp_Docentes_06_12_2024_19_06.xlsx </li> <li>- procesado_emp_Docentes_08_12_2024_20_45.xlsx </li> <li>- procesado_emp_Docentes_25_12_2024_06_53.xlsx </li> <li>- procesado_emp_Docentes_28_12_2024_06_58.xlsx </li> </ul> 02.Preinscritos<ul> <li>- procesado_emp_Preinscritos_06_12_2024_19_09.xlsx </li> <li>- procesado_emp_Preinscritos_08_12_2024_20_52.xlsx </li> </ul> 03.Listado_Matriculas<ul> <li>- procesado_emp_Listado_Matriculas_06_12_2024_19_08.xlsx </li> <li>- procesado_emp_Listado_Matriculas_08_12_2024_20_48.xlsx </li> <li>- procesado_emp_Listado_Matriculas_25_12_2024_11_37.xlsx </li> <li>- procesado_emp_Listado_Matriculas_25_12_2024_13_05.xlsx </li> </ul> 04.Consolidado_inasistencias<ul> <li>- procesado_emp_Consolidado_inasistencias_15_12_2024_10_03.xlsx </li> <li>- procesado_emp_Consolidado_inasistencias_15_12_2024_10_11.xlsx </li> <li>- procesado_emp_Consolidado_inasistencias_28_12_2024_07_25.xlsx </li> </ul> 05.Estudiantes_cancelados_por_inasistencias<ul> <li>- procesado_emp_Estudiantes_inasistencias_07_12_2024_04_36.xlsx </li> <li>- procesado_emp_Estudiantes_inasistencias_08_12_2024_20_56.xlsx </li> <li>- procesado_emp_Estudiantes_inasistencias_28_12_2024_07_36.xlsx </li> </ul> 06.Egresados_Graduados<ul> <li>- procesado_emp_Egresados_Graduados_06_12_2024_19_11.xlsx </li> <li>- procesado_emp_Egresados_Graduados_08_12_2024_20_55.xlsx </li> <li>- procesado_emp_Egresados_Graduados_08_12_2024_21_01.xlsx </li> <li>- procesado_emp_Egresados_Graduados_08_12_2024_21_03.xlsx </li> </ul> </ul> 02.C4C <ul> Datos relevantes de la plataforma C4C, divididos en categor\u00edas de educaci\u00f3n y protecci\u00f3n social. 01.Educacion<ul> <li>-archivos_C4C_Educacion.xlsx</li> </ul> 02.Proteccion<ul> <li>-archivos_C4C_Proteccion.xlsx</li> </ul> </ul> 03.Archivos_Manuales <ul> Carpeta que agrupa archivos manuales organizados por tem\u00e1ticas y \u00e1reas espec\u00edficas. 01.Archivos_Seleccionados <ul> 01.Transversal <ul> 01.Dim_Servicios<ul> <li>- AM-TRA-08.xlsx</li> <li>- AM-TRA-08_2022.xlsx</li> <li>- AM-TRA-08_2023.xlsx</li> <li>- AM-TRA-08_2024.xlsx</li> </ul> </ul> 02.Educacion_Formal <ul> 01.Dim_Libros<ul> <li>- AM-EDF-153.xlsx</li> </ul> </ul> 03.Educacion_Tecnica <li>archivos_manuales.xlsx</li> 04.Educacion_Continua <li>archivos_manuales.xlsx</li> 05.Proteccion_Social <li>archivos_manuales.xlsx</li> 02.Estructuras_Propuestas <ul> 01.Transversal <ul> 01.Dim_Servicios<ul> <li>- EP-TRA-04.xlsx</li> <li>- EP-TRA-04_2023.xlsx</li> <li>- EP-TRA-04_2024.xlsx</li> </ul> 02.Dim_Capacidad_Fisica<ul> <li>- EP-TRA-12.xlsx</li> </ul> </ul> 02.Educacion_Formal <ul> 01.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2022.xlsx</li> <li>- EP-TRA-05_2023.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> 02.FACT_AUSENTISMO_DOCENTE<ul> <li>- EP-EDF-02.xlsx</li> </ul> 03.FACT_BIBLIOTECA<ul> <li>- EP-EDF-05.xlsx</li> </ul> 04.FACT_BIBLIOTECA_VIRTUAL<ul> <li>- EP-EDF-06.xlsx</li> </ul> 05.FACT_DESEMPENHO_DOCENTE<ul> <li>- EP-EDF-09.xlsx</li> </ul> 06.FACT_ENFERMERIA<ul> <li>- EP-EDF-01.xlsx</li> </ul> 07.FACT_LEGALIZACION<ul> <li>- EP-EDF-10.xlsx</li> </ul> 08.FACT_PERMISO_ESTUDIANTE<ul> <li>- EP-EDF-04.xlsx</li> </ul> 09.FACT_PSIORIENTACION<ul> <li>- EP-EDF-11.xlsx</li> </ul> 10.FACT_REEMPLAZO_DOCENTE<ul> <li>- EP-EDF-03.xlsx</li> </ul> 11.FACT_RESERVA_ESPACIOS<ul> <li>- EP-EDF-12.xlsx</li> </ul> 12.FACT_SABER11_COLEGIOS<ul> <li>- EP-EDF-08.xlsx</li> </ul> 13.FACT_SABER11_INDIVIDUAL<ul> <li>- EP-EDF-07.xlsx</li> </ul> 14.FACT_SERVICIO_SOCIAL<ul> <li>- EP-EDF-13.xlsx</li> </ul> 15.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2022.xlsx</li> <li>- EP-TRA-05_2023.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> 16.DIM_TARIFAS_SERVICIOS<ul> <li>- EP-TRA-04_2024.xlsx</li> </ul> </ul> 03.Educacion_Tecnica <ul> 01.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> </ul> 04.Educacion_Continua <ul> 01.DIM_PERSONAL<ul> <li>- EP-TRA-05.xlsx</li> <li>- EP-TRA-05_2024.xlsx</li> </ul> </ul> 05.Proteccion_Social <ul> 01.Caracterizacion <ul> AM-PRS-03 <ul><li>- AM-PRS-03-2022.xlsx</li></ul> AM-PRS-10 <ul><li>- AM-PRS-10-202405.xlsx</li></ul> <ul><li>- AM-PRS-10.xlsx</li> AM-PRS-102 <ul><li>- AM-PRS-102.xlsx </li> AM-PRS-11 <ul> <li>- AM-PRS-11-202401.xlsx</li> <li>- AM-PRS-11-202402.xlsx</li> <li>- AM-PRS-11-202403.xlsx</li> <li>- AM-PRS-11-202404.xlsx</li> <li>- AM-PRS-11-202405.xlsx</li> <li>- AM-PRS-11.xlsx</li> </ul> AM-PRS-12 <ul> <li>- AM-PRS-12-2024.xlsx</li> <li>- AM-PRS-12.xlsx</li> </ul> AM-PRS-120 <ul> <li>- AM-PRS-120-202402.xlsx</li> <li>- AM-PRS-120-202403.xlsx</li> <li>- AM-PRS-120-202404.xlsx</li> <li>- AM-PRS-120-202405.xlsx</li> <li>- AM-PRS-120.xlsx</li> </ul> AM-PRS-13 <ul> <li>- AM-PRS-13-2023.xlsx</li> <li>- AM-PRS-13.xlsx</li> </ul> AM-PRS-145 <ul><li>- AM-PRS-145.xlsx </li> AM-PRS-145_CATEGORICAS <ul><li>- AM-PRS-145_CATEGORICAS.xlsx </li> AM-PRS-23 <ul><li>- AM-PRS-23.xlsx</li> AM-PRS-41 <ul><li>- AM-PRS-41.xlsx </li> AM-PRS-81 <ul><li>- AM-PRS-81.xlsx </li> AM-PRS-91 <ul><li>- AM-PRS-91.xlsx </li> AM-PRS-91_CATEGORICAS <ul><li>- AM-PRS-91_CATEGORICAS.xlsx </li> AM-TRA-11 <ul><li>- AM-TRA-11.txt </li> DIM_PROGRAMA <ul><li>- ID_PROGRAMA.xlsx </li> EP-PRS-02 <ul><li>- EP-PSR-02.xlsx </li> EP-PRS-03 <ul><li>- EP-PSR-03.xlsx </li> EP-PSR-01 <ul><li>- EP-PSR-01.xlsx </li> EP-TRA-02 <ul><li>- EP-TRA-02.xlsx </li> NSU CEC <ul> <li>CEC (2).txt </li> <li>CEC.txt </li> <li>comfenalcocec (2).txt </li> <li>comfenalcocec (3).txt </li> <li>comfenalcocec (4).txt </li> <li>comfenalcocec (5).txt </li> <li>comfenalcocec.txt </li> </ul> Cedesarrollo convenios <ul> <li>campanas comfenalcoconvenios (2).txt</li> <li>campanas comfenalcoconvenios (3).txt</li> <li>campanas comfenalcoconvenios (4).txt</li> <li>campanas comfenalcoconvenios (5).txt</li> <li>campanas comfenalcoconvenios.txt</li> <li>Convenios (2).txt</li> <li>Convenios.txt</li> </ul> Consultorias <ul> <li>campanas comfenalcoconsultorias (2).txt</li> <li>campanas comfenalcoconsultorias (3).txt</li> <li>campanas comfenalcoconsultorias (4).txt</li> <li>campanas comfenalcoconsultorias (5).txt</li> <li>campanas comfenalcoconsultorias.txt</li> <li>Consultorias (2).txt</li> <li>Consultorias.txt</li> </ul> Cursos y diplomados <ul> <li>campanas comfenalcodiplomados (2).txt</li> <li>campanas comfenalcodiplomados (3).txt</li> <li>campanas comfenalcodiplomados (4).txt</li> <li>campanas comfenalcodiplomados (5).txt</li> <li>campanas comfenalcodiplomados.txt</li> <li>Cursos y diplomados (2).txt</li> <li>Cursos y diplomados.txt</li> </ul> Egresados <ul> <li>comfenalcocedesarrolloegresados (2).txt</li> <li>comfenalcocedesarrolloegresados (3).txt</li> <li>comfenalcocedesarrolloegresados (4).txt</li> <li>comfenalcocedesarrolloegresados (5).txt</li> <li>comfenalcocedesarrolloegresados.txt</li> <li>Egresado (2).txt</li> <li>Egresado.txt</li> </ul> Estudiantes Activos <ul> <li>base1.txt</li> <li>base1Activos1.txt</li> <li>base2.txt</li> <li>base2Activos0.txt</li> <li>base3.txt</li> <li>base4.txt</li> <li>base5.txt</li> <li>Estudiantes Activos (2).txt</li> <li>Estudiantes Activos.txt</li> </ul> Proteccion social <ul> <li>campanas comfenalcoproteccion(2).txt</li> <li>campanas comfenalcoproteccion(3).txt</li> <li>campanas comfenalcoproteccion(4).txt</li> <li>campanas comfenalcoproteccion(5).txt</li> <li>Proteccion social (2).txt</li> <li>Proteccion social.txt</li> </ul> 02.DIM_PERSONAL <ul><li>- EP-TRA-05.xlsx  </li> <ul><li>- EP-TRA-02.xlsx </li> </ul> </ul> </ul> 03.Otros_Archivos <ul> <li>AM-DRE-05_08_12_2024.xlsx</li> <li>AM-DRE-05_25_12_2024.xlsx</li> <li>AM-DRE-16.xls</li> <li>AM-EPT-47.xlsx</li> <li>EP-EDF-02.xlsx</li> <li>EP-EDF-04.xlsx</li> <li>EP-EDF-09.xlsx</li> <li>EP-EPT-04.xlsx</li> <li>EP-EPT-06.xlsx</li> <li>EP-EPT-07.xlsx</li> <li>EP-EPT-08.xlsx</li> <li>EP-EPT-09.xlsx</li> <li>EP-EPT-10.xlsx</li> <li>EP-EPT-11.xlsx</li> <li>EP-EPT-12.xlsx</li> </ul> </ul> <p>Nota: Desplegar los items para ver su contenido</p>"},{"location":"05.Power_BI/00.Introduccion/","title":"Introducci\u00f3n","text":""},{"location":"05.Power_BI/00.Introduccion/#visualizaciones-del-tablero-analitico-de-educacion","title":"Visualizaciones del Tablero Anal\u00edtico de Educaci\u00f3n","text":""},{"location":"05.Power_BI/00.Introduccion/#1-menu-de-navegacion","title":"1. Men\u00fa de Navegaci\u00f3n","text":"<p>El tablero se estructura en varias secciones principales, cada una enfocada en un aspecto clave del proceso educativo. Estas secciones incluyen an\u00e1lisis espec\u00edficos que permiten evaluar tanto la productividad como el impacto social del sistema educativo:</p> <p></p> <ul> <li> <p>Productividad Organizacional - An\u00e1lisis de Desempe\u00f1o y Calidad:  </p> <p>Aborda la calidad del proceso educativo, evaluando indicadores como desempe\u00f1o docente y resultados en evaluaciones externas.  </p> </li> <li> <p>Productividad Organizacional - An\u00e1lisis de Eficiencia:  </p> <p>Analiza el uso de recursos, inversiones en infraestructura y el rendimiento operativo del sistema educativo.  </p> </li> <li> <p>Impacto Social y Comunitario - An\u00e1lisis por Servicio:  </p> <p>Examina c\u00f3mo los servicios educativos impactan a los beneficiarios seg\u00fan diferentes categor\u00edas y \u00e1reas de acci\u00f3n.  </p> </li> <li> <p>Impacto Social y Comunitario - An\u00e1lisis por Empresa:  </p> <p>Relaciona los servicios proporcionados a empresas afiliadas con los subsidios y aportes realizados.  </p> </li> </ul>"},{"location":"05.Power_BI/00.Introduccion/#2-analisis-del-perfil-del-proceso-de-educacion","title":"2. An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n","text":"<p>Esta secci\u00f3n brinda un panorama general del estado del proceso educativo, resaltando:</p> <ul> <li>Informaci\u00f3n consolidada de afiliados, beneficiarios y empresas atendidas.  </li> <li>Indicadores clave relacionados con la utilizaci\u00f3n de recursos y la experiencia del usuario.  </li> </ul> <p>Objetivo: Ofrecer un contexto general que facilite la identificaci\u00f3n de tendencias y \u00e1reas cr\u00edticas en las operaciones educativas.</p>"},{"location":"05.Power_BI/00.Introduccion/#3-productividad-organizacional-analisis-de-desempeno-y-calidad","title":"3. Productividad Organizacional - An\u00e1lisis de Desempe\u00f1o y Calidad","text":"<p>El an\u00e1lisis en esta secci\u00f3n incluye:</p> <ul> <li>Evaluaci\u00f3n del impacto de las estrategias educativas en los resultados de estudiantes y docentes.  </li> <li>M\u00e9tricas sobre calidad educativa, como la relaci\u00f3n entre cobertura y desempe\u00f1o acad\u00e9mico.  </li> </ul> <p>Objetivo: Garantizar que la calidad de los programas educativos responda a los est\u00e1ndares esperados y fomente un aprendizaje efectivo.</p>"},{"location":"05.Power_BI/00.Introduccion/#4-productividad-organizacional-analisis-de-eficiencia","title":"4. Productividad Organizacional - An\u00e1lisis de Eficiencia","text":"<p>Esta secci\u00f3n est\u00e1 dise\u00f1ada para identificar oportunidades de mejora en la gesti\u00f3n de recursos mediante el an\u00e1lisis de:</p> <ul> <li>Uso de infraestructura f\u00edsica y tecnol\u00f3gica.  </li> <li>Indicadores de gesti\u00f3n como tiempo administrativo efectivo y rotaci\u00f3n del personal.  </li> </ul> <p>Objetivo: Optimizar los recursos disponibles y maximizar la eficiencia operativa del sistema educativo.</p>"},{"location":"05.Power_BI/00.Introduccion/#5-impacto-social-y-comunitario-analisis-por-servicio","title":"5. Impacto Social y Comunitario - An\u00e1lisis por Servicio","text":"<p>Permite desglosar el impacto generado por servicios educativos individuales, considerando indicadores como:  </p> <ul> <li>Inclusi\u00f3n y accesibilidad para diferentes grupos demogr\u00e1ficos.  </li> <li>Participaci\u00f3n en actividades de bienestar y desarrollo.  </li> </ul> <p>Objetivo: Cuantificar el impacto de cada servicio en t\u00e9rminos de bienestar social y comunitario.</p>"},{"location":"05.Power_BI/00.Introduccion/#6-impacto-social-y-comunitario-analisis-por-empresa","title":"6. Impacto Social y Comunitario - An\u00e1lisis por Empresa","text":"<p>Esta visualizaci\u00f3n combina datos relacionados con las empresas afiliadas y los servicios educativos que reciben. Se analizan:</p> <ul> <li>Subsidios otorgados y servicios vendidos seg\u00fan tipo de operaci\u00f3n.  </li> <li>Relaci\u00f3n entre los aportes empresariales y los beneficios obtenidos.  </li> </ul> <p>Objetivo: Medir el retorno de inversi\u00f3n social y econ\u00f3mica desde la perspectiva empresarial, asegurando la sostenibilidad del sistema educativo.</p>"},{"location":"05.Power_BI/00.Introduccion/#diagrama-de-flujo-general","title":"Diagrama de Flujo General","text":"<pre><code>flowchart TD\n    A[Perfil del Proceso Educativo] --&gt; B[Desempe\u00f1o y Calidad]\n    A --&gt; C[Eficiencia]\n    A --&gt; D[Impacto por Servicio]\n    A --&gt; E[Impacto por Empresa]\n    B --&gt; F[Indicadores de Resultados]\n    C --&gt; G[Uso de Recursos]\n    D --&gt; H[Impacto Social por Categor\u00eda]\n    E --&gt; I[Relaci\u00f3n Servicios-Aportes]</code></pre>"},{"location":"05.Power_BI/00.Introduccion/#conclusion","title":"Conclusi\u00f3n","text":"<p>El tablero anal\u00edtico est\u00e1 dise\u00f1ado para ofrecer una visi\u00f3n integral del proceso educativo, permitiendo a los responsables tomar decisiones estrat\u00e9gicas basadas en datos. Su estructura modular facilita la identificaci\u00f3n de oportunidades de mejora y el seguimiento del impacto en todos los niveles, desde la eficiencia operativa hasta los beneficios sociales y econ\u00f3micos.</p>"},{"location":"05.Power_BI/01.Dashboard/","title":"01. DASHBOARD","text":""},{"location":"05.Power_BI/01.Dashboard/#analisis-del-perfil-del-proceso-de-educacion","title":"An\u00e1lisis del Perfil del Proceso de Educaci\u00f3n","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el estado general del proceso de Educaci\u00f3n y sus unidades de negocio a la fecha de corte. En la parte superior, se muestra un men\u00fa de navegaci\u00f3n que permite explorar diferentes an\u00e1lisis estrat\u00e9gicos. A la izquierda, se encuentran opciones para analizar aspectos clave como Totales de Negocio, Utilizaci\u00f3n, Capacidad F\u00edsica y Experiencia de Usuario. Al centro y a la derecha, se destacan indicadores estrat\u00e9gicos como empresas atendidas, afiliados atendidos, beneficiarios, servicios ofertados y vendidos, as\u00ed como informaci\u00f3n sobre aportes y subsidios. Esto permite un an\u00e1lisis integral y detallado de los datos.</p>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-desempeno-y-calidad","title":"Productividad Organizacional - An\u00e1lisis de Desempe\u00f1o y calidad","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el comportamiento de los resultados de las unidades de Educaci\u00f3n y c\u00f3mo impactan en la calidad, tanto de la formaci\u00f3n como de la gesti\u00f3n de la unidad. En la parte superior, se encuentra un men\u00fa de navegaci\u00f3n que facilita el acceso a an\u00e1lisis relacionados con desempe\u00f1o, eficiencia y otras perspectivas estrat\u00e9gicas. A la izquierda, se ofrecen opciones para analizar aspectos clave como Desempe\u00f1o, Comportamientos hist\u00f3ricos, Comportamiento financiero, Experiencia de Usuario y An\u00e1lisis Miner\u00eda. Al centro y derecha, se destacan indicadores clave como empresas afiliadas, afiliados atendidos y beneficiarios atendidos. Adem\u00e1s, se puede seleccionar el proceso de matr\u00edcula para analizar variantes espec\u00edficas a trav\u00e9s del control deslizante.</p>"},{"location":"05.Power_BI/01.Dashboard/#productividad-organizacional-analisis-de-eficiencia","title":"Productividad Organizacional - An\u00e1lisis de Eficiencia","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el comportamiento de la capacidad, inversi\u00f3n en infraestructura y los principales indicadores de productividad. En la parte superior, se encuentra un men\u00fa de navegaci\u00f3n que permite explorar an\u00e1lisis estrat\u00e9gicos relacionados con desempe\u00f1o, eficiencia y otras perspectivas. A la izquierda, se ofrecen opciones para analizar \u00e1reas como Educaci\u00f3n Formal, Educaci\u00f3n T\u00e9cnica, Educaci\u00f3n Continua y Protecci\u00f3n Social. Al centro y a la derecha, se presentan indicadores clave como horas contratadas, inversi\u00f3n en infraestructura f\u00edsica y tecnol\u00f3gica, porcentaje de utilizaci\u00f3n de bibliotecas virtuales y movilidad acad\u00e9mica. Adem\u00e1s, se incluyen gr\u00e1ficos sobre reductores de capacidad contratada para facilitar el an\u00e1lisis detallado.</p>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-servicio","title":"Impacto Social y Comunitario - An\u00e1lisis por Servicio","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el impacto social y comunitario de los servicios ofrecidos por el proceso de Educaci\u00f3n. En la parte superior, se encuentra un men\u00fa de navegaci\u00f3n para explorar diferentes an\u00e1lisis estrat\u00e9gicos. A la izquierda, se ofrecen opciones para analizar \u00e1reas como Educaci\u00f3n Formal, Educaci\u00f3n para el Trabajo, Desarrollo Empresarial y Protecci\u00f3n Social. En el centro y a la derecha, se destacan indicadores clave como porcentaje de detractores, porcentaje de promotores, atenci\u00f3n a poblaci\u00f3n vulnerable, afiliados atendidos y empresas atendidas. Adem\u00e1s, se incluyen gr\u00e1ficos que detallan servicios ofertados, afiliados por categor\u00eda, g\u00e9nero y estrato, as\u00ed como el recuento de actividades realizadas y empresas afiliadas por fecha.</p>"},{"location":"05.Power_BI/01.Dashboard/#impacto-social-y-comunitario-analisis-por-empresa","title":"Impacto Social y Comunitario - An\u00e1lisis por Empresa","text":"<p>El objetivo de esta visualizaci\u00f3n es presentar el impacto social de los servicios ofrecidos por el proceso de Educaci\u00f3n, agrupados por empresas. En la parte superior, se encuentra un men\u00fa de navegaci\u00f3n para explorar an\u00e1lisis estrat\u00e9gicos. A la izquierda, se ofrecen opciones para analizar indicadores por empresa, relaci\u00f3n de servicios y aportes, as\u00ed como servicios vendidos y subsidios hist\u00f3ricos. Al centro y derecha, se destacan indicadores como cantidad de aportes de empresas atendidas en Educaci\u00f3n, valor de subsidios a la demanda y n\u00famero de servicios vendidos clasificados por tipo de operaci\u00f3n. Esta visualizaci\u00f3n permite realizar un an\u00e1lisis detallado de los datos hist\u00f3ricos de servicios y subsidios.</p>"}]}